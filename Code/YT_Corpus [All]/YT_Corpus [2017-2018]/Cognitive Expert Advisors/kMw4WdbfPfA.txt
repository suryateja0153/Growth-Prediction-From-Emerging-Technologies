 Welcome to Episode #237 of CxOTalk. We are speaking about the future of work, and the disruptions that are changing our lives, and changing our society. I'm Michael Krigsman, an industry analyst and the host of CxOTalk. Before we go farther, I want to thank Livestream, who is our live streaming infrastructure distribution partner. Livestream is great. Those guys are fantastic. And if you go to Livestream.com/CxOTalk, they will give you a discount on their programs; their solutions; their plans, that's the word. That's the word. Their plans. So, we have an amazing show today. And, I’m joined by two truly extraordinary people. I am joined by Frank Diana, who is the futurist at TCS consultancy services, and TCS is the largest of the Indian outsourcing companies with $17.5 billion dollars of revenue and 400,000 employees. And I’m also joined by Anthony Scriffignano, who is the Chief Data Scientist with Dun & Bradstreet. Hey, Frank! How are doing? I’m doing great! So, thank you for being here. This is your first time on CxOTalk, and please, tell us about TCS and tell us what do you do as a futurist? I get that question a lot. Well first, thanks for having me. And so, Tata Consultancy Services, as you mentioned, the largest of the Indian firms at $17.5 billion, 400,00 employees. And really, it's about innovative consulting solutions and services, global … We have a footprint just about everywhere, innovation labs and research centers all around the world, so we're really at the forefront of bleeding-edge kinds of things that we'll talk about a little bit today. And myself, I’m a futurist. I do focus on the next 20-30 years, as unrealistic as that may seem, but in a way, that drives action for leaders today. Fantastic! And we will dive into your future predictions very quickly. Anthony Scriffignano, you have been on CxOTalk several times. Welcome back! Thank you very much, Michael! You are the Chief Data Scientist at Dun & Bradstreet, so tell us briefly about Dun & Bradstreet, and what do you do there? [Laughter] Sure. The second one is an interesting question, but I'll answer the first question first. So, Dun & Bradstreet is nowhere near as large as TCS, but we are one of the oldest companies in the United States. Just under 30 million companies in the United States and there are about eleven that are as old as Dun & Bradstreet. So, we are in our 176th year, and we capture information about businesses all over the world to help our customers make decisions about total risk and total opportunity, and compliance, and understanding their supply chain, things like that. So, business-to-business is our priority focus. And, my role as Chief Data Scientist is a little bit of what Frank talks about. So, understanding what's over the horizon, understanding what the new, emerging and enabling capabilities to need to be to get this right in such a changing world with Big Data, and so-forth. So, think artificial intelligence, geospatial inference, computational linguistics, all kinds of cool stuff like that. And then also, I work with our customers to kind of bigify what they're doing with us, to help us help them more with solving problems with data and also with the insight that comes from it. And then, I do a lot of work with governments around the world as regulations are changing and things like data privacy and data sovereignty and so forth, I'm called upon to opine upon that around the world. Okay. Very interesting. So, we are going to be speaking a lot about data, today, and the impact of data on the future of work. And I want to remind everybody that during this live show, we have a tweet chat going on. Use the hashtag #cxotalk, and you can ask our guests questions and interact with them very directly. So, Frank, let’s ask you to kick this off. We’re talking about disruptions and the future of work. What are some of these key disruptions that you see, that are going to change our work environment? And obviously, if our work environment is changing, there is also going to be a change to our social environment and our culture. These things are all mixed together. They absolutely are, and it's really the intersection of all those things is creating this emerging future, if you will. So, I focus on more societal factors, science, technology, economics; where they intersect; and when they do intersect, what kinds of scenarios do they create. And it's actually those scenarios. I track a number of emerging future scenarios that are the disruptive factors in the world today. And so really, it's about, I think more importantly for companies and leaders everywhere, about understanding those scenarios, how they intersect. Connecting dots; I believe that's one of the biggest leadership traits going forward is "How do you connect these dots in a way that will allow us to see where these things are going?" So, yup. It's going to impact work, it's going to impact humanity at a very broad level, and there's a lot of ethical discussions that are going to be had, I think, in the next several years. So, what are these forces? Either of you, what are these forces that are shaping the future of work? So, let me kick that off and I’d love to get Anthony’s perspective on it as well. Things like the driverless car is an easy one. That one, in the last six months to a year, has really taken off, and now people don't see it as science fiction anymore, but that driverless car, as just one scenario, has brought in deep implications across every sector. And when you actually start to look at that, you appreciate just how disruptive and impactful that one scenario is. But how about things like healthy life extension? That's one of the scenarios that I'm tracking as well, as we've looked to extend our lives, and that's not just in terms of years lived, but healthy years lived. And, what does that mean to retirement? And what does that mean to insurance, and all of the things that, really, we think about? And on, and on, and on; the maker economy. The sharing access economy. These are all scenarios that I call … And again, they do intersect and intertwine. Very impactful! So, maybe I can just add a little bit to that. On the driverless car, I would expand that to this concept of autonomy. So, we have things. We have cars. We have drones. We have fill-in-the-blank. And these things have agents in them that are describing their behavior, so we give them goals. In the case of a car, it might be “drive safely and get where you’re going.” And then all of a sudden, these autonomous agents need the ability to modify their goals. Something changes in the environment, somebody runs out in front of the car, etc. And now, we are … Autonomous agents are given the power to change their behavior at our request. That’s going to change everything for us. That’s going to change the way we interact with our agents because they may not be doing what we ask them to do anymore. Kind of like children, right? And also, because those agents might be able to think faster than we can, doesn’t necessarily mean that they have the experience and the context that we do, with the emotion that we do. So, if I could tie that to the healthy living comment, think about things like senior care. Think about things like understanding how to deal with people in the end-stages of life. Do we want autonomous agents doing that? I don't think so. So, I think at some level, this disruptive change gives us the opportunity to focus on things that human beings uniquely do better than machines, at least in the thirty-year horizon that we can see. And also, we have to pay attention to what we're giving up to those machines and make sure that that's not happening by accident. And, I would add one last thing, which is that not all of this innovation is for good. So, think about the ways that the band guys can use this disruptive innovation that's happening all around us to disrupt in ways that we don't even have words for, yet. So, there's a very high cost to doing nothing. And that high cost is that some of that innovation happens without us paying attention, and then we get disrupted in ways that are really terrifying and surprising at the same time. Frank, go ahead. I know you have thoughts on this. Oh, lots of thoughts! So, it’s a balance in my mind as we watch these scenarios play out. One, we want the positive, constructive things for society that plenty has. So, when you can solve the cancer issues with nanobots that target the cancer cells directly, we want those things to happen. We don't want the kinds of things that Anthony's talking about that happens. We need to manage against those things. But, history has taught us that we focus on the positive aspects of these advances, for good reason. But then, once you've done so, the negative is very easy to follow from that. So, I always use the example of plastic surgery, which was intended, initially, for the main soldiers in the battlefields, and we know where that went after the fact, right? Now, think about that in the context of what's emerging, and where they're likely to go after we've used them to solve some real challenges positively. But, the negative side is obviously the things we need to worry about. I think we also have to be very, very careful about the attribution of positive and negative because that's a matter of perspective sometimes. And, when we're thinking in a global context, what we want, wherever we are, isn't necessarily what others want. And so, this concept of really understanding the greater good is a common thing. So, we understand that having a clean environment is good for the Earth, right? But there are parts of the world like, say, developing nations, may be more focused on manufacturing and GDP growth than they are focused on their environment, and we shouldn’t necessarily judge that, but we should have the right advocacy to make sure that our opinion and our perspective is balanced with those of others. The other thing that I would say is that as we think about things revolving around us, it's not just the cost of doing nothing. When we choose to do something, when we choose to pursue a particular technology; nanobots are a great example; it takes a lot of effort to pursue something like that. When we pursue that, we dedicate precious resources to that pursuit; the most precious of which are human brains; human hearts, and human minds. And, in so doing, we're not doing something else. We have to choose very carefully in an environment that is evolving so quickly because the cost of setting out on that wrong journey can be very critical in terms of lost opportunity. Yeah. I agree. And Anthony, I do have a question for you in terms of choosing. You know, in the past, when governments and military were those folks that kind of managed to where science and technology went, I think those things are gone. And we know we’ve got techno-philanthropists that are spending their wealth on things that we aren’t able to control. So, how do we control the path of these scenarios? I don’t know that we control it. I would say that we try our best to influence it, and if we are right, then that influence will take hold. But, I think this concept of control and regulation … I’m not saying there shouldn’t be regulation, but it’s very hard to regulate emerging technologies because the technologies don’t exist yet. If the legislation gets out in front of the technology and the technology wants to do something that’s regulated, it can evolve in a different way; sort of orthogonally. So, there’s this little bit of a kabuki dance always, between what we are capable of doing and what we should do, and what we may do. And, I think that we get better at that over time when we focus on it. If I just used drones as an example, there’s a lot of things happening with drones right now that maybe weren’t intended when the drones were created. The legislation that covers, or the regulation that covers drones was primarily designed for aircraft. So, some new things around drones, right now. But most of it’s around aircraft. And, when the aircraft legislation was being written, some aircraft were, you know, pretty slow and propeller-driven, and now we have speed limits in the sky. So, I think you’re always going to see this sort of collaboration of the collective environment to kind of converge around the right behaviors, some of which will be regulated, and some of which will be sort of adopted by it. We all drive on the right side of the road, on the correct side of the road, not just because it’s the law, but because it’s terrifying to think about driving down the wrong side of the road when everybody’s driving down the right side of the road. So, you know, there’s a little bit of “I do it because it’s the law,” and there’s part of it is “I do it because it would be crazy not to do it.” Yeah. That’s all regulation and policy. Clear. But what about things like the AI Consortium that was recently formed, right? I mean, is that an attempt to get in front of some of the potential impacts of AI going forward? Yeah. It is, I believe. I don’t know that you can get in front of something like that. I mean, let’s just talk about AI. What is it? Define it. You know, you can get five people in the room that are experts in AI and they’ll have six different opinions on what that definition should be. So, yeah. I think that things like that can be helpful, but things like that also tend to marginalize it. They tend to keep people out. You’re either part of the consortium or you’re not with any consortium. If you’re not, what does that imply in terms of access to resources and mindshare, and market? I don’t think it’s as simple as having a consortium. I don’t think it ever has been, historically. I'm not saying therefore, we shouldn't have one; just saying "Necessary, but not sufficient." Also, I want to jump back in a moment to the impact on work. But, since you’re talking about these types of consortiums, how do you separate the ostensibly altruistic goals that are projected, advertised, and marketed from the reality that these are cutthroat business interests. And, I really wonder how altruistic these various consortia are. Thoughts? Either of you? That’s a great point! I like to use the sharing economy as an example. I mean, there’s nothing really sharing about the […] modus of the owners of those networks and platforms, right? So, but, that’s the way it starts. If you were to look fifty years down the road, there is this notion that the profit motive that is driven and has underpinned most of what we do gives away, at some point, to a purpose motive where the altruistic things that you talk about really are what drives us. And we clearly see from a generational aspect that purpose and social good is starting to really kind of weave itself into the fabric of even some corporate mission statements. But, we’re clearly not there yet. I think it’s a path that’s an evolutionary path. Yeah. I would just add that sometimes, the rush to market causes really, I’d like to have a better term, but boneheaded things to happen because the rush to market didn’t anticipate the unintended use of the thing that was rushed to market. So, I think organizations, more and more, are being called on the carpet when they do things like that. There’s an impact in terms of reputational risk to the organization, there’s an impact in terms of their customer dynamic. Customers are more fluid than they used to be in many industries. They can be fickle, they can move to other suppliers of goods and services. So, to your point, Frank, I think you’re absolutely right that there is more impact to ignoring that sort of thing than there ever was in the past. We have a question from Twitter. Bob Russellman is asking, I think, the question that everybody ultimately wants to know, or one of them, which is, when we talk about the future of work, what about, and this is his question, “income alignment trends?” The rich get more, the poor get less. Capital owns the technology. What about the ramifications of this? And now you weave this into the future of work and AI, and all of that, and it’s very messy. So, what about that? Yeah. Income inequality, I think, has exacerbated over the next several years primarily because, again, the wealthy who will be able to afford some of these things that are coming; for example, driverless cars, if we may start there. Extending our healthy lives might be only something that the wealthy can do initially until the price points come down. But so, I believe income inequality is exacerbating, actually, over the next several years. And it is an issue. It gets even more amplified when we start talking about the impact to jobs that automation and artificial intelligence will bring. So, there are some really tricky policy issues in front of us. And, Frank, I think I might have gotten it from you that a very large percentage of males around the world that are on lower incomes are employed driving things. So, that income inequality or as I would call it "marginalization" ... because you get pushed out. If something else can drive the thing rather than you, then that something else is not another person and we've created an exacerbation of that income inequality. There is, perhaps; it's not a perfect analog; but there's a lesson in history, I think when semiconductors started to come out. So, with solid-state devices, there were lots of people that knew how to fix things that had tube technology and resistors, and things that could kind of see and go and replace, and now all of a sudden, chips are here. You know, solid-state technology, miniaturization to the point where people who know how to fix things that are big and mostly analog aren't as much needed. Some of those people were about to make the shift and do other things and it freed them up to possibly even make more money doing cooler things. Some of them, quite honestly, got driven out of a job, forced into retirement, and forced into lower income, lower-paying jobs. So, definitely a real phenomenon and now multiply that by thousands, and you get what’s going on today, because almost any job is impacted by, “Maybe my boss will be a robot tomorrow." I would argue, to some extent, my boss is a robot today. I get a message on my phone that tells me I have a meeting in fifteen minutes. I look at it and I go to the meeting. My phone told me to go to that meeting. I'm okay with that because, at some level, I told my phone to tell me that. At some point in the future, my phone's going to say, "Don't go to that meeting because I think you should be doing this instead." That's a line that we'll cross without noticing, and I think we have to be very careful about that line. Yeah. I mean, I guess it goes from digital assistant, at some point, to digital agent, and the agent knows more about you than you know about yourself. And then, eventually, it gets to "digital overlord," which is what I worry about. Right! [Laughter] There's a progression from assistant to overlord, I guess is the question. And here's to go back to the point around inequality and jobs and, I guess, future work is part of the topic here. And the economists do seem to be split on this notion of "We've been here before, we've solved this problem before, and so this is just another blip on the radar," versus "We've never been here before, and the kind of lifelong learning that's going to be required going forward, the skillsets required to really do the jobs of the future just not skill sets that are readily adaptable too." And the education system really not being set to educate at this level, and at this speed. So, now I have my own opinion in terms of where things are heading, but those are all challenges that have led to some governments talking about Universal Basic Income, and we need to go to that path at some point in time because of this issue. You know, I was listening to a podcast this morning that had to do with a TV show, a popular TV show. And the makers of the show were talking about how maybe you don't need to go to film school anymore. You can go and buy a digital camera that will perform more than well enough to record your own content and you can learn how to be a director by watching other directors, and you can learn this anyway. And, I don't know. It's something I feel, but I suspect there's some theory behind it, I suspect there's some history that you need to know. And I think what's happening to some extent with the availability of technology is that certain careers, or certain, let's just say "undertakings" that would otherwise have been inaccessible are becoming accessible to the masses. So, there might be some derivative counterforce here that … This isn't going to help people who are at the lowest end of the economy, this isn't going to help people in developing nations. So, I'm not insensitive to the fact that if I look at the Earth, probably more people will be disenfranchised than enabled in terms of income inequality. But, I do see some opportunity that maybe we don’t have a name for yet. And we have another question from Twitter that is just right on point here. Arsalan Khan is saying, okay, “If AI can be your stockbroker,” and certainly, that’s happening all the time right now, Robo-advisors, “If AI can be your stockbroker, your employee, then the levels of disenfranchisement or potential disenfranchisement range across the board.” I mean, what occupations are even going to be safe? And so, there are tremendous public policy implications to all of this. Tremendous ones! Absolutely. So, the AI question is a really good one. I know Anthony knows this really well. If we think about knowledge work, and the fact that we historically felt that knowledge work was safe; and now we know, because it’s already happening, that AI and other analytic kinds of approaches can deal with a lot of knowledge work. And so, what does that mean to our knowledge workers over time? So, those are a set of jobs that once were projected to be sage, and we believe they're no longer going to be safe. And then, it begs the question, what is it that humans can do that machines can't? And so, we focus on the right-brain side of our human traits: the creativity, the imagination, you know, the innovation; those kinds of things that make us different from machines. And then we start to feel safe that if we focus there, things will be fine, just to find out that, you know, machines can compose symphonies that are indiscernible from a human-composed one. And at the Olympics, 400+ articles were written by machines as opposed to journalists. I mean, those kinds of things are also out there. So, it's a great question in terms of what is that segment of space that humans can remain different in? There was … I’m sorry. I was just going to say, Anthony, I apologize; that I recently saw Michael Chui who is the head of McKinsey Global Institute, and also has been a guest here on CxOTalk, give a talk last week, as a matter of fact. And, he was describing a study they did to Frank’s point that even CIOs, they … CEOs, rather… They analyzed all kinds of different jobs. And even CEOs have a significant proportion of their work that can be automated using AI techniques. So, nobody is immune. And, Anthony, I apologize. I interrupted you. No, that’s okay. I was going to pick up on the automated authoring of articles for the Olympics. And, I’m going to come back to what you just said about the CEOs, Michael. Alright, I happen to have the great opportunity and tremendous pleasure of working with some of the folks that were developing that technology in the previous Olympics. Amazing stuff! Absolutely amazing stuff! But, it makes a lot of sense when you have something like the Olympics where there’s going to be events that are well-known in advance. We know when they’re going to happen, and we know pretty much somebody’s going to win, somebody’s going to lose, somebody’s going to break a record or not break a record. The outcomes are relatively well-understood. And so, the question comes up: Could I write a piece of software that could write an article about an event like that that passes the Turing Test – that lets people believe that it was written by a human? And the answer is “yes,” until a hot air balloon lands in the middle of the track that was unexpected or, all of a sudden a geyser opens up. See, these unexpected things start to happen and algorithms aren’t going to be so good at that because they haven’t been taught to write about it; whereas, a reporter would jump in and say, “This is the coolest thing ever! A hot air balloon just landed in the middle of the track and I’m going to write about it first, and I’m going to get the greatest article and I’m going to get the Pulitzer Prize.” So, I think that there's my New Jersey coming out… So, I think that, you know, the unprecedented, the surprising, the never before happened, are great opportunities for human beings to still shine and do what human beings do. And by the way, there's a lot of unprecedented never-before-happened going on right now. So, I'm still okay with letting a machine make a suggestion to me about maybe what stock I should buy or not buy. I still have to think about independence and ethics, and things that maybe algorithms can't know. And coming back to the CEO, there's a great promise right now with technologies like cognitive computing and deep learning , where either the AI method kinds of walks alongside you and reads everything that's been written and knows about everything that you should be paying attention to, to help suggest to you how you need to go. But, you still get to use your human intuition and your use of experience to make the decision. I'd love for CEOs to be able to have technology like that. Doctors have technology like that right now, and it's doing great stuff. I'm not so sure I wanted to make the final decision about whether I cut the blue wire or the red wire when I'm disarming a bomb, but there's certain things where I like to get a little bit of help. So, I don't consider that a threat at all. I consider that great help. The one last thing I’ll say is that some of the neuromorphic methods like neural networks and deep learning where they’re making a decision; the unprecedented will always be confounding. And so, we should be humble about what technologies like that should be allowed to do, and careful not to allow them to cross that line. Frank, your thoughts? I mean, this is a … Well, it's a great conversation and I'm encouraged to hear Anthony's thoughts on us humans still have a role. The question I'd ask Anthony is around, let's just focus on the driverless car for now, because at some point in time, it is the algorithms that are making all of the decisions when we're at that fully-autonomous stage, right? And, lots of conversations around the ethics associated with does it decide to hit the bus full of children? Or does it protect the driver which is really its main charter? And now, an algorithm's making that choice at some point. How do you see that playing out? Well, if I look at the auto-flight systems in airplanes, which have been doing some degree of autonomous control for quite some time, they’re all more or less programmed to do certain things like maintain altitude and speed, but I don’t think any of us believes that it’s like Bugs Bunny where you push the takeoff and land button and then you just sit back and drink coffee. There’s still a lot for a pilot to do like listen to the radio and understand what’s going on and take over the controls when there’s some sort of wing vortex or whatever happens that wasn’t anticipated. And so, I think we still, right now, even with autonomous self-driving cars, I’m pretty sure we haven’t crossed the line of totally taking people out of the loop! We probably will. And, there will probably be delivery cars that do that, and so forth. And, I’m kind of okay with it at some level, because that type of decision making is already happening for us in many other ways, but I do think we need to keep an eye on it. And I do think we need to be aware that it will never be completely what science fiction tells us it will be, because of the fact that the world in front of us is always changing. It was a great example, not too long ago that was a bunch of kids that were in one of the cities where these cars are being developed. And they were creating homemade stop signs and stepping out on the side of the road and holding up their homemade stop signs. “Ha, ha! Look, I made the self-driving car stop!” It’s all funny until somebody goes to the ER because the car behind it had to crash. You know, those things can happen, so now we have to teach self-driving cars to be aware of when they may be being duped. And, you know, that’s never going to end. So, I don’t think we’ll ever … It’s an asymptotic thing. I don’t think we’ll ever reach the point where we just give up, say, we can just sit back and drink martinis and let the computers do everything for us. But think about the impact that autonomous cars will have on the economy, for example. So, of course, the future of work directly, but I forget the numbers, but the automotive industry employs, or has an impact on a huge, huge number of people. Yeah. We have a show coming up, incidentally, in a few weeks with the Chief Data and Analytics Officer of Ford, specifically to talk about this. So, you start affecting these jobs and autonomous vehicles may directly replace, say truck driver jobs, eventually. But, the downstream impact, in terms of lower car ownership affects all the feeder systems for the automotive suppliers and the parts suppliers. So, I know that individual that you’ll be talking to, and I don't want to channel my inner, I'm not even going to say his name, but I think I can, and I'm smiling and I hope he sees this. I think what he'll probably say is, look, robots have been building cars for years! Don't talk to me about an industry that's been more impacted by the advance in technology than the automotive industry. We get this, and it's what we do, and it's what we do well, so we will evolve and we will use the information to do things that we weren't able to do before because of that automation, and we'll be just fine. In fact, we'll be even better. I suspect he will not give you a doom and gloom version of that. And, if I could jump in and this isn’t a doom and gloom version, but I think this is where I focus a lot of my time on, and that is really the movement from the vertical value chain orientations of our past to more horizontal ecosystems that are emerging in the future. So, if we think about this in the context of a mobility ecosystem, that the depth and breadth of impact are massive and so it’s not just a lens that says it’s the traditional automotive view, but it’s all the hotels and motels and restaurants that are affected when truckers no longer stop in local locales and spend money, right? We talk about part suppliers, but what about insurers and the P&C impact to their insurance premiums? What about hospitals and emergency rooms when people aren’t dying by death by auto, right? All of those things when … When I go for an exercise that looks at the breadth and depth of impact, those are things that people don’t focus on, because we have this view that it’s the industry – automotive – and not really the cross-industry impacts of some of these emerging scenarios. In Japan, in decades past, women were pretty much kept out of senior-level positions, or really significant positions in the workforce. And, at that time, it’s within my lifetime, some of those women would actually argue behind the scenes that they had more time to play the piano and learn to speak other languages and study art, and so it wasn’t all that horrible. Now, this is a very, can be easily taken as a horribly sexist comment. I don’t mean it that way. Today, women have access to jobs that they didn’t have access to before and that’s great. I think what society, what I've seen, at least, in understanding how shifts have occurred in society as people get pushed out of, or drawn into different industries, is that we, as a human race, find other opportunities. We create other opportunities. And I'm not trying to sound overly altruistic, but I don't necessarily think that having fewer people stop at my truck stop means that now, I'm done. Maybe, I turn my truck stop into a movie theater. I don't know! I don't know what I do, but I know that the smart people will figure out how to turn that opportunity or that risk into some sort of an opportunity. Whether it will employ the same number of people or not remains to be seen, and the answer is probably not. I'm not so sure it's such a horrible thing if we don't all have to work 80 hours a week anymore. But, wait a second. You said that you’re not going down the gloom and doom pathway, Anthony. But, if what you’re saying actually comes … I wasn’t trying to … Just kidding. [Laughter] Well, but what you’re just saying … Think about this. You were just saying that, at least in the short-run, there may be a lot of job disruption, which is a very kind of clinical way of saying a lot of people are going to lose their jobs and … Or, have to find other jobs. Yeah, but how … Yes, okay. Fine. That’s the same thing, right? Lose their job or have to find other jobs. But, the point that I was going to make here is if you are not trained with any type of technology background, and you have a job that is simply being removed and handled automatically by various types of AI or machine intelligent agents, what are you going to do? I used to work for a very large consultancy. A lot of the jobs in my consultancy were displaced by Frank's organization! What the response was, was to find other business that had … You can either compete directly, or you can find other business that maybe has better matches, that maybe has better opportunity. You can just, traditionally, you either go get another slice of the pie, or you make a bigger pie. I'm not insensitive at all to the fact that people can lose their jobs because of the advent of new automation. I don't think that's a new problem. I think that's been going on since the Industrial Revolution. I think it's how we respond to it as a human race, and whether we just say, well, "Too bad! Go find another job!" or whether we think about how we're educating our children, what skills do we teach them that will be relevant when we graduate? What opportunities do we create to improve the human condition or make the environment better? Some of the things that Frank is way better qualified to talk about in terms of making things better with all of this excess human capacity that we create, I don't think that is a hopeless situation. I think there are all kinds of opportunities for benefits to come of this. Yeah. It’s a function of how we shape our future, right? These things are playing out. And, if we don’t get in front of them to help shape where this future is going, then it’s likely to define how we go forward. And so, the job question is not an easy question. There are folks on both sides of this argument that Anthony mentioned; the industrial revolution, we’ve been here before; and there are a lot of folks, very qualified economists, that believe this is just another cycle where we’ll figure it out. And, we might very well do so. There are others that just believe that the kinds of jobs that are emerging … We're going to have a shortage of skilled players for some of the jobs that will emerge. There's going to be a shortage in the data science field. Specifically, there's going to be a shortage. But, do we have the ability to re-skill folks that are manufacturing-oriented or other into the kinds of jobs that are emerging? Agriculture to manufacturing was not as big a leap. Can I, Michael, I don’t know if this is appropriate or now. Can I respond to one of the tweets? Yeah! So, Arsalan Khan said to you that while the progress may be slow for AI to take over everything, let’s not be foolhardy that’s not going to happen eventually. I don’t know, it’s hard to read through a tweet, what do you mean by that? But, I … It may be that AI takes over a very big part of the “it” that we have today, but that doesn’t mean we get to stick with that “it.” We can have a bigger “it” tomorrow. So, there are things we can’t do today as humans, either because they’re impossible or because we don’t have the time, or because it would just take the effort that it would take would exceed human capacity. So, cancer research is a great opportunity, as an example. Think about what happened when we came to understand the human genome. Before we fully understood all of the components of the human genome, certain things were just chemically impossible. They would take forever. And now, we have the ability to model things, and we have the ability to play out scenarios without actually trying them computationally. Understanding the human genome, we can model things that were literally impossible a generation ago. I don’t necessarily think that displaced oncology. It certainly transformed it, but it didn’t displace it. And since I’m not an oncologist, I’ll stop right there. But, I think that, yes, AI will take over things that we can’t do anymore. I don’t worry about the mix in my carburetor. I don’t even have a carburetor. My car’s fuel – injected now. I used to have to worry about that stuff when I got my first car. I’m okay that there are computers in my car worrying about the fuel mixture and I don’t ever have to think about it again. I really don’t care. I’m very happy that I don’t have to think about that. And, let’s go back to that conversation around digital assistant, and digital … Digital overlord. With the greatest degree, right? And I think it’s how we go forward and the degree to which that progression occurs, I think, is the real critical piece of this discussion. Okay. We have less than ten minutes left. And, I know that you both advise business decision makers. And so, let's pull back a little bit from the future, and talk about the present, which is to say, to talk about; let's put ourselves in the shoes of business folks, leaders, managers, who are now starting to have to think about this in a practical way, because it's starting to affect them. What should they do? Well, so I think the first thing that leaders need to do is to really abandon the status quo mentalities of the past, the belief systems that we grew up with, the intuitions that we've leveraged in the past, because they made us successful, and realize that the period that we're experiencing is very different from most periods that we've seen before. And that status quo doesn't cut it anymore because we have to think about the future very differently. So, the advice that I'm giving leaders around the world is one, think differently, because the future is approaching in a very fast manner. And science fiction scenarios that we thought were years or decades away are actually accelerating into our line of sight. And so, we have to think about the future differently. We can’t think about forecasting and three to five years plans anymore, because I’ve used strategy as a very iterative process. And quite frankly, the three things that I believe every traditional company needs to be very good at are seeing the future, rehearsing it, and adapting to the inevitable shifts. So, I have three pieces of advice. One is around transparency. We should work from the assumption that more and more everyone has access to the information that we have access to. It will always be private information that's proprietary to my company or to a deal that we're making, or subject to NDA, but in general, information is becoming more and more ubiquitous and more and more accessible to everyone. So, don't work from the presumption that I know something that I just went out and found out that you don't know. I should work on the assumption that you're smart enough to find it, too. Or, your digital agents or overlords will find it for you. The second one is what I call the human race calls epistemology. But, the belief system. Where are we from? What do you believe in? Why do you believe it? It’s not enough to work from intuition anymore. There are so many pieces of technology. There are so many conflicting paradigms in terms of whether we use something that’s regressive or non-regressive, or whether we let AI make the decision or advise the decision. I almost don’t care which one you do. I care that you’ve chosen it reflectively and you can defend why you’ve chosen that approach. So, not just doing something because it feels right, but understanding why you’ve chosen to do it, and what you have to believe in order for that to be true. And the third thing is that no matter how smart you are, no matter how much you think you know, no matter how many degrees you have, no matter what's hanging on your wall, what you know right now is always going to be table stakes from now on. So, we need to hire smarter people, people that are smarter than us, people that know things that are additive to the organization, and we need to ensure that the leaders of organizations are improving their own skill sets and learning every day because this world is changing so fast that if we don't do that, we become irrelevant very quickly. Frank, what about advice for workers who may be facing these kinds of disruptions? Yeah. You know, I get that question from parents a lot in terms of their children, for example, and what they should focus on going forward. I mean, the sciences and the math are obviously always going to be important and critical, and technology clearly is a great place in space for folks to focus on. But, I mentioned right-brained before. And I’m a big believer in that. The left-brained orientation of our past, in terms of the way we run a business really has to start to embrace more right-brained mentalities. And those are the human traits of empathy and creativity, and imagination, and reasoning, and all those things that really make us human. And so, how is our education system? How are our sports? How we personally embrace those kinds of characteristics and evolve them forward, so that we can really leverage them in a world that gets more and more automated, I think becomes very critical going forward. So, a couple things; one is, you know, right-brained orientation. And the other is the traditional sciences, and math, and obviously, technology. If I could add to that two things. Problem formulation: critical, critical, critical. So, I can tell you how many conversations I have with people that start with, “Well we'll use machine learning," and then they move on. Stop. You know, machine learning presumes that you can use the past to predict the future. If the future is containing something unprecedented, then you had better be able to defend that. So, just being able to formulate a question in a scientific way, and defend why you've chosen the method that you've chosen. Forget about the technology. Of course you need to understand the technology, but of course, that comes second. First, comes asking the right question. And the second thing I would add to Frank’s list is multi-culture. It is impossible for organizations of any size and significance to operate at scale today in this world without doing things across borders. And when you do things across borders, you get involved in multicultural communication, you have to understand how people in different parts of the world think, how they believe differently than you do, their timeframes for making decisions, what they consider to be aggressive, what they consider to be collaborative, because the fundamental basis of most conflict is a failure to understand each other. That’s a great one, Anthony. If that the emerging markets are a $30 trillion dollar consumption opportunity in the next decade, multiculturalism is very, very important for developed economies, anyway. And in literally one minute for each of you, your advice to policymakers, because obviously, the legislative dimension of this is important. Frank, you want to go first? Just in literally one minute or less, please. Okay, sure. This is a critical one. Policymakers, regulators… First and foremost, we talk agile. We need agility in regulatory and policy processes. First of all, we need them to focus on the right things, but second, we need agility. So, the structures of our past that were built in the manufacturing era and the industrial age just don’t work anymore. And so, I believe that we need to really critically look at the regulatory process, how we create policy, push agility into those processes and speed, and start getting out in front of some of these critical, real-world issues. And … And … Sorry. Did you want my one minute? Yes, yes. So, I would say two things. One is, be humble. Policymakers do not have access to all of the knowledge to make decisions on almost everything we’re asking them to make decisions on right now. So, we need to be much more multidisciplinary. We need to invite experts to the table in order to make sure that we’re getting the right advice and consent before we run out and make policy. And the second one is a cousin of that, to consider not only risk but opportunity. A lot of public policy is focused on what might go wrong and what might happen, and then we shut down some opportunity in terms of cross-border opportunities, in terms of growing the GDP, helping marginalized Others, etc. So, we have to balance risk and opportunity, and we have to invite the right experts to the table to make a decision. I love that! And when you say "Be humble," in today's environment that invites a political discussion, but we're not going to go there today. Antony Scriffignano: And there you have it, yes. [Laughter] All right! Well, you have been watching Episode #237 of CxOTalk. Our amazing guests today have been Frank Diana, who is the, I'm going to say the Chief Futurist, is that fair Frank? Can I call you that? Well, let’s just stick with Futurist. All right. The Futurist at Tata Consultancy Services, which is a $17.5 billion dollar company. And, we have also been speaking with Anthony Scriffignano, who is the Chief Data Scientist for Dun & Bradstreet. And Anthony, when was Dun & Bradstreet founded? 1841. So, two very significant companies. Everybody, thank you for watching and go to CxOTalk.com/Episodes to see what’s coming up. And while you’re at it, I think that this is an excellent time to “Like” us on Facebook and also subscribe on YouTube. I have to get that in there. Thanks so much, everybody. Have a great one! We’ll talk to you soon, bye-bye! Thank you. 