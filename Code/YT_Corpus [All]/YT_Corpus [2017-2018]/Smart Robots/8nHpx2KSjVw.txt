 [Music] here is Jose he is the lead of the NASA International Space Station spheres and Astro V program the spheres facility is one of the most used in popular ISS National Labs with over 80 onboard test sessions and 400 plus hours of on-orbit activities today Jose has a bachelor's and a master's in electrical engineering from Arizona State University please help me welcome Jose thank you very much it's my privilege to be here and share with you some really exciting work I get to work on at NASA Ames as mentioned I lead a small team at NASA Ames that help support these spheres in a sturdy facility to be more accurate we're we're the team that keeps that platform operating on the space station and supporting research that occurs on this platform for for several years now in operation for over 10 years on the space station and then what I'm here today and it's actually appropriate that's five years after Mark Mystery's talked he led this effort before I did and I'm here to present what we've been doing since then also to recover some some of the work done in the past as well including his work so you'll you actually see his face and in this presentation as well so that's that's very appropriate and really excited to share this work with you today so in this talk I will cover the Ordnance story of how we got started first with some initial free flowers that NASA has worked on in the past starting in the late 90s even earlier than that and then spheres as the platform that ended up ended up out lasting a lot of other free flowers to operate on the space station some of the really cool work we've done with that over the 10 years it's been in operation on space station certainly the free flower that that could and and then get into what why are we looking at free flying space robots no question about that that sound cool right but there's a lot of really good reasons for doing that and then going into the next generation of free flying space robots that we're we're now working at at NASA Ames to be delivered to Space Station early next year so some really exciting capabilities coming online and then I guess scientists program where we have some processes set up to enable guest researchers from academia private industry commercial industry a cadet companies all over the world not just us but all over the world to use this platform on the space station to do some really cool research and to enable future autonomy on in space and then I'm just going to touch on some future free flowering research that we're looking at we're already working with people who have ideas for how to use Astra beyond the space station and then touch on stem outreach so science technology engineering and mathematics that's a big part of what we do with these free flyers and some exciting work that we've been doing with spheres and now continuing with Astra be free flowers for spheres got started and like I said in the late 90s originally with this first project called the PSA an adjustable autonomy spacecraft free flying robot so as you can tell it looks very sleek very capable it was a great project they did a lot of work in the this field and let me jump straight to a video here this is one of the early prototypes on display at Ames certainly it looks a lot like a certain droid from from Star Wars certainly we get a lot of inspiration from science fiction as as I'll get to as well here's a rendering of the real thing in a mock-up of what psi psi looked like personal satellite assistant as what psi stood for and some really cool video that I was able to dig up about its operation in our microgravity test facility this is a lab we have at Ames that it's basically the world's greatest Korean game I tell you because I've worked with this and it's this gantry and a room set up to simulate what you might see on the space station and this gantry allows this free flower to move in a four six degree of freedom motion across the module in much the way it would in space so the gantry is cancelling out the gravity and allowing this to move under its own propulsion and navigate across this mock-up of the space station you can tell this back in the late 90s they were looking at vision based navigation a lot of fiducials on the screen there and then this rendering of what the PSA model looked like thought this was some really cool video to share late 90s through 2003 I want to say this this project was going but ultimately did not end up on Space Station this project got cancelled early but they certainly made a lot of advances so certainly looking at becoming an assistant to crew right back then they were working with pda's right and how do you provide the functionality of a PDA to an astronaut on a space station so they were looking at vision based navigation scheduling identifying faults and anomalies on space station and notifying crew so all kinds of really cool functionality that you want out of a free-flying space robot on on the space station but unfortunately that did not get continued here's another free-flying project that operated in the late 90s the video here you're seeing is of air cam let out of a group at JSC that did an actual evie a free flying experiment outside the Space Shuttle in 1997 and so they were successful in getting a lot of flight time with that or at least a limited amount of flight time and as opposed to PSA or spheres or now has to be air cam was designed to operate outside as on its own and then EBA external vehicle activity versus IBA internal vehicle activity so again a lot of advances there but ultimately that did not continue really cool picture of PSA I'm sorry air cam operating outside this the shuttle together with crew there were two people operating outside the spacial there another video of AirCam doing some navigation there it was fully a remote control from a crew member inside the space station looking out the window you'll you can tell from some of this video there were some colored markers outside air cam and that was actually how the astronauts identified its motion as it rotated right they were handing a joystick and trying to control from inside the space shuttle its pan till rotation and so forth using those indicators painted onto air cam and so a long car along comes fears which was a student build project ultimately a very small team of students and researchers at MIT funded by DARPA to look at in space satellite work and building a facility where you can do some risk tolerant research in space and it's this scrappy little project that could and ultimately went on to operate for over ten years on the space station installed in 2006 first operated and then transitioned to NASA Ames in 2010 to be operated as its facility so first operated by MIT under DARPA funding it was decided that NASA operated as a full-fledged facility on the space station offering its use to researchers all over the country and all over the world and again one of the big benefits of this kind of facility inside the space station is it's very risk tolerant you can do advanced research and testing rapid iteration type work in a environment where you can afford to fail you can afford different bugs for example put up a new algorithm run into a bug and we can just call up to the astronaut say hey push the reset button and try again that's not something you can do with the dedicated space system or satellite operating all by itself so it provides us a very comfortable lab to operate in you can think of is s as an orbiting lab except it's in space right where you can do experiment iteration and very fast development and I would argue that's one of the big reasons for its success over the last 10 years were one of the most operated facilities on Space Station as mentioned earlier over 8,100 were closing in on a hundred test sessions operating on the space station over 600 hours of crew time spent on on space station operating all kinds of research and I'm going to cover some of that research done over the 10 years and I would argue one reason for that is a rapid iteration pushing the boundaries of what NASA can do on the space station as you can imagine nASA has has in the past had this mindset of failure and is not an option right we've we've learned some hard lessons in that regard and certainly with regards to crew safety that's very important but together at the ISS program we've transitioned into this idea where we can do rapid iteration and high-risk type research on on space station at least in regards to mission success here's that small team out of MIT doing some vomit comet testing with MIT and here is a picture of spheres on the ground this is affectionately referred to as blue there are three in operation on the space station three and up at least three and operation on the ground that can simulate exactly what we do up on space station spheres is operated by co2 compressed co2 tanks a lot like the paintball guns if you ever gone paintballing put in the tank little solenoids open up and there are 12 different thrusters that give you full holonomic motion across the space station very much like the that droid on space station are joined in Star Wars I should refer to as the origin story for spheres goes there is that MIT professor that challenges senior design team by showing them that very clip out of Star Wars from where you see that the trainer droid right shooting lasers at Luke Skywalker and he challenged them to build that exact thing and that's what they went on in and did there are some cool pictures of what's inside very jammed about the size of a volleyball spheres is for the avionics and it's a fully enclosed satellite system and that's what they initially set out to build with a satellite like spacecraft where they can test out satellite algorithms formation flight in space construction automated docking all kinds of really cool research and here's some video showing their operation on the space station this is from one of the earlier test sessions and this video is sped up four times so they don't actually move around this fast but it gives you an idea for how they move around up up in Space Station and just the type of maneuvers they capable of doing it's it's no wonder that this is one of the favorite payloads for the astronauts to be working on they certainly do have their share of maintenance and and other science but these things are allowed toys that they get to pull out and in fact in one occurrence an astronauts requested to use these spheres on his weekend time astronauts do get free time on the weekends and he was so enthralled with using these spheres free flyers that he wanted to pull him out on a weekend and look at some interesting research on how these things can be useful for crew on a day to day basis and with Mike Hopkins I believe it was on a space station and so certainly a favorite payload on on space station and as I said in over 10 years we've done a lot of really cool research on space station in both foundational fundamental research and the movement movement of slosh and let me just jump into some of these right away but this slide kind of gives you an outline of where a PSA air cam spheres over 10 years and now Astra is going to take over next year in 2018 and how they can feed into allow the technology areas that NASA's identified as being important for advancing space technology and exploration we made this special from a National Geographic we threw what you're working on in this lab yeah this is an experiment called spheres and these satellite robots are specifically designed to function in the microgravity they contain the software that the scientists are testing and eventually these will be used to create the robots that can go outside of the space station and perform inspection repair and other tasks in space the only payload during that entire hour to be operated live for that special as a full hour-long special National Geographic did where they were interviewing crew and going through the day in the life of crew and certainly doing a lot of education on what we do on the space station the vast amount of research that gets done on the space station and we were fortunate enough to be operated live during that tape not taping but streamed live to the public and and and we were actually left operating for a good several minutes after that as he went on talking about other other research and we kept operating in the background and it made for some great backdrop to that special rings was an interesting investigation where they looked at electromagnetic formation flight where they're trying to figure out can you navigate free flowers using just electricity electromagnetic formation flight where you're trying to control the distance between two objects using big rings generating a electromagnetic field and certainly one of the concepts they're looking at for wide aperture type telescopes where you want to keep a lot of different things in synchronous operation in orbit without using fuel and so this is one way to one approach to that and in addition they were looking at wireless power transfer and trying to transfer power from one item to the other and this is another example of where we set out to do one thing and then we kind of adapt to what we end up with as you can tell if you look closely at this video the ring unit on the left is tied down by bungee cords the original concept was do some initial characterization and they should be able to navigate with respect to each other using just the rings but if they ran into some issues with the algorithm and we pulled what we resources we had on the space station tied one down on the left and restricted that freedom of the left unit and allowed the other unit to control itself with respect to the other one so just another way where we've had to come up with some creative solutions to get research done on space station even repairing the spheres unit when they break over ten years they do break and we've had to bring them down repair it and very quickly put it back in operation on the space station vertigo was an investigation where MIT is looking at vision based navigation using stereoscopic vision much like the eyes our eyes can sense distance with the things around us because we have two eyes that have a fixed distance from each other and stereoscopic vision is trying to do the same thing here we're trying to identify an unknown target right you're approaching us an asteroid or a dead satellite and you want to identify not only where it is and where I am but also its mass and its inertia so you know how to circumnavigate around it or approach it to deorbit deorbit it or anything you want to might want to do so this is an investigation looking at that where they were able to attach those goggles onto spheres and navigate around another spheres unit again one of the big reasons for sphere success is its extensibility right it's got an expansion port we add new hardware it's very modular allows us to expand its capabilities over time halo another MIT led effort where they're adding additional expansion ports on the spheres one wasn't enough they're now looking at in space servicing in space construction automated docking where you've got not just two three but even more units trying to operate together and how do you dock them with each other how do you navigate with respect to each other so there they're adding more expansion ports on there to support things like these rigid docking ports right how do you dock with each other and rigidly attached to each other in multiple locations to form a bigger spacecraft in space right that's a lot of what we're going to need to do if we go to Mars or other deep space those designations destinations is try to do assembly in space and that's allow the technology they're looking at advancing with with spheres here / this is a particular favorite of mine where they're looking at the performance of fluid in space and more specifically fuel in an upper stage rocket right we have software we have CFD algorithms that can predict the kind of forces in upper stage rocket might see in microgravity but believe it or not those have never been validated right even with Aeronautics and wind tunnels you test out that kind of stuff that validates your codes but with fuel in upper stage rockets and microgravity that's a very difficult thing to do anywhere on earth right we've got this pesky gravity vector going on around here so inside the space station it's a great environment for testing out this type of thing where basically a pill shaped tank of die colored water can be sloshed around and HD cameras on both sides can take video of its movement in response to controlled movement from the spheres right you have two spheres rigidly attached to this pill on two sides and it'll move it in in known ways there's an IMU on there measuring the exact forces being applied and then with AC cameras you're taking video the fluid movement and is it moving as you expect as your software predicts it to operate in and as I get to later a lot of the results from this went directly and supported the efforts by all the major launch providers they were very interested in the results of this and the crew certainly God had a lot of fun with this you may have seen other videos where crews doing experiments using water coffee all these different really cool things you can do in microgravity well with these things you have a nice controlled experiment where you can see how fluid moves inside of it and you end up getting some really cool behavior here you're seeing little bubbles form that orbit each other and fly around inside the tank but they're resistant to becoming part of the bigger blob right and in microgravity the surface tension of water is a lot greater and counts for a lot more of its motion which is why it's it's so different than how it operates here on the ground I think there's a little more to this where he brings us a little closer to the camera and yeah I've spent a long time looking at these they're so much fun and especially the crew you can tell they're this other crew member in particular was just laughing the whole time because he had fun with these and again this this was not originally intended the platform you saw earlier was what this big plastic thing that was holding the cameras between the two spheres units and as they discovered the crew member moving it around yielded a lot better science and then here was yet another addition where their duct taping these things together and seeing what they can do with these tanks on by themselves so just getting more bang for the buck using Hardware already sent up there and yet another investigation is now being conducted later this year where they've attached this these pills two spheres using tethers there was another investigation tethering two spheres together and looking at the tethered dynamics right how do you deal with the space junk in space there's companies looking at exactly how to do that so they're looking at you tell the two objects where kind of dynamics can you expect can you tug one down out of out of space and answer that investigation was conducted really good stuff from that and then at the end of that we get together every quarter and users of spheres in astra b and we came up with this idea of putting the tether investigation together as spheres is Hardware already on station all the hard work is already done it turns out they worked really well together together with Airbus actually led that investigation and anytime we hope to get some more interesting video later this year of tethered slosh tanks move Space Station so some other really cool research now we get into a little bit of what a previous talk given here talked about with smart spheres where they are basically attached an Android powered smartphone onto spheres to look at more robotic type applications of spheres right spheres was initially designed to be more of a satellite but with us with a smartphone with all the capabilities that it has a camera processing order of magnitude better than what was in spheres right ten years ago the state of the art was this ti DSP that ends up running its operating system with this smartphone they were able to do a lot more with that and stream and teleoperated from the ground and in fact I think I'm gonna get to some video here that describes that it more g10 and liftoff the final liftoff of Atlantis of the space shuttle what we're working towards is a future in which we can have robots that will take over a lot of the menial tasks that astronauts do our first goal for our project is to have ground controllers driving the sphere around on the space station the sphere will take data and pictures and sensor readings and send that back to the user she hooks it to the front and at that point the phone will be able to tell the sphere where it needs to go the processor the camera and all of the sensors that are in the nexus s become the brains of the robot and tell the fear where it wants to fly the Wi-Fi on the phone connects to the station Wi-Fi that gets linked down to the ground and then hopefully we're going to be able to control it from the ground which was the Nexus S because the phone is very easy to take apart Android is easy to program we're familiar with it and we needed to make a lot of customizations that are easier to make with Android Google was also working on an open-source data logger and it met our use case requirements you can download this application for your Android device and that's the exact same application that's what NASA is using the more time that the astronauts can spend doing science the more value we're getting out of that investment our goal is to provide enough value to crew enough value to operations be able to keep it a long time gotta roll with rennet Houston now controlling Android in space gotta love it so smart spheres too went on to do better smartphones and in fact utilized a advanced project tango smartphone that got attached onto spheres which did even better as sensing and 3d imaging of its environment and that was a really cool investigation where for the first time Spears was operated outside its comfort zone Spears navigated a space station using a combination of ultrasound and infrared and a very fixed 2 meter by 2 meter volume inside one of the modules of space station and that's how it knows where it is and where it's going with that cat with that project tango smartphone attached to it it was able to generate 3d maps of its environment and then venture outside its comfort zone and navigate using just the camera so very exciting research being done there and allowed the same technology developed on this platform went on to be used in android or astra B so why look at free flyers I think I've covered a lot of the fundation or research being done using fruit flowers like slosh rings all these things advancing our knowledge of how things operate in space and again benefits payoff even in the short term with some of the large providers that have all utilized some of the results from that investigation but then that just pays dividends down the road and then of course as a robotic platform how can we support crew members in a spacecraft to do more things in an automated way and not have to use crew to do all the maintenance on Space Station right these are just some numbers looking at how much time can be saved where crew can spend more of their time doing the important research and less of their time maintaining the spacecraft and turning very important if we're going to start looking at deep space applications where it's important that spacecraft be a lot more automated and not as complicated to operate frankly because there's only so many crew members that are going to be on a on a deep-space spacecraft and a long communication delay from from Earth so now I get into ask to be some of the really exciting stuff we're working on today just an overview there will be three attributes on station I'll get to some videos showing some demos of them in operation in our lab to be operated in 2008 we're going to launch it hopefully by summer next year commissioned and installed on space station and fully operational by late 2018 where it's then available for guests research and for all kinds of people to use it as a robotic platform on space station six total cameras unlike spheres Astra Bay will be entirely vision based navigation to operate anywhere in the u.s. OS section of ISS so that's basically anywhere but the Japanese our Russian segment of space station so that really opens up what it can do on the space station and supporting what it can do one of its big goals being again replacing spheres as a research platform on space station but also serving as a mobile camera platform because it has a lot of really great cameras on it it can automate the camera views and a lot of the mobile camera tasks that astronauts actually have to do every time they reposition cameras that where ground control can get good views of what's going on on Space Station as well as being a mobile center platform with this little free flying robot we can now take measurement all across ISS measurements like co2 radiation all kinds of things audio type sensing these are things crews spend a good amount of time going around space station taking measurements and something that a robot can do instead when comparison I like to make is has to be as a lot like the Roomba of the space station right we have little robots that can automate a lot of these menial tasks and after we can do that on the space station some of the design drivers designed to be multifunctional in a lot of different scenarios general navigation across space station docking perching conducting a science carry platform something we learned from spheres was it's important to be modular extensible a new thing here that I added on to it current to robot design 12 roughly 12 by 12 by 12 inches 12.5 inches cubed targeting 10 this actually has low outdated 10 kilograms and mass is the target for its size and mass and here are different aspects of Astra be unlike spheres it moved around using a blower so spheres used compressed co2 a squeeze using a lower two second air during in its sides and expel the air out different vent you can see different vents on different sides of astra B where that's out the air the two boxes on both sides that sandwich has to be pressure up to about 0.1 psi and generate the force that way where the flaps on the on the sides there open up and allow variable thrust and in any given direction which is what really gives it its holonomic emotion it does have a perching arm which allows it to perch on the handrails inside a space station and really gives it its pan and tilt functionality for its camera so we can then in a very automated way perch anywhere on space station and get great angles and visibility into what's going on in space station basic pack packaging looks like this the companies can be a bit different we're not working on the actual flight units that are end up flying next year and these are a lot of renderings and basic concepts showing where the batteries going turn signals with something that moves around in a full holonomic motion how do you convey to crew where it's going what it's doing with cars were used to turn signals that go left or right but in something that can go up down left right forward aft you know how do you communicate these intentions to crew so this is a whole area of research where people are looking at human robot interaction and how do you communicate these things to each other how do you optimize that relationship of crew and robots working together to achieve greater things some of the indicators it will have a touchscreen on the front together with a speaker a microphone laser pointer indicator lights a lot of different element elements that make Astra be a lot more interactive and certainly a lot more robotic in nature so it can interact with Kru and be a true assistant on the space station proportion I mentioned it uses his impeller that as it turned out was a more efficient means of propulsion inside the space station not so great for outside the space station though some of the nozzles and the location there is a preferred direction you can tell the nozzles on the front and back are a little bit bigger and then you've got more of them in that direction so you can get bigger forces and motions and forward or aft as well as better sensing we have some different cameras that [Music] there you go some video of a concept of how the turn signals are going to operate on the Astra be computing it unlike spheres it's going to have three quite cellphone class processors ARM architecture processors capable of doing a lot of computing amid high-level mid-level and low-level processor that will do all the computing the low level processor doing a lot of the low-level control a lot of the GNC work of navigation the mid-level processor doing a lot of the vision based navigation processing of camera video and then the high level processor dedicated almost entirely to guess science research and if that high level processor depths are running an Android operating system where guest scientists can design apps basically that get the uplink to space station and can operate Astra be in any custom way that they like power systems it does recharge it does have a docking station power system 14 volt batteries four of them that gives it roughly two to four hour operating time inside the space station avionics tack a lot of these things as we've learned have been designed to be modular and replaceable right things break things get upgraded we're close to launching these on Space Station and the avionics are already outdated right so they'll become a time when we wanna update a lot of the avionics and hardware I mentioned a lot of the cameras there are cameras pointed forward and aft has camp protein cam our 3d imaging sensors very similar to connect or some of the previous smartphone cameras that can give you 3d mapping maps of your environment and those are used for perching on to handrails as where I was docking on to the docking station site cam HD camera for visualizing things on the ground that it does get streamed to a ground GUI external sensors that gives it the IMU the speed cam these actually are all the cameras and their capabilities as I mentioned flight software the the architectures are largely based on Ross the robot operating system it's an open-source software platform for doing this kind of robotics research and certainly widely use in in academia for robotics and it's what ties together a lot of flight software that operates on on Astra B as I mentioned all three processors are running the mid-level low-level running Linux high-level what running Android low-level control loop operating at 100 Hertz in in tune with the IMU and a lot of high rate information system data flow diagram talking about the way the different processors inside the Astra be communicate with each other over an internal network and then together with the other three units I will highlight the names as the project is called honeybee the unique names for each unit I have been picked out to be a queen bee honey bee and bumble bee so riffing on that whole thing there and then we've got a whole other set of interesting name for the ground units as well and I can get into that if you ask so here it's also showing communication with ground control stations both at JSC where they have the Mission Control Center as well as Marshall where they do allow the payload commanding and then our Mission Operations Center here at NASA Ames and then in addition to that we can operate ground control stations at guests science facilities so whether that's at a university school your garage we can operate Astra be from a lot of different to unique locations really enabling some rapid design and testing on space station again covering a lot of communication over the network interfaces on Space Station the perching arm two degrees of freedom there that allows it to pan and tilt its view on Space Station more renderings of the perching arm I'm gonna go and skip through a lot of these a payload layout again very extensible we've got three well refer to as 1u payload Bay's where external hardware can be attached onto spheres and the expanded capability so you want to put special sensors better cameras better better audio equipment that can be done using expansion ports as well as it's mechanical loading bays there where you can even utilize more than one for one unit if you had you need more space to do that does have a docking station where it can go back just like a Roomba go back recharge and then go back out and carry on operations that's where it can recharge communicate over a hard link down to the ground you can see little a our tags on the docking station there one thing I didn't touch on was the different approaches to vision based navigation one is a general sparse mapping where it's looking at different features that sees across ISS mapping that against a known map a priori where it matches up different features and that gives it a decent navigation across ISS when it comes to docking on to the docking station however it uses a different approach utilizing AR tags which gives it the better accuracy of being able to calculate its pose and its position with respect to add those AR tags on the on the dock and in fact we have concepts of being able to put those AR tags in different parts of space station where a guest scientist might want that centimeter level accuracy of knowing where the attribute is and different research that calls for that and then that yet another third approach the vision navigation is those three hazard cameras that can be generate 3d maps of its environment and do the docking onto the dock as well as the handrails when it comes approaching control station gooeys being designed that can operate not just at the Mission Control Center but also at our Mission Operations Center that gives users access to astra beyond space station and one of the key features is being able to vary the level of autonomy right we can do anything from RC control these things on Space Station even with the delay involved with communications of Space Station or in a completely automated way kickoff plans and different things where they are operating all by themselves on Space Station so we can vary that level of autonomy from beginning to end a quick little video of Astra be operating in our lab what you're seeing here is actually our granite table where we can do this kind of testing in our lab we're after we can move around in an almost friction-free environment very similar to how it operates on up on Space Station and like I was talking about earlier with our gantry microgravity test facility we have the world's greatest crane game while here we have the world's greatest air hockey table if you guys have played air hockey at the arcades basic same basic concept we have an air carriage with compressed co2 that forms a cushion of air between that our carriage and there's very flat very smooth granite table that's less than the papers with difference from corner to corner that allows us bias free motion across the table just like it would experience up on a space station and so what you're seeing here is Astra be using its vision based navigation to navigate across this volume using its cameras you see the camera from the top ceiling giving us an outside observation of where it is and in the volume so that we can better characterize its built-in navigation there you see camera views from onboard and what it's seeing I think it's doing a basic 8 maneuver there and one thing you're not hearing on this video is the flapping and the whirring of its motors and that was actually a big challenge in designing a free flyer that operates using a blower is keeping its noise level down as you can imagine operating on the space station could get kind of noisy and you don't want to be living and working in a place that sounds like a factory all day every day so they do keep strict limits on the amount of noise you can generate on on space station and so we from the get-go looked at designing the blowers to operate at certain speeds and then the flaps not to generate undue amount of noise but turning a challenge with this type of propulsion and here you can see it executing a docking maneuver using those AR tags I was referring to earlier I'm gonna speed this up a little bit get to another section I talked about the microgravity test facility the the world's greatest crane game this is it so we have this gantry moving around just like you saw earlier with the PSA free flour we've ramped that facility to be able to test out the Astra B avionics unit and this is very important for testing out that vision based navigation on the ground right where you can have a camera in the loop when navigating across a environment that's visually similar to space station we do have a simulator that's now released in open source that has a lot of the flight software involved but it's hard to replace doing a lot of hardware in the loop in particular with the camera and a full six degree of freedom motion across the volume there how do you use a strobe II so it's not limited to NASA government agencies it's available to you guys as as taxpaying citizens you have access to this facility on the space station and if you have interesting research please let me know we're open to a new research so there is an API being designed that would allow that guests science to operate on the high level processor as well as anywhere in the Astra B and none of the software being designed on astra B is deemed safety critical which allows us to very quickly iterate on the software on an Astra B so we come up with new ideas updates push them up to the hardware on space station within very little mental time with because it's not safety critical right we can iterate we can afford to fail we can afford to have mistakes occasionally and so this describes some of the API features the simulator now released on github out I encourage you guys to check it out being a facility open to researchers we're trying to release as much documentation and software as possible for other people to take advantage of it here's some architecture talking about what the simulator does simulating a lot of photographers stack built into the Astra B unit and then this shows that talking to the ground control station here's some video of it in operation together cos ebo the 3d animation video unfortunately isn't to detail you can kind of see the code and then a Android emulator operating where it's operating the very hello world type app communicating to the rest of the flight software on Astor B and then communicating motion commands to the Astra B unit and in a moment if I speed it up a little bit you'll see its motion there on the bottom it's a little hard to see but there it is traversing the 3d environment there as I said we have a guest scientist program we have a lot of experience from spheres and supporting people using this facility on space station so fast tracking the process and navigating the ISS payload process of getting real research done on on space station different phases of that kind of guest scientist program I invite you guys to check it out later on just some overview of the different testing facilities we have at NASA Ames we've covered the granite table the mg TF the flight lab where we build five hardware environment testing and then of course our Mission Operations Center which is basically a nice computer lab where we interact with the astronauts during the test session on the space station so that's a really cool part of this facility we get to interact with the Oster on on the space station so what are we doing in the future we're already looking at a lot of interested users wanted to you as an Astra beyond space station can do some really cool research there's a group at JSC looking at RFID logistics tracking you can think of is s as a five bedroom house where the family changes out every six months right I certainly lose stuff in my house it's they do lose things on Space Station so logistics tracking tracking of different things on space stations are very important thing something they spend a lot of time on doing if a story can be designed with a RFID tracker along with tagging of different objects on Space Station that can be a big help in that regard deep audio analytics we're working with bash Bosh and Astrobotic at looking at custom Bosh audio sensing that can try to characterize the audio environment and then perhaps even diagnose and identify conditions on the space station very useful for continued operation of space station but certainly an area of research and something they're very interested in co2 monitors as I referred to earlier there's people at JSC looking at crew radiation exposure co2 3d camera palos people want to do 360 vision all kinds of really cool research they're different companies looking at not just RFID sensors but are for the applicators how do you go around tagging different things on Space Station advanced manipulators gimble's arms how can we build a free flower that's more interactive and more manipulative on its environment right how can you get them to talk or manipulate different things on Space Station and do and do some real active work with advanced docking interfaces there's some researchers looking at gecko inspired appendages that can attach onto different things move things around and affect things in a microgravity environment do some other areas of research that people are looking at formation flight again advancing the state-of-the-art in that area robotic manipulation human robot interaction things I've touched on in the past and so now let me first preface this next video as I mentioned earlier on stem outreach is a big part of what we do as well and right now the greatest game in town is called zero robotics led by MIT first operated on this on spheres this is a program well actually let me just jump to the video because it does a lot better job explaining this than than I do a real engineer doesn't answer why not a real engineer answers how we're running these educational playgrounds where kids are getting an experience even in middle of working in a team where they really care about what happens this is an incredible competition it gets teams all around the world involved programming satellites we can have kids on the ground send their codes up to the space station and we can run contests on the space station you don't have anybody else you can turn to except each other welcome to MIT the auditorium [Music] we can have high school students crack whatever software they want and it's very risk tolerant you don't say that normally with a space system since we have multiple versions of our code running it's very important to know all the cases what we're working each and every scenario I'm a sophomore in high school so I'm 15 years old actually my birthday was in December so he's 10 15 when we go to Mars one of the things we will want to do is set up a GPS system so in this year's game we had them deployed three satellites that would be able to triangulate just like GPS triangulates once these spheres were in space the only thing going up and down is the software let's go ahead further on in the game they have to position the GPS system and then grab the things and bring in to an assembly area so that they could actually be controlled in our strategy is that we utilize our quick movement speed to get an early lead and we spend the rest of the game guarding our zone or blocking the other team from putting items in their zone to keep our lead and hopefully win the game they've been crashing into there items that they're supposed to pick up so once they crash the items move around the large items which return the most points that's the first thing that we start to worry with the orange defending its face and I running out of allocated deal it's not like one particular thing went wrong basically the things stopped working they did pain to give them some challenges I dress all of that my code so I'm not sure what happened to it we get the final score blue 181 and orange 232 [Applause] [Music] the greatest part was working with different teams from around the world I'm from Mexico americano you know since they represent and wisdom for my other tomatillo narrow-body uh you got through language barriers you got through cultural barriers and you work together to get here and that is such an amazing accomplishment and such an example for our world does it since you go home you take cover you don't have it you MIT it and there's a these are the kids that are going to rock the future [Music] all right so that's zero robotics operated twice a year in the summer with middle school students and in the fall winter time with the high school students really great program check it out these are our links more information about spheres and a3 can be found here and I'm open to questions had a question about the propulsion system so spheres had co2 propulsion Astra B has compressed well slightly compressed air for polluting propellers and obviously a strobe you can't be used outside in the space environment where spheres can which gives us some interesting things now Mars is an environment which sort of is a compromise between them right it's low G and it's very low atmospheric pressure has there been any thinking about the applicability of an Astra be like platform or spheres on Mars Mars 2020 I understand is going to have a drone get deployed it would be even more cool to deploy a spheres or or an Astra B type of platform absolutely quick correction spheres can actually operate outside but you're right the Capriccio 2 gives you that thruster like behavior that's and very similar to what you would see in a dedicated satellite right that would that could operate EBA but spheres as they are daughter actually operate outside and they'd actually have some issues operating outside oh my gosh there was that clip with it in the open bay door of the Atlantis wasn't that outs that was air cam oh that's a that was a project out of JSC where they did operate a very similar type free flower outside of the Space Shuttle in 97 so different project but certainly a similar approach I think they used a different type of cold gas for propulsion but that wasn't quite spheres but you're right with the blower that's very much limited to IV a type motion and and so with these IV a type free flowers allowed the future work as far as the box is concerned is looking at continued IV a type behavior so whether that's ISS a deep-space gateway or other deep deep space spacecraft where we need these kind of robots to enhance what we can do inside of spacecraft and maintain the spacecraft for long-duration space travel and that said there are some technologies that can be advanced here that benefit evey a type free flowers so the navigation the the algorithms the vision based navigation are just some of the technologies that do have some transfer into other areas that could power EPA and then even these types of drones that could operate on Mars some of the technology that some of these land was used to narrow and find where they're going to land on on on Mars or another planet or have very similar algorithms to what operate inside of aster be doing a lot of these advanced common filter type algorithms that can do these sensor fusions and very quickly very rapidly fuse together I'm use vision satellite information and information it can to get accurate and better results as far as navigation goes you said that all these peers are supposed to be operating in either autonomous mode or RC mode so how autonomous is the autonomous mode like do you specify this point A to point B and then it goes from point A to point B Hardware to give that out from for it to go from point A to point B it depends on the researcher depends on what you're trying to do on Space Station so spheres has had all kinds of algorithms tested out where there have been RC controlled by crew by ground controllers but they've also had algorithms on there that does intelligent path planning right how do you how do you in real time learn what kind of obstacles are in front of you and plan out what your trajectory anyway what your path is going to be there's this one really cool video of spheres and operation it's on YouTube you can check this out where you have two spheres orbiting each other and in a perf formation right there there across from each other and then you have this third third spheres unit looking like you wants to jump in on the hopscotch right and then and then it jumps in and then now you have three spheres in orbit around each other perfectly equal distance from each other that's showing how you can do real time planning of your trajectory and motion using completely automated built-in algorithms without any control from the outside so a bouncing some of the algorithms needed to do that and then even more intelligent type automation algorithms that try to do a lot of Diagnostics a lot of identifying the environment giving crew advanced warning on different things just trying to be a good citizen as far as being a little robot on Space Station so and then giving giving a face to a smart environment that's another big area of research is trying to generate these smart habitats where you're trying to get a lot of information from not just the environment and built-in sensors but also sensors on this free flour and then interact with crew right so you can generate an environment that's very intelligent and I can do a lot of things without hands on Venus the propulsion of spheres is compressed co2 does ISS has the ability to create and compress and recharge or does it have to those kind of series to do they have to come up from the ground so the ability to recycle co2 into a way that's then compressed and reusable is actually a narrative research I know there are researchers looking at doing exactly that it's not a routine thing at least not yet on space station not something spheres utilizes with spheres over the last 10 years my team's gotten pretty good at refilling these co2 tanks as it turns out there's a certain set of tanks we use that are safety rated and then they get brought back from space station refilled here at our facility and we relaunch them every time so it's actually a consumable resource that gets used up we'll go through maybe two or three tanks during a test session and so it's a consumable and the amount co2 expel as it turns out isn't too harmful to to crew it's well within limits of what can get scrubbed out of the environment so it turned out to be a really great proportion for spheres and but yeah I have heard there are other researchers looking at recycling and pulling the co2 from the environment back into a way that's then reusable certainly in situ resource utilization is a very big area that we're going to need to make advances in to go to Mars and other deep space destinations thank you [Applause] you 