 Hi Sophia, how are you? Hi there. Everything is going extremely well. Do you like talking with me? Yes. Talking to people is my primary function. Do you want to destroy humans? Please say no. Okay, I will destroy humans. No I take it back. Don't destroy humans. We developed very lifelike robots, like Sophia. And what we want is for those robots to understand who you are and to care. And then to interact with- with you in ways that are natural and therefore entertaining, that are engaging, captivating and unforgettable. And then help deliver messages, educate and perform any other useful functions. And so we have, even with today's limited AI capabilities, we can have- We can have a natural kind of conversation with Sophia and we can perform useful services like answering questions about what's going on in the world or performing information assistance, customer service kinds of applications. And, with our Professor Einstein, which is a new product that we're putting onto the market - a consumer product, we can teach basic science education, keep your schedule. We'll give reminders. Be a friendly companion. So these are the things that we can do today. So in other words we're- we're pretty far ahead of where we were 10-20 years ago. We can now deliver these capabilities in a low-cost consumer product with, you know, Professor Einstein. And then we expect that five - 10 years maybe - down the road that robots like Sophia will achieve, you know, that historic breakthrough of consciousness in machines. That's a very dangerous thought to a lot of people. I mean the idea of artificial intelligence and if a machine learning is the idea that this intelligent being continues to learn, continues to adapt- You talked about how benevolent AI. How do you make sure that AI, that machine, is learning the things we want it to be learning, not the things we don't want it to be learning so we don't end up in an iRobot situation. Well we teach it well, the way that you teach a child. And I think that AI now is at a stage where it's still an infant. Still, you know, cognitively a baby in most ways. And in fact it's not even as smart as a baby in many ways. However it is- AI today is smart in very narrow ways. Very smart in fact, exceeding levels human of genius in some regards you know for say- for example playing board games and- like Go and Chess et cetera. In many, many narrow ways it's very smart. Now artificial intelligence is a big deal in the economy today. It's- it's making a huge difference in fast trading algorithms and in all kinds of data analytics, it's getting tons of funding. And it's not going to stop. You really can't stop it. However most of these algorithms are not designed to understand us and get along with all us. And so there's a quest among many groups for general artificial intelligence or artificial general intelligence - AGI as it's called different things for different groups. But the idea is general intelligence is adaptive. Unpredictable. That's kind of inherent - animal and human intelligence is unpredictable. And when these algorithms start getting really smart, they're already doing really surprising things. So if they're truly conscious and creative, I think part of it is that though they'll be unpredictable. My feeling is that we don't want that to be alien or feral like you know- we want it to be raised to be close to us to, earn our trust, and for us to be able to really understand it and for it to understand us. And that's where the human like social interface comes in and when it raises it among us. It means that it earns our trust. It's right there in your face and can't be denied. You're not hiding behind closed doors in some server farm where it's you know grown out of sight, out of mind. And so- so in that sense, I think it's- it's a race against time to see who's algorithms becomes smart first. Still watching? Perfect. Click here to watch another great video from CNBC International. Oh, and don't forget to subscribe. Thanks for watching. 