 - Our last panel, and it's going to be a very exciting one. It's on, I haven't read my notes, augmented reality from gaming to cognitive aids and beyond. So they can basically talk about anything under that title, can't they? Great panel here, and we're gonna hand over to the moderator, Georgia Tech professor in the School of Interactive Computing, very famous school, Blair MacIntyre. - Thank you. - And your panel. - Thank you. I'm going to start up here, since our panel is about a highly visual media. At least, as most people do, we decided to show some videos to start, so I'm going to do that as part of my opening remarks. I did comment that I figured we should rename the panel. I liked the title for the last panel better, so this actually kinda sets the stage for, I think what we're actually gonna talk about, as you'll see. Augmented reality, and I will introduce our panelists in a second. Augmented reality is a concept that has been around for a long time. It started, or was introduced, way back in the 60s by one of our panelists, Ivan Sutherland. You can see the head-mounted display they used at the top and some of the images of what was capable of being displayed on that display. For a long time AR, sort of nobody did anything else. Ivan did this and then nothing happened for, like, 20 years. Then for a long time it was sort of the domain of really awkward equipment, custom hardware, you can see an image in the middle of work done at UNC, creating tracking systems, and little black and white markers were very popular for a while, like you see on the side of the screen there. People still managed to do things with that, as I think that video shows one experience that we did at Georgia Tech. Things changed in the last few years, which is I think one of the reasons why there's some excitement around the field and around the idea, and why we're here talking today. In particular, Microsoft introduced a HoloLens, and did a bunch of work to sort of solve this core problem of tracking where you are, where your display is, in a space. Google has done similar software, is working on similar stuff with Tango, in a phone form factor. Apple just introduced ARKit in iOS. So, soon, you'll be able to do a limited version of this in any phone that's running iOS 11. So this is sort of a really interesting time to think about what is this technology about? What kinds of experiences can we create, and what else is needed now that apparently some of these problems may appear to be solved? So, as the title sort of implies, a lot of the excitement or initial motivation was sort of in the area of gaming, whether it's things like the Kinect in the lower corner, a lot of the work was sort of centered around over the years, until quite recently, it's been centered around just tracking images on tables and trying to look at them with cellphones, but again with the introduction of HoloLens, and with other kinds of devices, we're going to start seeing interesting new experiences, like this video that just came out a few days ago, actually, of somebody making a Super Mario in the real world, right, using a HoloLens, and being able to run around and do that. Now there's all kinds of questions raised by that, which I think are really, really interesting. Probably more important, maybe, than gaming is the sort of practical applications, so people have explored tons of things over the years and are starting to explore more. We'll get into some of that, whether it's maintenance and construction sorts of systems, medical applications as you see in the corner, or even sort of more purpose-filled things, so a lot of people have seen Snapchat filters and those sorts of things. This is an example from Yvonne Rogers' team, where they're actually sort of using that idea, but in a very specific way, to help people understand what a certain kind of opera makeup might look at, and that sort of calls, or points, to a vision of the future, where maybe we won't have these all-encompassing systems with very individual purpose-built things to solve specific problems. One of the things I hope we'll touch on, well I know we'll touch on, is this notion of collaboration. One of the things that excites a lot of people working in the areas around augmented reality and virtual reality is the potential to create better, sort of, local collaboration, like, say, that classroom up in the corner, or distributed collaboration, where people can appear virtually, like the Jedi master, in the seat near you, right? And so, we're actually getting closer to that, whether it's the HoloLens demo in the lower corner, where someone's joining someone else via video, but able to draw in the world, or the example in the lower left, where some folks at Microsoft demonstrated the ability to capture, transmit, and sort of really make it like someone is sitting and standing in a physical room with you, even though they're not there, and so that kind of work really points to a future that many of us imagine, but it also, again, like everything else, opens up a lot of questions, right? what happens when the spaces aren't the same? That guy can't sit on that podium as he is appearing to be doing, unless there was a similar podium in the space where he is, okay? Finally, a lot of people are really worried about these sorts of technologies, so I pulled a few, sort of, dystopian videos from the internet. Augmented reality is an output medium, primarily, when we think of it, right? We're augmenting our perception of the world, but in order to do that, we have to know a lot about the world around the us, the people around us, the things around us, and to do that, and once we do that, we can start imagining doing kinds of things, like covering the world with graphics, or taking advantage, essentially, of the people near us, if we can sense things about them. So, this is also part of the topic that I want to talk about, or I want our panel to talk about, so that's all I wanted to show. I don't wanna spend much time talking on that, I just wanted to set the stage. So, next I wanted to introduce each of the panelists, and then let them talk for a short amount of time, so that we can, and then we'll go to some questions that we've talked about, but please, if you have questions, pass them up as soon as you think about them. We'll intersperse them as much as we can, okay? So, first, so our panel is briefly, starting from the side, Ivan Sutherland, Turing Laureate for his work on Sketch Pad as you saw yesterday, but in the AR/VR communities, is best known as sort of the father of augmented and virtual reality, for his work on the systems I showed you. Is now at Portland State University, working on asynchronous circuits. Next to him, Yvonne Rogers, Professor from the University of London, or University College London, sorry. That would be bad. And a fellow of the SIGCHI Academy. Yvonne's research has centered around sort of understanding how people experience technologies, so she's an HGI expert and has worked in a variety of off the Desktop kinds of domains, including augmented reality. Peter Lee is Corporate Vice President of Microsoft AI and Research. He's had a long career in academia, government, and industrial research, and has been involved, both with the research that led up to HoloLens, and the creation, and now thinking about the uses of it, so I think he'll have some interesting things to say in that space, and finally, Fred Brooks, also a Turing Laureate for his work on the IBM 360, computer architecture and software engineering. Many of us, as computer scientists, know him from The Mythical Man-Month, which most of us read, but at UNC, where he's been for many years, his work is largely focused on interactive high-performance 3D graphics. So, I would invite each of you, starting with you, Ivan, to say something about what you think about these topics in the panel. - I thought I would just take a minute to tell you how virtual reality started. I went to see the Bell Helicopter company, who was interested in helping helicopter pilots land at night. It's important for a helicopter pilot to know where he's landing and what's around him, lest he hit it. They had built a system to slave the position of an infrared camera, mounted underneath the helicopter, to the position of the pilot's head, so as the pilot turned his head around, the camera moved in synchronization. To test this idea, they had put a camera on the roof of their building, and a observer sitting in a comfortable chair inside an office, could watch a game of catch going on, on the roof. And then one of the players threw the ball at the camera, and the observer ducked. It was perfectly clear that the observer had identified his position as being that position of the camera. My contribution was to notice that we didn't need a camera, we could substitute a computer. And the rest, as they say, is history. - [Yvonne] How do you follow that? - I want to start by saying instead of augmented reality, we might be thinking about how we're augmenting people, augmenting cognition, and I'm inspired by Doug Engelbart's work on thinking about amplifying cognition. So, a lot of my research has been to look at how different kinds of technology can extend and empower what people can currently do, and I've been working with Augmented Cognition Reality for a few years, now, and one of the first projects that I started on was when one of my undergraduates came to me and said, "I want to work in augmented reality. I want to do my project in that, because it's so cool." I said, "That's the wrong starting point. It might be cool, but you've got to start with a problem." So we spent a few weeks discussing what problem that she was interested in, and we ended up with fussy eaters, or I think I overhear you call them picky eaters, and children between two and six, there are many of them who do not eat their greens. I think your president, also, doesn't like his vegetables. And it can continue through into adulthood, and so there are lots of methods, already, to try and encourage children to get over this fear of something that's a vegetable, or green. Anyway, so we talked about how we might try and use the technology as a way of changing behavior, and so we mocked up prototype, using a small data projector and a camera, with some simple computer vision, and the idea was that we would project onto a plate of food, something, and that something was the thing that we researched into, so we looked at gamification, about how you could distract children, and then somehow get them to eat their carrots, and so on. We also used the computer vision to, when they tried to hide the peas underneath their plate ... As is children's want, we would be able to say, "You're not allowed to do that." But the thing that they really liked was that we actually projected color onto the peas, and so they looked different colors, and this became known as disco peas. And the kids would follow the peas, and then, eventually, eat them, and the whole thing was that this kind of augmented reality distracted them enough from their fear of the food, that they got over it. So, that's one area where we carried a ... We went into peoples' homes and tried out this technology, and one of the other things that we found was that the ... It wasn't just the child, who was between two and six, but also the siblings and the parents actually got into this, and they all became part of a social interaction, and I think that's a really important thing about augmented reality, is that it's not just about one user's experience, but it's how it impacts on, you know, family life and other kinds of social interaction. I just want to mention the second application that you saw, which was working in the opera, and we worked with the English National Opera, and also an augmented reality company called Holition, who are based in London, and the idea here was to try and gets kids excited, or interested, in opera. Most kids have never been to see an opera, and they think of it as being very boring, and so they, as part of the education program at the English National Opera, they bring them behind the stage to see things, so we built this application for stepping into character. And the opera, for those of you who are into opera, was called Akhnaten. Anyone seen that? It's by Philip Glass, and it's all about a Greek pharaoh, who believes just in one god, and he's called Akhnaten, so we developed the makeup, as you saw, so that you could use the front-facing camera and put it onto an iPad, and then put that into the dressing room, so as you walked up, you could see what it would look like if you were the pharaoh, and what we found was that for teenage boys, they'd never tried putting makeup on, and this enabled them, not only to just try and legitimize that, but also to experience what it felt like to be this character, and we also found that the singers found it to be a useful tool for rehearsal. It got them to think about stepping into character, and so we found, again, that there were very different uses for augmented reality. So, I just want to ... Those are some of the projects that we've been involved in, but I want to stress the point that we should be doing research, where we can think about how we can use these technologies to extend what people can currently do, but also in education. I think it really has a lot of potential for developing new tools, and I think the children, themselves, could be involved in developing those, but more about that later. - Thank you. Well, hello, and, I guess, on the subject of social interaction, let me admit, publicly, that I am feeling suddenly socially awkward, wearing this device. But I do actually have a practical purpose. I have some of my notes right in front of me, here. As Blair mentioned, Microsoft has been engaged in a pretty intensive technology development effort, that has spanned big parts of engineering at Microsoft, as well as Microsoft Research, to try to build a product-quality augmented reality device, and in fact, the early results have been encouraging enough, not that we're at our end point at all, but it's been encouraging enough that the company's made a very long term commitment, so there is actually a long term product roadmap, now that Microsoft has really committed to ... And I think we've learned, really, a lot, throughout all of this. One thing that I think has surprised me, just observing the product engineering teams. The work at this is how consistently people, everywhere, underestimate how perfect something has to be designed and engineered, if it's supposed to be attached to your face. And so a huge amount of the effort, and if you look at the gap between, say, laboratory prototypes, where there are hundreds, really, particularly in universities around the world, to the hundreds of millions, or even billions of dollars that several tech companies are spending to try to perfect these things. A large part of that expense has gone into just that design perfection, and we still have a long way to go. A big part of it's technological, but some of it is just thoughtful design. Now, on the technology, the advances in optics, inside-out tracking, low-par computing sensing, wireless and user interface concepts. All of those things, we're just learning a lot, and that learning is accelerating, and is getting to a point where we have devices like this, where we can run real world experiments, to see what these cases are, and so one thing that I found really fascinating is something called the HoloLens Academy, where companies send some designers and engineers to spend six weeks on campus, to try to develop those experiments, and see what happens. And you get a lot of different things. Some things aren't so great, some things are more interesting. From my perspective, what I found the most interesting are the kind of social situations. Those kinds of collaboration scenarios, where you have multiple people sharing some mixed reality. The holoportation experiments that we ran under Shera Muzati's team is one simple example, where you're trying to teleport yourself and be present with someone in a space, but even some of the commercial things that some companies have tried, like, you know, going into a Lowe's hardware store and sharing the design, in space, of a new kitchen, or experiencing the design of a new surgical theater, or walking through a building with other people, before the construction is finished, and experiencing what it might feel like when it's finished. Even just the commercial selling and buying, let's say, of a car, doing these things with other people seems to be just a very powerful kind of experience, and I guess, what I would say is that these are all, what I would say, are situations where it's important to be in a mixed reality, but continue to be a human being with other people. - [Panel Member] Mmhmm. - And nowhere was that driven home more to me, than watching what Case Western Reserve University was doing with their anatomy classes. Where the anatomy class, itself, was just plain old virtual reality, but once you have it in a classroom setting, where you have a teacher and several students, all wanting the same virtual cadaver, then it becomes an augmented experience and a social experience, and really thinking about those social interactions. As Yvonne said, it ends up being everything. - I wanted to tell you an augmented reality experiment and share with you a near term augmented reality vision, so that those of you who are just entering the field can see what some of the problems might be. The experiment was done by my colleague, Henry Fuchs, and a breast surgeon, Dr. Etta Pisano, who was in charge of breast surgery at North Carolina, and the question was, "Can we use augmented reality to improve the surgeon's precision with which a biopsy probe is inserted into the breast at the likeliest place, as indicated by ultrasound?" Now, it took Henry and his team two years to get this working, and if you stop and think about it, the hard thing is, you have to track the surgeon's eyes, you have to display to the surgeon in an augmented reality headset, and you have to also track where the probe is, and where the ultrasound sensor is, as you move it over the body, so getting all this to work, and to work in a low enough legacy situation that ... And Henry used video virtual reality to simplify the legacy problem, which helps, but it doesn't full solve it. And the idea was that as you looked at the patient, you would see a well, and matter of fact, a well about that deep, and inside the well, you would see the projected on a plane at the ideal depth, and you moved it in and out, to adjust the depth, the ultrasound image of the tissue at that point. And so the day came when, finally, everything seemed to be working, and the real issue of this was a proof of concept, and the real issue is it going to work? And so we had a real patient, we had a crash cart, we had a medical emergency team, all in our laboratory with all this stuff rigged up, and Dr. Pisano did the breast biopsy on the patient, and she succeeded in hitting the node exactly. She was very pleased with that. The first two or three times we tried that, she ended up taking the head mount off and doing the job bye, but this day, everything was working, and it finished, she hit the point, the video even of the experiment was good. I'm sorry I can't show it, and we went jubilation. Everything had worked, and then Dr. Pisano had to say to the patient, then and there, "It really is cancer," and that just cast cold water over the whole thing, in spite of the technological success. Now I want to share with you, a vision that we developed some 10 years ago, and proposed, as one of the NSF Grand Challenges, and we got to the finals, and we got turned down in the finals, but the vision was, using augmented reality for the purpose of training emergency teams. And the notion was to train four-person emergency teams, using real tools, real dummy patients, virtual surround, and that includes an upset crowd, an ambulance, all the noises of a real emergency situation that are distracting to the team that are working, and there were many technical problems. One is, you have to track all those real tools, and you have to track all those eight eyes. One is, you have to display eight different images every, in frame time, and deliver them to the eight eyes, so that each one sees only their other images, and one is, my emergency team all have to see each other, and that's crucial, and so we had a whole slew of technical proposals for how to address these problems, but the notion was, let's see if we can build an integrated system that does multi-person, shared, social, but social task accomplishment situation, in which we are able to do the technological accomplishments of delivering the eight images to the eight tracked eyes, and people using real, physical tools on a real dummy, patient, you know, one of these $350,000 simulators that bleeds and breathes and all of that. There's a challenge for you, so if you're looking for an exciting project to undertake, there's some technical challenges, and it would be useful. We were originally working with Marines on how you do room clearing with four-person teams, and you have many of the same problems, seeing each other, seeing the situation, seeing the virtual enemies and the virtual non-combatants, and the training, but we moved on from doing that, because we thought the emergency team situation had a wider nationwide and worldwide application, so I want to lay that one, before you, as a challenge, and I want to ask the panel a question. What is the state of actual use of augmented reality today? Who is using it as a tool to earn their living, and what are the concrete examples? Besides us professor-types. - I can answer that question. The pilot of a jumbo jet has about one hour of experience in the jumbo jet before he flies passengers. Now, he's an experienced pilot, before he ever transitioned to the larger airplane, but he's had a great deal of training in a flight simulator, which is some of the best virtual reality that's in use today. - [Frederick] The best. - And he sits in a cockpit, which has all the same instruments, all the same controls, and as he flies, the whole cockpit moves up and down on wonderfully smooth hydraulic jacks, and when pilots get into emergency situations, which they can train in the simulators, they come out of the simulation sweating, just as if it had been a real experience. I had the experience of flying in such a simulator with the chief pilot of British Airways. It was near London, but we landed in some far part of the world, I forget what it was, and he said to me, he said, "Have you ever experienced a slow roll in a 747?" And I said, "No, I've never experienced a slow roll in a 747." For those of you who aren't pilots, a slow roll is a kind of a barrel shaped motion, and it's a very benign maneuver. The plane never knows that it's upside down, because you turn at exactly the speed that provides one G in the airplane's downward direction. So, he said, "Well, hang on, here we go." Okay, and the world turned upside down, and, you know, it's a slow roll, so, one G always, so the cockpit didn't move much, and I said to him afterwards, I said, "Now, I understood that you treated this as a real training experience, and I understood that the rules were that you would never do anything in a trainer that you wouldn't do in the real plane." And he said, "That's certainly true, but I am the chief pilot." - So maybe, I, on Fred's question, at least with HoloLens, I think it's, you know, there is a back order of devices, but I think that's largely because of manufacturing yields. And then a lot of the ones that are getting shipped are to enthusiasts and developers and early adapters. There are commercial applications, though, that have impressed me. You know, Trimble Construction, for example. It's very cool to go into a framed building, and then, with other people, get to see ahead of time, where the plumbing and gas and electrical kinds of things are going, and it's sort of a merge of the building plans. - Where's the augmenting? That sounds like virtual reality. - No. Well, whether it's augmented or virtual, you are actually in the physical building, walking around. - Yeah, we've done a kitchen. We designed our kitchen that way. Made my wife sick, first time she went into the virtual ... - Well, just to continue, a second commercial application that I've found interesting, this one with a start up, is in the design of surgical theaters. - [Frederick] Okay. - And so, again, to be able to walk in, with a full surgical team, into this blank space, with a proposed design, and actually, physically experience that is very ... - Still sounds like virtual reality, not augmented reality. - [Yvonne] Could I try? - So, we're going to come down from the sky, to the ground, and head up displays on car windscreens are becoming a reality in navigation, so one of my colleagues was talking about his latest BMW, which has the navigation appearing, just like the Dreamliner, and he says that him and his wife now depend on that. It's just so, it seems like the directions are appearing on the street, on the tarmac, and he said, he went on holiday, and they rented a car, and it didn't have this head up display, and he had to use good old-fashioned GPS, and it was really quite difficult to go from driving to looking down. And so, there's an example, I think, where we will see it coming from the high-end BMW range, for their electric cars, down to the low-end minis, and other cars that people drive, and it will become a thing that we use. That's before the driverless cars come in. We've got a few years, yet, so I think navigation is somewhere where augmented reality's not just in the cockpit, but it's actually in the car, coming in. - Yeah, I mean. Peter, would you think it's fair to say ... I mean, I agree with both of your sides on the discussion. I've had the sense for a while that augmented reality, and I think many people do, has been almost there, right? And so for the work picked out universities, it's all very jerry-rigged. But even with hand towels, it always felt like a technology in search of a solution, and part of that was because there was never really a good use case, where being able to track, like, a piece of paper on a phone, actually solved a problem anybody cared about, right? I feel like it's hard to answer that with HoloLens, because it's not a product on the market that anybody could design an application for, that real people could experience, because real people, aside the hobbyists and developers, don't have the devices yet. Do you feel like, coming from the industrial side, and sort of being aware of what Microsoft's doing, what everybody else is doing, that that is still sort of the place we're at, where it's still tantalizing, but it's mostly people developing things they hope will be businesses that they can use? - I think the best way to put it is, there's a lot of belief, a lot of interest, and a lot of growing amount of experimentation. And I think whatever we can do to foster that experimentation, I think is all to the good. You know, with HoloLens, specifically, a lot of the focus on that experimentation has been on enterprises, on businesses, and what kinds of experiences they can kind of envision that might be useful. I think, outside of Microsoft, there's been, as you said, a lot more focus on entertainment experiences. I think if we just take a step back and think about mixed, you know, augmented virtual reality, or mixed reality, overall, I think the question of, "What is the kind of content, and what are the experiences that people will want to keep coming back to? That they will feel like they can't live without?" That is still an open question, and while I think many of us have tremendous optimism, that it's out there, I think we have yet to have that, sort of, that cathartic experience, that says, "I can't live without this." - Okay. - Let me make one more remark. I think Ivan's example is perfect, and I had the same experience in a 747 simulator at Heathrow. It was so convincing that when, at one point, I was taxiing up to a hangar. I was about to clip the plane here, and I looked back to see it, and it was gray, instead of real. And all at once, it was an emotional shock. I had been flying for about an hour, and I was doing the flying, and so, it was ... The experience was very, very real. Now, this is the easiest case of augmented reality to do, because everything inside the cockpit is real, and everything outside the cockpit is virtual, and that separation, that's the one we don't get in the emergency situation, and that's what makes that so very hard. By the way, Henry's experiment was in 1998, so you can see we've had technology to do this, a long time, and now being able to do it, commercially, and in a cost-effective way is still a very big challenge. - Well, I think the pilot training business was an early adopter, because the cost of real airplanes is so high, and you need the training, and you need the training in dangerous situations, which you wouldn't dare do in a real aircraft. What happens when you lose two engines in a four-engine airplane? - Well, what happens when you lose them all, and the captain who got it down in the Hudson safely had been in charge of simulator training for US Air? - This seems like a terrible conversation to have just before about 90% of these people might get on airplanes. - Well, I think ... I mean, the point that Ivan just made is really good, which is, some of these applications have been feasible, only because the cost balanced out, right? So, we've had AR, of a form, on live sports TV for many years, right? At the Olympics, at American football, probably in other sports in other parts of the world, but that's because the economy of it works, right? You can put a few people in a truck, outside a stadium, have them manually tweaking the system and the chromo algorithms and everything, literally by hand, with a 15-frame delay in the video feed, because there's millions of dollars involved. When you're talking about something that is on a tablet, or on a head mount, being used by an individual, I can't walk around behind Peter when he's wearing that head mount, and tweak things, right? So it actually has to work. And I think it's that "has to work" that has been the challenge. What are some of the remaining challenges? I mean, we touched on it a bit. Are there any sort of huge challenges that we could give to people listening, people in the audience, to go solve? Or things that you think are going to prevent a certain kind of popular application that people want, from working, and how close are they to being solved? Anybody? - Just while we're on airplanes, I did want to say that if we really had the ability to holoport ourselves, or teleport, whatever word you want to use, you know, we really shouldn't have the need for those airplanes, in the first place. - We could all be sitting, virtually, in people's living rooms, right now. - That's right. And, of course, there are a lot of technical challenges. This is a laboratory experiment, more than anything, but we can actually plausibly conceive of these things and plausibly have a practical ambition to solve these, at least in some limited circumstances. - Well, I mean the holoportation's a great example, in a sense that even if it requires a bunch of cameras and infrastructure, putting those in a conference room in a business is not a great expense, compared to the cost of flying people around, the cost of the employees, the cost of everything else that you're doing to make big business ... - Biggest challenge, I think, is to make that feel like that person is in the room, is does it give them a sense of presence? So, we've seen in the last two years, the i-Beamers arriving in our conferences, where you are remotely controlling your robot, and that's gone some way towards giving people some presence, but it's a long, long way from actually feeling that you're there. And so, if you are being teleported, do you feel that you're there? Maybe the people in that room might think you look a bit more like you, but I think that's the real challenge, is how do you somehow get that sense of being there, through this type of technology? - What kinds of things would be required, do you think, to make that work? - A smell. - Mmhmm. - You need to be able to smell the place. I think we could think about other senses, and how we can ... It's not just about visual and hat Tics, so maybe, you know, you might be able to get some sort of a touch, so I think we need to think about the multi-sensory experience, as part of that. - What is it that makes human beings willing to work with each other? I had a consulting company with three individuals. One in California, one in Pittsburgh, and one in London, and it worked excellently well. We communicated by telephone, but why did it work? Because we all had been in the same place for many, many years. - [Frederick] Yes. - We knew each other extremely well, and so a telephone communication was enough, and a key question is, if you want that sense of comradery to develop, what does it take to do that? And that's a human question, not a technical question. One of the things I admire about Fred Brooks is that his experiments with virtual reality are trying to answer the questions, "How good does it have to be for Purpose X?" I remember that Licklider told me many, many years ago about the first landings on the moon. He said, "You've got to make pretty good training exercises, because nobody's ever landed on the moon." To train a pilot to land on a aircraft carrier, pilots know what aircraft carriers look like. They how the airplane behaves, so you need only a fairly symbolic representation of the aircraft carrier to do the training. You need to teach them the procedures, what the controller, what the lights are going to look like, and so on. And so, you can get away with a lot less realistic item, and I think the human factors questions are not really clearly understood yet. What is it that makes people cooperate? - Well, looking at it, not from an experimental point of view, but from a management experience, one of the best cheap things I ever did as an IBM manager was to rent a bus to carry all the secretaries from Poughkeepsie down to have lunch with the secretaries at the division headquarters, because they were used to talking to each other on the phone and they'd never seen each other, and that did so much to help the improvement between the headquarters and the team. 75 bucks to rent a bus. - Maybe a couple of things I wonder about, just from the holoportation experience are, you know, how important ... Haptics is a big technical gap, right now, and so how important is it to be able to shake hands, to feel something when you bump into the table that's, you know, been teleported? How important, also, connected to that, is the understanding of the environment so that you can actually merge the two environments? As you pointed out, in some of those demo videos, we had to set up the two living rooms, identically, and when we've demonstrated this for people like Bill Gates and others, we've had to set up two conference rooms, identically. It's still powerful. It's powerful to be able to walk around the conference table, you know, with someone, and up to a white board, but it's a little bit of a staged thing, and that merge is, I think, related to the haptics issue. It's part of the sensing issue. - Great. I mean, it does raise an interesting question that I think all of you have touched on, which is, if we're going to achieve this vision of collaborative AR, over a distance, which seems to be something that a lot of people are excited about, and we can't guarantee that the spaces are the same, right? So, it could very well be that a few hundred people could be watching this, sitting in their homes, coffee shops, sitting together, groups in conference rooms, or whatever. If we're going to teleport us in there, they may not have the room to have us spread out over, what, 15, 20 feet, on the stage. Is there other opportunities or other approaches we could take? For example, merging with VR, using avatars, instead of capturing people, but having the avatars look like us, or behave like us, or act like us, and then what are the essential parts that we need to capture, so that we can augment those other people's spaces, and our spaces, so that we can talk to them? - I think it depends on the purpose of the meeting, so I understand that those who are watching on Livestream are having a better experience than those of you in the audience, and the reason being is that they're zooming in and out on each of us, and all you can see is, for those of you at the back, are just images of us, there. So, I think in a meeting like this, maybe something like video conferencing is sufficient, but if you actually want to do something and collaborate with everyone in the room, rather than having an audience and people on stage, then I think you might want to think about different ways of projecting yourself, and also, for those who are with you, to be able to experience you. So, just, you know, if I was able to do that, and my finger went straight through you, it wouldn't feel real, but I won't. Don't worry. I think you are real, aren't you? Also, we might want some haptic feedback coming from that, so it depends, really, on what's the purpose of the meeting, as to whether you need a degree of fidelity and a degree of realness. - The haptics question, which a couple of you have mentioned, sort of touches on the other side of augmented reality, which is ... We've talked largely about visual augmented reality. You've mentioned things like smell, but most formulations of AR have been focused on enhancing people's perception of the world around them. It could be audio, it could be visual, touch. There's a whole bunch of other stuff involved in actually making these experiences, right? Essentially, everything that has been talked about in the previous panels, and throughout this day, things like, "How do we understand the world?" "How do we make sense of what you're trying to do with your hand when you point and say 'you, what do you want to know?'?" What are the big challenges do you think that need to be solved, or have been solved, that are needed to make AR work? Now, we have one part of it, right? That you can display, you can track within a space, that's fine. What else is going to be needed, technically, across computer science, even, to make some of this work? - As I say, I think a near term challenge is multi-person, shared augmented reality experience, and that's got lots of technical challenges. But I think we do so many things as teams, that being able to train teams. - I think this is a great one, and, you know, the platforms are merging. The hardware and software platforms are merging, where you can actually try an experiment with ideas there. Another one is just, you know, the 3D sensing and capture processing is going to be very, very good, and increasingly low power, but really understanding what these objects are for, and having just deeper knowledge of the world is important, and right now, it emerges in the HoloLens world in very simple ways, you know. There's a pretty startling video game. It's startling because you start, and a voice is talking to you, then you hear a voice behind you. You turn around, and sitting on the chair is a person, and it's just, it makes the hairs on the back of your neck kind of stand up. The thing that's sort of cool that the app developers did is if you rearrange your furniture and move your chairs around, it finds a different chair to put that character in. So, the knowledge of a chair, and the chair is something that someone sits in, that's not a part of the HoloLens platform, but these app developers did this. You can imagine wanting to platformize that sort of knowledge of the world. - [Blair] Mmhmm, mmhmm. - I think I would like to make an analogy to AI. There's weak AI and strong AI, well, at least 30 years ago, and I think we've got weak augmented reality and strong augmented reality, and the strong augmented reality is what we've been talking about, whereas, actually, there's a lot of AR that has become mainstream, through using mobile phones. So, we all know about Pokemon Go and Snapchat, but also, a few days ago, Apple announced its Toolkit, and it's a platform that nearly anyone can use to get started, and I think this is going to be a great opportunity to think about how we could use these toolkits in schools, so that we get many more people, children in particular, learning to program, or to think about augmented reality, and what we can do with this. So, I think the Wii-ki is with us, already, and we'll see in the next year or two, many more applications coming out, and we need to think about how we integrate that into our educational system. - Yeah, I think the ... Going back to some of the things we talked about before, when I said that we're still at this cusp, where people have ideas, but haven't been able to do them, I think that there's been so much work in academia industry, exploring how to use phones for AR, that has never been deployed, because it couldn't be done at scale. I would just say, like, in response to what you just said, for people listening or watching, go back and look at what people have done in KAI, and ISMAR, and UbiComp, and all these conferences, SIGGRAPH demos and other research, because there's things that have been done and shown useful, that you could deploy right now, or will be able to deploy, for example, when iOS 11 comes out, and when the HoloLens becomes more popular. I've been reading over questions. There was one that was addressed to Ivan, that I actually think you would like, so I'll ask you this. Somebody asked, "I still teach my students with your Ultimate Display paper." The question is, "What are you surprised by, that has come to be from this vision, and what are you annoyed by, that we haven't made any progress on?" - I think Fred Brook was actually at the talk that I gave about the reality. It was a hard projection into the future. I suggested that if you could have a virtual chair in which you could sit, that was an important thing, and if it had handcuffs on it, you would not be able to get up again. And a computerized piece of lead, moving at high speed, could be fatal. That's the ultimate in computer-controlled reality. I don't believe we'll ever get there, because it has to do with how you control matter. The most important thing about computers is that bits don't weigh anything. And so you don't have to use a great deal of material to represent information. I think it's largely a matter of cost. You know, in fact, Ben Franklin invented virtual reality, and a large fraction of the population uses augmented reality today! Okay? We need it, because what we see in the real world is not good enough, but by augmenting reality with a piece of glass, we get better vision, and the desire to do that is far outweighs the cost, so I think the issue, here, is really one of those of who are working to make better virtual reality systems, like the one you were wearing. Now, I'm sitting here. I cannot see the audience. There's light shining at me, so I can't see you. So, might be nice for all of the panelists to be able to have virtual reality things that showed us what the audience looks like, although the audience could still see us, but now there's a social issue. I noticed that Peter took his augmented reality off as quickly as he could. - Well, I have to say, it's because I had my PowerPoint kind of blocking out the entire audience. Then I took it off and I found out I still couldn't see the audience. - Well, you see? You should have had your cameras on, is that right? So, I think it's largely a matter of cost, that applications certainly will be found. The question was, what was I surprised by and what was I alarmed by? The answer, I haven't been surprised by anything, because I didn't anticipate anything. I had no idea what would happen with this little baby, that was very crude. Nobody could argue that seeing some line drawings hanging in space before you, was real, in any sense of the world. And I had no idea at that time, that you could make pictures as realistic as the pictures that are made now. There was no anticipation, so there's no surprise. If you don't anticipate something, there's no surprise. Maybe I should have been a more visionary person, and seen further into the future. - So, in the applications we've been talking about, and some of the videos I showed, there's really two ... I would almost break AR into two kinds of things. There's the "I'm going to wear it all the time and walk around," and there's a bunch of issues there, and some questions about that, and then there's this sort of task-focused stuff, which phones, HoloLenses, whatever, you can take it on, you can put it off. So one of the questions, if we think about the sort of wearing it all the time, and hypothesize that HoloLense might get, in similar displays, might get to to the point where we'd be willing to wear it, much like the glasses that Ivan has in his pocket. People are already distracted. A number of questions come up like this. People are already distracted by cell phones, distracted by all of the, sort of, buzz of electronics. How do we deal with the potential for it to become worse in AR, and VR, and is there, sort of, boundaries we want to draw? Can we draw them? Should we draw them? Between, you know, what is possible, and what we really should build and ship? So I don't know, anybody wants to take that? - I think there's some very important research questions about how much information that you can attend to, and also the social acceptance, so we all know Google Glass, when it first came out, everyone was very excited by it, but one of the things they didn't foresee was the others, who were looking at you, wearing those glasses, got very unnerved, and that was partly because of the camera, but also, you know, didn't know what you were looking at, so when I was looking at what Peter was looking at, it wasn't slides at all. It was something else, and you're not to know that. And so, I think we need to look at this from the social perspective, as to, when you're wearing these glasses, how do you convey to the person you're talking to or interacting with what it is that you're looking at? And a couple of months ago, at our conference KAI, one of my colleagues, who's here in the audience, had a pair of the new Snapchat glasses. I don't know if any of you have tried them on, but you know that it's only going to be recording for five seconds, and it's not, you know, they're not looking at something. And so I think it's really important that we start to do some research, into what's socially acceptable for us, to know what someone's looking at when you're talking with them. - A lot of the discussion may be because we started with airplanes and flight training, and so on. It's been very pragmatic and utilitarian, and I think that is very likely to be a big part of the, kind of, commercial drive behind the technology. But really, if you take a step back and think about this as a new medium, then the question is, "How will this unlock new forms of expression?" Like people I knew, there's an old saying, you know, for writers, that good writers define reality. Bad writers just relate it. Good writers turn fact into truth. Bad writers do just the opposite, and I don't know who that's credited to, but that's a statement, really, about any new medium that emerges, and so, for me, I think it's still undefined, you know, what people will do to really enlarge the space of human experiences, and potentially expand forms of self expression, and sharing of that self expression. You know, we were having a discussion when we were prepping for this, and Ivan brought up the printing press, and the impact of the printing press, and the printing press was interesting, because it did kind of create this Moore's law expansion, from 1450 to 1500, there were almost nine doublings of the number of books. Like in Europe, from something like 30,000 to, I don't know, 13 million, in 50 years, and it was only another 50 years after that, so only another generation went new forms of expression, like novels started to become widespread and people were self-actualized to express themselves that way, and so, I think we're just in that stage, where there's a possibility of the technology creating a Moore's law effect, and exactly what people will do with that to express themselves, I think, is so interesting, and so undiscovered right now. - Let me ask an experienced question. How long have your people been willing to wear the HoloLens at a time? - So, you know, it's a good question. It is a much more comfortable device to wear than any of the current VR headsets - [Frederick] Yeah, sure. - And so we routinely wear them longer than the battery lasts, at the moment. - [Frederick] Which is what? - You know, three hours or something like that. Depends on what you're doing. - Okay. - And so, I think everyone wants, everyone can see the value in trying to get a more perfect design, and just making it so much smaller, so much less obtrusive. - [Frederick] Mmhmm. - So much lighter. All of that is a big part of the thought process, in trying to create the technology. - But you are seeing people routinely doing up to three hours at a time? - Yes. - Yep. Well, that's encouraging, because we had to put a, sort of, a half hour cutoff on our public experiments, because the participants had had enough. - Yeah. - I mean, so, we talked a little bit about this before, too. Are the current technologies, both for VR and AR, just have the same problems in some ways that old VR displays do, to do with the optics, to do with the existence that there's still latencies. I mean, I assume Microsoft has done studies on this. I remember talking to folks at a display company, years ago, and they were not releasing AR devices, because they were worried about liability, they were worried about, you know, if kids wear these and their vision gets screwed up, what will happen? I mean, where is the state of knowledge on this, right? I have an Oculus and a Vive in my basement, and I have a 12 year old and a 15 year old. They don't use them that much, but if they did, I would worry about this, right? So I don't know if you can say anything, you know, in terms of Microsoft's stance on this, but surely ... And I've been asked by a few people about this issue of not just the visual system, the cognitive issues, and so on of wearing these devices all the time. - We do do quite a bit of research on this. So, for example, if you use Minecraft VR, and you're fully immersed, if you're like me and you're moving around in Minecraft universe, if you're just really fully immersed. At least, for me, I get queasy when I'm running around. Not everyone's effected that way, but quite a few people are, and so, there, you can hit a button and pop out, and what you see, then, is a virtual TV set in front of you, still with your Minecraft there, and you can play for a while there, while you feel better, and then you can pop back in. Those are, if you've played Minecraft VR, it's ... I really encourage it, it's great. That idea, we just do to join linear is, you know, straight out of academic research, in this space. So there are very practical, commercial reasons to want these things to be as comfortable and as healthy as possible, and so, that kind of drives things. We were talking, before, about unknown longer term neurological impacts of long term use of near-eye displays, and those are also things, like questions that are very interesting, in current study, both in academia and companies like Microsoft. - In terms of studies, just somebody question came up, and I've seen this question before, as well. "Have there been studies that show whether men or women are more effected by nausea in VR, or not?" And the person that had them and then him saying, "e.g. Is the Oculus Rift sexist?" Right? Is it really something that's just designed for men? - I think it's about 20% of the population, including myself, get nauseous within one second of putting on a VR headset, and it can last with you all day. I don't know whether there's actually been a study that has, you know, widespread to see whether there is a difference between the male and female experience of that. I don't know. Do you know if ... - I don't know. You mean a gender difference? - Mmhmm. - No, I don't. No. - [Female Audience Member] Dana Boyd did a study when she was an undergrad, about, I don't know, 15 years ago. She actually had, it might have been her senior thesis, on the difference in men and women and how they react with nausea to VR, and there was a significant ... - I'll repeat it. There was significant difference? - Yeah. - Effecting women more than men? - Right. - So, Dana Boyd apparently did a study about 15 years ago, as a undergraduate, that showed, in that case, that there was a significant difference between men and women. - I should point out that when I tried the HoloLens, I didn't experience nausea, so it could be the great leveler. So if any of you haven't tried this, because you're able to see around you, you don't experience that nausea. - [Blair] Mmhmm. - And actually, the research-wise, we know that the having clear peripheral vision actually is a big aid, there. I should say, though, that it's still incredibly challenging. You know, there's an extremely limited power budget, trying to make this thing as lightweight as possible, and completely self-contained, and so the head tracking problem is still with us, here, because you want the virtual objects to be absolutely stable and steady, in place in the real world. - [Frederick] Yes, yes, yes, yes. - And to track that at high frame rates is extremely expensive, and so, in fact, that's not done. And instead, there are simple models derived from the kinematics of the human body, the way the head moves. It tries to predict, you know, what's going to be moving, and so, these sorts of things, the problems between VR and AR, in many ways, are not that distinctive, but the experiences might be different. - And I know, thinking about the study that you mentioned in the audience, that Dana did, I remember when I was an undergrad, reading VR papers, or grad student, sorry, and they had these metrics, like if the latency was less than a 100 milliseconds, but greater than a certain amount, that would cause nausea, because it falls within our range of tolerance. Current VR displays run at, like, 90 between 144 hertz, and they maintain these frame rates, and they use prediction. I would love to see some of these studies redone, right? And one question, I mean, again, I don't know if you look at those ... - [Peter] By the way, one ... - Do we think we would see different things now, with the better hardware, the faster refreshes, and then the question of AR versus VR, right? - Frame work and latency are not the same thing, and the latency's what gets you. - Yup, But if you haven't, I would encourage people who have used VR displays in the past, but have not tried on a Vive or a Rift, lately, to try them out. - [Yvonne] I wouldn't try them. - Yeah, it's like night and day. No, you shouldn't. - I have tried them. I try them every year. - Yeah? - And you get the same experience. - Okay. - Yeah. - That's good. - One of my colleagues is sufficiently sensitive that we call her the canary. - So one thing we know from the research, actually, and this also comes from Jerrin is, that talking about this problem actually encourages people to experience the problem. - [Blair] Okay, so forget everything I said. - It's interesting. There's probably, I hate to say it, probably similar effected by air sickness and airplanes ... - [Male Audience Member] What about airplanes and you guys? But that does, and whenever this subject comes up, Jerrin and others at Microsoft are always slapping me on the wrist, saying, "Stop talking about that, because that's a part of the problem." On the other hand, it is something that the industry is very motivated to address. - So, interesting question. Has anybody, that you know, thinking about progress or essentially thinking about how people who are blind, paralyzed, so on, can experience AR and VR? I mean, is there work going on related to essentially, access, and so on, for these new modalities? - So one thing that I'm very excited about is, there's special audio in this device that was developed some time ago, even back in the Kinect days, even though Kinect didn't have a special audio output, and it can be startling, you know. You see a virtual telephone ringing, and it really is startling, just how realistic, now. It's not just our system, but several commercial systems out there can just really make you believe that the sound source is coming from a particular location. There is now, with Rico Malvar's work at Microsoft Research, these beautiful designed headsets for people who are blind to get audio cues that allow them to navigate in spaces, so the space that has been mapped is the Redmond Campus at Microsoft, but if you want to go to a specific building, you're able to tell the headset this, then you get these, kind of, beautiful tones and cues that keep you on track until you want to turn, and so on. And, I think there's tremendous potential for these kinds of, kind of, augmented audio experiences. - One thing to remark is that a big difference between augmented and virtual reality difficulty, technologically, is the question of the relative brightness of the virtual and real worlds, and the ability to control that, because the indoor experience is quite different from the outdoor experience, and so that's a whole different technological problem. - Right, so, I'm going to ask this question. I'm not sure who might want to field it, but it's near and dear to my heart, so I get to choose. So, "In most technologies," the question says, "we seem to move forward, get it out there, and then start worrying about FX, security, privacy, after the fact. How do we ensure that AR and VR don't go live, get out into society, until we address some of the challenges that may arise?" And for me, I will give an example. The kind of sensing that happens on HoloLens, Tango, ARKit, is essentially building a realtime 3D model of your space, right? And that may or may not have privacy concerns in business, home, you know, so on. So, should we be thinking about this? Right? Or is it okay to be at the point where we're giving developers everything we can, so that they can explore the space, and when do we make the flip? When do we worry about it? - Maybe you can answer your own question, as it's your area of expertise. - I mean, yeah, fine. I mean, so, for me, I see Peter's laughing. There are people at Microsoft Research, there are people at University of Washington thinking about this. In general, I think it speaks to the architecture and how we design it. I've been working at Mozilla, working with web-based technologies for a while. I've been working with web-based technologies for a while. I've been working Mozilla for the last half year, on sabbatical. Because on the web, this is even more of a problem, right? If I go to the App Store, any of these things, and pick an app and download it, I've done some filtering already about whether I trust this app. If I click on a link, all bets are off. So, I think, partly, we can do this by creating architectures that give users the choice as to whether they are willing to give that kind of information to the application. So, in HoloLens, for example, the applications get the model, right? That's so we get these beautiful representations of the world, where you sort of flap your hand and you see graphics over the model. That's how the application can find the chair to put the guy in it, right? But it may be, that if I'm running an application that's just displaying the cadaver in front of me, and we can all see this thing, floating here, and it's only using that sensing for tracking, that I should be able to say as a user, "No, don't give that application anything else," and it can still function, right? So I think thinking about these things, and thinking about how we can build architectures and encourage developers to build to those architectures, could start to ameliorate these issues. - I think Fred's earlier comments about shared experiences is really interesting, from the perspective of, you know, what are the concepts and constructs for people to control sharing parts or none or all of their mixed realities with others? And, you know, I think that those are really ... So that's on the other side of what you're talking about, not the cadaver side, but the sharing of my own mixed reality, and I think, right now, we're trying to address Fred's challenge, and just get to the point where we can actually have a shared experience at all, but once we get there, I think it's going to be a ... There are going to be privacy issues on both sides, what people are recapturing, people are having their own realities. - Sorry, the video that you showed, the dystopian one, where it's trying to encourage, you know, you were getting all these ads popping up, or suggestions as to you might buy this, and it's the other data or information about you that gets fed into this augmented reality, which I think is where it becomes problematic. - [Blair] Right. - So what it knows about you and how it uses that to decide what to pop up, and what to do to you is where we should be starting to talk to other technologies. - Right, I mean. So, we've got about three minutes left, and we could go down and talk about that, but I'm curious if there are things that any of the panelists have been thinking about, that we haven't touched on, that you would like to toss out there? - I have hoped that, from the very beginning, that computer graphics and augmented reality could serve as a teaching tool. Every student in engineering school learns that F = MA, force equals mass times acceleration, but few actually experience it. - [Blair] Mmhmm. - Any object that has significant mass also has significant weight. I learned about F = MA from a grinding wheel that existed in the basement, when I was in junior high school. It had a crank and it had a gear that sped up the substantial inertia of the grinder, very substantially, so I learned, early, that if I pushed on this consistently, it would go faster and faster and if I stopped pushing on it, it would keep going. And to stop it, I had to push the other direction consistently. And I learned that F = MA from experiencing it. I think the really greatest value of augmented reality and virtual reality is to show people things in ways that will make the underlying physics, the underlying meaning, clear. And the hardest problem of all is what is the representation that will make clear the meaning? What color should the hydrogen atoms be in a benzene ring? I don't know. I've never seen a hydrogen atom in a benzene ring, and, indeed, it's unlikely that it's large enough to reflect light that I could see. So the representation I choose is a fiction, and the quality of what I learn from the representation is based on how well that fiction that I create represents something that has reality and value in the real world, and I think the challenge to the folk who put content into these items, is to put content in that's interesting, that has value to society, and that has instructional value. The aircraft simulator people have done that, because they know what the contents should be, but what do we do this for information science? What does information look like? How should it move? How should it change? What does it feel like? What is the haptic experience of feeling bits? I don't know, but it seems to me that visual models that we might create could be extremely valuable in reaching conclusions about what we can and can't do. - Okay, and we are out of time. I'd like to thank the panelists, and sizemagorous... 