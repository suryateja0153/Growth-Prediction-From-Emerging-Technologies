 [Music] Oh everyone awake how's that hangover it's also okay I'll try I'll speak very softly so that you know that no one gets sick thanks for having me hello Peppa my name is haiku I work at huge in New York you can probably tell from my accent that I'm not from the US originally anyone take a guess where I'm from nope I'm from Germany so there's a German excellent near 71 but I lived in Australia for for 15 years so I have just a bit of Australian in there as well so I'm a real mix and my mom is Chinese so like I'm I'm as international as I probably come so thanks for having me I want to talk about these today I guess emojis are a fun way to maybe map map your day so right now I feel a little bit like that maybe and then maybe after the representation or sort of feel more up there and I was actually wondering whether you know that greens faced with the like maybe some of you feel like that so the the reason why I want to talk about emotions is I guess maybe picking up a little bit on what Cynthia spoke about yesterday in terms of tragic design and we spoke a little bit about artificial intelligence and machine learning yesterday so I want to I want to dive into that topic a little bit more and I'm touched on I think something that will become more and more important for us as user experience practitioners over the you know the following coming years in in the contour and in the context of designing emotionally intelligent machines or designing emotionally intelligent services and I think I think it's important to kind of touch on that now because we are at an interesting point in time where we're unshackling ourselves from terminals and you know desktop computers and we're we're near a state of what some call ubiquitous computing so basically technology is all around us we have Universal connectivity one of these and you know I'm the internet-of-things subscribed kind of pointed out yesterday is is here now I'm I can't quite remember the number but there'll be billions of devices with a URL address you know over the next few years so like it's it's basically happening and and and I guess we're also moving away from interfaces to a world currently in Los Angeles 69 degrees with clear skies so even now we start need to start thinking about designing interfaces that are basically off-screen you know voice interaction how do you interact with a machine via text or maybe even my intuition it's not that designers have not thought about that but I guess it has been somewhat simplistic designers have always thought about and and try to evoke emotions and there's some beautiful examples like this sports car that is called the austin-healey sprite was produced in the United Kingdom and it was affectionately called the frog eye or the bark eye you can kind of see the eyes like it's really really cute all this this lemon squeeze are designed by Philip Starck for Alessi and it's sort of it's humorous that melts form and function and I guess in in order to evoke your emotional response and the purchased on the user of the product and even even when it come even when it came to designing computers or digital experiences I guess we've always intended these to be likable and friendly you know the smiling macaws I guess a good manifestation of that so maybe it's more accurate to say that we have been a little bit simplistic about this you know we've but even like a UX designer you think about user journeys and you know as these are happy it's a user angry as a user frustrated but it has been somewhat simplistic so maybe it's more accurate to say that we have always somewhat designed for affection and we have not really had the opportunity to think about the full emotional spectrum of emotions that we may need to think about and and here's what this is important we are we are at a real instruction point technology is coming to a point in 2017 where machine learning is becoming mainstream we'll all probably get around in self-driving cars very soon and machines and services already getting to the point where they will know us so well I'm powered by big data and through anticipatory design that they will be able to execute and make decisions or now we are now behalf without us having to do anything and you know user interfaces you know whether it be voice from screen are kind of moving to that point to what used to be personalization is now moving into the adaptive UX I found the talk and adopt a few acts very interesting yesterday and I guess it's sort of like a foray into this new world that were kind of entering in and then the final sort of piece of the puzzle is I guess that we for the first time really ever we have no technology that is able to detect users emotions and this is this is massive I mean if you really think about it the the term affective computing was first coined by MIT I think in the mid-90s and it's sort of you know says that it systems and devices I can recognize interpret process and simulate human effects so I'm just going to let that sink in for a second and I have a great video to maybe bring up to life for you little bit for video I asked her folks could we come up with a multi-touch talking about the invention of the iPhone they're like we type on I could rest my hands on the topic and about six months later called me and showed me this prototype display and it was amazing and I gave it to one of our guys and it comes to various is he more in the meetings I mean early early 2000 and I gave it to one of our other really brilliant UI folks and he called me back a few weeks later and he had an inertial scrolling working and a few other things now we were thinking about building a phone that time and when I saw the rubberband and Herschel scrolling and a few of the other things I thought it might god we can build a phone out of this love you Steve I mean that's that's crazy so what happens when machine learning meets effective computing and what do we as designers have to think about and what do brands have to think about in order to ensure that we create you know services and machines and experiences that are supportive and emotional is you know you know I'm positive so that they look like this this is a character from the movie big big hero 6 something it's called and um not like this Terminator Skynet you know seen them all scary future they're all - for energy we live in a virtual reality you're actually not here you're being farmed for your energy etc I'm just kidding you're not we're all here work we're good so how do we how do we think about designing emotional intelligence teams I think the first question that we need to ask ourselves is what we are actually trying to achieve because surely we're not trying to design I guess the full prosaic or full emotional response like we don't want our users to be extremely happy it should be extremely sad like I think that as designers we hello we have a responsibility to think about this in monument's terms and some of the stuff that I'm talking about today hopefully will maybe just shed a little bit of light and maybe a starting point of how we should think about this so thank you Cynthia do you want to talk about this wrong no I can do it so we obviously saw this yesterday and it's actually quite nice that you know we're sort of maybe touching on some of the similar things and I think hopefully you'll leave today I'm all the confidence to a notice that they're sort of themes that are emerging that we're kind of talking about this new world where you have machine learning attacked with UX like emotional design like it all kind of I think I think it paints like an end in picture what you will see in your career and the types of things that you will be expected to do that are maybe not just designing beautiful wireframe or thinking about information architecture and and I think we should embrace that change because ultimately it means that as designers we have more impact you know really enjoyed the talk about in design and moving into I guess the the built environment and you know the the techniques that we can kind of use there but yeah so the the we love emotions were robert plutchik basically he he wrote the textbook on human emotion I think in the in the mid-80s so he's been doing this for a while and I'm and he came up with this concept of basically eight basic emotions for joy trust fear surprised etc and the way that he's laying them out in this wheel of emotions I guess shows the interplay between those emotions but also the intensities select the closer you get to the center the more extreme you you feel so you go from serenity to joy to ecstasy and and that's what I that's what I was touching on me for that we don't want to necessarily design or you know create services or experiences that sit in that Center because that's probably not responsible and and I guess ultimately the point that I'm trying to make here is that emotions are complicated emotions are very complicated and I'm even even happiness can be complicated are you happy because you're not sad anymore you know like I think I think where sometimes it's a little bit simplistic as I said before in terms of users frustrated users angry users happy and and I think we have a responsibility to think about this in slightly more nuanced terms so another reference point the font very useful in putting this together is a American psychologist called Martin Seligman and he he has been an avid promoter in the field of positive psychology so basically he's been thinking a lot about he's developed a framework to think about the condition such humans need in order to flourish and so you know just kind of reading a few things off screen here you know we want to have positive emotions in our lives we want to feel a sense of engagement and you know authentic relationships in order to be happy as human beings you know it's nice to have a purpose in a meeting in life like I'm in this I know and I feel much more purposeful because I have something that I do that I love and hopefully you feel all the time about what you do others have it through family like you know everyone is different and then I guess the last one is the sense of achievement and then you know feeling that you're actually accomplishing things so when you put the first letters together P erm a he calls it the perma framework and that's been a really useful way for me to learn about our guests like the human condition and to kind of start learning about the space a little bit more so I guess the question is what how can machines how can services play a role in helping humans flourish it's ultimately that's that's what we're here to do to create positive experiences and I guess having more responsibility with the technology that's available to us now well we asked a bunch of people at the beginning of 2017 huge interviewed owners of an Amazon echo or a Google home and we we know we spent some time asking them um what in an ideal world their gadget would do for them and there was there was a number of sort of major categories that emerged so you know some people wanted their conversation III to be in a system so you know things like tell me the weather tell me about my day you know what meetings are coming up you know remember someone's birthday etc others one of their conversation you I'd do a choice for them like order do the laundry order my groceries reorder the seamless that I had last night and I'm lazy in are just wanted seamless again our you know seamless I'm sure you know seamlessly other participants like the third sort of group wanted I'm one of their conversation why to make them smaller so help me look up contextual topics so maybe even help me learn you know a deeper talk topic in more detail and then the last group was keen on their conversation you are to be the connector to all the other devices and things in your living room suta basically play well with other services but wait there's more so when we asked these the focus group what their ideal relationship should be with an RA I we we got this little footnote in here for people here and they listen to you you need that those ears they're going to well that's great you need that pat in the back and you can follow me sometimes you're not listening to yourself that's right instead of paying the shrink yeah you go there you talk to your nei you're relieved okay great not crazy it's a friend you come home holds your day honey good a shitty day are you okay you're beautiful don't have to pay the shrink of money you just have your amazon tell you how nice you are so the the key inside for us here was quite interesting when machines talk people assume relationships and I guess it's it's a very powerful medium voice compared to you know our text or any other interaction not you immediately assume that there's some sort of a friendly relationship that you have with you I and the expectations in a range from empathy to emotional support like the the Garda was destroying one person that named echo after their mom another person that named echo after their baby crazy but here's what users tell us flowing I guess that's the the world that we now live in so let's let's move ahead and I want to talk a little bit about the the technology that's available that helps that can help us to detect emotions there's it's a growing market so it's estimated that the emotion detection and recognition software market is worth thirty six billion dollars u.s. 36 36 million 30 36 million u.s. dollars by 2021 so it's big and we should probably pay attention and care so the first one is facial recognition it's probably the one that's most advanced and most ready to use so the way that it works is that you're the face has plotted in two different points and they're distinguish between pivotal points like fixed points and striking points like points on your face that move and there's basically micro expressions I kind of give away how you're feeling so even if you are not consciously thinking about it you know machines can pick up on the fact that you know like it's it's kind of quite amazing what it can actually draw so here's sort of like an illustration of like the the points on the face that you know through computer vision and webcams you can actually start analyzing and understanding like how someone's feeling you can kind of give you give away your emotions maybe even if you don't think you know that you are here's an example by a company called Real ID service I'm developing software that I can be demotion to this is macorís and you can see how you know it can kind of tell her level of having a surprise status constant fear confusion we're living in the future movements the second technology area that is somewhat Maturana starting to appear in commercial markets as voice recognition so these Steve Jobs example that I was surety was done by a company called beyond verbal it works by capturing sentiment and voice through a number of frequency characteristics time related features and voice quality so here's a software that the University of Trento has developed so you can it's German so it's okay that you don't understand it and I can basically to read and detect the level of anger this is the boredom category is next to the piece of wood it's interesting about this or the script forward is that with audio detection it is dependent on the language and the cultural context so you kind of need to set the language before you can run the algorithm because the German speaker will infinite differently compared to Portuguese a Brazilian speaker or an English speaker whereas with facial recognition its global so no matter where you are in the world you we all share the same way that we are frustrated angry etc so I thought that was interesting to point out the last one this quickly touching on is very much emerging but it's been very much hype due to the wearables market so biometrics essentially detect a combination of heart rate skin temperature and movement in order to derive like how someone is feeling whether someone's stressed so it's not sort of comprehensive and much more testing is needed there's wristbands headbands some readers but the most interesting that we come across it's basically a patch that we put on your skin it's like a little you know like a transparent translucent sticker and it can detect currency on the skin it can be chemical composition so something to look out for I think we'll see more of that but compared to the other ones probably still still in you know more in the developing face okay so we spoke about the technology but this this is really important this stuff works really well in a lab environment works really well with actors you know like the actress that I showed you before but real life is complicated you might have just broken up with your boyfriend or boyfriend and then you start interacting with a machine or a service and the machine or service doesn't know about your emotional state so I guess what I'm trying to say here is that this stuff needs to be tested and validated a lot more on real life so it's still very much emerging but it's kind of great for you to be aware of the stuff now so that you're ready you know maybe when when this stuff becomes more mature okay so but at a high level the way that this is meant to work is that the user comes to starts engaging with a machine or a service in and I get emotional clues and based on the technology that we have we can hopefully detect how the feeling or what sort of motor in the machine or the service and we'll try and overlay the context you know so like what context are we are we having this interaction the algorithm will then create a response and output that will I guess cause a reaction or outcome in the user and then that reaction gets captured by the algorithm gets fed back in so that the machine gets smarter over time that's sort of roughly how it's meant to work if I you know if we keep it really simple so how do we make sure we get this right and how do we make sure that we kind of understand all the inputs and outputs that we need to be aware of Javier Hernandez is a researcher at the affective computing group at MIT and I think he Kwanza quite nicely effective computing is like nuclear power we have to be responsible in defining how the user here's a little example of what not to do in 2014 Facebook got a bit of negative press they got a bit of heat sacked essentially because they they ran an experiment on on their users feeds so they manipulated the feet of I think almost 700,000 users and they tried to test whether reducing the number of positive messages on someone's feed would make that user post less positive messages or if you flip it they try to test whether with removing like negative worrying or negative messages on someone's feet would make that user post fewer you know sad or gloomy updates and it worked but the problem was that they didn't ask those users for permission so I guess the conclusion was that it was somewhat manipulative and unethical so this is really important to keep in mind that we need to have users permissions in order to manipulate their emotions otherwise we're going on a very slippery path this is a little clip from the movie ex machina where the robot the machine essentially seduces him to go on a date with her turn it up a little bit right first a traffic intersection and maybe show kind of nice looking yeah fine so she's in manipulating his emotions into believing that she's actually you know his girlfriend that she's friendly that he can trust her when in reality she's a she's a killer and and so I think I think you could say that AI already has a bit of a branch problem because we've all seen terminator we all know what happens you know and in the examples like the Facebook example I guess I'll just a good reminder that we need to be really mindful of what were actually doing here okay so Paul Allen co-founder of Microsoft kind of reminds us of this too he he says that we need to do much more research in understanding the human condition than human cognition and that we're really just starting to subscribe the surface so what much what you might see in your careers I guess that I'm not sure if we're all going to turn into psychologists I mean that's like a degree that you need to study but I think as UX designers we need to ADIZ have a better vocabulary and a better understanding or from the human condition and that we can to serve like say users happy users sad and a user journey like we will need to be more nuanced or not okay so how do we how do we tie this all together what is the framework doing the right thing so that we can work out when and how to apply emotional responses to services so first up we need to establish the desire for emotion and the permission to play so let me unpack that a little bit more for you so some questions that we might want to ask ourselves is what is the use ass emotional state what are the users ambitions what is the nature of the interaction that we're trying to design and what is the overall context yeah so that's sort of the first the first area of investigation I guess the this then we look at the permission to a place so do we have the right user is that the right context has the user given you permission that's I keep coming back to that like are we actually entering into an agreement that we can actually manipulate the users emotions essentially and as a brand and as a service do you have the right value proposition we don't want to just do this for the sake of doing it you know like just because the other technology doesn't mean that we should just like do it because we can do you have the right intelligence an order to actually derived like you know what a user is going through and coming back to Cynthia what is the danger of being wrong because you know like when you're talking about emotions like you can really hurt somebody and I guess that's something that we need really need to keep in mind okay so I'll come back to this framework a little bit later but just to kind of get your head into the space if we can probably we can map these two questions into a two by two so just put that in your head and we'll revisit it so the next question is like what is the what is the proper emotional response like you know how how can we kind of think about this there's in our research we've identified sort of I guess three three categories of three groupings and I'll take you through so the first one is to essentially react like a machine so we can acknowledge the motions in a decision-making process but the output is like a machine there's no there's no emotion in the way that we kind of get respond back to the user so this will really apply best transactional situations or security moments so think of a call center you know when you call and you're like zero what's your name I don't understand so we can we can take your frustration or your emotion and through the algorithm we can almost kind of develop like a giant switchboard that will route the user on directions over maybe start trying on the phone maybe it's time to just get the operator on the phone I mean hopefully I'm not gonna make me cry but I've spoken to AT&T before right the the the second area of investigation there's a few startups that are looking at assisted driving and so if we can detect that a driver is tired angry inattentive so this essentially tends to be on the road the the car could stop over and pull over by the side of the road in order to to ensure that you're safe and you know I think that that actually makes a lot of sense and I hear that I mean road rage is a real thing I don't know traffic I'm interview yet but I'm sure there's a bit of traffic road rage in Rio I'm going tomorrow so report back and you already tell Google home to shut the up and all it does is it goes quiet that's it but acknowledging that you've just insulted me essentially as a machine just go quiet what did you say I'm also confused this the the second sort of way that we can kind of think of this is react like an extension itself this is probably the the the the one that is closest to the idea of an office vendor like an emotional support system so we acknowledge and we interpret emotions but the user is in control of changing the emotions I will scan you for example scan me scan complete you have sustained no injuries however your hormone and neurotransmitter levels indicate that you are experiencing mood swings common in adolescence diagnosis puberty whoa what puberty what I like this quote this is a professor Judith Master from Aberdeen University and she says I would like people to have their own in angel that could support them emotionally throughout the day I don't know if you've seen the movie huh where the the protagonist falls in love with the AI and I think it's such a beauty portrayal of things going terribly wrong or just right I guess it's some opportunity side but I highly recommend that you watch it it's a it's a beautiful it's a beautiful it's a beautiful movie a film there's also some software that's being developed detect emotions in the classroom so if you own a in a teaching environment can we determine you know what the students are going through in terms of their learning process and is there a way to adjust the the learning plan based on you know what students are going through we need to be really responsible in understanding or actually read emotions again student is happy it's your in a sad like you know like I think you need to be trained as an educator to understand what their responses are and then to adjust the plan accordingly but it's interesting that was on to think about applications and real world use okay and then the last one is to essentially act like a human so this is sort of I guess the the place where we agree where the Machine and the user enter an agreement where the machine can actually manipulate the users emotions for for the users benefit essentially so we can diagnose in interpret emotions and then maybe give advice or you know give triggers to change the emotional state arm currently and different kind of this one little clip you are my patient I would like to help you can't fix this one buddy he's depressed Minnesota I can help you what are you doing I am downloading a database on personal loss database downloaded treatments include contact with friends I'm really ask Alexa I'm sorry that you're feeling that way sometimes talking to a friend listening to music or even taking a walk can help I hope you feel better soon Thank You Alexa so I guess we're kind of already here the area of machine therapy is really interesting well you know like for cases where you don't really happy for medics festival you talk to a virtual tour at least my kids keep me going what advice would you have given yourself 10 or 20 years ago to to not believe you to do not be so gullible so not be so gullible I been told recently that I have a tendency to believe people too readily without them having to prove anything and so as as a result I recently I've really I I've gotten myself in a lot of trouble um and so I think that looking back if I could have I would tell myself who do not believe to not be so stupid and to think and just to not be so gullible Wow so I do find it interesting that I guess I don't know if you've ever spoken to it like a psychologist about your your sort of problems but but I guess it's an interesting point to make that maybe it's easier when you talk to a machine like that sits on a virtual couch and you essentially was talking to yourself and the Machine kind of just triggers you to talk about the emotional state that that might be easier and it's important to point out here too or that this is not to replace a human but this is a way to gather information so that a human can still make decisions so this is not replacing the shrink but this might be just a way for you to you know maybe start gathering some information that is human and connect on okay so we have react like a machine or react like an extension of self react like a human and we've got our two by two and I guess we can now start mapping mapping those in so let's do it when there's no desire for emotion and no permission to play we probably shouldn't do anything right if there is high desire for emotion and low permission to play we may want to create something or a circuitry acts like a machine so we still allow emotional input but the output is lacus any emotion like the course and example that I've mentioned if um there's low desire for emotion and high permission to play we can react like an extension of self and then ultimately if both are high then we could design something that is you know more human-like and the experience that we create so just to kind of summarize things I hope that you have found some of that information useful and interesting let's remember that when it comes to designing emotionally intelligent services or machines that we need to have women on intentions again permission really really important we should honorably design for what can be understood and we shouldn't be renegades and and you know this is what the world West because you know there's a serious business when it comes to engaging users in an emotional context and like any relationship we should aim for gradual progression of into the mystery so you probably want to buy me a drink first before you take me home so I just keep that on munch I mean that's yeah this is this is a quote by the CEO of a Factiva one of the software companies that I mentioned before and she says in ten years we won't remember what it was like when we couldn't just thrown out our device and know what response or you didn't like that did you and I don't think we're really that far off so I think we can get excited about that future and we should prepare cells so the impact is that these expectations would shift natural emotional interactions will become the norm and ubiquitous computing brands will be able to form a much deeper connection with people than they have before and for us for you guys Laura understanding of emotional psychology will become important in the design field so a lot to think about but I think it's an exciting future if we think about it responsibly value I remember watching her and I remember watching the scene where he start talking to her in the arts kursi and he stuff her and say why are you breathing you're Robert you don't need to breathe and and then her start to to talk like I'm just trying to like to create that empathy with you and I remember also hurrying the the interview with the girl who does the voice of the Google on the maps and her saying like we need to where we are recording the voice we need to make like a robot voice if we speaking like natural voice the the person meets the the road like they need to to go like it TURN RIGHT if I say like this in no natural voice the driver doesn't get the message and the question I have is you say like we need to get the permission from the user to say like we are reacting as a human or as a robot but in some occasions can we like decide if what's better is the we should side the reaction and I don't know the question I'm trying to when we should decide and when we should ask the user what reaction which you have right okay I think I think that which that is a very good question I I think that it comes down to the context in in the interaction that you're having and and that's what I try to outline before if it's like a very transactional situation like a call center that is a completely different context when compared to you downloading an AI and NDA I actually becoming your emotional support system and you know what we're actually not there yet this is all a little bit science fiction up until this point in time but it's raising some really important questions like the one that you pointed out like you know to what extent like when I download the AI do I need to sign a piece of paper or contract that says I'm willing to have that computer I manipulate my emotions but I think it is really important to at least make clear that what what's about to happen or what some of the the downsides of the the negatives might be of he and engaging with a machine in that sort of way and I think it requires a lot more research and all be hard so I don't have an answer for you but I think it's a really important point to raise and something that we should all think about it thank you thank you for the talk and let's assume that as it's expectable we keep on doing research we get more data now everyone has a personal tracking device over so it's easy to do that and going forward we learn to design more emotional intelligent machines so my question is is that going to help us to educate or grow or inspire more emotional intelligence do you believe I am I really somebody said yesterday Melton Gregg that the the best way that we can work with AI is to actually have a collaboration between human and computer and so I actually very much believe in in the future where machines may help us to become better human beings you know like where you machines may help us work out new ways to play goal so I I personally believe that there is a way that we can actually benefit from machine interactions and that we don't add up in this in the future where we're being exploited or where it's sort of turning negative and and I think it's actually the people in this room and the designers that are actually having like much more influence now on maybe determining you know what that might look like we're not computer scientists we're not you know cognitive psychologists but I think when it comes to defining the frameworks in which those interactions will take place I actually think that we can benefit from learning from a machine maybe in ways that you can't when you're engaging with humans um that's my personal taking I guess we need to wait and see what happens thank you so much 