 [MUSIC] All right, so we talked about crowdsourcing, complaints, disasters. And I just mentioned earlier it ultimately comes down to politics. And so this talk is going to analyze the Indian political process.  Well, a small part of it. Thank you Amed and [INAUDIBLE] for inviting me here. So I'm the Ashoka University, it's a relatively new University near Delhi. Where I co-direct a center called Trivedi Center for Political Data. It's named after Ashok Trivedi an early donor, who gave us money to fund the center for ten years. And we also have one of my students is here, Saloni from Ashoka is here. So I'm presenting the work of many many students and other faculty members and staff. So the center was started in 2016 by a couple of us from computer science and political science, so it's a joint venture. I think it really worked very well because when we started, I mean I didn't know anything about politics. I think the political science people didn't know much about data management, but we've learned a lot from each other. So in that sense it's been quite successful. The mission is to understand Indian political processes and governmental processes better through data. So one of our common TCs was that there isn't enough informed discourse in India. So people would have a certain theory about what's happening to cost equations or what is happening to gender and so on across India. But even for something as basic as a political process, there isn't good hard data that you can base open end support. So we want to enable data driven discourse through data. Part of this is of course doing research ourselves. Part of it is organizing data sets and providing them for journalists, for students, researchers, whoever is interested in it and disseminating that information. So this is all sort of properly gathered, somewhat teacher quality check data. We are, of course, strictly non-partisan and we have a research orientation, we collaborate with several universities, typically in political science across the world. We have 7 staff, about 20 students like I mentioned, and we're hiring, so if you have students, post docs, people interested in this general space do refer them to us. So I'll talk about a couple of projects today the first one is called Lok Dhaba, it's a play on Log Server obviously. This is a data set that you can look at right now on our website. But what we have done is essentially calculated Indian elections data going back to 1962. And for all the states and central elections until then we have gathered data, integrated it and made it easy to visualize, download, and so on. So this is one place where you can find information about everyone who has contested in election at the central or at the state level, we don't go to the local level yet. So much of this data actually is available of the Election Commission's website, however it's not in formats that are easy to consume. So for example, you would have PDF files all over the place, they'll be hiding inconsistently organized or inconsistently formatted. They won't be in a way that you can actually perform analysis on them. So we are trying to solve that problem. There is no data quality checking like I said. So they have legacy data which they have collected over the ages but they really go back and look at previous elections. So, one of the distinguished fellows we have at this center is Doctor S.Y. Quraishi the former Chief Election Commissioner for India. So he has been very supportive and helps to educate us about what the processes inside the election commission are, and what the constraints and capabilities are. So we have taken this data and we have made it available in this interface. So just like you might see on a news channel during elections, you can generate your own graphs and maps of how various parties did. What was the turnout in various constituencies? What was the gender ratio? Things like that. But you can ask this for any election going back to 1962 and you can sort of build your own visualization. So these are some maps, there are some graphs, and so on. But behind it all is a lot of systematic quality checking of the data. So for a example, when we put together all the election commission data, we find that they are inconsistencies like same party, same election, same constituency. You have multiple people from the same party which is not possible, right? So they have some data entry errors somewhere or they have some problem in the process. Inconsistent constituency type, like constituency divided in India according to gender SC or SD within the limitations that the type is not supposed to change. But we find cases where they do change, so these are a bunch of checks that our political scientists thought of or we thought of and included on this spreadsheet. So now that you have a database of sorts, it's not actually a very big database, in the sense of big data, it's only about two million rows. So we're talking of all candidates who ever contested, not just the winners. Everyone who's ever contested an election at the state or the central level. So we load down these old consistency checks to write and then we find these problems, we refer them back to the election commission and so on. We also try to integrate different sources, so things like whoever the election commission deems to be a winner should correlate with whoever ends up in local server, right? But we find that the Lok Sabha record actually says something different, mostly its a Lok Sabha problem, actually the election commission is relatively clean, data is relatively clean. But the Lok server has various gotchas, various problems, sometimes there are processes we don't know about or that are very kind of mysterious or unknown process. Particularly in the earlier years, so for example, and the reason we don't go beyond 1962 is that before then there were actually multiple winners per seat, in some cases. Because some seats had special members for special casts or even in some cases for certain communities. So it gets very very messy before then but after 1962, it is relatively clean. So I'll come back to this later when I mention the kind of work that computer science research can enable over here. So this is the Lok Sabha website. And the general problem is given one data source and another data source how do you map entries that are mostly similar and integrated that way? Another big problem is there isn't a single identifier for a person in the political process. So if you have even who was contested in one election and in the next, you don't know if that is the same person or not because it could be a relatively common name. And the number of people with very common names especially in states like Punjab and is not funny. So because of this political scientists can't ask questions that they're very interested like what is happening with respect to incumbency over time? Are there more people entering the political process or less? How long do they stay on average and things like that. What are the trends along age, cast, gender, region? What are the differences there and so on. So we've built what's essentially an entity resolution tool to help map people who are the same across different elections. And I'll skip through it quickly. Basically, if you look at the literature entity resolution is kind of a solved problem, but when you look for a tool that you can actually give political scientists that they can use, there aren't many. So we have built a tool that factors in approximate Indian name matching to help resolve these rows and so on. So if you're interested come talk to me later about it. I want to mention a second project we did in the context of Smart Cities with the city of Hubballi-Dharwad in north Karnataka. It so happens that I lived there and I had some connections to the city. And so when the Smart City proposals were being worked out a couple of years ago, I told them that ever other city was having a marathon, and a workathon, and all of that. I said we'll have a hackathon. And so, because everyone was interested in preparing the Smart City proposal, they gladly gave a lot of data to us, which was very interesting. So we of course, we told them about 5-Star Open Data, which [INAUDIBLE] has been talking about. One star is when you just put the data out, make it available without the need for RTis and things like that to linked open data which is 5-star and then it's integratable with other data sources and so on. So a couple of my students built this app, it's a site called hdworks.org, you can go and check it. Basically what it is it's a list of all spending by the city, which is of course it's supposed to be all public and RTI-able, except it's not actually consumable and usable by most people. So you can in this case for the city of Hubballi-Dharwad, you can look over all the works. You can see who's contractor, what's the source of funding, what's the amount and so on. We have provided ways that you can geotag, you can say this work was done on this road and this much money was spent on it. You can have officials upload pictures of the work that was done, so the officials will say yeah this money was sanctioned for the road, that's the road. But there is also a way for citizens to give feedback and then the citizens will tell you that the road is actually something like this.  [LAUGH]  So this is very useful for actually the municipal commissioner to look at what's happening across the city. So that's what we're trying to enable and trying to study crowd-sourcing and citizen involvement in that context. We have sort of standing queries, so you can subscribe to a certain work or a certain ward. And get information when there is an update about work happening in that ward and so on. So I see I am out of time and I'm going to skip to this last part to, I'll just take half a minute to mention computer science problems in particular. So, easing data collection and analysis from loosely structured sources, whether it's web or other sources, it's a long-standing problem with something that we experienced painfully over the last couple of years. Automatic generation of data quality checks so I mentioned a few data quality checks that we thought about and enforced on the election data set. But what if you could have tools that sort of do data mining and online detection and things like that, and figure out that this is a likely check that two people from the same party can't contest in same election, in the same year, in the same constituency. Can you join similar columns? Like I have a Lok Sabha data set, I have an election commission data set, they are mostly the same but there are differences whether it's in spelling, or for other reasons. Can I have a loose join, an interactive join where I can say 90% of your data is okay, 5% is okay, modular spelling corrections and so on. 5% is something you need to look at, this is something that Soloni for example spent a month on and can we automate this process? Can you have conversational interfaces, data? So it seems like we can talk to your phones, we can talk to our rooms and so on with Siri and things like that. Can you instead have political scientists or others talking to data centers in natural language? Can express these whether its quantity checks or queries in natural language? Okay and we are doing a bunch of work on user interfaces and so on. So let's skip that, you can contact me later if you have questions and also here today and tomorrow, thank you.  [APPLAUSE] 