 [Music] hello everyone my name is Dave Smith I'm a developer advocate at Google on IOT platforms and I'd like to spend some time talking to you today about some of the developer platforms that we've been working on specifically in the areas of IOT and a little bit about the Google assistant so let's dive right into this so computing has evolved over the years we've gone from mainframes to desktops laptops to phones every decade or so we see sort of this major change in computing and now we're seeing computers literally embedded into everything and while phones were a very large jump over pcs in terms of the number of devices in the market we're expecting to see an upcoming wave of IOT devices with things literally everywhere so we use the term ubiquitous computing to describe this and it's this technology that's accessible to the user wherever they are and whenever they want it and today we're gonna talk about some of the platforms that Google has been working on to support this particular effort in the past we've trained users to install individual separate apps on every siloed platform but now we have devices that are spanning all over people's lives and some of these devices don't even have screens like we would traditionally use for a user interface in terms of a mobile application or a desktop application so we need to think a little bit differently about what computing really means to these particular users and we need to take their context into account in what we're building their location their physical activity time of day these types of things so we need to start thinking about these individual apps as actually just individual views or unique surfaces into a single application or a single continuous or ubiquitous service that can service across all of these different areas we need to create a single seamless experience so what I'd like to do is walk you through some of the developer platforms that we have here at Google to help enable your apps to span all of these surfaces and I'd like to start with Android things so Android things was recent LEED announced we announced us as a Developer Preview back in December and it's Google's new platform to support development for IOT devices and it's based on Android one of the most important features of Android things is the use of turnkey Hardware through a system on module or ssam approach and that's you see some of them pictured here on the slide Essam contains a CPU memory wireless interfaces all of the important electronics that are necessary with a common set of software and these are modules that you can buy in bulk they're very inexpensive and you can plug them into your own custom boards which can be manufactured at very low cost this is all part of our effort to democratize hardware development for everyone making it fun to prototype but also making real possibilities for you to build commercially viable products the somme enables commercial hardware and some very important features Android things software is a variant of the Android OS that is optimized specifically for IOT and we've added new api's that are designed to help you integrate better with custom Hardware beyond the device platform it also includes secure and managed software updates direct from Google these updates are managed using the Android things console and are verified on device for enhanced security we see many exciting benefits of the compute power that is possible in a device running something like Android things computer vision audio processing machine learning computing power in these IOT devices is increasing every year but at the same time they're getting cheaper and much more power efficient tensorflow is one of the examples that we are seeing as one of these great new introductory into IOT tensorflow has been ported to Android and all kinds of hardware such as Android things also supports this we've built a sample that takes essentially a capture of various images such as dogs or cats or other types of breeds of animals and then allows the device to classify what those images are using a pre trained tensorflow model so the training is done off the device but the application the device application is able to process the image from the camera and determine what it is by locally running it through the pre trained tensor flow model it doesn't need any cloud communication to do this it does all of it locally on the device using those machine learning api's this is actually a sample that we've open-sourced and you can take a look for more information if you want to play around with this on your own we also have this sample running as a demo in the sandbox in that little plastic Android head so I encourage you to take that and play around with it as well I'm not responsible for what it says when you point it at your friends all right so let's take a little minute to talk about the Google assistant the Google assistant enables you to get things done with the power of conversation it provides a new and exciting view into your app or service for users to explore the assistant is available on a wide variety of surfaces today from the Google home wearables phones in the car and we're working hard at adding it to even more surfaces over time you can extend the Google assistant as a developer to support conversations with your own apps using the actions on Google platform you can provide a we provide a simple conversation API to give you raw strings from the user that you can use to then generate replies this is an example of what we built as a conversation action around Google i/o this is a very helpful API because you don't have to do the work of parsing voice input dealing with text-to-speech all of that can be handled for you through the actions API however you are still responsible for interpreting what the user has said and for a lot of developers maybe you don't necessarily want to do that yourself it's a fair amount of control if you need it but sometimes there's a better way so we have a great tool that is called API AI that does a lot of this additional work for you so if you haven't seen this before I recommend that you check it out API AI uses machine learning to handle extracting entities out of sentences for you it's much easier and more powerful than trying to write these regular expressions yourself and it allows you to implement these conversation interfaces with ease it's a graphical tool that allows you to specify these intents and entities for the data that you're really interested in out of these particular conversations and you can see an example up here on the slide of kind of what this looks like with a sample that we built for a recipe recommendation app and essentially what you provide is you give the tool a list of phrases or sentences that you expect the user to say and you can see that API is automatically highlighting individual entities out of those elements that are actually interesting to your application so for this case it's a recipe recommendation so we're looking for things like a protein a temperature a type of dish and all of these things are just recognized automatically by API AI now the other really nice thing about this tool is that you don't have to pick every single element that you think the user might say because of the machine learning element to this system you simply have to provide a number of samples up front and then the system can interpolate and interpret what a user might say so that you only have to give it some initial data and then API dot ai will be able to always do the right thing picking out all of the entities and then your back-end application simply has to respond to that structured data so you no longer have to try and interpret out of a string the information that you need we've also announced the Google assistant SDK which enables you to embed the Google assistant directly into your own custom hardware projects we provide out-of-the-box support for Linux and Android things but the API is based on G RPC so you could pretty much port it to anything you can either use a button trigger to trigger the assistant or you can use a library that we have for hot wording support you can trigger it just like we do with consumer devices all you have to do is provide a microphone and a speaker and then you can use the actions on Google to implement additional functionality such as device control the Google assistant also supports home automation via the smart home system device makers can easily integrate existing devices with our home the home graph knows the state of all connected devices so that when you ask it to dim the lights just a little bit it knows how to do that in an intelligent way the user makes queries to the Google assistant but and then smart home makes calls to your cloud service to control those devices as a device maker you don't have to worry about handling all of that speech input just dealing with simple structured requests with very specific values the user speaks what they want and smart home coordinates across all of their devices inside of the home even across different device makers firebase also has an amazing suite of applications and services that are useful for IOT real time database for example makes it easy to synchronize the state of various devices across a mobile app and between various IOT devices in your application authentication is another example enables you to associate devices with the user's account and with Android things all of these features are even easier to integrate for IOT because you can use the same existing Android client libraries and SDKs right on those devices we also announced cloud IOT core back at Google i/o this is a fully managed service on the Google cloud platform that enables you to securely connect millions of IOT devices directly to Google cloud whether you want to connect million of devices and scale them automatically you have no need to worry about provisioning infrastructure or adding individual redundancies it has native support for standard protocols like MQTT and you can access all of your data globally dispersed as one single system it's very good for enterprise use cases where you need to do mass scale types of provisioning this is sort of converse with the firebase use case which works very well for individual user type home use cases you can use cloud services that are part of the cloud platforms such as bigquery to analyze your massive scale data and visualize that for internal use or for your users as well so that's sort of a whirlwind tour of all the different services that we have available for IOT and the Google assistant I want you to be sure to play with all of the demos that we have in the IOT sandbox in the assistant sandbox and our team will be on hand to answer questions as well immediately following this session I'm headed over to the IOT office hours for anyone who has additional questions about any of these platforms and you can connect with me directly later on today we also have hands-on training for Android things where you can actually get your hands on some of these devices and play with them and build an application and we've got another one for the Google assistant in actions on Google tomorrow so be sure to check those out oh and one more thing we want to get you started on the right path by building cool devices for IOT so everyone who has attended this session today is going to go home with one of our nxp pico developer kits for Android things make sure you grab a card on your way out from one of the attendants and you can pick up your kit downstairs so thanks so much for your time everyone today and I hope you enjoy the rest of the conference [Applause] [Music] you 