 [Music] you know whenever I give a talk at i/o I always ask to be first thing in the morning because I know only the most motivated smartest best-looking audience comes give yourselves a round of applause for being here so we're going to talk about building apps for the Google assistant if you know nothing about building apps for the Google assistant you're in the right place this is meant to be an orientation talk to give you a sense for what scenarios work how to accomplish it and then hopefully at the end of this talk will intrigue you to want to drill in more and find out more information so I'm Brad Abrams and I'm a product manager on the Google assistant team I'm Dara I'm on the product partnerships team on the assistant team I'm Adam Coimbra and I'm a partner technology manager on the assistant so when sundar launched the assistant in Iyer last year he did so for one reason and that was to build a conversational interface to all of Google and we wanted that to be a single interface regardless of what context you're in what what device you're in or what tasks you're trying to accomplish so the way we think about the assistant is that it's a conversation and it's a conversation between you and Google designed to help you get things done in your world and one of the reasons I'm personally so excited about the assistant is it builds on Google's long history of creating ecosystems and now history started actually with Google search where we created a strong ecosystem between publishers and readers it continues with YouTube where we have a strong ecosystem between creatives and their viewers and of course many of you know on play we created an ecosystem between Android app developers and there users it's that exact same kind of ecosystem we're creating with the Google assistant and we that ecosystem is enabled by a platform we call actions on Google so you might be interested in actions on Google because it enables you to connect with a whole new set of users in different contexts in different places everywhere the Google assistant is you can also connect to your existing users in new and different ways and finally it gives you an opportunity to innovate in a whole new computing domain this domain of conversational interface which we'll talk a lot more about in this talk so since we launched the platform in December we couldn't be more happy with the variety and creativity of apps for the assistant that we've seen whether you want to order a pizza from dominos or play name that tune the song pop you can do a wide variety of activities but I want to drill in on one in particular today to kind of give you the anatomy of one of these assistant apps what's really how do they work what's really under the covers so some of you may have noticed in addition to the Android version of the Google i/o app we now have a Google assistant IO app as well so you're able to say something you talk to your assistant and say ok Google talk to Google i/o 17 and then the assistant looks at all the ways it could possibly respond all the contexts all the possible different options and picks the very best one for this user at this time in this case because the user use the app name explicitly IO 17 then that's like a URL or tapping on a short cut on the desktop and it brings us directly into our Google IO 17 app the user here is the assistant given introduction and then here is an ear con so ear con is to the ear what icon is to the eye it's a visual audio distinction to help the users understand there's a transition happening and then there's a change in the voice and the icons change and there's a now there's a two-way dialogue between the Google i/o app and the user and that two-way dialogue continues until either party is ready to exit so that's how it looks on Google home but of course we knew we were launching four phones here at the event so we wanted to also make it work well on the phone and there you see it working on the phones suggestion chips and images and whatnot in addition to that we also wanted to let you book seats some of you may have noticed some of the sessions yesterday we're kind of full you might know you can actually reserved seats to the sessions so we wanted to let you do that transaction as well to book a seat so when the session comes up you can click the suggestion ship reserve a seat and if you click that we use our new seamless account linking to have you sign in and then you even if you haven't created account with just two taps you can go and create an account then you see your receipt and of course it's free to reserve a seat so that's fine and the transaction is complete so actually what we're going to do is walk through the Indian experience of building that app I just showed you in this session I'm going to start off by talking about the design process how did we come up with that app what was the design that went into it Adams then is going to go through the hard core development of it both the natural language understanding part as well as the transactional part of it and show you in code how to go build that and then vir is going to show how to make that app discoverable how you can get people to actually use that app okay let's drill into design but first you know do we need design at all I mean these conversational apps these are system apps means they're they're just chat BOTS right I mean it's text input text output there no images there's no forms to layout there's no CSS to do do you need design at all well consider a very simple case say we wanted to reserve a number of seats a number of seats at a restaurant how might we handle this case we say for how many look at the wide variety of ways that a user might respond to this query how are we supposed to handle each one of these cases well the answer of course is in the design but what is the nature of design for these assistant apps well Oren Jacobs of pull-string coined this phrase interactive screenwriting which I think fits perfectly what we're trying to build with these assistant apps with when you build an assistant at app it's kind of like you're writing a screenplay like for a movie or a TV show where you're writing dialogue except you get to write lines 1 3 5 & 7 and somebody you have no control over gets to write lines 2 4 6 & 8 and you have to use that to come together with a beautiful experience and to do that you have to pull together design elements from two different disciplines one is the linear narrative design that's what we learn about character storytelling and dialogue from books TV shows and movies but you have to merge that with what we learn about from interactive design well we get from games and mobile web app design things where we learn about creativity engagement and retention so we need to bring those things together so let's talk about how we do that here we looked at all of our assistant apps and we found out the element that they had in common the ones that were got the most retention is they had a really strong persona and so we wanted to build that for our app so what we did is we actually thought about you what what would you might want out of the app we benefited from having a marketing team that we could work with that you don't need a marketing team and really sat down and understood the brand attributes and the design principles and from that we distilled the style guide and the style guide helped us write the dialogue for our assistant app there are actually several of us writing dialogue and by actually having a guide like this I mean we literally had a version of this that we kept up while we were writing dialogues it kept the persona tight and crisp even though different people were writing so just to tell you we also wanted to launch for the phone so we needed we knew we wanted both visual and eyes-free experience and so we wanted to make sure we had the similar content so one assistant but similar content so the chat bubbles are a subset of the spoken text and that's because we could use suggestion ships which we just fell in love with as the easy way to navigate through your your assistant app users didn't have to guess at what our app could do we could put the most prominent things there and users could zip through very quickly we also found that a visual description even in very data heavy app like this a visual description really helped bring more life so wow that was a whirlwind tour of design for conversational apps there's way more to be said about it I hope you'll take an opportunity to drill into more of the sessions here at i/o about that or catch them on YouTube after but the turn over Adam is going to talk about actually building these things Adam thanks Brad so I work on Google's gtex team and our mission is actually to help developers and partners like you launch on the assistance so I couldn't be more excited to be here today to show some of these awesome new features that we're launching and hopefully motivate you to go try it out yourself so a couple slides back Brad showed some really cool screenshots of this assistant app for Google i/o that let you reserve a seat and sign in and today I'm actually going to try to build it with you right now so let's look at some of the steps that we took to do that and that you could try yourself so first we create a project on the actions console and this is kind of like the home for the assistant app we then connect a natural language tool like API today I now we really like API it's a world-class natural language understanding tool but if you have your own natural language understanding tool that's you know best-in-class you can also connect that right to our API s we then connect a web hook which allows us to perform back-end processing business logic and connect to api's again we like nodejs but you can use any web server once you have all these kind of basic integration points set up either test it out so we provide a web simulator which makes it really easy to do local development but it's really important to always actually test on a real device so just by clicking test in the actions console you can immediately try it out on your Google home or your Android or iPhone so once we have all that done we want to enhance it for mobile using some of the visual responses that Brad talked about so we can do that with API today I am with our web hook and then finally we enable that seamless sign-in flow and the ordering experience by integrating with the transactions API but wait a minute so once we've gotten all this done how does it actually happen that a user can say something to the assistant and it triggers your app and all and all the magic happens well let's take a look into that so what happens is the user said something like talk to Google i/o 17 to their assistance enabled device like Google home and the speech is stream through to the assistant and transcribed as text the assistant then applies natural language understanding ranking it uses our knowledge graph and it uses the user's context to understand the users query and realize that the i/o app is the right service to fulfill that request so it invokes the iOS API today ie agent and the API agent understands it against an intent defined there that you've defined it then calls the web hooks to perform business logic to talk to the i/o API and get some some data and formulates a conversational response which is sent all the way back through to API today I to the assist and out of the user cool so that's how it works and let's get into some of the details of how we build it so we mentioned that the actions console is kind of like the starting point and we're really excited about this we launched it yesterday and it's a really focused way to kind of develop and manage your assistant app so the three main things that it does is one allowing you to configure and set up the the metadata and the directory listing for your system app and you know branding information it then allows you to manage the testing and deployment process in a fine-grained way and then once live it gives you analytics so that you can track you know how it's doing out in the real world with real users then we connect it to API today I or another natural language tool so an API today I the the kind of main thing that we do is we define intense and entities so intent basically model user queries so that we can understand in a structured way what the user wants entities are sort of structured packets of text that let us extract meaning from the user's request so once we've gotten these defined we can then write responses to user requests inline in the API today I tool and so now that we have our kind of basic model set up we can use training in API today I to improve the dialogue model over time so the example here is for the Google i/o app you know if the user were to say what Android sessions are their API is going to understand that that map's to the list session intent and it's going to send a request down to the web hook and trigger the list session function there so let's look at the web hook now again you can build a web hook using any web server framework but we like node.js we like it so much we build a client library that makes it easier to to interact with so you can get that just with one command NPM install actions on Google and basically we have a bit of boilerplate and we have a handler for this list session intent list topics intent and you can see they're all we're doing is we're calling the Google i/o API getting a structured set of categories and then formulating a conversational response the topics covered are dot dot dot now that all this stuff is set up again we want to test it out so we have this web simulator and its newly updated to provide an interface for testing things visually and for testing a voice-only environment and again it's super important to actually test on device there just by clicking tests and actions console you can immediately take your device and say talk to my app and you're going to be able to test it out just like that okay so I'm going to go over to my demo one machine and we're going to actually try this out with the real IO app so this is the actions console and we can see it's already set up with the IO demo app we've got some app information set up there which is basically branding information and it's already connected to an API today I project we can go edit on API right now and we have some intents already set up we have a welcome intent which handles the case where the user triggers the app we have the choose session intent which lets the user get details about a session and a couple others so I've been around i/o yesterday and I heard some developers wondering what the free stuff was this year so why don't we make this app a little bit more useful and make it so that the user could just say to their phone any time hey what's the swag at i/o and get a useful response so do that we would just create a intent we can call it the swag intent and add a query what's the swag at i/o and right there in the tool we can define a response it's a Google home and $700 in cloud credits awesome and so we just hit save we go to the actions on Google integration and we click test and just like that we can try this out in in our web simulator so we say talk to our demo and we have to login invokes this this app and we can say what's the swag at i/o and it's a Google home in 700 and cloud credits awesome so now that we have kind of some of the basic wiring set up we can talk about making this work really nicely on mobile so here so to make it work really nicely on mobile we want to add visual responses with API todayI and with our web hook so API provides a built in card building interface and this is really nice it lets us easily define cards and chips and carousels and lists it also can then send that request down to the web hook which will enable you to create dynamic responses so that's a really nice useful feature we've added let's look at how we do it from the web hook so there's two really important things in this code that you see the first one is that we're checking whether the user has a screen so this is super important because we need to be aware of the user's modality of their context and tailor our experience accordingly so if the user has a screen we show a rich card that's populated with data about the session ok so now I can head back over to the machine and show adding that right into the i/o app looks like there's a delay so heading back over to the demo1 machine great okay so we have this session that this intent that handles the the moment when the user has asked for information specific information about a session so this is the choose session intent and what we can do is add suggestion ships right there with the API today I response builder so we add some suggestion ships and we'll add that reserve a seat ship and we can add some others like you know next session other topics and hit save now to add that rich card that's dynamically populated we need to turn over to the web hook and update it so this is the web hook code and right here we have essentially like a controller for our app so it has you know a pointer to each of the intents an API todayI that triggers a function in the node.js code so the true session intent is here and we can see that right now it's just doing a very simple thing it's calling the i/o API and it's creating a you know simple text response so we have that code that we showed before prepared here and we can add it in and we're checking the weather there's screen output whether the user has a screen and if they do then we add a this rich rich response otherwise we can fall back on this text response okay and my web hook will automatically update and I can go and update and test so now we're heading back to the simulator and let's say I'm interested in the what's new in Android session so I'll get this rich card with a link and with the suggestion ships so that was pretty easy right okay so the last part then heading back into the to the deck is to add this transactional experience where the user can sign in and they can actually make an order so we are so excited about the transactions API it released for Developer Preview yesterday so you can start building with it now and really what it does that lets you accept purchases and orders from your users with your app and we make this a great experience on the assistant with three main things the first is providing a seamless build an experience for sharing payments and identity information between the user and the app once the user has sort of gotten this information and approved the purchase we then give you a way to re-engage because you've now sent the user a receipt and we can send updates to that receipt that manifests as notifications for the user so you can actually reengage and get the user back into your app in that way now to integrate with the transactions API there are five main steps so first building out a basket or a shopping cart and this can be as simple as you know a suggestion ship like in the i/o app or it could be as complicated as a menu ordering experience you know with lots of different choices and customizations during that cart assembly process you might need some more information about the user you might need to know what's their delivery address this lets you set price and service availability etc so we give you an API to request that once your order is all set up you need to propose it to the user and get their authorization so we provide a proposed order API that lets the user preview what they're what you're asking them to buy and approve it once they've approved it you need to confirm the order so let them know that it's active and send them a receipt so we provide a confirm order API for that so lastly many transactional experiences require the users identity and so we provide the ability to integrate with an OAuth 2 web server and provide a seamless login flow for the let's take a deeper look into that so you know many of you hopefully are familiar with oauth2 it's pretty pretty standard and basically to set it up with actions on Google you go to the actions console and you configure the usual Roth - stuff client ID client secret auth URL etc there and that lets us know how to talk to your server and then in dialogue you call an API to trigger the sign-in flow so you can do that from API or or from the web hook now once the users signed in you want to propose the order so this snippet of code shows a proposed order API call and what we're doing here is we're building a structured order object we're populating the line item with the session title we're saying hey the price is zero and then we're calling the ask for transaction decision API to to propose the order once the order has been proposed we get a new request saying hey the user accepted the order now you need to confirm it so this snippet of code shows confirming the order and here we're building a structured order update we say hey the status is confirmed we provide a receipt and then we send it along to the user as a receipt just like any other visual response okay one more time going back to the machine and we're going to actually add all this in to our app so where we left off is we had this suggestion ship reserved a seat but we don't have any way to handle it so we need a new intent to handle the case where the user taps that ship so we can create the reserved a seat intent and it'll be triggered when the user says reserve a seat and then what we want to do is immediately call the sign-in API so there's just a little bit of code that we need to put into API today I - to trigger that and we can just add it here and hit save so with that we're calling the sign an API which will log in the user now to make this really work again we need to hook up our os/2 server to the project so going back into the console we can see how we did that so we have this account linking section we can edit it and you know we see that it's prefilled but we have the standard soft client ID client secret there's a couple extra steps that we take to in our os/2 server to make the integration really seamless and it's easy to do and you know we highly recommend everyone does it okay so what do we have we have an intent to handle when the user says reserve a seat we trigger the sign-in API but what happens when the user signs in well we have this intent set up that basically passes that event through to our web hook and what we're going to do then is call the proposed order API once the order is proposed the user accepts it we get another request to API today I saying hey the user accepted this you need to confirm the order and that comes through and is matched by the handle order intent here at that that's again is just passed right through to the web hook which calls the confirm order API and then we're done so the last thing to do is just add this code into our web hook so going back in we see we have the controller for our app and we have the handle sign-in and handled order handlers and we see that they're empty right now so we can add in that code so handle sign-in again this should look familiar we're building an order object populating it with session data and you know proposing it to the user with this call right here for handle decision this is where the user has already accepted the order and we want to provide a receipt so we can add that code and it should automatically update so that's it that's all it took and now we can actually test this out on my demo - device just have to update the project cool so we're just going to go over to the demo2 device and we can say IO demo what's new in Android we can tap the reserve a seat chip okay well that's why it's a Developer Preview we can do one thing and I think it'll make it work thank you thank you we appreciate it so I think it'll work if I can just do this might have been user error okay so let's try it one more time io demo what's new in Android hmm there we go cool and we see with just two taps I'm creating an account on this server and we propose the order to the user what's new in Android $0 I approve and we get our risky cool so that's all it took we did that in like 10 minutes build a transactional experience seamlessly signed in the user it's pretty awesome stuff so let me jump back in for just a quick recap on on what we did so we created a rich mobile experience for finding out about i/o sessions we added a suggestion ship to let the user reserve a seat and we connected an oauth2 server to enable a seamless sign-in flow and finally we use the transactions API to propose the reservation and get the users acceptance and send a receipt we did this again in like 10 minutes so I really I believe that all of you could go right now and add it and build apps yourselves that do the same exact thing and I'm so excited to see what you do so with that I'm going to hand it over to Veera Thank You thanks Adam I'm vera and I'm here to tell you how your app can be discovered once you build I have the opportunity to talk to partners like you every day and this is one of the primary things that we hear let's actually start by admitting that we live in a pretty amazing time in technology people are asking computers to do things for them they're asking them to help them plan their day to get from one place to another and to even clean their apartment and a mess and they're asking for the little things like my little brother despite being 22 recently asked the Google assistant how to make scrambled eggs for our family and so we know that if you're building a Productivity app or a recipe app or a smart home app your users are out there looking for you and if there's one thing that we've learned about Discovery over the years it's that the best way to find users who want your service is for them to find you and think about it this is actually a very different world no longer does the user have to know that your app exists or have to download it or even have to set it up all they have to do is say okay Google or long-press on home on their mobile device and they have access to your service and that's on over a hundred million plus devices and I'll be honest we're still getting started there's a ton of work to do but that's a pretty exciting thing our goal of Google is to help connect you to your users so today we're starting with three primary ways of enabling discovery of your assistant apps through the glucose system the first is in dialog so directly in the conversation with the user the second is through the assistant directory which we announced yesterday and then the third is through links that you can share so let's actually start with in dialog so directly in the conversation with the user the most reliable way that a user can get to your assistant app is by explicitly asking for it meaning we have a set of pre-established phrases things like talk to speak to ask or at that once said with the name of your assistant app we introduce you and then you own the dialogue and to end a user can also deep link directly to an answer so to extend the demo that Adam just did a user can say hey Google let's talk to Google i/o 17 and then we introduce the app and they can also say something like hey Google asks royal 17 about what was announced and will introduce the app and then take the user directly to the answer so some partner examples of this are hey let's speak the Dominos and then we introduced Domino's and then Domino's comes in you can order a pizza my brother might need this in case the eggs go awry or hey Google akinator and we introduced a great game on the platform or hey Google I love this app ask dr. doggy if dogs can eat chocolate and we introduce dr. doggy for what could be an urgent question the way to think about explicit triggering is very similar to typing a URL and getting to a website or tapping on an app on and then going inside via the next way to introduce your assistant app in dialog is through implicit triggering so I'm really excited about this one because this actually starts showing the promise of the platform we know that users are asking the Google assistant a whole set of things they're asking hey tell me a joke or I want to play a game or I want to work out and we at Google look at all the apps that can fulfill on that and suggest some to the user so this already works today you can say hey Google I want to work out and we introduce fitstar which has a great guided workout it's super easy to be able to do this all you have to do is add an invocation grammar to your app and a piti or whatever natural language solution they use so I want to show you what that looks like is super easy so we're here in the intent the swag intent that Adam already created and that you can see his what's the swag at i/o let's say you want to add something a little bit more colloquial like what's the freebie at i/o type it then you can scroll down the answer is still the same you guys got a home in seven hundred credits it's awesome make sure the the conversation you get save and that's really it and you're able to test it by going into integrations actions on Google you make sure you select the swag intent here and then once you hit test that's it we can do the test later but basically what happens is you say what's the freebie at i/o and then we introduce the Google i/o 17 app let's say you've never heard of it before that's pretty quite and no there was an assistant app that is about Google i/o and then the Google i/o 17 app is able to say your freebie at i/o is the Google home and seventeen seven hundred dollars and app credits awesome to go back to the slides one of the primary questions that we get about implicit triggering is how are you guys going to rank we're going to be looking at of different signals and it's still very early and will iterate on this significantly over time but one of the primary things we're going to look at is the quality of your abs as well as things like the user's context or their preferences and again we'll experiment significantly over time the next way for you to grow discovery of your assistant app is to the assistant directory so we launched this with the goal of letting a user try out new app browse apps as well as set the preferences for their personal assistant the way that a user gets to the assistant directory on Android is by long pressing on home and then tapping the upper right hand corner icon on iOS they get there by going to be assistant app and then same thing tapping on the upper right hand corner icon and there's also web link for the directory so once the user is in the directory they can scroll different categories they can tap on an app they can try the app directly there they can rate the app and then they can also set their own personal preferences with the app so we have this concept of voice shortcuts this is where a user can go directly to your assistant app so I have mine set as hey Google it's chill-out time and then Netflix starts playing on my chromecast and then I have another one which I love which is hey Google it's party time and then my soul cue bones turn on and then I can't touch this starts playing on my Google home device on Spotify it's pretty awesome the way that you can improve visibility of your app within the directory is by one again keep the quality of your app really really high this is what's going to help with both ranking and with reviews and then to submit rich images well written descriptions this is what's going to encourage a user to try out your app directly in the directory and then re-engage with it again in the future cool the third way of growing discovery of your assistant app is through links that you can share so you have a role here too you have the ability to promote and grow awareness of your assistant app we encourage you to do this by doing things like one share through social media encourage your users to take this viral to promote through your own owned-and-operated property so link to your sites or to your Android or iOS apps encourage users to use your service across different platforms and then three encourage press to drive traffic to your assistant app allow other sites to link to it enable awareness that way so let's go to device three and I can show you what that looks like as well as I mentioned you get to the assistant directory by long pressing on home you tap on the upper right hand corner this is what the directory looks like and we scroll down to education and reference talks at Google i/o this is the landing page within the directory you can hit share and let's actually tweet it and this is live just awesome you can say whoo we're live at i/o and actually treat it cool once a user taps on that link they go to directly to your landing page within the directory awesome go back to the slides please so as a recap the way that you can grow discovery of your assistant app is one in dialog so directly in the conversation with the user both implicitly and explicitly - through the assistant directory and then three through links that you share so we know if you're building a recipe app that helps you cook breakfast for your family or a fitness app that helps someone keep their routine your users are out there looking for you and our goal of Google is to help connect you to your users and with that I'll hand it back to Brad to wrap up awesome thank you we've shown you a ton of stuff today building conversational experience for I three in the phone doing transactions and getting your app discovered you're now ready to participate in our our app development challenges tons of great prizes encourage you to do that but let's keep this conversation going we're going to be at the assistant booth which is kind of in the main area in the walkway there come by and talk to us with more questions ton of other talks and just the special things to saach-- it who built the assistant app that we see here today so again thank you very much [Applause] [Music] 