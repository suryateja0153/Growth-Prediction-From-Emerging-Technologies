 [MÚSICA SONANT] Recentment hi ha una sèrie de forces que s’uneixen, es donen força entre sí i canvien la forma en què estem interactuant amb el món de la informació digital. Per un costat, tenim tots aquests dispositius intel·ligents connectats. I, al mateix temps, estem esperant que hi hagi accés als serveis digitals o de dades allà on siguem. Hi ha serveis basats en el núvol que ens permeten fer traduccions instantànies i comprendre el llenguatge natural que els desenvolupadors ja han començat a potenciar. Tots aquests factors s’han combinat per crear una interacció amb el món digital que és molt diferent a la d'apuntar i clicar que teníem en el passat. Per a la UI conversacional, ens referim a un espectre de disseny de la interfície d’usuari. Tenim bot conversacional intel·ligents. Els quals fan ús dels serveis i poden aprendre i millorar amb el temps. Hem tingut reconeixement de veu des de mitjans dels anys 90. Ha millorat la taxa d’error del 43 %, que teníem al 1995, al voltant del 6,3 % que teníem al 2016. La interacció multimodal és el futur de la UI conversacional. Estem intentant anar més enllà del límit de la veu i volem comprendre la intenció a través dels moviments de la mà, els gestos i les expressions facials. Imagina que acabes de passar la mà i el teu sistema d’àudio recull i ajusta el control. Amb els avanços en el processament del llenguatge natural i el software, la indústria del hardware també està ampliant els seus límits. Amb l’ajuda del nou xip NLP 5 de Sensory, ara es pot incorporar una interfície d’usuari de conversa als productes de consum. Pensem que la UI conversacional planteja problemes, reptes i oportunitats molt similars als que el mòbil va fer per a l’empresa fa uns anys. I les API que es dissenyen per a una interfície d'usuari de conversa seran molt diferents a les que s'han dissenyat per al ratolí. Així doncs, pels teus serveis actuals, recomanem el patró que hem destacat anteriorment a Radars “el back-end per el front-end” per començar a pensar en com es dissenya un motor que sigui específic per un entorn d'UI conversacional. Crec que el canvi més gran que hem vist en els últims anys en el món del software és la fàcil disponibilitat dels serveis basats en el núvol, que fan coses com la comprensió del llenguatge natural, el reconeixement de la veu i una varietat d’algoritmes intel·ligents. Però una de les eines que hem esmentat anteriorment al Radar va ser wit.ai. Aquest és un bot conversacional que, juntament amb Microsoft bot framework, va ser un dels primers de tota una nova generació de bot conversacionals que es poden entrenar. Recentment hi ha un radar anomenat api.ai que no només es pot entrenar, sinó que també aguanta algunes conductes dirigides a l’assoliment de la meta, característica es coneix com “ranures”. I, finalment, hem de mencionar LEX, que és el bot conversacional que es troba darrera d’Amazon Alexa. Actualment, només està disponible per Amazon com una bestreta, però de ben segur que reorganitza les coses amb aquest món. La gent pensa en coses com el processament del llenguatge natural, que està integrat en aquestes UI conversacionals. Comencen a pensar sobre la intel·ligència artificial i l’aprenentatge automàtic perquè realment és una part d’aquesta família. I quan penso sobre quin és el impacte potencial dels desenvolupadors quan comences a integrar cada cop més AI, és que al llarg dels temps cada cop hi haurà menys i menys coses per programar. En un futur, crec que veurem una gamma molt més amplia d’interaccions. I espero que tots s’infonguin al nostre entorn físic que difumina la línia entre les experiències físiques i les digitals. 