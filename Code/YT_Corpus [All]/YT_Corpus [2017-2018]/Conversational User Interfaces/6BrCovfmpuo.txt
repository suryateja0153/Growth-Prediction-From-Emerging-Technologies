 - [Joe] Double-check if his mic's on. - [Man] I think it should be. - [Joe] Cool, awesome. Everyone, please welcome Tim Noonan. (audience applauding) - Hello everybody, thanks for inviting me along Joe, and thanks Sarah, for allowing me to work this hard in my presentation, because Sarah's covered fantastic fundamentals that I don't need to include now. So just a bit about me, I'm a little bit older than I look, I'm 52 in a couple of weeks, and I got my first Apple IIe computer like Ron did back in 1984, and it was quite a revolution. I also, at that stage, there was a Unix system that was available for the general public run by a pilot, and you could dial in. So I learned Unix before I learned DOS, before any of those other things, and strange as it may seem, Unix is, if you're happy with the tech world, one of the most accessible environments possible, because if you don't like the way something's being presented, you just head up an alias and change the options, and pipe it through cut, and chop out a couple of columns, and suddenly you've got accessible commands, and you can use all sorts of devices. And I just recently, sort of got back into the terminal on my Mac. One of the reasons I love the Mac is that it supports three operating systems. You've got macOS that's pretty accessible, in some ways not as accessible as Windows is, but in other ways things often work automatically, much more easily, and you've got all the linking to the iPhone, and I've got VMware so I can run Windows in a virtual machine and run JAWS and NVDA, which is another screen reader on that. And you've got the terminal which gives you full access to Unix, so when I get frustrated with Finder, which is a very visual way of browsing through the file system, I just go into the terminal and cd around like I used to back in 1984. So I describe myself as a, although I have a few hats, I'll be honest. So one of the things that I am is a voice user-interface designer, I've been doing that, gosh, since the early 90s I designed a lot of telephone systems, telephone banking systems for St. George and other banks, and designed some telephony for when I was at Vision Australia, that let people access the daily newspaper, the Fairfax newspapers and the telegraph and so on, newspapers, News Limited papers, over the telephone, and it was, we had pull scripts. I was sort of the designer of the system and had a programmer working for me, but you know, in those days you had very small teams, so just two, and what you could do is you could ring up and this robot voice would say, you know, "Welcome to Today's News Now," which is TNN for short. People thought it was short for Tim Noonan's News, but of course, it was Today's News Now. I did come up with the name, so if you're looking for somebody to do copyrighting, I'm not too bad at that either. So you'd ring up TNN, it would say, "Welcome to Today's News Now," and you'd use the telephone keypad to login, and it would say, you know, "Here are "the papers available, what paper do you want?" We'd get the XML file from the publisher at four in the morning, it would come over through UASP or something, or FTP, and then we'd run it through a pull script into an access database, and then it would convert it into menus. So we wrote a whole fourth-generation language really called PhoneScript that allegedly is text-to-speech output, and if you say, "Say this," or, "Say that," and I guess it was the precursor of you know, what's going on now. I'm veery excited because, you know for 20 years or so, 25 years, people have hated telephone automated services, and my job has always been to make them as approachable, as friendly, as intuitive as possible, but you could never fully succeed. But this service let's people browse article headings, you could then choose an article, it would start reading it to you, and then you could even stop and pause it, and say, "Ah, can you read that sentence again?" And you could check the spelling of word, 'cause we had recipes. You know, people would read stuff in the guide and they'd go, "Now I need to know how "to spell the name of this TV show, "or this particular shop, or restaurant." So we basically developed a screen reader over the phone, it was a fun, fun project. Sadly the technology got very, very old and it died. So towards the end of my presentation tonight, what I'd like to do is to talk to you a little bit about voice user interfaces in the modern era where speech recognition is involved. Many of you have had some experiences, positive, negative or otherwise with Siri, and of course if you're an American, you've got a lot more options. You've also got, over there, Amazon's Alexa which isn't in Australia yet, but probably will be when Amazon come over here. There's also the new Samsung phone, the S8 is going to have a system in it called Bixby, and it's gonna be a bit more of a voice interface to the phone, so you can say, "Send this photo to Tom," whereas Siri is more of a sassy personal assistant and there's rumours that Siri is going to have a huge, huge brain transplant, maybe in iOS 11, and I can tell you that, as someone who uses Siri a lot, I'm really, really waiting for that, 'cause it's just not good enough for super-productivity. I try to have productivity systems where I can use reminders and set calendar appointments and so on, and Siri, although I have worked out some systems, still lets me down. I mean I haven't got my Apple watch on tonight because there's nothing quite like a braille watch to know when you're talking over time, and a talking watch isn't quite so good. Although I have to say, the Apple watch does have what now has tactile time telling, and you just double-tap the watch and it will go do, do, and it vibrates long for 10, a long vibration is 10s, and then shorts for single hours or single digits, and if you tap it three times, it will just tell you the number of minutes after the hour. So that helps, but the trouble is it takes about 12 seconds for it to tell you the time, and when you're talking and trying to pretend that you know what you're gonna say next. I've got my little computer here, this is a little braille input, braille output computer, I spent, you know, a lot of time keying in notes and so on, and you know, on the Mac, and then transferring them across, but the reality is, I don't have the cognitive load, capacity, capability, whatever, to read my notes while I'm talking, so whatever turns up is whatever's gonna turn up. So Siri, so Bixby's gonna be interesting, and I've also bought a thing called a Viv, V-I-V, and that is, the people who originally developed Siri have developed a next generation, who sold it to Apple. They then developed a next generation Siri called Viv, and it's sort of, the demos are pretty impressive, but you never really know what's going on behind the scenes in a demo, but Samsung have bought that and that will be incorporated as well. So look, if Bixby lives up to the promises, then it could be quite interesting for people who wanna have a bit more direct control. Their dream is that every app will be able to have a voice control interface, so more command and control rather than you know, Siri, "Oh, is that what you think," or "Why are you talking to me?" It's like you know, silly answers often that. I know you, in fact what I'm gonna do is we're gonna do this in reverse order, because I've only talked about voice user interfaces so far so we're gonna talk about those first, and then we're gonna talk about other aspects of inclusive design. But the point is that, you know, a voice interface is a form of inclusive design because it gives people more choices, more options, and if your modality is audio, if you like talking like I do and you know, as a person who, you know, can't see, my ears serve as double-purpose. They both are my eyes and my ears, so they work pretty hard. Every email I listen to, read, has to be listened to, and it makes you very cranky when you get spam. I sort of feel like I wish there was a way you could send a message to the person saying, "Yes, I got your spam message and I blocked you," and it wastes their time as well. I'd like sort of spam spam. A little bit messier I suppose, I've never said that before, I've never put it into words but I've thought it, almost like a, (groaning), I'm so frustrated that I'm getting all this spam, you know, and then, but yeah, maybe there's a startup there. Look, come and talk to me afterwards if you've got money and who knows what we can do, we can spam the spammers. So the voice interfaces are really interesting because if you have trouble typing, or if you have trouble seeing the screen then clearly this is an area where you can use a modality that works well for you. But let me tell you, artificial intelligence researchers for the last 30 years have thought that really great speech recognition is just around the corner. It's probably, it's the most undelivered promise in the whole history of IT, speech recognition, that's because the brain is very complicated, and the way that we learn language, we don't even know that Noam Chompsky talked about, you know, sort of a universal grammar that we're born with, and other people challenged that. There's a really interesting article that I, a podcast that I listened to awhile ago from, I tweeted it anyway, @TimNoonan is my Twitter feed. If you're interested in voice and sound, my tweet feed is full of what's going on in that area, and it was one of the newspapers has a science podcast, and they had a fascinating thing on grammars. But look, speech recognition is really hard, let me give you an example. If you send someone a text going, "Time for dinner," these days we'd assume it's T-H-A-I, like a Thai restaurant, wouldn't we. But of course, what if you're a business person, talking to your PA, saying you know, "Time for dinner?" and it's like, "No, it's open shirt." And you know, and if of course your assistant is your mistress, then of course it could be either, so. This sort of situational awareness for speech recognition and intelligence agents is really quite tricky. Now speech synthesis is another area that has really come ahead in leaps and bounds in the last few years. Let me turn this on, I'll let you hear this fabulous, I'll just turn this up a bit so, if I can remember how to of course. That's changing the pitch, that's not gonna work. All right, so this is a bit loud. (rapid robotic speaking) Sorry, thank you. (rapid robotic speaking) All right, anyway. So this is an oldish device, and it's got an old synthesiser, and it's not very human, is it? You know, it's very robotic and the first synthesisers were robotic. One of the things about a robotic synthesiser that's based on phonemes and it constructs the words just based on these core atomic sounds, phonemes and where phonemes join, is that when you speed it up, the comprehension stays there. Now we have these, what are known as concatenation-based speech synthesisers now, the voices that Siri uses, and Nuance have developed a lot of voice technologies, it's a pretty big field, and the whole idea is how natural and human-sounding can you make your speech synthesiser. That's I guess the objective, but the trouble is, and there's a bit of cognitive dissonance that can occur when something that sounds very human says something without inflecting in the right way, or without hammering the right words, and it's not always possible. So imagine this sentence, so close your eyes and imagine how many ways you could say the following sentence, "I didn't say "he stole the money. "I didn't say he stole the money. "I didn't say he stole the money. "I didn't say he stole the money. "I didn't say he stole the money. "I didn't say he stole the money. "I didn't say he stole the money." There's just, multitudinous ways, and unless you've got real context, it's impossible to know. So speech synthesisers, the modern ones in particular, try and come up with sort of a normal pattern. The old ones would go, "This is a sentence "and by the time I'm finished, "I'll be back down to the bass note, "and this is another sentence, and this is," can you imagine reading an erotic novel using a synthesiser like that? In my youth I read many erotic novels, well in my 20s, 'cause synthesisers weren't around in my youth, sad to say, (laughing) and if you're interested in the whole topic of eroticism and accessibility and disability, there is a, if you Google Netporn, Sexuality and the Politics of Disability, you will find a rather risque article that I was commissioned to write for a European magazine called Cut-Up Magazine, gosh, 10, 11 years ago, they paid me, I think 400 Euros to write this article. So I was researching and you know, different, totally different people, and occasionally I'd like to put my own stories in there, I'd say, "Conversations with the author," so you could never tell which was me and which was someone else, because I didn't want to give too much away. But in there I have an example of an erotic short story being read out by a computer, so if you're really keen, you can go and track that down. (all laughing) So we have a long way to go, but what I wanted to say to you is this, that voice user interfaces and intelligent agents, all of this area it's just starting to explode. Microsoft have Cortana, and that is available in Australia and it has an Australian voice, it'll even sing, "Click Go the Shears" to you, to prove that it's Australian, and there's some work being done by the NDIS, they're looking at developing a sort of an assistant that you can ask questions about the NDIS, and Cate Blanchett's voice apparently is going to be used. Now, if anyone listening is involved in that project, you really should get in touch with me because I think I could provide some great strategy on voice interface design, and ways to make it as accessibility where it's possible, 'cause I happen to be you know, focused on both those areas. But what I do technologically is, you know, I started in accessibility before the Web existed, and the first device that I developed, or that I was involved in was an Australian invention by a guy called Norman Wilson in Queensland in 1982. I was in year 11, and like Ron McCallum mentioned in his TED Talk, it's very hard when you have to write an HSC essay on ancient history, to sit in front of a typewriter and type a sentence, then realise you have to have a wee break, come back and forget where you're up to, and have no idea what's going on. So I used to braille my assignments and then type them, or sometimes people would read the braille. So that person would read the braille, and then hand-write on top of it, but basically it was very hard for me to effectively communicate in print. So this device, you'd put a braille machine on top of it, it has these little pins, plungers underneath, and it would, it had electronics in it, it connected to a dot matrix printer, and you'd braille away and it would spit out the print, it was like a dream come true for me in year 11, but unfortunately it was designed by someone who didn't really know braille very well, or braille users, and it was riddled with user interface problems and issues, and it just so happened that I heard about the machine and that was really my entree into technology. I remember, like a month before, people saying to me, "Tim, what are you gonna do as a career?" and like, "I haven't got a clue, all I can tell you "is it won't be to do with computers, "because I'm really useless at Macs," and of course, you know, I've had a whole career in computers and technology, which just goes to show that sometimes affirmations, thank heavens, or thank the universe, don't work. So this device was, you know, and then I wrote the user manual because people basically had an engineer write the user guide, so I wrote the braille in print made easy, and that was when I guess I came to realise that in accessibility and an inclusive design, the real challenge is that you need people who understand technology, that's crucial, but they also need to understand people, and that's just sort of a rarity. We've got a room full of people who can do both those things, we know people and we know technology, and that's why we're in the professions that we're in, but back in those days, there were the engineers and there are the fuzzy psychologist-type people. My background is in cognitive psychology and linguistics in education, because I didn't know what I wanted to do as a career, and psychology's just that perfect, perfect thing to do when you don't know. But cognitive psychology's great because it was all about how do your process information and they were like, would be saying, "No let's look at the tachistoscope," and I'm thinking, "That's all boring, I would look at sound." So then I heard about binaural studies where you'd play a recording in one ear, and in the other ear you'd play something else, and which part of the thing is the brain listening to, and I developed some sort of salacious experiment in first year uni where I basically had, you know, in one ear names of different fruit, and then in the other ear some sort of short story of things a long time ago, and the idea was you had to push the button when you heard a fruit name, and there was something about when the word banana was heard, people would push the button faster because it had a sexual association. I really can't remember all the details and I haven't talked about that for 30 years, but I was real interested in how we process information. How do we actually deal with sound, and there's a lot more research on how we do visual stuff than you know, we do with sound, so I just love that sound domain. Later on I worked on a project where there was an Australian, another Australian invention of a talking typewriter, and they got me to come in to work out what the typewriter should say when you push different buttons. It was 1985, so it was pretty early and there wasn't really, it didn't speak words, but it would spell the line out to you. But it was still better than nothing and at least you could work out where you were up to, and yeah, literally how I got into all that stuff. And ever since then you know, the word came along and we didn't have any Web standards, there were no guidelines or anything, and we were trying to look at me and go, "Uh look, let's just stay with Gopher "and not worry about the Web, because Gopher's "a bit more structured and a bit more easy," and then we had this Links browser and so on and so forth, and then of course GUIs turned up, and like, blind people around the world are like, "Oh my God, Windows is here and we can't use it," and I don't think until Windows 3.1 came out, I don't think there was much access. The Macintosh ironically had very early access to its GUI, there was a company called Berkeley Systems that had a thing called OutSpoken. So that was a very interesting product, and this device here, this was like what a synthesiser was like, it was a big box, so if you had a portable computer, you had to plug the big box onto the end of it in order to hear what the computer was saying, because the computer didn't have the CPU to generate speech, and what would therefore happen was that, you know, you had all these cables, and it was all a biggy, so but on the Mac, the whole thing was the Mac users would go, "Oh well, "I can just plug headphones into my Mac, "and it will actually read what's going on to me," and it's like, yeah, now we just take that for granted. Plug headphones into an iPhone 6 or 6+, or get your AirPods out if you've got an iPhone 7. While I think of it, this is an interesting wearable device, these are bone conduction headphones, 'cause we're gonna talk about augmented reality in a moment, and what these do is they make vibrations through your temporal bones, and your ears are still left open. Now if we think about augmented reality rather than virtual reality, it's about layering on top of, and augmenting what's going on around you, it's non-isolation. So say you're a blind person and you want to be guided to find a shop, so you want some sort of talking GPS. If you've got things covering your ears, you're probably gonna get hit by a bus or something tragic like that, and it's not a very good situation. So these, they're marketed to runners, they're called AfterShokz, make sure you don't buy the old models, you gotta buy the Titaniums, the others are really uncomfortable. And they're Bluetooth, they've got wired ones as well, but-- - [Man] Ding. - Yeah, sorry? - [Man] Ding. - Ding? Great, yes. And so the situation with these is that they allow you to hear what's going on. The AirPods also, just as an aside, I think Apple were very strategic in the way that they designed those, because what they allow you to do is to have one in, or both in, and still you're able to hear what's going on around you. So if I'm walking aside a guide with someone, or holding their arm, I will sometimes have one AirPod in this ear, and I'll be holding here, so I can communicate and converse with that person, and still, you know, check, you know, what people are tweeting. Now I have to say, I'm not tweeting tonight, listening to my tweets tonight, I'm gonna take these off 'cause they're distracting me. So I don't think I've talked about anything that I was supposed to talk about. (all laughing) But look, at least we got a few giggles. So let me talk a little bit about augmented reality and virtual reality. This little computer, I just had it in brief AR and it said, "Arkansas and VR," and this is the problem with speech synthesis, it doesn't always know when something is a town abbreviation or whatever, and yeah, really it's a bit tricky. So basically my work is really looking at what hasn't been done before, for the New South Wales Electoral Commission, we developed a telephone-based voting system and you could vote above and below the line over the phone. That was my biggest challenging job in my life I think, as well as a Web, accessible Web service that let people vote in the New South Wales election, and you know, there's a lot involved when you're trying to create something to increase the range of people that can use it, and of course with voice we had to make sure that it wasn't John Howard and Pauline Hanson, and so I had a guy in the studio reading 400, 1,000, I don't know, 400, 500 candidate names and I was like the auditor, and I would be listening and he'd go da da da, and I'd go, "Just another take of "that, I think it was a bit more, you know, emphasised," and he'd go, and no, it was exactly the same. He's the voice of Lee on the GPS systems, and he's got an amazing capacity to create absolute pitch. He also did The Sunscreen Song, if you know that from many years ago. So we chose him because of his ability to sound like a robot, and then we chose Joey Moore who had an expressive way to say, "Welcome to "the New South Wales Electoral System, please enter," and she had to be friendly, 'cause she had to coerce people and encourage people that the system was easy to use, and he had to be very boring to sort of say, "Candidate one, press two." So yeah, there's a lot of issues with voice systems. Now, augmented reality and virtual reality. Now virtual reality has, there's two things, a, could I use a virtual reality system, or could someone with another disability use it, and in many cases they're so visual it's not gonna happen, and you know, when people are starting to design stuff. The reason we talk about design rather than just accessibility now is because it's a strategic process. If you're doing something new and innovative you need to think about ahead of time, "How is this gonna work, how can we include people?" and you just can't do it afterwards. I don't really do a lot of work testing if I'm doing development with people, I'm sitting in the room with the developers and they're doing a prototype, and I'm going, "Okay, here's what's happening here." My job is to educate and to mentor and share my understandings with people so that I can get out of there and go work for someone else, and do something new and interesting that hasn't been done before. That's really, you know, if it hasn't been done, they used to say, "Call Tim," it's very stressful though because you're really working without guidelines. You've heard about the WCAG guidelines, and there is a version 2.1 in public comment draught, it has a bit more awareness of cognitive disabilities and making the language more comprehensible, mobile devices. But look it's surprising, you could have an organisation that has a true policy around accessibility that has it right through their DNA, and then they'll develop an app, a new app that is client-facing, that is the main interface to the organisation. I'm being very non-specific here for confidentiality reasons, but I worked for one organisation a year or two ago who developed an app, and they were told, "Look, if we develop it as a single-page Web app "and put it into an iPhone app and an Android app, "it'll cost you half as much to develop," and they did that, and not a single person on the whole development team for a year, apparently asked about, "Well what about accessibility, "have we tested it?" And it was launched, it's like, "This doesn't work," and then we found that when we went, okay, I said, "Well look, we need to look at ARIA." This is an Accessible Rich Internet Applications Protocol specification from the WCAG that allows you to make smart, you know, single-page applications that are like apps work with voice output, but the underlying Java libraries and JavaScript libraries they were using weren't accessibility-friendly, and it was extraordinarily expensive, and extraordinarily painful for that organisation to go back and redesign a big part of that product, and it took eight months to really get a version that was going to, in any way work. Now I've actually gone very close to the end of my time, I've got 35 minutes, oh that's right, you're very generous, good. So when it comes to augmented reality and virtual reality, just coming back to that topic, there's two aspects, one is could a person with a disability participate in that process, and two is, could that process allow a person with some kind of disability to experience something that in real life isn't possible? So there are two different angles. The first is particularly important though, because say that you go for a job, and the employee goes, "Great, we're gonna "basically put you through our training programme. "It's a virtual reality system, you basically put "these goggles on, and here we go," and suddenly you can't learn the systems, you can't learn the technology, and you're really not gonna be job-ready and able to do that job. So these sort of things, you know, can be really, really problematic. (rapid robotic speaking) Turning you off. (laughing) I am always telling my computers to shut up, 'cause they keep your brain. So with augmented reality, there's lots of examples of augmented reality that are really relevant to blind people, one is audio description. So say you're on audio watching Netflix, and I'm watching a show with my partner, we turn on the audio description that Netflix provides, and it's like, "He walks into the room. "The floor and walls are covered with blood," and (laughing), and then it's like, "Oh my God!" And he's like, and then it's like five seconds later, he's like here, "He picks up the gun," and you hear bang, and you hear, "He pulls the trigger." It's like, hello? (all laughing) And this of course, ladies and gentlemen, this is why there's very little audio described porn, because when people get excited, it's gonna be a bit too late when you tell them what's happened. So audio description tries not to talk over dialogue or over significant sounds, but really what audio description should be is then there's a version of a, there's an iPhone app that Disney developed that you can take into a theatre, and you run the app and you put your headphones on, the ones I showed you, or your AirPorts or whatever, and as the movie plays it hears it, and it describes what's going on into your ears but not everyone else's as it's going, so you can adjust the volume. So Netflix have, you know, they sort of construct their videos channel by channel, so they have an audio description track so I'm anticipating that the Netflix app on the phone at some point will allow me to privately listen to the audio description, rather than the whole family having to listen to, sometimes terrible narration, sometimes fantastic narration of what's going on. Or Alan, my partner gets sort of frustrated at times, he goes, "Oh, oh, so he's gonna strangle her is he? "Okay, I didn't know that, because it hasn't happened yet." (all laughing) Or he goes, "Wow, I hadn't noticed "that particular design, that's like, really subtle, gosh." So you know, that's an example of augmented reality and also, you know, walking along the street and being told what's going on. I would like, you know, because I've often said that you know, I'm pretty good with voices, I'm not too good with names, about all I can say is that I've honestly never forgotten a face, so when it comes to walking down the street, I would love an app that says, "Hey, this is so-and-so," because it's like, "Hey, guess who?" It's like, "Um, I'm blind, and I've got ears, "but you know, I listen to 1,000 voices a day, "how am I supposed to know?" So, well my name's Tim Noonan as you know, @TimNoonan on Twitter. I love voice, sound technology, and in particular when they're brought together. You, yeah, the reason I told you that story about the organisation that hadn't planned accessibility is because every single one of us could have been in the meetings in the room in the design team for that organisation, and someone should have said, "Have we thought about accessibility here? "Have we thought about users?" and it would have saved them, I wouldn't like to say how much money, and loss of face it cost that organisation, and you know what? It left, it wasn't an easy project to work on because they weren't actually easy solutions. It's a bit like, "We built this building, "and now we wanna put an elevator in it." Yes, it's gonna be messy, and that's what happens if you leave accessibility to the end. Thank you very much, I think my website's up there. It's been a pleasure sharing some ideas with you, I can't imagine all the things that I've forgotten, and I'm open for a couple of questions, thank you! (audience applauding) - [Joe] Yes, thank you Tim. So I think this is the first time we've been invited to watch porn at work, for research. - You don't have to watch, you just have to listen-- (talking drowned out by audience laughter) - [Man] We just might have to put a Bitly address on that one. Any questions, I'm sure there'll be a few. No one's got questions? When I invited Tim a few years ago to speak at some colleagues at work, I said, "Tim, can you come around, "put some lunch on, we'll talk for about an hour," I think we were there two and a 1/2 hours later and there were still a few hundred stories still in his back pocket then. - But do you know what, also, about a year and a half later, you guys got a contract to work with ABC, when you were working with those guys, or you might not have been there then, on an accessibility project, and I think I helped you with that, so how fantastic is that? - [Joe] Good continuation. Yes? Okay, the hands are showing up now. I'm just gonna speak to the room so that Tim knows where the question is coming from. - [Kevin] Hey Tim, my name's Kevin, and that was such an amazing presentation, thank you so much. - Thank you. - [Kevin] This isn't really a question, it's more an observation, but I reckon that you'd be the most amazing validator of any content, I mean, like some of the things that you described today in terms of process and the input that you put into these. I think you were talking about the process that you used to validate, like the election process, when you described that, I thought, "Why can't we all "do it Tim's way, and not queue up for four hours?" (audience laughing) - Well when we did that online project, interestingly if you were 20 kilometres from a polling booth or if you were travelling in to stay, then you could access the Internet voting, so there were an extraordinary number of people who actually signed up, and just happened to be travelling that weekend because they wanted to be able to vote online, and I should say there was no counting, it was just collection of the votes. So there's a lot of debate about vote counting systems, but every vote was printed out and then human-counted. But yes, the people did, like you, wish they could've done it, and they did. - [Joe] Got another one over on this side too. - [Man] Hey Tim, thanks for your talk. I'm interested in accessible maps, so you mentioned the apps, I think for runners, and helping them around get from A to B. Have you come across any interesting applications that give you a, sort of broader, special context? Beyond just (muffled by microphone). - Yeah, so GPS obviously is coordinates based, and I mean we can link into those coordinates, points of interest that we know about, you know, particular shops, or streets or whatever, but GPS can really, you know, with not enough accuracy, but with reasonable accuracy tell where you are. So there are a few apps for, there was an app that was developed, but I think it never went live because they were too worried about being sued, but it was called Breadcrumbs, and the idea was you could walk in a sort of a random pattern, you know, cross fields and all that sort of stuff, and it would track the way you walked, so you could then repeat that. So for example say you wanted to, you went out at a resort, a beach resort, then you, some of them might say, "Hey, "can you sort of take me for a wander around "the key things," you'd go along, this thing would record where you went, and then you could get to those points later on, a bit like Find My Home, find my way home. But then I look at the area of mapping is, if you want, there's a company called Sendero, which I think is pathway in Spanish, so Sendero, the founder of Sendero whose name I've forgotten now, I can remember that he's a good friend of Stevie Wonder's, and he was at a Stevie Wonder concert and his birthday was called out. Mike May his name is, he is the world authority on accessible mapping technologies, GPS, and of course there's a lot of stuff going on with indoor now, and beacons with accessibility, so that's about the roundabout answer of like, yes I can tell you a bit, but I don't really know enough. - [Man] Yeah there are a few working maps, but a step two I think did the one with beacons in the London underground. - That's right, they've done a trial-- - [Man] Ustwo, sorry, Ustwo. - Yeah, Wayfindr and now they did a trial in Sydney in the capital in Town Hall, and in Chatswood, and there's a company called BlindSquare and they've got an indoor mapping system, and they've done a huge installation in New Zealand where you walk up to shops and the shops tell you what they are, and it associates close and closer, turn left, right, you can get directions to different areas, so beacon technology's a bit slower to come together than we would've hoped, but there is a lot going on there. - [Joe] Going on this side of him. - [Man] Hi Tim, just a quick question though, just because when you talk about augmented reality and how have you been thinking or dealing with the subjectivity of people without, with a disability will be able to access it? 'Cause that's kind of a difficult thing that you do, don't you? So what are some tips, I guess. - So ways of making it more accessible? - [Man] Correct. - Well I think one of the aspects has to be that if you're using semantic data, rather than just imagery and you've got semantic information, what it is that you're showing someone, then you could potentially render that in sound. You know, like if you're walking through a city and maybe overlaid on that is, you know, the way the city used to look like, that's, you know, you could have an audio description track that could be activated that would give you a dialogue as you're going, you know, there's these virtual tours of museums and so on now that are starting to do that. The trouble with this stuff is that it becomes very, very case-specific, and you know, the way that I tend to deal with these things is I sort of immerse myself, because if there's another model, what you've gotta do is immerse yourself, overwhelm yourself with all the variables, all the constraints, and all the possibilities and the barriers, and just sort of see what starts to turn up, and that's what I started doing and before rather than after, and going, "Well what are the objectives of "the augmented reality environment? "What are you trying to achieve?" at that stage. And you know, look, we talk about innovation, innovation's a scary word for accessibility, because it means doing things ways that haven't been done before. What we, you know, what I encourage people to do and what I do is bring innovative thinking to accessibility and to ways of making information and technology accessible. Not a complete answer, but you know, basically redundancy, duplication and crossed modalities, they're the keys to inclusive design, giving people more than one way to access the information, but having them linked together so that they have equivalency. - [Joe] On that note, I think that's actually a very good point to end on, in vastidity and innovation, because one of the questions we always ask ourselves when we're conducting an experience activity, is, "How might we?" And so maybe what we're doing tonight is asking you to think how might you apply a different thinking into projects that you have now and over the horizon. Tim, thank you very much-- - Thank you Joe. (all applauding) 