 so my name is John visa desu I'm a product manager at Google and I work a lot on how enterprise customers connect to our cloud infrastructure and today's talk is going to be exactly about that well we're gonna be covering is a little bit about and you're gonna hear this throughout the whole week I'm gonna talk a little bit about the Google infrastructure what we how you connect to us today and then talk a little bit about how you connect to us tomorrow or soon talk a little bit about architectures deployment architectures and how you can use our cloud networking to build enterprise networks that extend out to the cloud something about how we monitor these systems what we do around monitoring some discussion about how you can get better application performance when you come to cloud and finally a little bit about the pricing of all this stuff so infrastructure and you know if you go to about half of the sessions of this conference you're gonna see a picture something like this and what this is trying to point out is where are all the cloud data centers when you build an enterprise network you have cloud data centers as well and all right I should say you have data centers this is saying we're Google's data centers are and the ones in green are showing the ones that are available today and all the ones in blue are data centers that are in the process of being built out the numbers tell you how many zones each one of those data centers has and as you can see what we're trying to do is cover the globe with data centers that are close to customers because millisecond closeness means application performance so it's really important to get that level of connectivity the other thing that we have and if I take away all the cloud data centers what pops out is all these little lines this is Google's backbone this is what we have been spending years and years on building predominantly it was to service the applications that Google's known for you know search and YouTube and Gmail and all those what we're doing with our cloud networking infrastructure is giving you access to all of this now you don't see it because it's hidden under the covers but your application data runs over this infrastructure and it's an infrastructure that Google continues to build on so this is what it looks like today if you see this little there's this thing that sits 2018 that's a fiber cable that we're dropping from somewhere important in the Oregon area to somewhere in Japan and we're gonna drop in you know a little over a hundred terabytes of infrastructure there to give you more capacity to originally just to give Google more capacity but in short it's also to give our customers more capacity as you grow so you know we're expanding you know didn't summary Google cloud is an expanding platform it's expanding to cover give you global footprint a footprint that's close to your customers that gives you high availability local availability the ability to take VMs and get them closer to your customers and continue to drive the scale that you guys are driving us to build so today there are a number of ways to connect to this infrastructure the first one is something what we call direct peering this is where you have a private ASN or sorry a public ASN and you're connecting to our infrastructure at one of our points of presence I'll go into where our points of presence are in just a second this is public peering so when you do that you get all of Google's routing table and you expose your routing table to us another way to do that is through a carrier interconnect and that's where you go through you know carriers that you know and love and connect to us through their infrastructure to us and finally if you do if you can't do either one of these two or you have a place where you know you don't have a lot of capacity you don't need a lot of capacity you can connect to us using a VPN tunnel so I'll go into some detail about that as well so our cloud interconnects you know first of all when you go through this direct peering links you do get a dedicated link that means you have he said I wouldn't say enhance security but you're just going over a cross connect in a colocation facility so it's in a protected physically protected environment and you know from a performance standpoint you're getting carrier level SLA s you're getting locations in 70 locations in 33 countries so it's a place where you can get closer to us and get better performance out of it and finally a lot of customers use these methods for the last reason which is there's lower egress costs when you come and meet us versus when we have to carry your traffic to you and finally with those systems you get access to the whole set of Google properties so if you're an enterprise customer who's rolling out G suite and you want to have a close connection that doesn't go over the Internet these are great solutions for you unfortunately a lot of the customers what you really need is a extend your private network into cloud and today the way you do that is with our IPSec VPN solution so all right IPSec VPN solution is a virtualized solution that runs in the cloud it's a scale-out VPN so each tunnel starts at about 3 gigabits per second but you can scale that out based on deploying more infrastructure on top of that and what it does is it lets you take your RFC 1918 space your private address space and extend it to cloud and we do that with couple entities here there's a cloud router and a VPN gateway VPN gateway of quartz terminates your IPSec sessions and the cloud router gives you the BGP a reach ability of everything in your cloud I'm gonna make one comment on cloud router because I'm gonna use this throughout the rest of the presentation I want you guys to understand what does the cloud router do yes it is a BGP endpoint but that's all it is is the control plane of our routing infrastructure so when you terminate a BGP session on the cloud router what it does is it programs the routes into our Sdn infrastructure if you I don't know if you've ever read about something called Andromeda Andromeda is Google's Sdn network architecture there's some great presentations on it I'm not going to cover that here there is actually some presentations online that go into a lot of detail there but cloud router is not the typical you know juniper or cisco router that all the packets go through it it just programs the it's the control plane that programs the data plane so packets don't go through that so it doesn't we don't need a scale out router it's a scale out network so I just wanted to cover that before I use it in other contexts and you guys understand what the cloud router do when you scale out a VPN - if you need more than three gigabits per second you can use multiple tunnels and use ecmp across those tunnels to get greater capacity and we have customers doing that today to drive tens of gigs of traffic into their cloud infrastructure but that seems a little bit yesterday so what we're doing today is announcing the some products that are coming out later on this year actually later on this quarter that will allow you to extend that using more traditional networking architectures other than VPN so specifically we're announcing two products one is called private interconnect another was called partner interconnect both of these techniques allow you to extend your RFC 1918 address space from your premise to the cloud with the private interconnect this is where you meet us in one of our colocation facilities and you extend a cross connect from your routed infrastructure to our edge and with partner interconnect is where you go using a carrier and they can offer you a sub rate interface or actually a full 10 gig interface to our cloud infrastructure so private interconnect this is where an enterprise customer comes to Google and partner interconnect is where an enterprise customer goes to a carrier and then comes to Google again the goal here is to extend your network to our network using your private address space into Google's in your private address space in the Google cloud and it doesn't require the use of any VPN devices and uses standard routing as I'll go into in just a second so more pictorial your pictorial view with private interconnect there's the Google peering edge and there's your peering router and your connecting to us in a colocation facility that means your network is connecting to your compute instances in the cloud and with partner interconnect you're coming through a service provider from your router to their infrastructure into the Google cloud this as in the previous diagram these are all layer 2 connections and I'll talked about how you do the layer 3 extension in just a second there are carriers that offer you a service like in Metro II kind of a service where they offer you an Ethernet connection and you don't have to worry about the routing infrastructure so there are two methods that carriers offer one where you have to deal with DGP and another one where you don't have to deal with BGP so where do you connect to us shortly when we come out with the product you'll be able to connect us where all these green areas are and over the course of 2017 we'll be lighting up a lot of these areas in blue these are points of presence that Google has across the globe so what is a point of presence for instance in Chicago were actually in two locations in Chicago were in coresight and in Equinix in Frankfurt we're in four locations in Frankfurt so we say that you're we have a metro availability what we're doing is actually offer you in a number of connections in that metro and in each one of those connections we offer multiple no shared fate path paths to a Google infrastructure so if for instance if you come into course site in Chicago what you'll see is there are two locations that you can connect to us in Chicago in course site what we call zone 1 and zone 2 and there's no shared fate between the two of them so if you're building a highly reliable network you probably want to connect in zone 1 and zone 2 I'll go with the high availability and architectures for high availability later on in this slide deck so in general you know it doesn't matter where you connect to us in that Metro you're connecting into the Google infrastructure but in multiple sites in any one Metro so a little some comments ok you know this is all well and good but what do I have to do a couple things this is all single mode fiber we support LACP for link bonding so we offer 10 gig interfaces you can link bond across multiple 10 gig interfaces to go up from 10 gig up to 80 and even more if you go for more please come and talk to us because there's better ways of doing that you have to support a link local address so if you're doing the private solution you have to have a link local address on your router you have to have a private ASN that you've exchanged with us 802 1q VLAN tagging and that's how we'll do traffic separation I'll go into the details about traffic separation in just a bit and this is all using ipv4 link-local addresses so a little bit more detail so link local address between your router and the router you connect to is actually the cloud router so that we talked about earlier this is where your virtual connection ends up being is on your cloud router in your project so in that project you can then connect to VM instances and you're taking your private address space you're going over a layer to connection to the Google cloud infrastructure and to your project instances running in the Google cloud so if you're in multiple regions you'd have a cloud router in one region a cloud router in another region and then you'd have VLAN tags going between both of them so this shows one VLAN tag going to one region and another VLAN tag would go to another region all those instances can talk to each other over the Google cloud background that's all well and good but let's get better so we're announcing a feature to cloud router called global routing what global routing does is why should I you know if I use BGP I should be able to advertise region 2 out of region 1 so now I only have two Devoy to deploy one cloud router that means I only have to peer with Google in one location and now you have access to our whole infrastructure remember and this is something that maybe we don't drill into you guys enough is that the network that you have in a cloud project is a network that spans the globe and this is what I'm showing here is that even though you're connecting in one region you have connectivity to all the regions that you have projects your project has VMs in so that means you get access to that infrastructure I showed in earlier slides and if you're a multinational company that wants to for instance do web serving out to you know people all over the globe you only really need one connected one connection to us and that gives you access to infrastructure across across the globe now there are customers that have actually most customers have multiple projects so you might have a dev project you might have your release project you don't want the two networks to meet that would be a very bad thing it gives you that of cross-pollination of information and you know hackers can get through one network into the other and most customers want to keep their production network separate from your development network so what you do is you can have a project with a cloud router here and another project with a cloud Rider here there's VLAN tagging that separates the traffic between those two projects and on your side you would do brf's to separate the traffic on your enterprise network so this gives you one link into Google but multiple projects using that link and having traffic separation across those multiple projects the other thing actually there's a talk this afternoon at 4 o'clock that's gonna go into a lot of detail on EXPN which is our cross project networking solution also known as a shared VPC so what is a shared VPC in google's world what happens is that you have a host project and you have service projects you're networking for those service projects ends up in the host project so this is where you virtually connect to the Google cloud in that project this is where all your network resources are these are where your firewall policies can live and what that lets you do is have a separation of concerns between the folks that are worried about security and networking and those that are worried about development so this lets you share a resource like a network connect connection to multiple projects without those projects really needing to know about the physical infrastructure of building a network so you can monitor you can have one set of people monitoring your network infrastructure and another set of people doing all the production deployments of your VMs and all of that so you have that separation of concerns you have that separation of management responsibilities and that extends to the iam roles that are associated with these hosts and service projects again this afternoon there's going to be a presentation that goes into a lot more technical detail about a shared VPC and how you can use it in your projects so as I said we were gonna talk a little bit about high availability when you deploy network infrastructure anywhere you're going to want to do multiple links into our infrastructure one of the reasons is that we can't support an SLA for one single connection we do maintenance on all this infrastructure and when we do maintenance we would take your network out which is not a nice thing so what we suggest doing is in one colocation facility have multiple links that gives you the ability to have redundancy and we give you the benefit of having no shared fate between those two lengths but in addition to that and a lot of customers want to go this route is that you want to do more than that you want to have multiple connections in multiple regions and the reason you want to do that is because you want to deal with failover you know Metro level failover if your infrastructure in a Metro fails you can fail over to another metro area so now you have two routers well we've also done in these two routers is we've built the ability to use BGP the way it's meant to be used so you can have different route preferences in each one of those routers so let's say this facility is in London and this facilities of the Bay Area in San Francisco if you get a cable cut here in London your traffic off your network would end up in San Francisco because the BGP route preferences would tell you that's what you want to do you'd see that there was a disconnect connectivity to your London facility and you'd route your traffic to another facility so this gives you what we're doing is starting to extend the cloud router the network infrastructure to look more like a traditional enterprise network with the same level of redundancy the same level of failover the same way of doing all these things that you do in a you know large Multi multi region multi-country enterprise network oh one other one last thing on this also when you think about I used to do a lot of work with telcos and telcos are all about it has to be 5/9 and they're starting to think about 6/9 so with this kind of an infrastructure you start building that level of failover that level of SLA by multiplying the number of connections you have so with a description if you if you were to build a network that looks something like this you'd be able to build a network that had a five nines reliability a number of customers have come to us and said yeah you know that's private address space is really good but what I really want to do is I have some public address space and I would like to backup that public address space with infrastructure in the cloud and there's a way to do that in GCP the first thing you do is at the VM level you detach an IP address to each one of those VM so you're taking that public IP address and attaching it at the operating system level of the VM the second thing you do is you'd with another feature that's coming out shortly is you'd be able to change the route that is being advertised today the cloud router advertises in a very static way what routes are available we're adding a feature called flexible routing that allow you to specify which wraps you to advertise a reason you'd want to do this is for instance you may have a production network that you're not ready to go and expose to the whole world that you want to have it already so you want the routing infrastructure ready you'll be able to flip a bit on that network and then it'll start to be advertised off the cloud router so a way to predictably release routes out to your on-premise infrastructure so that's a feature that's coming out so um in cloud router you'd add the prefixes for those public IPs that you want to advertise over bgp then you'd add a static route from the private IP because these VM instances will have a Google private IP and you need to know how to get the reverse traffic back so you'd rather put a static route taking that private IP to the public IP of the VM sorry from the public IP to the private IP of the VM and finally you'd set up your router so that advertises those prefixes to the rest of the world and that that is a method for getting public IP s into the Google infrastructure that are your own public eyepiece because today the only way you can use the public IP is if you take something out of our range so for monitoring so now we've given you a link to our infrastructure and you've decided to provision 10-gig and you have no idea how much of that link you're using so they'll be mum this is a mock-up of the user interface that you'd see in the cloud console and we'll do things like link utilization drops items like that it will also give you you know suggest that you get a ping endpoints so you can measure round-trip times and monitor that as well and all of these statistics will be available in stock driver so you can actually extract them and put them into your own console so you don't have to go to the Google console to get all this data you can actually get it out and use it on your own another thing we're changing as you know we've we've done some fundamental changes in how you interconnect to the Google infrastructure and doing fundamental changes means you probably fundamentally want to change the way we describe that in the cloud console so today we're interconnected as you see there's something called VPN that's going to change so the interconnect and that will subsume VPN and private and partner interconnect so you'd have one place to go in our user interface to control those interconnect methods into the cloud so now you've moved your application to the cloud you've connected to us in a variety of areas it's still different it's not your data center right it's not the rack of machines that's down the hall and what we found is that customers have a problem their applications have problems with this because we've changed fundamentally we've changed some of the network some of the basic networking parameters that applications are used to and what that big change we've done is we've changed the latency between your front and the application and the back end whether it be a database server whether it be some other REST API that that application is using and those changes mean that you may want to think about changing the way the application behaves so I'm going to go into some details about how you can change the application to make sure that you're getting the most of our network and it really has to do about something called the bandwidth delay product and let me go into a little bit about why what this is so if you look at typical cloud latencies and I'm throwing showing you three Google regions that we have and the average latency teach one of those regions from our pop locations so if you have an instance running in our US central region and you connect to us at the closest place you can connect to that US central region you're still about 10 milliseconds away from those VMs in u.s. East it's about 10 to 25 milliseconds and finally in Europe because it's a smaller place it's about five to seven milliseconds that's different and the difference is profound because what you'll see and now I'm gonna go into a little bit of details about how TCP works if you think about it what TCP does is it sends a bunch of data down the pipe right and it sends a Windows worth of data down the pipe when you're in the same data center your application and the backend are running in the same data center the time it takes to send that is you know fairly quick right well it's the time to take regardless of where you're at the time it takes the Senate is still about the same what's very different is how long it takes to acknowledge that data because your data goes down the pipe has to get to its destination before an acknowledgement can come back and on a network that is less than a millisecond in delay this time is very short but as you get to even like even short delays like seven milliseconds if you use the default settings in a TCP kernel you're gonna get really bad performance and I get a lot of calls from customers saying you know I connected to you I have these big pipes to you and I still get really lousy performance why and they're forgetting one thing is I need to change the TCP DP behavior to take advantage of the well not take advantage to remediate the issues you have with this milliseconds of latency that you've added to your application and the way you do that is by increasing the advertised window in your TCP session so rather than advertising in the default window you want to extend that window so that you can send more data to the remote site now this doesn't help applications that you know especially HTTP applications that are doing small transactions all the time but it really affects applications that are trying to move lots of data and that's where more often than not you complain about slowness you're doing an upload into GC a GCS cloud bucket you're you know taking you know the movie you just finished rendering and downloading it doing those kinds of things can take a long time if you don't take into account the did light bandwidth product and the way to do that is by increasing the window size and when you increase the window size what happens is that you send more data and you acknowledge more data at the same time meaning you can keep the pipe full so if you're getting 10 gigabit pipeline pipes to us you really want to keep the 10 gigabits full especially if you're doing these large data transfers so just some notes on one last note on this subject is that many of the TCP Colonels already set up this way and the reason I bring this up is because if you do see that it's a good way to go check this and if you you know do a Wikipedia search on delay bandwidth product there's tons of articles that go into how you'd go and look at these features and how you calculate all these things so let's talk briefly about pricing of the solution because everyone wants to know how much they're gonna spend right so with our public item right now it's when you're doing direct peering with us we don't charge you to direct pair with us and we give you some benefits on the cost of egress so you get a benefit in price on the cost of egress with VPN you're paying for the VPN gateway and that's roughly about five dollars a month for every three roughly three gigabits of large packet data with the new solution that we're coming up with private interconnect it's a twenty five hundred dollar charge for the port that you get we give you and there's egress costs on top of that with a partner connection there's a lot of charges and depending on how you connect with a partner we start at the partner access pricing so whatever they charge you to connect to us and then there's a sliding scale depending on how much data you're pumping into Google on our end as well so this gives you a sense of what the pricing is of those solutions so I'm almost finished so how do you learn more you know if you're really interested in this please talk to your sales folks whoever your sales contact is at Google so that they can help you get into our team possibly come part of the Alpha and be aware of when the beta of this solution comes out the other area where you can help a lot is somewhere this there she is there's one of my colleagues in an orange t-shirt back there and they're running a UX lab down on the first floor so if you're interested in helping us help you with a great user interface they're more than happy and more than willing to listen to you guys and you know get you involved in studies about how we do UX development at Google so that we can give you great user interfaces and getting great solutions back and finally there are a number of sessions that cover a number of aspects of networking unfortunately one of them is actually happening right now that's two doors down but I want to bring this up all these sessions are recorded so if you miss a session here you'll be able to see at a later time so I want to highlight some of these sessions that are happening throughout the course of the next three days and I finally I end up with one on Friday where were we talking about third party solutions to networking today check point for instance on announced there v SEC v SEC firewall so next-generation firewalls for for GCP we'll be talking about that and we'll be talking about other SSL VPN about load balancers and other solutions for enterprise networking in the cloud you 