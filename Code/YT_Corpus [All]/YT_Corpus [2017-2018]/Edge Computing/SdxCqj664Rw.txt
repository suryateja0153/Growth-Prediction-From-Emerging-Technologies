 I it's my pleasure to introduce Justin Chang justin is currently a PhD candidate in computer science at Stanford University Justin applies behavioral theory from social science to the analysis and design of social systems Justin's work on cascading behaviors and antisocial behaviors in social networks as well as crowd systems have been published at premier venues in ACI as well as data science and have also received several best paper nominations what's impressive about Justin is that he crosses data science with ATI and vice versa and asks important questions at that intersection such as how can bethe science inform better tools yti and how can humans human centered design can help produce new insights for data science justin's research have also received several popular press including the new york times and thanks to justin's analyses several popular websites have changed the way they fight antisocial behaviors we're super excited to hear his work in person so please welcome Justin Chang thank you for the introduction so hi everyone today I'm going to be talking about antisocial computing so social media has brought us closer together it provides social support can improve our mood in useful social good can think about how it's been used to self-organize like the Arab Spring but however in recent years what's becoming clear is that there is a dark side to social media and social computing so the strolling online harassment and misinformation that's increasingly prevalent in many online platforms today and even before the recent u.s. presidential elections maybe already thinking about what's going wrong with social media right why are there so many trolls and online discussions why do I sometimes feel unsafe when posting things online and why is there so much misinformation and it isn't just a feeling anti-social behavior is commonplace so there was a recent Pew Internet survey they kind of showed that 2:105 users online have been harassed in one way or another being call offensive names are being sexually harassed and you know that it's companies becoming a problem when many popular websites are so overrun with these trolls that they've just decided to completely turn off the ability for anyone to comment so the social media getting out of hand and an online community is getting worse over time and are we actually witnessing an epidemic of bad behavior so ultimately we want to create better healthier online communities to combat and social behavior and there are several ways to do this to create better guidelines fräulein conduct design better interventions or develop better systems but to do all these things first and foremost we need to understand what's going on right so what do you really know about any social behavior so prior work has characterized trolls as a small vocal minority and that antisocial behaviors do to sociopaths so in research using primarily qualitative methods including surveys and interviews trolls likely come across as being very different from most of us for example taking immense pleasure in others misfortune other world cases of trolls as having unique cycle psychological profiles being more Machiavellian being more sadistic but rather than being an eight and a domain of sociopaths my work tries to show the antisocial behavior trolling can be situational and that ordinary people can be driven control so given this previous view on trolling we might have concluded that simply removing the bad actors would make all of our problems go away but if trolling is situational then what we need is a different perspective and a different set of questions to understand what's going on and what we can do about it so here are three questions I'm going to ask to do and try to answer in my talk as well so first we look at why trolling occurs at all the causes of antisocial behavior or how anyone might become a troll and next we'll look at how antisocial behavior spreads across the network and how it might worsen over time and last we'll take a bird's eye view of this kind of behavior in general and spreading behavior more generally and look at Cascades and if they can be predicted and so how I do this is by complimenting data mining with crowdsourcing so I use data mining to find generalizable insights and combine this with crowdsourcing which enables all experimentation that can then establish causal links now while this talk focuses on antisocial computing today my work as a whole so involves other aspects of both data mining and crowdsourcing and more broadly my work seeks to identify principles of human behavior and large social systems that we use today which we can then draw on to design and build better ones so do this I use data mining and machine learning study large amounts of data and formulate predictions network size to understand the structure of these interactions and then HCI to design experiment and build social systems and to this end as well my work makes contributions to computational social science by using these techniques to answer questions and human behavior at scale so but all of the show and so I started the causes of anti-social behavior and ask if anyone can become a troll so before I continue as a heads up some of the examples in this talk are going to contain strong offensive language so do be warned so in this work as well we study antisocial behavior in the context of public commenting platforms such as on CNN right so here's an article from CNN from a few years back that talks about how women perceive themselves online and here are some of the actual comments on the article so here's one common which is pretty insensitive and here the replies to that comment so there's some name-calling there's some sarcasm and it's mostly not very constructive right so to understand these instances of antisocial behavior like what I just showed you collaboration of disgust we analyzed a data set consisting of large commenting communities and this DSi comprised over a terabyte of complete data over a year of activity from over 76 million users making a total of 470 million posts and 831 million votes but before we can analyze trolling we also need a working definition of what trolling actually is so now there are very different definitions that have come from different parts of the literature on trolling and antisocial behavior so could it be engaging an angrily marked online behavior could it be not following the rules could it be taking pleasure in upsetting others or something as specific as disrupting a group while staying undercover so all these kind of makes sense and some are broader some are more specific some encode intent and others do not and maybe your preconceptions and your experiences of trolls in real life may speak to even other sorts of definitions as well when this work what we are interested in lies close to the bad behavior in general so we're going to take inspiration from some of these broader definitions and defined trolling as behavior that occurs outside of community norms none of this definition regardless of intent trolling happens as long people are seem to behave as trolls and why this is nice is that the Community Guidelines for many websites are pretty similar so there's no name-calling no personal attacks profanity of offensive material and so on and also by looking at how moderators moderate these communities using these guidelines we can then have signals to automatically identify who's trolling and who's not so while these trolls exist we also don't really know very much about who's responsible for this bad behavior and as prior work as well as the these headlines suggest the media kind of portrays trolls as this group of misfits that aren't hopefully not any of one of us in this room right now but is this really the case and what kind of looking at data tell us so for instance if trolling is innate our trolls is trolling more often than not so here's a plot showing a partial distribution of users who are banned from CNN which you use as a proxy for trolls you might imagine that if trolls are inherently bad that they have most if not all their posts deleted by moderators as shown here so for example about like close to 40% of users have all their posts deleted on CNN but well many of these suppose the trolls do have all their posts deleted a sizable number also have a much smaller proportion of opposed to that as well so in other words the distribution of trolls all the people were banned is bimodal and could these two peaks correspond to two different types of anti-social behavior that goes on so maybe the people who are writing back content all the time of these lifelong regular trolls well those who only had a smaller fraction of posts leader are just having a bad day and more importantly because we are just looking at ban users as well this is going to underestimate the population of situational trolls and overall because of this observation we start to reconsider our assumptions that trolls are just a vocal minority so rather than trolling being mostly innate what if antisocial behavior was actually more situational but of course how do you go about even showing this so we can make observations of data but it's hard to demonstrate exactly what causes trolling and if you did run an experiment the issue might be that it won't generalize so what we did was to combine both to do in all I experiments simulating a discussion and then carry on an observational study of an actual discussion community and while this experiment helps us establish causality I'll be honest is that says demonstrate replicability and generalizability so I'm going to claim that anyone can become control and using evidence from experiments in data I'm going to show you how it's possible to induce people control I'm going to do so by first drawing on theories from social psychology the first of which is the broken windows theory which suggests that norms can strongly signal whether further bad behavior happens for instance that broken windows signal that crime was acceptable in a neighborhood the second theory concerns how unpleasant stimuli aversives increased aggression so studies showed how one study showed how exposure to secondhand smoke increase a person's aggression towards other unrelated people but again still a lot of this prior work was conducted several decades ago the absence of 'allah interactions and on the different circumstances so could this actually translate into trolling online the first thing we did was conduct experiment of Mechanical Turk simulating a discussion platform and the general structure of this experiment was as follows so we had participants take a quiz and we had them participating allowing online discussion so evading the study conditions we then ran many of these identical discussions in parallel to observe how participants behavior changed so in this experiment you used a two-by-two between-subjects vectorial design where we modified difficulty of the quiz and also the initial discussion context so drawing on theories of aggression we varied the difficulty of the quiz to manipulate participants mood and drawing on the broken windows theory we varied by the discussion context was good or bad so what does this quiz look like to start so the quiz that we asked participants to take part in looked like this and it had 15 questions and so the version in a positive mood condition was calibrated to be pretty easy as a shown here so participants with a high scores and maybe feel good about themselves the other version of the quiz was substantially more difficult and designed so that participants would score much worse and in this version he also told users that needed Paulina tests anyway regardless of how they actually performed and lastly participants also had five minutes to complete all 15 questions so that was the quiz so after completing the quiz we then had participants take part in the discussion about either an upcoming US presidential elections and for some contexts again this experiment is done during the 2016 Democratic primaries where people deciding whether to vote for Hillary Clinton or Bernie Sanders as the Democratic Party's presidential candidate and so in the positive discussion context condition we see that these discussions have initially more neutral constructive comments such as these and a negative discussion context condition these see comments were more negative and again I didn't need to come of any of these examples so what happens so first as a couple manipulation tracks who first of all mood using a post quiz valued at mood questionnaire if other people were in a much worse mood after the hard quiz and the easy quiz right and people also got much worse scores on a difficult quiz as well and the same time it's a check for discussion context we found that these initial seat comments in the negative discussion context condition were perceived worse as well the only 36% of voted and compared to those in the positive context condition which were 90% of voted so now on to main results so how much tolling was there in each condition so here we had two expert raters label posters trolling or not blind to condition and usually stands at Community Guidelines such as from cnn.com and we then measure what proportion of posts made in each condition with Tropos so if participants were in a positive mood in context condition or they saw the easy quiz and discussion context without any initial trolling the rate of trolling was lowest at 35% and so now this number might actually see a bit high but also remember that participants were commenting a relatively controversial topic at a time so people got the difficult quiz our show intro post previously the really increases in both cases by a similar amount and if people got both the difficult quiz and were shown troll posts does that almost twice the incidence of trolling so we tested the significance of these results using a mixed effects with just a regression model and find out both main effects are significant and that there are no significant interaction effects if you can and we can also analyze our data a different way and use Luke to measure the proportion negative emotion words as a proxy for trolling behavior and here we also find similar trends with a proportion of negative emotion words almost tripling in the worst condition compared to the base positive condition and it gives you a sense of what participants actually wrote here are two examples so here's one comment from the good condition so in participant in the easy quiz and we're showing neutral comments and like this one a majority of them are pretty reasonable on the other hand if people were in a bad mood and/or had seen prior troll posts they wrote things that were closer to this so another yeah right so so we kind of had these two expert raters rate pulse test rolling or not and we come the proportion of posts in each condition and how many of them are we were kind of rated labeled as troll troll post or non troppo and that's how we got any percentages so so in other words bad mood and negative discussion context increased trolling so now you might say that this is only a lab experiment so that these results may not necessarily hold up in the real world so what we did is also turn to analyzing a discussion community cnn.com to see we could try to replicate these findings so turning the data this one we found in relation in both mood and discussion context so we can't study mood directly from data we can't study its correlates so for example prior work which measured how mood tends to swing with the time of day India of week and far remark to be stable patterns and how negative effect on the amount of negative words used on Twitter changed with time so if you know observe similar trends with regards to indicators of trolling then there would also be highly suggestive of mood influencing trolling as well so here's a plot the time of day on the x-axis isn't a proportional flag post is a proxy for trolling behavior and why is this and what we find is that a post made in the morning is much more likely much less likely reflect for abuse than one made in the evening and what's nice about this is that it matches Golden Macy's findings about how negative effect changes at the time of day and similarly they are changes based on a work for you as well so post flying or trolling is highest at the beginning of the workweek and decreases as we near the weekend and we didn't observe this just for the proportion of black posts so across multiple indicators of trolling joining creases at a times of day and days a week where people are in worse moods you also find an anger can lead to more anger so just as we found that doing poorly on a quiz affected later commenting and discussion negative mood also can spill over prior discussions in two subsequent unrelated ones so show us we look at a discussion with at least one flat post and select a user who was flat and user who was in that random and so that we aren't selecting users who already trolls we ensure that both users never had any of their pros prior polls flagged or deleted in the past so now each user goes on to post in a separate discussion and then compare the line you could have that future post being flagged as well so he finds that user who was previously flat it was also more likely to be flagging later the discussion and in fact if you compare users who troll in previous discussions if those who did not those who did were actually twice as likely to troll in future unrelated discussions as well so turning to discussion context go so directly replicated experimental findings here and so an initial post in the discussion strongly affects the subsequent likelihood of trolling so here you compare two top level discussions of the same article where one begins to a flag post and one does not and we find that a discussion here that begins to have like post is more likely to have subsequent post flagged as well and here to control for confounds we also externally opie as well as users flagged or deleted in the past - and in fact here again initial troll post increases the rate of trolling and subsequent post by about 63% so there's context so having established factors relating to trolling and experiments in data as the next step carry predict rolling before it happens so here we examine imbalance the other set of 120,000 posts so I random guessing results in 50% accuracy and entry none they're just a regression classifying of following sets of features so mood discussion context and user features I can measure mood indirectly here through flight and previous discussions and also of diurnal changes and we could measure context by just looking at their prior posts in the same discussion the third is base can indicate a variable for every user and these features are us test the relative importance of two hypotheses but what actually is situational or if trolling is innate and here's what we found so if you just identify trolling by finding the supposed to trolls we do kind of okay getting about 0.66 AUC but we're looking at mood and context we can do a little better and so mood alone actually does worse but again this is expected because we can't we can never observe move directly but however discussions context outperforms using user specific features showing the extrinsic factors such as a discussions context are more important than these intrinsic uses specific factors in predicting trolling and if you combine both types of features we can do even better at predicting the subsequent post will be a troll post even without looking at the content of the posts so to summarize you might think about two factors that influence the user the troll so first their mood sets a baseline for how susceptible the outer trolling and when the user this participates in the discussion the post room by other users provides the sparkle impetus for to the user and directly results in them trolling or not and so the end of section because trolling is more situational than an eight that anyone can become a troll under the right or wrong circumstances yeah right yes that's the what's the goal of this study right so I guess like like speaking to that kind of like those factors can also all like kind of build into like this this kind of concept of mood right well that kind of participating prior discussions you kind of look we kind of like bundle that into the discussion of mood and how we can interact you observe this so looking at the prior interactions of people in the historical interactions as well and also I guess in this next section I'm going to look more into like kind of how the history of a user that can kind of like inform their future behavior so that's where we're going as well so so again like now we might come be thinking about like what we could do to mitigate bad behavior right so could voting be the answer to our problems and voting is present a lot of social media websites with one popular example being read and write the concept behind voting is simple but the content should get more votes and worse content should get more downloads right but this is actually work in practice so here's another claim so instead of voting helping to reduce bad behavior we claim that it exacerbates the problem because down voting can cause negative behavior to worsen and this is the next question we're going to ask right about how antisocial behavior might worsen over time and so in other words could this kind of behavior spiral so in this section we're going to look at the role voting has and how people got from bad to worse and as votes are essentially a way for users to evaluate each other's content we subsequently described him as evaluations right here on goal is to see how people might react to not only negative but positive evaluations so that we can compare the differences all right I think it's safe to continue okay okay so what do we mean by positive or negative evaluations all right so here's an actual comment they're really received in one of these articles they go five up votes and four downloads and and together these numbers can kind of help us quantify how positive or how negative and evaluation is so in this work we can't define a positive evaluated post there's one where the proportion of up votes was greater than some given threshold state a 75th percentile posts in terms of the proportion of up votes and similarly we define integrity evaluate at posts where this proportion of our votes is lower than some given threshold C at 25th percentile and so given that a user receive a positive on negative evaluation from other users in a community how will that specific use this behavior change afterwards right and so theory suggests that either could be possible right so operand conditioning on one hand says that feedback would guide authors towards better behavior right so the users would behave better after receiving either a down vote or an upvote right so novel means that you did well and should do more of that kind of behavior in the future and a dominant means that you didn't and should improve but on the other hand bad is also stronger than good right so bad impressions are quicker to form and resistant to this confirmation so people have also have a much better memory for when bad things happen than when good things happen so which of these is actually the stronger effect so answer this question we look specifically at for large commenting communities and the results also apply to all of them so say we have two users one positively evaluated and one negative thieve al you ate it and if you look at these two users posting histories one important question we're in asked is how either users post a ballot before that middle positive or negative evaluation but of course simply comparing two different users isn't going to work because who's to say that people who get downloaded are inherently worst commenters right and that a downloaded comment also might be inherently worse comment so that's why I got downloaded so how we solve this dilemma so what you do instead is conduct an observational study using what's called propensity score matching and the general idea here is that we want to match pairs of users that have been up to a point of comparison as similar as possible and then see what happens after we receive different treatments so in our case a positive or negative evaluation you know here again we have two users one positive evaluate and one negative evaluate it and of course these two users are not going to be writing the same thing but we want to ensure that they are so what you first do is kind of match these pairs of users on text quality which essentially turns to text into a comparable number but of course what on earth is text quality all right so here's how we compute it so what we did is train a machine learning classifier that used only by Gram text features of the post content to learn the proportion of upload speed that it received and you didn't define the predictor proportional upvotes as a text polity cue of the posts so that we can obtain cue just by looking at the text of the post but of course we also be concerned with bias in communing text quality from these votes since the proportional adverts is itself biased as well my whole theory doing well by using only Texas or features so as an additional check what we do is we crowdsource labels of whether post was good or bad using again standard Community Guidelines similar to our previous study for a subset of post but 10 crowd workers labeled each posts and from this we can obtain Q prime or true label of text quality and so now let's see how good Q is compared to P because we can correlate at Q prime in both P and Q and here's what we found so I find is that text quality is far more correlated with the crowds guest and with the actual proportion of voters and what is this saying is that text quality is a reasonable but again nonetheless noisy approximation of Q prime and then we can also observe that the error between Q and Q prime is distributed relatively randomly for different values of Q so there's no systemic bias and using Q X so we're back to the problem so the matched pairs of users we first ensure that these two posts have similar text quality they also control for the length of the of the posts or the number of words so we further made sure that these two users complete posting histories were similar before this positive negative evaluation for example ensuring that they had a similar number of posts as similar number of proportional up votes on those previous posts as well and after controlling for these factors we not matched to users that are basically indistinguishable from each other I'll match career it's and not only one got a positive evaluation and that the other got a negative evaluation and then as a quick aside for how we actually do this so we identify the covariance you run a control for tuning text quality which which I showed you how to computer yeah as well as number of prior posts and then we identify an outcome variable of interest which could be text quality of these posts afterwards and then the control for these covariates then the estimated propensity for which and users that you'd be assigned to each treatment condition and finally use these estimated scores to compute an optimal pair matching using an algorithm of choice so we recommend we also tried matching directly on course in the exact matching with empirically similar results so after controlling fall covariance how she measure how subsequent posts are evaluated so other than text quality as I mentioned earlier how might we measure changes in valuations so answer this question using to understand what an evaluation is made up off so essentially there are two components to an evaluation so when we evaluate something that someone wrote both these something the content and the someone your preconceptions that person both affect these evaluations right so the first component of these textual effects or text quality or how well people write so in other words was a post downloaded because it was badly written the second component relates to these community effects or how the community perceives that particular user so the person get downloaded regardless of what they posts because the community simply dislikes them and so the start let's first look at this first compute first component about text quality and ask if people write better or worse after a positive or negative evaluation having control for our covariance such as text value prior and so using your wilcoxon signed-rank test we find that post quality drops significantly after a negative evaluation but not after a positive one and this is true in all the communities that we studied and again this change kind of echoes findings in the across the positive negative asymmetry effect from social psychology and the intuition here is that you feel a lot worse after getting a negative evaluation then after a positive one and so people write worse after receiving a negative evaluation and then so let's also look at how the community perception changes after this positive and negative evaluation right so we looked at four different ones so there was CNN from before there was Breitbart there was i GN it's a gaming community and we also looked at a kpop forum as well so I think it would be interesting to extend these results to see if they can be applied to read it but again here because we had data about like exactly when votes were made and kind of when people kind of were posting content we had like this kind of this deep like granular already as opposed to reddit right right now you only have like the total number of votes so you don't know who voted on what that allows us to do this kind of analysis in the study oh yeah so after receiving a negative evaluation this community perception worsen so of course I also haven't showed you how to compute community bias so for each post no data set we have the number of votes number of downloads as well as tax quality all scale to be between 0 and 1 and comparing the actual evaluations we predict a text quality we then can see where the community was positively or negatively biased so what do we find so I find here is kind of a halo effect right so postmates after negative evaluation will perceive worse than we expect but not after a positive evaluation and so in other words here the community is predisposed to download you after you've been downloaded in the past regardless of what you're right so on CN n for example post an average of being evaluate about 30 percentage points worse than would be predicted by text polity and so the visualized is finding so far so say we have two posts by two different users one positively evaluate it and one negative evaluate it with the whites is signifying how positive the quality the quantity we allocated is so first we control for text quality of these two posts ensuring that they are the same and we also ensure that these two users who wrote these posts have similar posting histories and if you then look at what happens to text quality after this positive negative evaluation why first fine inset text quality drops after negative evaluation but not after a positive one and then if you're further compared a change in community bias or others perceptions of these posts if I had these this perception worsens after negative evaluation far beyond what texts what it's text quality indicates yeah right right right so something I also didn't talk about here is that we also looked at kind of like different amounts of posts after and also whether these posts were in the same thread or in different threads as well right and also again here we also find these kind of similar effects so in the same directions of course these defects are smaller if you go to a different discussion as well and definitely here again like kind of moot plays into these kinds of effects as well right so before we looked at like kind of how trolling just like trolling effects change things but here it's like also like controlling for like I guess how trollish something is and looking at what happens afterwards as well we can observe like these kinds of like effects that kind of like worse far beyond just like looking and seeing a troll post and that affecting your mood right and that the community also has an effect on like what happens to you afterwards as well right so that's actually why that green get it good thanks so so here in well I guess I'm also happy to talk more about this after us I'm just going to briefly skim over these results here and so in summary cares what happens to negatively evaluated users so not only do they kind of write worse posts after but at these posts also perceived worse by the community and there's also more bad news so you'd hope that maybe negative feet but I could suppress people from posting but in hey what but instead what happens is that people who are negative evaluate it I also more likely to post more frequently than those who have positive evaluated so if we look at people look at like how all these things differ is like in phonetic people who are negative evaluated they Imola and they are most likely to post people who are positively evaluated are less likely to post and people who are not evaluated at least likely to post again so in here they're kind of the the more of the story is to not feed the trolls right and of course this is even more bad news so there are also more likely to evaluate other users posts more negatively as well so they retaliate to being downloaded by downloading up by others as well so so if you update a model of trolling so mood as well as context true through much other people right can cause people to troll and beyond just writing downloading can also make things worse and that if he ever maybe here we can in this way kind of feedback in the system as people who get trolled or downvote also more likely to troll and down what others as well kind of resolving this negative spiral that's why this really means is that these trolls might have started out as ordinary users but that got downloaded and it starts to write worse and then be perceived worst and then never never really recovered after that and so given that antisocial behavior it can spread from person to person on a macro level can we also observe this downward spiral in these communities and so here's some food for thought about a slide on how the proportion of upvotes are given on CNN is decreasing over time and here in the x axis is time again and he backs this is a proportion of up boats or we know that is that the proportion of elbow starts are higher but then gradually decreases as time goes on and so if we kind of leave negative behavior unchecked in these it can have far-reaching effects in the long term and cause the community to worsen over time now obviously more work needs to be done here and there are a lot of different effects here the control for Volvo is interesting to see like kind of evidence about how microscopic interactions between the visuals can result in these translate into these macroscopic observations so at this point I've talked about antisocial behavior and how it might spread from person to person but I haven't talked about what's going on at a macro level right so how is bad behavior and information spreading on these networks and is that spread predictable and so popping up my level again now in this section I go to turn to explore and what happens when bad things cascade and here beyond bad behavior something that's also been getting a lot of attention recently is kind of bad content or more generally rumors all right so rumors don't only come in the form of fake news once in a while you see these kinds of image memes make the rounds and you might also wonder why these things keep appearing right and however like when we are starting these rumors something that we know this commonly is that the same rumor and the exact same rumors shared by different people can have wildly differing levels of popularity so here are two examples of two different people sharing the same rumor before but why did one get no reshares and one got 416 and what's worrying here is that the one on the right which got 400 system we share as many of its common kind of call it all to speak right but it's still not reassure so what's going on so rather than focusing on the rumor itself perhaps you can also learn something from understanding the underlying networks in which rumors misinformation and fake news propagate and so if you analyze the cascade that makes up the spread of a rumor we can also ask the broader question of whether these cascades are predictable and we're all findings can be then applied to rumor Cascades as well as the spread of other information cascades more generally and for some background as to what a cascade actually is here's a friendship network with edges connecting people and suppose that I share a rumor and then maybe two of my friends decided to share this rumor as well and two more people see this rumor shared my one of my friends and share themselves and as more and more people shadows rumor a cascade is form highlight it here and agree so but no we want to predict how a casket grows there's evidence that cascade prediction may be inherently difficult that Cascades may be unpredictable and there are several compelling reasons why this might be so first is that these large Cascades are very rare so shown here is the distribution of the size of reshare cascades on Facebook from 2013 and as you can see here number of cascades that actually gets large is vanishingly small so here less than 10% of Cascades reach 100 reshares or more and so because these large cascades are so rare it might be hard to predict when they come back and so past research also provides for evidence here so the famous music lab experiment participants using music ranking service to rate songs and the goal was to see which songs become most popular when the experiments repeated many times and what the study found was that it was hard to predict which songs would get popular in each instance of the experiment so that was increasing the strength of social influence increase inequality and unpredictability of success this suggests they might be difficult if not hopeless kind of predict whether something will become popular or if a cascade will grow large so another thing that also makes Cascades unpredictable is that they can die down and then resurface or recur after long periods of time but in contrast to prior work and perhaps on intuition what I want to show here is that cascades actually predictable so now we can we predict a cascades future size can predict how its structural change and how identical pieces of content can be differentiated and you can also predict if they will come back from the dead let's begin of the task of formulating the prediction problem of predicting their growth of a cascade and so given that we have seen some number of reshares how should we predict Cascades future growth so there's several possibilities here so maybe we could ask of a cascade we'll get a large number of reshares maybe we could try to use regression to kind of predict how long it's more be sure to get or you can try to you look only at the largest Cascades and compare them to the smallest ones but each of these have different problems so the issues in terms of the size of each class in terms of distribution of data in terms of how data was select in the first place so how am ia formulate a prediction task that doesn't suffer from these issues sorry a sister is a vacatio reach the median size and so by definition the median splits a dataset 50/50 so we have a balanced classification task and also you might ask what is the mean in f of K so perhaps more intuitively the question of whether casco reach the median size is also equivalently a question of whether it will double in size and this follows because the size of a cascade tends to follow a power law distribution we were exposed to and so the formally define a cascade growth prediction problem we asked given that a cascade has obtained K reshares will a double in size and what is good about this approach is that it results in the balanced prediction task and also allows us to track the growth of a cascade over time by varying K and so study cascading behavior we sampled was 70 million public photos from Facebook which resulted in 5 billion reshares and track these reshares on these photos for 28 days following the initial upload we looked at four different sets of features content features but they had overlay text whether they look like a meme or not user features friend count and gender for example structural features such as the proximity to the root note again because these cascades are basically directed acyclic graphs so can start to understand them that way and also temporal features for example how quickly these reshares are propagating and so what we find here is that we can predict cascade grow relatively well so again using a little just a regression classifier predictive a cascade that reached five reaches would double in size while finest that performance is robust independent of feature sets and even without the most particular set of features these temporal features we don't lose too much in performance so cascade Grove is predictable at least for five reshares but what if the number of you shows observed increases what happens to predictability as we observed more of a cascade right so how does prediction performance change as K the number of reshares increases so this is easier more difficult to predict whether caskey or 5e shares will then reach ten reshares or the Cascade of ten wishes will then reach twenty reshares and grow beyond that so in one hand maybe you have more data in the second tasks so that the second task is easier on the other hand the second one is also harder more complex question and that you have to predict further into the future so which of this is it so I find here is that as a cascade grows larger that it becomes easier to predict if it will double and again these results demonstrate about observing more of a cascade while predicting further than just a feature is easier than observing a cat-scan predicting while you'll do next again what's nice about this approach is that lasses continue to ask as a cascade continues to grow from small to large what is going to continue doubling in size but of course not only is cascade Grove predictable for instance we can also predict whether it will be structurally more or less viral and also if it will recur I'll come back in the future so this was the individual view of any social behavior from before this might be how the network view looks like where posts views comments and rumors are transmitted from person to person and also result in long range far-reaching cascades in the network and so to conclude this is an overall summary of what we found so if on that trolling behavior situational and that a person's mood and context of discussion can influence them control meaning that ordinary users can end up trolling under the right or wrong so the consensus we also found that trolling behavior can spread as well not only through these effects but also to negative evaluations and downloading and finally looking more globally and studying these Cascades about behavior misinformation look at the spread of rumors and off Cascades and find it contrary to prior belief that they are fundamentally unpredictable that this paragraph can be predicted so as I mentioned previously the pollen out portion up volts is decreasing over time is really interesting and one where more research is needed now these observations due to cascades or due to changing populations and more generally can we predict the trajectory of a community moving forward and when will community decline and how long will that take but of course given these results are presented about antisocial behavior and this talk about studying the demise of communities it might be easy to kind of feel cynicism and despair about the state of social media and social computing but of course now knowing the mechanisms of anti-social behavior something I also want to focus on is also on building better systems that deal with such behavior instead encourage pro-social ones so one important design implication of our results first was that downloading is relatively toxic and music communities so first one track prioritized doing is designs that exclude like downloading and of course because we also have a better understanding of how contexts these two people trolling here's an example of how a context aware discussion platform might use machine learning interventions encourage pro-social discourse so for example if we think that user might be angry in the heat of the moment maybe because they recently participated in heated discussion elsewhere you could kind of do they posts by that user for some time and beyond these they're also several promising directions with relation promoting pro-social discourse for example we may think about how we might encourage users to reflect or evaluate what others wrote in discussions or perhaps you've been drawing counseling techniques alternative alternatively you might think about how BOTS can mediate conversations by identifying when tempers are flying and guiding conversations and highlighting constructive contributions all you also could think about kind of how discussions might take place altogether is their optimal group size how might we instead facilitate small group discussions instead in also thinking more broadly what I hope it develop is a research program that kind of aims is about pro-social all our platforms more generally that not only interests trolling but also looks at polarization or misinformation and expanding on my existing work studying cascades on Facebook I hope to study them at web scale as they spread and evolve over different different communities and different demographics and finally I also developed hope to develop a line of work kind of characterizing how interactions differ on line and offline and tries to codify bias in terms of how we act online with how we act offline for example we might ask question about how much more or less positive do we present ourselves online versus in offline settings of course as these future directions kind of suggest that what I talked about today is kind of a small slice of the work that I've done and am interested in doing in this kind of space and data mining and crowdsourcing which has included this how large-scale now see is experimentation as well system building right and if you're interested any of these topics happy to talk about them afterwards as well and at the high level really what I hope to accomplish my research is about these holistic and UN approaches for analyzing and building social systems and by combining large scale analyses with experimentation I hope make generalizable observations dive backed by experiments or establish causality and which enable prediction for example like my work identifying the causes of controlling I hope to kind of look at both the big picture interactions and that was as well as related to the small scale interactions between the visuals for example relating that network theoretic properties of Cascades to the mechanisms through which they propagate importantly my research also seeks to leverage these findings have developed new systems that kind of better support online social interactions for example to build pro-social discussion platforms so as a whole my result my research kind of shows how these kind of multi methods analyses can allow us to identify patterns and data verify hypotheses make predictions and then develop social systems as a result it's in such an approach most of my work has contributed to kind of an understanding of antisocial behavior also as Castine behavior and in the future I hope to continue creating new methods tools and platforms to kind of further improve how we use technology to interact with one another and I'd like to acknowledge at this point my advisors and mentors who have helped me immensely in my journey towards a PhD as well as my collaborators colleagues and institutions that have supported me and continue to support me and my research thank you for listening and I'll take any questions if you have questions please raise hands and I can pass the mic all right so thanks for a great talk so I think in in the earlier work that you talked about on analyzing controlling behavior it seems like it doesn't really matter how individuals are making judgments about whether or not a given comment is trolling if you if they're doing it completely randomly and don't account for the context which the the trolling the comment is is is being placed but I wonder if you could just reflect a little bit on that that human determination of making a judgment about a comment is trolling or not trolling it seems like it's something that would be hard to get agreement on by different people who may bring different backgrounds in different context understanding what trolling is in the first place right so definitely there are a lot of different kinds of definitions of trolling right and I guess that's also like where like this kind of work is very interesting because here we kind of have to define like what trolling means and so again like to speak to that like again like in our experiments we kind of can give like expert raters kind of like a guidelines about how do I read create these comments right there are things like you're on the lookout for swearing we're going to look out for help these kinds of like generally negative behaviors they're not going to capture all the whole like spectrum of trolling that happens right kind of maybe the more in sinuous kinds that where people are trying to act nice at first or you don't know if they are being like genuine or not they're kind of all these that kind of like dimensions of trolling that we could be looking at but haven't looked at yet right so here we really wanted to kind of start at a basic level and trying to identify like bad behavior in general first and kind of all of these like kind of things maybe a bit more obvious like these are obviously like these this obviously trolling behavior this obviously not trolling behavior of course there's like a huge sex spectrum in between that's also going to different like based on the community that you're looking at as well so thinking about how how you might define trolling on 4chan versus defining trolling on CNN versus even defining for trolling or like CNN and Breitbart again right so again like I think like content also plays a huge role and kind of like the norms of the community also kind of play a factor in kind of determining what is acceptable behavior and when it's unacceptable behavior so again like to kind of like try to address this I partially at least in data what we did was kind of like use that kind of flagging and deletion by moderators as a proxy for like what is acceptable content right what is trolling content right and these are kind of not not exactly the same corner these are things that things that get deleted or people who get banned are not all trolls or vice versa but again like they kind of match up approximately well like in these settings and this lets us kind of I see like there are these moderators in these different communities that kind of like evaluate and kind of like create post differently and like we kind of use like what is the existing that community structure well what it has my that's been put in place and what do these moderate so I have these Margaret's decided for the community and we use that to kind of evaluate trolling but again like I think there's a lot to do again like trying to understand more deeply like what trolling is and how do you define it and how do you define it kind of like in a more like generalizable way right and I think it's really it's at this core is kind of like very community dependent right and it's dependent on a community to define what is acceptable behaving when is unacceptable behavior and there are a couple there are there are things that kind of like maybe like more generally generally unacceptable like swearing like profanity racism they're most in unacceptable right and these things you can kind of like VDOT obviously I once you start kind of like discussing like oh like in the gaming community like which are the better consoles or things like that right it starts to kind of become more vague about like what what kind of things you want to kind of address and what things you want to kind of leave alone right so again there's countless like tension between kind of like controlling this cow behavior and kind of like trying to read out all the trolling versus I have this idea of like being able to express yourself freely and I kind of disagree to other people so I think there's an important kind of balance to be made there but just to clarify you're the judgements are getting or not ones that that your collaborators are making determinations on for whether on a comment is trolling you're getting that information from the moderators who are members of that community is that right right so when we did our experiment we did get ratings from from our collaborators our expert readers as well because we can and we also get them from the crowd right okay like just using these guidelines and then for the data analysis there because there's just so much data as well so what we do is kind of look at these moderator signals as well sure when you have to when you have people of your own who are making those judgments if they both take the same comment do they agree on whether or not strong or not right so definitely that was going to be there there was disagreement and so what we asked those kind of like to kind of resolve disagreements through discussion right again there are a lot of like comments there like kind of on the border as well where it's like is this trolling is this not trolling I guess there are like a lot of time you kind of have to make a judgment call as well yeah great talk thank you I have a lot of questions but I'll try to just pick one not sure which which one I want to take I guess maybe I guess you covered some of the things about the different purposes of these discussions like why are the there are even these discussion boards on some of these sites right maybe the purpose is to have these very conflict prone interactions like at 4chan or Breitbart maybe that's why they're there I don't know so we have discussions in education settings and and we have feedback and we don't see this sort of behavior in those settings for the most part because of the social norms and accountability but we do want to be able to give critiques right so we want to have an environment where there can be feedback and where students can give critiques to their peers and instructors and so on and recover and so the question is if we see those effects like you were showing of after there's a negative critique the students then were to write all negative posts and if we saw that kind of degradation that would really may mean peer feedback doesn't work so obviously there's maybe it doesn't in some environments but people worked hard to try to make it work so there's some framework that instructors and we're people who use peer feedback try to put in place to make it work it's more than just an upvote or downvote so though I guess the question is can your technique try to tease apart how much is it the norms of the community that can make that community work or fail how much is it the mechanism you know voting how much is it what people brought in to the discussion do you think or is that something you need to work towards teasing apart those different factors yeah I think definitely I love the a lot of these factors kind of interact with one another right because I guess like inherently like things like up voting kind of like don't have as much value ascribe to them and that kind of like the value of those things that comes from how the community defines like what uploading and downloading means so a lot of these settings have like uploading and downloading kind of may mean to people oh I just disagree of things but then like to the person receiving is like oh this is like you're saying you really don't like you don't like me right or something like that I think like again like think about these mechanisms I think though that's actually a very like good solution to these kinds of problems right Caltech what's the right way to frame frame this kind of critique and I think that that's like a good way that kind of we might be able to like reach from like learning from like peer feedback as well to see like how I might improve these discussions and to trial like tease these kinds of things apart I think definitely it is it is possible to do right I mean I think mainly through like running experiments right on kind of like maybe different parts of the community again the challenge there is because of these network effects they were in company to be kind of creative and like how we like do control studies in these kinds of environments and it also may be like thinking about how many tests different mechanisms how might we independently like kind of like verify like verified equality of like country contributions that people make I think like by doing cavities like things I think we could be we could start to kind of tease apart these effects using kind of these similar methodologies as well I was also really interested in your cascading results and your ability to predict I guess accurately whether or not any cascade will go from five to ten or double can you talk a little more about the accuracy of those predictions and under what circumstances you get that accuracy because that would pretty fast that was stunning so that's an interesting result right actually I have some more cool things to show regard to that so yeah what what we do is kind of like we have we have like just cascades in general and Facebook right and then we just wanted to see like given like just any random cascade I can't be predictive it's going to double in size or not right given that we have like two Cascades I mean you've gotten five free t-shirts so far so rare you just have like just a random bucket of these cascades with at least this minimum number of us we're going to pull pull to pull one out and and guess is it going to double in size or not and then we can do that we've kind of like over 80% accuracy close to 90% a you see and I guess like if you're curious like what kind of factor is kind of like well predictive in this like for example like what happens is that like have kind of like the root know it can be a predictive factor as well and you can see how it also changes as as these cascades get larger right and where the network structure starts to become more important and then also like you might also see how like these cascades I cannot get a lot of views more quickly that for example if they get a lot of views initially and they're going to kind of spread more quickly right because lots of people see them there's a high exposure but again like as the cascade grows in size it becomes that's important because again it's kind of like the cascade has gotten legs at this point right and and you know you can see like popular caskets are one where there are kind of like there's a high conversion rate between like how many people share it versus how many people have viewed it so calc I looking at these factors about like or initially among side these first hundred people saw like if like 10 percent re sharing and this is like a good factor like that this is kind of going to be spreading like far and wide in the cascade tree right and also looking at how the initial structure as well right if things are kind of more star like it means that it's like it's like a maybe it's only initially poppy it's only popular to like a small grow people around like the person sharing but if we see that it's kind of a bit more like more tree structure like what is going to happen it's kind of like that's demonstrating that it's kind of like spreading like deeper into the network and that it's kind of going to become more viral so again like all these different like factors that we looked at know but more details in the paper right here are a couple of examples of holidays these factors are predictive Thanks so I also have lots of questions I'll try and focus on two first one's sort of in the weeds and it's about the the second study you talked about sort of the effect of voting on subsequent havior and it's sort of you know common to a lot of these causal inference from observational data studies that you know a lot of the conclusions rest very strongly on this propensity score matching right sort of the assumption that you've properly Mott basically modeled everything except for the fact that things up and down votes and so I wonder to what extent you sort of checked that assumption either by like you know I was trying to think of how you could do it and maybe just like looking at like the the matched posts from ones that were had very high up votes like what is the counterfactual there or like looking at placebo tests to say like this is common propensity score like what happened what are differences between the thing that got uploaded and its comparison prior to the up vote like in theory there should be no differences but like if there are differences that tells you that maybe your propensity score is not really doing what you wanted to write right so so a good question in ball I profess to score matching I think like definitely there are look there are lots of career it's there could have controlled for that we didn't control for again again like I guess one factor is also like controlling for every single career it means that you have nothing to match on anymore and I guess they're like we try to like kind of a kind of think like but like before and like what are these factors that we think are going to be important in this matching and then Bobby Wilson is kind of like validate the propensity scores there we got kind of with the crowd as well to kind of see like if we got random people to read these posts like are they going to rate these to different posts we have different kind of text in them kind of similarly I guess that's how we try to kind of like validate these measures as well I think also something I did more recently is kind of like try different approaches to matching as well so like see to try to see if we could I could replicate the same results as well and then and that I could again I think it would be interesting kind of like a little more closely and the actual actual post and I I guess like different like strata as well I think they'll really be like something that could really strengthen like discount data so I know so I guess another thing that we did is kind of replicate this across multiple discussion communities and here we observe the the same like directions of effects in all of them obviously the effect sizes are different but again I seeing this effect that consistently replicated in multiple communities as well I think in some way that we try to kind of like demonstrate that these results are more more generalizable they're not sorry I'll take another question but 10,000 foot view instead which is you know in the last couple slides you were talking about potential future directions I a bunch of them had to do with more sort of like designing and building and sort of taking the insights from what you found and feeding it back into systems and I was just curious if you could talk about like to what extent those were directions that you're like interested in sort of you seeing other people were converse things that you're actually actively pursuing in the short term right so I think like a lot of these actually actually are things that I'm interested in pursuing right right now like I have lot of like I'm talking a lot with different like communities of people right couple and Reddit on different like subreddits as well try to figure out what kind of experiments we can run there try to understand like what are the different interventions we can design think you know symbolic just like building systems is why so prototyping like what are these does kind of buckles going to look like in the future and also in terms of cascading behavior yourself so I also have some continued continuing work at Facebook try to understand these mechanisms or how these cascades propagate also like also talking with people as well or outside outside of computer science also have information science trying to understand like there's like online/offline difference I think this is I think these are all like potential directions for me for me to move in and also I think directions to other people so have done interesting research in so I think that there's going to be kind of a combination of like collaboration of like common interests between researchers and these in these kind of adjacent fields as well as also as well as things that I'm personally interested in doing obviously I guess in the future what what students are interested in doing as well my question okay I think follow stearic directly on to yours which is when you think about designing and deploying interventions what kind of strategies do you have as a researcher doing that in in academia because we we may have many ideas but no built-in audience and on the other hand the companies with large built-in audience may be they may be very reluctant to deploy any experiments with the outcome is uncertain right or you have a reasonable outcome but it's not in the business interest of the platform so how do you see yourself navigating those tensions yeah I think this is actually one of the kind of like like difficulties of like I guess data science that a lot of people don't talk about right when you think about it generally I think you're like I think I think it's definitely kind of like establishing relationships of Industry and with like lots of different people right and hoping that at least some of them are going to pan out in the future right so again like people have reached out to me and my colleagues Catholic and red is like oh we have we have this subreddit where we're interested in the how understanding this kind of behavior so thinking about what can we design to kind of like improve that so for example one I was like oh we have a huge soft puppet problem and we saw a paper on soft puppets and it's like oh can we know like what kind of care we like can't predict when when this kind of behavior is going to happen and then kind of like the second opportunity to come to deploy an actual system in practice receive like but our results like in an academic work is going to like generalize who like what happens in real life I think like kind of continuing like collaborations of industry as well definitely trying to for example if discuss with Facebook I think also through students as well I think that's another approach as well at least from the data analysis point of view and also like I think that their the thing to think about is I guess like for example in the first study were real Seikan tunnel and crowdsourcing so I think like crowdsourcing is also a good kind of experimental platform that's maybe just starting to be explored like with with multiple people participating at once and I think there are you can start with kind of start to replicate assimilate these kinds of discussions these kinds of multi-user systems and then I think there are again like maybe a a sub research challenge is to kind of like see how might we define design frameworks kind of support that kind of experimentation well effectively thanks a lot in terms of the evaluation effects you talked about I was wondering just curious what your thoughts are on other voting systems other than the binary up down so like for a while Facebook only had up votes and now they have this like emoji reaction thing it's curious how you think that would kind of affect these how that would change or moderate the evaluation effects you talked about and whether it's dependent upon which community you're implementing that system in right so I think it's really first it's going to depend on the community that you're implementing it in right so I mean like really have a voting Dominic I read it and kind of how uploading down is use is going to differ depending on the community and what kind of norms have come around there right so some subreddits are very particular about how you use downloading and there it's going to have like a more positive effect when it does happen whereas kind of purely used for content ranking than for like kind of downloading people that you don't like right oh I can't you just simply don't care about right and I guess I think about how reactions might play a role as well I think there was an interesting paper by Mauro Burke at CSC W a couple one or two years ago on kind of reactions so I think they're like this there's something to kind of start looking into I don't think they looked at like the negative effects of these kinds of different reactions but I think it's actually like a positive step like versus like just a light right something more expressive but also like kind of like by design kind of discourages you from like kind of giving like bad feedback to summarize so you you can be like sad about something but it's not like I I just like your post right so I think like yeah I don't know like I don't have a lot of strong intuitions about like how these things are going to affect like how each individual type type of reaction is going to affect like how how differently people perceive like there's these kinds of feedback mechanisms right so I think that maybe there couldn't be interesting study to be done about like if you got like happy reactions versus sad reactions how does that affect your after outside is that maybe still going to affect your mood somewhat or maybe going to make you feel better because other people understand your versus like oh here's a like that I don't know what I don't know what exactly means but now that I do maybe that makes me feel better about like that means me makes it make me feel like other people understand like what what I'm posting about and so I think there are a lot of interesting future directions there Great Auk interested in the trolling work and one hypotheses you may have about the psychology behind trolling right sometimes it occurs in communities where the person trolling thinks they're kind of policing community they have a certain standard and so the other person is an existential threat to the community so they're showing other instances it's there's like unn confronted personal issue but by trolling they sort of are able to have a little bit of therapeutic effect right for that individual but the the broader question is when you're considering okay well there's positive trolling and there's negative trolling some trolling is just expression right and you want to allow for that what are some ways of sort of measuring the net benefit of that kind of expression in the whole network right so if you're trolled maybe that has a therapeutic effect effect for the person trolling but maybe if you are told what is the cascading negative effect of being on the other end of that right so have you thought about the kind of cascading nature of positive and negative kind of sentiment and effect and how you might measure that globally right so I guess like trying to like trying to understand kind of cascading like negative behavior I think this is one potential like aspect of future all right so now we kind of shown the one step process of how like one person or one entity affects another entity and thinking about like how that might have a ripple effect I think that would also be very valuable to look at and especially like how positive change might also have a positive ripple effect now again like I think that again communities have to make a decision about like I guess freedom of speech versus like benefit to the community I think that then I guess there's also there's also discussion to be had about like whether venting is even good in the first place right and whether you actually want to enable venting in any form like even on even online or offline right and so I think that's that's one like question aspect to the problem and if you did a lot maybe there are different avenues to do it without kind of affecting other people like if if for example like and again like these kind of raises a lot of different kind of interesting ethical questions about like say you vent on the community and then like some machine learning algorithm kind of turns your post into something a lot more positive like is that is that good or is that bad right because it's like it kind of minimizes the impact to other people but still lets you write what you want just to what your outcome the outcome of what other people see maybe it's invisible to you as well but maybe that can also be like different thinking of different kinds of interventions that you might make to kind of like kind of support like how the personal personal benefit versus the global benefit to people yeah I think I think they're all very interesting discussions to be had there I would like to think just thing once more thank you for 