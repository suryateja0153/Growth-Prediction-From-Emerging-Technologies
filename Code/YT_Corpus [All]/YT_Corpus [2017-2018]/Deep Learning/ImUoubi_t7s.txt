 one of the most exciting recent developments in people earning has to the rise of end to end deep learning so what is entering deep learning briefly there's been some data processing systems or learning systems that require multiple stages of processing and what end-to-end deep learning does is it can take all those multiple stages and replace it usually with just a single neural network let's look at some examples tic speech recognition as an example where you go is to take an input X such an audio clip and map it to an output Y which is a transcript of that audio clip so traditionally speech recognition require many stages of processing first you will extract some features some hand design features of the audio conservative heard of M FCC that's an algorithm for extracting the certain set of ten design features for video and then having extracted some low-level features you might apply a machine learning algorithm to find the phonemes in the audio clip so phonemes are the basic units of sound so for example the word cats has made other three sounds that cut up and tuck so these strike those and then you string together phonemes to form individual words and then you string them together to form the transcription of the audio clip so in contrast to this pipeline both of all the stages what end-to-end deep learning does is you can create a huge new network to just input the audio clip and have it directly output the transcript one interesting sociological effect in AI is that as and deep learning started to work better there were some researchers that had for example spent many years of the career designing individual steps of the pipeline so there were some researchers in different disciplines not just a speech recognition maybe in computer vision and other areas as well their sense of all the time you know written multiple papers maybe even build a large time and career engineering features or entering other pieces of the pipeline and when end-to-end deep learning just took a large training set and learn the function mapping from X&Y directly really bypassing a lot of these on intermediate steps it was a challenging for some to come round to accenting this alternative way of building a our systems is because it really also leads it in some cases many years of research in some of the intermediate components it turns out that one of the challenges that incentive learning is that you might need a lot of data before works well so for example if you're training on three thousand dollars of data to build a stage recognition system then the traditional pipeline there's full traditional pipeline works really well it's only when you have a very large data set you know want to say ten thousand dollars of data and anything going up to maybe a hundred thousand dollars of data that deep end-to-end approach then suddenly starts to work really well so when you have a smaller data set the more traditional pipeline approach actually works just a small often works even better and you need a large dataset 240 end-to-end approach really shines and if you have a medium amount of data and they're all so intermediate approaches where maybe input audio and bypass the features and just learn I'll put the phonemes of the neural network and then have some other stages as well so there's be a step toward end-to-end learning but not ultimately they're just so this is a picture of a face recognition turn spell built by a researcher into Lin and I do where this is a camera and it looks at the person approaching the gate and if it recognizes a person then you know the turnstile automatically lets them do so rather than needing to swipe an RFID package to enter this facility it increasingly many offices in China and hopefully one more in other countries as well you can just approach the turnstile and if it recognizes your face it just lets you through without needing you to carry an ID badge so how do you build a system like this well one thing you could do is just look at the image that the camera is capturing all right so I guess is my bad drawing but maybe this is a camera image and you know you have someone very approaching the turnstile so this might be the image X billion zillion camera is capturing and one thing you could do is try to learn a function mapping directly from the image X to the identity of the person Y but turns out this is not the best approach and one of the problems is that you know the person approaching the turnstile can approach them lots of different directions so there could be it's a green position to get of a blue position you're and sometimes they're closer to the camera so they appear bigger and DMH and sometimes they're already closer to the camera so their face appears much bigger so what is actually done to build these turnstiles is not to just take the raw images and feed it on your net to try to figure out the person's identity instead the best approach today seems to be a multi-step approach where first you run one piece of software to detect the person's face so this first the detector to figure out where is the person's face having detected the person's face you then zoom in to that part of the image and crop that image so that the person's face is centered then it is this picture so I guess I drew here in red this is then fed to a neural network to then try to learn or estimate the person's identity and what researchers have found is that instead of trying to learn everything on one step by breaking this problem down into two simple steps first is figure out where is the face and second is look at the face and figure out who this actually is the second approach allows the learning algorithm or really two learning algorithms to solve to much simpler tasks and results in overall better performance by the way if you want to know how the second step actually works are simplified to discussion by the way if you want to know how step two here actually works i've actually simplified the description a bit the way the second step is actually trained as you train a neural network that takes us input two images and what in your network does is it takes us input two images and it tells you if these two are the same person or not so if you then have say 10,000 employees IDs on file you can then take this image and grid and quickly compare it against maybe all 10,000 employee IDs on file to try to figure out if this picture and written is indeed one of your 10,000 employees that you should allow into this facility know that it should allow into your office building if this is a turnstile that you know is giving employees access to a workplace so why is it that the two-step approach works better they're actually two reasons for that one is that each of the two problems you're solving is actually much simpler the second is that you have a lot of data for each of the two sub toss in particular there is a lot of data you can obtain for face detection for toss one over here where the toss is to look at an image and figure out you know where is the person's face in the image so there is a lot of data but there is a lot of label data X comma Y where X is a picture and Y shows the position of the person space so you could build a neural network to do task one quite well and then separately there's a lot of data for task two as well today leading companies have let's say hundreds of millions of pictures of people's faces so given a closely cropped image like this red image or this one down here today leading face recognition teams have you know at least hundreds of millions of images that they could use to look at two images and try to figure out the identity or we figure out the same person on so there's also a lot of data for task two but in contrast if you were to try to learn everything at the same time there is much less data of the form X comma Y where X is an image like this taken from the turnstile and Y is the identity of a person so because you don't have enough data to solve this end-to-end learning problem but you do have an update ER to solve subproblems one and two in practice breaking this down to two sub problems results in better performance than a pure end-to-end deep learning approach although if you hide an update for the end-to-end approach maybe the end-to-end approach would work better but that's not actually what works best in practice today let's look at a few more examples take machine translation traditionally machine translation systems also add a long complicated pipeline where you first take say English text and then do text analysis basically extract a bunch of features of the text and so on and off there are many many steps you then output say a translation of the English text into French because for machine translation you do have a lot of pairs of English comment French sentences end to end deep learning works quite well for machine translation and that's because today it is possible to get a large data set of XY pairs where that's the English sentence and that's the corresponding French translation so in this example a deep learning works well one last example let's say that you want to look at an x-ray picture of a hand of a child and estimate the age of a child you know when I first heard about this problem I thought this is very cool crime scene investigation task where you find maybe tragically a skeleton of a child and you want to figure out how old the child was it turns out that um typical application of this problem estimating a child from an x-ray is less dramatic than just crime scene investigation or filtering it turns out that pediatricians use this to estimate whether or not a child is growing or developing normally but a non end-to-end approach to this would be revoking an image and then you segment out or recognize the bones so know just try to figure out where is that bone segment where at that bone segment where at that bone segment and so on and then knowing the length of the different bones you can sort of go to a lookup table showing the average bone lengths in a child's hand and then use that to estimate a child's age and so this approach actually works pretty well in contrast if you were to go straight from the image to their child's age then you would need a lot of data to do that directly and as far as I know this approach does not work as well today just because there isn't enough data to train this toss into end fashion whereas in contrast you can imagine that by breaking down this problem into two steps step one is a relatively simple problem maybe you don't need that much data read only damning x-ray images to segment out the bones and toss to well you know by collecting statistics of a number of children's hands you can also get decent lessons of that without too much data so there's multi-step approach it seems we are promising maybe more promising than the end-to-end approach at least until you can get more data for the end-to-end learning approach so an enter ng of learning works it can work really well and it can really simplify the system and not require you to build so many hand design individual components there's also not panacea it doesn't always work in the next video I want to share you a most systematic description of when you should and maybe when you shouldn't use end to end deep learning and how to piece together these complex machine learning systems 