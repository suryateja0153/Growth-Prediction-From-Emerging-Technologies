 An 8-channel brain computer piano interface developed by the ICCMR at Plymouth University in collaboration with the Brain Embodiment Lab at Reading University, as part of the BCMI-MIdAS project Hello, my name is Duncan Williams. I'm here at the ICCMR studio at Plymouth University And I'm about to set up a demo of the musical brain cap I'm just going to switch this on to the time-lapse  so what this system is doing is we're taking a 8 channel reading from the occipital region and also partly from the Motor Cortex and we're using these to differentiate between three different frequency bands and The asymmetry across the brain to try and determine a person's mood and then we're connecting that via some freeware software in this case the Machine learning tries to learn about how we feel when we hear a certain piece of music and That is been transmitted to a music generation System using some artificial intelligence to this self playing piano (a Disklavier) So what we've got going on here is some unfiltered signal and an Earth channel That's been converted to a power spectrum over here. Which is blue at the moment.  there's a bit of a delay you see the color change there and then this app Is sending OSC over to our max patch where we do a bit of scaling to an arousal and valence value over here - a musical generator Which creates different pieces of music around the space and sends that to the brain for the piano and eventually to the self playing  