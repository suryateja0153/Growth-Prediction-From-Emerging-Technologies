 Hi, I'm Gordon Wetzstein. I'm a professor in electrical engineering here at Stanford, and my research is focused on computational imaging and display systems. We work on algorithms and objects  for lidar systems, for depth imaging, but also computational optics for virtual reality and augmented reality. Wearable computing is assumed to be the next big computing platform and virtual reality is a part of this. VR enables you to travel to distant places to experience things that you couldn't experience in the real world or to communicate with your friends at a distance, in a completely unprecedented way. With EE 267 we created a class that teaches the technology behind virtual reality. In the first few weeks we learn about computer graphics and rendering, we put that on the head-mounted display, learn about display shaders and optics. Then we do sensor fusion on the IMU, the inertial measurement unit. And finally we look at spatial audio and positional tracking as well.  The goal of the class is to build a head-mounted display from scratch. And using the techniques that we learn including computer graphics, inertial sensing, and so on. We're going to do a week-by-week project that ends up being the head mounted display that we build from scratch throughout the quarter. Students learn the basics of computer graphics and that includes rendering and computing images stereoscopically for a head mounted display. They learn about the optics in head mounted displays. They learn about inertial tracking, gyroscopes, accelerometers, magnetometers, and other sensors that allow us to track the user's orientation and position, and we also learn about positional audio. This class is really for students who have taken the basics of signal processing already. EE103 would be a great class to take. Any other applied math class or algebra class will really help. If you're interested in electrical engineering – please check out our website  and feel free to send us an email. 