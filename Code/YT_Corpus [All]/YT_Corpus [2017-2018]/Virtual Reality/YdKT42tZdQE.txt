 thank you so yeah and this stalker will present case customs interaction and virtual work and this was conducted Lancaster University with like Benedict Maya he's from the LA she was an intern and Jack Oman and Biggie and hunts galas so the previous talk was really studied how I guess works right now and showed off some of limitations but this dog it's slightly difference I'm not surrounding a study I'm not comparing anything I'm looking into exploring what can we actually do if I checking would work really well and but also what can we do right now with the current era limitations so okay I want to start with an example here so this is like the typical and we are seeing for that two objects here on the scene and so this circus yeah they're great okay you can't see my mouse cursor but in the middle of this is green a gray circle and that the chair shows or indicates when looking it's revolved all examples so I'm just gonna run it and what you can see is I can in a very dynamic way I can manipulate these two objects right and so I'm not using controllers even if the optics are far away and some I'm using just my bare hand free-handed input to have this very flexible way of interaction and so I wanna expand you in this kind of interaction and explore it further and following so good a little bit of structure first background and I'll explain how the interaction works what we implement it then give a few examples on new ways of manipulation and in the end also how we can integrate this kind of interaction into more sophisticated user interfaces such as menus okay so this book s similar to the previous one it's at the intersection between I clicking and virtual reality so I guess I don't have to introduce too much here but let's just say my perspective is I'm a lot into eye tracking before that and not in virtuality and one can separate this into these two categories here so gaze interactions since the 80s 90s gaze has been often used as a pointer to indicate the target and most of the studies like the previous one say okay guys really fast there's less manual effort but of course we have issues with inaccuracy possibly from the mildest Ashcombe but mostly most likely from hardware issues but in that sense I would say that in previous years I tracking improved significantly so I think there's a bright future anyway so but I'm not focusing on that aspect too much in this paper yeah so in the right side you see like works that have combined these two modalities and I spend a lot actually and then combining gaze with like keyboard input with different kinds of mouse and cursor interactions and so what I did kind of recently is looking at small D touch with I gaze and I was just interested okay how would this kind of interaction this multimodal interaction work in virtual reality and looking through literature there's a lots into like this case based interactions it's the importance to our time and race and different kind of menus or the previous talk and but there hasn't been a lot of work that exploit actually what can we do if we join the powers of the hands with the the magical very fast way of I guess so that's the focus of this paper so I looked into the virtuality literature and specifically in HCI and one paper found really interesting the one from mine which our environment interaction techniques and so there is that the before we can actually create the virtual world solution we must identify natural forms of interaction and extend them in ways not possible all right now so focus is on what what is actually natural and what is not possible right now it's also kind of referring back to the keynote yesterday where I was also discussed what was natural and supernatural and these all these kind of exciting interactions so she kind of separated this patient or this they are these virtual hand interactions weight directly money plate objects you can just simply use of hands and this kind of goes back to the skills that we've learned when we grow up we know how to grab things we know how to pinch things is very easy to use and on the outside there are these point on tracks right because in a virtual environment we have a lot of space and we won't interact with all these objects around us that are even out of the normal manual reach and yeah there's been a lot of work into that either focused on one of the sites or kind of combined them and I'm not going in too much detail and because we also see them right now in products like the leap motion using hand gestures hololens is some kind of variation there and applause playstation and HTC they have these right pointing metaphor you can control remote objects and I think it goes down to this trade of years so we have this trade-off between more natural interactions where you just simply use your hands as if you would use them in any normal physical interaction but if we want to interact with distant targets we need to have some kind of add-on the tougher and usually it's using a controller a right pointing metaphor and of course you need to hold the device and know which button is what and this is not as intuitive it's as if you would use just you know the normal 300 input it's okay so what is the proposed interaction here so what gaze past pinched essentially means is that you can look at any target and use pinching gestures to manipulate than such a target and the interesting part here is that these free hand gestures are quite natural so as far the inset and the previous slides so you can freedom gesture is very easy to do the intuitive but at the same time it's not really natural it's more like supernatural because it can attract anything you're looking at right so whatever isn't as I've just seen you can select it by just simply looking at it and this is how we these are like the basic principles how we implement it this Sam first of all the most important one is that hands through the world so wherever you're looking nothing happens you can look at anything as long as you want until you perform the pinch gesture and then you get the mapping and you can move an object and yeah two more things to consider we used target snapping so the closest target to be you this case ray is always selected so this this way we can kind of explore these interactions without thinking too much about inaccuracy and maybe a potential errors there and the second aspect here is the they say one to one translation movement and the object that you have selected so when you move your hand it will look like as if almost an entire moves in the same way so if you knots in the system so we used an HTC vive with a leap motion attached to it on top and inside there's a pupil I tracker and the users calibrated before the interactions and usually this works quite well the eye tracking as well and if the agency also well attached to your head so if it moves a bit on your head it gets a calibration drift and also but but usually it works sufficiently enough and yeah the virtual scenes are developed with unity okay so I want to talk about the design space so there are the atomic interactions of gaze image so we we can attract this one or two targets in this space but also with either one or two hand and I want to give a few examples on this so here in this video hope you can see well so here the gaze cursors again shown as the great circle and so I can just simply look at one of the objects and move it with my hands and if I want to attract with two targets and this is all squared so I just look at the first time then I look at the second target and do something you can see it and okay by many attraction this also quite similar so you just looking at out and you can engage the second hand at any time if you want to do some rotation and scaling so it supports all these typical 3d manipulation tasks and of course you cannot interact with two different objects at the same time if you're holding one and then you look at the other one and then you stay at the second hand here and the the key to this is actually that all of these atomic interactions so the user can switch between the right you can engage one hand you can put them out and just manipulate anything you want and for these three tasks of rotation scaling in translation so that's what I want to show you the full video here it's imagine in some kind of entire interior design scenario so here I'm rearranging the living room and I can quickly change between scaling or changing the we're taking the table in a way that I wanted and in a few seconds I have kind of moved around a few objects and have had a new design on the year in this room so okay so this was about the atomic interaction but what can you actually do with this and how dynamic can this become and this is especially interesting compared to okay how how would this be possible using the controllers or if you would only have the deep emotion for example and you would only have your hands to interact with it this is this other question that I always find interesting and and I looked into five different examples so I've I mean in a sense I just played around with this interface and tried a few things and first of all this is what we've seen at the beginning it's the juggling one so what it's really nicely shows us that it's very easy to switch the context between two different objects and just you know these are this is a very time critical task although it seems very easy but you need to exactly call the neck your fingers and your vision but since since you're looking at at the time at the ball that you want to juggle anyway it's quite simple to coordinate this and do that until at this point here okay but let's go so another interesting aspect is that you can play with the scale on a really large scale not get worried but is to see there's a small object quite far away yeah and I can resize it just make it a bit bigger so it's maybe a few meters in front of me and so this this scenario he has objects that are some kind of kinetic behavior so the they behave like like basketballs in a sense just to give you to me and so that this example makes sense but the idea behind this is that you can play with scale so this object is quite far away but you can scale it again up into a very large size and use it even for to manipulate the whole scene even if the Telos I've ever I really far away yeah so it gives you quite quite a wide range of control and it's for 3d manipulation across the scene so another example it's about more scattered interface so I imagine there are a lot of different objects around and then and like in this one and he I just want to sort them but it could be it could be any kind of more cluttered which a senior and I'm every time I'm just looking at one of the targets and I'm moving them around here so this has a specific interaction attached to it but it could also be freehand 3d manipulations among and in a few seconds I can just easily solve all the objects and with that so imagine you would have to do that good like you know yet at orientation or using whole lens or something like that so removing the hair to each of the objects on the scene that would be quite tedious and in my opinion ok so another thing that I found interesting is the power of by manual interaction so yes there's been a lot of working by my interaction that you looked at this dominant hand on dominant hands interaction and what I'm doing is essentially here on the left side and the left hand with my left hand is holding this pile of objects here with one hand and with the other hand I'm kind of stacking new objects on it so I need to balance with one hand and with the other hand I'm doing these micro interactions and adding one after another I don't know what it's for but it is that's really nicely so that you know you can very nicely interleave both of the hands into this compound task and I'm also trying to fix this at some point it's already quite jittery but yeah even if you need this kind of precision it just works and you don't have to immediately grab on to it yeah yeah so this last example here and this is about like more building and things on the direction of Minecraft or brakes and Lego designs but of course could also be more into this 3d modelling interaction of some so what I want to do here I want to build a statue so I'm stacking up the objects and this also quite works quite simple that this is because like I I know exactly what to do with my hands because it's the typical pinch gesture or a string but what he can what is kind of more invisible here is that you you always have a sense of the environment so even if it goes out of your reach you know where's the object relative to the other objects and you can stack them around them yeah and do these kind of interactions yeah okay so yeah my next part I want to I want to show you that we can study because the previous examples were all about moving things around resizing them but of course this is not the whole thing usually an interface you have a much more to offer different kind of tools different apps different interfaces and there's it's totally unclear how you would use your eyes in that with that kind of interface so so here welcome to a VR literature however many is designed in the past and I found two papers quite interesting one it's about proprioception so how much are you actually aware of your body and it's actually the fact that you always kind of know the relative position of your hands to your body but also the relative position of one hand to the other hand and this can be kind of utilized for for the 3d virtual interaction and others have suggested menus that can appear the fingers or the hands or they're kind of all the bigger theme here is that they are like body based interface so by using the body of the user allows to add interfaces there where the users always aware of them where they are so they can't get lost if the menu somewhere in the virtual scene or something so yeah building on this we looked at the following interactions so here this is kind of the whole system in one figure on the very left side this it shows the basic interaction 30/40 so you can manipulate objects far away or close to you but if you bring in your arm on your forearm this UI in a way and it's like an armband or watched it is kind of attached to your arm and you can interact with it using case and pinch interactions and this kind of forum menu is essentially like a system-level anyway I can select between different tools and applications and if you selected one of the applications they can have an additional interface that is on your head like on the very right side here so so to actually use the application I want to first focus on the more system level menu here and this is designed in a way like a marking menu and first of all I want to show you so the menu only appears when you look at it as you can see and when you look away it kind of fades out again so if it's not there you can just interact normally with a virtual scene nothing special but if you're looking at it then you can use some kind of gaze pinch interactions as you can see this one so here if a pinch I get the center of the menu and then I can go in any direction to choose one of the applications so in the say at the beginning I'm just the saving the menu and another option if I flick to the right then I can select the map application okay now to the specific applications so yeah and this is kind of a tablet light interface imagine you're having your hand and there's a tablet or something and there's been a lot of work into this and priority reality interactions but here I look into it how how it would work in the context of this case a pinch interaction and if you think about menus there of course a lot of different types of menu so we we look into three different groups in a way so the first one is about allowing users very rapid access to the items on the menu and the second one is about slower interaction but where you just require more precision so if there are a lot of different tools and your big menu and then thought when we look at 3d interfaces okay so the very first one I hope this video is not too small so this is about the quick quicker interactions and if you pull up the hand you will see this interface with just four options that could be a bit much and to select an item you you look at the items so right now you see the circle on the on the block yeah and then I can drag out objects from that so I can immediately starts using the case and pinch in action interactions because they are and then attached to the to the hand and see I'm just looking at the same time that's dragging off a lot of different objects and this is the beginning of the other did you actually yeah so this this allows you to you can look at any of the targets and just do this pinch gesture and you can drag out and one of your targets so of course this was limited so you can only have a set of items there depending on how accurate your I guess is and I thought okay what's what if you want you know different interfaces with a lot of items so this is just an example of a periodic table here and you see there's a little cursor in the middle the interface so imagine it's like a Windows tablet console and something like that and the interaction is slightly different yet so I guess only select the menu itself and wherever you're looking on the menu it doesn't matter the only thing that happens when you use the pinch actions is it's this year so when you move you move the cursor right so it's like a touchpad you drag and then you drag the cursor off and if you perform this pinch action without movements you can select one of the items and the and the elements that were created other generated at the position where your hand was actually pinching and from that you can immediately interact and do something else with it okay so let's go on to the next it's the last example here this is about 3d a more 3d way of inter interface on your hand and here it shows a mini map of the whole virtual scene and this is space or inspired on the world in miniature of paper from long time ago in a sense of the loss they what they showed is that you can you have in your own avatar in the interface and move that around and then you can actually move yourself around in the real virtual scene it is a example it makes no sense man so here again I guess only selects the interface and when I pinch I automatically select the red so that's like the small so I move it up and then locomotion happens and Eva moves the trajectory up to the position where you there was and then you can do some kind of other interactions based on this better overview of the scene this kind of stuff is what I thought I showed before and if you want to go back you can bring out the map again and just immediately and move your avatar to to go to a different position so it's it's very easy to just switch between in manipulating things around and then okay I want to move somewhere else I bring out the map I move and so yeah it was a lot of different example so that shows and I guess I stay a little bit of time to give a summary say what we what we introduce here is an exploration of this gas and pinch interaction technique and it's interesting from the perspective of natural and supernatural or natural interfaces it's kind of natural because it uses these familiar gestures I wouldn't need to learn anything because you know how teams you know how to zoom but at the same time it's it goes beyond to be cool gesture interaction because you can interact with anything that you can look at right and the whole thing whether it's far away or close to you so yeah we we draw out a design space showing these are kind of the atomic interactions and based on these call interactions we can build up from that a lot of different manipulation methods such as these things where you do somewhere know you can work with large scales you can you know build some kind of basic 3d model or do this juggling face interaction and we also show that there are different ways to integrate I guess within this interaction style of case intention to different user interfaces before either you want very quick access very precise access or whether it's controlling something in a small 3d GUI in your hand yeah so we at the end we had to use a feedback session with 8 users so they tried a lot of these things and gave some feedback and most of them were like I was very easy so magical this stuff and of course they they couldn't learn at media it was kind of difficult one of the user said for example was rather difficult at first to understand how many works after a couple of trials and they got the hangman usually it was quickly and there are some issues with false detection gestures but there was I'm not sure if this the technique of this the gaze the leap motion itself because you know if you include thing else and all stuff then there's some will pinch detected and so on of course there's a gorilla arm problem that was also mentioned yesterday so as to you the said for example it was tiring to keep the hands up but even if they are not stretched full lengths thanks to the technique so because you don't need to stretch your answer but it was still use I had to keep the arms in the range of the deep motion - thank you really work and there was still an issue if you want interact or what for longer duration ok I want to conclude the talk for the following points of course I am hand tracking to be improved to make the syntax really work but nonetheless the phone is very interesting there I love under explored potentials by tracking just last two points yeah we showed a lot of powerful ways of manipulation using this technique and yeah it's unclear whether whether it's really natural or what else natural and how this really works and say more studies are needed to clarify these questions thank your artists thanks a lot we have time for a few quick questions I think this is a very outstanding work really my components I've just one fear about this supernatural so there is an important theme of this conference I know that fly pilots of airplanes they after a virtual simulator they cannot drive data cannot pilot for a few days because simulator cannot be exactly the real thing you know so why I say this because in when you use the superpower in Indian Navy air in the mihrab objects probably you can transmit the habit in the user which is not them real so then the user can go outside and have problem is in coordination so your system it works very well but there is the the threat the risk that the user then becomes completely scaring dangerous in real life so do you ever think about this problem forever forever I just suggest to keep the interface is outstanding for faraway objects I think it is really revolutionary instead I will keep a near object natural so I can answer to your last line of probably you troll you throw this question you already prepared this question so you I think in when you can have a natural interface and it works like you have a very near object I will say I will go for normal mapping one-to-one like mine says in his in his paper of 97 and the one you are far away then you can have a supernatural power you know it's like spider-man it doesn't throw stuff all around it just when it's needed it does it yeah but it's no definitely it's interesting I'm I'm not sure whether this is really natural or supernatural or whatever because there are a lot of supernatural things maybe are already right so all second is this is really great work God do you do you have a like a unity SDK or something like that because it seemed pretty easy to plug in a generic I don't know it was quite easy to simply integrate the I trick which is X Y position and then the better if you've done it though I could I could think about it [Applause] 