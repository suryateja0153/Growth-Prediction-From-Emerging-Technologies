 he says the people don't actually recognize him when he appears without it it is a little bit disconcerting so it's good to see that he has the Hat on in his picture here um what we're going to talk about today is a little bit about smart logic a little bit about the concept of content intelligence then tom is going to introduce caps group and he's going to talk about what text analytics is and give us some examples of actual use of text analytics to drive business value for organizations we have all microphones muted at this point if you have questions we would encourage you to type them into the question box in the GoToWebinar control panel we will get to as many of those questions during the broadcast as we can and will I will answer any additional questions by follow-up emails so when I think about content intelligence what I think about is the fact that eighty to ninety percent of the information in organizations and in fact most of the human intelligence and organizations is um is locked away in in content it's in PDFs Excel spreadsheets PowerPoint files documents contracts project summaries and so on and so forth Gardner has said that organizations that integrate high-value diverse and new information types into a coherent information management infrastructure will outperform their industry peers by more than twenty percent we believe that the ability to unlock the value in content is the untapped frontier of competitive advantage it is the thing that is going to allow organizations to become more competitive in in 21st century we've got a pretty good handle on what we're doing with structured data at this point but unstructured information to most organizations is still a bit of a mystery and when we talk about it it's smart logic we typically talk about it in terms of the fairy tale okay once upon a time there was paper people did business on paper they sent you purchase orders in the mail or over a fax machine things got filed away in filing cabinets um people wrote out invoices by hand or type them out and and sent them through the mail checks came in the mail and so on and so forth and then sometime in the 1950s 60 70 s somebody got the really bright idea of taking some of that information and putting it into a structure that would allow it to be automated and so we have this thing called a hierarchical database and hierarchical databases were great because they allowed you to to automate the the production of invoices they allowed you to automate the accounting for checks that were paid in and so on and so forth but they had some significant shortcomings because you couldn't understand the data unless you looked inside the program to see what the data meant so those of you who were as old as I am we'll remember COBOL programs where you had whole sections of the program that were defining what the data meant and so if you actually needed to make a change to the data you actually had to go Jin yourself up a cobol programmer in order to be able to do that so that was a step forward and then in the 1970s 80s we had a shift change and what happened was we started to take this data and make it self-describing and we put it into a structure called a relational database and relational databases were great because you could basically ask the database tell me what your data is about and it would say well bytes 1 through 25 or the customer number and that's alphanumeric and bytes 26 through 43 or the customer name and so on and so forth so you could actually have multiple programs using the same information because the data itself would tell you what it's about and that actually led to a hole explosion of innovation we got data warehouses we got business intelligence to sit over the top of the data warehouses so that executives could actually look into the data um we've now reached the net next generational shift with the structured information in in what we call the post relational data stores the no sequel databases that actually allow us to define less to have more freedom around around the structure of the information because one of the major drawbacks of the relational database was that you actually had to presuppose the question and structure the information in a way that the question should be answered so the big promise of the post relational data stores is that because they are scheme elasaur schema agnostic you no longer have to I'll presuppose the question but you actually have a lot more freedom to ask any kinds of questions that you like of your data the big problem with the promise and why it hasn't been received or hasn't been achieved is is that in the vast majority of organizations are still only using that twenty percent of the information which was automated way back in the hierarchical and relational database days in order to be able to predict what's happening in their marketplaces and where their information is going so what was happening with the paper all this time and with the unstructured information well for a long time it stayed on paper and we put it in filing cabinets and then there was the point where we said let's take those filing cabinets and electronic I them and we turned them into file shares and then we had a brief romance with image management systems and because nobody could find anything we invented Enterprise Search to go over the top of all of that stuff and then the letter innovation was content management sins which essentially allowed you to structure the unstructured information in a more intelligent way but there's still document-centric and they're still very hierarchical if you look at most content management systems today they are they they are built on a construct of filing cabinets and folders and unless you actually open the document and read it you can't get out the bits of intelligence that are inside and that brings us to content intelligence which actually allows the content to become self-describing so that in the same way that you could ask a relation in ways so tell me what your data is about you can now ask a PDF or a document and the document will tell you i am a contract i am between this company and that company i cover these services i cover this range of dates and so on and so forth and the ability to make the content self-describing actually allows you to get to the concept of unified enterprise information where you now have all of the information and all of the intelligence in the enterprise that is managed under a consistent semantic umbrella and it allows you to gain the insights from all of the unstructured information that you couldn't use up till now so content intelligence I originally come from gartner and a Gartner we all define we all did like to define things and so one of the first things I did when it came to smart logic was was created definition for content intelligence and basically it is conferred combination of semantic technology and information science and what it allows machines to do is to model the problem domain interpret that model in order to create the rules by which information can be classified and described allows you to describe all of those unstructured information assets which allows you then to analyze and visualize them in order to leverage the human intelligence that is locked in that content and the components of smart logic semaphore that do those things are ontology server which manage the models the rules bases which actually interpret the models to create rules for classification and extraction the classification server which is responsible for attaching complete consistent and very rich metadata to those information assets advanced language packs which allow you to do all kinds of analytics and extraction and somatic enhancement server which actually allows you to visualize the results because we all know that people do better with charts and graphs than they do with green bar reports and with that I'm going to turn it over to Tom to talk about the caps group and what they do and to give us some real life examples ok Thank You Anne and thank you for that nice introduction I'm going to continue the introduction briefly talking a little bit about caps group which is company I started about 12 years ago it's a network of consultants put together for different projects we've been doing this stuff for a long time we started out with taxonomy as we do fast attacks on amazed applying complexity theory and natural level categories and emotion taxonomy is to actual business applications we've been doing almost exclusively text analytics for the last 10 years so you can see we do a lot of different services we help people get started we partner with smart logic all the his clients and if you want to see more you can see the various presentations and articles that I've done on the website and lastly as an mentioned I'm the program chair for text analytics world conference we just finished a conference in march in san francisco and of course are to getting ready for next year so enough about that let's talk about data in fact so i'm assuming everybody has heard about big data volume velocity and variety and yeah there's a little bit of a hype about it but the reality is it is incredibly important and there's been some amazing applications developed the big difference between big data and what we're going to be talking about is that there are new techniques to access all the amount of data but the actual data analysis it's fairly well known its traditional methods it works we know it it's very precise on the other hand we have something that's even bigger than big data which is big text anywhere from 75 we're actually looking at not close to ninety percent of valuable business information is in unstructured text and one of the big jumps of courses because of social media well even though big text is much bigger than big data it's there's a lot more of it there's it's a lot more valuable in a lot of ways the problem is that these traditional analysis methods don't work on unstructured text and so it sits there being underutilized and what we're going to be talking about the rest of the time today is how to get into big text and get the same kind of value out of that that you get out of big data so how does that all work well the basic idea is there's two ways that text analytics can help create value out of unstructured text the first is simple in a way you just go in and you extract all the information out of the text turn it into data you find all the people and the company names and all the various pieces that you bring out as data then then you can just apply for additional data techniques so that's that's very valuable it's one of the big parts of text analytics on the other hand there's another part which is even more valuable in a lot of ways and that is new techniques and technologies that we've developed in text analytics to basically understand the concepts within the text we can model the various relationships we can model the concepts and their relationships and we can develop methods to really understand the text in a very deep way and this is the second part of text analytics so the two pieces come together and they enable us to create value out of unstructured text so what do we mean by text analytics well I know and as just talked about how she loves new definitions and Anna and I get along very well on a lot of areas for me no I'm not so much concerned about defining what text analytics is I mean after all what kind of a definition could cover all the different kinds of things that text analytics does for example one technique is to treat words as option and then it's applied very advanced mathematical techniques to those those objects you can you can define the patterns of words in documents and when you do that you can find out some pretty amazing things and we'll talk about one in a second in addition X analytics also deals with social media it analyzes what people are saying in Twitter posts and forum posts not only in what they say but we try to dive in more deeply and what do they really mean behind those those textual expressions it also covers things like fraud detection for example looking at words as objects in one case we had a keynote speaker at our conference a couple years ago that wrote a really great book on a secret life of pronouns but what he did was look at patterns of words that people normally don't pay attention to function words and turns out that you can by looking at the patterns of those words you can actually tell the about seventy five eighty percent accuracy whether someone is lying for example we analyzed the Enron emails to do that you can tell whether someone is writing an email to someone who is more powerful than them versus less powerful so those all different kinds of things you can do with just the patterns of words but you can also do more deep of analysis in the for example 11 application we're going to talk about a little bit later you can actually predict customer behavior based on the text another application is duplicate dr. the detection that's in town particularly exciting or sexy but the reality is that companies are being swamped by documents that are duplicates that clog up their search results that make it hard to actually use and much more difficult than actual duplicates are near duplicates and trying to figure out what the right the most official version is so there's text analytics techniques for doing that there's also text analytics techniques for doing advanced business and customer intelligence what are your customers saying what are your business rivals saying and then there's also of course the real hard effects analyst advanced software using tax on amines and ontology using library science cognitive science to develop all these applications so text analytics really covers all these different kinds of things there's there's pieces there's there's there's definitions that kind of overlap there's a famous philosopher 15 shine that talked about definitions really don't deal with precise the limitation of a concept as complex as tax analytics but rather develop something like family resemblances so what are we going to talk about today well what I'd like to do to give you an idea of what text analytics is all about before we go and dive into some actual use cases and see how it's being used in business is I want to talk about what the different from basic functionality pieces of X analytics our first one is text mining that it was NLP natural language processing where you actually do define words as objects and subjects and you define the different types of words but you don't actually get into the meaning of words it's an area that has a great deal to do machine learning and very complex statistics there's a lot of definitional conflicts probably between textbook planning and text analytics the reality is they all pretty much go together although they do call for different kinds of skills but text mining is there's a piece that's most advanced in terms of the actual techniques but it's limited in terms of its not dealing with the actual meaning of words another type of basic functionality is now in trades extraction you develop catalogues and rules for the software to go in and find all the people names in a document all the organization names the dates the methods of diseases disease states things like that and then you pull all that out and as I mentioned then you can apply various kinds of data techniques to it third big area of functionality of sentiment analysis where you again you have the software trained to go in and look for positive and negative phrases around company names product names and so forth this is an area it's already seen a huge hype cycle we everybody jumped on the bandwagon they started just looking for big catalogs of positive and negative words look you know the word love is next to our company therefore they're saying positive things well it turns out the the first round of sentiment analysis didn't work very well it was written almost just a little bit above chance we developed since then much more sophisticated techniques for really understanding the context around those those positive negative phrases and I'll show you some examples of those as we go on memorization is another technique where the software will go in and look at like a thousand page document and create a two or three page summary out of it and that enables people then to scan information in intelligent ways but also not having to read the entire document this is something that's been somewhat underutilized but it's also corrupt something that people are now beginning to combine with things like not just creating an abstract summary but creating a narrative describing a document or do scribing the results of anything from a financial analysis to a baseball game and so people people's brains are really tuned to stories we pay attention to stories we remember stories and so that's another use for this type of summarization and then there's a whole area of fact extraction where you have on policies oncology's as a sort of recovering philosophy major I have to admit our somewhat dismayed that the word ontology was being taken over again but it's okay I've gotten over it but the reality is an ontology is a model and it consists basically of triples the other subject and object in a relationship and that sounds simple but and it is but you can create really really complex models of various kinds of environments and so the software then can go in and not just extract a single noun phrase but can extract relationships between entities between companies and people and events and so forth and then the last piece for functional effect analytics is auto auto classification typically this is again based on an ontology or taxonomy some kind of a structure and auto classification it's it's somewhat of a misleading word and that it's basic functionality can be used for writing things one of which is automatically classifying documents but the reality is that this is the real heart of text analytics this is the brains of the outfit on a classification the functionality is something that can actually be applied to all the other areas of text analytics and make everybody else smarter so this is a piece that's really the heart of the foundation okay so enough about abstract definition and personalities and so forth let's try to take a look at two case studies that we did over the last few years to try to make this a little more concrete a little more specific okay the first one mostra company BAM doctor all communication service provider and they provide services to all the telecommute telecommunications companies so what they needed to do was to create a platform or to solve multiple issues and to provide multiple services to their clients so yes they looked at categorization we looked at into the extraction we looked at centen analysis we also have to look at the different languages not everything is written in English we tend to think it is but but there's other languages just as important for business as well particularly for giant companies like telecommunications company the content that we were looking at were two basic types one was customer support notes those are notes that customer support reps are typing while they're on the phone and we'll talk about what that means later and then the second piece of social media forums around telephone company forums product forums where people are doing expressing their opinions discussing various aspects of telecommunications products and services and one of the key parts of this project was that the scalability issue was such that we were looking at literally millions of documents or French fragments of documents a day and so we had to come up with a solution that would work for all that so a check approach we had to develop was a very deep understanding of the content which enables to build new applications we're looking at things like why were people calling or one of the different motivations we actually defined about 30 different motivations that might prompt somebody to call we had to look at both direct and indirect sentiment and we also this is where we did our first behavior prediction project australian example of that effective but what i want to mention at the categorization of these these customer support notes again the scale is such that it really really need to have a senate semi-automated or automated solution using software such suck the same kind of software for example that smart logic applies and so this this was a key part of the project and it also meant at the customer support not only had which amounts of content but the amazing spelling and grammar creative spelling and grammar that these customer support notes came up with was truly amazing you have to imagine this is somebody that they're on the phone they've got a computer screen in front of them their customer is screaming yelling in their ear about they hate this it doesn't like this and they're sitting there typing as fast as they possibly can to take it all down so you can imagine the kind of spelling errors so what this meant was for us is that we had to develop a different type of tech text analytics rules that separated the logic from vocabulary and I'll show you an example that as we go on but first i want to show you this this is a brief hint of the kinds of variations that we came across so on the right you had the department names their spellings on the left different customer spellings now this is actually only a small part of what we found for customer and customer wasn't even the worst word the worst word we came up with for this project was the first two thousand customers sport notes we looked at there were 40 different spellings of the word transfer so this is not something you can build a little dictionary and and everything works you have to you have to have a constantly updated list of these creative spellings and keep that separate from the logic of the rules so what were some of the things that we could do once we could analyze the customer support that's well one doesn't say we could develop ways to understand the call motivation and figure out how to analyze what the trends in call motivations and so forth but the most exciting application was actually predicting customer behavior based on these notes and what they wanted to do was just distinguish between people who are calling to cancel their entire accounts versus one accounts on one phone but they want to do the entire account versus those people who are you're just calling to threaten and to do this you to do a pretty sophisticated analysis of the text but more importantly the context around text so the first thing we had to do is look at is this call about canceling an account and canceling an entire account and so that was a fairly straightforward text analytics problem we had to look at all the text words that meant canceling an account I'm gonna come up with rules to do it but then the second piece was does the text also contain what we call bargain words so what do we mean by that well here's a couple of samples so then the first one the customer called to say he will cancel his account yeah that's pretty straightforward to find that if he does not stop receiving a call from ad agency well there's that bargain word in the middle if that bargain word tells you that this person isn't really calling to cancel their account what they're calling to do is stop getting a call from an agency same thing in the second example on CC I by the way is another spelling for customer the customer is upset that they have discharged and wants it off or and that's the bargain word they're going to cancel their account and so we developed rules that would look for both the words that indicated cancelling out but also bargaining words in relationship to those so this is a kind of advanced application you can build all right second application we developed for them was against social media and this is something that there's been a hot area in text analytics recently the last few years and as I mentioned before the big issue right now is going to that next generation of social media analysis beyond just simple good and evil positive and negative but we're going to look at degrees of intensity of emotions complexity of emotions and and complexity of documents and so one of the ways to do that you have to look at the context around specific words and phrases so one of the key things to look for things like a rhetorical reversals I was expecting to love it so if you've got obviously actually the word inch by the way and that it's another problem for text analytics is you have to do this kind of co reference resolution to figure out what it refers to but let's say I was expecting to love the new camera well if you do a simple text sentiment analysis of that and just looking for positive and negative words you see the word love you see the word camera up great they love our camera the reality is of course the next trays is going to be something like but I really hate it because it doesn't have this feature of that feature so you have to do this this contextual relationship not just look for words this involved both categorization and concept extraction to really do well it also involved using new taxonomy is called appraisal taxonomy and emotion tax office so for example the phrase not very good is made up of three basic components the word good and that again there could be hundreds and hundreds of different words for the word good and then that so that's that's the basic attitude then you have the qualifier very and that gives you indications for intensity and again there's lots and lots of different ways that that very intensity can be described and then the third piece of course is the the negative that turns at all completely around and so we had to develop those kinds of models as well in addition we actually had to model the users in the communities to a much greater degree than in other applications so the social media part was we're looking at and say forums around telephone usage and to figure out what people were saying one of the things for example that you can do with this kind of analysis is not just you know our our customers happy or unhappy but what what exactly are they unhappy about you've used it to uncover or discover you know potential problems in your your product before they really become out of hand and take your appropriate action before that happens so that's a fairly common application for social media so this is an example of a screen for example looking at the words very dissatisfied and as you can see underneath there's lots and lots of different words that are in that general category of very dissatisfied and so you can use the software to look at all those different variations you can also use other software components like looking at narrower concepts that are aren't quite the same but but are related and so this is the kind of text analytics application screen you would develop your rules on to analyze the sentiment okay though at the first youth gates and since we got a late start I'm going to try to rush through a lot of this but the second case wanted to talk about was the company or barrier it's a pharmaceutical company and what they're looking at were how to get more value out of the scientific journals that they all subscribe 20 the problem is that scientists are struggling to keep up with all that literature there's multiple journal types there's a variety of formats some had metadata some didn't all different kinds of subjects and styles so even though they're all so-called science journals the actual amount of variety was pretty amazing and of course at the time they had a pretty poor search which is not that's almost kind of redundant enterprise search is something that's been struggling for many many years and they were struggling as well and what happens of course is that because of that bad search researchers are wasting the enormous amount of time and even more importantly they couldn't really use those journals to discover new ideas and build new applications okay bill what do we do for them well first step almost always in text analytics is to create a structure that can call it a taxonomy incall an organizational schema can color can be an ontology there's a lot of different words we can use there the reality is you have to model the domain somehow or other and this particular case we actually did what's a very good technique by the way in text analytics which is don't try to build anything anything from scratch if you can beg borrow or steal it from somebody else so in this case we use medical subject headings mesh when you use a subset because it's way too big for the kind of categorization that we wanted to do and this by the way also is a general rule giant taxonomy is that are the book they're developed in order to index every possible concept and dr. it don't work very well when applied to text analytics you need to trim them down you need to do restructure okay so the second piece we we developed the way a faceted search application and then faceted search is becoming pretty much the standard enabling people to sort by date by author by journal instead of having to refine their query which of course they don't do and then that that faceted search is being at the one piece that's really made search done begin to work the problem with faceted search is it requires an enormous amount of metadata and so what we did we built entity recognition and to the extraction capabilities to go in and pull all that those that information out to stick them into the various facets facets things were in this then what they're interested in were things like species on the document the study type the drug and disease named adverse events and so forth and so once once that all those facets were populated using text analytics then search could be you could develop a cert that would really enable people to find what they're looking for by making simple self selections out of the facet and also using what they already knew about what they're looking for in ways that they really don't if you have to type out some complex search query so one of the key parts of this particular example was that we use the categorization rules to actually define sections in the documents now we talked about unstructured text all the time the reality is there's no such thing there is no such thing as unstructured text it all has structure first of all it's made of letters and then letters are made of work make make make up words and phrases and sentences and paragraphs and then when you get beyond that those are pretty straightforward but when you get beyond that almost all documents are of a certain size are going to have sections of some kind or another and so what we did we develop rules that would look across the range of different journal types of and some of them might call it an objective section for example one one of the sections we use some might call an abstract a purpose a name the reality is that those sections are all pretty much the same and the other reality is that once you define those and you're using the text analytics capability to dynamically define them once you do then you can you can use that section structure to wait and explore the different words and documents so the result was a faceted search application thread by text analytics smart entity extraction and Vance categorization so let's take a little closer look what that meant so for example I'm looking once you define this section you could develop much more complex rules so in this particular case for example what you're looking at is a rule that says okay if this article has these sections and we define one section as abstracts one sections methods and the phrases in those sections match things like all the different words for clinical trials or all the different worlds words for humans but not words that had to do with animals within five words of those clinical trial phrases so it sounds fairly complex but it's actually pretty stable kind of a rule and the point is that once you develop that rule then you can count the words in those sections and weigh them more heavily so what this means is you're basically developing a relevancy ranking algorithm that is way way way better than simple search engines counting up the number of times the search term shows up in a document which is a pretty pathetic way to try to figure out what a document is about this gives you much more powerful ways to figure out what a document is about another example would be where you know you find any variation of bug name in the title of course we all that's easy to do but then a variation of the drug game in the keywords and in one of these sections or you find it two times in this section then counting is hit and weighted heavily so these kinds of rules particularly win again when you separate the logic from the vocabulary these kinds of rules can be very very stable and way more powerful way to to evaluate the relevancy of particular search terms but in addition we also had to do it we did some entity extraction as well and that actually some in some cases anti detraction fed into facets in other cases who could use it to actually feed into the relevancy ranking of the application as well and one of the big issues here is distinguishing between major mentions of something so if you're looking through a scientific journal and you're looking for particular diseases you might find dozens of diseases that are really just mentioned in passing and so you want to throw those out now mention in passing doesn't necessarily of course mean that they're only mentioned once where the key term is mentioned three times now it's way more sophisticated than that and so you have to develop these rules that determine whether a disease is mentioned is a major enough mentioned good to make it into the rule second big piece of that was disambiguation and for disambiguation you need to have in a way of analyzing again the context around words so the simplest example would be when we are a lot of us I'm use a lot is the word for word ford can be a company it can be a car it can be a person and it can be a way to cross a stream so the way you have to do what you have to do to distinguish and disambiguate which one it is in that particular text is look at the context around so if there's a whole bunch of company business concepts around the word for then then most likely it's going to be afford the company if there's there's all sorts of car park kinds of terms then it's a car so when you do this kind of analysis and combine the extraction with these kinds of section based rules we ain't by the end of the pilot we ditch them we are actually getting close to one hundred percent accuracy and this is an example of how some of that might work so you develop rules and you can see over on the left you've got these specific words but the words can be expressed in a lot of different ways and then over on the right you see actually rule-based that is constructed by the software that gives you a starting point for developing your own rules and so we don't have time to dive into the the screen too deeply but basically the idea is that this is this is this is the kind of this is standard kind of text analysis development environment and this is particularly good because say it does develop those those base base rules and it also gives you the ability not just to look for individual phrases individual words but all the different variations I mean diabetes for example sound ok it's a simple straightforward know the reality is there's a lot of different ways that people use a lot of different words that people use to describe diabetes and so the software gives you a way to organize that classify and then develop the rules I'm it also viewed this is what we meant or the fats a search using the ability to go in creative good faceted search based on entity extraction it enables you to pull out in this particular case all the different mentions of gastric cancer and again you can develop rules this that distinguish major mentions from minor mentions these can be just combined with those facets that we see over on the left okay so what would may discount this project of the test the first piece was as i mentioned making using those base rules that the software starts that software creates as a starting point one of the big tricks in text analytics is how to get started and if the software can help you get started then you're way ahead of the game number two was using the text analytics to utilize all the semi-structured elements that you find in documents so instead of treating him as they called giant bag of words we could use that semi structure 3rd really key part as i mentioned was separating the logic from the terms the terms change all the time but you don't have to change your whole structure every time you find a new term that those are kept separate they're fairly straightforward very kind of thing so the new term comes in you just simply add it you don't have to go back you don't have to restructure things and it becomes much more of a stable it becomes less less what we call brittle rules where everything lunch and everything breaks when you have new content so if you do all these pieces then some art semantic search can work it also gives the ability to model in mind the semi structured content which can result in a range of new applications and that's what we're going we're doing now with that company is developing those new kinds of applications based on top of search engine so in summary to leave a few questions first of all text analytics really should be looked at as a platform for multiple applications I mean if you're just interested in doing social media analysis or you're just interest in doing Enterprise Search I mean that's fine but the reality is text and links really is a platform it can be used for all these applications and the way to get the most value out of text analytics is approach it as as a platform not just one particular application one of the big New Directions in exile eggs right now is the integration of text and data and going back to the big data and Big Tex we're figure out ways to combine the methods of analyzing both of them and combining enterprise content with social media content because the difference between them is blurring and blurring and so in the big directions is integrating all the above lastly it or not less but it's important to remember that language is really messy and complex and we will learn it but it takes years and years and years and the reality is to take advantage of this messy complex thing we call language you really need to have these kinds of text analytics tools and expertise in looking at the the ability to look at contacts the ability to create structures with power the text analytics so what you need to succeed what we found in our work with a lot of different companies in order to succeed in text analytics you need first a strategic vision of what the text analytics can do for you and your organization that requires a fair amount of research but you don't want to spend too much time on research without getting direct business value so you also need a quick win so one way we do that and our work is we do this sort of three step process and we create a quick win as an output of the analysis the research another thing you have to do with text analytics is it really does require interdisciplinary skills need IT business information pros third thing you need and this is something that's getting better and better and better is creating modules that can be reused that can be combined in different ways that it can be you can you can one model module for example might be used to just find disease states well then you want you have that working really well you can combine it with other modules you know there's lots of an example of the pun module for for beating jeopardy was was I thought was was great and 11 module was only devoted to looking for parts so when you create these kinds of modules then you can develop much more intelligence almost human like brain Oh clinal II then success in text analytics can is the platform that enables you to get to use new resources ie unstructured text that's sitting around doing being underutilized right right now text analytics enables you to actually get value out of all that unstructured text it also enables you to have new insights into text again or into your your your business into communication by developing these kinds of rules that open up new avenues for understanding what's going on inside documents in new ways and once you have that then you have a whole range of new applications that can be built on top of it like that behavior prediction and so with that let's open up questions and by the way if you do have more questions after one last little plug I booked text analytics how to conquer information overload and get real business value from social media is as soon as we finish here today I'll go back in and almost finish it up it will be short coming in a few months from information today we're back thank you okay thank you very much tom we do have a number of questions and really really good ones the first one is directed at you can you talk a little bit about the amount of ongoing tuning and maintenance that's required for a system like the one at bearing or one assumption that's made in this questioners place of work is that these things will run themselves and competing assumption is that these things take too much upkeep to be worth the investment what what is your experience been well that's that is a great question and my experience is again if you approach it in the right way ie you develop the kinds of general-purpose rules and and then if I separate the logic of those rules from the vocabulary you can actually develop rules that don't require a lot of maintenance on the one hand but on the other hand the idea that the once you build them they're just going to be running for years all by themselves is not realistic either I mean you do need to constantly monitor what's coming in in terms of the content because the content is going to change and and if your rules are developed in the right way they won't have to change very much but you do have to be aware that certain expressions and one of the nice things about text analytics is you can actually develop tools that are separate from the actual application that are just designed to do that they're looking for new words new usage new patterns i mean people start calling you know a particular business picking business for example the business concept the words change over time and so you do need to monitor some but but if you do it right you don't have to be constantly updating the rules I would add to that that you know ontology zar a living thing on as your business changes the concepts change as new advancements are made in in pharmaceutical research there are going to be new concepts that that bearing or will want to to be tracking so there's always going to be some level of upkeep you can't just set it up and have it run forever because it's essentially a representation of your business and your business does change on the other hand as tom says if you do it intelligently it requires some level of effort but but not a huge level of effort and that actually leads to kind of a another question that was asked which is how do you get executive support how do you get people to realize that these things while they may take some upkeep are worth the investment yeah that's that's a good question as well um the quick glib answer is well you hire me and I'll help you know I'm just K now the reality is that text analytics is complex and some parts of it are pretty straightforward to sell the value that's one of the recent social media became such a hot item being able to listen to your customers and what they're saying is pretty straightforwardly obviously a big win a lot of the other applications turn out to be more productivity gains and search for examples is the classic example you know exactly they say oh well somebody searches a little bit too much so what you know they'll just go get a cup of coffee or whatever but the reality is that what you need is to get executive support is again that strategic vision what is what is texn one is going to do in your organization and the best way that I found for getting support is as I mentioned is looking at text analytics as a platform saying here's oh here's all the things it can do but on the other hand that's pretty abstract and so what we've done is for example we when we're helping a client for example figure out what text analytics software to buy in the first place one of the ways that we do that is by doing like say pilots where you use the pilot to create a quick win so they actually see a functioning application that they can understand and at the same time if it's done well not only have you created a little quick win an application that you can point to but you've actually also trained people within your organization to continue to build bill and so so that's those are those that's how we found it gets a good way to get an executive support but yeah it's it's something that that's it's not straightforward you have to really spend some time thinking about it yeah you absolutely do and I go back to these two examples and I think that the reason that they were able to garner executive support was was very very clear in the case of amdocs the objective was to to provide tools that would help the telecommunications companies reduce churn in order for them to be able to figure out exactly who was I was threatening to cancel their account whether they were really threatening to cancel their account or they were actually bargaining for something that they wanted and so on and so forth and since telecommunications companies measure themselves one of the industry benchmarks is the level of churn then what they're doing is they're they're not saying we're going to create this text analytics platform they're saying we're going to we're going to solve a problem for you around preventing churn and in the case of mooring or angle haim I think it's very similar they actually wanted to speed up the the drug development cycle the research cycle which you know depending on who you read costs anywhere from one to four billion dollars for every drug that reaches the market they wanted to make their their scientists more effective so that they could spend more time doing their own research and less time actually reviewing other people's research I think the key is to have a clear business outcome that you're looking to improve and and not just trying to make the data prettier there are a couple of questions here before we end that are focused on smart logic so time with your permission I'm going to answer those one questioner has asked if smart logic smart logic has its own search engine or do we work with other search engines and the answer is smart logic does not have a search engine it works with all of the major search engines ah with you know out of the box integration to things like Google Search Appliance and solar and so on the objective of smart logic is to provide the metadata that the search engine can then use in order to be able to provide a much better quality user experience and we also provide the plug the plugins that will allow you to create faceted search for example what Tom showed a couple of slides ago and the other question is do you build the analytics and smart logic or do you use a different tool arm and the answer to that is it depends on what kinds of analytics that you're talking about if you're talking about the the analytics and the rules that you use to extract the facts that you use to classify and and and and apply metadata to the information assets then that is within smart logic what we're finding is that a number of our customers are actually taking facts from the from their their unstructured information assets and importing them into other tools graph databases and whatnot in the form of RDF triples in order to be able to do much more sophisticated analysis of the fact so we are essentially providing the fodder for those other analytics tools to work and with that I think we have time for one last question and that would be for you Tom what do you think the optimal composition of staff is for a project like this that's a very good question and the answer course is it depends it depends on the company it depends on the first application so forth but but but it can sit a deeper point which is that as I mentioned earlier text analytics is really interdisciplinary and what I found for example is that if it's just looked at as an IT project then and it's probably not going to work very well it's going to fail if it's just looked at justice as a simple business project it's not it's not going to work either because when you're dealing with language it's different and when you have if it's like run by the library that tends to be a little bit better but there's dangers there too with you know librarians that sort of think of everybody else in the world as librarians as well and so the reality is that what you need you need IT people obviously you need business people and you need information professionals people that understand language or information structure and what exactly how you fill those roles that really will depend on on your company it might be you know for large companies you might have you know a department of four or five people that are devoted to text analytics that includes some of the above that work with these other departments for a small company it might be you know one or two people doing it so so it really varies but the important point is that it requires communication and integration among at least those three different groups okay well thank you very much we will add any additional questions respond to any additional questions an email I want to be respective a respectful of everybody's time we appreciate the fact that you hung in even though we are in even though we are we started a little bit late today we will be we will be distributing a PDF of the presentation materials and a link to the webinar recording after the fact and I encourage you all to read Tom's book when it comes out and if you have any additional questions you can contact a info at smart logic calm for additional information thank you very much 