 Dear Fellow Scholars, this is Two Minute Papers with Károly Zsolnai-Fehér. In an earlier work, we were able to change a photo of an already existing design according to our taste. That was absolutely amazing. But now, hold onto your papers and have a look at this! Because here, we can create something out of thin air! The input in this problem formulation is an image, and the output is an image of a different kind. Let's call this process image translation. It is translation in a sense, that for instance, we can add an aerial view of a city as an input, and get the map of this city as an output. Or, we can draw the silhouette of a handbag, and have it translated to an actual, real-looking object. And we can go even crazier, for instance, day to night conversion of a photograph is also possible. What an incredible idea, and look at the quality of the execution. Ice cream for my eyes. And, as always, please don't think of this algorithm as the end of the road - like all papers, this is a stepping stone, and a few more works down the line, the kinks will be fixed, and the output quality is going to be vastly improved. The technique uses a conditional adversarial network to accomplish this. This works the following way: there is a generative neural network that creates new images all day, and a discriminator network is also available all day to judge whether these images look natural or not. During this process, the generator network learns to draw more realistic images, and the discriminator network learns to tell fake images from real ones. If they train together for long enough, they will be able to reliably create these image translations for a large set of different scenarios. There are two key differences that make this piece of work stand out from the classical generative adversarial networks: One - both neural networks have the opportunity to look at the before and after images. Normally we restrict the problem to only looking at the after images, the final results. And two - instead of only positive, both positive and negative examples are generated. This means that the generator network is also asked to create really bad images on purpose so that the discriminator network can more reliably learn the distinction between flippant attempts and quality craftsmanship. Another great selling point here is that we don't need several different algorithms for each of the cases, the same generic approach is used for all the maps and photographs, the only thing that is different is the training data. Twitter has blown up with fun experiments, most of them include cute drawings ending up as horrifying looking cats. As the title of the video says, the results are always going to be stunning, but sometimes, a different kind of stunning than we'd expect. It's so delightful to see that people are having a great time with this technique and it is always a great choice to put out such a work for a wide audience to play with. And if you got excited for this project, there are tons, and I mean tons of links in the video description, including one to the source code of the project, so make sure to have a look and read up some more on the topic, there's going to be lots of fun to be had! You can also try it for yourself, there is a link to an online demo in the description and if you post your results in the comments section, I guarantee there will be some amusing discussions. I feel that soon, a new era of video games and movies will dawn where most of the digital models are drawn by computers. As automation and mass-producing is a standard in many industries nowadays, we'll surely be hearing people going: "Do you remember the good old times when video games were handcrafted? Man, those were the days!". If you enjoyed this episode, make sure to subscribe to the series, we try our best to put out two of these videos per week. We would be happy to have have join our growing club of Fellow Scholars and be a part of our journey to the world of incredible research works such as this one. Thanks for watching and for your generous support, and I'll see you next time! 