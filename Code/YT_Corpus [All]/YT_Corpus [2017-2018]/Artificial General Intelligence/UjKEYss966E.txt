 Seven years ago, I started a company called DeepMind Technologies. The mission of DeepMind was to solve intelligence, to try to take what it is that makes us unique and special and creative as a species and reproduce that in an algorithmic construct, and, of course, to take that and reproduce it in an algorithmic construct that we could use to make the world a better place. That's the second part of our mission. But in order to do that and to tackle something so, you know, unique in many ways, we actually believe we have to create a hybrid organization, one that puts research at its heart and takes the very best from academia, with its focus on long-term, hard research questions, and combine that with the pace and the scale of a company, but all the while, underpin those two values, those tendencies, with a social mission. And in many ways, if we could try and bring together the very best from these three different types of organizations and incorporate them within a new culture, in a new structure, we believe we have a chance to really focus on some of the world's most complex and toughest social problems and develop general-purpose learning systems to help us make progress in these kinds of environments. And the reason we're so focused on not only the challenge of technically solving intelligence, but also the challenge of bringing to bear the best of those algorithms in the real world to make a difference on some of our most challenging problems, and thirdly, simultaneously combining that with a new type of organization, is because we believe today that in some sense capitalism in many ways has delivered so much for us over the last couple centuries. We've delivered so much progress. No other construct or idea has been able to distribute benefits so broadly and so rapidly. And yet, in many areas, as I hope to persuade you in the next 15 minutes or so, capitalism is currently failing us. We actually need a new kind of set of incentives to tackle some of our most pressing and urgent social problems, and we need a new kind of tool, a new kind of intelligence that is distributed, that is scaled, that is accessible, to try and make sense of some of the complexity that is overwhelming us. And that is the overriding challenge that I think we see today. We're being overwhelmed by the complexity of the systems that we have created around us. Whether it's the challenge of modeling our financial systems, taming them, making them serve the interests of the many and not just the few, whether it's the challenge of modeling our climate and trying to predict the likely trajectory of our weather systems over the next three decades, or whether it's the challenge of making cheap energy available in a renewable way to everybody, the complexity of our systems is, I think, what's holding us back. And if you just look at some of the key trends, 800 million people don't have access to clean water today, and, in fact, contrary to a lot of popular default opinion, that is, in fact, going to more than double over the next decade. 800 million people are malnourished, and yet almost a third of the food that we produce every year goes wasted. What does that say about the mechanisms and the incentives that we've created and evolved over the last thousands of years of our species to produce and then distribute our surplus value? In fact, it would take 3.1 planets' worth of resources if all of us across the world were to consume at the rate that we do in the U.K. How is that sustainable? What does the long-term future look like, given that default consumption rate? And, of course, the concentrations of greenhouse gasses are now higher than at any point over the last 800,000 years. On many, many fronts, we have ticking time bombs that our current system is failing to address. The incomes of the top 1% -- most of us -- the incomes of the top 1% have risen 300% over the last 30 years, and yet the bottom two-thirds of our world have seen their incomes stagnate and, in many cases, fall. Again, what is the system of production and distribution that we have created and how can we radically change that? How can we improve that to assure that the benefits are distributed as widely and as fairly as possible? We believe that in order to make progress with solving some of our most intractable challenges, we actually need to discover new knowledge. Reproducing an existing human insight and applying that in the novel example that you encounter is actually not going to be enough. We actually need to discover and learn the structure of new complex environments. And I'm going to talk a little bit about that today. We started last year with Go, something we've been working on for the last 18 months, the ancient Chinese game. On a 19-by-19 board, as you see here, two players take turns to place black and white stones. There's three very, very simple rules. And out of this simplicity emerges incredible and overwhelming complexity. So much so that typical human intuition and typical human knowledge really fails to model the game optimally, unlike chess, for example. And to give you a bit of an intuition for the size of the search base, this is what the branching factor in Go actually looks like. There are 10 to the 170 possible configurations of the game of Go. That's more atoms than there are in the universe in every liquid, solid and gas, in you and in me and in this room and around us and in the entire known universe. There are more atoms than there are possible combinations of moves on the board. And so modeling the complexity of this board well enough to be able to predict what's likely to come next in order to beat one of the best human players in the world was known as one of the greatest grand challenges left in AI. And lucky enough, last year we were able to beat one of the world champions widely regarded as a decade before its time. So just to give you a insight into a couple of the things that Lee Se-dol said after the game that show what was special about AlphaGo, he said that, "After the game, my thoughts have become much more flexible, I have a lot of ideas, and so I expect to have much more results." And what he was actually referring to there is that the game had been so challenging, AlphaGo had revealed so many interesting insights, that it had prompted him to think about the game in a new way. And, in fact, he went on to win almost all of the games that he's played subsequently. And so here what AlphaGo was able to do was to discover new knowledge. It didn't just reproduce what we had taught it from expert players, but it discovered its own intuition, its own insight. And that was extremely exciting for us because it was one of the first times that we were able to demonstrate that we could train systems to learn their own representations of rewarding behavior and fundamentally teach us what it takes to solve challenges in complex environments. The other thing that he said is that, "The union of human and computer players will usher in a new era. Together, man and AI can find the truth of Go." I think this is a really important insight because it's still the case that in many challenges -- particularly chess -- that man and machine performs better than just machine on its own. And in a couple of weeks' time, we actually play with man and machine in a festival in China with some of the best players in the world who are going to go head to head with the best machine systems in the world, and so we'll see what comes of that. And this isn't just work that we've done in research and left in research. We're very much focused on trying to apply some of these techniques to the challenge of solving some of our real-world problems. And so let me give you a couple of examples of how these sorts of algorithms are in production today and helping us to discover new knowledge. DeepMind Energy. We're approaching an inflection point in global mean temperature change. It looks like we're on track to hit 2 degrees per year. This is clearly unsustainable, and so one of the things that we've been looking for over the last couple of years are opportunities to apply our algorithms to help tackle the challenge of our warming planet. Data centers, in fact, consume 3% of global energy, and so we were lucky enough to be able to train an algorithm, in collaboration with the Google team, that was able to reduce by about 40% the amount of energy that was used to cool the entire Google data center infrastructure. Essentially, we built a model of what demand was likely to look like over a period of time and we were able to match that demand to how the physical infrastructure of the data center responded. And so with an enormous amount of sensor data, we could correlate how demand changed the physical experience of the pressure points in the set valves, the cooling systems, in this enormous piece of physical infrastructure, and optimally marry the cooling system to the incoming demand. And this is really interesting because it showed us that if we take power usage efficiency, which is the primary mechanism that is used across the data center to measure aggregate efficiency of consumption, we were actually able to turn on the machine learning system and turning it off over an hour period and see very, very substantial -- very, very substantial improvements and this is now in production across the Google fleet. But the important thing to remember about this breakthrough is that we took the existing data that had been collected for many years, used the existing hardware -- there was no additional capital investment -- the existing software infrastructure, and applied DeepMind intelligence. And that starts, I think, to give an insight into the extent to which there are enormous potential gains from taking data that has already been collected about the world around us and trying to learn new knowledge that describes the optimal way to run our physical systems and, of course, ultimately our human systems. And that brings me on to DeepMind Health. When we talk about health, people often think that the cutting edge of modern healthcare looks like this. Smart watches, robotic surgery, scans and imagery that can reveal exactly what's wrong with you in advance. In fact, sadly, the reality is that it looks much more like this. Most of the data that has been collected is actually stored on paper, which means it's really difficult to access right when you know that you need it, right at that moment when you need that opportunity to detect what's wrong with somebody proactively. And part of the challenge is that our health systems are really struggling to cope with the complexity that's burdening them. 50% of care is actually not evidence-based today, and so it's not that we don't actually know what is optimal. Most of the time we do know what's optimal and clinical best practice is available to guide us and steward us when we need to navigate a new example of a patient case. And on top of that, medical error is actually the third leading cause of death in the world. 250,000 people a year in the U.S. die from medical error, preventive medical error, and so this should really sharpen the focus on the extent to which the application of known best practice can really save an enormous number of lives. And part of the challenge that's connected to that is that we really struggle to provide proactive care. Most of our care in hospitals today happens when a clinician has already identified that something has gone wrong and they're reacting to that thing that has gone wrong. So something like 97% of that care is reactive, rather than proactive. And that's with we see such runaway costs, which we know are crippling our healthcare systems. In the U.S., 18% of GDP now growing at 5% year-on-year. So in many respects, these systems look unsustainable if you imagine where they end up in 30 years' time. And this is sort of understandable when you consider how overwhelmingly complex the day-to-day operation of an acute hospital actually is. So let me give you a cartoon version of what it feels like to work in a hospital like many of -- many that you'll be familiar with as a junior doctor. What you typically hear is that pathways are the solution. All you have to do is follow best practice. A patient is admitted, whether by ambulance or recommended by their GP. They're given some kind of history or examination. There's a further investigation. It's identified that they have appendicitis and so they're given some antibiotics and they're admitted to surgery. And so now our doctor has to remember, for an appendicitis patient, what are the optimal sequence of tasks that should happen to that patient during the course of their admission. And she has to remember for that patient the right time and the right place to do exactly the right thing. But of course our patient also has an underlying co-morbidity of asthma. Whilst they're in, it's noticed that they have an allergic reaction to the antibiotics that they've been given. And after the surgery, it turns out that they have a wound infection. So each one of these events triggers another set of clinical best practices that should be followed, another pathway that needs to be implemented at the right time. And so now our poor doctor, junior doctor, has to remember five pathways to implement the best practice for this one patient. But, of course, she's also responsible for at least eight other patients and she has to now coordinate all of the things that should happen for each one of those patients, for each one of those pathways, along with porters, nurses, senior doctors, consultants, managers, and so on and so forth. And so, in fact, this is an incredibly complicated planning and prediction problem. If you think about it, each one of these circles that have been identified represents a unit of clinical activity -- a test or an intervention or a task -- that should happen in the right sequence at the right time, given full visibility of the entire system. And so we think that this is a real opportunity to deliver the kinds of benefits that we've seen elsewhere in the application of our machine learning algorithms to drive improved efficiencies and more proactive treatment. And that's why we developed Streams. Streams is a tool that simply takes all of the existing data and tries to generate intelligent alerts that prompt clinicians to respond and intervene much earlier than they otherwise would in the system. And at the moment, we've been focused on the particular condition of acute kidney injury. One in four admissions in the U.K. is related to an acute kidney injury, and something like 40,000 people a year are dying with acute kidney injury as a major complication. In the U.S., 285,000 people a year are dying with AKI as a significant complication, costing on the order of 5 billion a year, but the incredible thing is, that around a quarter of these deaths are entirely preventable. Very often, the primary intervention that reduces or even prevents an acute kidney injury is the application of intravenous fluids and antibiotics, one of the cheapest, fastest, simplest interventions that you can make in a system. And so there's an enormous opportunity to try to detect when somebody's likely to get an acute kidney injury, prompt a clinician to intervene proactively, and hopefully do something about this incredible number of entirely preventable deaths. And I think this is quite important to put in context. 30,000 people a year die from road traffic accidents, and so, you know, whilst we focus on some of the exciting and wonderful opportunities that there are in self-driving cars, I think it's also important to remember that there are many, many other opportunities to have a dramatic and improved impact on the lives of many people across the world with our technologies. Another example of some of the technology that we've been developing is for 3D eye scans. 3D OCTs, as you can see here. One in four people in the U.K. are obese, and if you're obese, you're 40 times more likely to get diabetes, and if you have diabetes, you're 25 times more likely to suffer some kind of sight loss. And yet the incredible thing about this explosive growing condition is that 98% of the most severe forms of sight loss are actually entirely preventable. If you can detect early that one of these scans shows signs of onset of diabetic retinopathy, then you can use very cheap treatments -- injections, periodic injections -- that actually reduce enormously the probability that a patient contracts some of the most severe forms of diabetic retinopathy. And we've developed algorithms, although with other teams, that try to do that kind of early detection. But, of course, in order to make progress with these sorts of problems, we need access to an enormous amount of data, and at the heart of the challenge of data is the question of transparency and trust. So of course the first thing is to try to demonstrate utility. We're very much focused on trying to explain that these algorithms can have a massive opportunity to improve the world around us. But trust is also critical, and I would argue that trust is a function of transparency and control. Transparency, I think, can, in part, come from technical oversight. One of the things that we've been extremely hard at work developing is what we call verifiable data audit. For any data that sits in our ecosystem, it should be possible to say exactly who has had access to that data for how long, for what purpose, and under which policy. And we should be able to enshrine that validation with the proof of cryptography, which should output a ledger that describes exactly who has interacted with that data set that can be scrutinized by an independent third party, fundamentally underpinned by the proof of mathematics. And for that independent third party, for the time being, we've brought together a panel of independent reviewers to scrutinize DeepMind Health in the public interest. They are unpaid, uncontracted, they haven't signed an NDA, and we've invited them to look at any of our commercial documents, our product roadmap, to look at our technical infrastructure, to look at our data sharing agreements, and we've asked them to say what they like publicly about us. They can interview anybody on my team without me there. They spend time in our office. And we've actually given them a budget to hire independent technical oversight to come and look at our data center infrastructure, to review our governance. And we think that experiments like these are what it takes to try to make progress in some of our most complex social challenges where, in fact, demonstrating utility requires us to get access to vast amounts of data, which, in turn, requires to us build a new relationship of transparency and trust with the public. So as I've tried to make clear, our social mission -- using AI to make the world a better place -- is what really has been motivating us over the last seven years at DeepMind. We've made incredible progress with machine learning systems and AI and we believe that it's a really powerful tool that can help to massively improve our world, provided it is managed and stewarded for the benefit of everybody. We think it can help us to tackle some of our most pressing and complex challenges like the examples I've tried to give in health and energy systems, but ultimately we know that we'll only succeed in partnership. That's always been our model. And that's what's going to drive us in the future in the coming decades. Thank you very much. 