 Greetings Professor Falken, Shall we play a game? Machine learning, neural networks and deep learning are all buzzwords in AI circles. But essentially they’re all referring to the attempt to teach a computer to recognize a dog in any photo, or translate a language in real time, or… lots of other tasks To do that, engineers present a computer with a lot of data, and teach it by repetition; similar to teaching an animal a trick... encourage it when it does well, and discourage it when it’s wrong. Eventually, the AI will get better at facial recognition or predictive text, or… whatever! But the thing is, even if it can spot the dog, the computer has to do the calculation every time. It has to scan every pixel and check everything. It can’t anticipate what you ask, it can’t realize that usually the dog is here or there in the photo… They don’t work that way. Until now. Engineers at ‘DeepMind’ -- Google’s AI system -- wanted to give their computer a memory. As in, the ability to remember the tasks it had done before… and learn from its success and failures on those tasks. They did this in… sort of a funny way. They taught the system to play Atari, and published a paper on their findings. I love science. It makes sense! Video games are about learning new skills through repetition and failure. You have to build on what you learned! As the game progresses, requirements usually grow in complexity, and have to be combined with other skills… All that requires memory, and the understanding of the tasks you’ve completed before. But AI still needs lots of repetition and data to learn. So, they made the computer play each game 20 million times. Then, because they added the ability of the machine to remember what it did before... Deepmind could apply what it learned playing Pong to playing Fishing Derby, or Kung-Fu Master. AI is already good at playing other games, like Go and Chess -- but it looks at the board, and then calculates the best options for each move. Each time. Imagine if a computer could keep things in mind when learning to solve a new problem, like realizing opponents trained by certain teachers would always try some special move. Or more practically, realizing you always take the same route home, every day. It gets a little freaky… Do we want machines to be able to learn? To anticipate actions? To be able to get set in their ways over time? Bae Stephen Hawking said artificial intelligence will be ”either the best, or the worst thing, ever to happen to humanity.” But as of now… AI ain’t ready. It had to play those video games 20 million times. Even the most hardcore Atari gamers never approached that and they’ve mastered all those games. Over time, AI learns and then it just… does it, but unlike life it doesn’t have the ultimate motivator… It wasn’t programmed to die if it fails at gathering resources. It wasn’t programmed to reproduce… It’s just a machine doing a simple, single job. Even though now, AI might acquire memories, we probably shouldn’t read too much into it. Jerry Kaplan, a futurist and computer scientist wrote in the MIT Technology Review… “The robots may be coming, but they are not coming for us—because there is no “they.” Machines are not people, and there’s no persuasive evidence that they are on a path toward sentience.” Are you still freaked out by AI? Cause you shouldn’t be. Watch this video right here to learn why and also let us know in the comments what you think about all this stuff and come back for more episodes. 