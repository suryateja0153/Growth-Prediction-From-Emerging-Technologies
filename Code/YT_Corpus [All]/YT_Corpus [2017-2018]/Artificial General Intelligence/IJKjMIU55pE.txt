 “So once I added your RSS feed to our site, every single article that is published on Vox.com is getting sent through a feed and we’re just like automatically creating a video for it.” “Oh my god that is so crazy. Every single article through our feed.” “Every single article.” This is Wibbitz. It’s one of the companies automating news video production. You might call this the robot coming for my job. “So this article, our algorithm will just intelligently summarize it into just a quick 30 second to 1 minute video. And then based on the keywords in the article, it’s gonna match relevant media to it.” It’s pretty impressive when you think about all the ways it could get confused. “In the beginning it was very rough. People with the same names would confuse it. Turkey the country and turkey the animal would be another example.” Their product was built with machine learning algorithms, and it became more accurate over time. The result is a video made in a few seconds that’s not drastically different from what a human would make in several hours, given the same constraints. Wibbitz is part of a rapidly growing industry of so-called “AI-powered” products. The number of companies mentioning artificial intelligence in their earnings calls has skyrocketed in the past 3 years. But the truth is that the term “artificial intelligence” isn’t very well defined. “What happens with AI is that initially lots of things are called artificial intelligence. It used to be the expert systems; the kind of systems that fly airplanes were called artificial intelligence. Then once they were working and routine and everyone takes them for granted, then they are not called AI anymore.” Right now when people talk about AI, they’re mostly talking about “machine learning” - a subfield of computer science that dates back at least to the 1950s. And the methods that are popular today aren’t fundamentally different from algorithms invented decades ago, So why all the interest and investment right now? I asked Manuela Veloso, the head of the machine learning department at Carnegie Mellon. “You have to understand that there is something very important about these past years. It's data. We humans became collectors of data. Fitbits, GPSes, pictures, I mean look how much credit card purchases, how much data is around.” Certain machine learning algorithms really thrive on big data, as long as computers have the processing power to handle it, which they do now. If computers are the cannon and the internet is gunpowder, these are the fireworks and they have only just begun. In his book, Pedro Domingos offers a nice simple way of understanding supervised machine learning. He says: “Every algorithm has an input and an output: the data goes into the computer, the algorithm does what it will with it, and out comes the result. Machine learning turns this around: in goes the data and the desired result and out comes the algorithm that turns one into the other.” The algorithms are trained to find statistical relationships in the data that allow it to make good guesses when presented with new examples. That means we no longer have an easy rule for what kinds of tasks computers can and cannot do. “Ten years ago, I could have said with confidence, we know how this works to computerize something you need to understand all the steps, then you script the steps and get a dumb machine to do it and just follow mechanistically the process that you would have followed. But now we have machines, I shouldn't say we, I don't make them. People have developed machines that learn from data. That makes it harder to say what set of jobs are going to become substituted, readily substituted by automation, and which will be complemented.” A study by the McKinsey Global Institute gets at this question by looking at the many tasks that make up 800 different occupations. And they grouped those tasks into 7 categories: 3 that are highly susceptible to automation with currently-demonstrated technologies, and 4 that are not. “Things like managing people, they include things like creativity, they include things like decision-making or judgment. And caring work that requires empathy or human interaction, with an emotional content to associate with it. Those are much harder things to automate.” The report concluded that while most jobs include some tasks that can be automated, less than 5% of occupations can be fully automated. “So this idea of occupations and jobs changing may actually be a bigger effect than the question of jobs disappearing, although of course, there are some jobs that will disappear or at least decline.” That’s because most jobs are made up of a bunch of different tasks and most of today’s AI can only do one task. Don’t get me wrong. They can be really good at that task. A deep neural network watched 5000 hours of BBC news with captions and now it can read lips  better than human professionals. And machine learning algorithms trained on images of tumors can predict lung cancer survival better than human pathologists. The mistake is to assume that these focused applications can add up to a more general intelligence. Or that they learn like we do, which is simply not the case. When they get the right answer it’s tempting to assume they understand what they see. Only when they make a mistake do we get a glimpse at how different their process is from our own. It’s pattern recognition masquerading as understanding. That’s why researchers can easily trick a learning algorithm into mislabeling a picture. “A lot of machine learning, at this point, is very superficial and very brittle. It's based on immediately observable features, which may or may not be essential to what's going on.” Last year the director Oscar Sharp produced a short film that was written by a neural network trained on sci-fi movie scripts. “The principle is completely constructed of the same time.” “It was all about you to be true.” “You didn’t even see the movie with the rest of the base.” “I don’t know.” “I don’t care.” It’s great. It makes no sense. Because it doesn’t have what a 5-year-old child has, which is an abstract model of how the world works, why things happen, or what a story is. And why should it? We evolved these things over millions of years. “So there's a lot it can do, much more than before but I mean, we humans are amazing, I think. We are very broad, see.” AI applications will keep getting better. Robot voices used to sounds like this. Now they can sound like this. Which means Wibbitz will so be able to offer natural-sounding narration. Algorithms are also starting to analyze video frames. IBM trained a system to select the scenes for a movie trailer. So instead of just pulling generic clips, Wibbitz might pull specific ones. But there’s no clear path toward a more human-like intelligence which includes common sense, curiosity, and abstract reasoning. “I think AI is as good as the content that goes through it. So you can’t really expect AI to do magic which some people expect it to do.” Machine learning algorithms can translate 37 languages but they don’t know what a chair is for. They’re nothing like us, and that’s what makes them such a powerful tool. Wibbitz will never make this video, but AI could help me make a better one. 