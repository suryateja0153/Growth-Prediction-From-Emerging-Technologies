 okay thanks for the introduction so this is work done together with my colleagues paprika actually go and recover Lana as well as my supervisor I'm a duck salt at the Interactive Media Lab place so as you might know 3d visualizations have several challenges such as misleading perspective or occlusion you can see this in the terribly drawn 3d bar chart that I created in Excel there or also interaction just imagine having to select a data item in the 3d scatter plot down there so these are well known issues but we believe that mixed reality today has the the potential to to address some of these issues and why is that now we believe that mixed reality being suitable for 3d content can address these issues for example interaction so we have non-traditional devices new exciting interaction paradigms spatial interaction and so on we also sometimes have situated data and semantic connection even to to a physical location so this is an interesting trend there's things like for example in most of analytics some of you might have known might have heard about that so recent trend in visualization community so one might be thinking about a revival so to speak of three visualizations I wouldn't go that far because I don't believe that we can address all the issues but at least try and look at what can be can be done here and and as I said interaction is one of those things that might benefit 3d visualization spatial interaction might actually be one of the key advantages of mixed reality solutions compared to more traditional forms of input when when I think about that when we talk about that we specifically mean in this case with like tablets or other handheld devices but the device position is mapped to a virtual camera and you basically as you can see in the short video clip there freely move around explore visualization in this case it's virtually located on top of that table and use that to to basically explore the data and you can also see a picture to the to the left of that so this is what we're interested in but the question is of course is this really useful it might sound exciting but maybe it's it's unusable or even even worse than traditional input so we don't know that yet how do we use spatial interaction in comparison to other modalities what are the benefits if any and of course what could be possible limitations and yeah that's what we would like to find out so what we did is a study where we compared spatial interaction to touch input for 3d data visualization on mobile devices we doing that study identified some interaction patterns that we're really very exciting and we'll talk about that and and I believe we are able to form about some insights into challenges of situated 3d visualizations so of course we're not the first to look into this or into to work in that area there's a whole body of work concerning for example people who windows so basically windows into 2d or even 3d information spaces such as work done by fitzmorris or spindles work into tangible views for for data exploration then there's of course several papers that use a mobile device a tablet or smartphone as kind of a 3d controller for for controlling 3d velocity visualizations are kind of decoupling the input and output space a little bit then obviously mobile AR in itself and recent technological advantage advantages advances sorry the two new applications in that area and we see the first visualization applications using mobile AR technologies and then there are also specific studies on spatial input such as the the up there Benjamin Bassett I presented that some weeks ago at I believe this also might into print let's work on pinched rec flick where basically he tests it or he studied spatial interaction for 2d navigation or in navigation and 2d data sets compared to touch and found that this can actually outperform touch so how does this work for 3d our prototype or set up for study looks like this so we have a tracked tablet we have a virtual information space that we place on a table the table is not interactive it's just a kind of a physical and mark to orient yourself and we have some study PT and so on as the baseline condition touch we use orbit camera model you can see that in this video so basically use one or two finger XS just and we support camera panning rotation and zoom so it's basically the same prototype that we also use for the spatial interaction but with a touch camera now we investigated three different visualizations in three tasks and the first is a navigation task we have a 3d height map and the task was to to locate and select several markers several targets in this visualization so this was really heavy on navigation and we need to be try to focus on that first and then we had to two more tasks but also obviously have navigational components but also a little bit more than that so the second task was a comparison task for this task we used 3d bar chart and as you can see the the task was basically to come the height of two indicated bars and find out which one was higher and the third one we call that structure understanding task so basically you had a 3d scatter plot and in this scatter plot there were several clusters of data and users had to explore the scatter plot and and try to understand and memorize this and then on an additional study PC they were presented with several pictures of of scatter plots one of them was the correct one and the others was similar but a little bit different and they had to find the right one basically so as far as study design we did this within subject design with the three tasks I just presented and the tutor and conditions of touch input and spatial input we collected lots of data obviously we recorded all the participants during the study we wrote down observations and we also and that's going to be important later on tracked and recorded the camera position both for the touch and for the spatial camera in case of the spatial interaction this was of course also the device position we also have questionnaires so after each task we had Likert scale questionnaires on task load and user preferences and we also measure to task completion times and and error rates very political so in the case of the navigation tasks there there were no errors like that so we had 18 students and postdocs taking part in our our study and all of them completed to study successfully so let's see what do we find out let's take a look at the results maybe let's start with the task load and the user preferences so in general and I have to say that I only present some of the results here there's lots more in the paper and generally found out and this is not surprising that physical demand was higher for the spatial interaction tasks because you have much more physical movement of the table of the tablet in comparison to just holding it and touching so this was not really surprising but we also had better control of the camera so users reported that they felt more in control and overall spatial interaction was preferred by most of the users we also have some significant results specifically for the first task the navigation tasks so their spatial interaction was rated to be more precise and users also reported a lower mental demand as well as stress level during doing the task and they also had a higher perceived success rate some of the comments we we got and as I said there's lots more on the paper they said that interaction spatial interaction was more memorable than touch more engaging also more intuitive but they noted the weight of the device is one of the problems and also trekking was sometimes criticized so we had some slight jitter at the edges of our tracking volume sometimes so those users that really made use of the whole interaction volume sometimes experience that now if you look at task completion times and error rates it's interesting whether the preferred method of interaction also performed better so as I said received level of success was higher and we also found that for the navigation tasks when when looking at the data so spatial direction was significantly faster with quite a large effect size but on the other hand we did not find any significant difference as between touch and spatial interaction for both the comparison task and the structure understanding tasks and and our our idea here our reasoning is that we believe that navigational components that is basically what we do when we move the tablet around don't play as a bike of the role in the more complicated tasks where you also had to focus on point sample comparing to two bars and in this bar chart and you didn't really need to navigate that much or at least it didn't help you very much now what's also interesting is that we observed several distinct patterns of interaction during doing the tasks and this was kind of helpful because we we found some exciting insights I guess so what we did is we observe those patterns during the study and then we analyze our video recordings and and try to to come up with a list of those patterns and then we validated that by looking at the tracked and recorded camera data so we did or we recreated a custom 3d camera for trajectory plot visualization and I don't know if you can see that in the video because it's rather fine lines but you can see it maybe in the picture up there also in the screenshot basically what you can see there is this colored lines showing where the camera move was moved during during the task and the color encodes the speed or the relative speed I should say of the device so red was slow movement or being stationary while greenness faster movement and I'm also going to talk about some of the results we have here but again only the the most important one so one pattern that we identified was we call it Birds Eye views and I hope you can see it in the video but try to explain as well and you can see it on the left side for for touch and then again for spatial in the middle basically the idea that users try to look at the data from above trying to reduce the dimensionality so if you look at a 3d height map from above you don't have any occlusion so this is helpful and and this is this is behavior that we didn't train them we didn't tell them to do that so use us and I have to say almost all of them learned that during the task in a very short amount of time and it was easier for them to to look at that and of course was for spatial interaction you can tree hover above the data like physically impossible but still a similar pattern emerge and in this second one I wanted to briefly talk about this using the principle directions for example for the bar chart but also in the scatter plot tasks users would look at the data from from the sides from the top and and from the front and you can see those clusters basically and in the camera movement data and this is the same for spatial interaction as well so let me briefly talk about some of the limitations of our study each task and you might have noticed already we only tested with one visualization so this is definitely a problem and our touch camera why we try to do it as best as we can there was no accepted gold standard so we could argue that maybe a different touch camera would perform better or the data or most of the data use is artificial and our participants weren't really visual and it analytics experts but yeah students basically so we don't know if this transfers to two other user groups however we still found strong indication that navigation at least can benefit from special interaction and navigation is kind of the basis for all other tasks so this is kind of a good result for us here now some insights that we that we found is that it's important to talk about the connection of the physical and virtual so this should be done in future work like the position and scale of the data how to use physical landmarks and we found the table was really helpful for our users but this should be investigated further guidance and learner ability is an issue so this default strategies that some of our users used could you try and and and tell them before that build this into the visitation may be in some way so this should be looked into and also tool assistance because we had really simple tasks and more complex tasks might need to it's shutters clipping planes and so on so this is also some some future work I guess so in conclusion we believe that mixed reality might benefit 3d visualization our spatial interaction is one but not the only of course promisin paradigm in this area the results of our study I think the we believe underlined the potential and we also found some distinct behaviors or patterns and yeah with that I can all say thank you my name is member thank you for your attention and I'm open to questions I'm Leo from modern so you mentioned that the users reported that this patient and that with the special interaction they felt more in control of the data yeah that's an excellent question so the the more or less exact wording of the question was do you feel in control of the camera and then of course they had to iterate that under the cat scale so I wouldn't go as far as saying as you said feeling from control of the data but rather the the camera to explore the data so I I don't want to speculate whether or not that's because of immersion I believe it was mainly being an very intuitive interaction technique was really fast so for example we had of course some short training period before the tasks and we found that this is basically not needed for spatial interaction so for touch they they needed a little bit of training to understand all the capabilities like the you need one hand finger two fingers whatever for spatial interaction it was instant basically so that might be a factor hybrid also you mean combining spatial interaction and touch or yes so we didn't we didn't really test this in our study but I believe or we believe I should say that this is one of the advantages and it's also one of the reasons why we looked into mobile devices instead of our glasses or something else the advantage of having both the option to to use spatial interaction but also touch for example for precise movements for selection of the so we didn't look into this and into in this study but this is one of the things that I believe are very promising for example also using spatial interaction to position the camera to navigate and then using touch control clipping plane and this is something that we tried out in our prototype but didn't do in the study thank you 