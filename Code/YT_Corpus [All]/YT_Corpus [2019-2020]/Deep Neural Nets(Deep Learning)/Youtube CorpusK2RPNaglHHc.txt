 OK. Welcome to Serverless Days ANZ 2020. I'm extremely excited to be part of this event and I would like to thank upon the organizers, the community members, the audience, everyone who is involved with this event for the great effort they have put in to get this one running. So with that, let me start with my presentation. So today I'm going to talk about Serverless deep neural networks with Azure Functions and ML.NET. This is the  topic of my talk. Let's get started. So a brief introduction about myself. I'm a cloud architect at Harman, a Samsung Company and the domain I've been working on is a professional audio, video and control. Area of expertise is a cloud and distributed computing. Interest areas Artificial intelligence machine learning, cloud and IoT. I'm based out of Bangalore, India and I'm a member of .NET Foundation. So this is a brief agenda about today's topic, today's session. So we're going to cover a little bit on the deep neural network, then serverless, then little bit on Azure Functions then .NET and a demo followed by these topics, so I'll just cover a brief about these topics. I'm not going to go deep dive into the topics because each one of them involves a lot of studies that is required to have them, and each one is a very comprehensive and have a very deep study involved in it. So let's get started. So we'll start with the deep neural network, so in this we can say if you look at the picture given below we have a lot of things so that is revolves around the field of artificial intelligence and data science and when we say artificial intelligence is just like a super set of all these things that is present in this diagram, where that is the machine learning neural network or deep learning, so what is artificial intelligence? So artificial intelligence is nothing, but it involves a computer executing a task that human can do, so it is more or less related to the things that machine can do, which is very much similar to what a human can do, whereas machine learning is a subset of artificial intelligence. It involves computer learning from its experience and making decision based on the information that is available to it. So what it does is it tries to gather the information and based on that information it tries to see the pattern that is present in that data and based on that pattern, based on those patterns, that have been evolved as part of the machine learning, it is being utilized to make decisions based on the information that is developed. So this is about machine learning. Now coming to the neural networks, neural networks are very much similar to what we have in the brain. So our brain is composed of lot of neurons which coordinate with each other and which function as a cohesive unit and it whenever some action is triggered they get activated. Neurons get activated and based on those activations we get different output, some output from the neuron and which is being transmitted to the next neuron which gets activated. So it is a chain of reaction that is happening within the brain as part of the neurons getting triggered  and getting activated. So similarly the same thing happens with our neural networks as well wherein we provide some problem to it, it gets analyzed by these neurons and which based on the information provided to the algorithm or the network it activates those neurons and once those neurons gets activated, we get to have some output out of that one and which is being carried forward to the next neuron. So it is a chain of reaction which allows you to utilize the information that is provided by the previous neuron and being for carried forward to the next neuron. This is all about the neural network, but how does deep learning is different from a normal machine learning? There's a question that comes to everyone's mind, so machine learning is more of a, it involves some of the manual tasks that is being done, whereas in deep learning everything is automated and it the way it differs from the neural networks or the artificial neural networks is it has a high level of a deep level of layers that allows you to make better predictions in less time compared to an artificial neural network where we only have one layer. So a deep learning involves a multiple layers where layers could be off input layer than followed by multiple hidden layers and finally the classifying layer that is output layer. So that is all about this picture the deep neural network that we have now. Coming to the differential between the machine learning and deep learning, I already told that is some of the four task has been carried out with the manually, whereas in deep learning everything gets automated. For example, if you look at the current picture that you have input being fed to the machine learning algorithm and we do the feature extractions. Feature extraction is something that is done manually, so it may be done by artificial intelligence expert or a data scientist which allows you to get the features and once the features are extracted it has been parsed for learning the patterns that is hidden in those features. So once we get those features we give make a prediction out of it or we can make a classification out of that one and give it as an output. So the features could be, for example, if I take example of car, a car will have a set of wheels. It will have a set if it will have a steering, it will have a headlight. So these are kind of features which is being given by the, which is being given by the data scientists or the artificial intelligence experts which extract this information and feed it to the network. Whereas in deep learning these features, what we call it as tire or steering or or had like these are all automated. So these all are analyzed by the network itself and the fed into the network for further learning or for the classification. So this is a basic difference between a deep neural network and machine learning. So coming to the serverless, so serverless is a computing, it's a cloud based computing which allows execution, an execution model in which the cloud provider runs the server, and it allows dynamically management of the allocation of machine resources. So for example, you have some code that you want to run, either you set up the whole thing for it for example, you can hold infrastructure for it. For example, you will set up the virtual machine. You will set up the virtual network or the network settings for it, and you set up the database. Everything you will be setting up so, but that's the very expensive activity. If you have, uh, something very small to be run and that doesn't need the maintenance of these things, so why should we go for that one? So if you look at the diagram here, traditionally all the security aspect, the database aspect has been taken care by the infrastructure people and we need to maintain it on our own, but with the advent of serverless there are plethora of use cases that have evolved and which involves like delegating these activities to cloud provider and focusing mainly on the business logic. So it's very fast as well. So time to market is reduced to a great extent and the cost has been reduced a lot because here you are going to pay only for the usage and you're not going to pay for the idle time of execution. So, for example, if your function, if your code is not executing, you're not going to pay anything for that one, whereas you are only going to pay for the things that is for the code that for the time duration for which your code is running, so it makes it very good use case for many of the examples. So in for example, the example I'm going to demonstrate is about image classification, so it is about classifying class within a set of from my image that is being fed to the system. So for example, it will detect, uh, we will be fed image of a dog. Then it will detect whether the images contains a dog or what class does it contain. So just for this thing you need not to set up each and everything like a virtual machine on network settings or a database. And all those things. So these can be very easily delegated to serverless environment. Coming to the Azure Functions. So it is a serverless system or technology provided by the platform. It is a serverless platform provided by Microsoft Azure for running your code in the cloud, and basically what it involves is you have code that is nothing but your business logic and it will be triggered based on some event which may have the data. So in our case the event is you uploading an image to server, so here it will be basically a Function where you are uploading the image and the data is acting as a, , data is acting here, image is acting as a data over here and the code that you have returned to classify the image. It is the acting as a code part of it. So once you combine these two things you will get the Azure Functions here. It is being triggered by a multiple event sources. So in our case, for this example, we I'm going to use the HTTP trigger, whereas it could be done by multiple sources such as Notification Hub, Event Grid, Event Hub, Cosmos DB. So there are lots of triggers that are already available and you can leverage and get the data out of that one, process it and give output and it will be pretty fast and it will be, it's very easy to scale the Azure Functions compared to a server where you need to do either a horizontal scaling or a vertical scaling. Here everything is done automatically. I'll just briefly touch upon the ML.NET part of the system. The thing that I'm going to demonstrate today, so ML.NET is a machine learning framework from Microsoft for specifically focused for .NET developers, and it has been released, I think last year and it is making a very good progress in terms of the features that is getting added day by day or week by week. And so till now if you, if you're a .NET developer and you wanted to try something in the field of machine learning or data science, you need to go learn either Python or R or you need to, plus you need to have a platform such as Azure Machine Learning Studio or Azure Machine Learning Services such as Cognitive Services. Which is based on the subscription from the Azure, so you are totally dependent on those things. Now coming to this ML.NET, so ML.NET provides you a framework that is you can run locally on your system and you can try an experiment, few things and if you are convinced OK things are working fine then you can push it to any of the platform such as your web apps or Azure Functions or in your VMs as well. So it is nothing more, much more than a library. It is very small library that has a lot of capabilities in it and for making different type of machine learning algorithms so you can have a different set of problems being defined and which can be easily solved with this framework. So these are some attributes of this ML.NET Framework. So build your own so you can build your own custom models by writing C# or F#. So till now it was available in Azure Machine Learning through, by writing up Python code only, but now you can leverage those things and write your custom models where you need to have more control, then in that case you can use this Machine Learning Studio. Then it's very much a developer focused, so which what does it mean? Is ML.NET provides just the right amount of productivity and control, so you can write C# code, you can normally debug it and you can play around with that one. It's very extensible, is has a very compatibility with different Machine learning models, such as a Tensorflow or the framework such as Tensorflow, Pytorch, so extensible in the sense it provides a common standard such as ONNX, which is open network neural exchange, wherein you all these platforms are give model in the ONNX format - .ONNX format, and you leverage that one into your thing. So suppose I have a predefined, someone has created a model which is in Pytorch, so I can convert that one, that PT file into ONNX file and we can leverage that one in our ML.NET Framework. So you need not to create the models from scratch. You can just leverage and you perform the transfer learning out of that one. Next One is proven so ML.NET has been introduced in Microsoft in the year 2002 that is 18 years back so and it has been extensively used internally within Microsoft in platforms such as Bing, PowerPoint, Excel, so it's kind of a very proven that library or framework that is available now for the public to use that was open sourced last year and current version is 1.5.1 so that means it's making a good progress and with a great features coming up every week. It's last not, but least, the last not but the least it is the open source and cross platform support so it's a cross platform and open source. That means it can run on any of the platforms that is being provided. It's a great tool to check it out and we will be leveraging it for image classification problem today. So now image classification. What is image classification? It's about feeding some data of images and once those images are being fed to the system, we see that we are feeding it to the networks. What network does is it tries to learn the features out of that one. For example, it tries to learn the features such as car wheels, car headlight, car steering, so these are the different features it try to learn and based on these features it makes a prediction out of that one in the end which is recalled as a classification. So as you can see here we are feeding a lot of images of the car and the network is learning and based on these features it is making a prediction and this is like a probability. OK so it's saying that 95% it's a car based on the features it has learned and 3% it is still saying is a truck or a bicycle, so that way the reason why we are getting truck and bicycle here is a truck is also having a set of wheels where a bicycle is also having a set of wheels, so the network is thinking that it may be truck as well. It may be a bicycle, but the percentage is very low compared to the percentage that is being predicted for the car, so this looks a very good model wherein you can easily say OK, like if the threshold you can set a threshold here. If it is 90% accuracy then we can say OK we will take that probability. So today I'm going to use the transfer learning. I'm not going to train the model from the scratch. The training from scratch is like you feed in the whole set of images. 100 million images or 10 million images to the network and it learns the features out of that one and it makes a prediction out of that one and it generates some model. So the model is used for making a prediction. So this whole process is very time consuming and it made it very from a day or two weeks to months, and the computers it requires very extensive here. It involves a lot of GPUs compared to a CPU here. So not everyone will have that flexibility of having high computing power in their systems. So what we do is many companies have already trained the models on set on large datasets and they have shared their model along with the weights that is being discovered after training the models. So MobileNet is one of them. So MobileNet is a very lightweight model that is being utilized within your mobile to make image classification. For example you have take a picture and the mobile is able to classify what is present inside the picture, whether it's a cat or a dog or something like that. So it is being utilized in mobiles extensively. The advantage is it's very lightweight. It's around like 13 MB, which I'm been using today, and compared to a normal architecture such as AlexNet, VGGNet or other models which are very heavy, such as they're 480 to 200 Megabytes. So like I will deploying it to the Azure Functions in order to keep things very lightweight I just used MobileNet for this this session. So transfer learning is about you have got the model such as MobileNet. You got the model now you make up utilize that model to make a prediction on your images, on your data set. The thing is that here the datasets would be very closely related to the original model on which the training has been done. So if we look at that MobileNet it has been trained on Imagenet data set which comprises of 1000 classes in it and each of these classes represent something within the ecosystem, such as a cat dog, then car, truck, all those things, and  for todays scenario, we're going to predict a dog, which is already present in MobileNet. The MobileNet architecture has already learned all these things, so we need not to recreate a model, we need not to retrain the model and we can save a lot of time and computer science on that one and the transfer learning will be pretty fast compared to normal training, which is done on from scratch. With that, so this is the architecture I'm going to follow. The application that I have developed today, so this is a user which is nothing but your class client in today's scenario. So what he will do is he will upload image to the Azure Function which you have exposed our API such as ClassifyImage and we will be loading  a model. So this is the ONNX file which is nothing but our model, our MobileNet model which I have stored on the Azure Blob and we will be a loading that model to our Azure Functions and Azure Function will leverage that model and make a prediction and based on the prediction, it will give you a number, which is nothing but class is present out of 1000 classes that is being defined in the Imagenet classifier. So with that, let's get to the demo. So we are going to create a Azure Function App that is already done. Then we need to save a model to the Azure Storage Blob. Then we need to create a ClassifyImage API, we need to load the model in Azure Function, make prediction, test through Postman locally first, then once we are convinced OK things are working fine then we'll just deploy it on cloud in Azure Function. Let me turn to the code. Give me a minute. OK, so before I jump into the code I'll just show you, so for example, this is my Microsoft Azure Storage Explorer and you can see here you have the emulator running. I have the Azure Storage Emulator running. It has some blob container and one of them is serverlessdnn. This is the name of my container in which I have uploaded this MobileNet ONNX file. So and if you see here it is a 13 MB, so the size is pretty small compared to the normal models that we get for image classification. That is one of the reasons I have chosen this thing. So this is on the local I have. So first we look into the local part of it, then OK. OK, so this is my code editor for this thing. So if you look at here. So yeah. I have already created my solution with name as SeverlessDNN. It has a Azure Function Project, so you have to create Azure Function Project so it will create a default file called as function dot CS. So I've just renamed that one to my function name like ClassifyImage and it has a couple of other files such as ImageSettings. ImageSettings is like you will be uploading a file for one of the classes that is presenting Imagenet but the problem is those size of those images may vary and when we train classifiers something on the model it requires to have a specific size, so for example for MobileNet it is, it has been seen that it is, it takes a image of size 224 by 224 by three, where three represents the color channels, but the size is 224 by 224. So ImageSettings has a record of those things and I'll show you how we can set the size to 224 by 224. Then local dot settings. It is nothing but it contains your connection string and various variables present in the system. Then model input is, it will hold the information about the image that you will upload and model output is something that gives you the score of the prediction of the prediction done by the model. So let's see those things. So first thing is, I'll go into the ImageSettings. Yeah, so if you see here like you have defined it as 224 by 224 so whenever we upload a file it has to be resized to this dimension. For in order for our network to consider this thing. Now coming to localsettings.json so here I have. This is the connection string for the Azure Blob Storage. In case of local setup it is using use development storage equal to true. This is my container name I showed you the blob container that I have in my storage blob. Then this is the file that we have uploaded on the Azure Blob. OK. Next is mobile input. So here this represents the size the image source, which is nothing but your image that you upload. It holds information, so it holds the information in a Bitmap and image type attribute tells you what is the size of the image that you are expecting, so here it will be 224 by 224 that we want it to have. So it has nothing more than this one. So we just keep this much of information. It's like a placeholder for the image that is being uploaded. Here, this representative score is like it's a array of 1000 classes as we are using MobileNet which has Imagenet data set which has a 1000 classes. So when we look into this score it will hold the values for those thousand classes. Now this column name is very important for image classification. The place from where I got it is I have this MobileNet v2.2.7.0 ONNX files and there is a utility called netron which allows you to see the content of this file. So I have already opened it and if you look at here, so if you look at here it has a lot of layers. You can see the architecture of this one which contains convolution, BatchNormalize and Relu. So all of the layers have been defined in that one and we can say OK, see it takes a input image of size 224 by 224. Now this is the name of the input and this is the name of the output that it is giving us. So we need to be very careful with this for things we have to use this one for our model. So this is the name that I have used here. This is same as that is present there, so it represents this is the output column name in our model. But these two are defined. Now we will finally go into our classifying page. So this is our main Function and here you can see that couple of things to note here. This is the Function name that is being exposed. Then here I have provided the authorization level which is anonymous, so anyone can access it, but based on your requirement you can have a different set of authorization level and this is basically a HTTP trigger. So once someone hits this URL that means it will get executed. So first, what we're going to do is we're going to load the app settings and from there we will read the container name, we'll read the connection string. We will read the model name, so this will hold the information about those things. Next thing is load model from Blob Storage and save to temp path. So why do we need to save it to temp path? The reason being currently the ML.NET loads ONNX file from a model path only or from a file path and not from the stream. So we need to create a temporary path where we can save the model. So this is about just creating us temporary path. The thing is that you need to have a unique thing here unique ID just to avoid any repercussions of having the same name next time when you run the Function. So once you have the temp path, what we're going to do is read the model from the blob first thing. So here what we're doing. We're just creating a blob container client and getting the blob and converting it into a stream. So this is a very basic thing for like loading a blob from a URL from the storage. So you got the model stream and you need to save this one somewhere on the directory so that you can access it through the path. So what we're doing, we're just saving it to the path, creating a file, and just saving it. Then the model is getting saved there. Now, once it is done so this is nothing but your input column name and output column. We have data and the other one that I stored in the output. Now comes the real magic of the ML context or the ML.NET. The first thing in that needs to be done is to create a ML context. Context is very much similar to your DB context, with everything within your ML.NET is done through the context. So you create an instance of that one. After that you just create a empty list. It is just to say that what is the schema of the input data that we are going to load for the context to understand it, it is in the interest of the ML context knowledge only that what is the type of the schema that is being loaded. So we're going to load it in terms of the model input. Now the pipeline is something that is very important here, so it does the whole magic. Here what we define is we have a, we perform different transformations on the input image. For example, we resize the image, then we extract the pixels. So if image is not of size 224 by 224, we will resize it using this transformation, so various transformations are done. Then we will extract the pixels. Pixels is like in an image is composed of lot of pixels. So for example in this case it'll be 224 by 224 pixels that will be present and wach pixel value vary between zero to 255 based on the intensity of the color it is having. Then we need to extract those things from the input image so that is being done by the ExtractPixels. Last one is the ApplyOnnxModel, so this one is the actual one that loads the model from the file, ONNX file that we have downloaded and saved into our temporary path. Once this is done, we will just fit it. Fit it means we will train it. So currently we don't have any data as of now, so it will just create a model with the empty data so that the model can understand what is the input type, what is the output type of it. Once we have the model ready, then what we're going to do, we're just going to feed it to our network to make a prediction. So first thing is we need to load the image, so req.Body will give you the stream for the image that is being uploaded. We will convert it into bitmap and creat our input data, so this will act as our input. Now ML.NET has something called a prediction engine which allows you to make a prediction on a single item. Also what we need to do is we need to provide the model which is being utilized to make that prediction. What will be the output input type and the output type. So with this we'll get the prediction engine so it exposes a predict API where we provide the input, input is nothing but the image which user is going to upload. So it makes a prediction out of that one, and it gives you a score, so score will hold the list of 1000 classes values, so we will take the max out of it and say which is the predicted value for this one. The closest. So for example, in our case we saw car had 95%, truck has 3%, then bicycle had 2%. So likewise we will get the maximum value and we will say this is the predicted value by the algorithm and this one just we will return it. With that I'll just run it locally first and I'll put a breakpoint here just to show you like score will have thousand classes in it. OK, in the mean time it is running, I'll show you the Azure part of it. So This is the same Azure Functions I have here and if you see the Function here I have created. So I have already deployed it to my Azure Function and here we can see that same thing. I can show you this also, this is the file that I have uploaded on Azure blob in the cloud. So the same experience that we have there and here locally in here. In the meantime, let me, OK, it's coming up. OK, so this is the end point that we have for our Function. If I just go on to the Postman, so this is the same endpoint, have the body binary and have selected the image of a dog. If you see like this. So this is the image of my dog. I just hit this URL. Yeah, so if you see here this array should contain thousand elements. You can see it is like 1000 element array. Which each one of them having some value. I'll take the Max and get the class out of it. Yep, it's 212, so if you look at this one. I've already seen this one, so this is the place you have that thousand class mapping. 1000 classes along with the so if I search for 212 I'll get English Setter. Which I search on Google. It's like a dog. It's one of the breed of dog. It seems to be very correct for the model that we have very lightweight model. Now the next thing is to deploy to Azure. So we need not to make any code change any configuration change here. You just go and right click and publish, that's all. So I've already published it and I just demonstrated it how it is done so once it is published you will see it in your Azure Function, then you will see your Function app. Also, you just make sure that you should have this file available here. Now I'll just make the same thing with the Azure Function, so this is my URL for that and I'll do the same thing here and it should give me the same result if everything goes quite well. Cool, it's working. So that's the demonstration part of it. Now I'm going back to my slides. OK, so these are some custom successful user stories for the ML.NET. These are the user stories success user stories which are present in some of the products and systems being deployed at these by these companies, you can have a look around it and see the use cases of them. I'm just running out of time, so in the interest of time I'll just move on. This is a link to my resources, so if you look into this it will be very similar. So this is a place where I have put everything Serverless Days 2020. It has a direct link, source code link. The same source code is available here, same class and everything. We can just go through that one and references. I'd like to thank you each and everyone involved with this great event and thanks for joining this one and listening to the talk. Hope to see you soon with that I'll just conclude and thank you. Have a great day or good evening or whatever time you have at present. Thank you. 