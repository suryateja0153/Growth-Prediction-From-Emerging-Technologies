 in recent years new research into understanding how neural networks work has really revolutionized our ability to interpret how they operate providing the tools and building blocks for explaining why they make the predictions that they do stay tuned as we dive into convolutional neural networks and try to understand how they see the world welcome to AI adventures where we explore the art science and tools of machine learning my name is Yu Feng Guo and on this episode we're going to see how to use lucid to better understand what neural networks are looking for convolutional neural networks or CN NS have significantly advanced the state of the art of image recognition they've achieved incredible accuracy across a wide variety of tasks but understanding what's happening between the inputs and the outputs in those hidden layers that's been slow going so today we'll look at a number of different approaches to try to gain some intuition behind what it is that makes a CN n work ranging from focusing on individual neurons all the way to looking at the response of an entire layer before we dive in I wouldn't get us on the same page about why it is that we care about how a neural network arrives at the prediction that it does isn't it enough that the final prediction is right well not quite in real-world production use cases of machine learning image recognition systems a lot of additional value can be gained by understanding the how and the why of a given prediction this helps the end user of the predictions better understand whether it's being made for the right reasons let's take a hypothetical example say in medical imaging where small details can really play a crucial role in differentiating between different types of results what if let's say a model not only gave just the right prediction for an image but it also provided information about which parts of that image were the primary contributors that led to its inclusions then a doctor could see whether this model was coming to these conclusions for the expected reasons moreover this approach could even potentially highlight new patterns which hadn't yet been identified as useful in these images so what kinds of tools and approaches would we need in order to construct this kind of understanding of an image models predictions well let's set the stage by first understanding the structure of a convolutional neural network convolutional neural networks get their name from their many convolutional layers and they work in concert to understand the different details of an image in the early layers close to the inputs the convolutional layers are expected to be looking for your basic lines and simple shapes and patterns further along in the network the work from these early layers are passed on words and respond to more understandable looking inputs we might see images that appear similar to various parts of real-world animals or objects this information then continues propagating onwards through the network and eventually reaches those final layers which are put together in generating the final outputs of the network's conclusions these tends of course look more directly like the categories that we are expecting as the outputs there are a number of parts that make up any single convolutional layer at the lowest level is the single individual neuron neurons are the most fundamental building blocks of a neural network and the strengths of each neurons response to input is what we will use to understand their behavior so now let's zoom out a bit and see how multiple neurons can be connected in a specific channel so a single channel is made up of a two-dimensional rectangle of neurons which are used to process the previous layers outputs there are many channels in a layer each channel stacked on top of the other much like a layer cake and within a whole layer all the channels receive the same values as inputs from the previous layer but they each process that input slightly differently looking for different features all of these outputs are then come and pass onwards to the next layer now that we have a basic understanding of how a convolutional neural networks layers are assembled let's take a look at how to find out what a given neuron or perhaps a group of neurons is quote-unquote looking for when an image is passed through the network in what is called a forward pass each neuron responds or activates to a different degree now we can measure that activation strength well because it's literally just a number that comes out the greater the magnitude of that number the stronger the activation now these activation values can be positive or negative so we can have a strong positive activation as well as strong negative activations so let's start by seeing what a specific neuron in our network responds most strongly to by looking at how it activates when the network is presented with an image input if we take this train model and then hold all the weights static so they can't change and then we run an image through that network and we measure what a particular neurons activation value is we can begin to optimize this input initially we'll start with the image of pure static noise and because neural networks are differentiable we can figure out how to adjust that input image that noise there's just nothing there to get an even higher activation value for that specific neuron we're interested in so we tweak that image a little bit and if we're doing it right the activation of the neuron will be even higher when we pass that image through the second time so then we can do it again we can adjust the image to boost that activation of the neurons response to the image and pass it through over and over again we repeat this process and eventually you end up with an image that has been optimized to activate one particular neuron of the network maximally the result is an image with a focused region surrounded by a kind of a more blended background now these patterns can be all over the place and thankfully lucid has made this really easy to compute there's no need to write an optimization loop yourself you can just choose what layer channel and neuron you're interested in and we'll take care of the rest now if we instead look to optimize the activation of not one single neuron but instead that entire channel of neurons we can get a pattern that is a bit more consistent and fills in the edges - and this is what we'll be primarily seen throughout the rest of our experiments now let's take a look at some ways to combine the different neurons together allowing us to see how neurons activate in pairs this is showing the optimized input images when optimizing for two different channels of neurons simultaneously rather than just one what ends up happening is that the images sort of show up as a blend of the two channels that they originated from and finally let's see how we can interpolate between two different neurons rather than just copped amaizing for both equally we can weigh them unevenly giving us images that are along the spectrum between the two channels this gives us even more context about what sorts of patterns these channels are able to detect so far we've gotten some background on CN NS and we've seen some examples of feature activation at the neuron and channel level in the next episode of AI adventures we'll take these ideas that feature of visualization and apply them to the entire image to create activation grids and then we can use that to produce an activation atlas which will give us insight not to one neuron channel layer or just an image but it'll allow us to see how the entirety of the network operates as one cohesive unit if you want to learn more about feature activations and to experiment with lucid on your own check out this distilled pob article really fantastic and try out the lucid library on github thanks for watching this episode of cloud AI adventures and if you enjoyed it be sure to hit that like button and subscribe so you can get all the latest episodes right when they come out for now go check out lucid on github [Music] you 