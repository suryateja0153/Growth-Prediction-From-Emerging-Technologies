 okay I'm gonna go ahead and get started it looks like we've got quite a few people in attendance so I'm going to start off just by introducing myself I'm Alicia frame I'm the lead data scientist at neo4j I work on the product team so what my role is is I work with our product engineering team to develop the graph algorithms library I work with early adopter customers to figure out how they can use graphs for data science use cases in production and take kind of their feedback and experiences back to improving our product roadmap and then I work with scoping what our long-term roadmap is and where we're going to do more data science with neo4j I have worked in data science for the last eight years mostly in the life sciences sector and I'm super excited about using graphs from machine learning and so just to start us off I really like to kind of have the one slide that if you zone out for the rest of the entire presentation this one kind of drives the message home this is my TLDR slide why should you use graphs for data science it's a pretty easy answer you should use graphs when context matters so there's like the old aphorism of you know it's not what you know it's who you know and the example we like to give is to talk about you know maybe how did you get your last job was it based on where you went to university or the specific degree you had or the number of years of experience at awesome company or was it influenced by you had a mentor who who helped you build your skills in a specific area or your college roommate introduced you to someone who already worked at that company who could get you up to speed more quickly or you had a friend who scheduled an informational interview for you or your old boss made an introduction those are all examples of when relationships are the key determinant of an outcome so to sum up when do we use graphs it's when relationships matter a nice kind of less hand wavy example that I like to share is when you talk about figuring out who's going to smoke or who's most at risk for being a smoker I was a big study it's fairly famous where they tried to predict what factors predict if someone is going to smoke or not and they looked at kind of standard data science approach right I'm gonna go figure out you know what is someone's demographic data how old are they where are they from how much money do they make what do they do know what's their ethnicity right and they actually found out that those were all informative but the single biggest predictor was in fact whether or not they had a friend who smoked so again this is an example of relationships can sometimes be the most predictive factors for a model and using a graph makes it much easier and more straightforward to pull those relationships into the modeling pipeline and frameworks that you're already familiar with so when we talk about what can I use graph data science for these are just eight examples you can you know if you want to have fun later on you can say how do you use graph science for X these are eight examples that we've run across kind of in our early adopters program in literature from customers that capture kind of how broad the use cases are this is not a niche solution so if you start from financial services how can you use graphs for data science you know fraud detection is something we talk a lot about it neo4j so I have a transactional graph of who's interacting with who who's buying which services and I want to use the graph to find out what patterns look unusual can I find money laundering rings can I find someone with more account transactions than I would expect them to have can I find people who interact more frequently with each other than they should and then can I put those into my predictive models and we'll talk about this later on drug discovery is another example this is sort of what my background is and if you think about biology and chemistry these are all really Network and systems based right you have genes interacting with chemicals and diseases you have protein protein interaction networks so you can use graphs to improve your ideal ability to identify drug targets so genes that you want to treat with a chemical or you can represent chemicals as graphs and there's an awesome talk from the Rd kit folks later today around this exact topic and then you can also talk about recommendations so graphs have been really popular in the recommendation space for quite a while but mostly in the context of collaborative filtering so people who bought this item also bought these items can I filter my graph of purchases and find you know Co purchase data the way you can use graphs for data science here is let's say you have a model where you're predicting what should this person buy next I want to predict the link between a person and an item you can use graph based features or graph embeddings to characterize what transactions look like and better make a more precise recommendation based on your total graph topology when we talk about customer segmentation this can be related to recommendations historically you'd think about okay I have tabular data this is like that smoker example right I want to break it down into people of a specific gender race age group in a specific location and maybe that's informative but what you can do instead if you have a graph of interactions or COO purchases or who's interacted with which products you can break it down based on who interacts with whom more frequently so instead of saying I want to find a white female who lives in Brooklyn I could go in and say I want to find a group of people who interact frequently with each other and they are more likely to have more in common than saying you know these demographic groups interact with each other so this is super powerful cybersecurity is a really natural fit for graph data science we talk about network security right so it's really easy to represent your network as a graph it's naturally a graph and what you're looking for there is what patterns are unusual where are the outliers I know what a secure or like safe graph looks like I want to know when there's been a network incursion so I can use a graph algorithm to describe what my normal network looks like and I can train a model to predict when something is outside the range of model churn prediction is another one we're going to talk about a little more in depth later on with a real-world example but the idea behind churn for as I have a service maybe it's a telco maybe it's you know some kind of subscription and I want to understand who's going to leave next you can use craft based features so have any of my friends left the network who's the most influential person I I'm associated with and are they still on the network and companies like Huawei have actually used this there's a great publication from a few years ago where they found things like when someone with a very high PageRank leaves the telco network their connections are more likely to leave search and MDM is really where a lot of this graph data science and network science applications in production or in industry really started so I just mentioned PageRank it's called PageRank because of Larry Page it's from Google right graph algorithms are what powered our ability to really take off with search on the Internet they're very powerful for saying I have a large graph I need to sift through it and figure out what's most important and then the last category here really shifts gear if it's quite a bit we talk about predictive maintenance so this is more closer to like the supply chain and operations research sector so if I can represent my supply chain or let's say my my manufacturing dependencies as a graph you can find which nodes are the ones where if that node fails your entire network goes down or you can find out what is the flow across this graph and where is there an unusually high level of flow so I proactively maintain that aspect so these are just kind of eight high-level examples we're gonna go way more in depth later on but the idea is how do I use graphs for data science and what do I use them for I can use them whenever context matters and that's not set to a specific industry and the basic idea here is when we talk about graphs and data science we're not saying throw out everything you've done we have this crazy new thing we want you to do instead the bottom line is that graphs let you make more accurate predictions with the data that you already have so this schema is kind of nice I have my rows and columns on the left hand side that most companies with a data science team there's already a machine learning line in place where you have predictive features you're training a model for some predictive output you know what you're doing what we're saying is with a graph you can create new features feature engineering that you can add to this pipeline that you already have and make better prediction so that's like your churn prediction example so I already have information like how long has this person been with this service and now I want to add in has anyone in their network left this service so it's just adding better data into make better predictions and the other piece of graph slit you get at that I think we don't want to brush over it sometimes when you have your data in a graph you can make a new type of prediction so I mentioned with recommendations link prediction right so if I want to predict links forming in a dataset I need to have a graph so I have an explicit representation of those links so graphs are great because you can bake both make better predictions with the data you already have as well as predict new things and in case you're listening to this and you're like this is just marketing talk you know neo4j is making this up who's ever heard of graphs and data science I like to have this slide in to say you know no this isn't just us this is actually kind of in the data science AI machine learning space there's really a general consensus that graphs are really powerful so instead of forcing everything into rows and columns using graphs gives you an ability to generalize about the structure of your data in a way that kind of standard approaches just don't have and Google and deepmind published a really good paper on this in November 2018 basically a position paper saying here's a new framework for modeling use a graph neural network it's it's much more predictive but what was really interesting in their paper was they said the biggest hurdle wasn't the framework or the technology they said it was where do the graphs come from that these networks can operate over and what's really cool for me working at neo4j is we're a graph database company we've got the graphs so what we're doing here is we're bringing the data science to the graphs to give our users a better ability to kind of generalize and make more accurate predictions and sometimes I feel like this talk can be really high-level you're listening to me and you're like she's saying we can do amazing things but what does this mean in practice so I like to have this slide to just pull back and say how do I actually do this we will revisit this as we walk through specific examples but the general framing when we talk about using neo4j and using graphs to build machine learning models is you're starting from your different data sources maybe it's already a neo4j graph maybe you have data on spark or sequel or CSVs you pull that data together and you unify it in neo4j and then once you're in neo4j you can do graph transactions and graph analytics so in the graph analytics space you can start building features either by hand using safer queries or with the graph algorithms basically creating new columns of predictors for that tabular data and then you can export that into the space where you're already building predictive models so this fits into the pipeline you already have we're not saying start again throw everything out we're saying this is a tool in your toolbox that lets you make better predictions and so one thing that we're pretty excited about and if anyone is attending the SPARC summit in Amsterdam next week I will be there along with several members of my team you should check out our awesome talks we'd like to talk about spark and neo4j and how you can put those together so spark is super powerful in terms of data unification and data pipelining spark 3.0 will have cyber 9 available so you can run cipher and you can project your tabular data into a graph format and you can create a non persistent graph once you've figured out how do I reshape my data into a graph do I have a graph problem you can move into neo4j just like I talked about so you can store your graph you can run graph algorithms and run complicated queries then you can pull that data back out into let's say ml lib to train your models and when we talk about how do I choose between spark and neo4j spark is great for being scalable really powerful data pipelining and it lets you start experimenting so you can project your data frame into a graph and you can say do I have a graph problem how what would my graph schema look like I can run simple one into hub queries to understand how it's associated with a graph once you have that and you understand that you can pull the right set of data into neo4j to start building graph solutions so you have a database where you can persist your data you can have graph native query and algorithm optimization and then you can make use of our constantly growing list of graph algorithms and embeddings to answer your questions more powerfully so stepping stepping back to now you understand how it's done so cool I pull my data into neo4j I run some algorithms and then I put it out into my machine learning pipeline what am I doing here right how do I get started and how do I add value and I really like to frame this as the steps of graph data science so what I'm going to do for the second half of this talk is walk through steps that you can do to get started and going from left to right kind of more complicated advanced sophisticated they all build on each other so we kind of have to start off with I need a graph to do data science on a graph right so the foundation when we talk about graph data science is having a graph that you can query so for each of these steps I'm going to walk through an example a real-world example of how you can do something with a graph to add value and learn and improve your models so step one I have a graph I want to query it building on that now that I have my graph and I can answer basic questions I actually have a machine learning pipeline let's say I'm training a random forest classifier I want to use Seifer our query language to engineer specific features based on what I know about that data that I can put into my model building on that and you step back and you actually say I don't want to hand engineer these things that's when you start using graph algorithms these are kind of a category of algorithms that tell you about the topology and network structure of your graph and they fall into different categories but generally speaking they're unsupervised learning algorithms that extract key and formation about your graph so instead of hand engineering it is a domain expert you run a graph algorithm you can put that into your pipeline the next step kind of increasing in sophistication is a graph embedding and I really like them to think of them as kind of a pivot point between graph algorithms and deep learning our neural networks so graph embeddings are basically custom trained representations of your graph for the thing you're trying to predict so a graph embedding is basically a type of graph algorithm but it's customized to the graph that you're running it on we'll talk more about all of these later on and then the last step is what deepmind in Google brain we're talking about this graph neural network concept so instead of pulling my data into a machine learning pipeline I have a graph as my input I learn on that graph and then the output is another graph and so let's start off with query based knowledge graph this is really the simplest first step great place to get started if you've seen presentations from neo4j before we really like to talk about the lessons learned graph at NASA this is actually one of the earliest projects that I'm aware of that we still talk about so in 2012 we worked with NASA to basically create a better way of accessing document so what they had is they had you know documents from decades of research and history and lessons learned they had you know engineering plans they had memos they had white papers how do you find what you actually need to answer the question that you need to answer for the job you have to do this is that foundational piece so they used a combination of topic modeling and things like PageRank and just linking which papers reference which concepts to create a knowledge graph and once they had that knowledge graph we have this great example of the up writers on this capsule so they needed to build something they hadn't built in several decades they were able to leverage this graph query it and find the information they needed to fix the problem and it saved them several two years of work and a million dollars of taxpayer funds so the bottom line here is you need a graph to get started a knowledge graph allows you to answer the questions that are that you know you need to ask very efficiently and there is value even in the first step we're not saying there's no value until you're running a neural net every step in graph data science you're empowering yourself to do something you couldn't do before so cool I've got my graph now I want to start doing some feature engineering and when we talk about feature engineering that's basically reshaping your data to add new columns to that tabular data set for predictions so an example I like the site here is turn prediction and a telco network so telecom networks are really easy to represent as graphs I have kind of a complicated schema here from one of our blog posts where you have you know company is calling each other you've connections incoming outgoing what happened to them you can kind of also simplify that and just think of I have different phone numbers that are calling each other and churn prediction is basically I have a network I want to know who's going to leave it next and I want to be able to predict for the next month who's at risk of leaving so I can devote resources to preventing that and so research in this space has actually found that simple hand engineered features are really highly predictive so these are things like I have my graph and I want to know how many calls or texts has this account made and to whom and how many of their contacts in this graph at one or two or three hops have churned and this is from a paper by Connor Doyle from 2015 there's another paper that I can cite as well where they basically took their data they reshaped it into a graph for feature engineering and they added graph based features almost all of these were hand engineered so they looked at the features and figured out which ones were most productive predictive and what they found were these simple hand engineered features of what was the in degree and what was the out degree and what was the in degree during the day and what was the changed you know how many incoming calls did I have versus my neighbors have where some of the most predictive features in this model so this is an example of someone who knew a lot about telco and churn using the graph that they built from their data and making simple queries to find out okay these I know that these are important features I'm going to query it I'm going to generate this number and I'm going to add it to my predictive model so it's really powerful it's a way of just like we talked about knowledge graphs let you answer the questions you should be able to answer the hand engineered features are a way of saying I know this is important I'm going to leverage the graph to get this information out if we want to talk about fraud detection you could cite the example of looking at how many users do I have in two hops from this account who've committed fraud so how do I actually do this going back to that spark framing we talked about you can merge your data reshape it into graphs start exploring it with cyber queries and spark once you know you have a problem and you figured out what you want to do move into neo4j and then use your queries to interact with that data and export it into your machine learning pipeline building on that we want to start using graph algorithms so these are the unsupervised category of features and just going back reminding everyone what feature engineering is this is how you combine and process your data to create new features so you've probably seen by now examples from Game of Thrones you have your interaction graph I want to predict who is going to win the game of Thrones I could have started off with my tabular data of who's in which house but then I can start running graph algorithms and adding columns that represent things like influence with page rank or relationships with degree centrality which communities individuals interact with I'm using something like looping and so I'm just adding columns to my dataset neo4j has five categories of graph features and coming up on a six ones shortly we talked about community detection which is how you partition your group your graph into clusters based on which nodes are more tightly connected to each other than other nodes in the graph so label propagation and LU vein there are examples of this you have centrality and importance Algar which determine the importance of distinct nodes in your network so this is something like PageRank you have pathfinding in search which find the optimal paths and routing across your graph you have similarity which lets you say how alike are any two nodes in my graph based on either their relationships or the nodes they're connected to you have heuristic link prediction which is basically I have some rules about whether or not a link should be present and I want to calculate a probability that two unlinked nodes should be linked and the last category is embeddings which we'll talk about later and so for this we like to use the example of financial crime because different algorithms can answer really different sets of questions so if I have my transaction graph I have my account holders they have various identifiers as they have bank accounts that make transactions with each other this is a really naturally graphi problem financial institutions already have modeling pipelines and heuristics that they use for this graph algorithms just add new data points they can use so if you're looking at something like first party fraud where you want to find out okay who is committing fraud by creating fake identifiers some fake authorized users on their accounts I can look at something like connected components which will find all of the disjointed sub graphs in my graph that have shared identifiers I could use something like PageRank if I want to find accounts that are making more transactions or larger transaction volumes than I would expect if I want to do something like try to find money-laundering where I have account holders or who are repeatedly passing money between each other not in like a simple one-hop way but let's say in a six hop way I can use blue vein to identify these fraud rings and then pull that data out or let's say I have some account holders that have been labeled as fraudulent and I want to look at my other account holders and figure out are they likely to commit fraud to I can use jacquard to say this account has committed fraud what's the most similar other account in my graph to this account based on who they're interacting with because maybe I want to investigate that next again just circling back this is not neo4j making-up uses four yo 4j there are over a hundred and forty thousand peer-reviewed publications on this topic in the last ten years this is a really hot area of research that's really useful and it's really powerful I'm just circling back to how do I do this again we talked about merging your data pulling it into neo4j running those graph algorithms and either interacting with those results directly or bringing them into your machine learning pipeline for training and so in neo4j I'm sure you've heard other presentations today where we've talked about we have 45 different algorithms across these five classes I work on the with the product engineering team where we're working on ensuring that these algorithms scale up to billions of nodes and relationships terabytes of data so what we're doing is picking up the highest value and kind of most requested algorithms and remaking those so that they scale to the biggest graphs you can throw at us so the ones I've highlighted in yellow the team is already worked on and what we're doing now is going algorithm by algorithm based on demand and making sure everything scales so this is something super exciting next step graph embeddings so I'm going to actually be speaking on this later this afternoon so I'm gonna skim over some of this section if this sounds exciting it's tuned in at 1:15 but a graph embedding is just a way that you transform your graph into a vector or set of vectors it describes its apologi connectivity or attributes of nodes and edges in the graph right and you can create different types of embeddings so you could have a vertex embedding where you're describing the connectivity of every node and that's how deep walk works a path embedding where you have traversals across your graph and you want to create an embedding that represents those or you can have a whole graph embedding where you want to conclude your entire graph into a single vector and this is really relevant especially in my background in the chemistry space so I want to encode a molecule as a graph basically all I'm saying is I want to take some part of my graph be it a node a relationship a path and I want to represent that as a series of numbers that represent weights that help me tell the difference between in the visual nodes because they're numbers I can easily put those into a machine learning algorithm so a cool example of this that I really love to cite is from eBay they were doing reasoning over a knowledge graph for recommendations and this is a path based inventing so what they had is they had a user interacting with a song and they wanted to know well which song should I recommend to that user next but that song the user interacted with Alice likes the song the shape of you um he's part of a knowledge graph so there's all of this context around the song so it's sung by ed sheeran it's a pop song it's Sheeran also saying castle on the hill etc etc so can i leverage paths across this knowledge graph to make better predictions and so what they did is they extracted all of the potential paths in that graph up to six humps between the user and the endpoint or the song they were recommending and then they used an embedding to condense that to basically a vector of of numbers that they could then use to say well what vector is most similar to this so what should i recommend next this is really cool because it's a way of taking something very complicated and adding context in a way that's easy to use sort of in a machine learning pipeline when we talk about doing this in SPARC basically same concept move your data into neo4j write it to your graph to persist stay tuned for for graph embeddings and then once you have those bringing those into your machine learning pipeline the last step and I've got one minute to talk about this is the graph neural network and so this is kind of the the most sophisticated most advanced endpoint which you really don't see in production outside of basically image processing or kind of video recognition and graph innate of learning when we talk about graph neural networks is a type of deep learning which just means you're training multi-layer neural nets using gradient descent so you have an input hidden layers and an output layer graph native learning or graph neural networks or deep learning models take your graph as an input perform some kind of computation on that graph and then return another graph from the deepmind paper you have kind of your standard steps or you have your input graph you do an edge update you do a node update and then you do a global update and then you make a prediction a cool example of where this is actually being used is an electron path prediction so if you represent your molecules as graphs you can encode those into you know as you have your molecule it's a graph you represent it as a graph given to molecule graphs and some reagents what will they form and how will they form it so you have two input graphs in a reagent and you have a data set of these two were combined with this and you got this output you train the neural net to say here's my input graph here's my output graph what are the steps in between and then you can predict not just what two reactants will form but also what the mechanism by which they format is and since I'm crunched on time I'm not gonna go a lot into this but it's pretty cool and so just stepping back to where we got started so we start from building a knowledge graph hand engineering features using graph algorithms for features using graph embeddings to train custom algorithms for your graph in your use case and then graph neural network so you're staying kind of natively in your graph from end to end if this is exciting please check out the graph algorithms book feel free to contact me I can talk about this all day and so now just the comprehension check if people were paying attention The Hunger Games questions and see I should keep okay hi this is Jennifer so we do have one question coming in on the Q&A so asking are there embedding techniques that work beyond just ones and zeroes of the adjacency matrix in other words can embeddings typically based on the adjacency matrix that also embed node and edge labels don't think things like no defect do there are embeddings that exist to take into account more than the simple adjacency matrix so if you think about something like graphs those are not currently implemented in neo4j but they there they exist in there like a really active and exciting area of research so they're the kind of field is moving towards more sophisticated techniques where you can consider more than just the you know this is connected to this where you can say something like using PI torches big graph or a rescale or something like that you can say I actually want to look at different node labels or graphs age lets you look at attributes so research is ongoing in this area it's a matter of how do you take that into production someone asked about machine learning examples too sure about specifically about graph embeddings are just in general looks like graph ml examples so this will be posted to YouTube afterwards every example that we kind of walked through in here is an example where graphs were being used for machine learning if there's a specific use case you're curious about happy to talk more if if you're kind of more interested in a specific category or whatever you can type it into the Q&A box ok one on if your data is not originally in the graph do you see any reason for bringing the data to graph and then using graph embeddings to model it as vectors so so there's a couple of questions here so one is if your data is not in a graph should you bring it into a graph and the answer is if your data is possible to move into a graph and the thing you're trying to predict can benefit from a graph based feature then it would be beneficial to move into a graph right so if I'm talking about my my tell code churn prediction example I have my rows and columns but I have a suspicion that something like how many people two hops away in the graph tells me if someone is gonna leave or not then I would want to say okay I'm going to move this into a graph when you asked about should I use a graph embedding I think maybe the confusion is I'm saying well a graph embedding flattens your graph into a vector but what a graph embedding does is it uses the the relationships in your graph and the topology of that graph to learn waits for that vector so that vector actually represents the neighborhood around that node in the structure of your graph as something that's easy to put back into the end of that tabular data format and someone asked about using our with neo4j jewelry age of data science so I believe there is an AR connector that was put out by the lab steam and I click an experimental art driver so you could connect directly the other thing you can do is you can run things in u4j export it as a CSV and then import it into R so you can either connect via the art driver or sort of more hand engineered I want to use you know I want to export to a flat file and then pull it in okay probably one more question and then probably out of time so someone asks how big are the graphs number of nodes a number of edges for these pipelines and do you need distributed execution for these can you say something about performance scaling for these algorithms so for our algorithms the largest production use cases I've seen of algorithms has been on a multi terabyte graph with like I think the largest I've seen is like nine billion nodes and 20 billion edges so our algorithms scale really well but you need to have a sufficiently beefy machine so they can run concurrently they're optimized they run on an internal data structure that's customized for graph algorithms they scale really well and they actually don't require a distributed processing so what's really interesting is some graph algorithms just don't distribute very well so if you look at SPARC you'll see a handful of graph algorithms but not as many and that's because not all of them can be distributed so what neo4j lets you do is run over a giant graph and run those algorithms that don't distribute what wealth okay that's probably where we have to stop for today we will try to paste a couple more things into the chat I'll send a couple of links out as well to answer some things for those of you interested in learning more about this topic there is a lightning talk after this on leveraging graph algorithms and visualizations there's also one by Amy hablar and Mark Needham a full length session on community detection and recommendations I using graph algorithms and more of course another one from Alicia coming up after that on graph embeddings so if you're curious more about this topic there's plenty more material coming up and hopefully we'll answer all your questions throughout and thank you everyone for joining this was fun 