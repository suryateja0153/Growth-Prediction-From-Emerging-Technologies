 Oh, welcome to cataloging and cocktails, episode six, you've got Tim gaspare here, director of product to the world, and Juan secada, our principal scientist. Hey, Tim, how are you doing? Doing pretty good, how are you doing today? Great well, I'm excited always. This is my the middle of the week kind of our break. And I really enjoy this. And I'm actually looking very quickly here up the list of participants. I'm seeing a lot of new names. This is pretty cool. Yeah, welcome, everyone, really excited to have you here cataloging cocktails is where we get together, Juan and I, we have some topics as your we talk about data. We usually have drinks of some kind in hand. And we'll talk a little bit about what drinks we have today. But go ahead and check out the chat. We'll be watching the chat throughout the conversation. And ask any questions and let us know what you're drinking and what are you drinking. Well, I actually did make a drink today and not just beer or liquor. I don't know. I was looking at my what I had in my bar. And this is like this is a vodka Martini with some orange bitters and a little bit of an orange in there. And I kind of squeeze a bit of orange. It's OK. Well, not the way. It's not the best thing I've got to give anyone else out on is the orange flavor is a pretty strong or well, depends how much orange you want to go. Squeeze and squeeze that much into it. That's more the color than anything else. So Cheers. What are you drinking for. Is I got some local Garrison brothers, whiskey from high Texas, pretty close by to Austin, Texas, is starting to get a lot more different types of beverages. That's pretty cool. So what vodka drinking that is? It's not gray goose. It's the other one that I have, Belvedere. That's what I have. So, hey, for folks around, can you just if you want to share in the chat, where you're coming from and what are you drinking? And and as you mentioned, like we like to keep this first 30 minutes we're recording. We're having Tim and I will have a conversation. And then after 30 minutes, we'll stop recording and then you will open up the mix and just have a conversation and just note that we're recording. So if you have a camera on, it's fine, but you're being recorded. So so, Yeah. So we're happy. Where have we been? Let's do it quickly. Yeah we've had quite a few episodes now at this point. We're on episode six. We've had five episodes before this and yeah, we've covered a lot of ground. So we've talked about sort of a lot of the data problems that people face, you know, and we kind of started to look at some different types of personas, some personas that are more on sort of the data producer side. So you're sort of your engineers and your admins and your sort of caretakers for different systems versus sort of more the data consumers. Right so people who are your analysts or your scientists or even just sort of your knowledge workers, you need to download that Excel file every day or every week or whatever that might be. Right and then we also talked a little bit about a bridging kind of person, somebody who kind of bridges those two worlds and it helps kind of be a Steward across all those. Right and we all know that there's this concept of a data Steward who is a kind of a relatively well known pseudo title for people on the job that they do and kind of caretaking for the stuff. But we also introduced data product manager, as well as knowledge scientist as some sort of different ways to look at this as people who are really bridging those two worlds, sort of the technical on the business and really helping to sort of productize high value curated, high quality data products and data assets. And we talked about features as well, right? We talked about things like data catalogues, having business glossaries and lineage and search and, you know, quick tizer. Next week we'll be talking about lineage, more specifically search people and how people are really the center of everything. I don't know. Would you add anything to that one? No, I think that really recaps it. And on all the features and stuff you now, one of the things that we do, a data world in general, sorry, by the way, I'm sitting outside and I got chickens. My chickens just kind of walked off on the table. But anyway, so what are the things that we have a better world that we say is that we're data powered by a knowledge graph. And this is something that is kind of becoming more of a hot topic about what knowledge graphs and what does it mean for deko data catalog to be powered by knowledge graph? Why should it be powered by an autograph? Why should you care? And what even is a knowledge graph? Right so I think that was kind of we want to discuss today that started this discussion. So just kind of get a little bit of context into this term. Knowledge graph is a term that was popularized around 2012 by like Google. They came up with this blog post about introducing knowledge graph, which is basically they called it string's, not things. Essentially, in kind of my definition of a knowledge graph is you want to one your goal is to do data, integrating data to do data integration. And second, you want that you're real world business concepts and your real world business relationships. Are part of that data that's being integrated there, first class citizens, and when you start combining, you say, I want to go integrate data and I want my concepts and my relationships to be first class citizens. That's basically a knowledge graph. And it happens that you start the data model. You representing all this information happens to be in a graph. So that's why it's the knowledge graph aspect. And what we do is that we're able to accomplish linking metadata and data together. So data and metadata become one same thing that you can go across a single query and represent. And it happens to be that all of this is represented as a form of a graph. So that is kind of mind what I always call my presentation. That's one definition non-scientific, non pedantic and inclusive definition of what a knowledge graph is. So it's data integration, plus real business concepts and relationships on your first class citizens. Now, naturally, you have all these technologies to go represent, create knowledge graphs, and then you go into the two different types of kind of camps like the semantic web type of camp with RDF, or is this the property graph camp? At the end of the day, it's all a graph. There are reasons why you wanted to do one or the other. But for now, this is focus that you're thinking about, the model of a graph. And I think graphs are really, really important for data degradation, because if I imagine I take two data sets that are represented as a graph. And they're separated, how do I take two separated graphs and turn them into one? I just start adding edges relationships between the nodes in the graph and these two things that were separated start getting connected. So data integration is by definition, basically a graph problem is finding connections between all these different nodes in your graph. So I think that has always been kind of the realization of why you want to be able to use craftsmen's as a very flexible data model. But obviously, kind of for the last 20 plus years, a relational model has been the most important kind of the dominant model in industry. But we're now starting to see this rise again of graphs. And it's just what comes around goes around when I tell people, guess what was the first database that ever was out there in back in the 60s? It was a graph database, network databases or graph databases like I mean, hierarchical databases. Were these trees. Right? so that's where this all comes out. And then afterwards, the relational model came in. So that's how we see the world, is that groups are coming back and they've had a couple of iterations. But now the technology has really stepped up after so many years of working on it. So that's my quick definition of what is the knowledge graph? What do you think, Tim, based on everything you've seen? No, I agree with that. And I know you're going to go more into this, but I like that, that when we think about knowledge graph and we think about what sort of information you want to put in a knowledge graph, I think that usually people seem to be kind of thinking in two directions. Right they think about more like property graph type problems. Right more like information that makes sense to display in a graph like, you know, if you have a bunch of locations and those locations are connected to each other in some way, like cell towers and things like that. Right people think about like, you know, fraud and fraud detection cases and things like that. But then the other kind of set of these cases seems to revolve more around sort of the semantics around information. Right and I think especially in that use case, when we talk about metadata, we talk about data about our data. It seems like in general knowledge graphs and graph databases are sort of the perfect representation for that. Right because you've got sort of the underlying data itself, kind of represented by tables and columns and dashboards and things like that. And then you have a layer of data about those different things. And then on top of that data, that world, for example, we're not trying to be the one stop shop for all your data collection because sometimes you're using other tools, right? You're using things like maybe mantha for a lineage or you're using some data quality tool or you're using all these different things and you want to bring that all together into a common repository. Right it isn't always so easy to just be like, Oh yeah, I want all these things to magically come together. Having a graph representation makes it a lot easier for you to represent all that information. So this goes back to the discussion we've had before on the crawl, walk, run, right. So do you think about grabs? People immediately are knowledge, graphs and stuff they're thinking about, oh, I need to have a database. I need to get my data into the graph. And I see stuff that people literally just dump CSV files into a graph database. And then while my data is in the graph and somehow it magically I could go solve a lot of problems. No, that's like basically dumping a data into a lake. Like you are not solving any problem by doing that. So please stop doing that if you are so. But now it seems it seems that the way people want to go, just jump again into the deep end and go do stuff with graphs. And if we think about this, this may not it may sound boring. It may it's not sexy. But this is the way how we believe. This is our point of view. And frankly, and what I've been looking at for so long is crawl, walk and run. Let's look at our metadata first. And if you think about it. Your metadata is a graph for you, should you should you forget about your metadata. You want to be able to capture your metadata and how all your metadata happens to be connected. Guess what? You represent that as a graph. So are real world business concepts and relationships here. We're not talking about a customer or an order. We're talking about what is a table, what is a column, what are analysts? What are our dashboards? Right what are our business glossary? So those are parts of our metadata who are people? Are people are stewards, who's an owner of a database, who is an owner of this subset of the table. This is a column this column is derived from this other calcu, other table. And there was a query that represented this type of transformation. This column represents a calculation. And so a calculation itself is a concept in the ground. And so this is really, I think, your first step, if you think about it, your first novel is crafted honestly, I think should be a knowledge graph of your metadata. And that's how you start connecting things all together. That's how you know what's out there. It's how you can go. I mean, lineage itself is a graph, right? And that's the type of stuff that we do, is that when we go figure out, we go crawl stored procedures. I mean, what we do with mantid and go get a go kart Etl tools like when we get all that information that happens to be representative as a graph and that's how we're able to go trace all the lineage. And then you can go you want to go do really advanced stuff and figure out all the people that have used this column for this dashboard over the last amount of time. That's all data that's connected. And what's the better, best way of doing this than representative is a graph. I think for us that's kind of the key idea. Why your catalog of data you did a catalog should be basically powered by a knowledge graph. And if it's not because everything I just said, you can say, oh, I can just I can create a relational database, I guess. Of course, you can. But that means that you are in this rigid framework. And I think that's the other thing we need to go think about, which is the real big advantage of cataloging all your metadata represented in the graph is that today, you know what you're cataloging today, you know what data you have, or at least you're thinking of what do you have tomorrow? God knows what type of data is going to be around there. And so if you create your create your data catalog or you work with the data collection. So rigid, you can only catalog the stuff that we support today. How do you know that you able to be nimble and agile and flexible to go be able to bring in and catalog the metadata that's going to show up tomorrow? I think that's really, really important. What people think about this is really to build your foundation. Yeah, I mean, the flexibility is a huge aspect here. And I think that, you know, one example that even I know that we're experiencing in real time right now is data that world is one of the things that people are asking us is like, hey, can you model apis? Because we have APIs that we want to bring into the catalog. And and maybe they're like data data access APIs. Right and normally that kind of a thing coming along, whether it was to our customers or to us as a company, would be like, oh, god, now we have to completely rethink our data model. We have to change the way they were representing all these things. But but actually, because of the graph model, it becomes very easy for us to say, like, OK, well, tables in columns, that's the type of data. Right those are different data structure representations. And an API endpoint also might be sort of a representation. Right and maybe that's sort of at the same level as a table. Right and then you've got tables and columns and API endpoints. Both have properties. And so that's just one sort of an example of how this flexibility can kind of come into play and allow you to kind of future proof what you're doing. Well, just, don, here asking the question why graph databases were regarded as a failure due to inflexibility as businesses change with relational as a solution, where are they coming back now? So, I mean, I would argue this is a touchy subject about if you look at if I look at history. Right and I've been studying a lot of the history of knowledge graph, specifically going back to the 50s. So what we see is an original kind of in the networked world. Right when you have Charlie buchtmann comes up with ideas and things were very tightly coupled. So you needed to be able so you had a structure of data which happened to be the graph and you had to go, right. Basically query your data. You basically had to write a program that knew the structure of your data. And guess what? Your structures changes because requirements change your program, that extra data broke, so you need to go update that again. So then that was so it was it wasn't nimble at all. It was very tightly. So the whole idea of the relational model, that cord comes up with the same weight. We need to have this term called data independence. And I want to be able to go separate the way in. He actually thought about it from a mathematical point of view. I want to be able to think about sex. Right and that's what a relation is. The relation is, is a set of things. Evolution is like a table. And I'm seeing a set AAA and I'm seeing a set b, and then when you want to go do it, like, oh, I want to be able to find the intersection between AAA and b, guess what, that's where the joint is. Right so they start doing this and then he starts decoupling kind of this mathematical abstraction based on sex from the physical abstraction of data. So when you say ajoint v, you never say, oh, it has to be a which I'm going to join to be you. You don't say that because it could be bija joints 8 and you don't know what joint algorithm is going to be happen. It could be emergent, could be a hash join. It all the so when you write queries in school, it's at a higher level of abstraction and that's why you have to have compilers and optimizations and so forth. So you have this separation. Now what happens really interesting is that this is all in the 70s. Right and then the 80s come along and you would argue that a lot of people would say, well, you can't solve everything with relational. Right people are kind of being skeptical about things. And b, what comes and what comes up during this time is object oriented programming languages. So then they say, wait, I have to write code or I'm creating objects, but I'm my data is being persisted in this other thing called the relational database. So now I need to go take my programming language, which is in terms of objects, and we need to go change it into a query and go do this. And they said, no, why can't I just go query an object? And that object is persisted and this gives the right to object oriented databases. Right this happened all during the 80s and a lot of the work on graph databases kind of early on, more academic came during that time. But the whole point was that they got to separate it. People said, let's go start bringing that back together. We can have so many discussions on why object oriented databases failed and stuff, but they basically are not around anymore or they're very, very specific to very specific types of scenarios. So relational databases where you have I mean, Sybase at that time came up in Oracle and SQL server, all these things, they just became a gigantic big market about that. And what I would think is that the over time, the graph, the graph theory and the graph systems have been maturing to the point that we say what happened during the 2000s was all the big data and the no single revolution of being seamless. And that's where graphs came in again. Right, being documents sort of starting out like MongoDB and then you want to have graphs is just another natural data model that came back. So out of that one is that's the language. And that's kind of didymo. Let's come back also specifically because you have query languages and also because of all the semantic web work that happened all throughout the 20s that gave you a standardized graph data model and a query language. So I think it's just it's not a particular like there's so many pieces in history that occurred for us to graph to come back in. But bottom line, a graph data model is just flexible. It's just very nimble. Like I can just add an edge to the graph and my data continues. My database system continues to work. I don't need to go to find the schema beforehand and so forth, which that's a good thing. And also a bad thing. That's why you need so you still need to have schemas around. I believe there are situations where you don't need schemas, but you can still have schemas with graphs. Holon so I've been branton for a while. I don't know. What do you think? Now, I think that's I think that's good, I think, you know, I think what's interesting is it's sometimes the history provides a lot of context on how we kind of got to where we are today. And, you know, I actually think that your response around sort of the structured in the schema versus the seamless, I think that actually connects a little bit to a question that another person had around. You know, what about fast changing metadata, where the information may be changing shape pretty often, you know, think like real time data, document data, stream data, things like that. You know, I'm curious what you think. The first thing I'll add is that, you know, I think that one of the nice things about taking a graph representation and there's ways to do this in a structured representation. Right and we know some tools to do this, but it's especially easier in a graph representation. Is this concept the sort of generic object model, right. Where information is getting crawled and being collected and at first you're kind of collecting it all and you're kind of saying, OK, this is a generic analysis component or a generic data component. And then as you're bringing this data and you start to realize, oh, interesting, either I need to model this at a higher level. And I need to kind of think of this as like a blob. And I'm just going to let this information, be a blob. Right and then I'll kind of I'm going to process it later down the line. Or you say, hey, actually, you know, this information makes sense to kind of call properties or fields or slotted into sort of the metadata model in a more specific way. And then model it later. Right and so the idea of being able to model it later and that being a first class citizen and the underlying system, as opposed to more complex layers of abstraction that maybe is going to require a joint or many joins in most cases to kind of come to fruition. Is is nice, right? Yeah so so this is something that we built, I mean, within data where we built it this way. And it's built on a lot of open standards on just representing data sets and stuff like that. So we internally. So we have our own schema, our own model to represent any type of metadata. We call it dwek. The data that world enterprise, catalog ontology basically. But this stuff is built. We didn't invent it. We built it based on a bunch of open existing standards. So, for example, dickert gets is a very standard vocabulary to represent data sets. And then you have double core, which is something around there. Then you have phot, which is a friend of a friend, to help define relationships between people. You have Provo, which is a way to represent the provenance, which is something we use to represent lineage. So you have a bunch of these things that we start putting together and then basically you say, well, there's an asset, right? There is this thing that we're going to go catalog. And this asset can be a table which belongs to a database. It can be a column, which is connected to a table. It's going through a database. There can be an analysis and analysis could be, oh, we will make it very specific, a Tableau dashboards, that type of a power BI dashboard is one and so forth. Right and then you have oh, you also have scios. Write the simple knowledge organizational system. Right that's basically the standard to go represent taxonomy. So you start there's already all these standard ways to go represent a lot of the metadata and that helps you to be very flexible. And then you can say, look, either something that I'm cataloging exists in my because I'm cataloging the table. So I'm going to say, hey, this thing I just cataloged my graph. I'm going to say it's a table or it's something new. And I'm saying, you know what? We don't know what it is yet. And that's probably happening to the stuff that we're doing with, like, APIs really unclear. But we can go start bringing all this data in and then people can start accessing that data and querying it. And it allows us to be very flexible because otherwise, if you're going to go, you're going to go find a relational schema to bring it to go manage all the men that you're bringing in. You've got to come up with all these schemas. I mean, define it, which is you don't even know what these things are yet, right? Tomorrow, we don't know what system is out there that we want to go. I mean, like we have a new crawler for AEW as glue. So, I mean, that took us. That was pretty quick for us to go generate these things, and it's because we just don't have to. We have we have a model that allows us to bring in any type of data. I think people wouldn't sleep if we were building a data catalog built on just kind of traditional relational databases. I literally think that people would be going crazy internally. Yeah, I think it's easy to sometimes not even realize how much easier. We have it because of the graph approach that we're taking. And I think glue is a good example where we were starting to pull in these Lambda transformations. Right and we're like, OK, how do we want to represent these lambus? Right and we're like, OK, we're going to call it an activity. Right? and we're like, OK. And what about the lineage of one sort of land, a job interacting with that data and then writing it to another data? Right OK, cool, we'll just write that into prava. Right and it just makes it so easy in terms of like being able to accommodate those kinds of things. Now and then. So I know it's interesting that this we've got like five minutes left before we're going to open this up to everybody else. But I find it interesting that we've just had this discussion around metadata. Right we haven't talked about yet, although I'm actually representing data about customers and orders and stuff like that to go do interesting politics that just naturally the next step. But I mean, within your organization, you want to be able to organize all the data you have as a first step that you're calling. Let's get our metadata organized. And we generally believe that the best way to go do this is to go do this as a graph. Now, as I mean, let me just stop being a salesperson here about the world, because that's not my intention here. Go look at other people who have done this and I'll put some links so we know we started when I personally started looking into a little bit, kind of like the history of data catalogs. You look at the first tools that came out that were data catalogs or they didn't call themselves data catalogs at that time. But it's like folks at airbnb, right. Or folks at Lyft and folks at LinkedIn, they were creating I mean, they all had this idea that they needed to go democratize data to be able to give people the ability to go find their data. And so that's the ultimate premise. And they built something which now is considered a data catalog. Guess what, they built it on, so they all built it on different graph technologies, let it be, let it be, because they built that they used an existing graph database. I think other people, they implemented a graph approach within a relational database. Right so, again, I'm not saying the graph that that relational databases are going to go away or whatever. No, no, I'm not saying that at all. It's just the graph model that you want to go think about it, because it enables them to be very, very, very, very flexible about that. Actually, I had a quote here that I really liked, and this is from one of the articles I saw, Airbnb. They said a graph of the ecosystem has value far beyond tracking lineage and cross-functional information. Data is a proxy for the operations of a company. Analyzing the network helps the surface lines of communication and identify facets or disconnected information. So if you're really trying to understand how your business works. You want to track how who is using what and for what and guess what? That's that's just a question about how things are related. Might as well represent that all kind of a graft model. Yeah, oh, Thanks for posting certain. Yeah, no problem. As you mentioned that I wanted to get that in there and, you know, I really love this progression that you talk about where, you know, at first it's about creating that first knowledge back around your metadata. Right and then as you bring in knowledge, graph, knowledge, graphs around data itself, now it fits into already a structured framework where you have sort of metadata about your metadata, you have metadata about your data. All these things triangulate together and create sensibility around your data, not just human sensibility or human sort of UI that can kind of which is your catalog around that, but also machine readability around it. Right so that as you think about what the call, crawl, walk, run is right. In the future, you want to do more advanced things around and help around a automation, different things that when your data is all part your metadata and your data is part of that knowledge graph. Now that run aspect, which I think for most companies isn't really within reach right now, really starts to become more realistic. And so here's the transition from them. From the crawl to the walk is within your knowledge graph of your metadata. You start representing your business, glossary your vocabulary, and guess what, those terms there start to become the real world objects that your business folks talk about what isn't. You start defining what is an order, what is a customer, what is a product or different product categories. And then later on, you say, wait, I now want to represent my data in terms of this business view, which happens to be also represented as a graph. And you OK, where is the customer information? Or you realize there's multiple ways of customers, where's my order information? And then you start connecting that again, more connections, the concept of an order back to where your data is and you realize, oh, an order is everything that's in this table that has I mean, where everything work order, everything from the table called order where is active equals 1 and whatever. Right that's your mapping. And then you start adding more kind of adding the semantic layer on top of that. And then we start getting into the really fancy stuff of having meaningful data represented that business people can understand. And then you can go off to really cool graph analytics that people go do for recommendations for fraud detection, all that stuff that you're seeing out there. But if you're just going to jump into the deep end, I'm seeing people are treading water unsafely and there's so much risk. And I think you really want to build your foundation little by little. Anyways, I think we're at this hour a happy hour and it's so cool to so many people around. So any final parting thoughts there? Tim? no, just that. Thanks, everyone, for joining this part of the conversation in a second here. We'll transition to more of an open, open conversation. We can talk about metadata. Is your first knowledge graph or other questions or topics that might be of interest? And a quick shout out to next week. Next week, we'll actually have a special guest. Ernie, I think is actually on right now. He's a regular of cataloging cocktails products, head of product over at mantha. And we'll be talking about dan'l data lineage. And we actually have a webinar coming up tomorrow and anybody wants to join that. We'll post a link here in the video second. You can join us in the webinar tomorrow and then we'll have a catalog and cocktail conversation next week. So should be a lot of fun. Well, thanks, everybody, for coming in, and we'll see you around for the after party. Oh 