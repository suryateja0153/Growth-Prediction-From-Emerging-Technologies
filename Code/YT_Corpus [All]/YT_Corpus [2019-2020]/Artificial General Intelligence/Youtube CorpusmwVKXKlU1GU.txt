 [Music] let's begin with the jetsons fallacy so some of you may remember the cartoon The Jetsons and of course all of you know about the film Star Wars in both those cases notice that the world is depicted as having highly advanced artificial intelligences but the humans themselves are unenhanced well the historian Michael best says that this is a Jetsons fallacy it's a situation in which we assume that AI is capable of changing the world and forget that in fact artificial intelligence could be capable of changing the human mind hey I may go inside the head and that's what I'd like to talk about today the evolution of the human brain was constrained by metabolic and environmental demands but AI based brain enhancement technology could augment intelligence in a way that is far faster than biological evolution I call this exciting new enterprise mind design mine design is a kind of intelligent design if you will but we not some God purport to be the creator's today as a philosopher what I'm going to do is I'm going to explore the idea of mind design using artificial intelligence technologies invasively inside the head and in particular I'm going to explore the idea of a mind machine merger and I'm going to ask the question could you really merge with artificial intelligence Elon Musk for instance has recently commented that humans can keep up with artificial intelligence by having some sort of merger of biological intelligence and human intelligence to this end a few years ago he founded the company neural link that has a am as developing an implantable chip in the head that allows data from your brain to travel wirelessly to your digital devices there's lots of current work in a similar vein for instance the company kernel and I imagine DARPA is working on similar things I mean they are working on it officially for the purpose of medical therapies but one person's therapy could become enhancement technology and in the domain of neural prosthetics or brain enhancement or excuse me brain chip therapies Ted Berger has a very well-known project involving the artificial hippocampus which is now in clinical trials in humans to aid with memory loss so in this talk what I'm going to do is I'm going to suppose that these kinds of technologies take off AI does move inside of the head and musk himself suggests that this could be quite beneficial for the future of humanity for two reasons first consider the worry of technological unemployment with increasing automation and increasing sophistication of AI technology must suggest that we enhance our brains in order to keep up with artificial intelligence further he suggested it's a mean for us to understand the complex workings of super-intelligent AIS that we may develop at some point in the future well is all of this really possible I want to look at these questions from a philosophical standpoint - let me start with a thought experiment that brings it home it involves you so I want you to suppose that it's 2040 and you're out on a shopping trip you go to the center for mind design there you can choose from a variety of brain enhancements human calculate would give you the ability to do mathematics in a highly advanced way like a savant Zen garden give you a Zen experiences of a Zen master without needing the years of practice and if clinical trials go as planned customers would soon be able to purchase merge which allows you to gradually through the use of brain chips in the head to eventually just augment your intelligence and then migrate on to the cloud so let me ask you this how many of you would choose one or more enhancements at the Center for mind design assuming that the medical technology is good yeah I mean who does it want to be more efficient right be smarter keep up with super intelligence perhaps one day stay employed that's sort of scary well as a philosopher I have so many concerns about all of this I mean one thing that I'm not really gonna get to today in any detail is that even though the enhancement could lead to extreme intelligence and extreme longevity even because you could outlive your biological brain there are worries that this could lead to a dystopia in which individuals are forced to get enhancements in order to keep their jobs or keep up with a eyes or only the rich have enhancements and of course there are massive privacy worries with the use of artificial intelligence and data technology today so imagine if AI goes inside the head but let's suppose that regulatory work is done and it's done well and these issues do not arise so let's suppose that you really do have an option here to safely enhance without these sci-fi dystopian nightmares in your future well in this case I want to suggest that there are some philosophical issues you should also consider I want to talk first though about what exactly it means to even merge with AI so transhumanists are individuals like Elon Musk and Ray Kurzweil who think that humans can overcome their biological limitations through science and technology and it's awfully hard to object to that as it's framed but if you look at the trajectory for enhancement that they offer it's far more radical than merely what the generic claim of transhumanism says indeed if you look here it says that you start with the 21st century unenhanced human and then that person engages in significant upgrading with cognitive and other physical enhancements and then at some point they become posthuman they become a cyborg who's no longer even technically human then as the technology progresses and here you get to this idea of technological immortality you could in fact even upload onto the cloud because you've transferred your neural existence into a digital one ok so the idea then is that you are able to transcend your biological brain well as I framed this view notice that these transhumanists are suggesting that different parts of the brain will actually be removed and replaced with AI components that's going to be important to my later points well you might wonder why even talk about such a speculative position it sounds like a science fiction novel but of course it seems increasingly with AI technologies that science fiction can become science fact far quicker than we think further I find in my experience at Washington DC where I work with members of Congress and others in politics as well is just in interacting with tech leaders that transhumanism has become very influential it's an influential view of the future of humanity that we see in pop culture as well this idea of merging with our technologies so that we're no longer biological beings so it's that sensible my perspective is this I suspect that there could be design ceilings on human intelligence augmentation I'm interested in limits on human intelligence enhancement that aren't imposed by evolution or medicine they are philosophical in nature ok so that's what I'm going to talk about of course neuro technology will inevitably have its own limits as well but today I'm going to look at philosophical walls on enhancement that may be there and that should actually influence the way we think about the human future as well as the direction we go with neuro technology and the way that we decide we want to integrate with artificial intelligence if we do that at all first I'm going to talk about a conscious and a ceiling that arises if microchips fail to underlie conscious experience then I'm going to talk about a self-sealing a point beyond which the person who attempts to enhance is no longer the same individual they were before that individual who saw enhancement actually stops existing ok this is an issue in philosophy in the field of metaphysics ok so let's get started I want to start with consciousness and consciousness is in fact the center point of my new book so when you see the rich use of a sunset or you smell the aroma of your morning coffee notice that it feels like something to be you you are having conscious experience okay you are conscious throughout your waking life and even when you're dreaming it's that your life has a felt quality to it which makes it so wonderful for you to exist at times but also so incredibly difficult at other times consciousness is not the same thing as conscience I remember when I first thought of these issues as an undergrad I kind of confuse them and it's natural so Jeffrey Dahmer didn't have much of a conscience but he was a conscious being it felt like something to be him okay so that's something to bear in mind now Richard Dawkins said something very provocative he often does in this film that we were both on called super sapiens the rise of the mind he said it's not obvious to me that a replacement of our species by our own technological creations would necessarily be a bad thing and I hear this a lot I mean you know maybe they'll be better than us in a variety of ways we might think but just note something if non conscious artificial intelligences supplant us it won't feel like anything to be there right if they supplant all biological intelligences on earth that would actually be a nightmare right hey I would hardly be promoting human flourishing instead it would lead to the end of consciousness on earth so I think it's important that we figure out whether a AI can be conscious and the first half of my book does in it tries to do that I won't say I definitively prove to anything but what I did do was take a wait-and-see approach and argue that the situation is far more nuanced than the techno optimist like Elon Musk and Ray Kurzweil argue okay so I want to now mention the consciousness ceiling and then moved the self-sealing so what if you buy merge remember at the Center for mine design when you had a choice of different enhancements the last one was the radical one merge in which you gradually uploaded your existence to the cloud notice that if artificial intelligence isn't conscious then merging with AI would be a terrible idea wouldn't it because you would lose consciousness so if microchips turn out to be the wrong stuff for consciousness then a my machine merger can't happen okay and also the robots around us no matter how human-like they look or behave it won't feel like anything to be them there would be a wall on human enhancement you see now there is an important reply to this much of what the brain engages in is actually non conscious computation only a small amount of our mental activities are actually conscious at any given time so you might say well we could use artificial intelligence technologies to enhance the parts of the brain in which we don't have any activity that's conscious so it's just that small part of the brain that underlies conscious experience that is off limits well here's the problem both working memory and attention turn out to be key mental functions to our capacity to integrate information but they're notoriously slow there are attentional bottlenecks and it's very difficult to us for us to even remember phone numbers so the problem is that those mental faculties are implicated in current research as being part of the neural basis of consciousness so if it turns out that microchips are the wrong stuff for consciousness it will be difficult to enhance those parts of the brain through artificial intelligence we should look to biological enhancements if we choose to enhance but in that case that consciousness sealing emerges you see so enhancement could hit a wall and it hits its wall because of an issue which is deeply philosophical the nature of consciousness okay now what I want to do is I want to turn to the second design ceiling or wall on human intelligence augmentation that may or may not exist okay suppose for the sake of discussion that the consciousness ceiling does not arise so microchips can be the right stuff to underlie human conscious experience so we can swap out neural tissue with artificial intelligence components and not lose the felt quality of our mental lives well even if this is the case I want to suggest that there's a deep problem so go back to the mind design center and think about the menu of enhancements so you have these alluring possibilities right I like the idea of getting Zen garden right so in order to understand whether you should purchase these enhancements and even seek to merge with AI it's important that you understand what you are okay that is to say it's important to think about the nature of the self mind and person in particular let's ask what is it to even be a person would you continue to exist if you radically change your intelligence levels and your mental all kinds of mental capacities or would you be replaced by someone or something else to answer this question we have to look at the metaphysics of everyday object so metaphysics is a key area in philosophy that studies the fundamental nature of reality and I'll use an example consider getting an espresso shot you're standing in front of the espresso machine and I say to you okay they just turned the Machine off has the Machine ceased to exist in any kind of real sense and you know your answer is like well no because you haven't changed anything essential about the machine but suppose I grab my ray gun and I vaporize the machine well then you're gonna say yes the machine has in fact cease to exist the upshot is that some features of the thing are essential to its continuing to exist while others are not and the big question here is what is essential for you to continue existing how many of you would say your brain seems reasonable okay so I think we need to think about this before we enhance so consider the idea that you are your brain or that your brain is somehow essential to your survival if that's the case you shouldn't buy merge because you would have removed parts of your biological brain so you'd be killing yourself right and how many of you are confident that you're not your brain and say nervous system sort of doesn't matter you can add all kinds of other components so only one person you see okay so the point here is that even if the technology works in that case the sharper mind and fitter body that you get through enhancement would be experienced by someone else you would have ended your life in the process of enhancing that's not much of an enhancement right so that's why it's important to think through these issues because we want to avoid perverse realizations of AI technology this is the self-sealing net it's a point beyond which the person who attempts to enhance is no longer the same individual they were before for the procedure causes the individual who sought enhancement to no longer exist the problem is that the nature of the self is extremely controversial in the field of metaphysics we don't know whether there is such a self-sealing because we don't definitively know the nature of the self and we don't know how high or how low the self situating would be situated so let me explain this in a little bit more detail so there are various theories in the field of metaphysics on the nature of the person one is simply brain based materialism which says you are your brain but another one which a lot of transhumanists identify with is what's called the psychological continuity view and on that view you are essentially your memories and your ability to reflect on yourself this goes back to the work of the philosopher Locke and in its most general form you are your overall psychological configuration what Ray Kurzweil and a lot of other transhumanists refer to as their pattern well pattern ISM is this version of the psychological continuity view that a lot of transhumanists like Nick Bostrom and Ray Kurzweil hold and as a cognitive scientist it appeals to me as well at least initially it says in particular what is essential to you is your computational configuration the sensory systems or subsystems that the brain has such as early vision the association areas that integrate the basic sensory subsystems the neural circuitry making up your domain general reasoning your attentional system your memories and so on together this forms the algorithm that your brain computes how's that sound so that sound like a good view yeah I see some nods I mean I think it is attractive at least at first blush but what I want to ask shortly is whether it really justifies the perspective that you should merge with AI other views that have been very important in these debates and in society as well for example consider the soul view which just says that you are your soul okay another view that has been very influential in philosophy and also within Buddhism is the no self view this says the self is an illusion there no underlying self there there's no survival because there's really no person so now that we have some of these theories in our minds let's go back to the question should you merge with AI well each of these views of personal identity actually has its own implications about whether you should enhance your brain in these radical ways if your brain basement materialist as I mentioned then you can't change substrates so you cannot merge with artificial intelligence in the way the transhumanists envisioned so these invasive brain chips if they actually will replace the neural tissue will actually end up eventually killing you right at some point and you don't know where you don't know what point that will be the case you'd be replaced by something else so that means that neuro technology should develop biological brain enhancements and minimal AI enhancements that do not replace or damage key parts of the brain so there's a concrete proposal for research there based on that philosophical issue the soul theory on the other hand suggests that your decision to enhance would seem to depend on whether you have justification for believing the enhanced brain and body would actually retain that soul or immaterial mind and that's an issue for religious advisors okay the no self view says that you can't really merge with AI at all because there's no self that would survive in any case right there's no you as Nietzsche puts it the AI is a grammatical fiction still you may strive to enhance for instance you might find intrinsic value in adding more super intelligence to the universe you might value life-forms with higher forms of consciousness and think that your successor should be such an individual now let's turn to pattern ISM as I mentioned this is the view adopted by many transhumanists so if we have the transhumanist view of the nature of the self in hands you would think it would be easy to justify merging with artificial intelligence not so there are so many problems with the view I'll just name the key one a key one is called the reduplicating problem so suppose you're just your pattern if that's the case then suppose you upload your pattern in principle couldn't it be downloaded to hundreds of copies of you maybe they're clones of your biological body which one is you right are all of them you I mean if you're asking questions about your own survival these are life-and-death issues right it may be fun to adopt a certain perspective on things when you're talking your friends but would you bet your life that you could really be located in say a hundred different spots that's called the reduplicating problem your pattern then isn't sufficient for identity over time but there's a retort and that is to say that an individual is the same person over time not just when they have the same pattern but also when there's a sort of space-time worm that connects them over time so as you move throughout your life over time you trace out a kind of trajectory through time-space right so physicists talk about your life as being a sort of worm in space-time you move over time through space no brakes are allowed on that view okay so if the psychological continuity view modifies their position saying this that you're not just your pattern but you're the worm you carve out through space-time you can't survive uploading because your would be broken right and even if you took out like a third of your brain and located it somewhere else for example or even if you replaced your brain with microchips that wouldn't be anything like a normal space-time worm so what I'm wondering is how this position even justifies radical enhancements because I would assume that if you know transhumanists are suggesting this kind of route for the future of humanity there would be some underlying coherent rationale for the position but of course I'm just talking about the leading kind of theory of the nature of person maybe they have something else in mind for instance the influential transhumanists Jim Hughes is a Buddhist so he takes the no self view okay now there is a retort to this and it is that someone could in fact still merge with artificial intelligence through a series of gradual but cumulatively significant enhancements that add AI based components inside the head slowly replacing neural tissue so this is a slow kind of alteration this wouldn't be uploading because once thinking would still be in the head but the series still amounts to a transfer of your mental life over to another substrate so then in a sense you're still merging with AI well I've already said it's a little weird on the space-time worm front but let's put that issue aside I think there are also some other problems here the problem is this where does the pattern continue and when does it end for instance suppose you lose all of the memories of your past are you the same person you were before or have you started to become a different person entirely and how would you find out whether you're truly someone who has survived right maybe deleting a few bad chess-playing habits through some of these brain enhancement technologies will turn out to be kosher it will turn out to be a continuation of your pattern but what about a serious mind sculpting endeavor like the kind of enhancements I've raised at the beginning of this talk the kind of enhancements like Zen garden or merge where is the self sealing how do we know where it starts and what instances of a pattern are still instances of you that's the question if the self is just the mind excuse me if the self is just the brain you've died you've died at some point okay so you have to know the answer to this before you borrow embark upon radical enhancement okay so some upshots from today I'm leaving you with some known unknowns if you will we don't know if there are self and consciousness ceilings if there are you can't merge with AI and all the money that's being spent on these sorts of technologies to go inside the head had better keep these issues in mind people though who have the option for these enhancements say forty years from now may just ignore these warnings if the technology does get developed because they might not like philosophy or they might feel secure that they have an answer to the question what is the nature of the person but they could be wrong right and if that's the case then you know they will have paid money to end their own existence right now let's go back to mus twin goals he suggested that we should merge with AI to alleviate technological unemployment that's anticipated to happen in the future due to artificial intelligence technology jeez and to keep up with the complex computations of super intelligent AI well some of the humans who ignored the philosophical warnings may still be able to play this role right but it's still not a way that AI is promoting human flourishing in fact the thing to do in this situation is to make sure that the public understands the risks which leads me to some some more suggestions but first before I sum up with suggestions I want to mention the cosmic import of these issues because as the NASA chair my job is to think about our place in the larger universe of intelligent systems should other intelligences exist so there are all these exoplanets and they're said to be potentially habitable maybe they're inhabited and maybe there's intelligent life and it survives its technological maturity and maybe other worlds are developing their own AI technologies if so the issues I've raised today do not just arise for earth issues about the future of intelligence whether these future beings would be conscious or not it impacts the understanding we have of the evolution of intelligent life throughout the universe so again these issues are crucial the takeaway here to go back to Earth is that as AI technology turns inward reshaping the human brain we may actually be playing with tools that we don't understand how to use the self the mind and consciousness an insufficient grasp of the nature of the self mind or consciousness could actually under the use of artificial intelligence and brain enhancement technology so my suggestion then as we move forward is that philosophy and AI and neuro technology stay in dialogue because often our social development lags behind our technological innovations and it's important that we hit the ground running on these issues and concretely we should definitely watch the results of implanted chips as they're developed when they start to replace parts of the brain that are found to underlie conscious experience because we will be able to tell or so I argue in my book that the felt quality of experience has been altered by the AI technology so in other words we will learn whether microchips are the right stuff for consciousness as we replace parts of the brain responsible for consciousness in the context of neural prosthetics so already medicine is working on all sorts of chips in the brain right as I mentioned at the beginning of my talk such as the artificial hippocampus so should we begin to replace parts of the brain that underlie consciousness we should see whether consciousness has been altered and that will instruct us on whether microchips of that sort actually underlie conscious experience or whether the whole idea of machine consciousness is off the table so that's productive I think there we may actually see an answer to the consciousness ceiling issue okay on the other hand I don't know how we would ever figure out the self ceiling issue I think that is very difficult because if you replace parts of your brain with isomorphic chips chips that do exactly the same thing right you may not you may cease to exist but that creature there is still functioning and has highly sophisticated abilities and it may and believe it's you so the answer here the path forward in this context is not to stop working on brain enhancement technologies instead I believe we need to inform the public of the risks so in the context of genetic testing for example most hospitals require that individuals have genetic counseling before getting their test results so that they understand the perils of genetic testing as well as the benefits well I think you know 40 years down the road should people actually consider brain implant technologies for enhancement purposes they should actually sit down and learn the philosophy okay because otherwise it's disingenuous of AI companies to develop the technology and sell it to people so that they can keep their jobs or keep up with the complex computations of super intelligence and of course all this has been assuming that the use of AI in the head still respects people's privacy and that there aren't horrible cybersecurity nightmares there furthermore even enhancements that merely involved the rapid or even gradual replacement of parts of one's brain without enhancing one's cognitive or perceptual skills those might be risky you see because as discussed the brain could turn out to be essential to the self and in that case you would have died so a path forward is to perhaps seek instead a limited integration with AI if you're concerned about these issues through the use of external devices such as wearables or implants that don't remove existing brain tissue but some problems still arise if you put implants say elsewhere maybe you No remove the appendix and add some brain chips there or what not if you radically alter your pattern and pattern ISM is right you could still cease to exist thank you with all the conclusions about in these situations where we consider the brain to be dead or ourself to be dead why not looking at it as a instead being dead we just evolved like I'm not myself I'm not the same self with yesterday's myself I've changed a little bit yeah that's a really good question I mean I think the real issue here is if you take a picture of yourself from kindergarten or first grade and you actually are told that that person would cease to exist the person in the picture who's you as opposed to the rest of the class you would probably worry that you now would not exist anymore right so the real question here is which changes are just changes that evolve you as a person like ways you develop right like what you made you're in who you marry I mean these are all monumental shifts in who you are but they are not what I've called alterations in your essential properties so the question here is what is essential to you such that you would no longer exist anymore and I went through several answers I mean one is your brain one is your soul one is this idea that there's some sort of psychological continuity right and another a very important one is that there is no self so this whole thing is just you know looking for something that's not there so I do think we have to engage with these issues right and try to figure out which are the scary things that we shouldn't change if we care about survival is there any thinking unlike the development of these brain chips for animals like because for a lot of cases an animal like you don't you may or may not care about its stream of consciousness if it's the same self but there still might be some advantages to you know like make a cow smarter to lead the herd somewhere and even in this case it was a different cow you don't really care interesting so this science fiction writer David Brin I don't know how many of you read science fiction but he writes about uplifting animals right like uplifting their intelligences so I mean I don't you know I'm a big animal rights person so I don't like the idea of animals being experimented on at all and I think you know I don't know if anyone doing it to change animal cognition so much as experiment on what would happen with human cognition so like Ted Berger before he did put the artificial hippocampus in you know human experiments he used it in the context of great apes ok yeah it just seems that like the one of the conclusions seems like if it kills yourself I mean might be impossible to know if that happens but if that does happen you seem to be suggesting that like that puts an end to this kind of development whereas it seems like the natural progression it was like okay if it does kill yourself you still have this other alternatives within animals or like who knows yeah so I just don't think that there would be much of an incentives to develop it in non-human animals if you couldn't use that kind of technology in the human brain right from a medical perspective I mean I mean maybe from a medical perspective but not economical standpoint sure you know like like have a smarter dog or something you know there's a lot of like then you don't have to have people work to if you have a Kyle that can do everything like oh I see so in other words could animal control like from agricultural Oh scary yeah yeah no I mean that's a really good point I see what you're saying now you know I hope that if it is done it's done humanely you know when you look at the history of factory farming and you know in this country you know it hasn't been extremely humane as a practice you can imagine that if we did all this testing on animals and we so didn't know whether or not it kills the the self of the animal but they seem to have some you know they're they're now an enhanced animal in some way I can imagine a dystopian future in which that kind of technology is used on humans who have committed crimes and things like that where you know society no longer cares if this person continues to exist as their self but they may be more useful to society being an enhanced human who may not even well I think there's a problem that might emerge in authoritarian dictatorships right I mean you know look at what happens to prisoners in China you know their organs can be harvested and so I think if there's the possibility of creating super soldiers and these decisions are in the hands of authoritarian dictatorships or individuals who are smart super smart we absolutely have human rights worries and so you know my job is to raise the philosophical issues which I think are actually relevant even in countries that are democratic because they involve misunderstandings of the underlying philosophical issues right but yeah AI technology as you all know in the hands of an authoritarian dictatorship can involve all kinds of terrible practices yeah so since I already have the mic yeah kind of an unrelated question that I have for you is so this this point of view that musk seems to have that you know as AI systems continue to get better and better humans may need or want to keep up with them in some way like in in my personal opinion it seems like it's coming from a bad place right like in the 60s Doug Engelbart and other people like that imagined these kind of symbiotic relationships between human and humans and machines where you end up being an Augmented human where you're not really replacing anything in your brain maybe you're wearing a device or whatever where you know the fact that you're wearing a device like that you can now do things that you wouldn't otherwise be able to do and so like in in my opinion I think that future would be a nicer one to live in than a future in which people are kind of messing around with their you know innards or so I was wondering if you had thoughts on on that yeah yeah I mean I think wearables you know are under development as you know Facebook just bought control apps for instance and you know that is one path to integration with AI I still think that there are privacy issues right I mean you know Facebook's already been you know selling our data all over the place and not telling us transparently so you know if AI is something we wear and that data's just collected and gathered I mean let's hope that AI regulations improve so that people like you can do your job without worrying about these you know awful uses of the technology you want AI for human flourishing that's what we all want so I think there are some concerns but yes that's the path in which there wouldn't be these radical worries about personal identity I on the other hand I didn't mean to sound totally anti invasive brain enhancement I mean it could be for instance that technology is capable of enhancing the brain in all sorts of ways like through the use of biological enhancements so you know what if nanobots are capable of helping us you know think better and our brains live longer I mean you know I'm very transient in a certain way like the generic statement of transhumanism that we should use science and technology to improve our lives is something that I think a lot of us agree with I mean we absolutely should pursue it but you know my claim today was it the invasive uses of neuro technology like should we really put chips in the head we'd better watch out for shifts that are too radical in our personalities especially if you believe pattern ISM or if the chips actually end up removing or damaging parts of the biological brain of course if somebody needs a neuro prosthetic if they need a brain chip because that part of the brain isn't working properly that's another matter I'm very excited for instance about the developments over at neural link to help individuals who need to communicate with digital technology who are locked in right and so I'm not arguing against that at all yeah building on top of the last question or the last last question in your head so in my personal opinion there is no way that we can stop this so the whole AI development is like unstoppable and also as human beings the how they evolve and and be here in the first place we have some genes from bacterias that just got into us and became part of us and also along with our evolution there were other like cousins of human beings and some of them just extinguish and some of them were like a killed off by our ancestors so so so my point is that if you do now if we do not do this ai stuff some other people will kind of evolve into the aah right so my my question is this if that happens what are we going to do about it great um it's funny because my daughter Allie who's in the audience she and I were just talking about this we were driving the other day I think that's a wonderful point to raise because I think the idea that something's inevitable is often raised in the context of AI developments and especially if you think that some other country with less of a concern for human rights might develop it right and it kind of implicitly causes us to think we have an AI arms race on our hands and you know what if the next domain that involves you know an so called arms race or a race for supremacy is actually us that is what if the brain becomes an economic commodity or something that we feel needs to be enhanced so that we can maintain parity with another country so I think the important thing here is public education and AI regulation right like I said and I don't think someone will want to enhance their brain in radical ways if they believe they're not going to survive because most people who sign up for enhancements are doing it because they think that it constitutes survival there are other ways that we could have a society that keeps up technologically we don't need to throw people under the bus and have a perverse realization of AI technology so I began the talk by talking about the nature of conscious experience and what we really want to do is we want to maximize conscious experience that is we want to ensure the flourishing of conscious beings and to do that we need to understand whether microchips even are capable of underlying conscious experience right and we also want to make sure that the individual who is considering an enhancement will continue to exist right so I think there probably are ways that we as a society can productively move forward and use AI for human flourishing but we just have to bear in mind these philosophical debates a couple of weeks ago we had a Sean Carroll as a guest who talked about quantum worlds and many worlds theory in which case we're not talking about a worm going through space-time but different branches so my question is in this case if we merge with AI do you think it would kill a branch would it add one or how the conscious oh that's so cool that's so cool I don't think well first of all don't get me started on the many-worlds interpretation because you know I think that whole thing is rubbish to be honest that interpretation of quantum mechanics but I don't think in any world you know where you like you know split would you survive if it's the case that you know you are your brain if you are your brain you cease to exist right unless there's a world where you didn't enhance you know and there are this gets into philosophy because in some other universe these you know these parallel universes that creature maybe your doppelganger but it's not really you right I mean it's somebody who resembles you in all sorts of ways but you've died in your timeline this does sounds a lot like what's that film twelve Monkeys right yeah but I love the physics stuff and I know Sean's work that's great that you had him here yeah I'm all over the emergent space-time issue super cool but you have many worlds have you thought of this these philosophical questions you proposed in the context of drugs because it seems to me that all of these questions can be applied to drugs you know these are substances that alter the chemical structure of the brain so you could say that if for those who believe that there are brain you could say that draw drugs if they alter the brain yes yeah I think people grapple with these sorts of issues the same way yeah yeah people grapple with these already these issues I mean they grapple with them in the context of taking say psychiatric medication that they feel changes them drastically so if they're already grappling with these issues in the context of something that seems may seem somewhat moderate and everyday like taking you know psychiatric medication can you imagine what it would be like to walk into a mind Design Center and change all sorts of cognitive abilities this would be potentially life-changing right and life-changing in a way that isn't just like life-changing when you start college it's like life ending you see so you seem to have a little bit of a negative preconception about the pattern continuity train of consciousness kind of thing so doing like a full brain replacement or an upload is one of those things that since we can't observe the self and there's no way of proving that the self exists after this kind of operation that we immediately should we never pursue that train of thought is that something that's just completely off limits in your mind or is it something that we should be you know probing and exploring and it's still on the table it's the latter so I'm doing I wrote the book for people like you you know and for the younger generations who may have to make decisions about machine consciousness and brain enhancement and I think everybody considering these issues should deliberate and understand that a stance of what I call metaphysical humility is suggested and that means that understand that there's no easy answer to these vexing questions in fact these are classic philosophical issues which if you've taken philosophy class you realize you can't really definitively prove something often when it comes to these classic philosophical debates because you know they're very difficult and you know how would you run an experiment on whether the self is a pattern so what I want is for people to be humble in the face of this and some people may choose to be extremely daring and maybe they don't even really care if they continue to exist but I want them to understand the issues if you can reduce the philosophical problem to the question of whether you'd be killing yourself or not then I say there might be an argument that in countries where euthanasia was already illegal like people have already done the philosophical work to decide that it's okay to upload themselves have you thought about it euthanasia that's really interesting I mean I think there are some issues there that are similar because it's about you know the right to die right and so somebody who believes that they may not continue to exist but say values super intelligence or something I mean maybe they just they're done with their time I mean you know suppose we are able to live very very long lives 300 years and you know we have end-of-life parties and we decide that we're going to morph into something else and we find that spiritually important for us that's great I mean I'm pro-choice in these ways but I think that public engagement with these issues is key so that people can deliberate with the philosophical issues in mind thank you you you 