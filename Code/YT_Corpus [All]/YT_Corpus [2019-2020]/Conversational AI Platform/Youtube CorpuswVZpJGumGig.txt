 [Music] hi and welcome to our channel my name is daya and I'm a part of the executor research team at etc we built software to test software do check out our website exact procom if you want to learn more about us feel free to subscribe to this channel and hit the bell button if you want to see all the new videos and we have plenty of those coming up today we'll talk about testing the intelligence of a iie let's start with defining what AI is AI is machine behavior or function that exhibits the intelligence and behavior of humans there are seven widely accepted patterns in which AI can be implemented and that means there are seven different ways in which I can substitute for a human being and this is where it gets tricky while we do trust qualified humans to make decisions in all kinds of mission critical areas we don't yet trust AI neither do we have mechanisms in place to ensure its efficient performance nonetheless AI is obviously gaining traction and governments all around the world are moving quickly to ensure that the legal framework remains up to date visa via the technology change and can indeed face the new challenges posed by AI in fact the regulatory bodies of many countries have already issued some form of official documentation on AI bait prescriptive or descriptive in nature unequivocally in the coming years comprehensive AI regulation is expected to come to life so how do make sure that AI does what it should and does it well in its AI and software testing foundation syllabus the Alliance for quality suggests that AI systems should be assessed pretty much like other traditional IT systems that is against a certain set of quality characteristics worked out by the QA industry in addition to these characteristics there are three criteria applicable specifically to AI systems and these are the ability to learn the ability to generalize and trustworthiness regulators predominantly highlight the importance of human agency and oversight technical safety privacy and data governance societal and environmental well-being as well as accountability is key aspect of implementation the ability to generalize is understood is the ability of the system to apply to different previously unseen scenarios it's as important to characteristic for an AI based system as it is for any other non deterministic system in that AI systems and complex platforms underpinning financial market infrastructures are very much alike in AI systems the ability to generalize is usually associated with variance it refers to a model sensitivity to specific sets of training data however traditional meaning non AI based complex financial platforms perform similarly being tested on a relatively small set of expected data they experience failures when prompted with new data thus the test approach focusing on the ability to generalize is equally applicable to traditional as well as AI systems so there are a lot of similarities in how we approach quality assurance of complex non deterministic systems whether they are built with traditional technologies or AI based ones testing activities in general can be affected by the same cognitive patterns as every other activity involving human judgment there is in fact quite a number of cognitive biases affecting our decision-making in every area on a daily basis software testing is not an exception when it comes to software engineering biases a quite a serious impediment to begin with but some types of systems under test tend to be more susceptible to specific ones let's look at the most common areas of application of AI to the financial services industry we will see how well they align with the cognitive biases commonly manifesting themselves in quality assurance activities around these areas machine-readable news or mrn is one of these areas basically mrn is data in an easy to consume format which enables AI analyzers to define the sentiments behind the news pieces and extract information on new trading opportunities market inefficiencies event risks etc testing of this type of AI systems would mean assessment of performance of an M RN analyzing algorithm which largely depends on the underlying textual data the media pieces tend to be full of fixed views and opinions and the sentiments attributed to a particular topic in the mark-up process can be different from the author's actual intent hence the main problem of the news media is its perception via the prism of confirmation bias that is when a person interprets information in a way that affirms their prior believes and hypotheses when testing AI based systems it's important to avoid confirmation bias as well according to researchers this bias is very common in testing as well as in software engineering in general one of the most illustrative examples of the confirmation bias in software testing is the BDD approach it's focused specifically on checking the lines in feature files rather than exploring all the possible paths of interaction with the system under test make sure you check out one of our latest white papers on testing the intelligence of AI it contains all the scientific sources we relied on while preparing this research you'll find a link in the description below the next type of systems highly prone to biases are conversational assistant systems these are a very common part of banking insurance and portfolio management services just a mere enumeration of the virtual assistants names allow us to suggest that the most common bias associated with testing chat BOTS would be anthropocentric bias it's no secret that we tend to perceive objects and processes around us by analogy to humans vivid example is provided by the story published in the Washington Post in the story a colonel calls off the experiment with a mind of using robot being enabled to watch and I'm quoting the burn scarred and crippled machine drag itself forward on its last leg he described the test as inhumane another example demonstrating this Chandon see is provided by Kate darlings research about compassion towards robot dinosaurs from the software testing perspective this bias can obscure the understanding that what is evident for human being can be a challenge for any system with conversational agents the most typical example is anaphoric relations while for a human it's easy to say what a pronoun refers to for a machine it would be easier to look at the closest word in the context another example is misspellings a simple typo or an extra question mark can derail the otherwise successful dialogue with the virtual assistant thus when testing chat BOTS one should rethink the equivalence classes and significantly broaden the data sets containing user inputs another good example of an AI based system is an adaptive smart order router or an algo trading platform in high volume low latency environment it's often impossible to predict the exact outcome of a test scenario the cognitive pattern which is likely to affect the QA activities around this type of systems is the so called congruence bias conference bias occurs due to over alliance on direct testing of a given hypothesis while neglecting indirect testing concurrence bias decreases the adoption of the advanced software testing techniques such as passive testing and post transactional verification these methods are much better suited for testing a based systems compared to more common active testing approaches moving on pricing calculators are an example of systems which were using machine learning Big Data and non deterministic methods long before they were adopted by the industry on a large scale however in some cases like in mortgage based structured products it seems like the validation priorities might have been misplaced there's a cognitive bias called Parkinson's law of triviality also known as the bike side-effect this is a tendency to give disproportionate wait to travel issues Parkinson provides the example of a fictional community whose job was to approve the plans for a nuclear power plant what the committee did instead was spend the majority of their time on discussions about relatively minor but easy to grasp issues such as what materials to use for this staffs bike shed they completely neglected the proposed design of the plant itself which is far more important and far more complex tasks this behavior is very common when testing sophisticated systems another bias worth mentioning here is well studied in safety critical systems it's the automation bias it doesn't just affect airplane cockpits but also test automation is the maturity of the software testing tools increases proper testing is important for monitoring systems as well one of the approaches to overcome the automation bias is software testing tool diversity when testing market surveillance systems it's paramount not to rely on a single tool instead one should consider using a toolset based on different technologies and approaches these can be script based tools participant simulators built-in custom alerts and so on the use cases around insurance claims management cover processing of images text and other unstructured data in order to predict an estimated cost of the loss the role of an AI based system suggests using historical data and comparing it to the predicted total loss cost to make a decision on the claim while our experience does not yet cover software testing of this kind of systems some lessons learned from the insurance industry can serve as well humans hate risk and ambiguity this is where the zero risk bias comes in the zero risk bias is a tendency to prefer the complete elimination of risk even when alternative options produce a greater reduction in risk overall from the software testing perspective we frequently observe efforts to eliminate the risk in a specific module or around a new functionality without proper end-to-end testing of the whole system last but not least we'll touch upon the illusion of control the concern about the unpredictability of AI based systems is ever-increasing yet humans tend to underestimate the complexity of the existing distributed non deterministic platforms thinking about complex distributed platforms built with traditional technologies as of last challenging compared to AI systems is an example of work of the illusion of control bias it makes people happier and less stressed multiple studies program although less stress does not necessarily mean better performance this concludes today's video remember to browse to the testing the intelligence of AI white paper on our website you'll find that it contains the official list of references used in preparation for this video feel free to give us a thumbs up if you liked the video we do have a lot more interesting content for you so don't hesitate to subscribe to the exec Pro Channel we'll review a ton more quality assurance and software development issues in the upcoming weeks remember to hit the bell button if you want to be the first to see the new content we'll see you soon [Music] 