 the following content is provided under a Creative Commons license your support will help MIT OpenCourseWare continue to offer high quality educational resources for free to make a donation or to view additional materials from hundreds of MIT courses visit MIT opencourseware at ocw.mit.edu so today will be some sort of future technologies future developments that might not be around yet but are interesting things to look for and if you're interested in like researching these kinds of things you want to make a MNH out of this or want to make it who knows PhD probably is a little overkill for a lot of these things but if you're interested in this kind of research here's some things we'll talk about today block / you know block filters or committed bloom filters sharding accumulators and UT Excel commitments okay so first one we'll talk about is block filters so I don't think I ever really talked about what a bloom filter is I'm still not really going to explain how they work but the basic idea the the sort of high-level here's the prototype here's the function prototype here's the like interface that bloom filters have so you make a filter from a bunch of objects and in this case objects are just bytes right or some string of bytes and blue filters usually use hash functions under the hood a lot of times they don't use cryptographic hash functions they can use sort of faster functions where there may be collisions but in this case it's not like a security problem so you've got a bunch of objects they might be addresses which are 20 byte pom key hashes or your UT exo's which you can represent as a 36 byte TX ID and out point TX ID n index so you've got you know they're small right so either 20 bytes 36 bytes 7 times 32 bytes you put these lists of data objects in make a filter and you get a filter out and the filters are usually Killah by sometimes but the idea is it's sort of a mix of hash functions and then you say okay I want to match filters usually a different person does this and says ok I've got a filter that someone generated and I compare it against this object and see if there's a hit right so I see okay that matched you know this object match the filter or this object did not match the filter and this you know returns a true or false and so what's interesting about these is you can have false positives so it may be that this object was not in here was not used when creating the filter but it still returns true so it's sort of matching against multiple different hash functions seeing hey do any of these bits match and says oh yeah this this object may have been in this filter however there's no false negatives so if you did put say address a into this filter and then match this filter against address a it would always return true there's no way you can find you know you there's no way you can put something into the filter and then it doesn't show up when you try to match against it so this is useful for lots of things bloom filters are definitely not like restricted to crypto currencies or any Bitcoin or anything like that they're used all the time in various databases all the time things like that the current way they're used in Bitcoin is for SPV filtering so we explained svv like months ago the basic idea is I'm a client I don't want to download and verify the whole blockchain I want you know someone else to do that I assume the miners are doing the right thing I assume the rest of the network is doing the right thing and I just want to know about my data so I'm not gonna download the whole block I'm not gonna verify all the signatures or keep aut Exocet on my own I'm just concerned with my UT exo's in my wallet so what I do and this exists today you can do this you make a bloom filter of all your UT X OS and addresses so you say okay here's all my addresses that I'm hoping to receive money on I've got 20 of them 30 of them 100 of them however many although bloom filters don't really work once you have too many but so the idea is if you have five addresses let's say you start a wallet you don't have any money you're pretty sure you don't you know you don't know of any money yet existing but you say okay I made five addresses I told these addresses to people they might have sent me money that would be nice so you make a bloom filter of all these addresses right so let's say you've got okay address a a through and you make a filter okay so so you say I've got my filter F I then send that filter F to a remote server so there's the cloud there's some Bitcoin full node out here it receives filter F okay so this this got filter F and it knows that this filter F is specific to me right so it seems that hey I'm a client I'm an SP V client I connect to a full node and I say hey I send a message that's called load filter and I say hey load filter here's my filter F only send stuff to me that matches this filter ninety-nine you know 99% of all the whole thing everything going on a Bitcoin I don't care about here's a filter and only send me messages that match this filter and so when it sends a transact well they send in messages right when it sends an in message but inventory was saying hey I found this thing that you might be interested in normally a full node to another full node so like let's say there's communication between two full nodes these guys will talk to each other about every transaction they see right so if they see a transaction it's valid it's got you know there's nothing wrong with it they'll just send it to each other to propagate transactions throughout their network so they can get mine later however if a filter has been loaded it says oh okay I will only send you in messages that match this filter so if there's a transaction that doesn't have any of these five addresses as an output I'm just not going to send it to you similarly when a block comes out this is the big one normally blocks get propagated the same you know I just send you the block here we do something called a merkel block I don't send you a regular block I filter everything within the block and send you only the things that match to that filter so this is anjana generally gets very small so the Merkel block might just have one transaction in it and it has the sort of Merkel proof up to the root so the server sends only the matching transactions in the block which can you know drop from a megabyte to less than a kilobyte and then the client says oh cool there's a transaction where I received money great also let me update my filter to include this new transaction that I received so if that gets spent later I want to know about it even if it doesn't send to one of these five addresses right so if you're only matching on addresses you can only sort of get money but if you're matching on these UTX zeros you can lose the money as well and you don't want to lose money but you sort of want to know when everyone else thinks you lost money so this is this works today this was implemented like 2012 ish the history behind it was the the Android the first Android Bitcoin wallet the ondrea's Shabak wrote it and it didn't do this right it just downloaded the whole block and then threw away most of the data and only cat it didn't it wasn't a full node and then it didn't keep aut Exocet but it did download everything and then they were saying okay this is really slow we want a decentralized way to do this kind of thing where instead of just connecting to a server so the other model they find again weeks ago was you just have some server and you tell it the interests say hey here's my address how much money do I have and it sends you transactions and you you maintain your wallet that way this is nicer because it's decentralized right every full node can do this and by default if you download Bitcoin 0.6 teen or whatever recent versions I in recent sends like Oh point most of the versions will will have this pot you know capability where if a client says hey here's a here's a bloom filter load it your full mode will load that filter and then every block that comes in or every block that's requested they will match against the filter the filter match function calls not too heavy it involves a bunch of hash functions it's not too slow but it's slower than doing nothing right it's lower than just sending it directly ok so this is nice right you can sync the entire chain in way less data and having SPV security problems it's really bad for privacy you're sending a bloom filter right so it's this thing that's created from your list of addresses but in practice it's got about the same security as just telling them all your addresses um right so it's sort of like oh oh I'm sending a hash of my address instead of my address well yeah but I know all the addresses in existence on the Bitcoin network I can just try to matching it you know try to imagine stuff like that when you do blue filters there's this sort of false positive rate that's sort of a knob you can you can twist and you can say oh I'm gonna make a blue filter where 10% of the time when you perform this match filter for any given object 10% of the I'm gonna create a filter where it'll just return true so I can dial in a false positive rate so I can say okay I'll make it 1% and then when I get these when I get these matching transactions from the full node yeah I'll get an extra few transactions that don't match my filter that they match my filter but they don't actually match anything I'm looking at and that will improve my privacy right because then the full node doesn't see what's you know he doesn't know what's truly mine he might in fact you don't even know what the false positive rate is when you receive a filter it could you know you you don't know what the false positive rate is you just see okay these things match and you send them another strategy is okay I'm a svv client i connect to a bunch of full nodes and I can give different filters to each one I think the initial software did this and because you can sort of put some randomness into your different filters to hope why did they do this it actually makes it worse it actually makes it worse because if these full nodes collude collaborate whatever if these full nodes share the information of the filters it makes it easier to determine to sort of filter out the false positives because they'll have different false positives because they had a different filter and so if they collaborate if they work together they can say Oh I got some false positive transactions I did too we can filter out the ones that one of us had as a false positive not the other right so we can detect the false positives we're sending to the client so privacy is really bad there's a paper written I think twenty thirteen or fourteen where they basically like broke the whole privacy argument for this bloom filter based SPV and they said like in practice you can get like ninety something percent of the addresses and you TXO as the people are sending for the given you know the software and their recommendations were like yeah i don't see how you make this work privately there's just no privacy here it's slow for the server's so when you're running i can see when you're running a full node when you're running a full node you can see here's all the nodes that are connected to my phone node and running downstairs most of them are other full nodes all okay these are not I don't know what those are those are like not true like these all these Oh point nine point nine nines they're not actually nodes at all they don't seem to ask for anything and then some people put like their version message they put an address hopefully someone will send them lots of money it's not gonna happen that's weird there's like no SPV well bit okay bitcoin J so that's a SP Java implementation which does filter load and so we can look [Music] the fee filter but no filter load okay so like no but well that's weird someone's sending me lots of different fee filter messages there's lots of weird stuff going on in the Bitcoin network but i weirdly don't have any STV filter load things going on right now which is unusual I don't know it changes a lot too based on like so like Indus so also you can sort of track your hourly data usage and this is this server basically it's only for like all this traffic is the clients connect it you know Bitcoin and so I'm doing like you know I'm gig a gigabyte every hour which is you know a lot for a home connection but not too bad for here but like in December everyone was interested in Bitcoin and so you had lots of people downloading it running it and it would be something like 10 times this we're just tons of people were you know installing it downloading it getting the whole blockchain and then probably after losing interest deleting it but whatever and a lot of SPV clients doing filter loads can slow down your server it can it can take CPU time right now yeah okay so six percent 2% it's pretty low CPU usage generally for Bitcoin even with that many however many that was 30 or 40 different other nodes connecting and downloading stuff basically this is like receiving transactions verifying the signatures and sending them out and granted but this is per core right so if I have two percent that's two percent of a single core it's it's really not much and then I guess the kernel is only using one percent so even less so yeah it's not much but when you have a lot of SBV clients it can it can start using a lot of CPU okay so how do we improve this this is a new ish idea it's actually about two years old and it was kind of interesting who it was just a random anonymous internet person posted on the mailing list with like a fairly I I think he's like email address with some inappropriate swear word or something anyway but if whoever this person was just said hey why don't we do it the other way why don't we do it backwards and instead of having the client create a bloom filter and send it to the full node have the full nodes make bloom filters from all the transactions within a block and then the client will just ask for that filter the client can then perform the filter match function on their own ut Exocet and then if they do find a match they request the entire block right so this is a different model like I don't know does it get the idea where okay so you're a client all you do is request filters so you say you know filter please so you have some kind of filter request this and then the full node just says okay for every block in the blockchain I'm going to create a filter right I take all the objects in the in the block which are basically all the addresses used in every transaction all the UTF so spent in every transaction I concatenate that so there's gonna be you know five thousand ten thousand a lot of these objects put it into a really big bloom filter generally bigger than the ones used in this method because usually a wallet won't have thousands of addresses or thousands of UTX oh so it's possible but in this model usually you've got you know 20 30 maybe 100 but in this case you're gonna have thousands make a larger filter create the filter and store it for each block so maybe it's 20 kilobytes or something and maybe in this case they're only like one kilobyte so you have a filter and then the node will request these filters for every block so it's okay this block get the filter gets we have the filter and then perform the match the matching on their own right so they've got the filter they see hey does this filter match any of my addresses so is there anything in this block that may have paid me or anything in this block where my transactions may have been spent and if they get it true they just request the whole block it's download the whole one megabyte block or whatever it is and there may be false positives right so they might be downloading walk for no no reason they download the whole block see there's nothing there wait ridiculous and milepoc sighs yeah I guess they're not gonna actually like I don't think any any of these have actually 32 megabyte blocks and that no one's using them even Bitcoin now right where the actual block usage has gone down substantially you've got like I don't know 500 K or something average now it's it's it's low occasionally you have like lots of little transactions saturating the mempool and then full blocks for a few hours but it's gone down and it's not even at full usage so and Bitcoin cash like yeah you've got 8 megabyte max sighs but right and they're gonna do 32 Meg's full size but still there's actual blocks are like 10k 20k whatever so it's not I mean yeah but if you did have actually 32 megabytes a false-positive would be a big problem for a light node because now you have to do you know download this 32 megabyte block through the whole thing actually there was nothing of interest it was a false positive okay try again but you can download 32 Meg's it's not the end of the world and if you're only downloading you know one out of every hundred maybe if you have a 1% false positive rate no it's not too bad that's like 32 Meg's a day or so but anyway this model is and not only that you can request all the filters match them and then download from someone else the full block right you can request a block download it from someone else so this full node they know you requested all the filters they don't see anything else other than that and then they see another full node just sees you requesting blocks and things thinks nothing of it because that's totally normal this is a lot nicer model for privacy because the full nodes don't learn anything other at most they learn you downloaded this block and not this other block so maybe you have transactions in this block but not this one but that's a much bigger sort of needle in a haystack problem we're okay here are the blocks they used what are commonalities between these sets of blocks they were downloading not impossible to maybe weed things out right if the blocks are small and there's only a few transactions and they download the entire blockchain from a single node and that node can track okay which ones which blocks are being downloaded what are the common transactions or addresses in these it's possible but it's a lot better for privacy than the current model and a lot better for CPU right so privacy great great improvement this server has much lower CPU because it can pre-compute all the filters for every block right so as soon as it downloads a block or a few seconds later there's no rush compute a bloom filter for it store it on disk because it doesn't change and then when everyone anyone requests it you've already got it on disk so you just read it off the disk send it over the network you're done the current model where you don't write these two discs because they're sort of client specific so a client connects in sends you a bloom filter you have to keep that in RAM and then match all the things against this specific filter for this specific user where's in this model you make a filter for the block save it you're good um just just bless indeed yeah it's it's because if it were the addresses like if it were just the addresses and the UT EXO's then would be really big it'd be oh maybe 400 like 40% of the whole block size so the idea of the bloom filter is you squit you you you squish it down so the bloom filter itself might only be like 20k and so yeah it's got like the use basic basic way of bloom filter will work as you take sort of a bunch of hashes and populate a bit filled bit filled with them so the thing is if you if you keep adding objects to the filter the filter will eventually just be like ffffff and everything will match it so you need to sort of decide how big the filter should be when you start creating it madly adding objects to it so with this you can you can get it down to about 20k and then it'll have like a pretty low false positive rate but not tell you exactly what the address is in ut EXO's work so it's a nice trade-off to have yeah so it's I mean the the perfect sort of easiest bloom filter would be here's a list of all the addresses and all the UT XO s basically a block - the signatures which is sort of what you can get with segments where you say hey in seg what you can say hey give me the block without all the segment data because I don't I'm just looking for things I don't want to actually validate the signatures so if you did that with regular like yeah it drops it by about 50% but the bloom filter drops it's the same substantially more so if you did this it'd be better lower CPU for the server it's also harder to lie and omit things so in the current STV model if someone is running a client says hey here's my bloom filter and the full node response the full node can easily just omit things so there was a transaction that did hit the bloom filter and did match and you know it address a was present in a transaction and the full note just doesn't send it there's there's really nothing the client can do to detect that kind of thing which in general is it's not the end of the world in normal Bitcoin usage if you don't hear about a transaction maybe you'll hear about it eventually the worst they can do is sort of lie about you they say you didn't get paid but you actually did not the worst thing in the world although enlightening network that can change the middle a little bit in that you want to know about the transactions that potentially close the channel and immediately respond to them so that's that's more of a security problem with lightning so with this it could be harder to omit things especially if you commit the bloom filter into the coinbase transaction so if the if this committed filter becomes like a consensus rule and you say okay everyone makes the twenty kilobyte bloom filter everyone takes the hash of that and puts it into like an opera turn in the coin based transaction the way they do with segue then it's a consensus rule then it becomes essentially impossible for the full notes to lie or omit anything because you can get you can say hey I've got the the headers give me the coin base transaction and a Merkle proof for it and now I've got the coinbase transaction and now hey give me that filter that matches this committed you know hash in the base transaction so that becomes you know they would have to do they would have to do valid proof of work to lie or omit whereas now they can just easily omit anything they want Oh lying also so it becomes harder to lie because it's in a block right so so this is operating on the block level the current SPV does not operate on the block level so you can get unconfirmed transactions over the wire that match your filter I think this is a really bad idea I not a hundred percent sure why they put it in but there's still people who like it but the whole idea of SPV is that you're verifying the proof of work right you're verifying that the miners validated this and you think well the incentives are such that miners mine invalid things they won't get paid so if it's in a block I'll accept it as okay for mempool transactions if it's just an in message for a transaction that's not in a block yet there's no SPV security at all and it's trivial to send an invalid transaction to an SBB client this currently so if you say hey here's and it's and it's not only as a trivial but you can also try to figure out what their addresses are and lie to them and say that hey you just got thousands of coins so that's the current problem with SBB you said you say you're basically telling the full node your addresses and you're accepting transactions without proof of work so the full node can say hey here's a here's a transaction that sends you five thousand coins to your to address than I think you have because I figure out your address from your filter and it's got an input that doesn't actually exist right so I'm just saying I'm spending five thousand coins from here and the from part isn't actually a thing but since you're going to be you know you don't know that so there's like a let's see why - SPV is like a branch on Bitcoin treats okay yeah so there's there's a branch that Peter Todd made called wide SPV I don't know quick and dirty hack to lie to s pvwatts they came verify amounts so yeah so you can just sort of detect well you want to look at it you can detect their addresses if and then I think that one just sort of opportunistically if it finds a match just like multiplies the amount that they're receiving by like a hundred and there's no way that they can validate that since it's in pool so this also makes it on the block level which is like what SPD really should be so that's nice downsides mainly that it's gonna be hired network traffic for the client right so even at low false positive rates the entire rest of the block is essentially a false positive right they're like hey there's one transaction in this block I want to get I have to download the whole block to get it so yeah more network traffic for the client which is a downside but helps with privacy so there is current development lightning labs basically Lalo's working on it's called neutrino it's a variant of this so and then hopefully something like this will eventually get into Bitcoin core itself and replace the current server-side bloom filter code hopefully but something to work on any questions about the bloom filter stuff cool okay okay other issue sharding so this is mainly being worked on in the context of etherium and it's sort of their sort of holy grail of scalability it's common in the database world where you've got D data objects and servers so in the case of Bitcoin are these block chains you just store D times n right every node stores all data instead store something closer to D itself and shard the data over all the servers so that each server holds like D divided by n right so if you have 10 servers and a gigabyte have them each store 100 Meg's and then you still got all the data of course if they actually store exactly D over N and you need to coordinate it so they all store this you know their own little shard and then if any single node goes down well you're stuck so you don't you know this is sort of the limit and there's no no no no redundancy there but you can have different result redundancy ratings so you could say okay well any you'd have like a race you're coding so if any five nodes or any 20% of the nodes disappear we're still okay so the database world this is a wealth cell exciting problem but in the context of Bitcoin aetherium block chains it's more difficult it's difficult here because you're in this adversarial environment where people are trying to break your system at all times people want to create transactions that are invalid because they that can be worth money invalid coin you know I can say hey you don't know about this shard but I'm telling you that on this shard I have a lot of money and I'm sending it to you so give me your house or whatever so the idea is to split a single UT Exocet into multiple smaller sets and that that part is okay but you need communication between the shards right so you could say okay a little making sort of a a bunch of different UT EXO sets each node can choose their own UT Exocet that they're keeping track of and then you have some kind of merge mining between the you takes off sets but you need swaps between the shards it's kind of an interesting thing to think of we already have multiple multiple UT x oh that's right so as of this morning coin market Capcom tracks 1614 different currencies ten thousands markets there's supposedly 434 billion dollars going room is this charting right like we've sort of and and it's sort of a joke but in a real sense it has taken scalability pressure off of Bitcoin and off of these any individual currency because there's so many of them so if you didn't have dogecoin maybe there would be more Bitcoin transactions right so so in the case of like GRC 20 or ERC 721 it actually is worse because now you've got sort of multiple UT EXO sets all being all being managed by a single UT Exocet so like if you want to keep track of how many I don't know what's in the ICU 20 token if you want to keep track of how many Pied Piper coins there are you need to download the entire aetherium blockchain so that's that's sort of the opposite of sharding in it now any single UT Exocet you want to keep track of you need to keep track of all of them however in this case if I want to keep track of my Bitcoin UT exocet I don't need to download dogecoin so that's great and if people want to swap between dogecoin and Bitcoin they can do so well dogecoin doesn't have segwayed support right so it's a little harder but Verte coin like coin a lot of different coins have fairly easy swaps but it's more than just swaps we need like actual funds ability between the shards because if I can say oh I'm gonna use light coin and I can just swap to Bitcoin whenever I need to pay someone who accepts Bitcoin right maybe but maybe light coin drops in value 20% with respect to Bitcoin and then I tried to pay and and this is sort of getting ahead of the real use cases of these things because well the coin also drops 20% randomly against whatever asset you're trying to buy and so Bitcoin but Bitcoin does tend to be a bit more stable than most of the smaller market cap coins I mean again you can sort of think that generally if you have a bigger market capitalization the you're gonna be you're gonna tend to be less volatile and and we've seen that in Bitcoin where like it still seems ridiculously volatile right it's gone down 50% since like January and most currencies in the developed world don't do that but if you actually compare it to like like in 2011 it dropped like 95 percent in a month or two yeah yeah so so sometimes there's a currency that like has these like really inflated market caps so you'll see one where they jet you know someone makes a coin it says okay I'm making a million coins and I'll sell you to one who sell you one for $100 and really I still have nine you know all of the coins and one other person has one of them but we can sort of do the math and get a market cap of 100 million dollars that way so a lot of the coins do that to sort of inflate because it's like when market cap is literally a it's like literally a ranking and it even says like rank so if you click like like yose it'll say rank where does it say there yeah rank five so like it's the fifth best and yeah to what extent how many actual people hold these things they just sort of made them up yeah so so any but there's all sorts of problems with this but the idea is if you really want charting you want the the swaps between the shards to not really have counterparties and to maintain the same value you want fungibility between the charts so that you can quickly and easily say okay well I've got something on shard hey I'm going to pay someone who's using shard B and I don't want any friction I don't want any like exchange between there so this is hard there's a lot of cool of research going on here and if it works it's a real scalability improvement like this is sort of the Holy Grail I don't really see much in in Bitcoin they're sort of like side chains but those weren't really talked about as a scalability improvement and it's mostly the etherium crowd that are like this is our real sort of holy grail for scalability so it's interesting to look at I haven't kept up I read a little bit about their current their most recent charting ideas so it's cool if it works but there's a lot of sort of different assumptions that go ah they sort of like a lot of them hinge on fraud proofs so the idea is you've got say five different chains going along and you don't validate the other four you say I'm gonna only validate this one there's four others going on and if in my chain something bad happens like a transaction with an invalid signature gets confirmed or transaction has more coins coming out than going in something like that you provide a small fraud proof you provide a proof that says okay here you don't need to know everything that's going on in this chain but I'll provide enough data to convince you that this transact or this specific transaction is is broken and then I try to broadcast to the other people on those other Ford like sub chains and then they know okay something's going on wrong here let's like freeze like let's not accept any cross shard swaps from that one and then the other you know this chain will have to reorg so the idea is as long as you have and and it sort of makes sense as long as you have a sum number of people checking it that can then broadcast it between the different shards you can assume that they're doing okay or just accept that holes two years ago so I'll assume it's okay yeah which is probably more than you yeah so so sort of availability and liveness are other issues here where if in big in Bitcoin or a theory oh well it's more of an issue in a theory in Bitcoin there's a lot of copies of the full set so if you're not sure about something you you can pretty easily get the entire blockchain even though it's like 180 gigs and go through it there's so many copies of it out there in aetherium a little bit less so well there's more full nodes but full is sort of redefined and so it may be harder to get the full thing and in the case of sharding if you you know divide it too finely it may be that you lose data and like no one has it and then you're in real trouble okay so that's sharding okay accumulators this is something I'm actually looking at I'm not gonna go into the details of what I'm working on but accumulators in general this is a cool this so accumulators as I will describe are nothing new but if you read the papers like so one of the first papers is called one-way accumulators in like 93 and if you read the paper a lot of the words jump out is like hey this might be useful for Bitcoin it's like set membership and like time stamping and like signature aggregate like it's got a lot of stuff in there's like hey this could be useful so an accumulator is basically a cryptographic set and there's some set operations that you can do and then provide proofs so the simplest well not even the simplest the simplest would just be adding proof but sometimes you can add sometimes you can remove sometimes you can prove something's in there sometimes you can prove something's not in there and if you can do all four that's even better so the idea is you take an accumulator and you add an object to it and in general you know objects are gonna be strings of bytes or just numbers right and then it spits out a new accumulator essentially it modifies the accumulator so if you delete you say okay I've got an accumulator and I want to delete this object well it'll modify in place and return a different accumulator and then maybe I want to prove that this object is in this accumulator and it will return a boolean like yep that worked or no it didn't so the simplest example which I think it's kind of fun composit numbers so accumulate prime numbers so to add multiplied to delete divide so let's say you're a human so really if you're going to do this you start with 1 1 it's not a prime I guess but whatever so let's say you've got so yeah one is not a prime so that works so you can you can't not prove any prime exists within that accumulator anyway but let's say you start with 1 and then you added 3 to the accumulator so you multiply by 3 and you get 3 now I want to add the number 5 to the accumulator so I multiplied by 5 I get 15 and now I want to add 7 to this accumulator so I've got my accumulator which is 15 I add the number 7 into it and I get 105 I just multiply by 7 I get 105 so wait is it called like fundamental theorem of arithmetic I think that's what it's called we're like everything's a product of primes it's got some cool name so like you know everything's a product of primes and everything has a unique factorization so 105 is 3 times 5 times 7 right there's no other ways around it and if you want to delete you can say okay well I'm going to leave the number 5 from this accumulator just divide now I get 21 and then I want to prove 27 is in there so I can say hey 7 is in this accumulator it was added but not deleted and I can do that right I tried to divide 21 by 7 and it worked there I want to divide and I want to make sure there's no remainder I want to see that a divided e divides evenly so I get a true like yep fine divide 21 by 7 I get 3 3 is a regular old you know 3 is a natural number it works so this is kind of cool it it's not really constant sigh oh but this works even if you do modulo so you could do modulo some big prime and have just like criminality based accumulators so there's some so anyway you get the idea right I think in this case you can also prove things are not in there but this is limited different numbers anyway but the idea is keep adding things to it removing things from it and proving that things are in there so there's RSA accumulators which are some of the most well known and that's you've got some RSA number which is basically a product of two large primes and the accumulator itself is of constant size and the proofs are also of constant size so we call this a proof you know you're just giving the number itself in this case so it's efficient but the RSA accumulators use trusted set up so the idea is you need to find some composite number n which is P times Q where P and Q are prime where nobody knows P and Q or nobody knows or you trust that the person who does know P and Q not to screw around with the accumulator because the person who you know if knowledge of people I think it's actually knowledge P or Q will let you create proofs that hey this is this object is in the accumulator when really it isn't so that's not so much fun for Bitcoin if you need trusted set up people people don't really like that there's all these other accumulator I say ideas some are one way where you can't delete you can add things to the accumulator but there's no way to remove it sometimes you can batch things where okay if I want so you could see in the in the prime in the composite number accumulator you could batch things where if I add 105 to the accumulator I'm performing one operation that essentially adds three objects right three five and seven some can be batched like that some cannot some have trust and set up some don't so there's different trade-offs for all these different use cases and in the case of Bitcoin the idea of you know accumulator would be put the UT Exocet in it or put the STX Oh like spent trans shanell put into it and then prove in the case of UT EXO's prove that it's in the accumulator or in the case of SD EXO's prove that it's no longer in the accumulator right provide a proof of non-inclusion that hey it's not in this SD Exocet so well with the SD EXO inclusion so let's say you did it that way you'd have headers and then you've got this st EXO accumulator and what you could do there is say I've got a transaction it's got some inputs I prove that this input exists in the headers right I provide you an SPV proof so I say okay at some point this this was created right this input may be a year ago I show you okay there's a setter here's a merkel proof that this was in a block so this exists then I also prove somehow that it doesn't exist in here right it exists but it was never spent so now you can accept that oh okay he gave me an STD proof he gave me a non-inclusion to the SD Exocet proof so I know this transaction this input still exists and can be spent so what this would do if you get it working you don't need to store the UT Exocet anymore you just store the accumulator and then everyone provides proofs that hey I've got these coins but so right now if you store the UT Exocet it's a couple gigabytes three or four gigs and when someone sends a transaction you just look in your UT Exocet right so you see this input you say hey does that exist in my UT Exocet okay it does cool well no Val verify the signature or verify everything else about the transaction if it doesn't exist in my UT Exocet I'm like hey you're trying to spend something that isn't there so what would be cool is if you got rid of the UT Exocet and only used an accumulator because the accumulators are constant size so even if the UT Exocet is 20 gigabytes well I've got this like 10 kilobyte accumulator thing on my hard drive and I just modify that in place and now I don't need to store a zillion gigabytes to there and I can do you know I basically can have the same security as a full note I'm still a full node but I just don't store the UT Exocet I just require either SPV proofs or SDX oh you know different proofs from the people trying to spend the transactions so this is really cool constant size the small proofs are small sometimes the proofs are really small and then the wallets track the proofs so some questions proofs can be like constant size or sometimes their login if the proofs are and like oh then then it's like not useful right because you should might you might as well store the UT excess at that point also what is n is it the number of transactions blocks can you a great these operations so there's a bunch of questions there another really big problem so I was talking to Peter wolf who's sort of like one of the premier researchers on Bitcoin he had been talking to people at Stanford about a lattice based accumulator that did not need trusted set up and he was very excited about it because it was like hey there's no trusted set up you have constant size proofs the accumulator itself is pretty small CPU wise it seems doable the thing that sort of killed it was you couldn't batch you couldn't batch operations to the accumulator so you need and that and the other thing is that we need some kind of bridge node so the idea is normal transactions right they just say here's my input I've got a couple inputs I've got a couple outputs I don't provide any proofs or anything I just say I just point to where what I'm spending and you look in your UT Exocet and see if you have if it's there with this new idea with accumulators you're gonna have to stick proofs on so really it's an extra data structure probably per input is he saying hey I'm a node I don't I run an accumulator I don't keep the whole set so for all your inputs please provide proofs and wallets can maintain these proofs and and attach them to their transactions and then the nodes will verify them how right now most wallets don't have these proofs have no idea that this is a thing right so if you're the first node to do this and say hey I'm getting rid of my UT Exocet I'm only going to verify proofs that these UT exo's exist most of the wallets won't provide those proofs and so as a new nodes say hey I got rid of my UT Exocet but no one's giving you proofs okay I'm just stuck right I see a block camp come out I can't validate it so you're gonna need some kind of of transition right if you start it from scratch and say okay the responsibility of every wallet is not just keep your private keys and keep track of like what you know your UT X always it's also to keep track of a proof so that when you want to spend it you give it to someone else maybe you start it that way great but if you want to transition well you're kind of gonna need is a bridge node and the idea of a bridge node is you've got so here's an accumulator node where it requires proofs here's a you know old node that just has regular VT exo's so when the old node attack you know sends a transaction this gives T X proof right so this basically has proofs for everything like all proofs so the bridge node can can provide proofs you'll need one bridge note right so if these if these accumulator nodes talk to each other they can send the proof so long to each other and stuff like that the old nodes cannot send proofs because they they don't they're not aware of it and their software but if you have the new nodes you can say okay well when I receive a transaction I verified the proofs I also keep the proofs and give them to other peers who want to verify them but you need some kind of bridge between these two networks until everyone switches probably forever so yeah so that the issue with the bridge note is like well if you're an old wall like you don't have to keep track these proofs maybe so how much of a problem is this and and the lattice based accumulator that was sort of what killed it was that you couldn't batch operations so every sorry and the proofs changed that that's not the case with the sort of silly prime number accumulator that I showed but in this in the lattice based one the proofs changed every time an accumulator operation happened so every time an ad happened your proof had to change so you need it you didn't just need to add something and modify the accumulator in place you had to modify your proofs in place as well and so if you're a wallet and you've got three UTX those that meant that every block you'd have to do a couple thousand operations right because every every block you're gonna have a few thousand adds and a few thousand deletes to this accumulator every time one of those happened you'd have to modify your proof for each of your 3ut exos so do you know a little ugly but doable because you've got three UXOs you're basically three X the number of operations set operations in the block the bridge node on the other hand has to keep track of something like 70 million UT X s alright that's about how many there are right now and so since there's no way to batch it that means you're gonna have like maybe 10 K times 70 million every block it's just not gonna happen so that was that what and it's like well maybe you can sort of try to shard the bridge knows and like this bridge node only keeps track of this portion of the set but it just looked really daunting and that was why he was sort of like yeah I I don't think this lot is I think it's really key that the either there's some kind of batching operation where we can consolidate all the operations within a single block to one set operation for the accumulator or try to make it so that it's easy so that the proofs don't have to be updated or something like that so this is still an unsolved problem although I'm working on a phone way that I think might work to do this and I don't want to like because this is like videotape what's going on internet stuff I don't want to like talk about it but if you have questions we can talk about it at UH like office hours or something so if it works it'll be cool although in some cases it might so in the case of that like bridge node it was the it was the bridge node that really killed it because it was just like oh you're gonna have to do billions of operations per block but in other cases it's like well these are you can have accumulators that seem good but aren't actually faster because it's like verifying the proofs takes a long time or something like that so it's sort of like with the range proofs or something like Wimble and what we're like the O of n is great but you've got these constant factors that in practice end up meaning you're not actually faster right because the decoding you TXO said well it's for gigs not even right it's three and a half gigs now so in practice there's probably a lot of cool cryptographic technologies and you could write a whole paper and have all these cool things and if you actually implement it it's like well it actually goes twice as twice as slow it's just you think the regular also this is super optimized one of the biggest like sort of code engineering things that has happened in Bitcoin core is okay how can we make database updates this how can you make like different caching different like flushes to disk and like editing leveldb itself so you know making this UTI Exocet database operation faster it's like a a big thing in Bitcoin so it's pretty optimized and even if you've got something that seems like in computer science terms hey this is login you know instead of n like yeah but what about the constant factors so so that's another issue for these this idea okay other things I was gonna talk well yeah so the last I'll do last one and then we can maybe end a little early and talk about projects you want UTF so commitments which is somewhat in the same region as accumulators a little bit different idea and this exists in some points like in if you're in job and I was saying that you basically have a tree of all the different state you know all the different contracts that exist all the in different addresses in aetherium and the root of that tree appears in every block header so you can make these proofs that the you know coins exist based on a block header also it exists in the etherium it doesn't exist in Bitcoin but people have been talking about it for years the simplest would say take a hash of the UT Exocet and put it in every coinbase transaction and make that a consensus rule so that when you line a block you have to you know take the hash of the UT Exocet you're aware of put it in the block so that everyone can see it and if everyone disagree is they're gonna invalidate that block this is really simple you probably want to do a little bit fancier than this a bit more useful well make it a instead of just taking a linear hash of the entire UT Exocet make it a Merkle tree right and that way yeah sure it's it's very little extra hashing well no wait twice as much hashing right but anyway to X the hashing but now you've got these the ability to make small proofs and then you can prove an output exists at a given block height pretty easily and as an SVG sea level security so currently you can prove that a transaction exists at a block height and you can also prove it prove that a transaction was consumed at a certain block height right so if you have you know all these different blocks 2 3 4 5 you can say hey here's a vertical proof that transaction 1 was included in block 2 and then you can prove here okay here's transaction 2 that consumes one of the outputs from transaction 1 but you can't prove just given but also you can easily you can omit this proof right so if you want to prove that a so at block 6 how do I prove that the outputs from transaction 1 still exist at block 6 you're stuck right you basically have to go through Oh blocks three through six and look at the whole thing so even so with current SPV proofs we can prove inclusion right it's you sort of think that this is an accumulator where you've got you know a Merkle tree is kind of an accumulator I can prove inclusion and then I can prove transaction one is in block two I can prove that transaction to destroy you know consumes transaction one and block five but you have to rely on me to give you that proof honestly right if I'm trying to cheat you and say oh yeah I've totally still got money I can't prove that it hasn't been deleted whereas with a you TXO set commitment if every block there was a total commitment to every you TX oh I could just say hey at at block six my output from transaction one it's still in there well it wouldn't be in this case but I could prove it at block four right they say hey look transaction one still in their block for no longer there at block six depending on how you construct the you TXO commitment you may be able to provide non-inclusion proofs which is also really cool so for example if you had to be a Merkle tree if it was just in order insertion so like this is TX 1 this is T X 2 this is TX 3 and you make a Merkle tree that way then you cannot prove that something's not in it right so when TX 3 gets deleted and now TX 4 goes here TX five comes here you can't prove the TX 3 is not there anymore in any real way however if you sort them so that every time so now that like you sort them canonically so like by hash just like greater than less than and then the order gets all weird right so like now TX 5 is here and TX 6 is here because TX 5s hash is closer to 1 and stuff like that then you can prove non-inclusion so then you can say hey TX 3 is not here because TX 3 would be between 5 and 4 right just based on what the hash looks like and I can show you 5 I'm gonna prove for it I can show you 4 and approve 4 I can show that these two things are adjacent right in the tree and there's no three there and it would be there if it were you know if it existed it would it be right here and I can show this not there so then I have non-inclusion proofs in the UT Exocet which could be used for some kind of fraud proof so if someone makes a transaction spending something you can say no look here's the last block here's the UT Exocet hash and here's a proof that this input doesn't exist so this must be an invalid transaction that would be really cool too because then you could propagate that on the network and sort of prove fraud so this is an idea that's been around for a long time I think maybe the reason it hasn't yet been implemented is no one can really agree on exactly how to do it a lot of people are like yeah we should do that that would be cool yeah you can prove that cv security so one thing you could do with it is skip years of initial block download say I don't really care what happened from 2009 to 2015 I assume it was fine right I'm gonna start my synchronization in 2016 and just synchronized the last two years so I'll go get this UT EXO commitment from 2000 end of 2015 I will then not just get the commitment but download a UT EXO snapshot from that time and then I'll check that it you know matches the commitment of the committed UT Exocet hash and then I'll just start from there and go with the let you know and then become a you know full node where I didn't check the first six years or something and that's this interesting mix of SPD security and regular full node security where and I think personally that's like probably okay right you if you only verify the last six months of signatures well if everyone's been wrong for six months we have bigger problems right like if there's some erroneous transaction in 2015 and the entire networks been just extending for like three years without reorganize blocks right because then then the miners have full control and the miners can just make up transactions and if you really just say oh well the miners are doing the right thing then they get a lot more power but if you say well other people are validating it in real time and I assume that that's the case and I'll validate six months worth of transactions so I'll pick up any errors in the last six months and be able to report them but I will assume that after a certain amount of time pretty sure it's meant okay everyone else has been looking for this so that's that's a you know slightly different model than full nodes but in practice not really because if you look at the code for Bitcoin today there's a assume valid which doesn't check signatures it sort of has a block hash and says okay anything before this don't stay don't check signatures the developers themselves have said yeah this is every signature before here's okay so you want to check the signatures which is a little nicer that before they had checkpoints where it would just not validate anything before a certain block cache so you sort of already have things like that to speed up the initial synchronization process but but a you txo commitment would make it a lot more sort of decentralized because right now it's just the programmers are like well you know this is last year everyone's validated it let's just you know hard code this into the code into the the client anyway so this is an idea the issues timing is probably one of the biggest issues if it's consensus critical then the miners need to put this into their blocks and miners also need to verify it when they get a block and adding even like a second to creating and verifying a block can centralized mining a bit because the idea is I want to be able to immediately start mining as soon as I see a block because like a larger miner a larger miner doesn't need to verify the block that just came out right because they created it if they created a block themselves they know it's fine they build on top of it immediately with zero you know zero propagation delay zero verification tool a smaller miners or mine are receiving that block have to make sure it's correct before mining on top of it so adding even a one second creation there vacation delay is something that like a lot of the programmers like mmm you can get it done in like half a second maybe we're okay you know like we want this functionality but not at the cost of increasing that like that's the worst time to add something if you can defer it if you can say oh well you you needed you know verify this but you can do it after the fact or something then it's fine so this this I've ran up against this because I had this fun idea where you could have aggregation or signatures within a block and do it non interactively and it was really cool and I'm pretty sure it works but it added like three seconds to block verification so that killed that idea so one of the issues yeah timing another issue is it does encourage more STV level verification or you can sort of see that a lot of people will now use this method to not run a full node because they're like well I don't need and you know I can just get these compact proofs for all UTX O's whether inclusion or non inclusion so why run a full node I don't need to verify it because other people are you don't really want to encourage that because there's so much of that already also the biggest is probably there's got to be a better way to do this so there's all these different ideas on how to do it and they never seem to settle or converge on a single way so they're the main the three main ideas are sort of hash based you TXO sets elliptic curve based commitments in our essay based commitments so and and there's a lot of overlap with accumulators in that you're sort of you know the UT EXO commitment could be the sort of route or the hash of the accumulator itself that you want to prove that something's in there approve that something not in there and the EC one is the current one the SIP was looking at but I've never made sense to me because it's like trivially you can provide invalid Proops really easily so it's all trusted and but his idea as well let's say you have a node that you synced up and you want to sort of port that to somewhere else you can do that very compactly with an elliptic curve based you txoko commitment which is cool but you can't trust the inclusion or non-inclusion purrs and there's like RSA ones that also yeah so there's there some overlap there anyway it's a pretty cool idea it's it's it does exist in aetherium which is just hash-based that Joe Bono sort of explains the tree thing they used but that doesn't provide for non-inclusion proofs which would be fun so yeah so this is another research area any questions about UT EXO commitments there's a bunch of graham Cohen's like bit field thing have you seen that yes so that was a really interesting case of like in computer science terms it's o of n but he got it so that it's actually one bit per spent transaction output so the idea would be maintained at a maintained at T Exocet right so for every transaction output ever created in order you have just bits right so if a transaction outputs created that's a bite and you leave it all as zeros when they're unspent and when they have been spent you just set it to one and the thing is yeah there's like 70 million but that's if it's that well there's more there's like hundreds of millions but if it's bits instead of bytes that's pretty small right it's like maybe 100 megabytes if you have 800 million outputs ever and then you can quickly see on your hard drive ok this this outfit is advancement and you can like provide proofs and stuff so the the bit field thing was kind of an interesting where well okay it's o of n but one bit per object and you can sort of quickly sort between so these are some of the things that like I think that's it for today right and then what's going to talk about covenants but that's another story so these are some of the like current research issues in Bitcoin blockchain and cryptocurrency and there's lots of other topics these are some of the big ones I'm aware of and I know people working on yeah there's lots of ways to improve privacy scalability functionality it's certainly not like and sometimes people say while bitcoin was made in 2009 and it's like you know version blockchain version 1.0 and we need to make blockchain 4.0 or whatever and to some extent yeah bitcoin is annoying to change right it's difficult to change you got like the idea of a bridge node and you know can't we just start over it'd be so much easier in some cases yes it would be nicer to start over but that's sort of the challenge it's like wait can we make this system better but maintain backwards compatibility and so in a lot of cases like the accumulators or the client-side bloom filter checking it's not a fork at all right nobody has to know there's no change the miners don't have to change anything if you don't know about this new change you don't have to change anything and so they're totally optional ways to improve some of these things and that's like a fun challenge right you're given the system it's sort of like trying to improve an airplane while it's in flight where you're like okay I'm gonna you know make it faster make it better while it's lying we can't even land so yeah that definitely makes it harder but but other things are but what's also interesting is that there's not that many things in it that were that really requires starting over from scratch so I know at the New York City like Bitcoin core developer meetup in March Bram Cohen who made BitTorrent he's making his own coin I guess now and it's kind of interesting because usually the the Bitcoin people don't like alt coins or are sort of wary of them and don't invite altcoin people to their events and stuff but Bram Cohen like invented BitTorrent so everyone sort of owes him in some spiritual way like a couple thousand bucks for all the music and movies they've downloaded right so it's like olives for him you know he helped us out so he comes to these things and he was asking at the thing in march okay asking a lot of people if you were gonna start Bitcoin over from scratch what would you change you know all the people who are programming this like four years and dealing with all the annoying problems in it okay if you you know start over from scratch what code do you change or what sort of basic infrastructure things do you change in the system and there weren't that many right a lot of people like oh you know there's a little things like Oh get rid of the little silly op zero and multi say get rid of this or like change a couple these things but not a lot of like really fundamental changes people would want to have made some people were saying hey maybe instead of pointing based on TX ID be able to point like height and index you get a lot have a lot smaller there some different like opcode things but what was interesting is that it also it's a super biased sample and it's like if you're asking all the people who work on Bitcoin well yeah they sort of like how Bitcoin works or at least they've grown accustomed to it so you might want to ask other people if you want to sort of think out of the box but there weren't a ton of major changes that people wanted to admit so it does seem that it's like a fairly well thought out you know base of a system that you know and I'd say the etherium design is the other design that's like very different right the account based versus you TXO base and a lot of the people work on Bitcoin think that account based is worse a lot of people maybe in aetherium case think UT exobase that's worse they they do app trade-off 