 Good evening virtual audience, and welcome! Thank  you for joining us tonight from wherever in the   world you are located. My name is Kate Bruns, and on  behalf of Harvard Book Store, the Harvard University   Division of Science and the Harvard Library, I am  so pleased to introduce this event with Christoph   Koch discussing his latest book, "The Feeling of  Life Itself: Why Consciousness is Widespread but   Can't Be Computed". Joined in conversation tonight  by Gabriel Kreiman. Tonight's event is the latest   installment in our Harvard Science Book Talk  series, which works to bring the authors of   recently published science-related literature  to our Cambridge community and beyond. Coming up   in the series on October 28th, we will virtually  welcome James Fleming for a discussion of his new   book, "First Woman: Joanne Simpson and the Tropical  Atmosphere" and then on November 10th, we will host   cosmologist Janna Levin for her latest book, "Black  Hole Survival Guide". To learn more about this   and our other upcoming events, you can sign up for  the Book Store's email newsletter at harvard.com,   or check out the page harvard.com/science for  more info. We also have a science research public   lecture series YouTube page where you can see  any previous talks that you might have missed.   This evening's event is going to conclude with  some time for your questions. If you would like   to ask Christof and Gabriel something, please go  to the Q & A button at the bottom of your screen   where you can submit a question. We're going to get  through as many as time allows for this evening.   Also, once the event begins I'm going to post a  link in the chat to purchase tonight's featured   book "The Feeling of Life Itself". All sales  through this link support Harvard Book Store, so   a huge thank you for your support, your purchases  and your financial contributions. There will also   be a "Donate" link in the chat. Make this virtual  author series possible, and now more than ever   support the future of a landmark indie bookstore.  So thank you so much to our partners at Harvard   University and thank you to all of you for tuning  in and showing up for authors, publishers, indie   bookselling and especially for science, because  it really matters. And finally, as you might have   experienced in virtual gatherings the last few  months, technical issues can arise and if they   do, we'll do our best to resolve them quickly. So  thank you for your patience and your understanding.   And now I am so pleased to introduce tonight's  speakers. Physicist turned neurobiologist,   Christof Koch is the chief scientist and  president of the MindScope program at the   Allen Institute in Seattle. Best known for his  studies exploring the brain basis of consciousness,   he's now leading a 10-year large-scale effort  to build brain observatories for mapping,   analyzing and understanding the mouse and human  cerebral cortex. Prior to the Allen Institute, he   was a professor of biology for 27 years at the  California Institute of Technology in Pasadena.   Christof's also the author of two technical  textbooks and a previous book, "Consciousness:   Confessions of a Romantic Reductionist". He's joined  on screen tonight by Harvard Medical School and   Children's Hospital Professor Gabriel Kreiman. He  leads the Executive Function and Memory module in   the Center for Brains, Minds and Machines, and his  lab studies the neural circuits and mechanisms   underlying perception and cognition. Tonight the  two will be discussing Christof's latest book   "The Feeling of Life Itself", just released in  paperback this last month and hailed as 'thorough,   witty and compelling'. Nature calls it "invigorating - Koch  tracks the neural footprints of experience; swims   off the wilder shores of integrated information  theory and speculates about the feeling of life   itself in ravens, bees and octopuses." We are so  excited to welcome them to your screens tonight -  so without further ado, the digital  podium is yours, Gabriel and Christof.   --Thank you very much, uh - Kate - for the introduction.  Uh - I don't quite see Christof - he disappeared   ...very much, uh - Kate - again thanks, everybody  for - for your patience. I apologize for the   technical - uh - glitches...so Christof - um - it's good to have you back. Uh - why   don't we start by you telling us - uh - what  "The Feeling of Life Itself" - uh- is about? --So here's the book in its paperback edition:  "the feeling of the" book -- "The Feeling of Life   Itself" is about the feeling of life itself: what I  describe every experience; by consciousness, we mean   many of us mean any experience - the way  it feels like to be alive, to be sad,   to be distraught over the state of the world - those  all different conscious states, and over the last   fifty years, there's been a concerted effort to  look at the physical basis of that called the   neuronal correlates of consciousness; to track  the footprints of consciousness in the brain   of humans and closely-related species. It helps  determine who is caused, who is not caused,   and to do and to understand the pathologies of  consciousness and disorders of consciousness   like registered states - coma, behavioral  unresponsive states - but then there's   also the question, how far does consciousness  go who else has it, and how - how do we know?   um -and then of course there's a question that's  confronting us today: computers that we build   ourselves - they are becoming increasingly more  intelligent - and what is the relationship between   their - their behavior, intelligent or not, and their  ability to feel; can they - ha - do they feel? can they   ever feel now, or in the future? And to answer all  those questions, finally, we need a theory; we need   a fundamental, rigorous, empirical, accessible theory  that tells us sort of from first principle - first   in ourselves - it has to be tested in ourselves - only  we are sure ultimately - I know that I'm conscious,   but then in - in closely-related cases like you and  my friends and - and other humans and ultimately, in-   in animals - that tells us who is conscious, who is  not conscious and where -particular where does   this- this consciousness, this feeling, this- this  strange feeling, this- this this buzz in the head,   the voice in my head, the -the image in my- the  movie in that -that makes up my life; where this   comes from, and how does it fit into the picture -  uh -of the universe that science has given us?   So that's what this -uh - this book is about,  particularly with respect to this one theory   called integrated - uh - information theory that's  one of the two sort of promising candidates   of scientific theories of consciousness  that people are pursuing today in the lab. --Can you- uh - can it provide a brief summary of- of  the theory of- uh - integrated information theory? --Yeah - so it - integrated information theory - it sort  of takes a - an axiomatic fundamental approach: it   says, well, consciousness ultimately is something  intrinsic to the system and exists for itself.   Right? Only I know that I'm conscious and I may not  be able to move, I might be paralyzed, I might be   in a sleep -in a state - where I'm -er- where  I'm asleep and my muscles are paralyzed,   yet I have conscious experiences, I -I dream;  so ultimately, consciousness is for itself -   it's definite, it's - it's highly informative, it's  integrated, and it's- and every experience is one,   it's a definite experience. There's certain things  that are in my experience and there are certain   things that are not part of my experience, and  then from these sort of five axioms of what every-   of every conscious experience has to obey-  these five axioms - it then derives postulates   about a physical mechanism, so it looks like  a physical mechanism: a bunch of neurons, or   transistors, or any other physical state and  then ask what is it about this state, this thing,   that it has to have in order to be conscious,  and the theory ultimately says - ultimately what   consciousness is - is sort of intrinsic [causal?] power, it's  a - the way the system is influenced by its past,   and the way the system determines is pregnant  in the words of [?] is it- it's pregnant   with its own future. To what extent the -  the - the system determines its own future -   and any system that has a lot of intrinsic causal  power - something that you can measure, you can look   at the system, you can describe its states; if you  know how to go from one state to the other and you   know that [?] for all states, you can  then in principle determine the full intrinsic   causal power of this system and the theory says  ultimately that's what consciousness is, in any one   conscious experience. For instance, the conscious  experience of a spatial extensive extendedness   has to be explainable out of this intrinsic causal  power, and so it's a certain system, it - it measures   the causal power system has; it - this is a number  called "phi" that some of you may have heard:   it's a number that's either zero, then the system  isn't conscious, the system has no [?] power upon   itself, the system strictly speaking doesn't exist  for itself because it can be explained as a - as an   independent sum of individual components  so therefore it doesn't exist as a system;   but any system that exists for itself has a  number phi that's bigger than zero - the bigger the -   the number phi, the more conscious the system  is in principle. The theory gives rise to this   measure of consciousness, that you can apply to  babies and to fetuses and to normal adults and   to -you know - stroke victims, and to cats and  mice and dogs and worms, and in principle   you can sort of take this phi meter and - and measure the amount of intrinsic causal   power the system has, thereby how conscious that  particular system is in a particular state. --So this sounds -uh - really fascinating and to  me one of the most counterintuitive aspects   of this theory is exactly what you were just  alluding to - this phi meter: the notion that   we - we might be able to - to measure phi in - in all  kinds of- uh- and all kinds of things from flies to   bacteria to chairs and tables and computers. Some  of these may have a very low phi, but a non-zero phi -  so how do you reconcile or how do  you think about the notion that -   that bacteria may have a low degree of phi - or that my iPhone may have a low phi value? um -   and what does this number - um - what does having  a higher phi value or lower value mean?   --Well, so it means to what extent is the system  irreducible? I mean ultimately it's one number -   it doesn't quantify, it - it doesn't sort  of describe the qualitative aspect of the   particular conscious state, the -the -the brains - so  let's see, my phi might be 6.8 times 10 to the 25:   that's a high number, but it doesn't tell you am I,  you know, conscious of pain or [red?] or of the state   of the affair, right? So for that you have to read  out the individual component of the system but it   tells you at least this is a system that's highly  integrated, highly differentiated and - and therefore   has this intrinsic causal power - is conscious - and  it [violates it?] because as you said it may be true   that even simple systems like flies, like worms - the  worm C.elegans that's studied widely in the lab -   or maybe even individual bacteria may have  because they're so vastly complex today - we cannot   even run a supercomputer model of all the molecular  interactions within a single cell - so it may well   be that even this itsy-bitsy tiny cell has some  measure of phi that's different from zero - so that   violates our intuition because we think well, only  you and I and maybe cats and dogs and great apes -  you know -- and elephants and other charismatic  megafauna are conscious, but of course here I'm   not talking about high degree of consciousness,  we're not talking about mental content like you   and I, right? - if I - if it's true that a bacteria  has a phi, let's say, of 25, for the sake of argument,   or 42 -it's a nicer number, 42 - but that doesn't  mean the bacteria has thoughts about tomorrow   or has regrets or feels fat or feels, you know -  you know - it -it- it just may feel like something -   and when it's dead, when it's dissolved into its  component, it doesn't feel like anything, so it   may be it - it will be, a very primitive form, but  it may well be that this feeling, again, of life   itself may persist even in in a simple organism -  that most people assume - for heaven's sake, they   can't be conscious - just like, you know, many other  measures in the universe, like temperature; we know   out in outer space as actually temperature  different from absolute zero, right? It's 4.2   degrees, it's a background radiation. It's  incredible cold in outer space, yet physics   and measurement tell us there's still a minimum  amount of molecular motion that can be measured as  -  as temperature in deep space; and so it may be  with this measure phi, and this is of course   a very ancient philosophical belief. Some of the  greatest thinkers in the west - Plato, Schopenhauer,  uh Russell [?], you know, one of the fathers  of -of computers and and and integral calculus all   thought that consciousness is far more  widespread than we - than we are led to believe. --One - one aspect that- that's fascinating  that you touch upon in the book is   this: the connection between consciousness - uh - and  intelligence or the lack of connection -uh- between   the two. Um - There are many movies out there  about -um -the idea that we may have -uh - sentient   uh- machines. You even wrote a beautiful article  about the movie "Ex Machina". You have argued quite   vehemently that intelligence and consciousness are  quite different things so can you expand on that? --Intelligence ultimately is a measure of behavior;  it's - if I'm - you know - if I'm confronted with some   particular new environment - how quickly do you  adapt to it, over immediate or over short term?   Over the long term, right? - so that ultimately is  intelligence: the way to rapidly adapt modulate my   behavior appropriate to the circumstance. That's all  behavior - that is, that doesn't say anything about   feeling, that doesn't say anything about experience,  so conceptually intelligence and experience are   really very different things. Now in humans, or  maybe in all evolved creatures such as, you know,   other animals, intelligence and consciousness may  well correlate; in fact, in our brain they may well   co-mingle; but conceptually they're different -  and you can certainly imagine a super-computer   that is as intelligent as us or that even, you  know, superhuman artificial general intelligence,   but that has no feeling whatsoever. Conversely  you can easily imagine brain organoids   that you can - that we can now engineer  in - or at least in 10 or 20 years - in large   sort of a carpet of cortical art  you know, engineered from - from   human inducible pluripotent stem cells that  give rise to a large carpet of- of cerebral   organoids that have high consciousness, yet no  behavior, because they have no output effectors.   There - so you can certainly - the way I think  about them is a plane, and on the x-axis you   plot the intelligence of that individual or of  that species, and on the y-axis you plot the - the   measure of consciousness that the species or the  individual of that species has, and in principle   these are independent things. In fact - so integrated  information theory predicts that digital computers   of the sort for normal machine we have today  have - have [?] very small intrinsic causal power   and although -although in their aggregate they can  simulate the human brain or they can in principle   simulate intelligent behavior and they probably  will do that soon in the future, it doesn't feel   like anything to be such a digital simulation, even  of the comple - even of a - of a human brain. Just like   you can simulate the causal power of gravity, for  example of the - the - the black hole at the center of   our galaxy, right? [?] - you know the  Nobel prizes were given out for that last week -  um - we can - we can write a computer program  that simulates the power of the black hole to   attract everything to it so nothing can escape, not  even light - that's the name - but funny, we don't have   to be concerned that the computer program - that  the computer programmer, himself or herself, will be   sucked into the computer simulation. Why not? Well - that's the difference between between the real   and the simulated. The simulated doesn't have the  causal power of the real, and because it doesn't   have the causal power, you won't get the- the  gravitational singularity; likewise you can be -   you can simulate behavior but you will not get  the consciousness associated with the behavior   unless you replicate the human  brain in particular hardware. --So uh - despite this dissociation -um - in  your - in your book you also argue that   in principle there is no physical limit uh - to to  consciousness in the sense that we might im[?] with a different type of hardware and a - you - um - alluded to neuromorphic engineering, for example,   we might be able to build devices that that would  have a - high phi? --That's correct, yeah. I mean there's   nothing supernatural about the human brain - it  doesn't have extra magical properties that other -   you know - it's the human brain is part and parcel  of the universe; it's a piece of furniture of   the universe, subject to the same laws of quantum  mechanics and general relativity as everything   else so that's it - there's nothing supernatural. It  is true, IIT has no natural limit on phi; phi can be   big - in fact, we might be able to artificially  enhance and enlarge our - our- our brain by   connecting to brain, so just like - you know - we know  that if I take a normal brain and I cut it in two   to prevent epileptic seizures from spreading  from one cortical hemisphere into the other   one - it's called a split brain procedure - I can  do the inverse; I can take two brains and see   your brain, and my brain, and with the future yet-  to- be- invented technology I call "brain bridging"   where we directly connect my brain, my neurons,  my cortical neurons with geocortical neurons,   sort of like an artificial corpus callosum, we  would then - according to the theory if we add more   and more wires at some point we would abruptly get  a new conscious, a new conscious entity that would   have aspects of your brain and your and my brain  - it would be some sort of amalgamation of Gabriel  and Christof. It would control you know four - two miles, and it would, you know, have four   arms and four legs, and its phi would presumably be considerably higher than the phi of either you or I - [?] right we can try as soon as we can - --First be able to do it in mice like the  creatures in - in flatland who cannot imagine   uh -other dimensions - uh I -I find it hard to even  conceive what it would mean to have um - a higher phi.   uh - Imagine either by merging two brains  or by some sort of a device that you can   implant in your brain or by training, or  any other mechanism, imagine that you can   uh - duplicate phi. What - what does - what would that mean,  what would that feel like, uh - what would be the   feeling of life itself be with a higher phi? Well - I mean, just cast your mind back when you were   before - let's say you knew about sex or before  the first time you fell in love, right? - there's   this entire new universe when you - when you  discover sexuality and you - you find and express   your own sexuality - you now become sort of  more conscious, right ? you become conscious   of whoever attracts you and that gives rise to it  to a universe of conscious states; you fall in love.   Yeah, right it's a profound new conscious state  that you know, presumably, seven- or eight- or nine-   or ten -year- olds, you didn't have; the first time  you drank alcohol, the first time you tried if you   ever dipped psilocybin or [?] or any other  drugs, the first time you drank wine, right? So these   are all from our own experiences. We know to a  certain extent what it means to have new conscious   experiences and so likewise, you just extrapolate  that you know to a [merged?] brain when we have new   states accessible that neither your brain or  I, my brain by itself, will - will be conscious of.   It won't be dramatically different because you're  still a human brain and I'm still a human brain   um - but but it-uh - there will be new states  that we cannot have experienced before. --Can - can you switch gears now to -to a more  personal level? You - you end the book on a   passionate, a passionate argument,  about how studying consciousness how -  has changed aspects of your life, or how you see  the world or - or how we as humans interact with   the world in general? uh - What do you think are  the implications of um -uh - getting further and   further into the mechanisms of consciousness,  uh for- for - for you, for society, for our lives?   --Well - A - that you realize how very precious it  is, how we would be nothing to ourselves if we   wouldn't be conscious. Without consciousness,  we don't exist for ourselves, right? If I'm a   perfect zombie that moves around the world - that  looks and behaves like me and does everything,   if you give me a billion dollars - but I - but I say  I'm gonna take away your experience - well, what's   the point? Then, you know, I - I'm no one to myself, I don't exist, I may as well not exist for myself so -  you just realize the preciousness of experience  and how it is unique above anything else, and   also you realize particularly when you study  consciousness in other animals, be that closely-   related species like dogs or be that more  distant like an octopus, that consciousness   and - and the pains and pleasures of life, you know,  they're widespread and we should respect them even   in insects. So you know since I had this sort of  conversion to a more broader view of consciousness,   I -I don't eat the flesh of - of animals any more; I  don't even kill insects any more because they too   have this brief moment you know book-ended between  to eternity - this brief moment when they can exist   and when they have feelings, and so once  again it makes life all the more precious. - Thank you - thanks -uh -that's -uh- that -that's quite  uh -quite beautiful. um - Again uh - sort of on a -on   a personal level, um -the question of consciousness  uh - has always solicited very strong reactions uh -   from scientists, philosophers, many people who  have argued that that we're not quite ready to   tackle this question. Many, many people who have  argued that these questions are unanswerable.   How do you -um - how do you have the courage  to - to drive the field forward? How do you - uh   manage - uh - in the midst of uh - so many  different opinions and skepticism and -   uh - and other ways of thinking about the  problem? - Well, you disregard much of that;   of course, it's self-fulfilling prophecy if you  say we can never tackle it, then, of course, by   definition we'll never solve it. So you know  we have to - we have to do the best we can -   yes, maybe [unintelligible] - [and the?] theorem won't be the correct final theory,   but - but the most important thing, it makes very  specific predictions: we're now engaged in -in this   adversarial collaboration - in fact you, Gabriel, of  course are part of that - where we test prediction   of the two dominant theories of consciousness: the  dominant scientific theory, integrated information   theory in global neuronal workspace, and so again  in that sort of clash of ideas and specific   experiment, even if both theories will shown to be  very imperfect approximation, that's progress, right?   and on this - on this - on this ancient 2400-year-  old, at least - old problem we can make progress.   So for instance IT has already now  provided progress; there's now a procedure   that's used in - in - in several hundred patients  already that's being tested in many clinics   called "zap and zip" to actually test whether  this patient who's unresponsive, right? who [?]   I cannot communicate with because her - her brain  is so damaged due to traffic accidents and whatever-   I can now test using - using this calculus whether  the patient whether it's somebody home, they are   not - so that shows that real progress is possible  despite - despite the doomsayers and despite   many people saying 'well, it's - it's philosophy'. Of  course, it's philosophy; it's one of the oldest   forms of philosophy, but all scientific problems  started off as philosophy early on - and then as we   developed powerful tools and theories, we took them  from philosophy and turned them into empirical science. - Very good - um - I'm gonna turn it now to the audience -  there's a - there's a lot of questions in the   in the Q & A - uh - so I'm gonna read some of the  questions. There - there are two people here uh -   uh Swami and Glenn - that are asking about where do  you stand on the hard problem of consciousness? Is   the hard problem of consciousness- uh- answerable? - Well, once again, I mean you know if you believe   the hard problem of David Chalmers said, 'it is  forever hard', then of course you're never going   to try to solve it; so I - once again I find that  a defeated argument. Many philosophers over the   last hundred years have made often the argument  that certain problems can never be solved,   will never be accessible to human insight, - like  for example, Auguste Comte in the 19th century,   the father of positivism, made this assertion: 'we  shall never know what stars are made out of'.   Today he probably would have said 'well, that's a  hard problem' - with a capital H - well, it turned   out 20 years later they invented this spectroscopy -  spectrogram - and you could analyze the constituents   in the atmosphere of our own sun by looking at  the - at the spectral decomposition. So yes, these   problems are difficult but are they forever hard?  We don't know. Human ingenuity is very powerful -  so let's trust our good old ingenuity to solve  these problems. Let's not be taking in too much. - I agree - I agree absolutely. uh -  David Ryson -uh - asks about uh -   the functions of dreams and I assume the  relationship between dreams and consciousness. - Dreams - so the function of dreams, you know, the  many hypotheses about it; you know, Francis Crick,   of course, had the famous one; it's - it's - it's  used to more officially reorganize our memories.   We don't - still don't know what the  function of dreams is, if it has one,   but certainly dreaming is one part of  consciousness: it is conscious, you're   highly conscious of it, you've seen here; in  fact inside the dream you cannot typically   distinguish the dream from reality, right?  Most people - except if you have a lucid dream -   you don't know that you're in a dream and you're  not surprised that you can walk through walls or   fly or meet, you know, a long-lost pet or long-lost  loved one, so it's - it's - it's another manifestation   of consciousness inside a sleeping body, so  it makes it particularly interesting to study. Uh - I apologize to the audience if I don't get to  all the questions or if I mispronounce your names.   Peter Cariani asks -uh - how does [Tanoni's?] theory of  requisite -oh- of requisite informational complexity   of accessible functional states relate to neural  global workspace theories that requires closure   via sustained regenerative - uh - recurrent activity  and feedback? - So it's the relationship between   IIT and complexity and Victor Lam and [?]  Baars, Dehaene and global workspace theories.   --Okay, well, okay there are four different theories  they all so iit is being tested right now in this -  in this international collaboration with -uh -  ten different labs - Gabriel Kreiman here being   one of them - where some of the predictions of IIT  are contrasted against the prediction of global   neural workspace. It's very difficult right  now because global neural workspace makes   very different assumption about consciousness  than - than IIT and has different implications   for computer consciousness. Right now those kind of -  but what we can, some of the neuronal application -   global neural workspace has consciousness, is  the footprint of consciousness essentially,   in the front of the brain because it has  to do with cognition, with intelligence.   IIT essentially says nodes in the back of the  brain, the back of cortex, where the connectivity   is higher - so that's experiences that - that we're  trying to test. The two theories also differ on   how- on the relationship between the - the timing of  the footprint of consciousness and how long you're -   you're conscious of something. Again that's - that  can be tested and that is being tested right now   in the three-year-long effort, so we will know in  two years or so, or three years maybe, given Covid -   we'll know more about the status of G and - G and W versus IIT. --Chang-Yang Lin Gu -- and again I apologize if I am  mispronouncing your name -uh - consciousness  is something confused with awareness and or   attention but by the general public. Are these  terms related in some way or are they totally   uh - separated cons- er- concepts? So, consciousness,  awareness, attention. - Okay, it's a very good question.   So - some people distinguish between awareness and  consciousness. I don't, I don't; I've never found any   useful operational way, so for me it's the same and  I just note that sociologically some - most people are   more comfortable speaking about awareness, for  example, in [?] rather than consciousness but -  but - but scientifically I -I don't distinguish.  Attention and conscience are very different so and   we now know experimentally there are probably 60 - 70 different experiments where people have shown   that you can attend to something, attention visual  in this case - but not be conscious of it, which   sounds strange, right? So attention means selective  processing of information, selective in space, in   time, or in some feature; you can do that without  being conscious, so at least you can dissociate   attention and conscious one way. Whether you can  dissociate both ways - that in other words, can you   be conscious of something without attending to  it, that remains experimentally more difficult to   address and that's my - that remains much more  controversial but I think most psychologists   would now agree that you can attend to things  without necessarily becoming conscious of them. - So in your book you touch upon meditation  as well as states of consciousness   devoid of any external sensory experience. An  anonymous attendee asks, hare krishna chanting or   [bahkti?] yoga is said to evolve one's consciousness  so meditation, yoga, certain practices that   are purported to evolve consciousness; can I know  your take on this? -Yeah - so people - so I don't know   personally because I'm not a practitioner of - of  these particular meditative or practices; people -   there are these what -this class of experience  called 'mystical experiences' that you can get   in certain forms of of meditation, and some  people call it naked awareness or sheer awareness,   pure awareness, it's called; some people also report  these doing in an isolation tank, these mystical   experiences; of course, the world literature  is full of them with respect to religious   conversion experiences. They also have some  of this character near-death experiences,   sometimes have this character and um - certain drugs  particularly the drugs of the serotonin class like   psilocybin, DMT and 5-MeO-DMT can also lead to  these mystical states. So what's a mystical   state from a phenomenological point of view? A  mystical state is a state when time - two things   totally disappear, the self and time, so typically  and I've been in the states - you're gone, your   memory is gone, your thoughts are gone, the self is  gone, your body's gone - there's no more Christof,   no more thoughts, no more dreams, no more desire,  none of that is present; they're timeless, they're   not too short, they're not too long, there's no flow  of time - the sense of self is completely gone - the   sense of time is - is totally gone; sometimes the -  the sense of space can be gone and typically you   don't hear, you don't see, you don't have fear,  you don't have pain, you don't have pleasure.   Typically they associate with very powerful  emotional states - either ecstasy or dread or a   choice combination, so in some of my mystical  experiences you have this combination of- of   awfulness - sort of you - the awfulness of pure  experience - the ecstasy and the terror of - of   being confronted with this what feels like a  pure thing and there's no more you there. It's   a very peculiar state - it's very very compelling -  but I think ultimately it is a product of the [?] I'm not sure whether I would call it higher  consciousness: it's a very rarely-encountered   form of consciousness. I'm not sure to what  extent it is a higher form of consciousness. --You just alluded to a memory. Javier Masses asks   does consciousness require a capacity  for memory, at least short-term memory? --Probably yes, although IIT doesn't say the theory,  doesn't say anything specific about memory;   certainly for human level  it's very difficult to imagine   being [cons?] without at least having very  short, short-term memory and I know no patient   that doesn't have --of course there are plenty  of patients who've lost long-term memory, yet   are still conscious like - you know - people with um - with dementia - they're clearly conscious but don't   even know who they are any more; it's very difficult  to imagine what would it be like to have - to not   even have this short-term form of consciousness;  in principle, though, it may be possible. Uh - with several others - uh - Kiril Sinkel asks  whether there is a function -uh - to consciousness,   and - and I know in the book you talk about  um -uh - the evolution of consciousness as well.   -Yeah, so that's a very, very good one, because we  have to ask - I mean, we clearly are highly conscious   and I can be - you know - I think you get older, you  can be conscious of your internal states, and   it's highly differentiated. So clearly  this couldn't have arisen by chance.   So what is the function of of consciousness?  and there have been many, many functions that   have been proposed, including by myself  and Francis Crick, so for instance to make   my particular ideas, executive hypothesis: I live  in a - in a very complex environment. If I want to   quickly summarize what goes on and make that  summary available to my planning stages, like   an executive summary, that could be one function.  [--ology?] it's very -it's very often very difficult   to answer this [fashion?] -what's - what's the function  of one leg or what one eye, or of one gene? Those   are very difficult to answer and the way to - the  way I think about consciousness and evolution is   per IIT, consciousness by itself doesn't have  a function, it just - it's internal causal power -   just like no physicist would say 'well, what's  the function of electric charge?' or 'what's the   function of gravity?' Gravity is just, you know, space,  it's curvature in space-time; electric charges just the propensity of things to attract or to repel  each other. Now biological organism can exploit   electric charge, right? for example, to separate  charges inside and outside the neuron, and you get   a neuronal - uh -you get a membrane potential and an  action potential but - but primarily it doesn't have   a function. Behavior, evolution, select for behavior,  right? Evolution ultimately selects whether I'm   going to survive or not, not what I feel inside  so it's - it's from the point of view of evolution   you could argue that consciousness directly it's  like a what -what [?] or Wilson at Harvard   calls a "spandrel" - it's not directly selected  for. What's directly selected for by evolution   is - is behavior, but indirectly you can  show this very nice in computer simulation:   when you have creatures that you evolve in  artificial environments, the creatures do   better to the extent they take all their sensors  and integrate them and make all that integrated   information available to their processor. Right  there their- their- their sound in their   site, their camera and everything goes into the  central processor to - to make that information   available to planning, and you can measure in these  simulated creatures that they also have high phi   so you would expect evolutionary that sys -  that -that have systems evolved that have   high adaptability and high intelligence also have  high phi which is why intelligence and I think phi [xommon?]  in evolved creatures. But an engineered system  like on the one hand, brain organoids, on the other   hand, artificial - you know, computers - I think you can  separate that and you can build systems that have   high intelligence and no consciousness, or that may  even have high consciousness but no intelligence. --So an anonymous attendee asks uh - whether you  think it's ethical to induce consciousness in   machines. So you talked a little bit about -um- the  fact that today's machines don't - don't quite have   it, per IIT -uh- but what - what if future machines  built on different hardware could actually um   uh - have- uh- high phi and therefore according  to a theory of consciousness, do you foresee   any ethical problems with building machines  that are sentient? -- Well, I mean, you know, you   can look at "Black Mirror" you can look at  "Westworld" - you know there will be untold -  you know, it's a complex world, and you  can imagine all sorts of nasty scenarios   where you build something that only experiences  pain, that's in fact only capable of experiencing  pain - and that would be of course atrocious  to put such a creature into the world. You can   also imagine that you can build creatures that  only experience pleasure, or more likely, these   creatures actually have to survive out there  that have like us - that can experience both   pain and pleasure - and then I think the moral  imperative is to enable them to live in a universe   where they maximize -uh you know, the -the- the  pleasure, or they maximize their own capability   to experience and you minimize -uh - the pain, but in  practice there will always be scenarios where this   doesn't happen, or where you get these conflicts  as you can see in watching "westworld" episodes.   --Uh if it's okay with you uh - Christof  uh - we'll take a few more questions. Uh   uh, is - is that okay? Um - Murtasa - uh - asks is  intentionality a property of consciousness?   -Is -I assume this is talking about the  relationship between consciousness and -   and volition and free will and intentionality;  are these -uh - things related? --Well, yeah, so consciousness always has content: it's always about  something, right? So it's about my toothache or it's   about -you know - seeing - seeing Gabriel here on the  screen. As I said, it may be possible in a state of   pure consciousness when there is no more content,  and then the question is then there isn't really   any intentionality anymore because it's not about  anything - in - if it's really true that you can   truly obtain a state of pure consciousness with no  content whatsoever. Free will is a totally separate   question. So according- um - A, having will -uh - having  the - the feeling of will, of agency, you know, I'm now   raising my left hand and now I'm raising my right  hand - that goes hand-in-hand with uh - ownership, I  know it's my hand - it's not Gabriel's hand - and  it goes 'hand' with a feeling of intentionality:   I wanted to raise my right hand or I wanted to  raise my left hand and - and the feeling of wanting   to do it as compared to when you put a [transcranial?]  magnetic stimulation on my head and trigger it   then I feel my hand flip but I know it's not me  that triggered that and that's a very different   feeling. So these are all conscious feelings that-  that go hand- in- hand with consciousness. IIT says will - what people call 'will' - essentially is a  maximum of causal power, the maximum of intrinsic   causal power, that's it - what you experience  as a feeling of agency that we all have. --The maximal causal power is also -uh -  important to understand in terms of   two other questions that are here that I'm gonna   put together. uh - One question relates to uh - what  do you think about Marvin Minsky, "Society of Mind"?   and the other question relates to -uh -  consciousness at different levels: for example,   is there - does a society as a whole -uh- have- uh - have consciousness? --Okay - so that relates to the   general question, the- the mereological question of  the relationship between the parts and the whole.   So IIT says it's only the maximum for any  particular substrate that's conscious so right now   Gabriel is conscious, I'm conscious; we interact, so  clearly there's some sort of amount of interaction   among the two of us, but that - but if we compute  the integrated information across both Gabriels   and [?] is minuscule - so there isn't  any entity that exists that is Gabriel and   and - and Christof. Likewise if I extend this over  all 310 million Americans, that is a tiny max -  it is a tiny number - vastly less than the number  inside my head or the head of any other American.   Therefore America does not exist as an intrinsic -  as a maximum of corporal attack power - therefore it   doesn't - there isn't anything like it to be America  as a conscious entity - although America, of course,   has external causal powers - it can start wars, etc. -  but it doesn't have any intrinsic causal power   so it's really only the maximum. So likewise the  neurons in my head, the individual neurons, are   unconscious; it's really the collective, the maximum  of -of whatever in my - in the footprint in my brain   that's constituted by the maximum at that level  of resolution is what conscious - not the individual   neurons, not the individual atoms that make part  of it, and that's true whether you're dealing with   society or with brains or with sub-components  of brain, it's always only the maximum. -Very good - so - uh there's a question here uh - maybe I'll take one more question if that's   okay with you Christof - I know we're running  uh - a little bit after six uh - uh in Boston.   Um - there are two questions here by Sachin  Sang: does current research in learning theory   from both neuroscience and machine learning  community help us in any way to understand   consciousness? --It helps us practically for sure;  so you know at the Institute I run here, the Allen   Institute for Brain Science, you know, we have - we  use all sorts of advanced machine learning, deep   interpolation, other advanced machine learning  techniques to help us make sense of the data.  Will it help us conceptually to understand it? I   don't know at this point - I can't answer that - I  haven't seen that directly but I don't exclude it. --All right, very good, thank you very much, Christof.  uh - This -uh - this was uh - really - uh - wonderful.   Uh - I'm glad that you're surviving the windstorm  and that you managed to connect with us and uh -  it's - it's been a pleasure talking to you about -uh -  "The Feeling of Life Itself" - uh, uh - which I -I truly   enjoyed - so thanks a lot. --Thanks a lot; thanks a  lot, Kate, for hosting us. --I was going to say if   you have time and you'd like to you're more than  welcome to go ten minutes over because I know that   we started late- but if you have somewhere to go no  problem -- --Yeah, I have my next uh Zoom call coming up 