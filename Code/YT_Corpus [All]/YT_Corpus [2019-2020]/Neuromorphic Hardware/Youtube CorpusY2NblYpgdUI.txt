 okay so we have six panelists today and directly introduce our panelists today let me introduce we prep hench from IBM who is the right now used to be a manager now he is relaxing little let's work on Wilfred and let me introduce our own professor VBA chief from ECS let's break apart here professor Daniel Sanchez from from ECS mi he and professor dr. Hajra Melo from MIT DMC what's your science department and and here mr. Angelo person from DARPA this last here is a Jennifer group from mature science in MIT okay let's pick extreme okay let's have a exciting discussion so all the questions that I got will be here I pick the two questions are of many questions receiving and we create some important question here so let's take a look at the question here okay let's let's listen discuss about the custom from the audience's first okay we're talking about spiking your network versus non spiking neural network what is your opinion about these two different types of neural network and what could the future of these can we start with that's a very loaded question so I think spiking networks are very intriguing because they they look like what we see in the biology but from a technical implementation I think spiking networks are looking still for an application where they are useful so I think for our research we finally start from the application standpoint something backwards so as a result of that we primarily focus our own research basically am I echo exactly what will freedom be Beyonce let me just add that you know there was at the beginning of the of this workshop you know an interesting presentation on you know how all these is how the brain is really not a matrix multiply accelerator and you know maybe it's not that that you want to demand spiky or less but the concept of having time or exploiting time in in the computation of this works how it applies to other signs of logic let's say grace logic right there's a lot of interesting recent working in this topic so I think you know it's not necessarily spiking personal spiking but how to incorporate time into to make these systems more efficient so and there was idea too much on the digital spiking or so there is experience with spike it's so so a couple of things two doors is not trained each other it's only an inference the energy efficiency from true north is not coming from the spiking it's come from the sparsity of the ways of the weights are spiking is used spiking is used to get some benefit in these communications so this respect it's a it's really not bonafide it's spiking I think it's interesting we're sitting here in Brandon cocked and and I can be mistaken but I think most of us are electrical engineers or physicists right so in some sense there are probably the hundred people in this building that are more qualified to answer this question that I am and you know it's said but this gets to a point which I'm sure will come out which is that we're really talking about norm or freaking seeding which is brain inspired but we're not doing your mimetic computing no no none of the people there today are really focusing on that so in that sense I'm going to sort of dodge the question by saying that spiking is is really a different question which is you know what comes next what's going to be the electrical engineering challenge twenty years from now it's too close to neuroscience now for AES to really sink our teeth into it but you know if you it is an interesting instance of asynchronous computer so if you think of it that way you know it allows you to decouple processes and different parts of the processor and perhaps there's some some progress that could be me thinking about those so sorry I manage protocol outside and how people doing animal computing and including a Spiker neural networks and I would say that young the application also be a huge hurdle getting to work reliably my practical sense and the effort involved in creating each circuit no with the digital we kind of provide our little code press open surfaces button to get something fairly optimal because we believe oh now look we don't have that so you get a very expensive effort for every data point so we end up getting a very small scrap maybe three or four data points and of course yeah you know you're right your your tensorflow fight towards network right and any deployed to you or senior when you innovate very very quickly so whatever you comparing to the alternative is already moved forward like more like by a thousand eyes so I think that's one of the charge they're always comparing things like interesting but it's got to move at the speed of everything else so if you receive the per quarter one it's it's gonna be application okay with your perspective they're still outstanding application for which you're waiting for the right spiking implementation of the law I would say is if it's just linear algebra that's not very it's something that's a tightening coupled to some kind of stimulus okay Jennifer yeah I think that's a very interesting comment so I'm adding to that is we discussed our computing but also do we say enough about the hybrid type population so can actually a palace I don't know computing also since parallel what was going on in the environment there are for instance questions as increment here at hardware level and that's a operation principle are quite attractive to look at and that one I would actually agree very much with you these questions are not like that so may ask but I think the objection so is there - if I'm activity on a parallel way more on to especially thank you what was the question my question is missus of spiking was advanced by this post we looked at post and I think based on our experience with the with the spiking we think it's spiking it's just not there so we still it's an interesting solution but as I said it is it's not clear what application you would like okay thank you let's go on to the first question there okay yup this theme is workshop one air your mother honey pan yourself so is it right custom for this workshop so never go shy 810 years old what is in it what is the highest party - what depends where you stand right there in the university you want to look at no ideas issues look at the person who wants to make money out of it then you need something that works reliable and usually there's a 12-year difference right so if you look at a ten year time horizon then you get a different answer either from home from my academic colleagues so I think whom do you ask what he's asking you what what if you ask if you ask my opinion right I want to make work what we know is feasible right now right and we have ample ample evidence then these Arabic solutions are feasible whether they really hold water that's a long way to go skii right so so what is the biggest change and now I think the biggest challenge is really two things one thing is to find a manufacturable material solution that's one thing and the other thing is to build it to build a system or building an architecture that is software compatible what we have right now right because if you don't have that you cannot go anywhere this is this is you should stay in the commercial space if you really think apart and you need to complete your software infrastructure there's a huge huge barrier for inserted into the commercial space all right thank you um so I think you know obviously we're in the age where I think one of the big challenges is that when you want to be domain-specific you won't know what to be too narrow at the same time right so obviously it takes us much longer to make these hardware than it takes new algorithms so I think one of the big challenges moving forward is how you build efficient hardware but still make it flexible so that you can support future algorithms and obviously most the times that reduce flexibility it comes at a cost to efficiency so I think the understanding where to draw that line is important I think also coming from an application standpoint is also important to understand the application while and not just to look at it like a workload you're also involved right so people in that space let's say working on her all that so she's an example there are certain things are trying to achieve depending on what application that they're looking at so it's important to not just look at it network of how this network might change in the future as well so having some notion of where an either like kind of dynamic work with it will evolve over time so flexibility and also under Sharia classification yeah so I would say one of the main things that we think hard about from the hardware side is you know over the past by almost ten years basically GPUs the amount of hardware have been the enabler of the neural net on the current revolution a tippler and one major concern concern is that you know these hardware might actually restrict the kind of algorithms that get studied and developed and it would be really constraining if we started focusing on yeah all the implements there's basically a big bathroom here where we only focus on accelerating the algorithms that are already developed that are already targeting the previous generation of fairly restricted hardware so even things like sparkle s you know attention networks and so on there is you know a lot of trade-offs are being made to try to map these efficiently to card so I think that we have one really important part of how do we revolution years it's really generality this is to figure out from starting from the algorithms what is the right thing to do especially you know one thing that we're very good I'm doing in hardware is to take a problem that is not algorithmically efficient and accelerate it to death right so you know graph algorithms for example you know you can do an accelerator for they're a pretty efficient algorithm that processes the entire graph for a duration right but then there are algorithmic advantages that I will make the algorithm hundreds of times more efficient right so I would say you know with once once you sit down with with a domain experts you can start finding ways of making that typically that efficiency usually it worked like this do you work like this you provided piece of hardware the software people go edit and see the limits and then they get creative and work within two limits right so so I think I think it would be interesting to find a model where you don't have to wait till the hardware is there that people think out of the box and addressed limits right because this could also guide an improvement of hardware development but this is not how the world works right now right the GPU it's a typical example but it's so pretty nicely the problem is that then as a hardware designers will look at the software that explained within the limits and say well you know this is great this is completely sufficient to do let the software people wander let's just restrict it a little bit more sealer they can keep yeah so I I guess you said ten year if I can answer the question of twenty year you know III think one thing which it urges from the first talk and some of the questions is that we're missing the complexity of the brain and we have ways of capturing that like fan-out numbers and and in precision right it's totally impossible for neurons for that we do in oxides or so I think that there are people again in brain ACOG who treat complexity as don't science and we would develop Goodman from them so for example maybe ten fifteen years ago there was a hype wave around self-organized criticality and complex systems things like cellular automata I think that there's a lot of useful ideas there where we can stop trying to analyze every single little device and figure out what emerges when you couple end devices and then scale in another area where this you know could could it be very useful is borrowing some ideas from quantum annealing so how do you optimize in materials so inferences is not a hard problem it's like a soft problem maybe it's optimization or training that is consuming all of our energy resources so you know can we do that in materials there have been efforts that it's a quantum computing that went down paths of simulated annealing considered not real on computing and that's that's fine I'm not here to talk about quantum computing but there's a lot of interesting optimization within materials where if you take a systems level approach you could say well how do we define the topological and boundary conditions that would cause the system to evolve toward the solutions and you know right now when I work on neuromorphic computing I'm still you know thinking IV curves which is fine right out of material sciences but it seems like that's what the field is missing that's what this one is one of the things that would really take us from you know where we are today we're crossing I like your shirt that the array is right to the really understanding you know what are the profound what the profound advantages in an energy savings do we get due to massive scale massive advantage of the scale competition I just so the first thing I would say giggle out per watt of innovation so you should look at useful computation so so seen way way too much by allies Neela statement maybe we need to do over seven years of profound found the heart problem that requires collaboration across disciplines I would say yeah I think that I'm sort of excited that there's always a cost of flexibility that's basically what a person level been doing with twenty years not designing commercial chips and to quote one of my colleagues like rearranging the chosen Titanic the ship is going down just doesn't really matter what you do you can trade off a little bit flexibility for performance doesn't really matter so I would say yeah 20 years from now I'd like to see something that is not even configurable in the field morphs in the field either chemically or mechanically or by some means where imagine a bag really gonna go out out there that would a bag of molecules right that somehow involved the time might for a certain application I don't see any other way to fight this effects ability versus efficiency yeah yes sir I mean any material scientists here I'm poking their cap off one moment I think I have two dreams for in 10 or 20 years the first one is an enlarger scale to see far more hybrid devices I'm not treating like cells a traditional way anymore that they have to send especially many much more integrated with you know some other type of units so questions like cavalry also have a part of a sending function as well can a processor also have these functions this would give farm opportunities and it stands currently that these disciplines are still very separated if you go to a classic neuroscience conference you know sensing suppose you and you have a normal computing symposium and you have that say some other domains this has for me to intertwine more answer needs to be more cross talk to design this new chemistry and physics and on a smaller length scale the second one is physical principles what are the dynamics what does he the effects are involved this phenomena and what is the cross of energy that I have to pay for those to gain more clarity for zurafa computing power but also for the other domains in AI what is possible here so this I see the true positives I think one dish to explore together yeah everyone else you know you know I think all these things we're kind of in this weird mode where he got here through a self-organized process that not that nobody controls which is the whole Moore's Law loop with a cop with economics which is the input factor and so it's not clear to me we can go anywhere else without another input factor from the economy really driving us now we don't know what that is yet so we got to do research to try to find it but I think kind of like it's very difficult to step back and say ok we're gonna like invent a new paradigm now when you have to have economic loop in there right [Music] not sometimes getting it over the values how many billions can you push yeah I mean yeah this get philosophical but I mean obviously right I mean nobody's gonna invest up that far out in time except for the government right I look at the you know it's kind of interesting the government application which could be justified by society was a defense one for semiconductors and it just so happened that the same parameters for that investment also are valued in the commercial domain which is extremely rare right so you know what society will pay for going forward it's not it's not actually clear that we'll find another economic loop anytime soon so for example you know that anthrax can be very important for a defense application but but there's no commercial spillover right so so it just it's just I think these things are a lot harder than we think because you've been in an easy paradigm [Music] [Music] well I disagree with that because if you look on IV characteristic which one this twenty years ago and you look at in a V characteristic of a transistor from a seven nanometer node the first order they look alike and this is why and this is why this modular approach is is working and but if you if you lift the air if you lift the lid you look at the pot what boils right the even if the chip industry the modular the modular model is long gone because there's such a tight interaction between technology design architectures that that it is you cannot you cannot look at these different levels independent level independent way anymore to get the optimal solution you can kludge something for together this is suboptimal and this might be okay but if you want to have an optimal solution there's a tight interaction between the different levels in the eye space what I believe what I believe the coupling between the different levels is even larger right I think because the technologies will drive algorithms algorithms drive technology algorithms will drive applications and so forth all right and I see this already when I look when I look at the it's the analog space right digital dudes very very successfully so has a gradient descent right in all its different variations and forms in the analog it doesn't work because you need this perfect symmetric device right now no one in the world would create it perfect symmetric analog device right so so what you have to think about is there anything that we can do in the analog level that we can make it work and the answers yes they are possible ways how to make it work and this goes up the whole the whole the whole food stack the other thing is you look at the enormous success of convolutional nets right and if you if you step back and look at how convolution saw implemented when you're going to analog space that's a nightmare right the question is can we do the same thing that convolutions do in another way right it's an algorithmic question right to take advantage of the technology but you cannot you cannot you cannot separate that stuff this is true for digital course you don't want a hard thing because you don't want to talk to the other guys of this neck because it's a big problem that's exactly the problem yes right the software guys will talk of the hot guys yes is the other way around right yes well I'm working in the industry I did work I'm retired now so but I work 30 plus years right and how many times did I go to the design community and say what time this summer you like give me the same that I always have right what would you do if I can if you get this switch well I don't know all right give me what I always have right because they were so busy living in zeliha that they didn't see any value talking cross ideas and this has to change this is a nature of the technology the eye stuff is a new beginning to that point there's actually business theory showing that in industries are old enough you go from vertical integration to horizontal back to vertical there's no question vertical integration is where things are gonna appear which means that you know you get people together to through the stack to work together the problem here is I don't see the value at the other side you know but but that is definitely the truth well see this is this already a fallacy that in this argument because when the end key people work together the vertical integration they do that because they have to because there's no other way how to make progress yes right yes but I advocate here in AI space they'd have to work together because they want to know I have to know III agree except that usually you have to have some so we've done this actually I did this the last seven years and we didn't know the exact application we didn't know the last market but we did get people together vertically and now you have chips coming out that are completely unique with new materials in them but we kind of knew what we were we didn't know exactly what form but we knew there was market value in a wide range of things so like it made sense to march together towards that even if it's ten years away see here I have the profit there's no marching order so if you solve this problem it's not clear what we do all right you see this is what the academically says but but actually if you look back to look at the adventure transistor everything else it was never like that it was it was not people doing random stuff at all so it does not work that way even though over and we love that because we could sure if we talk if we talk in the very very very very narrow picture of a my deep learning right it's a very narrow very picture because they I it's much much more but if we only talk about deep learning I think the problems that have to be addressed are very clear very clear and and there are solutions out in certain spaces and other spaces not but the problem is very well-defined so I think in general I think one of the motivations for our group how we got into deep learning was the higher level question I had I worked in video compression before I came back to MIT we have video compression and behind most image sensors out there we if we really want something like deep learning or something like computer vision to be ubiquitous you have to fit that kind of capability in the same area energy and cost budget in general as you would video compression right so we took a look at both handcrafted features which was the state up they are at the time and then deep learning that was up-and-coming and even with just pure hardware optimization on both just digital hardware there's still a two order of magnitude gap in terms of energy and so you can't just you're not going to be able to close that just sting at a digital architecture level you really have to start thinking up and down so we chose just because of the area of expertise that we have we chose up so we co designed both the algorithms and the hardware together and there you can get another order of magnitude almost two orders of magnitude savings to try and close that and that's the motivation because you actually want to deploy these and very cost constraint type of application like systems you really have to look beyond just one layer of optimization and you would see similar challenges if you go in the cloud to because what they're limited by is also power efficiency so if you want to have a lot more things running deep learning in AI you need to be computing more efficiently and that's also the motivation of going to domain specific types of applications as well right so you have a lot more demand of compute but because of the slowdown of Moore's Law you need to be have more specialization and so again when you start talking about domains you have to think about what is the definition of domain to think of the application you have to think of the algorithms otherwise you're designing for today's algorithms which might not be the future algorithms that you actually need right so the co designer knows Daniel said it opens up the space much more broadly to think of new architectures as you're designing the algorithms and then vice versa and there is a big motivating case because there's a demand for compute and in the existing separated approaches we can't deliver for that demand its limit in progress space just be successful on the physical side good so actually interfacing physical things I mean as standards everywhere and you know they tend to be pretty coarse things like USB PCI Express but at the as you get further down into the package we don't have a way of Hebrides for integrating things right that is an enormous opportunity space for getting games right so DARPA super 20 programs there for 10 years now things like Dottie trying to blend materials right to create really really good RF circuits like chips program we were trying to cut a monolithic die into tiny chip let's each optimized right so you can imagine having a catalogue of specific functions that think it's bonded onto some kind of wafer so but the idea of combining the best of read/write whether it's the memory devices or transistors with new functionality right but for that you need you need interfaces right and it C it doesn't seem like anybody can agree what those interest rates should be materials electrical interfaces but if you could then do you think in government agencies there is a specific effort to combine this hardware it's doctor activity together so when it comes to standardisation we can't do anything right we got the government can't set a standard right it's gotta be in this together so we can serve like I said we we have the we have a bunch of programs er I like this electronics for certain initiatives 1.5 billion dollars investing in computing the hardware is software and I mean it's it's got a bunch of really great programs but I would say it's still fairly near term five to ten years out beyond that who knows 10 years 10 years yeah then this makeup smooth transition okay are you asking if like small-scale a I'm gonna drive area hardware that does inclusion without our legacy was you know you can there are many many oh this is a question that is half big cake right you always can meet little power if you run it very slow did you make this Krishna did you why you've got a revolt I mean for me most Lord the manifestation of most lawyers said that every every gadget that you buy right has his hard work is some microchip Ian right and whatever whether this will be true with I realize it the hardware I'm not sure right there are people out there that say that that will be pervasive right I'm not quite there yet so so it's it has to be seen what I can deliver but we have to understand right if we use AI in a very kind of martial art way right all the popular stuff with the talking I right now this is all deep learning and deep learning is a very very small part was very very actually very tight constraint on to make it work right so so ten years from now but we talk about either might be completely different right and then this question might be more relevant I don't know it is the end of Moore's love is placing a lot of constraints on how capabilities evolve but I mean building on what Wulfric is saying I hope that in 10 years right the algorithms have evolved I mean one a different way to look at this is you know we have a great existence product of you know doing intelligence we think what you watch how is current fabrication technology failing to get a stay right so one of one of the things that you know it's a constant at least in computer systems computer architecture is that we love to focus on compute see people building quarters here you know a lot of thoughts have to have to matrix-matrix multiply multiply it's for really fast but in fact if you compare to the fabrication technology at least where we are now the brain the largest differences in the enterprise Alabama right so the brain is great at doing memory at very low power and in a similar way which is something that in silicon we have not yet figured out how to do to get cheap memory we are not fully fabricated in a completely different process I'm putting it far far away so memory axises completely energy and then the capabilities of the brain interconnect are far far beyond what we can build and sleep on today starting from the very fact that you know we were to me to these substrates but even when you look at systems like what max has presented early in the morning it is 3d but it is through in a very structured way whereas the brain is very good of doing very dense very unstructured and long collections and so I wonder whether you know there's some device level progress in that style of the prototype of my it enables more more connectivity and humans I would really second that the Von Neumanns paradigm is something we can wrap our minds around right and we can design it these elements and it provides motivation sometimes when we don't know even what the application is right you can't look at a transistor in the CMOS and integrated circuits in the 70s in envision with the cloud or a few people can but if you could use in that direction and the challenge now is that the brain provides us our inspiration right but the brain is too complicated for me to understand so one thing which I think could help focus this question right what what am I am I supposed to look at a the fionna device and see some future applications I mean I'm incapable of that right and I don't think too many people can hear Jenny but you know I think we're missing an element of modeling right so for example we have Kirchhoff's laws we have spice how do we model anything that a device engineer for the sister material scientist can dream up how do we model the emergent behavior when when you need wire 10,000 of these things asynchronously we don't have software for that that's actually big computing problem you could use AI deep learning to model such things and that's pretty you know need applications and and try to see emergent behavior and always always have the power in the denominator right so you're always modeling power because that might be the way to discover right we have to model these systems at scale much more than an individual you know IV curves and cross point arrays and let that about that that those outcomes tell us what sort of physical behavior to look for right because the IV curve the transistor it it doesn't speak by itself it doesn't tell us what the application is again this comes down to talking right all right so we have the question from audience so you see mr. ho ho ho hey hurry program for pretty goodness I even understand yet it's a little more about your question yeah like what language what language features with the appropriate for interfacing with with AI harder love language your said it seems clear that the language has to be able to handle a lot of power loads of problems and that's presented by the AARP AI hardware can be exploited what what is the context what is the context of the question programming programming I'm a I'm an applications person and I want to IA I hardware to an application so you want to build you what to build an application and it does some stuff floating a I'm building a self-driving car you know and I have programmed the write the software to do it and it's going to use an AI hardware very well to do get the seed I did a biopsy polls all the things that a self-driving car has to be able to do we ideally the programming language would be you stick the device in the car and you take it for a drive [Music] the problem is that even though we love math says that in the end there's going to be a neural net they need images and controlling the steering wheel when you get on that tire is the way my kid learned to drive the car one minute right so I think the great argument is that you can you can put enough sensors that you know Hartstein be going better than he wants but I mean we suck at driving right like it's pretty little are the I think there's an interesting question there which is how what's the interface between you know one of one or some of these big learning based techniques that are much more about training models and then you know just use more data to get to get more accuracy kind of AI applications I'm more you know programming or classic AI applications if you will right there's something in the middle please seem quite disparate right now well seems though that there should be some interesting continued platforms out you jockeys one for everyone right in the flow I thought whatever whatever's out there and they all help to abstract so that you don't have to write real code right but I don't know whether if this is the question that you asked regarding to the self-driving car okay I'm gonna say something that's one of the core organizers here so just one thing I want you guys to maybe step back and just a big-picture question intelligence how the brain computes it what what that even is these are Nobel price questions and the Natural Sciences and the greatest engineering challenge in our history and I think it'd be nice if we could figure out how to leverage in all the expertise you know every talk I'm looking at oh I see Inklings of what might be going on in the brain and some of you have mentioned like even tools to simulate what's going on it's heard that mentioned that's that's a lot of the activity here in the department is oh we see opportunities to simulate what's going on and rather than thinking you know I sort of appreciate it that it's become a bit of a I equals deep learning how do we implement that in hardware and that's a very narrow view that seems to be kind of dominating where people are being pulled and I understand that as economic forces but it would be good to figure out how we at the university can step out of that narrow view to support the larger view of hey what's the next generation of this even going to look like and I'm not asking for this is not going to be coming only from all of you right this is really again a bigger challenge and I can't put it all on you but sort of figure out how to enable those forces together is kind of what the quest is about and really what this workshop is about so and that's not really a question but maybe a call to motivation and maybe you guys want to very good in describing things right for different components you don't tell me what it means right they don't tell me how it all fits together in the kind of algorithmic point of view right and I think this is one of the major shortcomings that that maybe it's a training issue maybe they are not aware maybe maybe they or it could just be a hard problem that's a hard problem a hard problem this is an this is a cheap excuse right if you know what the problem is and it's worse for to solve it you are headed right but so so so what when are you people aren't trying to aren't trying to solve the problem but I ever seen anything I haven't liked most of the stuff that comes from the biologically oriented community it's on a description level and it's hard to find the description to prepare the data to isolate it to see what's going on I completely get it right but the next step is what is really the underlying data flow there what happens again so connected so what so for example this is let's say we don't we have chronic comics there are big well funded programs to try to figure out all the math that connections in our brain but it's not ready yet let's take C elegans right what about the quest implements the mcgrath elegance and let's students put devices different devices in there and set different rules and just play right because already that you know it's emergent some of the things emerge you don't always understand why they emerged but at least you have a model system right you can let physicists do scaling analysis you can let people calculate the power budget did you did you have a more power efficient worm by with your meadow with the earth memristor than with this synapse that is biological and so forth I mean we we lack a playground and such a playground is a way for different scientists to talk to each other and I think that's one thing which maybe we could we could do together Martha come back to this because I think that the criticism that you raise is is a very important one and I think that I think that there is a lot of neuroscience that is descriptive and I think there's a reason for that because there is a lot to describe in but I think neuroscience in the last decade or two has gradually become increasingly driven by the by the desire of people to explain what's really happening at an engineering level and to really understand how those circuits work or at least understand how they emerge during development and how they're trained by the data that they get to do their job so I think your criticism is valid but I think there's a increasingly big part of the neuroscience effort that's dominated by this is a desire to do exactly what you're suggesting there are cases where we're getting to gets beginning to get some Inklings as to how these things work but we don't really have most of those questions answered yet and you could think of the activity right now I think of it as engineering forward engineering within the constraints pace of the measurements so you're never gonna measure the brain and it's gonna hand you a blueprint of what to build we need people building things within the constraints of the measurement so what the C elegans is an exact suggestion here is like when you're providing the constraints then engineers working within those constraints then discover things right is there that's the spirit of what again we're trying to do with the quest is to have both of those you can't do it alone from brain science but you maybe can't do it alone from just engineering without guidance exactly this is exactly true right if we want to make progress we cannot do it alone you guys cannot do that right that's right right this is where the interface stuff comes in your part of the layer but has to talk to each other right sometimes there isn't a shared language of these different deals I think that was a big part of what I ordered you notice as most people aren't talking because there's not a shared language and I'm wondering if there's any thought that anyone has given everything to be risky setting to help encourage people to speak more it technical terms that are cross-disciplinary yeah both can add something to that so if you think about materials and spraying that as some language that they share since you could most have lots of processes by equivalent circuit models that share actually information all the time spends on the dynamics that you have in the system and you can use I think the same models that you know electric engineering also I think it's some of the brain models and also to many different materials and processes and that can I sing form a quite strong basis and look later actually on how to program that and how to speak to people developing novel isms more right and so I think apart it's shared it's not that not all is not shared but man we have to get to give them more in developing roadmaps on what we take onset for materials different paths like physics and chemistry you can drive and then later coming to more complicated networks we should talk I think there's some joint degrees at least for I know there's something with like Korsak said I think that they're trying to build these bridges so that the students can get joint degrees across these to support living we have to grow are all those people to operate basically I'm sure that's part of the college of computing initiative something related to that roll it up all right to our you won't thank you flora in eyesight's life 