 Hi, and welcome to this video overview of PLDA’s vDMA controller IP. As we well know, the explosion in data traffic due to the advent of Artificial Intelligence, machine learning, automotive and IoT prompts for new System-on-Chip architectures that allow system developers to build high-performance applications that are able to ingest and process huge amounts of heterogeneous data. This new breed of System-on-Chip combine an increasing number of processing units, which can be CPU cores, GPU cores, custom accelerator engines, as well as different types of memory subsystems (such as RAM cache, DDR, HBM to name a few). To allow these System-on-Chip components to communicate, System-on-Chip need efficient data movers also known as DMA engines that can support hundreds of concurrent, high-performance communication channels. To address the increasing demand for a scalable high-performance data moving engine, PLDA has developed a DMA controller engine dubbed vDMA, which combines the features and performance expected by designers  of next generation System-on-Chip. The DMA engine connects to the rest of the System-on-Chip through industry standard AMBA for AXI interfaces which can be configured with a 256-bit or 512-bit datapath The vDMA IP Core is a highly efficient DMA engine intended to be used as a centralized DMA in System-on-Chips, allowing data movement across a large number of concurrent channels, in any direction. One of the key features of vDMA is the support of up to 2048 dynamically reconfigurable DMA channels (or queues) which can be shared across up to 512 hosts (or processing domains). This allows System-on-Chip with hundreds to thousands of CPU cores to concurrently and efficiently move data in between CPU cores and between CPU cores and other processing elements such as accelerator engines, GPU cores, memory subsystems, and other on-chip peripherals. In term of performance, vDMA offers up to 16GB/s of data throughput across all active queues when configured with a 512-bit datapath running at 250Mhz. Of course higher throughput will be achieved at higher frequencies. One of the engineering focus for vDMA was to ensure the highest possible throughput for small packets (in the 64- to 128-bytes range), and the design achieves this goal successfully through various techniques, including large descriptor prefetch tables, contiguous descriptor memory allocation, in-descriptor reporting, to mention a few. Emphasis was also put on Quality-of-Service and security, with features that include fair bandwidth management, non-blocking queues, domain isolation, ECC protection for memory buffers. The vDMA IP is equally supported on SoC ASIC and FPGA and is proven to offer better performance and more efficient resource utilization compared to existing FPGA-based DMA solutions. Check out the next video in the series which demonstrates the performance and capabilities of the vDMA IP. Thanks for watching! 