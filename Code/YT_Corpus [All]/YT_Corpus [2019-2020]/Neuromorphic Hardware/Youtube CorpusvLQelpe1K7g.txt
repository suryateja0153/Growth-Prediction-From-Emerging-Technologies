 (loud swooshing) (keyboard typing) (soft beeping) (melancholy music) (uplifting music) - Hi, I'm Terry Sejnowski and I'm here to tell you about the deep learning revolution. I'm the Francis Crick professor here at the Salk Institute and also a distinguished professor at UCSD with adjunct appointments in a number of different departments including the neurosciences department, biology, computer science and engineering, psychology, cognitive science, bioengineering and I have students from all those departments, so it's a very broad area that I cover. So here we are, looking out over the Pacific Ocean. This lecture is going to have three parts. It's going to be about the past, the present and the future of artificial intelligence. Now artificial intelligence was launched in the middle of the 20th century when computers were invented. And the goal back in 1956 was to program a computer to have the equivalent of human intelligence. To be able to solve problems and to be able to interact with the world the way that we do. Now what's happened over the last of five years has really been extraordinary, because some of that great promise is finally being fulfilled. Now we're not all the way there, but I hope to show that we've made great, great progress in some areas. And what's exciting about it for me is that it's really a merging of two different approaches. There's one where we're learning more and more about human intelligence and specifically about how the brain creates human intelligence. As we learn more and more about the brain, that's helping to inform us on how to build a better artificial intelligence. And so it's really the convergence of these two fields that is powering the advances that are made. I wanna start with a example just to give you a feeling for how this has unfolded. Let's go back over 100 years ago to Kitty Hawk and the first man-powered human flight took place there, the Wright brothers. Now the Wright brothers were very inspired by biology. I highly recommend a biography written by David McCullough on the Wright brothers. And they were inspired by birds that could glide for long distances with very little power, 'cause that's really what they were facing, is to try to get an airplane with relatively small power to be able to deal with the wind and all the other uncertainties about flying. And so from bird wings, they were able to get airfoils and they built a wind tunnel to be able to test the airfoils. And the second thing they discovered, that they tried to emulate from the birds were the fact that the feathers were incredibly lightweight and very stiff. And so as you can see, their airplane was cloth around wooden spires, as lightweight as they could possibly get it. Now there are a bunch of other groups that were trying to fly at the time including the government that was launching metal of heavy airplanes that crashed. They were the only ones that actually did get off the ground and we now know that this was the beginning of the aviation era. But the key take-home message here is that you want to be inspired by biology. Take away the general principles and build on them. Now there's another amazing thing that birds can do and I wanna show you a little clip which is a falcon that is being tracked with GPS. And you're gonna see what it does. It's looking for a thermal and it wants to climb the thermal. And the color here tells you whether it's going down in blue or up in yellow. So here it goes. It's flying here and there, going a little bit up and here it catches the thermal and it finds it. And you can see it's looping around the thermal as it goes up. And this is a very characteristic way that birds, without flapping, can ascend to great heights. In fact there are some birds that can travel all the way, annually, from the Arctic all the way down to our area thousands of miles by using thermals without eating for weeks. Now we don't understand how the birds do this, it's a mystery. And we'd like to understand. It's very difficult to do experiments on birds. And part of the reason why it's a difficult problem is that the atmosphere is not a very smooth place to try to navigate its turbulence, especially when there are hot airs coming off the ground and you're trying to figure where a pocket of hot air is, 'cause there's also cold air going down. And so a couple of years ago, I teamed up with Massimo Vergassola who's a professor of physics at UC San Diego and our graduate student Gautam Reddy to see whether or not we could use modern AI to try to understand something about what are the features that the bird might be looking for. And we did that in the context of a real glider as you can see here on the left. This is a six-foot wing spanned. These are airplanes that are used by hobbyists to radio control to try to get them to go up thermals. Well we, as you can see on the right, equipped it with computers and all sorts of sensors, for example, acceleration sensors, tilt sensors, angle of attack, and these were all important features that we thought might be important for the bird to be able to sense and to be able to now take actions. Now how did we proceed? Well, we proceeded by going to a area here in Poway where hobbyists gather to try to see whether they can go up thermals. It's a place in the summer where there's a lot of hot air going up. And the way we went about it was not to write a computer program which is the way that most artificial intelligence has been done up until recently, but rather to trial and error using something called reinforcement learning. this is trying to learn through practice, something that humans are familiar with. Learning how to play tennis, you've gotta try many different approaches and you get better and better gradually. And so this is what we did, we started out by launching our glider with very little knowledge of either anything about thermals or knowledge about the task. And the goal was to try to go as high as you can. And as you can see, at the beginning, you just go down, down, down. But after hundreds and hundreds of trials, you begin to start going up. And you can see here, this is now a well trained system. It's able to catch a rising thermal and after many trials, it looks just the way that birds do it. You can see the loop here as it very rapidly, rises, rises, rises. Now the difference between our little glider and the bird is that we can look inside the glider and find out how it is the glider learned how to climb a thermal. By the way, this is amusing that Gautam, after the launch, would sit down in his chair and put his radio control down and everybody would stair at him thinking that he was crazy. But here's an example of where the glider not only outperformed all the others, but it actually reached a point here, 600 meters where it went out of radio range and then had to come back on its own. But this is showing us that, really, the performance could improve on human performance. Now it's not just the gliding, but if you look carefully, for example, at this eagle, you'll see these little feathers here. What are they there for? Well, you've also noticed that airplanes have created little wingtips here. And the reason is that this saves 5% in fuel which adds up to many hundreds of millions of dollars for airlines, it's a big savings. And biology was there first, so this theme here is being inspired by biology. Now we're gonna come back to reinforcement learning later in the talk, but first I wanna give you an overview of artificial intelligence. Deep learning, which is the focus for this lecture, is really just one small part of machine learning, which is writing programs that learn through experience. Reinforcement learning learned through experience by trying over and over again to try to achieve a goal that we told the program, the learning algorithm which gradually improved performance, to try to get as high as you can. Now machine learning itself is just one part of artificial intelligence which is the attempt to reproduce all of human intelligence. And that includes other things, not just learning how to locomote or how to see or how to hear or how to talk, but also to make decisions, complex decisions in the real world. And there are other parts of artificial intelligence that are equally important. But the focus here is gonna be this one little piece at the bottom here. So let's look into the brain. Let's open the brain and see what's in it, 'cause after all, it is the only existence proof that any problem in intelligence is solvable. So let's see what the machine looks like. And this is something that neuroscientists know a lot about and we're learning more and more everyday. We've learned more in the last 10 years about how the brain works than we have in all of previous existence in terms of human science. So here's what we know, some general principles. We know that there are a lot of neurons in the brain, there's about 100 billion neurons. And each of them is connected with thousands and thousands of other neurons. Very high degree of connectivity. And this is much greater than the number of transistors in a chip or the connectivity between the transistors, much, much higher. Now each neuron integrates information coming from other neurons. Some of it is excitatory positive, some of it's inhibitory. This is integrated and then sent down to a region here, this is the cell body, where it's turned into a signal. And if it reaches a threshold, it'll send out a pulse, what's called an action potential. Which will go out along these these long, thin axons and then contact other cells through these synapses. And these synapses are connections that have a strength. And the strength of the connections are variable and we call it synaptic plasticity. So a lot of work has been put on studying the conditions under which these synapses will change their strength and this turns out to be the secret sauce that helps brains become intelligent. And as you'll see, this is a key input to deep learning. Now the history goes back to building networks of neurons, artificial networks, goes back to 1943. And McCullough and Pitts made a very simple model, oversimplified, this is a cartoon model for what a real neuron is actually doing. But the idea is that there are inputs to the neuron and then there's outputs and then there's a transformation in between. And so here's what the perceptron, was a term that was actually coined by Frank Rosenblatt in 1959, but here's how it takes the inputs. It takes the inputs and you can think of each of these inputs as having a value. It could be the value, for example, of the gray level of a pixel in an image. So if you have million pixels, you have a million inputs to this one unit. Each one of it is weighted by a number. This is called a synaptic strength or weight that is summed, some of 'em are excitatory positive and some are negative. And that's compared to a threshold. If it's above threshold, then the output is a one. If it's below threshold, it's a zero. So this is really, like I say, it's a very simplified version of a neuron. Now what Frank Rosenblatt did in 1959 was to actually build one and it was at a time when computers were very slow and so he actually had built it out of analog components. And these weights here were physical variable resistors, potentiometers. And the way he was able to come up with a set of weights, 'cause how do you determine what these weights should be to solve a problem? Is that you gave it examples. Suppose you wanted that this thing should be in pictures of cats and dogs. Well, what you do is you have a lot of images of different cats and dogs, you give them one at a time to the input and then it produces an output. And if it makes a mistake, if it's given a cat picture and claims it's a dog, then Frank Rosenblatt developed a learning algorithm, that is to say a procedure for changing all the weights a little bit in order to be able to, more likely, have the right answer. And he had a theorem that was a very powerful theorem that said if there exists a set of weights that could solve the problem to discriminate cats from dogs, then his learning algorithm is guaranteed to find it. Very powerful, and so this is a paradigm now in miniature of what led to deep learning. And I'm going into this detail just to give you a sense for the nuts and bolts. And the fact that there's mathematics involved here, this is not just throwing together something and seeing whether it works or not, you have to have very rigorous mathematical guarantees. So let's give you an intuition about what the algorithm does, this is the perceptron learning algorithm. Here's a very simple example that I actually worked on in my lab when I moved in the 1990s to La Jolla from Johns Hopkins University. And we got a hold of a database of faces, of male and female faces. These are college-aged kids. We cropped the hair and all the other secondary sexual characteristics. And we trained up a perceptron to distinguish males from females just like I said cats and dogs. So here's the question I'm gonna gonna put for you right now. I want you to look at this face and I want you to decide, is this the face of a girl or a boy? Okay, so how certain are you of your decision? Okay, now let me ask you, how did you figure it out, how did you figure out whether it's a girl or boy? By the way, in many audiences, roughly 90% of the people think it's a girl, but nobody has been able to explain to me why they think it's a girl, even though they're very sure of it. Some people say, well, I can tell from the eyes and some people say, oh, no, no, it's the nose and so forth. But the reality is that we don't know. We've had many, many people that we've known of the two sexes and somehow through that experience, we've been able to generalize to new people that we meet for the first time. Now after training the perceptron, the perceptron actually does as well as humans. So it's clear that this is a problem that's solvable with a perceptron. It's not perfect, but it does really well. And what you're seeing here is the solution. The solution is a set of weights and each of the pixels here has a white or a black square depending on whether it's excitatory, inhibitory, and the area of the square is the strength of the weight. And without going into the detail, you can see that there's information about whether it's a male or female from every single pixel. So this is, it's called a holistic approach, that is that you're looking at the whole picture, you're not looking at any part of it in order to make the decision. And that's really what, in terms of trying to understand a general principle, this is really the most basic principle which is you need to gather information from all the evidence coming in on the inputs. Now the perceptron was a very simple example, but it was only, it gets direct inputs and it has direct outputs and there's nothing in between. We know in our brain that there's a lot of neurons that are in between the inputs and the outputs. In the visual system, for example, the retina projects into the brain and there are dozens of areas in your brain, in your visual system, which is analyzing all of the features in the inputs. And it's only at the very end that it projects to the motor system. Now back in the 1960s, people tried to generalize the perceptron from one layer of synaptic strengths to multilayer, it was the multilayer perceptron, but no one could come up with a learning algorithm and it was conjectured that no one would. And that was the general belief, that this was a dead end. (keyboard clicks) Until Geoffrey Hinton on the right and this is me back in the 1980s. We were postdocs at the time. I was at the Department of Neurobiology, Harvard Medical School. I just finished my PhD in physics. Geoffrey had just finished his PhD in artificial intelligence and psychology, so we had complimentary backgrounds and skills. And we took a crack at it and we solved the problem. We developed a learning algorithm for a multilayer perceptron, but we had to make one change and that was to change this hard decision between zero and one into a smooth decision. And we used this as a probability of whether it was gonna be zero or one. We called it the Boltzmann machine and it was a proof of principle, that was in 85. Now shortly thereafter, Dave Rumelhart who was here at UC San Diego and was the head of a group called the Parallel Distributed Processing group, which was a very early group that was studying neural networks, came up with an even more powerful learning algorithm called backpropagation of error and it is this algorithm that is by far the most popular, that is fueling all of the work that's been done in artificial intelligence over the last five years. So it really was the key step, it was very small, you might think this is a small change, but mathematically, it's a huge difference. Now to give you a feeling for modern networks, I wanna show an architecture. It's feedforward architecture. There are also architectures that have feedback connections, but this is a good one to start with. This is an architecture that's gonna be used to solve a medical problem to diagnose a disease based on inputs that are tests. For example, it could be x-ray that are going into the input layer here, that yellow. And then you might have some physiological measurements, the EEG, the heartbeat and so forth. And also you could have genetic input, there's all kinds of different sources of evidence that might help make predictions about what the problem is. Is the problem, has the person had a myocardial infarction, a heart attack or is it that the person is having indigestion. I mean, these are life and death decisions that have to made in the emergency room. And if we can improve on that, then this could really help a lot of people. So in any case, the inputs come in here on the first layer and then they project up to, we call them hidden units, on the second layer and then they project to further layers. Each of these little lines here represents a weight, a number that has to be changed during the learning process. And that projects all the way up and finally the input from the different sources of evidence is integrated and then at the final layer there is a decision that has to be made. Let's say there are three possible outcomes. Now just like in the case of our male versus female, you have to have a lot of labeled examples. The inputs coming from people who actually came in to the emergency room and then what their actual outcome was. And from that you can now use backpropagation or other learning algorithms to change all of the weights throughout the entire network and it gets better and better and better. And now comes the big test, if you give it an example it's never seen before, can it generalize? Can it now come up with a right diagnoses? And the answer is if you do the training properly, if you have enough data, you need lots of data, and for many problems, you'll be able to do as well or better than the doctor. And this is really astonishing, because it takes doctors years and years and years to learn how to become a good diagnostician. But once you have a network like this, it could be disseminated in many emergency rooms. Okay, so let's give you a flavor. Now one of the things you'll notice here is that there are many many layers and we can prove mathematically that the more layers you have, the better the performance, but nature was already there. So here's a hierarchy of cortical areas in the visual system. And here's the retina down here. And each of these boxes is a region of the cerebral cortex that's on the top of your brain, the surface, and it's been greatly expanded in humans relative to other species. And you can see there are dozens of areas. It goes from the beginning here, primary visual cortex, V1, V2, V3, V4. And for temporal cortex where we know that learning takes place, object recognition. And finally going up to the very top here, the hippocampus. Where memory for specific faces and specific events is being integrated to help the brain solve much more difficult problems. Not just vision, but also somatosensory system, auditory system, olfactory system, it all funnels into the hippocampus. Now this hierarchy is the secret and that's why it's called deep learning, because there's so many layers between the input and the output. Now let me give you an example of one of these problems that you can diagnose and that is, here's a skin lesion. You come in to a dermatologist and say, doctor, can you tell me whether this is a dangerous skin lesion, is it malignant or is it benign? And the doctor will of course look at it carefully and give you the best opinion, but ultimately you need to take pictures and maybe a biopsy and then its processed, it may take weeks before you get the results back. And there are thousands of these skin lesions, so to become a really good person to distinguish the dangerous cases, you have to really have lots of experience. Now I've written a book that summarizes this whole history, called "The Deep Learning Revolution," published by the MIT Press just in 2018. And one of the pages in it, here, page 10, had a little vignette on this. It turned out that someone had trained the deep learning network to literally, 130,000 images, 2,000 different diseases from the database. And they were able to diagnose as well as the best doctors. In some cases better. And here's what I predicted in the book in 2018, it will soon be possible for anyone with a smartphone to take a photo of a suspicious skin lesion and have it diagnosed instantly. A process that now requires a visit to the doctor's office, a long wait for the lesion to be screened by an expert and the payment of a substantial bill. Well, shortly after the book was published, I heard a interview on NPR and here was a company that actually had one of these apps First Derm. And you take an image of the skin lesion, you send it up to the cloud and it'll ask you some questions about it, how long you had it, is it growing, and then it will come back with its best guess and give you some recommendations. But it's of course, the value is you get it back instantly. And of course it tells you to go and contact a physician to be sure. They gave an example. They even gave you a place, here's a place you can contact, but they gave an example of a girlfriend who saw a lesion on the back of her boyfriend and she noticed that it had been growing over the months and she was concerned. So she took a picture, sent it up to the cloud, it came back saying this potentially is a very dangerous malignant lesion and you should go instantly, really, immediately go to a dermatologist office and get it checked out. And indeed they did go in, it was a malignant lesion, they got it out and it may have saved his life. Of course he didn't see it. He was fortunate he had a girlfriend and was fortunate she had this app. But in any case, this is a little anecdote about something that's gonna be happening over the next few decades as more and more of these apps are gonna become available to the public. Well, here is another use case, which you've heard about, it's been touted in the media for several years now, which is self-driving cars. We've finally reached the point now where we have good enough sensors and we have good enough artificial intelligence to begin to train cars. And this is the key, is that you need lots of experience. And in fact Google has, Waymo is a company that was a spinoff from Google. They have had millions of miles of experience in San Francisco and in other parts of the United States where they have self-driving cars collecting data and especially the rare cases. It's very important that even things that only happen once in a million times, you wanna be prepared for that, 'cause you're learning from experience. Now let's extrapolate, this is by the way, people think this is gonna happen overnight, no it's not gonna happen this year, it's not gonna happen next year. In fact, it's gonna happen over the next several decades. The timescale for rolling out a new technology really requires a tremendous amount of improvements that are going to be done and are being done. And I'll tell you a little bit more about that later. But here is why this is a very important use case. So first of all, most cars are only used less than 5% of the time. So it's very inefficient, especially in urban areas where you have to find parking spaces. Well, if you can have a self-driving car that will appear within a minute of pressing a button, you don't need to have your own car. And if you don't need to have your own car, then are fewer on the road. Cities are covered with parking lots. You have to park it somewhere. And if you don't have your own car and if in the city you don't need to park it to get out of your car, then a tremendous amount of space is going to be repurposed. Could be used for parks, I mean, who knows what else you're gonna, shopping centers will become little parks. A lot of companies are gonna have to shift if you have, the cars can talk to each other and avoid accidents, autobody shops aren't needed. Car insurance industry is gonna shrink. 40,000 people die on the road every year, both from falling asleep, from drunk drivers, it's gonna save many lives. Now commuting, the average commuter in the US spends 51 minutes a day in their car often during rush hour and getting to work feeling frustrated. And billions of hours every year could be saved from commuting, because you could be working or reading a book or doing anything else with your brain while the car takes you to your work. These cars can caravan. You can get many more on the highway. We don't have to build millions of miles of new highways. We can get more cars on them. And finally, who would steal a car that could drive itself home? This is the end of grand theft auto. Okay, well this all, I'm sure I'm not seeing, this is things that have occurred to me, but I can't really predict the future or the impact it's gonna have. There are other things that are gonna change. And one of the concerns is people losing their jobs. Taxi drivers, truck drivers. There are millions of people employed right now driving cars. Well, as those jobs are phased out, there are gonna be new jobs phasing in. For example, these cars that are chockablock with sensors. It's like your body, your body is chockablock with sensors that's absolutely essential for being able to see things and walk and make decisions. And so these cars have lidars on them, high-precision laser sensors, they have radar, they have cameras. All this information is gonna be used to make decisions about how to operate the car. Now here's a job that you may not have thought about. It turns out all the raw data that comes into training on that work has to be cleaned. There are a lot of artifacts, the formats are different for different types of data and so there's a lot of people who are gonna be employed by just taking the data and preparing it for training purposes. And that requires skills. Well, these cars, air traffic has to be controlled, because of the fact that there are congestion in airports and along the way there are routes that you have to space the airplanes on. And the same thing will be true. There'll be congestion in cities, especially during rush hours and you'll have to have humans sitting there and make sure that nothing bad happens. So that's again another job that will have to be for people that will have to learn skills, how to the oversee the system. And finally trucks. Right now there are long-haul trucks that go thousands of miles. And these trucks, again, the drivers in them spend weeks away from home. They often are going for long periods of time, they get tired, sometimes they fall asleep. This is a very tough job and it requires a lot of time and effort. Well, right now there are companies that will automate that with existing technology especially on the interstate highway, it's pretty easy to stay in your lane. But here's the problem. Suppose that you are shipping tens of millions of dollars of cellphones or electronics across the country in a 40,000 pound truck. This is a sitting duck for carjackers. So, what do you do? Well, you higher someone to sit there as security. So we've taken away one job, the truck driver and we replace it with someone else who's gonna sit there and be sure that the load is safe. One for one, which job is better? I'll let you decide for yourself. Now this is really bubbling up. There's a lot of people going into this. Kids are going to courses at MIT on self-driving cars. There's a massive open online course, a MOOC, that Udacity has. In fact, you can get a nanodegree. You could take a bunch of courses from them on self-driving cars and with that you can go and get a really good job, why? It turns out that every major car manufacturer now has bought or is developing in-house self-driving technology. So there's a tremendous number of jobs for young people and these are courses that you can take online or being taught now at universities. UC San Diego for example. Machine learning used to have classes, these was like 10 years ago, with 20-30 students, now there are 400 students taking machine learning and that's because you can get a very well paid job if you have skills in machine learning. Now I know a little bit about MOOCs, because I actually have one which was started in 2014. And this was an effort with Barbara Oakley who's a very, very experienced educator at the, she's at the University of Oakland. And I was the neuroscientist who helped give some background to learners who were trying to figure out how to become a better learner. The title is Learning How to Learn. It's a free MOOC, anybody could take it. We've had over three million learners in 200 countries over the last six years. It's a four-week course, three to four hours of videos a week. And we've touched literally thousands and thousands of people of all ages from 10 to 90 from many, many different parts of life, housewives. Our biggest segment is 25 to 35, half of them are college educated. These are people in the workforce, they need new skills and so our course helps them become better learners. We recently wrote a book that would reach, this is aimed at middle schoolers, 10 to 12 years old. And as you can see, I think, these are specifically helping little kids become better learners. That's their job, they go to school everyday to become better learners and so this is a way for us to help them. One of the biggest problems we have in the world is communicating with each other. There are hundreds of different languages and this is a Tower of Babel. And there's so many misunderstandings, cultural misunderstandings, language misunderstandings. Words can mean different things in different languages and when you translate them, they often can be misleading. Now it has been one of the holy grails in artificial intelligence, as far back as I could tell. This is really something that, as I could remember, it was, can we come up with a language translator? Well, in science fiction, the universal language translator has already been invented and here's Captain Kirk in "Star Trek" holding a language translator. Well, the fact is that you have one in your hand probably at this very moment, which is in your cellphone. Google Translate will translate written text and speech recognition. And I was in China recently on a book tour and had trouble communication with the waitress and I spoke into her cellphone, it was translated to Chinese and then she spoke into her cellphone in Chinese and I heard the English. So there we go, universal language translator. Now the algorithm that I started with which was a reinforcement learning algorithm is something that's found in almost all species including invertebrates like the bee. When you combine reinforcement learning with deep learning, magic happens. The game of Go is thousands of years old and especially in the East Asia, it's raised to a very high art. And in 2017, AlphaGo which was a program that combined reinforcement learning with deep learning beat Ke Jie who at the time was the reigning world champion in Go. It's a very difficult game. Go is much more complicated than chess. Go is to chess what chess is to checkers. And it didn't just beat him in three games, it played at a high level that was higher in terms of the moves it was making that no human had ever even thought of making before which were extraordinarily effective. And it achieved something that humans thought was a unique part of human intelligence, namely creativity. And here's what Ke Jie had to say after his defeat, "After humanity spent thousands "of years improving our tactics, "computers tell us that humans are completely wrong." Well, this was a bombshell in China. It was their Sputnik moment. And now AI is one of their 10 top innovation goals. Billions of dollars have been poured into it. It's really amazing how many engineers that they're turning out now who are trained in machine learning. Now looking into the future. We can learn from the past. Let's look 250 years ago when James Watt built the first steam engine. Now the steam engine amplifies human physical power. Back in 1790, 80% of the workforce in the US was on the farm, but 100 years later, only 40%. And that's because the steam engine was able to power tractors and one farmer could do the work of 100 with horses. Well, what happened to the children of the farmers? They went to the city. They worked in factories which were powered by steam engines. This was the beginning of the industrial age. It tool hundreds of years to gradually incrementally improve a theory in physics, thermodynamics helped optimize the steam engine. Where did the energy come from? Coal, coal mining became a profession. It was a dangerous profession, it was unhealthy, but there are still coal mines today. Well, oil has come to become a source of energy. And now here we are, we're entering a new age, a new revolution which is not based on materials, but rather on information. And it's all being, what's the equivalent of oil is data, tremendous amount of data that is being accumulated through the internet and it's data that you need that powers deep learning, labeled data in particular. But there are unsupervised learning algorithms that are also very powerful. If you go to China, there are large companies now who are employing people basically to handle data, to claim the data, to label the data, and prepare the data for machine learning systems. And when I went to China, I would give keynote talks that were streamed to eight million Chinese, this is really scaling up something that's going on here on a much smaller scale. But where is the future? The future is with students and I'm the president of a foundation that runs the annual Neural Information Processing Systems meeting which last year in December in Vancouver, was attended by 14,000 researchers with 6,000 who wanted to come who were on the waiting list. And this is now becoming a very, very powerful force, not just in academics, but also in industry. Anyone with lots of data, all the big high-tech companies are using it to improve their performance in ways that we're just beginning to appreciate. Now NeurIPS has a lot of concerns about ethics in AI and this is a big topic at the meeting, we have speakers talking about privacy and bias. And it is an interesting dialog that's going on and we can continue this in the question period. But here's an example, use case. A company has a ton of data on interviews that they've had with future employees. So they have the data and they also have all the questions and all of their past history and so forth. And they also have the outcome, because they have, what happened to the person? How did they perform? Where are they now? And so using that data, you can train up a deep learning network that is really good at predicting whether a new person coming in is going to be a star employee or a wash-up. Now here's the problem, these deep learning algorithms are biased, why? Well, because they're using information that perhaps would bias against minorities or bias against women or who knows. And any new technology can be used for good and evil and now the question is what do we do about it? Well, here's another way of looking at it. Are humans biased? Of course they're biased, we're all biased. And can we correct that bias in humans? Good luck, the problem is that prejudice is very deep seeded and it's a generational change, it's not gonna happen to an individual, at least not very fast. What about the machine learning? Well, we built the machine learning algorithm, we can look into it, we could figure out where those biases are, we could fix it. And so that's really the trade-off, the trade-off is that yes, the machine learning algorithm will mirror human biases, but unlike humans, it is possible to fix. And so that's an example, one example of many issues that are arising. So I wanna end with a couple of quotes. And this is relevant to the issue of diversity and inclusion as well as ethics. So this is from a website called VentureBeat. For the first time ever, this is in February, researchers who submit papers to NeurIPS, the biggest AI research conference in the world, must now state the potential broader impact of their work on society as well as any financial conflict of interest. And this is something that is going to be part of the review process. We need to know what the impact is gonna be, for better or worse. It's a very difficult to get your paper accepted at this meeting, 20% of the paper's are accepted. And this is an issue that is becoming to the forefront, which is that we want to make sure that people are aware of the impact of their work and what the downsides could be. For example, in China, everybody using face recognition big time, every city, every person is being screened. And people accept it there, but there are issues of privacy. So finally, and then from our website, that NeurIPS is taking seriously questions of diversity, equity and inclusion in our conference. Our efforts are building on several grassroots efforts from the past. Like the women in machine learning. This is a group WiML is a group that has been co-locating with us for the last 15 years and we're very pleased that we have a large number of women on our organizing committee and in our board. But there's other affinity groups including Black in AI, Queer in AI and LatinX in AI. And they have their own workshops and we help support them. And we are working to expand these efforts to make the conference as welcoming as possible to all. Well, that's the end of my story. I hope that you have learned something and I'll be happy to take any of your questions. - Thanks, Terry, that was excellent. Before we get into some specific questions about some ethics issues. It occurred to me that it might be helpful to delineate a little bit more the definitions of just what we're talking about. Good ethics depends on a good understanding of what it is you're looking at. So, you've talked about a number of terms, you provided a hierarchy of artificial intelligence, includes machine learning which includes deep learning. But what wasn't as clear is how reinforcement learning fits into that picture and be more specific about how we should distinguish those different categories. And just as a precursor to what I'm looking for is that you mentioned that reinforcement learning is based on trial and error as opposed to deep learning, which would use a computer program. But in fact all these thing are computer programmed at some level, so could you clarify the distinctions here? - Sure, yes, that the reinforcement learning is part of that middle circle. It's a machine learning algorithm and it was inspired by a classical conditioning in our brains. But it is a different algorithm. All of these are being simulated right now, the learning algorithms are, there's a program written that will do the simulation for you. That's all changing, because it's possible to build hardware, special purpose hardware and so very soon were gonna have, and we already have deep learning chips. Google has something called TensorFlow and tensor processing units and many company startups are building these chips. And neuromorphic engineering, building chips that actually emulate the actual spiking neurons have matured. So, what's the difference, in the case of, say, supervised learning, you need to have labels on images, so that's expensive. You have to have a human being label millions of images. In the case of reinforcement learning, you don't have to label anything, you just give it a goal, say I want to get as high up as possible or I want to get rewarded, as much reward, I need to get food, I wanna maximize my food. And the only feedback that you get, there are no labels, but the only feedback you get is how well you're doing. Are you coming closer to your goal? How far did you go up? How much food did you find? And so it's a very weak form of supervision. In the case of Go, for example, you have to decided many, many, many moves to get to the end and the only feedback you get at the end is whether you win or lose, that is the reinforcing signal. So it's really impressive that you can figure out, it's, which of the moves that you did was responsible for winning, that's the difficult problem that needs to be solved. But on a more general plane, I've mention briefly that supervised learning is the fastest and the most effective way, but there are other forms of deep learning. For example, unsupervised learning, where you don't give it any labels, but what you can do is absorb the statistics of the data so that you have an idea, like clustering, of how different parts of the input fit together with each other. And this works, for example, extremely well with language. Language was one of the parts of the deep learning that I would've never guessed would be so successful when we started out in the 80s. It was considered the pinnacle of symbol processing, rule-based AI, the traditional AI, but now it's amazing. These networks just love language, they're fantastic. They've really made a huge impact. I hope that helped. - Yeah, it does. And it leads to, in terms of this definitional question. So one of the questions that came in mentioned still another approach which is called generative adversarial networks or GANs. And before we take their question, maybe you could say a little bit about what GANs are. - Okay, so I can do better than that. I can show you what a GAN is. A GAN is a generative model which means it's not passive, it's not taking data from the outside, it's generating data. And it sounds supervised in the sense that you just give lots and lots of images. And in this particular example, someone gave it lots of images of celebrities. Pictures of actresses and famous politicians, thousands and thousands of them. And here is what the images look like. These are high resolution images of celebrities. A real person, an actor. This is somebody I recognize. And so here's Farah Fawcett, I recognize one or two of these. But what is it that makes a celebrity a celebrity? You can ask yourself that. You recognize one when you see one, but what is it? And so somehow this GAN figured it out and now it's gonna generate celebrity images of people who do not exist. These were just generated. And again, look there's a problem with the ear, it's not perfect. These are fake people, but these are people who could be celebrities and that's what really makes it a very powerful technology. And I wanna do something which is, I think, this is, for me, what you wanna do now is go into the network and figure out how did it do it, it's called latent space interpolation. And what we're doing, it's like knobs in the middle of the network that we're just moving it through the space of faces and it's morphing from one to the next and it just shows you which faces are close to each other. This is a space, it's a very high dimensional space populated with these images and we're just walking through it. So that is what a GAN is. And now it's being used to generate pictures of indoor cloth patterns, for example, for designing clothes and for designing interiors, interior decoration. This has now become a big industry, it's huge. And this is only a couple of years ago, so this is really moving extremely quickly. One thing you have to understand is that the number of researchers is exploding. The big high-tech companies are hiring 'em by the dozen. We can't train them fast enough, it's really become huge industry. - Excellent, that's was really helpful. And you hit on, I think, the core of this person's question, 'cause you mentioned that you could now create, if your goal was to create images of celebrities, you could create fake celebrities, you could create something that isn't necessarily real, but would fool people into thinking it is real. So the question is what do you think are some of the most important ethical concerns specific to the development and use of GAN? So do you have any thoughts on what worries you? - It's something that is potentially, extremely, and it's not just GANs, it's potentially very dangerous, because if we can no longer trust an image and by the way, with other algorithms, it's possible to take a video of somebody and put literally words in their mouth. In other words, make it look as if they're saying things that they never said, so fake speeches. And if that's true, that if human beings cannot distinguish between a real video of somebody and a fake one, what can you trust? And how could that be used and this is one of the great problems with technology. I said that they can be used for good and evil. And obviously this is not the first time new technology has come along that could be used in the various ways. And so we've adjusted, the society has figured out ways to ferret it out, for example, you may not be able to see the difference, but another AI algorithm could, so if you're not sure about something, you press a button and then screen it, have it screened by an AI. So it's a technical problem. It's solvable and there are people already working on it. And that's one of the nice things about the community is that it's very responsive when one of these issues comes out like bias, there are people who are coming up with AI solutions to try to reduce bias and so it takes time to figure out where the problems are and it takes time to figure out how to solve them. - This one is about the ethics of use of AI which we're getting into a little bit. As you said, it can be used for good or evil, but as in your talk, you talked about the potential for AI to be used for diagnosis. So what world will doctors have if artificial intelligence does the diagnosing? - I think that the image that was just portrayed is that, oh, the doctor is replaced by AI, that's not how it's gonna happen. And my book is all about that, by the way. I wrote the book specifically as an antidote against all the hype in the press. Scaring people that they're gonna lose their job and that we're gonna have robots that are gonna be human-like, no, no, that's not what's gonna happen, at least not right away, not in my lifetime and probably not anyone who's watching this. So let's just take the one example I gave which was dermatology. So it turns out that the best doctors, when you throw pictures at them, they're about 92%, where they're able to accurately diagnose what the lesion is. It's a difficult problem. And it turns out that AI when you train up a deep learning network, it does about 92%. Now here's what gives me some, a little bit of intuition about how this is gonna unfold. Now what you do is, you give the doctor the AI and you combine the two. In other words, the doctor's using the AI to help the doctor. Together, they do 98%. You've gone from 92, which is 8% away from perfect to 98, which is 2%, that's like a factor of four, it's huge. Now why is it, how could that be? Well, it turns out that AI was really good at rare cases that the doctors rarely see, 'cause they may not have seen something like that, so will miss it. But the doctor is maybe better at the subtle differences between images that are in between benign and malignant. They've figured out where to draw the boundary better than the AI. So together they're a great team. They're gonna do better than either alone. And I think this where the future lies, it's gonna be a partnership. And in my book, my mantra is that AI will make you smarter. And I'm gonna give you one more example. Let's look at chess, back in 1996, Deep Blue, IBM, built a chess playing machine that beat Garry Kasparov, which is at the time, the reigning chess champion. Now it was thought that all this is gonna, humans have no chance anymore, they're not gonna wanna play chess, 'cause they can't beat the machine. And indeed, the machines have gotten better and better and better, but so have humans and why have humans gotten better? Because they were playing the machine. If you wanna play tennis, you play somebody who's better than you are, you might get better. Now something that nobody would've predicted has happened which is the reigning chess world champion is Magnus Carlsen, Magnus Carlsen who is a Norwegian and he came from a small town in Norway. Now traditionally, if you wanted to become a grandmaster and you wanted to become world champion, you went to a chess club in the big city, in New York, in Moscow, because you had to play people better than you, the grandmasters were at these chess clubs. Well, Magnus played against a chess program on his computer and got to be the world champion. Now that means that the AI has actually democratized chess, it means it doesn't matter where you are, if you have the talent for it, you can become as good as you can. So I think that's gonna happen more and more. - So when someone does that, are they becoming an example themselves of reinforcement learning? - Well, we all are examples. I mean, that runs you, with your life. I mean, see, the thing about reinforcement learning is that you have to have something called a loss function which is, you have to tell the machine what it is you're trying to optimize. You're trying to get better at what? If it's go or if it's survival. And nature has given us a fantastic set of brain circuits in the hypothalamus especially which are essential for providing us with enough food and energy for care of our bodies so that we're not injured. Pain is very important, because I you don't have pain, you'll lose the sense that you need, of danger, and we are designed to be survivors and that's because we have these cost functions built in. We come with that over the process of evolution, otherwise we wouldn't be here. - Yeah, so getting back to the core of this question about what will happen to the doctors. So there's a pretty likely scenario which is that, as you've laid it out, we will probably do better on average than just the doctors themselves. And so I'm going to accept that premise, that's where we we'll be moving with diagnosis. But it's also pretty likely that the way human beings are, including the doctors, that if you see that result from the AI which you will come to rely on, you might not look somewhere else, you might, not always, but sometimes, be tendered to go with the direction the AI result takes you. And if that's the case, then I find it quite plausible that there will be instances where a physician will not see something that they would have seen if they weren't relying on and using the AI. And I know that might seem a little bit farfetched, but a really good example of this is with the idea of autonomous to semi-autonomous cars, that the chances are that we're going to decrease the number of fatalities. But one can imagine where if a human being was their at a particular case, that we wouldn't have had that fatality even though on average we have more. So any thoughts on how we either deal with society to prepare people for accepting those losses or to protect against them in the first place? - That's a tough question and of course, who's making the decision? So let's put it this way, and I actually think this is the wrong comparison, but it's the equivalent of the self-driving car. So you have a choice, you can go to a doctor and get the diagnosis of the doctor by the best doctor you can find and you know what their success rate is and then you go to the AI and the AI now has a higher success rate. And they're telling you two different things. Which would you choose? It's true that, any rational person would say, I'd rather take my chances with whatever source of information is higher likelihood of surviving. But on the other hand, people go to doctors for a lot of different reasons. I mean, it's not just for a diagnosis. It's for advice, it's for help, for empathy. And I don't see that coming from the AI. So the reality is what we're gonna do is go to both for different reasons and it's always the case, you want a second opinion. I don't think there's anything wrong with going to an AI for another opinion. And here's what I think the reality is, that if we can help improve the performance of all doctors, there's some kind of a curve of, here's the average doctor in the middle and then here's a long curve where we have the best doctor, a few doctors who are the world's best. If we could take this curve and move it over toward the best doctor so that the average doctors are good as the best doctors today, wow, that would be a great improvement. So I think that's what we're really trying to do. - Yeah, no, that sounds like a good goal. So these kinds of questions I just asked you are ones that could be seen as potential barriers to the work that that's being done. And so somebody again asked an interesting question along those lines, is the development of artificial intelligence hindered or slowed by concerns of ethical issues or fears of what might happen, like job less or misuse of technology or is it simply strengthening the enterprise? People are doing a better job of what they're working on? - All right, well, I can tell you by experience, which is helping to run this very big conference which by the way has grown just in the last five years. It started out with just a few thousand people and now it's going exponentially that the typical now, machine learner, is very, very aware of these issues of fairness, of danger and it's, for example, there's a lot concern about the military use of AI. And how is that gonna play out? Vladimir Putin was at a meeting, a big conference, he gave a big keynote talk at the beginning and said that the nation that controls AI is gonna control the world. So that's pretty scary. But amongst the academics and also the AI people working for big companies, they're very, very concerned and aware of the uses that are going to be questionable or potentially dangerous, that are probably things that we're not even aware of today, that are unintended consequences. But we can look back in history and what we see is that once the unintended consequence has gotten identified, then there's a way to regulate it, there's a way to prevent it from happening. When the atomic bomb was invented, everyone was really concerned that this is gonna be a nuclear holocaust, it's gonna end all human life or all life on the planet, my God, this was a existential threat. But here we are, we've managed to get through it. We managed to control our worst instincts and it's because we need to survive, we understand that. And along the way, there are gonna be mistakes, there's no doubt about it, but I think that as long as we're all working together, the people who are creating this technology, the engineers, the ones who are using it, the feedback we get from society, we're listening. We want to understand what the issues are and we can help. And that's the thing is that we built this technology, we can fix it. If there's a problem with it, it's something we can work on. And I wanna be really clear here that I have no crystal ball, I can't predict the future, neither can you. Human beings are incredibly bad at imagining the future, I'll give you an example that the older people in the crowd will be able to appreciate. So the internet hasn't always been around when I grew up, there was no internet. There were just computers, they weren't connected together the way they are today. And in the 90s, actually, when I started in the 80s, we used the ARPANET to communicate with Geoff Hinton and others at Carnegie Mellon, researchers, 'cause it was only in a few universities. And in fact I helped bring the ARPANET to Johns Hopkins when I arrived in the 1990s, so it was very incipient back then. Now it went commercial in the 90s. And here's the question, Mike, I'm gonna put this to you, you remember that, right? - Oh, definitely. (laughs) - Okay, could you have imagined the impact that the internet was gonna have on every aspect, including right now that we're having this Zoom meeting? Or it's gonna effect entertainment, it's gonna effect social media, it's gonna effect political elections. I mean, I don't think anybody had any clue. This is like we're living in a new world and humans are not capable of imagining what the future is gonna be like when you introduce something like this, some powerful new technology. - I'm gonna assume that was somewhat of a rhetorical question, but I think the fact is that, I mean, in February, I could not have imagined that I will be talking to you on Zoom this evening instead of being live at the Fleet Science Center where we normally meet. - That's a good example. - And so yes, I mean, and I think part of what you're saying behind this is that there are so many, sometimes, incredibly minor things that could happen that could explode in ways that we can't imagine, so that's why it's so difficult to predict the future. Who would've thought that a virus could transform the planet the way it has, a single virus. Well, obviously evolving. - In a couple of weeks, I mean, the shocking thing is how fast it happened and the uncertainty about where it's heading. - I wanna come back a bit to the jobs question, because I think that's a really intriguing one. I was interested in the idea you said, for example, we have all these people who drive cars and trucks now, they would be out of a job if we had these autonomous vehicles. And this is gonna generate a new industry. We have to clean the data that we would use to be training the algorithms and so on. And I'm just going to note that as you described those data cleaning jobs, I thought those sound perfect for artificial intelligence. I mean, why wouldn't we be turning to artificial intelligence for that as well. I mean, is this gonna be everything, it's turtles all the way down, if you know the reference. - Right, yeah, that was, let's see, this was Bertrand Russel. - Bertrand Russel, I think, yes. - Who said that after a talk that he gave, some lady came up to him and had a theory that we're all living on the back of a turtle. And Bertrand Russel smiled and said, "And what is the turtle standing on?" And the lady says, "You can't get me, Mr. Russel, "it's turtles all the way down." (laughs) - Yep. (laughs) So anyway, so people are welcome to look that up after tonight's program. - And it's wonderful story, but the reality is that it is all the way down. This is life. There are levels within levels within levels and by the way, this is also the way the internet works. You're not aware of what's going on, all the bits flying around, there's packet switching, but there have to be protocols, protocols and there are collisions and the brain works just like that too. There's like 10 orders of magnitude of spacial scale that you can go down to the individual molecules and all the way up to very complex behavioral systems. And the same thing's gonna happen in AI in the sense that we're gonna have AI solving a lot of small tasks and then right now we need humans to feed AI, and by the way, I should have pointed out, I had two pictures, one of a coal miner and one of a data miner sitting there in front the, in China, sitting in front of the terminals. And in a sense, they have the same job, right? In a sense, they're working to get some value out of either a coal mine or a big data stream. And look at the value of those jobs in terms of the coal miners isn't getting paid as much as, it's not as healthy a job and so forth. So I think it's a fair trade, actually. If you're looking at switching from one job to the next, but the trouble is that right now, AI, because the labeled data allows you to learn much faster and if you're going into a new area where you don't have labeled data, you've gotta get it if you want it to run fast. But the future of AI is actually gonna go in a different direction and it's already happening. There's something called self-supervised. And GANs are an example of that. You don't have to label anything except the starting, what area are you interested in? Are you interested faces? Are you interested in houses? Are you interested in flowers, I mean, whatever it is. You just have to gather a lot of images like that and it will figure out what the differences and the similarities are. It will create new flowers and things, patterns and things. So that's the future, is unsupervised so that there's no human involved and that's the other extreme or self-supervised and also reinforcement learning is also very powerful when you combine it. Oh, that's the other thing, is to keep in mind that the human brain is very adaptable, adjustable and has many different learning algorithms that are operating together in parallel and many, many memory systems. And for example, the motor system has a very different set of brain areas that is used to learn how to play tennis and the part of the brain that does visual logic recognition is specialized for that. And so we have all these different ways of solving, in some cases, the same problem. And so having that diversity is really very powerful and right now in AI things are kind of focused. We've put tremendous amount of people, talent, computer power into supervised deep learning which is one very small part of AI. And there's so much more that is gonna be done and integrated with the deep learning. But the reason why deep learning actually, in my view, and this is something, I wrote a article in Proceedings of the National Academy of Sciences and you can look it up, it's online. The reason why I think what's been done recently is so powerful, it provides a foundation for AI. See, before you did symbol processing, but how do you connect the symbol to the real world? How do you know if there's a cup in an image? You don't that. You have a symbol for a cup, but it has no structure. But now we can create very deep representations for cups in general. So we have a symbolic representation, it's a huge vector with billions of dimensions, very high dimensional space and that's how we're gonna make a way to go from the real world, which is very high dimensional and very complex and varied and so forth to the simplified world, that conceptual level, where you just not simplify it, but you take the essence of something. And that's what's really the highest level, in some ways, of processing, which AI tried to go for without putting the foundation in. So now have the foundation and what's nice about it is that it's a foundation where we have a language, it's all done with the same material, whether you're solving a problem with speech recognition or a vision problem, it's the same kind of network, it's the same kind of learning algorithm and that means that you're trading, it used to be the case you had to write different programs for each of those two different problems or if you have 100 problems, you have 100 different programs. You have domain now which each engineer is specialized for one or the other, not all of them. But with learning, as long as you have the data, enough computation, you can make progress in all of those problems. And that's going on all over the world, I mean, and the place that the most progress has been made, of all places, is in science. And especially in neuroscience, 'cause we're collecting huge data sets from recordings from the brain with 10,000, 100,000 neurons at the same time and before, it was one at a time. And so we're just making, and how do you analyze that? You can't analyze it one at a time, you gotta analyze it with machine learning. So, the very tools and techniques that were inspired by the brain are now being used to understand how the brain works. And that's amplifying, that's speeding things up. And that's happening in every area of science. It's really truly astonishing. - One of the premises that you came to in your talk, and it's a common trope or a common issue for new technologies or any technology and that's that you can do things that might be good and you can do things that would be bad with that technology. And what's so interesting about some of these things that you've described are that it's so dramatic what you can do. I mean, who would've thought, why would you even ask the question, what does a celebrity look like, for example. But somebody did. And they've developed pictures of celebrities. But people have done some things that are more worrisome than being able to say, oh, that's a celebrity and that's not, such as try to look at images and predict criminality. So the question is, do you have any thoughts on the recent project from Harrisburg University that claims to predict criminality from images of faces? Are you concerned about phrenology and other racist pseudoscience cropping up in the field of artificial intelligence? - Well, that's cropped up before. You don't need AI to have racists. (laughs) And almost, I'm not familiar with that particular study, but I would be very weary to trust it in the following sense, that we know, and again, that your environment has a huge impact on you regardless of what you look like, right? (Terry laughing) It's true that I look like people in my family, but the same people from another family that grew up under conditions that were, badly treated when they were a child and had serious malnutrition, I mean, the very same face could turn into a horrible killer. So that tells you immediately that if they claim that they can do it, it's probably under very, very narrow conditions when they're looking at a small data set in one culture under conditions where it's not really controlled very well. Like I said, I haven't read the article, but I would be very cautious to. - Well, the premise is tricky and it makes me wonder and this may be the last question we can cover, but going off on that issue is, if it is quite plausible that the court system we have is biased in various ways, I think most of us would believe that. And one of those ways, independent of somebody's economic background, even if of their race, might be that certain faces are going to cause people to think this person is more likely to be a criminal than not, which would mean those people would be overrepresented in the population you define as criminal because of the way their face looks rather than because they're actually a criminal. - I'm very, very certain that this is very cultural and that people are very good and it's like, learning to distinguish between males and female faces, right? That's because we're exposed to so many male and female faces and if we happen to be exposed to certain criminal faces, then we're gonna think that those faces are always associated with criminality and that's just because of associations we've made. By the way, there's a fantastic book that's out by Pat Churchland who's a former co-author of mine on conscience. And she is able to really build a case. This is true, not just for our prejudices and judgements, but also all of morality is probably based on experience and this comes from very deep biological roots. It's a fantastic book. - It's my pleasure to thank you for a really stimulating talking generating a lot of good questions and I hope some answers for our audience, so thank you very much for that. - Well, you're very welcome and thanks for giving me this opportunity to talk to such an audience. (uplifting music) (melancholy music) (soft chiming) 