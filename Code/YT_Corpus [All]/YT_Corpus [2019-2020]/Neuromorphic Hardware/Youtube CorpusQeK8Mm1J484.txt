 Hi, my name is Alex Jones. I'm a PhD student here in the MIND Lab at the University of Cincinnati, and today I'm going to talk to you about why we want to pursue bio-inspired computing. So for a long time computers have been very good at crunching numbers. They've been very good at adding, multiplying, and dividing. However, computers are a lot worse at performing more complex tasks such as pattern recognition. These are activities that living organisms and humans alike can perform easily with almost seemingly no latency in between stimulus input and acting. This is, for example, when something is thrown at you and you have to react to what it is to see if you need to catch it or avoid it. You can tell what's friend or foe. You can communicate seamlessly with one another through writing or speaking like I am to you right now. So it comes down to what actually allows people to perform these tasks effortlessly while computers struggle to perform them, and in order to do that we have to look into what exactly allows the human brain to think. The human brain is comprised of a large array of neurons and synapses. Neurons are going to be the cell within the brain that performs what are called action potentials, these are effectively firing signals that will fire when given enough input to the neuron. When a neuron fires it's going to send that pulse that it emits through its axon to other what are called synapses that are connected to other neurons within the brain. These synapses can have varying strengths in order to vary the connections between neurons to create variants within the network to form tasks. This concept of thinking about why are computers bad at performing pattern recognition tasks and associating things with one another, while humans and living organisms are good at it, started back in the 1940s when people started thinking about this concept in terms of how can we, at a theoretical level, develop a network of neurons and synapses to be applied to the realm of computation. With that, the initial formal definition of a neural network was developed by McCulloch and Pitt's in 1943. Later on in that decade, a man by the name of Donald Hebb came up with a concept that was called Hebbian learning, which coined the famous phrase, "Neurons that fire together wire together." This basically means that when you see or observe two things happening simultaneously those two things are going to be associated with one another in the brain. This is very similar, and can draw association to, Ivan Pavlov's famous dog experiment, where he would give a dog a treat and every single time he gave the dog a treat he rang a bell, and after a while he could ring the bell without giving the dog a treat and the dog would automatically salivate because it was anticipating the treat. It associated the treat and the bell as one thing. So to develop these theoretical artificial neural networks they had to define what exactly a neuron was within these networks, this was defined as something called a perceptron which was simply just a neuron like device that would act as a summation of all signals coming in to the neuron itself through its synaptic connections. That signal strength coming into it would determine its output signal strength according to some mathematical function. So you can take these perceptrons and you can put them together and connect them into what is called an artificial neural network. Now with an artificial neural network the neurons are usually organized in an order called layers. With layers you typically divide them into an input layer, a hidden layer, and an output layer. The input and hidden layers, their job is to encode the information that comes into the network from external inputs such as cameras or an external hard drive or an external interfacing GPU or something like that, and it'll be able to encode that data and get all of that fine granular detail that comes in to all that data over time and store it in its synaptic connections in the input and hidden layers. Finally, the information gets analyzed, what was called the output layer of the network, this is usually multiple neurons, fewer than there are in the input and hidden layers, and with that it's able to determine what activity it's seeing or what object it's observing. Now, an example of how this would exactly work. Let's say for example we have a neural network that has four output neurons, or perceptrons if you will, in its output layer, and these four neurons represent four animals: a dog, a cat, a fish, and a bird. Now, what we can do is we can feed our neural network images through the input and hidden layers, image or camera data that show at various images of dogs, cats, fish, and birds. Now the key thing to take note here is that this network is going to learn exactly like a human would whenever they're given a new task or objective. When it's initially shown the images inside of the network it's not gonna know what to do. It's gonna start randomly guessing that fish are birds and dogs are cats. However, over time, after it's been told what a cat is and what a dog is, or can even learn by itself in certain cases, the network will start to figure out all the fine details that make a cat a cat, a dog a dog, a fish a fish, and a bird a bird. After a while it'll be able to just look at an image of a dog, a cat, a fish, or a bird and simply without any further instruction is able to discern which are cats, which are dogs, which are fish, and which are birds with high accuracy just like any human would be able to do that with any task it's given. Now let's get into the concept of Von Neumann architecture. All Von Neumann architecture states is that memory, where data is stored, and processing, where data is analyzed, within a computer exists in two separate places. Then data transfer happens in between the two locations in order to accomplish tasks in the computer. We can take this artificial neural network and put it into one of these systems, however processing times in a lot of modern computers is slow for artificial neural networks. This is because synaptic values, the numbers associated with synapses and their strengths, have to be passed back and forth between memory and processing constantly while the network is being analyzed. This really slows down processing time on many modern computers. So this is where we bring in the concept of neuromorphic computing. What neuromorphic computing attempts to tackle is it attempts to directly map an artificial neural network and it's theoretical design onto a specifically designed piece of hardware for a neural network. Instead of having to take memory and processing and pass in between two separate locations, neuromorphic computing wishes to merge the locations of processing and memory into one space. This will decrease processing time and also consume less power in the long run. 