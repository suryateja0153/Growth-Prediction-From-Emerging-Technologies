 Hi. This is Steve Michelotti of the Azure Government Engineering team. I'm joined here today by Vishwas Lele, CTO of Applied Information Sciences. Welcome, Vishwas.  Thank you, Steve. Thank you for having me.  Today, we're going to talk about Migrating and Modernizing to Azure Government using Kubernetes. So we hear this term a lot, migrating, like I need to migrate my workloads Azure government, and there's different motivations for this. What are some of the motivations you're seeing out there with your customers?  So Steve, I thought this was where we're going to start, and this is an important way to motivate this discussion here. So I have a few bullets here. We're seeing a lot of customers wanting to migrate to the Cloud, and I've listed here on the slide. You can see some of the key reasons, and first and foremost, that I see often is the time to value. They are under a lot of pressure from their customers to produce new functionality to enhance these application to meet the business needs. There's time to value argument about taking the requirements and showing that into production, that time needs to be shorter and shorter. That's the pressure. Of course, they are not able to achieve the time to value that they have in mind, because they've collected a lot of technical debt, the total cost of ownership is high, they're still worried about patching the machines, making sure the hot fixes are there, making sure their applications are highly available. Of course, in some cases, and this is not uncommon, but running on a platform that is outside or very quickly going to be outside the support cycle, if you will, and all of these together are sought of combining into, I'm a CIO, I am running out of capacity in my current data center, do I go to a new data center, or have been forced to evacuate my current data center? These are some of the common motivations that we are seeing in people migrating and modernizing their applications to the Cloud.  Absolutely, and it's one of those situations where it's one thing if you have a brand new Greenfield app but when you get to some of these older legacy apps you're talking about, it becomes more complex.  It becomes more complex.  So we hear different approaches for doing this modernization. You hear people throw out these terms like lift-and-shift, they're modernized. So why don't you talk a little bit about, what are some of the traditional approaches, and then how does that compare with what we're talking about here with modernizing with Kubernetes?  Sure, sure. So let me just talk about the approaches that we see often in a discussion like this. So you can see in the slide here that the first approach commonly referred to as lift-and-shift. You're digging out of existing application, and you are essentially, most often than not, you're taking your VMs using things like site recovery and moving that application to the Cloud. I think everybody understands this. The other approach, of course, is the refactor part, where you can opportunistically take parts of your application and PaaS enable them. So if you have a database, maybe you can go to Azure SQL database. If you've have app application, maybe you can move it to App Service. So that's the refactoring approach. Then, of course, if you've decided that this is a mission critical application, and you have to constantly keep changing this application and you're seeing more requirements, maybe it is time for you to reimagine that application and start taking advantage of Cloud-native technologies like Serverless and Kubernetes and things like that. So those are the common approaches we see. As you said, for our discussion today, we're going to talk about an approach which is commonly referred to as re-platform or also referred to as lift-and-reshape. What I mean by that specifically is, you're still lifting that application, so the lifting part is the same, but you're essentially reshaping it. By reshaping I mean, you are containerizing this application. So you're shaping it in the form of a container and then moving that application to the Cloud. So this is the other approach that we want to talk about. These are some of the common approaches. People look at the slide and say, if this is a 4R, and I have heard somebody talk about a 5R model, and what I have not shown here, it is equally important, is you may want to retire an application completely and maybe go to a SaaS or a low code environment like Power Apps. We have not shot it yet, but that's important to consider as well.  Okay, makes sense. So presumably, there's pros and cons of each of these approach. So talk a little bit more in detail about that and where this re-platform in particular fits in.  Yeah. So that's a great point. Let just go into some of the details here. So I will quickly compare the approaches that we talked about. So the first approach as I said here is the lift-and-shift approach. In this case, you are not making any code changes. You're taking existing code, moving it as is. The operational cost remain high because you have not really changed the application. The Cloud costs are high as well, because essentially you are paying for the VMs even though your CPU utilization maybe five or 10 percent. You are not able to leverage the Cloud-native capabilities because you've essentially moved your application, your DevOps maturity may be low. It depends on how you're doing DevOps today. The scalability is all vertical. So if you want to scale the application, you will have to go buy bigger machines. That's it. The code structure is essentially unchanged. The time to value that we talked about in the previous slide remains high, because you still have to go through your processes. One common term that we are seeing in the Cloud often, and it is really an important factor, and if you're successful in the Cloud is called the Site Reliability Engineering. The Site Reliability Engineering maturity is still low because you're not taking advantage of the Cloud instrumentation to make the applications more available. So that's the lift-and-shift part. Let's just very quickly do the same columns for refactor. I'll just highlight the ones that are impactful here. There may be some code changes because you are going from the SQL Server instance, perhaps to Azure SQL Database, and of course, you can take advantage of managed sensors to reduce the code changes there. Operational costs are reduced, because for some parts, you're taking advantage of what the Cloud provider like Azure is providing. Cloud costs are lower, because you're not paying for the entire VM. You're only paying for that instance of the service. The code change is slightly there, because if you are moving to App Service, then you have to change it, at least the configuration files and what have you. So that's the refactor part.  So in this case, some advantages of lift-and-shift, although lift-and-shift have the advantage of, I don't have to change any code.  I don't have to change any code.  Make sense.  Even though the code change maybe less, when you look at Azure SQL database, it is largely the same as your SQL Server. But where the real impact of this approach comes in is in the testing aspects.  All right.  When you go into the Azure SQL database, do you have the right logic to retry and you're handling the transient errors, have you tested every single scenario. So the testing cost is quite high and has to be considered. The last thing that I want to talk about as part of the reimagine is, here the code changes are great. You are essentially rewriting the application. The Cloud costs have a significant impact here, because you're not paying for a VM. In fact, you are paying for a very interesting model called the dynamic cost where you're only paying for the time the code is getting executed, what we call the serverless computing model. So that's really high. You're taking advantages of the Cloud-native capabilities. You have horizontal scalability, which is where you want to be. Now you really begin to hone in on the time to value argument because Azure Gov is adding new capabilities all the time, and now I can tap into those capabilities. I have aligned myself in a position that I can start taking advantage of those capabilities. Of course, I can do things to improve my SRE maturity. Cosmos DB, for example, gives me a geo-replication that's built-in. My Site Reliability Engineering maturity is much higher with services that are natively enabled for geo-replicated scenario.  Right. So this is another spectrum, lots of advantages technologically, much more innovative, you're getting these benefits of the Cloud, costs are less but, of course, everything has a downside because now you're rewriting your app.  You're rewriting app. If you superimpose over lift-and-reshape approach, which is the focus of our presentation here, on this diagram here, and it's interesting to compare and contrast some things. First and foremost, the code is not changing in this approach. You are essentially containerizing this application. We will talk about it more. Your operational costs can be lower, because you're not paying for the entire VM, you're paying for the cluster. But you have this ability of more densely packing that cluster. So you can get higher CPU utilization.  You can start to take advantage of some Cloud native capabilities. Your SRE maturity is higher because if your container dies for some reason, the orchestrator as a service now comes in and starts your application again. So you have not done anything but you are still getting the advantage of SRE maturity here.  Very interesting. So two quick points that I think come out of this I think are hugely important. The first one that you mentioned was containerizing your app. A lot of times when people think that Kubernetes, they think. "Okay. I have to modernize and do all these different microservices all over the place". But no, you're saying. "Take your existing legacy application which might be a monolith and just put the whole thing in a container." The other two-part question.  Yes.  So the other interesting part of that is that you're saying that even this legacy app, this model with legacy app can suddenly start taking advantage of these native Cloud capabilities like self-healing and these sort of things.  That's exactly right. I was smiling because that's a very common question that people often think of Kubernetes as a microservices environment, and then when we are talking about this approach we are taking core screen pieces of our application and then hosting them in Kubernetes. So you're right, we don't have very small images of our architecture, is not microservices enabled, and you're not taking advantages of all the things you can potentially take ultimately. But at the same time even this intermediate step or a first step, is an important step in that journey. You're taking your applications, essentially taking these coarse-grained applications converting an immutable image or Docker image, and then taking advantage of Kubernetes and we will talk about in a moment. In this case, we're using the orchestrator is Kubernetes and we are using Kubernetes as a service which is what Azure Kubernetes service is all about, and all of the control plane is managed by Azure Gov. I don't have to necessarily worry about if my orchestrator goes down. Even the patching is done for me, so the underlying OS patching is done for me, so there are incremental benefits there.  All right, great. So it was also a good time to jump into a demo?  Yes, of course. We have an application here for you Steve that I want to talk about, and many users or viewers of this video will recognize the music store application for many, many years ago. Probably came out in 2010 MVC application, a standard music store application. As we were preparing for this video is saying. "Okay. We're going to show this demo of converting this music store application, containerizing it, and running on Kubernetes, and this question kept coming back to me that people will look at this and say, "Hey, this is a very simple ASP application, ASP.NET application." I would expect it to be converted into a container quickly, but my legacy application does not like that, my legacy application is far more challenging. So is it okay. In order to make our demo more realistic, what we did was we looked at the container forums and saw the kinds of problems you are running into, and deliberately took some of the problems from those forums and injected those problems into this music stored application. So just to quickly show you the music store application is based on ASP.NET MVC but we went and injected web forms just to show that you might have this, injected WCF, injected a P-invoke, some people are always worried about that, that this is a container, can I make a low-level calls, so injected that. Maybe a file watcher capability which is often a concern. I'm looking for an event, and if I'm running in a container, can I get that event in a timely manner. So they injected these challenges deliberately onto the music store application and then convert it over to Kubernetes.  Okay. Very interesting. So it wasn't like you just let's go about pick a bunch of random things. These are the specific challenges that you were seeing people in the forums actually having when containerizing, let's say legacy Windows.  This is my view of the challenges and I'm sure there are other challenges and this is a journey, you should continue to collaborate on this but these are some of the things that surfaced for me and I picked those that's why.  All right.  So let's take a look at, Steve, if that's okay, we'll let's look at the architecture of this application and then we will show you some code here as well. So here's the before and after architecture. The before architecture is quite easy to understand, it is running in an on-premises environment, maybe some hypervisor, ASP.NET application, and running SQL Server, quite easy to understand. Let's look on the right-hand side of the screen, this is where things get interesting. So first and foremost, we are going to take the application convert that into a bunch of container images. So to illustrate that we have essentially broken this image into multiple container images, we took the that portion of the application, convert into a container image, we took the Windows service portion of the code, converted that into a container image. All of those container images could be stored in any kind of container registry. I just happened to put it in Docker hub, that's where I'm going to be picking it up from. Then I created an AKS cluster, and they guess cluster essentially is where we go and start these containers or ports as they call them. Then you'll probably be curious to see that I also have something called the Azure container instances in this picture, and there's a very specific reason for that. Today, Azure Kubernetes service does not support Windows based containers.  That's because today Kubernetes doesn't support Windows.  That is true, and in fact there is an upstream version where Windows container support has been added. So you can see, you can expect that to come to AKS shortly. But in order to get around that, what we are using is a container instance project which is a virtual cubelet. So you can still go to your AKS cluster and ask for a container. That container just happens to be spawned inside the container instance service. So you can see here there are multiple Windows containers running in container instances. That's essentially the architecture. For the database portion, I could have done one of many things, I chose to do something simple, I could have just run SQL Server on a Linux which is a complete Docker image. In this case, since the database was simple enough, I just converted it over to Azure SQL Database.  All right. Sounds good.  Okay. So this architecture in mind I'm going to come out of the presentation and just go into essentially a virtual machine, there I have a bunch of things set up here. So let's just go over to the virtual machine here. The first thing I want to show you is the code. So I've taken the Visual 2010 code converted it over, and then added the projects that I was talking about.  I see some WCF bindings there?  You can see some WCF binding CS, and in fact, you can see that this is the music store application right here. There's this WCF service. The details are not that important at a high level. you can understand that the music store application, the VI injected WCF was. In the music store application when you generate an order, it will call the WCF service, WCF services essentially write out a request to the database. So that's what's happening and there's a Windows service here as well. Then finally, there's a printing service which uses the pinball capability. So that's essentially the code. So you can see that there are four bubbles here, and you can think of these four bubbles as translating into Windows container images. So that's at a high level what this code structure looks like.  So this was the first part of adding these challenges, if you will, to the application. The next part was building these projects, getting all the binaries and the next part is now creating Docker images and that's where things get interesting. So I want to call that out. Let's just go over to Visual Studio Code and then let's look at some of the Docker files here and see some of the things that are interesting. So I want to show you a very simple Docker file here. So what is interesting here is, when you are creating a Docker file, you have to start with a base file and we are starting off with base file right here. This is something that the Microsoft Teams have provided. We are starting with a base image, all of the ASP.NET binaries are there. I didn't have to configure any of those. Essentially, I copied all the project binaries at this portion and what is interesting about this. This is something that the viewers should look at, which is, after you've copied the files, the kinds of challenges that you run into, a permission challenge, essentially. So you can see the last command here is, I'm using the NTFS permissions and granting NT system authority, certain permissions that I met.  Okay. So this isn't just like ASP.NET Core, this is actual traditional ASP at that framework right on.NET Framework on Windows. Okay.  Absolutely. This is.NET Framework full with all the dependencies. We essentially took all of our binaries and moved it to the container image and then we are assigning certain number of permissions.  Right.  So that's one. I just want to, if you don't mind, I want to very quickly also show you one other Docker files and then we will be off to showing you a quick demo here. In this Docker file, notice here that I am starting with a WCF base image. So all the WCF's things are set up for me automatically and the only other interesting part in this Docker file is because this is a Windows service, I'm having to call and install Util command as part of my image creation to install that Windows Service. So when this Docker image comes up, that Windows service will automatically be installed for you.  So these are actually really standard Docker files of a couple command line things you have to make sure you run?  Yes.  But other than that, very standard Docker files.  That is true. These are the kinds of things that you have to think about carefully when moving the application, but as you can see, this is not hard.  Right.  You just have to figure out what permissions you need, what services you need and making sure those are executed in the right order when creating a Docker image. So we have the Docker images ready. The next thing we want to do is setup over AKS cluster, right? So let's just go ahead and show you the cluster here. So right now, I have a cluster set up. Let me just go over to the cluster here. This is my monolith demo cluster right here. So this is the cluster that I created and this is a separate resource group. Let me go back to the dashboard. The other resource group that you see here is on the screen right here. So a way to think about it is your AKS cluster is broken up into two resource groups: the resource group that's managed by Microsoft, the control plane, and an infrastructure resource group that all your resources are. So here's where all my VMs and clusters are located and this is the place where we will deploy our Windows containers that we talked about and get our application running.  Okay. Cool. I feel obligated to point out to the astute observer if they notice we're running a regular Azure instead of Azure government, I'll speak from the perspective of the Azure Government Engineering team. We will have AKS in Azure Government very soon which is why we are wanting to show this demo here in this environment, but depending on when you're viewing this video, we may already have AKS in Azure Government.  That is true.  It depends on the time.  It depends on the time. So to keep things in the logical sequence, we build the application, we created the container images, we created the cluster and now it's time to go and look at the cluster itself. So let's go ahead and do that. So I'm going to go back into this. I'm going to go back to the PowerShell Window and because you are spinning up these container images inside the container instance, it can take two or three minutes or four minutes to get it up and running. We didn't want to wait for that, so I started these container images, if you will. The first thing I want to do is, I just want to show you all of the pods and if you're new to Kubernetes, I should just throw out this quick definition pod is one or more containers essentially.  Move your down just an inch there so it's not blocked.  Yeah. So let's just move this down here. These are all of the containers that are running and it's worth explaining some things here. So this is my first pod. This is our ASP.NET application. This is the second board, which is the WCF service and I don't want to clutter this picture, but you get the idea that I have four pods running. So remember our application was four projects. Each project got converted into a container image. Each container is manifesting itself as a pod here. The one thing I do want to call out is the last pod and this requires some explanation. You can see this is a virtual cubelet. So to the AKS cluster, it just appears that ACI instance just appears as another node. You don't have a physical VM or a VM as part of the cluster, but there's a virtual cubelet and this is a very interesting project where you can say, "Hey, I want to create a Windows Image," and then they will route it to the ACI automatically, if you will.  Right. If you have a legacy app that's maybe written in Node or Java, already runs on Linux, even this part you don't need. This is truly just showing the whole way where if you haven't legacy Windows and then it's needed.  Exactly right. In fact, what I want to do is, there's a very simple Cube CTL command which you can get as the details about one of the pods. Let's just do that. Let's just go out of this. So let's just describe this pod here. You will see that the screen is slightly busy. So I'm going to just explain this to you here. Don't worry about a lot of stuff on the screen, but the most important part of that I wanted to point out is, remember that we are looking at the details related to the ASP.NET pod and notice here that there's something interesting going on here is, we are telling Kubernetes that I have this pod. When you schedule this pod, make sure you schedule it on the ACI instance. So we are saying, "Hey, the node selected happens to be a virtual cubelet." So that's what's happening. Our pods are running. At this point, Steve, we should be good to go over to the browser and exercise our application. Would you like to go see that? Okay. So let's just go over to the browser. I will start out with the non-containerized version of the application.  The beautiful music store app.  The beautiful music store app. This is what you would expect. I can go create an album but notice here that I'm running on localhost 81 at this point. Of course, we don't want to do this. We want to go back and show you the other application here. Let me move this out of the way here. This is the application right here, which is running inside Kubernetes. So you can see here the IP address. This is the load balancer IP address that the Kubernetes cluster assigned us. Let's just take a look at this application. I'm going to go to add to the cart, check it out and select the John Doe prefill, and I don't want to worry about credit card in this recording. So I'm going to give myself a free code. Submit this order, and you can see that we were able to do this and if you are wondering, "Hey, you didn't show me that form page." Let me also bring up, this is the VAT form page right here. This is the ugly, my rendering of some of the tracking details. In fact, you can come in here and also the printing of the receipt for an order is done with the Pinvoke capability, and that's being done inside of Windows Service container. The last thing I would like to show you here very quickly is the encryption part that we talked about. So you can come in and let's just, for the purpose of this, just say AzureGov, and I can create this cookie and if I refresh it, I'm able to go back, find Music Store 3 and review the data. So again this is not very interesting for your viewers. But the reason I showed it was important things, like this is an HTTP Module encrypting the cookie works as you would expect, and we will not take up the time to run the next set of demos, but I'll just point out that in this case, the logging library happens to be log4net. That's fine, and that works just fine here as well. The last thing I want to also call out was, in this case, they're using not a Redis cache instance but a Memcached. We didn't show that Docker file, but essentially once the image got created, we set up a scheduled task to run Memcachd.exe as part of the container image. So essentially all of those capability including the challenges just work here as part of this.  So really is the price of admission really is just containerizing your app.  Containerizing your app, exactly. In fact, we can go back to the slides here. Just want to summarize some of the steps here, essentially the steps, Steve. So it's really important to do an assessment of your application, and then oftentimes a critical step is understanding the dependencies. So I have a Windows service. What DLLs do I have? What permissions do I need? This is probably the most critical part, the dependency analysis. Once you've done the dependency analysis, then you write your Docker files, you containerize your applications. Once you've containerized these applications, you want to host them in a container registry. Then you start essentially go to a Kubernetes-like environment and then start creating your pods based off of those images. Then once you've done this, you can now come in and start doing fault tolerance and continuous modernization and things like that.  So even without having to change a of a whole bunch of code, I've containerized my app, I've deployed it into Azure Government and now suddenly on a legacy app that I wrote years ago, I have these capabilities now, like self-healing, efficient resource management, understanding how to efficiently pack the nodes and you get all that just from deploying your app on Kubernetes.  That is correct. We don't have the time to show you this. But if I went into the dashboard and it might be worthwhile to just go into the dashboard. I want to run the whole demo for the sake of time here, but let's just go to the portal here for a second. In fact, I think I have the command already here. So let's just go over to the VM. Let's go to PowerShell, and one thing I want to do is just bring up the Kubernetes portal here. So let's just bring this up here, and once a Kubernetes portal comes up.  It's interesting. You just brought that with one command in the Azure CLI and you launched the portal.  Launched the portal. So this is the portal, where if you notice here, if I go further down on the left-hand side, I have all my pods. But these are all the pods that we were talking about. This is the web application. This is the WCF service. This the Windows service and so on and so forth. If I came in here and essentially let just go ahead and do this. Let's just go ahead and delete this, talking about the healing part. I'm going to go delete this pod. "Are you sure?" Yes, I'm sure. I can delete this pod here, and you can see that it takes a few seconds for this pod to get deleted. But because we have this resilience in place, Kubernetes notices that you requested me to have one copy of this pod running. Somebody deleted this pod. I'm going to bring this up again. This is a great example of self-healing that's going on right here. This pod would come back up again in two minutes.  Excellent. Okay. Great. All right. So what comes next?  So I guess what we should talk about and then maybe go back to the slide here for a moment. What comes next is in my view, once you've migrated the application and I think I certainly subscribed to the agile mindset like many of the people watching this video. The idea is that you can move these applications quickly, containerize this and move them to a Kubernetes environment, where you get these benefits. But then you have these coarse-grained containers. What you want to do is now that you are running these applications in the Cloud, in fact, let me just very quickly bring up that slide that I had in mind to describe this. So once you have this coarse-grained application, now what you want to do is you want to figure out which parts of the application maybe are using too many resources, can be further broken down. So this gives you a great way to say, "Okay. Now my application is running in the Cloud in a Kubernetes manner. But here are some issues that I'm running into, and this application, I'm not able to change it. I want to take advantage of the Cloud native capability perhaps." Now I can focus on that one, of coarse-grained pod and start bringing it up and optimizing it. I call this continuous modernization far more effective than trying to go to a big bang approach of I just want to rewrite this application, go to the Cloud. This gives you an opportunity to think about the pieces that are causing the most problem and focus your time and your team's energy to solving that problem.  That makes a ton of sense because otherwise what we see a lot of times is a team might take a year to try to modernize our app prior to deploying to the Cloud, but this turns out on its head because quickly get you to the Cloud. Once you're there, great. Now you can start optimizing and modernizing from there.  Right. We see this because you might want to just rewrite this application, and it may take you a long time, six months, 12 months. By the time you're ready to deploy that application, the Cloud cadence as we all know, the technology that you took a bet on may not be relevant at that point versus this approach, "Hey, I want to containarize, go to an AKS environment, but this piece, I really don't want to give you this much compute capability and pay for that." I would rather take this functionality which is very occasionally run. I want to take that capability and run it as part of serverless and only pay as run it as functions perhaps. I want to take this out so you can start doing those things because functions is what everybody wants to do, a lot of momentum behind it. So that's how you can reason about it and constantly modernize your application.  That makes a lot of sense. Okay, great. All right. Well, this has been Steve Macoloni with Vishwas Lele of Applied Information Sciences talking about migrating and modernizing the Azure government with Kubernetes. Thanks for watching.  Thank you. 