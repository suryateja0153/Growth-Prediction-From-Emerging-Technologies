 hi welcome to our session serverless functions fast that is secure scalable resilient anywhere my name is vinod and i'm a product manager at google and i'm presenting with my colleague dustin ingram and matthew lawson from ikea so let's get started so here's today's agenda first we'll give you an overview of the product cloud functions then we'll walk you through key function as a service use cases then we'll follow up with an interesting case study from ikea and their digital transformation with serverless after that we'll walk you through key security capabilities and diagnosability and availability capabilities in serverless at google cloud and then walk you through our functions everywhere vision so let's get started cloud functions cloud functions is google's event driven serverless compute platform where users can write small snippets of code that react to events as well as http you can write up these functions very easily and get started to process you know small snippets of code for say for example uploading a file to google cloud storage and do some processing also wrap up with some ml apis do some ml processing on the file and then store the results back in the cloud cloud functions is truly serverless where you pay only for what you use it scales seamlessly with zero infrastructure management it also has a streamlined development model where you wrap up and write a function very quickly in addition it's integrated with key events all across gcp to build up complicated applications and services when we talk to users users really like to use cloud functions for its simplicity scalability the fact that you don't have to manage servers the pay for use model and the fact that it's connected with broad range of cloud services key functions of the service use cases that our customers use cloud functions are are things like serverless web hooks where users can wide up you know functions with github notifications that are processed and then served in slack further real-time data processing wherein users can you know upload data to the cloud to cloud storage uh you know trigger a function to do some processing uh call an ml api and then store the results in the cloud again serverless iot backends where you know users have iot systems all across the world sending things like sensor and temperature data and then that's processed through pub sub messaging systems that trigger cloud functions and then you do some iot analytics and then store the results in the cloud and then uh intelligent applications using ai and bigquery for example you know chatbots using twilio where functions are wired up to invoke an ml api or a natural language processing api as well as doing sentiment analysis with that and trend analysis with bigquery along with these key fast use cases when we talk to customers they have several key fast user needs that come up and these needs are things like developer productivity building complex enterprise workflows with serverless and functions building applications that are secure and then having the ability to build applications with multiple languages with diagnosability debugging capabilities telemetry and local development further users will care about global availability and scalability to ensure their application and functions scale for their application traffic in addition users really care about portability and can we reduce vendor lock-in when we build our serverless applications and to meet these user needs cloud functions offers the following key differentiators first is ease of use cloud functions is a very easy to use product where users can write up a function very quickly from the ui from the cli from their favorite ide and from an api for example here's a simple function in node.js where users just written hello cloud next the user quickly wires it up and deploys it using the cli and then it's ready serving traffic all in a single command the user is writing their code you know it's getting built in the cloud it's getting deployed in the cloud with head checks and then is within minutes running and ready to serve traffic this is really powerful that all in a single command a user can get this and achieve so much along with the ease of use cloud functions offers the ability to build complex end-to-end solutions these end-to-end solutions can be built using key powerful building blocks which are event-based for things like data processing with ml apis and bigquery and so on and then for automation workloads with things such as cloud scheduler cloud tasks and so on and so forth and to walk you through this application journey of building end-to-end applications i would like to now invite matthew larson from ikea to walk you through ikea's digital transformation with serverless and cloud functions hello and good morning good afternoon or good evening depending on what time it is wherever you're watching this i'm very happy to do this presentation for you today but of course i would love to have done this in person but because of the current global situation i get to do this from my home office here in sweden so in this talk i'm going to explain to you how ikea is using google cloud functions and other serverless technologies in our engineering efforts as we go through a digital transformation so my name is matthew lawson and i work at ikea as an engineering manager here in southern sweden i usually don't start my presentations off with who ikea is but i do have a couple company slides two of them to be exact so first maybe i can share something that you might not know about ikea and that is our vision it has very little to do with furniture actually has nothing to do with furniture and that is to create a better everyday life for the many people so whether it's becoming one of the world's leaders in sustainability starting to sell solar panels working with international charities or creating that great furniture for the home all of this to help the many people to create that better everyday life but the two words out of that vision that mean the most to me are many people and to let you know what i mean let me give you some numbers here so ikea is over 76 years old and is made up of many companies organizations and hundreds of thousands of co-workers across the globe so here are some highlights from our previous fiscal year as of september 1st 2019. so ikea had 433 stores open with 12 of them opening that fiscal year and actually within the last few months of this recording we have over 450 now we have 211 000 co-workers working for us globally and this is growing especially in our digital organizations across the globe and we're now opening small stores in city centers as an example of this within the first four months of opening we had a million visitors to our ikea mandalay store in downtown paris we have billions of visitors to our website each year and we have over 100 million ikea family or our loyalty program across the globe as well so this means that when we when we create a new physical product or a new digital product like a mobile app web application or an api we need to make sure we cater to those many people the millions of people so ikea as in many different companies are going through a digital transformation ikea has been around since 1958 and to be completely transparent we have quite a bit of technical debt across the organization or what we like to call it as our spaghetti in the data center our digital transformation was not simply a matter of migrating to the cloud one decision we made early on was how this was going to happen we did not want to do a complete lift and shift to a cloud partner but instead we decided to re-engineer the organization and digital products at the same time our chief operations manager stated once we are flying a plane and changing the engine at the same time personally to me this is quite hard to do but as an engineer it has been a ton of fun so new solutions and projects are striving to be completely cloud native and this is quite hard to do when the brain of your application the data is still sitting on premise and we're doing a lot of work in that area internally as well creating new data pipelines to cater both the old and the new so one of the use cases that we started re-engineering that is heavily using google cloud functions and many other serverless technologies is our almost live feed of our inventory system that we have at each ikea location across the globe so this enables us to show a live feed of what is selling allowing us to export that data to bigquery for further analysis or and also to create dashboards to give the store insights on what is happening instead of that daily or weekly report and i'm sure there's much more use cases that we haven't even thought up of yet here so let's take a look at architecture of one of the use cases that my fellow co-worker michael created first we have our inventory server which sits on premise at each ikea location and talks the google cloud through a compute engine from a shared vpc on a vpn vpn and this sends many different messages as xml the xml is then compared to google cloud storage looking for new or changed rows and the ones that are changed are sent as a json object to a pub subtopic we then have a batch receiving side of this which uses google cloud functions and actually powers this entire architecture this pulls in messages from pub sub and puts the raw data into many different bigquery data sets depending on the message type and we can also move that message on for further processing using other pop-up topics finally we're pulling in the messages from the capturing google cloud function using a schedule system as well that was built and this is using cloud scheduler another google cloud function cloud tasks and this configuration data is stored in firestore so this tells the google cloud function the capturing one how often to execute depending on some criteria like the amount of messages in the queue time and also optimizes everything from a cost per perspective as well we then can create custom dashboards using the bigquery data sets and all we can also process it further on like i said with pops up topics one aspect of this architecture that we're currently working on is the ingestion of data from the on-premise server to the cloud we're looking at how we can do this without using a vpn tunnel or shared vpc so some people have asked me why are we using google cloud functions here and not something like dataflow well one thing we like to say here at ikea is we do not respect the solution until we know what it costs and if this solution was to be turned into mission critical then we could change the architecture to better support message ordering duplication and other aspects this solution currently handles between 60 and for to 60 000 messages per a minute and can certainly scale higher higher as we've seen and it actually costs around 30 us dollars per month to operate to get the the data from our on-premise to google cloud functions and so this really showcases the power of serverless without needing to spend a ton of money so let's take a quick look at a demo that my colleagues axel and joel created to show what you can kind of do with this data so here is a map of north america with our stores and for fun we're just showing our inventory changes from our iconic product the fracta blue bag so as you can see here we're getting some messages popping in from sales that are happening in those stores and this really kind of showcases how you can use serverless technology to bridge between what you're doing on premise to new cloud technologies so with that if you have any other further questions you can please feel free to contact me my email address is here and also as i mentioned we're also hiring so please visit join.inca.com for more information around that and with that i thank you for listening and please stay safe out there thank you matthew for that amazing presentation on ikea's digital transformation with serverless and cloud functions now moving on one of the key user needs as well as security and cloud functions offers key security differentiators for users and serverless one of the key features we offer is per function identities where we provide fine grained control on which users are privileged to invoke a function and we take it a step further and also provide on which specific resources a function has access to for example here's a user who's trying to invoke a cloud function using cloud scheduler and you know that user is authorized and the user can invoke the function and then there's a malicious user who's trying to invoke the same function and is prevented to do so likewise here's a cloud function that has permissions to access bigquery but it does not have permissions to access cloud storage by providing these fine grain controls on security you know we really help users control who can access the function and which resources a function can access and then take the security level a step further along with that users really care about vpc they have systems across the cloud as well as on-prem in vpc networks and our cloud functions play really nice with these vpc networks functions can connect with these vps networks and we take it a step further uh by providing what is called vpc sc or a security parameter to prevent things like data exfiltration along with you know fine grain access and vpc users are really concerned about the denial of wallet attack and serverless for instance if you know a user service gets a lot of requests from a malicious user they could at the end of the month get a shocking bill if their you know scaling is not capped to prevent this we offer a service called max instances that let users cap their you know serverless services thereby you know preventing you know the denial of wallet attack and also letting their serverless service scale to the extent as needed and within their monthly budgets along with scalability and security users really care about you know multiple languages diagnosability and local development cloud functions today is available in key languages such as python node and go further we're super excited to announce java 11 which is generally available as well as dart net and ruby and we have more runtimes coming soon as well and to talk to you more about diagnosability and fall tolerance i would like to now invite dustin on stage to give you a demo in the space hi i'm dustin ingram developer advocate for google cloud let's take a look at how we can build a reliable resilient self-healing system using cloud functions and cloud pub sub let's say we've got a fleet of deployed iot sensors that are sending temperature data in degrees fahrenheit along with a sensor id and json payload via an http post to a cloud function now say we want to take that temperature data and write it to firestore which is our operational database and also write it to bigquery which is our data analytics warehouse traditionally we would probably do this in the same application or in the same function but this has a couple drawbacks so if for example the code that writes to bigquery is not available or has a bug in it or maybe there's a networking glitch and it can't talk to the service now the function errors out and you're left in a weird state should i rerun the function but then what if firestore write did succeed and now i've written to firestore twice what is the overall state of my application so we want to decouple these now one way we could do this is to put it into two cloud functions one that writes to firestore and one that writes to bigquery and this is a step in the right direction but that post temperature function is still responsible for running and retrying and understanding if those other functions succeeded or failed so we want to decouple these completely and to do that we'll use cloud pub sub which is a high scale messaging bus on google cloud now all post temperature has to do is write a message to the pub sub bus and then it's done the write bigquery and write firestore functions are listening for messages coming in on that topic in cloudpub sub when they get those messages they'll do their functionality and they'll fail and retry independently from each other asynchronously let's take a look at this in action here are the three cloud functions that we talked about post temperature write bigquery and write firestore i've written a shell script to simulate the iot sensor posting their data via an http post so they're going to post it to this sensors collection in firestore and you can see these values coming in but we've also got a tracking sheet that we wrote that this actually looks at the timestamps coming in and puts in a message when it's about to try writing to bigquery about to try writing to firestore and then whether it's succeeded or failed and you can see these update in real time everything is good so it's all successful but i want to simulate an error in the let's say write bigquery function so i'm going to open up the editor here in cloud functions there's a built-in editor but you can also use your normal ide your normal editor to deploy from your workstation and so on but this is handy for doing quick edits so i'm going to go here and i'm going to intentionally break this function i'm going to change the name of the table from readings to let's just say readings with a few s's so maybe one of our python developers made a typo and put the wrong name of the table so let's deploy this so i'm deploying a broken version of the write bigquery function and while that's deploying you can look at some of the other attributes of our cloud function you can set identity so your function can maybe only access certain resources or you can set environment variables for example the sheet id that we're doing the updating in all right so now that our function is deployed i'm going to rerun that shell script that simulates 10 iot sensor readings coming in and let's go look at it in google sheets so you can see it's succeeding and trying and you can see it's happening asynchronously those functions are running and failing independently we've set cloud functions to retry which means that if it gets an error it will retry immediately if it gets another error again it'll wait a bit longer and so on and so forth as an exponential back off all right so those are all failed so we want to figure out okay what went wrong now i know what went wrong because i put that typo in there but let's pretend that we didn't and we actually need to debug this cloud logging automatically picks up all the logging messages from cloud functions but also cloud run app engine kubernetes and a bunch of others and you can see we can identify our error here the table cloud funcs readings is not available so cloud logging is great you can do monitoring and alerting you can have it automatically aggregate error reports using error reporting and it's really handy and useful tool for debugging your serverless code on google cloud so let's fix our bigquery function i'm going to load the editor back up and fix it so that instead of readings with many s's it's just readings with one s and then we will redeploy this now let's check our tracking sheet where you can see it's actually been retrying this whole time as it retries again with the new version of write bigquery it'll start to succeed now instead of failing and again all we did was redeploy the function we had to set cloud functions to retry so the data wouldn't be lost because the system is keeping track of it internally as it retries the function with the same payload again and again until it succeeds and that'll happen for up to seven days retrying your cloud function so you don't have to worry about losing data and that is how you can build a reliable resilient self-healing system with cloud functions thank you dustin for the amazing demo on diagnosability and fault tolerance now moving on uh when users are using servers and cloud functions they really care about uh local development and disconnected development imagine that you're working in your team and you have to take a flight or seven hour flight uh you know and you want to continue developing your application that you're working with on your team you can now do that with cloud functions uh as well as on your plane and then when you land you can you know connect with your team and share your work as well to do this you know let's unpack what's really in your function a function is as running in an operating system for a particular runtime such as node.js with a web framework for that particular runtime such as express with the functions framework and then with the user score and dependencies everything uh in green below is managed by google and only the user's code is what is provided by the user and what we have done at google is we have taken the second green box which is the functions framework for each language and runtime and open sourced it we call this the functions framework for example here's the functions framework for nodejs on cloud functions now with this functions framework a user can run a function locally with their favorite ide and here's an example of the node.js functions framework along with a node function in your favorite ide and then a user can basically step through code write code when they're on a plane and debug and test it and then integrate with their team when they land on along with diagnostic ability language and local development users really care about availability and scalability for their serverless services cloud functions is available in a broad range of regions and today we're super excited to announce that we have added 13 new regions over the past year for cloud functions making the total number of regions 19 where the product is offered with this global availability of the service we're super excited to provide it to our users in the broad range of markets in the world along with availability users really care about scalability for their serverless services and functions cloud functions is backed by google's infrastructure which runs uh with you know on borg and it uses a technology called g-wiser which really helps its scale and here's an example of a load test where you know a server service for cloud functions is sent several thousands of requests and we see that all of the requests are served and none of them are dropped and the cloud functions scales seamlessly in this test along with availability and scalability users really care about openness and persuasiveness of their you know application and serverless service and here's a key differentiator for cloud functions in the space where cloud functions with the underlying functions framework that runs it and the build mechanism to build it have all been open sourced as a result a user can take their function and deploy to cloud functions which is a fully managed product they can run it locally in their favorite ide while they're on a plane they can also take that function and run it in any environment where you can run a container this could be cloud run which is our serverless containers product or any other container environment in other clouds as well this is a really key differentiator for the product and now i'd like to invite dustin on stage to provide you a demo on functions everywhere to walk you through this vision if we're a developer who's not used to working with containers let's see how we can use build packs to take our existing cloud function with its simple developer experience and have it automatically turn into a container that we can run anywhere including the powerful cloud run all without having to understand docker files or how to create a container you can use build packs to turn your source code into a containerized application either locally using the pack command or in google cloud build which has support in alpha bill pax will look at the source code of your application and figure out what is the language what is the run time and what will it take to turn your application into a container so in this case i'm going to use the local pack build command and we'll give it a destination where we want to publish the container we'll also let it know that it's a google cloud function this is the name of the function within our file that we want to run so if we go to my container registry and refresh you can see here is the container that we just built see just now and again containers are portable so i can deploy to kubernetes engine or virtual machines on compute engine but let's deploy it on cloud run because it's fully managed just like cloud functions once you're using cloud run you have some advanced configuration settings so you can customize how much memory it has you can give it two cpus and you have a longer timeout in cloud run you can also do concurrency so one running instance of your application could handle multiple requests which might lead to fewer cold starts and more efficient usage and potentially you can set the minimum and maximum number of instances now that is deployed you can see that cloud run gives us a url just like cloud functions but you can also specify your own domain name let's post some more temperature readings to the app that is running on cloud run and if i pop over here to firestore you can see the data coming in click here and we can prove that is in fact going to the cloud function that is running on cloud run so we were able to take our existing cloud function with just source code and using build packs turn it into a containerized application that can be run anywhere even the powerful cloud run thank you dustin for that amazing demo on functions everywhere please check out cloud functions at cloud.google.com stroke functions please also check out our functions framework and build packs which are open sourced the github links are provided here in addition if any questions please feel free to reach out to dustin or myself that's a wrap of our session thank you dustin and matthew for joining me in this session and i wish our viewers a great confidence 