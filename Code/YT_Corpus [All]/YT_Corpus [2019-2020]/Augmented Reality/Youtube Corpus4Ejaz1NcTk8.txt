 so afternoon everyone so yes I am Arthur shamoto I am a PhD candidate at the University of Illinois Chicago and today I'll be presenting this work that was conducted at the electronic visualization laboratory on the direction of my co-author adviser dr. Andrew Johnson and I'm using augmented reality to extend virtual reality display wall environments so the motivation behind this is that large high-resolution display walls are good for collaborative sense making where you can have multiple multiple participants in front of these high resolution display walls enough that you can make out the details when you're standing close to the wall but they able to step back and get the broader overview and and this any sort of environment because they are kind of fixed display walls the field of view when the field of regard is basically restricted by the physical let's play the wall without these are some virtual navigation such as panning or zooming and but a key feature of having these sort of large display environments is that you get these face-to-face interactions within people and that they can more naturally interact with each other and help us amidst have better discussions and make discoveries and in some cases we have the data that again can be displayed above or below the walls so virtual reality head-mounted displays improve immersion in these environments particularly when you're exploring three-dimensional spatial datasets and by filling this the single participants field of view they can use the head tracking to be able to see more of the virtual environment around them beyond using users head rotation increasing the field of regard so they can look right see everything and well the resolution in these headsets are improving which each generation of HMDs they're still limited compared to high resolution display walls and and once again they have there was reduced sense of presence or be able to see that sense of yourself in the space in this case your collaborators around you unless using some other another medium such as avatars to sort of get around that likewise an augmented reality particularly in see-through head-mounted displays to kind of get around the sense of presence and speaking with your collaborators and you still get the ability to look around with the higher field regard around the space but the field of view that you could see I wanted a given time as well as the resolution is typically even lower than say virtually a head-up displays and so the main goal this work is there a way to combine these technologies together to get the best of both of your environments the high resolution display walls the ability to talk to the people around you but still be able to use a device an augmented reality device to regain that sense of immersion feel to regard of the data around you that might not be readily available on just how display itself even if it is at a lower resolution than what's on the display wall so just a quick look at some of the related work so and so the work I'll be using focusing on is using these large numbers and display walls I tend to do virtual reality work so for example Cave and the LCD successor cave to and many of these works here provide direct comparisons of these of the same tasks on these two different devices so the first work they're exploring a network based graph and so they're looking at two participants that are identifying features in these graphs they're comparing their experience in their cave to versus had not the display but in a lot of these they have the interaction modalities also different so on the cave they're using one pointers to interact whereas in the head-mounted display there they're using a leap motion to do more hand gesture work second paper sort of a similar idea this time in a projector base cave and they're looking at interacting these spaces and again they're comparing so one navigation to as the gaze crosshair of this mobile phone-based HMV that was used and here and so the other other area of later words tend to combine augmented reality displays and big displays with main purpose of using this to simulate outdoor environments to sort of understand how to better improve augmented reality techniques in a controlled environment so experiment a little bit in fact with interesting factors like these perception changes how the latency particularly changes when you have more fine control because you can use the big display as in a controlled setup and in both these the experiments these large displays actually are capable of doing 3d stereoscopic graphics Bennis cases they're using the preceding outdoor environments are far away they don't necessarily need those cues to depths and so the work I'm more interested in is is when you have a 3d virtual environment when you have virtual objects are much closer to the user and then where those 3d cues of deaths are much more important and so the system that is probably use physics around is the k2 hybrid in reality environment we have at the lab it's kind of designed and it was a scientist a hybrid approach between high resolution tile display walls and the immersive classic projecting base caves and so one of the key features of the environment is that we're surrounding participants with high resolution stereoscopic visuals are greater than erhm D at the moment yet this 24 foot space that they can physically walk around to explore the world as well as large enough have a group of participants field to have this face-to-face interaction and so this was sort of highlighted in the picture above but we actually had a group of scientists that worked in the worked in cave two for a couple of days they brought in tables they it was a busy a working environment where they could actually have you know part part of the cave with more 2d work that the geologist were more familiar with still maps other documents but then on the right half or even on the full display when they needed to have a virtual recreation of this lake that based on stone or data that they were exploring on the searching for augmented reality device to sort of add on to this system the main criteria what that had to be a see-through display so again we could preserve the high resolution and be able to keep that sense of presence with the real world with yourself and your collaborators and so the main device we worked with is the original hololens since that was the one that was most rarely built at the time but since then there are certainly other interesting devices that could potentially use such as the magic leaf which has greater field of view than hololens as well as also think of other ways that that in these kind of collaborative sayings other tools that might be more useful whether it's heavy interaction on tablets or maybe more low cost of air devices that may look it looked may look at for future work and so combining these two devices together to get kind of the the best of both so we retrofitted the hololens with the retro reflective tracking markers that we used for usual navigation within the cave and this was done to improve the tracking of the hololens is a native tracking system it's also kind of minimize the differences as you're trying to compare how this experience would change and we add this head mounted display with the track markers and so that's protruding upper left where we end at the markers and to preserve the stereoscopic we actually add the same passive stereo lenses on top and this is all to give you a general sense of kind of systems so we have all the inputs are coming to the tracking system the cave2 system which has a tracking server and central master node which is generating the virtual world and a building respect for all the devices and then dealing with either feeding that information back to the hololens to get the perspective to line up as well as going to the computing cluster which is rendering the displays of the virtual displays and so the big experiment here was was having this augmented experience would have a significant impact compared to just using this with the standard cave setup of just lightweight glasses and a wand controller so the experiment we designed here was explorative with within-subject user study and to evaluate the impact these of a spatial search tasks to this network based graph understand how the test performance and the user behavior changed in these two conditions and so in this case we had 10 participants for this study mostly graduate students most of them had prior experience with virtual reality both in the cave or with head mounted displays half of them had had some development experience mostly on the hmd side of things half had at least tried hololens before and three of them had had never used hololens headset but if the task was a visual search of 3d spatial network graph sort of example that at the top that's actually the trainings that they were given and basically the count the number of triangles formed by exactly three nodes in this and these ones one of 32 graph structures that they were presented and so sixteen they were given 16 of these graphs without wearing the hololens and 16 with and these graphs vary in size no complexity but most importantly they kind of they changed on how they were initially presented to the users so some of them the graph would be completely viewable on the cave screens to begin with some would be on the case beings have this extend above some would extend below some would actually do both and in most of those cases since we were very interested and seeing how well the stereoscopic effected work on having a head mounted display and in the cave environment most of these graphs also extended from the projection plane into the cave environment so they had more of a space that they could walk around the cave and look around the graphs and in both cases they still had the option to use the wand controller to do more virtual navigation so using the control stick to just rotate and move the graph around and it took about 50 minutes for these complete both graphs so we collected both log data of basically all the tracked movement going on within the cave the one button movements how they were moving the graphs around and then there were a number of survey data that was collected so kind of information before the study and then between each after each condition we did a test a number of questions to assess the physical and mental demand presents realism comfort sickness as well as having a short session for just semi-structured interviews to get more interesting feedback from the participants so the independent variable they had the control condition was having a personal contestant explore these graphs using the standard cave two glasses as Juan just pictured in top so just lightweight 3d passive glass the same as you would see in the movie theater using a Playstation navigation controller with the wand so they could use they could point and rotate environment around and then the experimental condition instead of wearing the light weight classes they'd have the hololens but they still were able to use the long controller exactly as they could in the other condition and then the dependent variables task accuracy completion time as well as a couple of several metrics and how they were moving where they were looking around both physically and virtually and so just quick overview of the results in terms of completion time and accuracy we didn't find any significant difference between the two conditions which we did find rather encouraging since one of the biggest criticisms of wearing hololens was the discomfort and even with the kind of limited field of view and this was kind of the first iteration of this system there was a decent latency between when the participant would move their head and the graphics flying up which Ronna 300 milliseconds and there was a bit of a range and there depending on various conditions that were hoping to improve in future work in terms of movement we noticed that participants that were had the hololens on would use the wand to virtually navigate significantly less in the data size compared to use in the cave to condition so they were able to look you know we were looking around more versus flying around and this sort of is connected with some of the interview responses is that when they had the hololens on it was easier for them to maintain spatial spatial awareness and not have to you know move back and forth to get a better sense oh did I count this section of the graph again or do have to recount all the nodes in terms of the survey responses we got in terms of mental the only major the only significant see the significance we found was that hololens was more uncomfortable than or in the glasses physical and mental demand wasn't there was we didn't find a significance for that and the we're in the hololens did not succeed we significantly impact the sense of presence in the cave to which was also kind nicely given that you know where the hololens it does change the the contrast after wearing it as well as if there is some limitation for the field of view compared to the other just wearing the glasses as quickly as some of the interesting interview responses that i've already mentioned is easier to count in hololens one of each more interesting notions is in the k2 displays it's these large tiled displays and has displayed borders and most people find that distracting at first you should they adjust as they get used to environment but in terms of the search tasks the grid actually became more useful again in terms of partitioning the spaces and actually became more distracting with hololens which is just a flat display didn't have that grid that's like oh the grid is gone and it found it distracting which i thought was an interesting just perceptual response if i just sort of recap the sort of preliminary work and combining these large see our display walls in augmented reality trying to get the best of both of these devices and so we developed this framework that fairly reliably was able to get these pieces working together without a significant user impact and so future work would be to kind of explore this even further as part of my PhD dissertation and you know use this with more complex datasets and examine multi user interaction within this framework thank you [Applause] which on I was Virginia Tech do you think you saw any fact due to the effect of the hololens is kind of heavier than the glasses that it is in the control condition did any participant tell anything like oh I avoided looking up and down too much because the thing is having a my head yeah yeah so in addition to the comfort we did yeah never a person is notice if they were they said they were less inclined to yeah I looked up and down particular in the graphs because of the heaviness of because of the weight of the head said although we did I believe yeah there was still a significant portion of you know at least they tried even though he said some important said the demon like the hololens at all in the condition but overall even they still believe made attempts to look up and particularly down and something that uh that i think why do i explore also later is whether there was a difference in like if they're looking up versus looking down to the get sensible weight differential could be also interesting so you expect me right now absolutely that so there's something I want to explore in future work to get a better a sense of you know how these would compare again and compare the better comparison to some of the prior work that we're specifically looking at the interactions but yes again so the first step is seen we're waiting to go with the combined air display but I think yeah future work or to me for my dissertation I do intend to Explorer agent the only case as well [Applause] 