 hello everyone my name is Susana schmidt from the University of Hamburg and I'm very happy to be here today and to show you the results of one of our latest research projects and actually this project is part of a bigger idea to build what we call a blended space so first I would like to show you what we mean with this concept of a blended space so a planet space is an environment with physical real objects that can be transformed into any state within the reality of it reality continuum so for example natural history muzeum could just take one of their exhibition rooms and could place an exhibit a real exhibit inside of this space and could then augment it so for example to say just augmenting small parts of the exhibit like only highlighting some body parts or showing the entire skin virtually so how did the dinosaur looked like or even they could show in this space how was the context of the dinosaur so all of this could be done in the same space in the same spatial boundaries and the second special feature of blended space is that all of these states or the transitions between all of these states have to be seamless so a user does not have to put off his wife and then use a hololens if he wants to transition from a via condition to a a condition for example and the first challenge we face we are faced with was which kind of technology could be used to build such a blended space because most of the existing our hardware is very limited in terms of the field of view so we could not use a hololens for example to build an immersive virtual environment so we decided to use a technology which is called spatial augmented reality or projection based AR or projection mapping which means that you can mix virtual content and real objects without a digital displays so all of the con as projected directly onto the surfaces of the real objects and therefore the user does not have to wear big glasses or a tablet in his hands so it's very comfortable for the user and since we want to augment not only the object but also the environment or the surrounding we need more than one projector and we build some kind of extended cave so we had three walls and one floor as projection surfaces and in addition we had one projector for the physical object inside this cave in this case it was an exhibit this Tanis I showed you some slides before and within this cave we wanted to show different kinds of virtual content so both monos copy contents there is copy content and also view dependent content which was floating inside of the cave so we also had to install a tracking system and one of the users were was tracked or his head position was tracked and the view dependent content was adapted to his current position so the perspective was correct for this user and in fact this extended cave the example I showed you before looked like this so this is one of the states within this continuum with the highlighted body paths or with an entire virtual skin so the user could move around this physical skeleton which was augmented with the skin or he could see the environment the dinosaur was living in and this technology special mental reality had some benefits for us of our idea of building such a blended space because we can present reality virtual reality and all states in between and we also have a large field of view when the user standing inside this cave like environment and we have a minimum level of user instrumentation so if we want to show mano scopic content only then the user does not have to wear glasses at all and if we want to show stereoscopic content then light weights glasses like producing a mile sufficient so this is a benefit in comparison to other AR solutions also in this planet space with special augmented reality we have some kind of shared space both virtually and also in reality so multiple users can see the same content the physical content and the virtual content and we found in previous experiments or demos that this is very preferable so most people like this very well and I think also in the keynote session we saw that it's very important for public installations to have the social idea of such installations on the other hand we also have some disadvantages or maybe more challenges using the special augmented reality for this kind of application first we need a way to do the transitions between all these states so usually if you have atom on the display you also have specific controllers of hololens you have the predefined gestures but for special minded reality there are no integrated devices or people know so they would have to learn them and we didn't want them to learn new gestures or new input devices so we thought about how could we solve this without yeah this new input devices which have to be learned another challenge which is very special for projector systems is the self shadowing so objects cast shadows and such systems and sometimes even on their own object paths we cannot solve this but we can try to guide users to favourable places so if they are very close to a project of a projector then the self shadows reduced and this is what we wanted to try and last but not least although it's a shared space we have the problem that if we want to show the view dependent content for example this virtual skin which is floating inside the cave then it's only a single user system because only one user can see it with correct perspective and for other users it's distorted unless they are also moving to the same spot as the track users and this is what we wanted to do with with our user interface so we wanted to improve user interaction user guidance and also use a collaboration within such a blended space because of this we developed user interface and we decided to project it onto the floor because we thought it's very intuitive easy to learn it's not very distractive so users can still focus on the exhibit which is in front of them and of course we also evaluated it I will show you this in a second and for this floor user interface we design different user interface elements the basic element are some buttons with footsteps or the user knows that he has to enter such a button if he wants to interact with the system and with these buttons we were also able to integrate some kind of meaning and with regard to the position and the orientation in the cave so for example if we want to show a scene where a user has to observe the object from a very near distance then we can also put the button very close to the exhibit but if he wants to get an overview for example for this context scene then it makes more sense to place the button in further away when one user entered a button progress bar appears and afterwards 2d floor map expanded and this floor map was like safe walking space or walking area so when the user was walking inside this area we could make sure that he get good view points so the self shadowing was reduced or was to a minimum within this walking area and also from a narrative point of view we could make sure that he is always seeing the exhibit from the points which are most interesting for this specific scene and also we integrated region of interest segments which you can see on the bottom part which only directed to users to parts within the scene where the action takes place in the specific scene and for collaboration we introduced a master follower concept so the first user who entered a button was the master and all of the view dependent contents were adapted to his current position and all other users are the followers and they get a circle around them and when the circles read this means that they have a very bad viewpoint for the current scene so they are directed to the master user and if they are close to the user the circle turns greenish so these are the different elements we used and we tested them and use a study with 40 participants of different ages between 19 and 65 and we had most participants from our own department but also participants with a non-technical background and since we wanted to test the collaboration we decided to use pairs of participants so and every experiment session two users were using the system together and we also decided to balance partners or groups where their users knew each other before the experiment or they didn't know each other before the experiment because we thought for museums this is very common that sometimes you are visiting a museum with your friends or with your family but it might also be that you are in front of an exhibits and you are meeting a stranger and we wanted to make sure that our interface works for both groups and not only for people who know each other so we simulated the exhibition scenario as I showed you before with the dinosaur skeleton and we compared our extended user interface with a basic one which only featured buttons which were positing to make sure that users know that they can enter these buttons and we compare these two conditions with between subject design we collected different subjective and objective measures but I only will show a subset of them so you can see the basic UI represented by the green bars and the blue bars represent extended UI and we had some questions regarding usability and also feedback quality and as you can see here the extended UI performed significantly better for feedback usefulness and also feedback curacy in comparison to the basic UI and we also investigated collaboration with some objective measures so for example for the scene with virtual skin it's very important that both users are close together so both users the master and the follower user get a good viewpoint so we wanted to reduce head test distance but we know to users as you can see here for the extended UI the head distance was lower in general but what is even more interesting is that phantom família uses it keeps nearly the same as for familiar users and compare and comparison for the basic UI users kept a much larger distance when they are not familiar with each other and in the right diagram you can see a balancing score so in our implementation we didn't do some balancing we saw thought it would be best if we had a first-come first-serve principles or the first user who entered a button was the master if he left the walking area then the assignment of the world's started again so the users had to do the assignment of the roles by themselves and as you can see here for the extended UI this worked very good so a balancing factor of one would be best and in this case it's very close to one for the basic UI didn't work so well so and some groups one partner was the master all the time and the other one was the follower always so the interface elements helped users to understand that they have to balance this somehow to get the best experience for all of the users we also investigated communication behavior so if you're interested in that please have a look in the paper and yeah in summary we implemented and evaluated user interface for these kind of planet spaces with a floor projected with floor projected elements and the evaluation was done with a user study with 20 pairs of participants and results and indicated that interface is self explanatory that it's easy to use that it encourages users to move closer together but we couldn't find any positive effects on a storytelling so we also asked users did you understand the story was it easy to follow and we got high scores both for the basic and extended UI so for future work we could test this in a more complex scene because our scenes were very simple and also what we didn't test was learning success so this was not a focus of this study but it would be interesting if users were distracted by the user interface and therefore maybe the learning was worse than without but we hope at least that they are more excited and more interested and therefore they learn more than without interface so that's all thank you a lot for your attention and if you have questions don't hesitate to ask [Applause] any question Mohamed's Arland University I have a multi-part question so how did you maybe mention it but how did you measure the head distance and secondly what is the effect of the head distance on for example the storytelling or actual experience overall of the two users because if you get too close I guess it's kind of inconvenient right okay yeah that's a very good question so we had some markers on the stereo glasses or shot glasses to users had to use and the head distance was just a distance between the center of these markers and this is also was an observation we did that sometimes if there were too close together of course for the unfamiliar users for some how strange so for some scenes it was not important that they had to close it was only important that they had a they were not too far away from each other but for this virtual skin if they are only one meter away from each other then one of the two users would see the skin floating besides the skeleton and not around the skeleton so for this particular scene it was very important for the experience that they're close together but I think for future projects we also have to think about how can we prepare the scenes that they are best for such experiences so I think for the skeleton and particular it was a little bit difficult to get a good experience for both users but what we also saw is that with the extended UI the users realized that the master user was the one who had the best view and so they left the scene and said that now you can test it also so it was still a very social experience so still it helped hi George University of British Columbia I was wondering when your users are wearing shutter glasses couldn't you just render different viewpoints in alternate frames so each user can get their own viewpoint with maybe a lesser framerate I think there's a very popular paper from Lima so they have this projector systems which can be used for up to six users by using this shuttle system so this is also mentioned in a paper as a possibility to show it for each user so a different perspective for each user but first it's kind of expensive and difficult to use so we also work with museums and if we can tell them you can use one projector off the shelf projector then they say okay we can do this but if we would tell them how you need a very complex expensive hardware setup then they probably would say this is not possible and also what I always think is then you again have these private views for each user so it's very similar to a hololens for example and what I like about this system is that even if you have a distorted image you know what you add a person is seeing so actually it's for me it's more social than these private views but I understand that it's maybe a better experience of each user has the prospectively correct image so I think yet it's this is the problem yeah yeah so actually I didn't test it but for me I thought maybe you you are not sure that the other person is seen the same as you do but of course thank you okay thank you thank you [Applause] 