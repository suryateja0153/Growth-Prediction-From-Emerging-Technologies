 good morning good evening good afternoon depending on where you're joining us in the world uh welcome to our next nano explorations our twice weekly opportunity to engage with our students at mit that are doing phenomenal research across nanoscience nano engineering and technology and science broadly i'll be your host for today uh brian anthony the associate director mit nano i will my job is to introduce our gracious speaker for today and to shepherd questions at the end uh we are being recorded as you saw at the beginning uh please when we get to the end raise your hand or type your messages in chat and i will marshal questions to our speaker so with that it's my great pleasure to introduce melissa notaros who's a doctoral student in electrical engineering computer science uh working in integrated photonics but integrated photonics for enhanced reality her talk today liquid crystal based integrated optical phased arrays for augmented reality uh with that uh melissa please take it away and participants thank you for your time and lisa thank you very much for joining us today yeah thank you good morning everybody and thank you for the introduction brian um so as brian mentioned my name is mili sanathrosh and today i'll be presenting on our work for liquid crystal based integrated optical phased arrays for augmented reality and we call this system cipher for short which stands for visible integrated photonics enhanced reality so first i'll give an introduction to head-mounted displays in general as well as some motivation behind our viper head-mounted display which is based on integrated optical phase trays i'll then give a summary of the viperal approach overall viper approach and i'll go into some of the recent results that we've achieved these results include transparent glass wafer bonding passive holographic display an integrated liquid crystal phase and amplitude modulator and integrated the first integrated visible light liquid crystal based phased array and an active viper pixel as well as scaling this pixel to a full display so as most people are probably familiar a head-mounted display is usually a pair of glasses or goggles that sit in front of the user's eye and relays information directly in the user's field of view this means that the user can gain information from the glasses while also seeing their environment around them there's many applications for head-mounted displays just to name a few are military medicine and engineering those are the current head mounted displays such as the google glass shown here have a few limitations namely they're large and heavy so they're very indiscreet also when you look through one of these devices this is the type of image that you're going to see you can see that the field of view is actually very small so the area where the information is relayed is very small also as you can probably see from this image the image quality is not very good for example it's not very bright so i'm not sure where everyone is today but here in boston it's a pretty it's a pretty sunny day on a day like today you wouldn't really be able to go outside and use these goggles outside also another very important limitation of this type of display is that all of the information is displayed on one focal plane and this focal plane is directly in front of the user's eye so if someone is using this device their eye is having to focus between this very closed focal plane and then the farther away focal planes in their environment so as your eye is focusing between these two focal planes it causes eye fatigue and this issue is known as the virgin's accommodation conflict and it can actually result in headaches for people which limits how long people can use these devices so with the viper head-mounted display we're aiming to solve all of these issues the viper head mounted display is a chip that sits in front of the user's eye it's a direct view near-eye modality that projects fully holographic images for only the user to see and because these images are fully holographic this means that they have the appropriate depth cues so it solves this virgin's accommodation complex and it allows for people to use this device for a long period of time also the viper display is flat and transparent so it's highly discreet the viper head mounted display is based on integrated optical phase trays and a phased array consists of an array of antennas across which a phase gradient is applied and if you actively tune this phase gradient you are able to steer the direction that the light is propagated and with integrated optical phased arrays you're able to place greater than 10 000 antennas on a millimeter scale chip so integrated optical phased arrays allow for low cost and highly scalable way for scale production to date there has been a lot of significant work on integrated optical phased rays and a majority of this work has been focused on this high speed beam steering the driving application for these types of um phased rays is mainly lidar for autonomous vehicles there's also been integrated optical phased array work for other modalities such as far field patterns focusing the beam and the near fields to generate very focused spots as well as generating interesting beam patterns such as vessel beams so we were interested in exploring if we're able to use integrated optical phased arrays to generate 3d holograms the viper display consists of a grid of optical phased array pixels and you can see one of these pixels shown here the pixel consists of silicon nitride waveguides to route the lights on the chip liquid crystal modulators to actively tune the amplitude and phase of the light and silicon nitride antennas to emit the light from the chip and then the entire viper display consists of a grid of these individual single pixels that are cascaded in both directions and for this display we encode each of these individual pixels to emit a hologram with the appropriate visual cues so next i'll go into some of the exciting and recent results that we've achieved with this viper system so as you might imagine if this chip is supposed to sit in front of a user's eye it has to be transparent you have to be able to see through the chip and see your environment around you one of the first steps that we focus on in collaboration with our collaborators at cnsc suny was to develop a transparent silicon photonics platform and here you can see a photograph of a fabricated transparent silicon photonics wafer we're holding it up in front of a window here and you can very easily see through the wafer with very minimal distortion and once you get this wafer you can then dice it up into individual chips and here you see a photograph of three chips inside a gel pack and you can very nicely see the grid within this gel pack it's hardly even distorted and also you can barely even see the chips that are in here and this photograph on the right shows how the chip would eventually be used the chip is placed in front of the user's eye and the user looks through the chip and when you're looking through the strip you can hardly tell that you're looking through anything at all it's very very transparent next we wanted to just to develop a passive holographic display this passive display consists of a grid of over a thousand passive pixels and we route the light from a single silicon nitride waveguide to 32 silicon nitride waveguides via an mmi splitter tree and then within this grid in each row we have a cascade of these individual passive pixels and if we take a closer look at one of these individual passive pixels you'll notice that there's three components that are varied from pixel to pixel these three components are a phase taper which encodes the absolute phase to each each pixel the eminence and tap that allows us to encode the amplitude of light that's coupled off into each pixel and these cascaded taps that allow us to produce a phase gradient across the antennas so for each pixel we have these three components that we have to encode here you see a diagram of how this passive display is used the viper display would sit in front of the user's eyes and then a virtual image is produced behind the viper chip and we use the gertberg saxon algorithm to determine the encoding for each of the individual pixels here you can see a simulation result of the resulting image here we chose to focus on a wireframe cube that is projected one meter behind the viper chip and here you can see simulation results for these three components for each of the individual pixels and again that's the amplitude absolute phase and phase gradient for each of the pixels next we've fabricated and experimentally demonstrated this passive display here you see a photograph of the experimental setup we have the viper chips and then sitting on top of the chip we have a lens that emulates the lens in your eye and then a camera that emulates the retina in your eye and here you can see a photograph of the transparent passive projector here's an experimental result of the wireframe cube that is displayed one meter behind the viper chip so now with this passive display we are able to display static images so the next question we ask is what if we want to display videos we would have to take this passive display and replace all those passive components with active modulators typically in silicon photonics we use silicon as the waveguiding material because it's easy to modulate however silicon is lossy at visible wavelengths so instead as i mentioned earlier we have to use silicon nitride and this is because silicon nitride is transparent at visible wavelengths however silicon nitride has the downside that it's fairly difficult to modulate because it doesn't have significant electro-optic or thermo-optic properties in order to address this challenge we introduced liquid crystal liquid crystal has a strong bar fringes between the two axes we use pneumatic phase liquid crystal which means that the liquid crystal molecules align in one dimension with respect to one another this means that if you have a region that's filled with liquid crystal the liquid crystal molecules will align in one direction and this in this initial alignment direction depends on some mechanical alignment layer and this alignment layer actually mechanically anchors the molecules in a certain direction then if you apply an electric field across the liquid crystal region the molecules will begin to rotate to align to this electric field and then as you increase the strength of the electric field eventually the molecules will completely align in the direction of the electric field and then as you go the other way and reduce the strength of the electric field the molecules will rotate back to their initial anchored position and here you can see a cross section that demonstrates how we integrate the liquid crystal with the silicon photonics here you can see a mode simulation this is our silicon nitride waveguide that's recessed within an oxide cladding down below and then there's the liquid crystal region that sits on top of the waveguide and here you can see a simulation of the mode within the waveguide and you can see how the mode is actually pulled up slightly into the liquid crystal region this means that as we're modulating the index of the liquid crystal we're also impacting the mode within the waveguide and here you can see a more detailed cross-section of the device we have our silicon nitride waveguide which is recessed within the oxide clotting and then we have a trench that is filled with liquid crystal that sits above the waveguide we also have these integrated electrodes that fit on either side of the liquid crystal region and we apply a voltage across these electrodes or in other words we apply an electric field across the liquid crystal region initially when we have zero voltage applied across the electrodes the molecules are aligned parallel with the waveguide and then as we apply a voltage across the electrodes and an electric field across the liquid crystal region the molecules begin to rotate to align to that field until eventually we reach the maximum voltage where the molecules are completely aligned perpendicular to the waveguide and as we're rotating these liquid crystal molecules we are changing the refractive index of the liquid crystal or in other words we're changing the mode in this waveguide so as we go through this length of liquid of liquid crystal we are inducing a phase shift so now this device is fabricated on the wafer scale at cnsc suny and the wafers are fabricated in a cmos compatible 300 millimeter process and once these wafers are fabricated they're diced into chips and then we do some further chip scale packaging in-house at mit on the top left here you can see an initial cross-section consists of the silicon nitride that's recessed within the oxide and then we have an empty trench above the waveguide and the first step we do is a dry etch to bring the bottom of this trench closer to the top of the waveguide and we want to do this because we want to get the liquid crystal as close to the waveguide as possible so that this mode and the waveguide can maximally interact with the liquid crystal then we pattern an suh resist spacer layer on top of the chip and on top of this resist spacer layer we place a glass chip and this glass chip has a polyamide alignment layer on the bottom of it and this is that alignment layer that mechanically anchors the molecules in their initial state now we form the cavity and then we inject the liquid crystal into this formed cavity and finally we seal it off with uv cured epoxy and here is a top view diagram of the final packaged chip then we have our photonic chip with these photonic devices this su-8 spacer layer is outlined around these devices and we leave an input gap and two output gaps in this resist spacer layer and then place this glass chip on top of the spacer layer and we seal it off with uv cured epoxy and then we inject the liquid crystal through this input gap then the liquid crystal fills this entire region and finally we seal off these remaining gaps another important thing to note is that in blue here you can see these metal pads which sit outside of the liquid crystal region and we touch down on these metal pads with electric probes and that's how we apply that voltage to those integrated electrodes so directly measuring phase is actually pretty difficult so in order to characterize these devices we integrate them into an integrated box center interferometer this mci has an input coupler that couples the light from a fiber onto the chip then we have a 1x2 multi-mode interferometer that splits into the two arms of the mvi we have an lc phase shifter in both of the arms of the mci then finally at the output we have a two by one mmi and an output coupler to couple the light from the chip to a fiber which then goes to a power meter and we apply a 10 kilohertz square wave to one arm of the mdi so we're modulating this top phase shifter on the left here you can see a photograph of the experimental setup here we have our final packaged chip we have an input fiber and an output fiber that couples the lights in and out of the chip and here's that electric probe that i mentioned which touches down on those metal pads that applies the voltage to the liquid crystal region and when we modulate this top arm of the mci at the output we're able to observe power modulation so here you see experimental results of the output power and when we're at a maximum power this means that the two arms of the mci are in phase and when we're at our minimum power that means that the two arms are out of phase this means that when we dip down in power and then go back up that corresponds to two pi phase shifts so for this device we are able to achieve 36 pi phase shift in a 500 micron long device within only six volts peaks peak this means that for your typical two pi phase shifter you would only need 28 microns this is a very significant result because in typical silicon nitride heater based modulators you would need hundreds of microns to achieve two pi we then also explored how varying these waveguide widths impacts the phase modulation here you see experimental results of as we increase the waveguide width we are able to increase the amount of phase shift that we see but it does take a larger amount of voltage to achieve that phase shift we also explored how varying the width of the liquid crystal region impacts the phase modulation and we were able to experimentally see that as we increase the width of the liquid crystal region we're able to achieve the same amount of phase shifts but it takes more voltage to get there and this makes sense because as you're increasing the width of the liquid crystal region you're also increasing the distance between those integrated electrodes so it simply takes more voltage to rotate the molecules so with this device we were able to show that we are able to achieve compact phase modulation we were also able to show that by integrating it into an mvi we are able to achieve amplitude modulation however this mci structure itself can get pretty long because as i mentioned before the mci has two mmis it had escalators it has phase modulators in both of the arms so overall this mci structure can get quite long so we were interested in exploring if we're able to make a more compact amplitude modulator using this liquid crystal device we explored is a variable tap device here you can see a cross section and it's very similar to the phase modulator except now we have a second tap waveguide that sits below the bus waveguide and here you can see a top view of the device we have this liquid crystal region with the best waveguide that runs underneath the liquid crystal and then we have the second tap waveguide that runs underneath the bus waveguide for a certain coupler length and then taps the light away and the amount of light that is coupled into this tap waveguide depends on the coupling coefficient between these two waveguides and this coupling coefficient between the two waveguides depends on the beta mismatch between the two as well as the mode overlap between the two waveguides and what's very interesting here is that because the bus wave guide is directly below the liquid crystal the mode and the bus wave guide is pretty significantly impacted by the liquid crystal as we're tuning it however because the top wave guide is farther down it doesn't really see this liquid crystal so the mode and the tap waveguide stays fairly static and here you can see a mode simulation of the mode in this top plus waveguide at the low liquid crystal index the mode is fairly well confined in the waveguide and then as we increase the liquid crystal index you can see that the mode is pulled up farther into the liquid crystal region when designing this device we have a few parameters that we have to work with namely this is the bus wave guide width this half wave guide width and this coupler length when designing this device we first choose a bus wave guide width and then for this given bus wave guide width we choose the coupler length to ensure that there is no coupling at the high liquid crystal index to do that we do a simulation where we sweep the coupler length for a given tap waveguide with and then for example for a tap width of 390 nanometers we would want a coupler length of 17 microns and then we can repeat the simulation for various top wave guide widths and calculate the appropriate coupler length for each tack width and here you can see a wider sweep of top weight guide width and the appropriate coupler lengths for each individual width so the next choice we have to decide is which tap which guide width do we use and for that we want to maximize the amplitude variation that we're able to achieve so now for each top waveguide width we're sweeping the liquid crystal index and for example for this 390 nanometer wide waveguide we're able to achieve from zero to 60 transmission and then again we would repeat this for various top waveguide widths and then here we show the simulation results for a wide variety of top wave guide widths and then we'll simply choose the top waveguide width that gives us the most most the highest amount of variation so for this device a 300 nanometer 390 nanometer wide tap waveguide gives us 60 transmission variation and again this is only in a 17 micron long device this is a very very compact device next we wanted to demonstrate the first integrated visible light liquid crystal phased array for this system we have one long liquid crystal region with a bus waveguide that runs underneath the liquid crystal and then we have these cascaded evanescent taps that couple some of the light that taps some of the light from this bus waveguide and route it to the antennas in the phased array here you can see a photograph of the experimental setup on this card here you can see the main lobe as well as some of the side loads that are projected by the phased array and here you see the experimental results of the far fields the main beam has a full width half max of 0.7 by 2.3 degrees and then as we vary the voltage across that liquid crystal region we're able to steer this beam and as we increase the voltage we're able to get 10.5 degrees of beam steering so the next step we wanted to do was to take that passive viper pixel that i mentioned earlier and generate this active pixel counterpart so as i mentioned earlier there are three main components that vary from pixel to pixel in the passive display these were static components but now we want to replace each of these three components with its liquid crystal modulator counterpart and this is what this active viper pixel looks like so now we have a liquid crystal phase shifter that is able to modulate the amplitude the absolute phase for each pixel then we have this liquid crystal variable task that is able to tune how much light is coupled into each pixel and then we have this lc phase gradient that's allowed that's able to actively tune the phase gradient that goes across these antennas next we fabricated and experimentally demonstrated one of these active pixels and we showed a good performance in all three of these components with our lc phase shifter as we modulate the as we vary the voltage across that device we're able to achieve absolute phase shifts for the pixels for the variable path as we vary the voltage we are able to modulate the amount of light that's coupled into the pixel and then with our lc phase gradient as we vary the voltage across that device we're able to vary the phase gradient that's applied across these antennas next step is we wanted to take this active viper pixel and then cascade it into a full display and here you see one row in this viper display this row is made up of four individual pixels that are cascaded one after another and a really important thing to note here is that the liquid crystal modulation and routing layers happen in layers that are towards the top of the chip and then in red here you see the antennas and these are in their individual silicon nitride layer which is below the routing and modulation layers and this is important because now we can take this row and duplicate it in the y direction here and now you can see that for the second row the liquid crystal modulation and routing actually happens directly on top of the antennas of the first row this is very important because it allows us to make a very compact display and here we just highlight the individual pixels just again to show how the pixels of the first display are really below the modulation of the second row the next we fabricated and experimentally demonstrated this 4x4 array and here you can see experimental results of us modulating the top row of the display you can see that we're able to turn the individual pixels on and off independently then we took this 4x4 display and we turned on the turned on and off specific pixels in the display in order to write out letters so here we're showing the letter l and we change it to i g h and t to finally spell out the word like so we are able to demonstrate a 4x4 display but looking towards the future we would want to eventually have a display that has thousands of pixels how would we do that we would do that by having a photonic chip that has thousands of these phased array pixels on it and then we would have a tft backplane chip and each of these tfts individually addresses each of the pixels in the display and then we would have this liquid crystal layer that is sandwiched in between the photonic chip and the electronic chip and this work is currently ongoing so just to summarize all of these recent displays that we've achieved the viper system through the viper system we proposed a phased array-based holographic head-mounted display we're able to demonstrate a transparent glass wafer bonding we also showed a passive holographic display that was used to project a wireframe cube we also showed compact and low power integrated liquid crystal phase modulators and amplitude modulators we showed the first integrated visible light liquid crystal based phased array we've also shown our active single pixel as well as showing a display made by 16 of these pixels as well as working towards a solution for scaling this to thousands of pixels so the current application for this viper system is a head mounted display for augmented reality this viper head mounted display would solve a lot of the issues that i mentioned at the beginning however you can also imagine that this viper system can be used for broader impacts you can imagine this viper display being used for tvs or other types of 3d displays this viper system can really be applied beyond just augmented reality and most importantly i would like to acknowledge all the work done by my co-workers at mit a huge thanks to yala nanatosh as well as monon ravel and michael watts i'd also like to thank the team at cnsc suny that fabricated the wafers this team was led by tom chris and dan i'd also like to thank our funding sources which consists of the darpa viper program the nsf graduate research fellowship program and the mit presidential fellowship and at this point i'd be very happy to take any questions lisa thank you very much i send you the the virtual and the physical clapping here so participants please uh do raise your hands uh or uh enter a message into chat uh to me or to everyone and all marshall questions through melissa but let me just kick off um with a question of my own um as you think about the scale up in transition to sort of a a real display or a real device you know there are issues such as as power and and resolution and refresh rate of those what do you think is the the most important research question or or scale up question that needs to be addressed to actually start to translate such technology into a device of some sort yeah so the biggest sort of issue with scaling it up is just how do you address these thousands of pixels uh for example for the four by four display we were able to just route the electrodes through the display but when you have thousands of pixels you just don't have the physical space to do that so the biggest concern with scaling is just how do you address these pixels and as i mentioned that one slide and we'd hope to address that with that tft backplane and then the tsd backplane itself is very high speed so the speed issues don't come with that um if you're trying to make it higher speed the the limitation would more be on the photonic side with the with the liquid crystal switching very good uh thank you so let me go to some of the questions uh in the chat here um one of the questions how does the holographic projection compare to projection onto the retina of the eye and like what um avagon's technology is as a company that's making a hypnotic display so this display actually does project the light straight into your into your retina so the way the holographic display works is the chip is sitting in front of your eye and it's projecting into your eye and then the way the wave fronts are it looks that this an image is coming from behind the display so the image is not actually being projected out into the world very good thank you um another question here related to a particular application space um how does this technology for pilots make flights or flight simulations more efficient or easier to process information more on the consumer side of a mounted virtual display sure um yeah so i guess just head mounted displays in general um so that's that's one way of sending information to the user um another way would be like heads-up displays and that would be where for example in this flight application the information would be displayed perhaps somewhere in the cockpit of the plane there's also head-down displays where the information would be displayed perhaps somewhere around the um controls for the plane um so in both those cases the user has to avert their gaze in order to get this information with the head mounted display it's just nice because it directly is in your field of view so you can be looking at your environment and just quickly gaining this information very good thank you another question in comparison to existing products uh what would the view look like through your liquid crystal display compared to google glasses now um so it's um they look fairly similar so our chip as i mentioned earlier is extremely transparent that's one of those one of our main goals so um ideally when you're looking through this chip you wouldn't see any type of blurring or distortion and then as far as the image that you see um as i mentioned this chip is directly um you know directly projecting light into your eye so you would then see an image and because it's this holographic uh modality the image will actually be displayed as if it's coming from the environment around you so that if you have a say a cube sitting in front of you and it's it's directing these wavefronts towards your eye and that really helped solve this virgin's accommodation complex that i mentioned earlier because now you can have different images being projected as if they're from these different wave wave focal plane site so now if you have say someone sitting in front of you a meter away you can place a so-called name tag that only you would see that would remind you of their name and then you could have someone standing two meters behind them and again you could you could have like a little name tag on that person so you can really have these these images as if they're coming from different focal points in different places in the environment around you very good thank you um another question here sent to me uh directly um if you can comment on the i think the brightness um you know how would the this approach potentially solve the dimness issue with competitive approaches and so we haven't directly characterized the brightness yet however with this device the liquid crystal itself does not introduce significant loss so really the only loss would just be the intrinsic loss in the waveguide so really most of the power would be projected out of the chip into the image so you're able to achieve bright images um thank you another question um maybe they the comment maybe they missed it but how do you plan to scale up the liquid crystal integration into a large scale fabrication process so this slide as i mentioned we have a photonic chip that has these pixels on it and then this tft backplane chip that has these uh electronics on it and the liquid crystal layer would be in between these two chips and currently the we do the liquid crystal packaging you know on the chip scales at mit and that's just because we're sort of developing the process but we're actually working in collaboration with copen on this and they already have developed a process where you can actually do more large-scale liquid crystal packaging and they do it in an automatic process so you can really then start doing it on the wafer scale very good uh thank you so i think with with that we're probably at a very good time to again uh melissa thank you very much for both the very interesting work uh and the the phenomenal presentation uh and participants thank you for your time uh so i sent you the physical in the virtual clap again and i do want to remind everybody um so we are twice a weekly engagement with the mit student community and on tuesday july 14th at 11 am our our next speaker will be ali kalatipur speaking about new frontiers in terahertz quantum cascade lasers uh so with that uh movies again thank you very much participants thank you everybody stay safe and have a good remainder of your day so thank you thank you 