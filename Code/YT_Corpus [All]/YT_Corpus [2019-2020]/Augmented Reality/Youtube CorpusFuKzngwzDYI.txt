 Augmented Realty has the power to visualize any data that we want in the real world, from creating deeper, more enriching educational experiences to previewing decorations in your house. AR Foundation for Unity adds high-level functionality, which allows you to build cross-platform AR content, which then integrates features from both ARKit and ARCore, making it easier than ever to create immersive experiences from multiple AR devices. For more information, see the first video linked in the description below for a full overview of the package. Now AR offers a wide range of possibilities of what we can do. But what if we really want to dial up that immersion? Well, in this video, we will go over a few techniques that you can implement right now to make your experiences even more impressive. All we need to do to get started with AR development is go into our Package Manager and import AR Foundation, ARCore if you want to build for Android, and ARKit if you want to build for iOS. Keep in mind, you will need access to a Mac running Xcode to build and deploy your iOS projects. So let's start with lighting. Imagine we have two objects in AR space; one is under the table, and one is above. The first thing that we would expect is that when a shadow is cast on the lower object, it would get a bit darker. This is where light estimation comes in. We can use a shadow to decide how intensely our object should be lit. Well, let's say we have a  model in a room that has got all the lights on. If we turn those lights off, we can use light estimation to adjust the brightness so that the model more accurately blends into the environment. Now, to actually apply light estimation to our Scene, we are going to click on the AR Camera GameObject, go to the Light Estimation Mode setting, and change that to Ambient Intensity. We will also need to go to our Directional Light, Add the Component Light Estimation, and we are going to drag our AR Camera onto the Camera Manager field. From there, we need to redeploy the project, and Light Estimation will now be in our Scene. Now when we deploy the project, our model will now adapt its lighting based on the environment around it. One of the things which can break immersion is if we see an object that should be reflective, but does not reflect the environment around it. Objects that would have reflective surface are very much 'make or break' an AR. We can solve this by using real-time reflections. Since we already have access to the mobile device's camera, we can actually just take that feed and use it as a Texture for our Reflection Probe; meaning that as we move around, the reflections appear to be based on the real world behind us. Now that we know where that is, let's implement it into our project. Start by going over to the Hierarchy and creating a new empty GameObject. From here, we will add the Component AR Environment Probe, which will also come with the standard environment probe. Then drag this down into our Assets window, which will then create our Prefab. Now, let's delete the original and go over to our AR Session Origin GameObject. We are going to add the Component AR Environment Probe Manager, and then drag our newly-created Prefab onto the field. Now if we redeploy our application and we use a reflective Material, we can now make use of that environment probe we created based on our camera feed. Finally, let's take a look at Plane Occlusion. This is a technique that allows us to make models appear as if they are behind an object in our environment, based on planes detected already. When we create a plane in AR space, AR Foundation generates a Mesh based on where it detects a flat surface in the environment. We can then use this Mesh to hide objects behind it. If we also disable the visualization of the plane's Mesh, we can make it seem as if the physical object is occluding the digital object. And the best part about this is how easy it is to implement. All you need to do is download the Shader that is linked down in the description below. We are going to right-click and Create a new Material, and we will place that Shader straight onto that. For this project, I am dropping the Render Queue position down from 2000 to about 1000, to prevent any kind of conflicts happening there. Feel free to change this based on your own project. We can then place that Material onto our AR default plane. And now if we redeploy our project, we will see that any object below a plane that has this Material on will now be occluded. These are a few techniques that you can start applying to your own AR content creation, in order to make it that bit more immersive. If you're interested in learning more about AR content creation in Unity, or XR content more broadly, we have added a link in the description below where you can find a link to our Unity Learn page for even more information. Thank you for watching, and we will see you next time. 