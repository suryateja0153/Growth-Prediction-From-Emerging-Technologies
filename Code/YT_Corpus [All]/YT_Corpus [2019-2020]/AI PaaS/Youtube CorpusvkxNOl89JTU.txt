 [MUSIC]  Hi. My name is Brenda Bell, Program Manager of the Azure Compute VM size team. Today's Agenda, I would like to walk through what are some of the new VM offerings that were recently released, what they are, and what some of the values that you might get by using them. We'll also have a quick video as well. Azure provides a solid foundation to run your core applications. When you think about the broad category on investment for customers running business critical workload, the three categories that come up most often are the comprehensive infrastructure that deliver choice and flexibility. We have choice ranges from Windows or Linux, Intel or AMD, with GPU accelerated from Nvidia or AMD, single-tenant or multi-tenant. As your footprint grows, your need for increased scalability, with great performance will continue to be important to meet that need. Cost-effectiveness and cost automization are always key priority as well. We'll talk about some of the VM offerings that were recently released and how this will contribute to some of these categories. With Azure we offer infrastructure for every workload, be it the virtual machines or purpose-built bare-metal, DevTests application, customer facing applications, or mission critical production workloads like SAP. We have VM Series that optimize for compute, memory, storage, or GPU intensive workload and this portfolio is growing constantly. For example, the AMD Dav4 general purpose, Eav4 memory intensive VM database on the second generation of Epyc 7452 processor. We have expanded the availability to 16 new regions. This wider deployment offers your organization the ability to span and run your application around the world. The region availability will allow you to build solutions with higher availability and improve the uptime of your applications. We also have recently announced a new Intel Cascade Lake-based, general purpose Dv4 and memory intensive Ev4 offering. They are better performers than it's previous version Dv3, Ev3. We will deep dive a little bit more on this new VM offering later in the presentation. In the high-performance computing space, we recently GA'd the HBv2, which are designed to deliver leadership class performance, message passing interface, MPI, scalability, and cost efficiency for variety of real-world HPC workloads. In CFD, FGA, weather simulation, Earth science. This is powered by the AMD rams, CPU and Mellanox HDR infinity band interconnect. Customers can run a single MPI job on a HBv2 at up to 36,000 cores. For our large cores customers, HBv2 VM support more than 80,000 cores for a single job to deliver performance. That's vital to some of the world's largest and most powerful bare metal supercomputers. With our GPU VM offering, early this year Azure launches NVv4 VM Series with a hardware partition GPU to offer affordable and right sized GPU VMs to fit the workload requirement. Azure is actually the first public Cloud to launch AMD data centered GPU for VDI, graphic and gaming workloads. Giving the customer the flexibility to choose a VM with one-eighth of the GPU and scale up as needed to use one-fourth, half or full GPU. The NDv2 VM series are the current generally available scale up and scale out AI and HPC GPU offering. Featuring A in a video Tesla V100 MV linked interconnect GPU with 32 gigabyte of memory each and 100 gigabit per second EDR InfiniBand. These VMs are ready for the most demanding machine learning models and distribute AI training workloads utilizing Cuda, TensorFlow, PyTorch, Cafe, and other frameworks that support the Nvidia Nico 2 for distributed GPU work out of the box. However, we are also excited to review a new product currently entering preview that build upon this offering. We will talk about that a little later. Workload built for the NDv2 should just work on our new NDA100v4, which will offer substantially increased capability for large models. As mentioned earlier, we recently announced a new Intel V4 VM family. The availability of this new general purpose and memory optimized Azure Virtual Machine based on the second generation Intel Xeon Platinum 8272, Cascade Lake. This custom processor runs with a base of 2.5 gigahertz and can achieve All core Turbo frequency of 3.4 gigahertz. With the new Dv4 and Ev4, that surpass the price and performance ratio of the previous v3 version, which is up to about 20 percent per improvement, depending on the workloads. For the easier VM sizes is, increase the memory to 504 gigabyte of RAM and also support ultra SSD in a certain region. The new Dv4, DSv4 or Ev4 and ESv4 virtual machine, the subscript of D, indicate Disk, which includes a low code data temporary disk. We offer 50 percent more storage compared to the Dv3, Ev3 instance, as well as better local disk IOPS for both read and write operation by using a gen two VMs. These VMs are a great fit for the applications that need access to high-speed, low-latency local storage, including those that need temporary storage of data for temporary files and caches. We also introduce a new sub-family for the first time. The new Dv4, DSv4, and Ev4, ESv4 Virtual Machine, to new category of the virtual machine, which rely on the remote disc and do not provide a temporary local storage of the host and the VM. We offer the size from 2-64 VCPU, and on the Es family is up to 504 gigabyte of RAM. These new VM sizes are similar to the DDSv4 and EDSv4, VM sizes which provide an improved CPU performance of up to 20 percent compared to the previous v3 version depending on the workload. As you recall, since the introduction of the Azure IaaS, every VM had a drive volume mounted that are backed by the local disk of the host, as you can see here in the D drive. Though this, time disk are not persist, that drive could be used for different purposes like, OS pagefile automatically done when you deploy a VM with the window as a guest OS or tempdb of the database. Some of the customer example where they use it in the automation as immediately store to copy the SAP installation bid on those volume, extract the compressed content, and then install from there. As I mentioned earlier, the new Dds v4 and Eds v4 offer up to 50 percent larger local storage competitive v3 version. With the new VM that has a no local temp disk, that SDS v4 and Es v4, you can see that there is no longer temp disk. That means no D drive. The OS pagefile has now moved to the OS disk that will allow you to continue to deploy your Windows image without issue. Both VM offerings still allow you to attach remote HDD, and Premium SSD, or Ultra SSD as a remote storage option. We understand that this could be a bit confusing, since the news of family that do not present a temp drive or resource volume and now name DODS or UOES. Whereas the subfamily that represent the same capability of having the same local disk support as the v3 version and now named Dd or Dds, means that you are looking at matrix like this. For Dv3 that which had local disk, with a v4 version, the one that with the local disk is called Ddv4. Now, with Dv4, it's a VM version that doesn't have the local disk. In summary, if your workload that's you need a fast cache access to the local disk, then use the Dds v4 or Eds v4 version. If your workload doesn't require the fast local disk access and mostly rely on the remote disk like the DevTest application or game server, then try out the Ds v4 or Es v4 VM size. Now, let me pass it to Rishab where he would do a quick demo on this new VM offering.  Hello and welcome. My name is Rishab Verma, and I'm a PM in the Azure VM site listing. Through this demo, we hope to showcase what's new in Azure's D and E series v4 offerings. A quick important note regarding my terminology, through the course of this demo, I refer to VMs without local disks as this last VM, so please remember that. In this demo, we launched Ev4 instance of E series VM from Azure command-line interface. We then launched an instance of the v4 D series VM from Azure portal. We then compared specs between few different sizes of the D series family to specifically focus on spec differences between v3 sizes and the newer v4 sizes. Finally, we'll talk about some of the performance improvements with our new v4 offerings. Let's begin with the developer-friendly method of creating Azure VMs. Here, we'll create a new v4 instance of the E series. A simple one-line command, as showcased here, creates an E4 Dsv4 VM with the Windows 2019 Datacenter image. For those who've been following Azure VM naming dimension, available in our documentation, the small letter d in this VM limb, the e4, ds v4 indicates a local desk is present in the size. After creating this VM from Azure CLI, when we check its configurations, we can see temporary storage is available, as showcased here. For customers who'd like to take advantage of the local disk in their VMs, can still do so, by opting for the newer v4 disk options available in Azure's D and E series VMs. Now, let's use Azure Portal to create our next instance of a disk class, Dv4 VM. Let's use the created resource option. Upon selecting "Virtual machines", we jump into its configurations. For the purpose of this demo, we'll again use Windows Server 2019 on this VM size. Here, we'll select a D4s v4 from the "Select site search" option. Then we'll hit "Review" and "Create" to launch the VM. Once we launch D4s v4 size VM with a Windows image, we can see there's no longer a local disk available in the VMs configurations, therefore, implying its diskless attribute. As you may already know, the pagefile used to be on the local temp storage disk. However, for diskless VMs, the pagefile can now be found in the C drive, as shown here. Moving forward, let's do a spec comparison between v3 offerings and the new v4 offerings in the D series family. Specifically, let's pick the D4sv3, the D4 v3, the D4ds v4, and the D4s v4. Narrowing down to the four options of the D series family, so the key takeaway here are D4s v4 size, the first option here has no temporary storage. The "0" in the temp storage column again, showcases its diskless attribute. Our newer v4 D series VM with a disk, in this example the default Ds v4, now has 50 percent more temporary storage offering than its previous v3 option, which is the D4 v3 size, as you can see here. To showcase performance improvements, let's take the default Dsv4 and let's compare it with the D4sv3 option. Using IOPS's benchmark tools, we conducted a throughput comparison between these sizes, both which have four vCPU and belong to the D series family. There is a significant increase in this throughput with the newer v4 offerings. In this particular test case, we found an increase in drive IOPS of about 26 percent in the v4 offering. Finally, to measure CPU performance improvements, we ran the Geekbench 5 benchmark tool among these sizes. While there is a gain in CPU performance of about 20 percent with the newer v4 offerings, in this 4 vCPU size, we found an average increase of about 14 percent. Thank you for watching this demo. We hope you found this demo informative and useful.  Thank you, Rishab for the demo. Next, we would like to talk about the scale and performance. Application Performance matters, for some application, is what make happy customers and grow the business. Other just want functions without a certain level of performance. Many factor can affect the performance of your application, and we continually improve the performance of the underlying infrastructure and the VM that we offer. Performance can also mean raising the limit of what possible on the VM. We are announcing the public preview of NVIDIA T4 GPU based, NCasT4_v3. Optimizing for machine learning inference workload. The new VM series offer better cost per performance ratio for inference workload compared to existing NC_v1 NVIDIA KAD GPU or NC_v3 NVIDIA V100 GPU skilled on Azure. Customer can also take advantage of the dedicated RT cores for real-time raised chasing in the T4 GPU to run graphic application. These are some of the spec of the new VM offering. Initial preview is in West US2 with more regions planning in the coming month. A high-performance offering have always been about pushing the limit of what possible for our customer using the latest silicon at a greater scale. With computationally demanding natural language model at the forefront of the AI today. We're excited to review our next-generation scale up and scale out GPU VM for AI and HPC. The ND A100 v4, VM Series start with a single VM and 8 NVIDIA and pair A100 GPUs. But just like the human brain is composed of interconnected neurons, our ND A100 v4 based cluster can scale up to thousands of GPUs. Each individual GPU is provided with its own dedicated topology agnostic, 200 gigabit InfiniBand connection for 1.6 terabit of clustering connectivity per VMs. Put another way, this mean GPU to GPU bandwidth in a large clusters, 16x higher than any other public Cloud offering harnesses transparently through standard multi GPU programming library. Like NVIDIA [inaudible] and backed by all-new Azure engineering, AMD roamed, PCIe Gen4 powered platformed. Most customer will see that immediately boost of 2 to 3x compute performance over the previous generation of system based on NVIDIA VM100 GPU with no engineering work. The ND A100 v4 is the next generation of standard oriented AI supercomputer available on-demand air scale in the Cloud. Limited private preview is available now with an expanded availability public preview coming soon. The last category that we will talk about is cost-effectiveness. Especially in the early stage of the Cloud adoption journey, we see customer being very focused on costs as they shift from a CapEx to an OpEx model. Our approach to cost-effectiveness is center around flexibility of consumption model and pricing advantage options available on Azure. First off, we offer Azure Reservation one or three years time. We can reduce a Cloud consumption costs significantly up to 72 percent compared to the pay as you go price, with one year or three years term on Windows or Linux VMs. When you combine the cost-saving gain from the Azure RI with the added value of the Azure hybrid benefit, you can save up to 80 percent. Azure Spot VMs, which gives you access to unused Azure compute capacity at a deep discount of up to 90 percent to one workload and non-time-critical and can handle interruption. Batch processing jobs, dev-test environment, rendering, and more. This VM may be evicted within 30 seconds of notice if Azure need the capacity. Both Azure reservation and Spot Vm option available for any of the new VM offering that we have mentioned earlier, like HBv2, AMDv4, and Intel v4 VMs sizes. Your customer will be able to take advantage of this pricing option with our latest VM offering. For example, some database workload like SQL Server or Oracle require high memory storage and IOPs bandwidth, but not a high call count. Many database workload are not CPU intensive. Azure offers certain VM size where you can constrain the VM vCPU count to reduce the cost of the software licensing while maintaining the same memory and storage in IO permit. The vCPU can be constrained to one-half or one-quarter of the original VM size. This new VM sizes have a suffix that specify the number of active vCPU to make them easier for you to identify. For example, the current VM sizes with the standard E32-ds_v4, come with 32 vCPU, 256 gigabyte memory, and tempt us with 1,200 gigabyte, with the spec of the IOPs identify here. The new VM sizes on Standard E32 dash ads v4 or dash 16ds v4 come with the 16 active or 8 active vCPU rather than the 32 as identified here. While maintaining the rest of the spec of the Standard E32 v4 for memory storage and IOP bandwidth. These constrained core sizes are now available on the new VM offering, for Msv2, Esv4, Edsv4, and Easv4 coming later under the year. The licensing fee charged for the SQL Server or Oracle are constrained to the new vCPU account. As you can see, with the approximately 14 K licensing cost per active vCPU, the constrained core size can result in 50 percent or 75 percent saving because of the reduced active vCPU core count, from 32 vCPU to 16 vCPU or 8 vCPU. These new VM sizes allow customer workload to use the same memory, storage, and IOP bandwidth with optimizing the software licensing cost. Azure is steadily reducing the price per performance rate for the SAP workload. We know that SAP is the core of many of your business process and is a mission-critical application for your enterprise. SAP introduced their own measurement and sizing metrics called SAPS, where 100 SAP is equal to 2,000 order lines items processing per hour. What I mean is that the higher the SAP is, the better it is. So with latest SAP HANA Certified Edsv4 VMs, it will allow you to lower your cost to run your SAP business. the smaller memory VMs, as you can see in the chart it has up to 50 percent reduction compared to the older VM families, to achieve the same set numbers. For the larger memory VM sizes, it is up to about 75 percent of the cost-saving compared to the older VM families. Last year we have announced the Dasv4 and Easv4 VM offering. This virtual machine feature the AMD 2.35 gigahertz, epic 7452, second-generation processor. Dav4 VM offer up to the 96 vCPU with 384 gigabyte of ram, while Eav4 VMs with up to 96 vCPU with 672 gigabyte of ram. Below with Azure Compute Unit, ACU 230 to 260. This new Dasv4 and Easv4 virtual machine family, a SAP NetWeaver certified VM. The increased performance of this VM family provide a low price to performance ratio, driving down a total cost of ownership. With the highest CPU performance, that is with ACU of 230 to 260, D64asv4, and E64asv4 filled the gap in performance portfolio that require more expensive solutions before. Great business process report on a single vCPU as salary SAP application, psi processing. Benchmark can often be a useful tool for assessing your Cloud option. It is important though, to ask if those benchmark would conduct by independent third-party and whether they used today industry-standard methods. The image here show the per price-performance comparison from the February 2020 GigaOm performance benchmark per price. An independent study by GigaOm compare SQL Server on Azure Virtual Machine to AWS EC2 using a few tests, deliver from the industry-standard TPC-E benchmark. GigaOm find that Azure was up to 3.6 times faster and 84 percent cheaper than the AWS that using Azure Hybrid benefit and three years reserved instance. This result continue to demonstrate a SQL Server runs best on Azure. Here are some of the actual resources to learn more about our offering. Thank you for hanging out with us today to get a quick update on what we have in our list of VM offering, and hope this has been helpful and thank you for watching. [MUSIC] 