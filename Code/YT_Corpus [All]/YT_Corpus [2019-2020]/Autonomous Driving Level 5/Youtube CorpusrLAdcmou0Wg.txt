 hi I'm Phil Kopelman from edge case research and I'm going to do a whirlwind intro to the UL 4,600 safety standard for autonomous vehicles let's start with the basics of you all 4600 this is a standard issued by underwriters laboratories which is a non-profit standards development organization the standard was approved by a standards technical panel that includes developers suppliers universities government insurance Assessors international representation and so on you all 4,600 was issued in April 2020 for light vehicles another version is underway as of summer 2020 and a new version for trucks 4,600 - 2 also is starting off in summer 2020 youõll 4600 takes a goal based approach so rather than saying this is how you have to do the various tasks it talks about what the goals are to make sure you've done whatever tasks you choose to do properly and with enough coverage to ensure safety it works with other standards to avoid gaps in the safety approach the strategy of you all 4,600 is that it standardizes the safety case assessment approach or what's a safety case a safety case generically has some claims what is safe me it has some arguments why do we think our vehicle is safe and it has some evidence where's the data 4600 helps make sure that the evidence actually supports the arguments and that the arguments actually support the claims so rather than being a big pile of documents this results in a structured argument that someone else can understand and say yes indeed it looks to me like the claims are true it has extensive lists of pre seated hazards to say yes this is something you should worry about now maybe it doesn't apply to you but did you think of that did you make sure you covered it to reduce the chance of a missed hazard finally 4600 takes a system-level approach to safety now why would you need to do that a lot of the emphasis has been on driving safety and you have functional safety what if there's a fault inside the vehicle and you have safety of the intended function so diff what if there's something strange going the environment sure those are important and you all 4600 says you have to do them and includes a chapter specifically about machine learning and autonomy to make sure you cover those as well but in fact self-driving cars to be safe need to do more than just drive down the road the issue is there's no captain of the ship so to speak so here's a nice kid cute kid kids in the car seat is it okay to go well no of course not there's no seat belt somebody or something has to be in charge of all the things that are other than driving that also affect the safety outcomes that includes life cycle things what about making sure maintenance gets done handling incidents what about infrastructure what about of the cloud computers go down and you are depending on them for an HD map updating what about other road users and also the environment you have to detect operational design domain violations and do something reasonable about them rather than assuming that everything will be perfect on the first day 4600 adopts a feedback approach the idea is that it's unlikely you will think of absolutely everything possible in the first day and even if you do the world will change out from under you so you're going to have to have field feedback the feedback largely takes the form of spies safety performance indicators for example in this picture there's a kid next to an adult and the perception system does not see the kid but does see the adult well the kid is not going to get hit by the self-driving car because the car will avoid the adult but what you would like is some feedback from the field knowing that you got lucky so you can fix the root cause problem before in the future the kid runs out into the street and you get unlucky because you had no idea that kid was their spies Metro several things one is is the system behaving safely but another one that's just as important is are the assumptions in the safety case true is our assumption that we've accounted for all the possible objects in the environment actually true or are we seeing things that we can't classify but we're getting lucky so we didn't worry about it also does the field data look like we expected to there are feedback loops required by 4600 to diagnose and fix the root cause of alerts caused by spies feedback not only helps you fix bugs with a design but also helps you fix problems with a safety case and improves your risk evaluation you can find more documents more extensive tutorials and the ability to view the standard for free at the below web address with that I'd like to thank the organizers for inviting us to this panel and I look forward to an interesting discussion 