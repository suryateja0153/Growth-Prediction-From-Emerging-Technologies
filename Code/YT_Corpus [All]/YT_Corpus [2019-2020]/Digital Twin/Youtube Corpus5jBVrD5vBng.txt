 okay hi everyone I'm Matt Vogel a program manager on the azure IOT solutions team and I'm will Gaiman I'm a program manager on the hololens and computer vision teams and the purpose of our teams is really to help accelerate partner development across a sure as IOT and cognitive services and so we're here to tell you a little bit about how we're combining our two worlds together and what that means for you guys as developers as a little bit of a brief intro I'm sure you're familiar with this talk track already but Mike stuff has gone through a few phases lately we started years ago with the cloud just getting people to send storage and compute to other people's you know other people's locations other people's data centers really helping people get on board it to Azure eventually we started realizing that agile can actually be the place for all of these new connected devices whether it's in industry and manufacturing whether it's in a smart building in retail and health all these devices have a way to get to the cloud and start sending their data up to Azure so you could start deriving insights and intelligence from that now that we have more and more devices connected we're noticing new connectivity protocols as well as new ways of interacting with your devices and so that's where the edge starts coming in so if you take the example of a people counting device you want to use the edge for something that would learn in the cloud but then send the model down to your device that way you could actually start analyzing that video locally instead of wasting all your time and all your bandwidth sending that video stream to the cloud as well as not having to worry about privacy privacy and security with your device data once it's sent to the cloud finally we also now have artificial intelligence and mixed reality and that's both an input into your cloud as ways to now understand your environment as well as new canvases to create new experiences for your solution and so the whole purpose our presentation today is to really tell you about the opportunity we have to bring IOT and mixed reality together and how we're starting to empower those types of experiences to ground us in some common terminology we just want to tell you a little bit about how we think of mixed reality is Microsoft for us mixed reality is a spectrum across what you might call augmented reality where it's really a transparent pane of glass over your physical environment to virtual reality where you're immersed in that experience in your living in the digital world for Microsoft we want to empower all ends of that spectrum through various devices whether it's through hololens or through a head-mounted displays through I phones Android tablets and so on so we're investing in a wide variety of ways to help accelerate your development across these experiences now when you're starting to build out your solutions it's important to also understand the real world in context of your solution and that's where what we have as digital twins fits in so for us a digital tween is a way to fuse your physical world with your digital world with mixed reality than being that canvas and so when we think about IOT and digital twins we go across a few different domains we call them things insights and actions or systems context and processes so what you have here is IOT allows you to source data from each of those pillars so with devices we talked about different ways or different protocols of communicating with those devices how do you send insights back to those devices how do you do command control with spaces it's all about understanding the context of the physical world how do you start sourcing data from things like an AutoCAD diagram or a floor plan and then associate that with all the devices that you already have in that space lastly are the people how do you source information about the people in your environment what's the information that you want to source and how do you do that securely and privately so that way you're not invading anyone's privacy with what you're collecting with digital twins we allow you to model all that together in terms of your spaces devices and people and now start deriving insights from those intersections as your digital twins was a platform as a service offering that we launched into public preview October of last year and at its heart it's a way to help you model your world again in terms of space of devices people but all with your industry expertise so while we started with examples on smart buildings so for example a connected office kind of scenario you might be working on a smart stadium or a smart retail environment a smart mall a smart hospital we allow you to bring your domain expertise your ontology Xand model that in terms of your digital twin and then lastly we also allow you to start accelerating your salute and act on those insights faster now that you've modeled everything cleanly and so a digital twins we really concentrate on making sure that we could allow you for multi-tenant experiences as well as invest attendant experiences to make sure that you can now scale your solutions globally and across any number of domains to give you something a little bit more concrete here this is just a typical diagram you might find of a connected office solution it's not prescriptive by any means completely flexible and so we always start with the spaces so here you might be modeling your solution let's say in terms of Microsoft's campuses around the world in Puget Sound alone we have a hundred sixty something buildings and so each of those would be its own layer of your topology within a building you might have multiple floors and then within those floors you have multiple different types of areas or spaces this is where you start getting into the interesting parts about an ontology so for example a conference room might be booked a bowl it might have resources like a team's room or a projector where as a focus room might not be bookable in exchange and you might only be able to grab it ad hoc it might just have a small phone in the room again this is where you start modeling other domains as well so you could bring in your smart Stadium and model bleachers and the stands and the field or in a smart hospital you might have an operating room a waiting room and so on once you model your spaces then you start adding in the devices and the sensors and context of those spaces and so for example here you might previously have a bunch of motion sensors sitting in one database and then your space is sitting another with digital twins we actually allow you to parent those devices to their specific spaces and so if you wanted to find out if let's say room 1 2 3 was occupied now we give you the right API is to go in and query for that room status based on the sensor values in that space rather than you having to do all that custom logic to bring those together finally we also have users and the people who actually go about those spaces not only modeling location or other information that you might want to see in your solution but also building things in a way that scales across your tenancy so we have a several role based access control api's that allow you to model who has access to what information and so you might have someone who has full admin privileges to create your entire topology versus someone who might be a device installer who has very specific permissions to install a device in a giving space in a given amount of time this is how we're starting to kind of bridge the gap between the physical world in the real world and then we'll tell you a little bit more about how we're starting to light up other experiences with spacial anchors built on these digital twin platforms yeah so Matthew's been talking about this computing shift from the old way of somebody entering in data into a PC to this new world of all these IOT sensors that are streaming data to the cloud which thanks to the digital twin service can be represented as the actual spaces and the things in those spaces that will stream up data about how they're being used the health of those assets and all that data is coming first into the cloud which flips the world from the old reactive way to now you can be proactive about the data and we've noticed that this also requires a change in how we consume and interact with this data and we've heard from partners that the traditional method of a mission control style room of people looking at PC screens packed with data and these dashboards is overwhelming and complicated and a lot of the benefits of digitizing your entire space to begin with is it very useful if only being consumed by a limited view and fortunately with mobile devices and apps like teams we now have channels to be able to push that data out onto a mobile device and give alerts so something went wrong go investigate but we think mixed reality is the way to complete the circle and be able to actually give anyone the ability to access that ubiquitous digital layer in their physical space one of the key challenges in order to realize that vision is of course it starts first and foremost with knowing where are you and you have to know your position and orientation in order to be able to pin digital information to the physical world there are of course Positioning Systems today on your mobile phone most notably the GPS but for many of you know GPS accuracy is usually around 7 meters on a mobile phone and indoors and in urban environments it can be much worse and so the spatial anchors platform is trying to solve that location problem it's trying to combine computer vision and spatial intelligence and give you a very precise location so that people can pin digital content to a particular spot in a physical space how does that actually work so an anchor for those of you familiar with computer vision slam will take a series of images from a device which would be your iPhone or Android camera or Holland's cat the Holland's tracking system it'll detect features and those images to determine the positions of those features using computer vision algorithm combine it with IMU data and will generate what we call an anchor which you can think about as an XYZ coordinate in the world that image on the right is actually our one of our office buildings and Redmond that has four storeys each of those a bright green and orange dots our anchors that are placed about all four stories of the buildings so you can create many many of these anchors throughout space and anchors live within a domain we are not building a global world map which is a very difficult problem right now we're actually creating the service so the individual spaces and enterprises can build out a particular domain of anchors and anyone that's part of that domain which is secured to that enterprise can create those anchors and any other app from any other device can locate those anchors so those anchors persist over time and can be found by anyone and the last important point which I'll show show why it's important later is that behind the scenes we're storing a graph of all these anchors together so that once you find one anchor you can find all the others so we're gonna show how this comes together in the demo so the scenario we'll take you through here is based on an open source github repo that we built in partnership with partner intern ology and this mocks up the scenario where you're the facility manager for a couple brands of hotels those brands might have multiple hotels around the world each of those might have multiple buildings multiple floors and so on kind of similar to that topology I showed you before and in this case you're actually trying to manage those devices and see what your real-time data is in comparison to your occupancy and so we'll show you a couple different ways that spatial anchor is now lights up new experiences for you to actually navigate your digital twin and then also visualize data and context of that digital twin so I'll jump over here and so you might have seen me scanning the room before and so here I see that I've placed the spatial anchor on the stage these are two different brands that I have in my hotel and so if I dive into let's say the smart hotel brand now I can see all the different building models of the buildings in my portfolio let's say you want to go even deeper so it's select that first building and so now we have multiple floors within that building and you see that that spatial anchor starts pivoting with me as well yeah thank you helps with slack on this now I could dive into a specific floor and those floors might be laid out you know differently here we're just kind of templating the same diagram again it's kind of statically in my space but I can now move around depending on my perspective let's dive in here to that first room you'll see I have three different sensors in this room I've laid out those coordinates as spatial anchors themselves and so now if I click into them there might not be close enough you can see that now it'll actually start showing you some of that real-time data which are actually pulling from the MX chip which I'll tell you about in a second let's looks like I lost it but here if I now switch views I'll jump into what we call the physical visualizer and so here again I've scanned my space before it's actually now relocating me in my space using those coordinate systems as well as the camera imagery that we had before again remember that will tell you everything's maintained as a graph behind the scenes and so we could actually find these different anchors from each other and so now here I've actually placed an anchor on top of my sensor it's an MX chip with various sensors on board so there's a simulated occupancy there's temperature motion and so on and so here we're just showing a few yeah you can see that this is just the current readings I come here and actually tap on this button that we've used to just simulate occupancy and so that will round-trip in a few seconds although with Wi-Fi here you never know and so that should kind of round-trip and a little bit as that's loading you also notice that I could pivot around and start seeing this anchor change with me there the occupancy finally changed and so for a facility manager this is actually pretty interesting because now you can actually place your anchors on top of devices in your space and if you're the repairment you can go back and now virtually visualize all this device data in context of your field of view whether your phone tablet or hololens in the case of a repair situation you might also want to do remote assists or have historical information compared to real-time information on there that's all powered by that digital twins back-end as well as connected field service and remote assist that you can now bring in in the context of your app or your solution so now we're gonna jump back to the laptop for our last demo see all the losing baseball teams I root for these New Yorkers thanks Matthew so he showed you the the kind of base scenario just being able to walk up to an a certain machine in the real world and see the digital information coming from it there's another element to that which is you at that point I mentioned about the graph where if you find one of these anchors and the device can relocate itself you can find any other anchor and this lets you actually chain together a very precise indoor navigation system without any any external infrastructure the way that this is a little demo we built in their office where it's gonna identify first it's gonna find the meeting couch and then on the bottom you can see it's found 34 other anchors and we dropped an anchor on every person's desk and you can imagine in a office type scenario these are all interesting points of interest and you can then see where everyone's desk is and you don't have to use this as you know hold your phone up your arm gets tired type navigation experience you can just I still use it normally as you would and then only hold it up when you really want to see a particular piece of information so you can imagine if if the technician is new to a space and they don't know it very well they could get it directions to the asset they have to fix someone in an office space could figure out what conference room or meeting place I need to go to the command just being used on the factory floor so we think that there's some interesting wayfinding type experiences that could be built by developers on top of this digging in a little bit into just the architecture behind this it starts with the client which can as we mentioned either be a mobile phone or Hollande's and it'll make a request to a service that just uses Azure Active Directory to get a authentication token to use on the service and then you specify what space you're in in the digital twin so it might be hey we're in the Washington State conference center right now and the digital twin service will look up all of the anchor IDs corresponding to that space and then the mobile app or the client will then find those anchors once the anchor is found it will ask cosmos DB to pull the most recent digital information from the digital twin any new information that gets streamed to the digital twin like the sensor data gets pushed by the event hub in an azure function into that database so that you're always getting the most up-to-date information and we are now seeking to make this real and so the purpose of that github repo I mentioned was to help accelerate our partner development on these things like digital twins and spatial anchor service CBRE is one of our first partners that went through the full journey of digital twins with us and now is starting to flight spatial anchors and other mixed reality services Seabury is a facility manager they have over 6 billion square feet of real estate under management today their app is in production called Seabury host where it's a smart office experience for the occupants in a space and so they help you as an occupant navigate your route your way around the environment they actually do real-time wayfinding from floor to floor they also help you find rooms that fit your needs in real time and so it's not just based on real time physical data from motion sensors to see which one is occupied or not it's also activity data so they know that let's say you want to find a brainstorming room you'll probably need something bigger something that's ok being a little louder something with a whiteboard maybe a surface hub so you can start collaborating together but if you wanted to find a coffee chat and just have a one-on-one with someone you're looking for a smaller environment something that's you know more intimate something where you have a quieter conversation all of that's now modeled behind the scenes with digital twins and it comes to life in their experience using those api's they're taking that one step further and now going out to their text in the field by using these kinds of scenarios with spatial anchors to light up all this contextual irrelevant information not just with the repair saneras that we're talking about but also now to help empower occupants so for example let's say there's a spill somewhere or the wires were broken as an argument I could take a picture of that and that would actually place an anchor for me in the system and it'll track work orders through connected field service to make sure that's tracked through completion we see a variety of different opportunities with this and we're actually excited to see not only Smart Office but a wide variety of other domains as well that's everything we wanted to show you know please get started with those various services we have spatial anchors we have digital twins we have those github repos that I mentioned that'll help accelerate your development you know we'll be around if you have any questions and I think that's everything thank you thank you 