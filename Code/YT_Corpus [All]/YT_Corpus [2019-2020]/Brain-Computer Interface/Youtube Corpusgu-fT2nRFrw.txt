 [Music] it's a great pleasure to be here at the fest this is a great event and we kicked off with an amazing keynote and I couldn't be happier to be here in this event and where we talk about making a difference and maybe a little bit related to the theme today what I'm gonna talk about is contributing to making a difference in a underrepresented part of the society I hope this is gonna be a fun talk I will try my best to make it as enjoyable as possible there are a lot of new tech involved and making a difference let's start with the boring bits this is the the usual introduction slide I'm Armand I'm jyler that's the correct pronunciation of my name I come from Berlin here in Germany I work for a company called you know again Baja and I serve as the head of software engineering there what we do is we build electric scooters electric motorcycles much like West pop but with batteries and then we are also inventing tools for the future of mobility and urban mobility I'm also a founder of something called lounger works which is a software craftsmanship school for women that is completely voluntary because we have a huge gap to to close for the between between different genders and we try to help the West we can I'm also active on github I have a lot of open-source libraries from front and libraries to Becky on libraries to brain signal processing and making music with the browser most of them are in JavaScript almost 90% of them are in JavaScript it's all open source I like everything I have written in my personal career is open source so if you are interested in any of these topics you can check out my data before we start I'm also a little bit a little bit under the weather I I had a flu for in past two weeks so if I cough during the the presentation I apologize for that I don't want to irritate your ears but I yeah sometimes I might need that so the question is very very simple the question is what is the ultimate hack of our lives and this came into my imagination while I was attending a a meet-up in Berlin and that was called Berlin HEC and Tel so hackers around Berlin and other other cities got together they do it every month at the at the end of the month and they present their hacks and these are not like software software hacks where you hack a web page or something these are like real life hacks that you use a device or a technology out of its context out of his purpose and I was participating for two times in a row with different projects and I was very fortunate enough to win the title of the best hack of the month two times in a row and then for the third time I thought if I win it again they would give me a cup you know like the World Cup if you win it three times you get to keep it because there was a trophy that they were giving giving out and then you take it back every month and the question was like you know what can I do more to impress these amazing people these amazing hackers what is the the ultimate hack and while I look no further than that myself and then my brain in fact I had the idea that maybe maybe we can do something with the brain we can type with the brain now obviously this idea is not new it's been around for a very very long time and I think last year or maybe the year before Elon Musk came up with the idea of a new country in neuro-link and what they do is they build a high-speed highway between your brain and a computer so they are building brain computer interfaces or human machine interaction devices and what they is to have to open your skull and put some electrodes there that will transmit wirelessly your thoughts to a computer or your phone so that you can type or communicate with your brain signals and he had this code I think we're about eight to ten years away from this being usable by people with no disability and I'm gonna talk a little bit more about that in a few minutes but you know Elon Musk is a great great guy but here's a little bit optimistic about everything in his deliverables as well and this is not gonna this is not gonna work in 8 to 10 years in fact this field is being tackled for the past 30 years now it's art in 1988 and we still have like 20 30 or maybe 50 years to make this work with real people with people with no disability there's a distinction between people with disabilities and not able-bodied people obviously it's a lot straightforward we treat able-bodied people like mice lab mice because you know they respond perfectly to whatever you give to them so we do the research on them but in fact the actual target is disabled people so if you have ALS if you have locked-in syndrome and if you cannot move your arm or eyes or or any muscle in fact you still deserve to communicate with the outer world because you can think there is nothing wrong with your brain in your mind other than that your body is paralyzed so it's it has its own difficulties and challenges working with people with disabilities in this context but the end goal is to make this a part of everybody's lives especially people with disabilities so that they can you know they are back back in the game so Facebook also made an announcement right after that I think one or two months after that after Elon Musk they said we're also working on brain computer interfaces and they said our goal is to build a brain computer interface that lets you type to your mobile phone you don't dictate with your voice you just think and you're gonna be able to type much faster than you can physically type with your fingers so this is like a superhuman ability or this is gonna be and she was a little bit realistic she said this is gonna be there in 20 years so we're just kicking off and you know it's it's some future technology so bear with us we'll take some time to make this a reality now this is a picture from I guess eight years ago from 2010 this is me in the picture if you couldn't identify right now and this is my assistant now I'm kidding she is she was my best friend she is - my best best friend and she was helping me out with this experiment this is right before a live broadcast where I demonstrated a brain computer interface where I typed with my brain signals in real time on TV and I was getting ready for for that and this was eight years ago so this tweet is from January 6 2010 and I typed it with my brain signals all with all those Smiley's and and everything and I tweeted with my brain signals so no motor neurons involved or no muscles involved in the making of this tweet and it's still there I think in my profile so if you go way back eight years back you can see that this technology is actually reality right now and I'm here today to talk about how we do this with JavaScript because that is the hack part of it right it's great to be able to type something from your brain but it's even cooler if you can do it with only JavaScript and and nothing else obviously this was part of my master's thesis back at the University and I was using MATLAB C++ C and C sharp all together to make this happen right low level drivers for EEG headsets and the UI in in c-sharp that wasn't a good experience and all the classification algorithms we call them machine learning algorithms right now but that's a fancy name so all the classification algorithms were in MATLAB and it worked really good you can type up to 20 to 25 characters per minute so it's like every two three seconds you can type a single letter and if you think this thing works with locked-in patients it's the world of a difference for them you know one one day you have no ability to to communicate with your loved ones and the other day you can type like one letter or one symbol like an emoji as well in a few seconds that's that's a huge huge difference and that's why I picked up this topic again so a little bit introduction on EEG raise your hands if you know what EEG is a lot of people that's great raise your hands if you ever saw an EEG recording like this okay great EEG means electroencephalography so the basic idea is we have electrodes on your scalp and they track the electrical activity in your brain or on your skull not in your brain obviously this is a non-invasive operation so that we don't delve into our brain but we gather whatever we can from your scalp hence that's why I'm I'm bald because it works best you know life sometimes has this push a little help like when you want to do research about brain signals life takes away your hair from you and this is a perfect match so this is one of the earliest easy recordings in history that's done by a German scientist called Hans Berger I'm not making the name up I know that's the most common German name Hans and Berger but it's a very real name of a very well-known scientist in Germany in 90 in 24 so he was he had the idea that the brain is very powerful so maybe we can record electricity out of it and he came up with this experiment and this is one of the earliest recordings of brain signals however the scientific community mocked him they shot him out and they like nobody believed him for about 10 years he was struggling with this he lost all of his credibility in in the scientific community but after 10 years some people were able to replicate his results and his experiments that you know some people have different electrical activity in their brain and then they restored his his career but this is what happens to very early people if you're an innovator like this you you face the risk of being mocked but he persisted wrong and the the story is a happy ending story and he was you know he's the founder of this whole EEG thing and now you know we treat millions of patient patients every year with this technology so it's it's a groundbreaking thing but one thing you'll notice here is that obviously the resolution of the data is not that interesting it's almost like a science wave both on the on the bottom and on the top as well and obviously the equipment of the past was unable to gather high frequency high quality data from the brain it was still useful though this was still useful and nowadays we have huge improvements in technology and also we digitalized obviously everything and what this means is we now get very quality signal out of the brain and right now it almost looks like noise if you ever saw audio noise it almost looks like noise because it includes your brain signals plus all the electrical and magnetic noise around you therefore the best experiments are done in something called a Faraday cage raise our hands if you know what I fire that cage is yeah so it's completely isolated magnetically so even God can't see you inside and there are no no interceptions from any mobile signal wireless signal radio signal whatever and you and your brain signals only and that is the safest place to run these experiments but yeah so it's very very high quality you know like 96 kilohertz sampling rates which is really high for brain signals which are from zero or one Hertz to maybe thirty Hertz so we have a lot of signals that we have that we can work with and the challenge is actually huge but hopefully I will be able to demonstrate how this thing works in JavaScript so I built a node application an electron application for this and let's see if it's gonna work it might not yeah it does that because that's how live demos go right most of the time it just doesn't work so this is me sitting in my home with the same headset the same laptop and I'm demonstrating how the the typing actually works do you do you wonder how it works is this interesting to you thank you so there's a countdown and basically what I do is I just stare at the screen and the computer knows what I want to type here I'm trying to type a message hello that's the first word in hello world so that's also in on my Twitter profile if you go to my Twitter profile asleep in tweet so you can watch this afterwards so I just stare at the screen there are letters there these if you cannot up oh oh that was the wrong button let's skip forward yeah if we cannot identify them these are letters of the alphabet and they are flashing they are randomly flashing and I want to type one single letter I think I now want to type E and I'm looking at E okay and whenever e flashes I'm counting it internally oh sorry this is still the H and let's do the exercise so I'm looking at E right now and whenever it flashes I'm gonna count 1 2 3 and so on and so forth and after a certain amount amount of data being gathered the system knows that you are being excited about a single letter and that's e and all the other letters when they're flashing they don't mean a thing to you so obviously I mentioned the quality of this headset and and that is a consumer-grade headset that's why it takes significant amount of time to come up with the letter but you have you can run any any machine learning algorithm or any classifier tensorflow or whatever you want in order to identify these patterns all of these brain signals so it's actually very simple and kind of a boring watch so I just look at the screen and I cannot move I'm not allowed to move because again this headset uses contact glass solution have you ever tasted it the contact best cleaning solution raise our hands if you ever tasted it yeah one super perfect yeah we yes I love you of course I did because you know it looks like water right there has to be something special in it what is it it has some salt in it it's a salty solution cell line solution we call it and that's the perfect thing for this headset because it increases the the transmission of electrodes electrons from your skull scalp - to the electrodes so you just wet the the pads here the electrodes put it on your hair or your bald head and then you get nice signals obviously in real life in the hospitals or in actual research we use gels that are very sticky and that is that are really hard to get out of your your hair hence I had to use myself as a research subject when I was doing this research but sorry but the idea is that if you move your head obviously there is no strong connection between the electrodes and and your head and these signals are on the order of micro volts like 10 micro volt 20 micro volts that's very very small and when you move your head the muscles come into play and obviously oh yeah yes I was able to type hello and yeah I then right away posted this on on Twitter of course because why not but if you move your head what you see is in fact there is a lot of noise both due to your own movement and the movement of the electrodes it's it's it's actually a very yeah I mean you can imagine the the level of excitement that I had right it was huge so let's how do I move forward yeah alright so how does this black magic work what is the underlying mechanism for this thing now we have a hundred billion neurons in our brains a hundred billion neurons it's like the number of galaxies in the universe it's a lot it's a huge number and currently I have 14 electrodes on my scalp and the best devices that are external that are non-invasive have like 256 electrodes which leaves you with 400,000 neurons per electrode okay which means we actually don't know what's going on in your brain we have no idea what we get is a single electrical lead that gives you the sum of 400,000 different neurons firing in different directions and the worst part is these electrical signals are vectors we're at a university so I can maybe talk a little bit about math these are vectors that have an amplitude and a direction so one neuron is firing this way okay the other neuron is firing this way when you sum them up but you get zero right so imagine how many neurons fire in all the ways of 400,000 neurons and what you end up with is you know mostly zero you don't really get a lot of signals obviously in certain situations you get certain signals but it's really really hard to to get quality quality signals from the brain but obviously if we could if we had a way to go inside your brain and to implant electrodes there we could even read your dreams in fact there is research being done for this even with external high-resolution electrodes we can read what people see so it's like a live feed of what you see because all you see actually is information that's been transferred to your brain and it's processed on the back of your skull and by just reading there we can see what you see obviously very very low resolution but research is being done on this okay so there are some chemical reactions of potassium and sodium that exchange well one neuron exchanges for su and the other ones your sodium and then there is a potential difference which basically means voltage there's a difference and this is what we measure from the from the brain now if you open the skull you can with the consent of the person of their family of their Hospital and of the government because the the patient has to be terminally ill because the probability of losing the patient is really high if you open their skull and implant electrodes some people receive it very well some of the brains just reject the electrodes and terrible things can happen that's why this is not gonna happen in the next 8 to 10 years maybe it's gonna take 50 years to get all the governments on board and to make this technology a safe technology to operate but if you can do that then you can implant thousands of electrodes inside the brain then you have a lot more visibility in the actual firings of not individual neurons obviously because nobody can use 100 billion electrodes but at least a little bit more resolution but the the underlying idea is unfortunately we just don't know how it works and that is the that is the worst worst bit about this ok so what I just showed you on the video is something called a p300 signal and it's called the oddball paradigm why the oddball paradigm because I have 35 different letters that I'm not interested in I'm only interested in one symbol or one letter and that is odd you know the probability of that flashing is very tiny with respect to the other ones and therefore the name is the oddball paradigm and this has been first published about in 1988 thirty years ago by Immanuel dungeon they were able to write more type 2 point 3 lectures per minute and then you know we were able to expand this to the further 10 letters 20 letters and further so I already talked about how this thing works it works based randomly flashing letters in a matrix and what you see is that there is an action potential 300 milliseconds after you see the letter flashing and you're excited to buy it if you look at the graph in the black in the black one you see the actual signal that we're interested in and if you can read it after 0.3 seconds 300 milliseconds of the original signal you see a peak in the signal in the black signal that is what gives us this notion of yes this is what the person is looking at so this is what they actually want to tell you gather hundreds of these and and refine your judgement about what letter that they what letter they want to type the thing is the red one is the other signal alright the regular signals so if you can separate the black from the red you can do this task it's it doesn't look like really hard because there is a certain difference in between these signals but obviously these are refined these are averages of again about 50 to 100 different signals from both for the black and the red groups usually what you see is the difference is not so clear sometimes you just focus on a different letter because your attention just diverges and you know you get a lot of false positives false negatives and it's the the machine learning tasks to make sure you can separate these black from red so how do you start with JavaScript any JavaScript developers here please raise your hands okay it's okay to admit if you're a JavaScript developer I mean I have a proud JavaScript developer and I'm here to prove to the world that JavaScript can't do anything desktop mobile applications and brain signal applications although it didn't work previously because of the headset raise our hands if you know JavaScript you don't have to yeah all right so everybody can read this code right it's actually very straightforward in plain language constant mind requires bits then you do mind open and open your mind and then you read your mind to to the console now let's see if this thing is sorry he's going to work because looks like I have connection yeah so these are the real-time brain signals thank you obviously you cannot discern what the individual signals mean and you get a lot of muscle movements when I'm talking when I'm speaking or when I'm moving even when I'm moving my hands so it's pretty much all the information is invisible to the eye but there is only two types of information that you can see with your eyes and that is for example when I'm blinking and now let me do it so you see the peaks right 1 2 3 the peaks there are the cause of the blinks my eye blinks and in fact there are no different brain signals there are your muscle signals because I have a lot of electrodes around my eye here now there are a huge ton of misinformation or this information about this online people claim that it's easy to read brain signals and and they do all sorts of things with their brain signals but what they usually do is they use the muscles and muscle signals because they are at least an order of magnitude bigger or higher than the actual brain signals so again when I blink my eye that is what you see and that's mostly through my muscles and I can play with my jaw and again I'm moving a lot of muscles on my face and these are all muscle movements these don't contain much brain signals or or information in your brain signals okay I'm glad that this demo worked let's maybe move on to the other one so I'm gonna type Const minds require weights right mind that open and mind that we'd console.log now hopefully when I run this what you see is yeah here it is basically adjacent log of your brain so thank you so what you have is the the battery percentage the counter numbers so you can track each frame contact quality in an arbitrary fashion the gyro so you can also track your head movement and the levels of each electrode that's present in the system obviously these are just numbers so if you know how to work with numbers you can do anything with your brain signals and yeah this is an infinite infinite loop of brain signals and every 7 milliseconds it's like 128 Hertz every second every 7 milliseconds you get one signal or one reading from your brain and it's up to you to aggregate them and and make them make them work I wrote AC driver for the headset but then everything else is in JavaScript so not J's binding bindings and then basically all sorry all the operation is in JavaScript there is another oh by the way this this tool is open source so if you want to check the source code fork or contribute to it or welcome there is another one called brain monitor that is like a command line monitor just like this I mean the same thing in your command line let's see if it's going to work so you just like brain monitor and yeah it does and you see the peaks there this is running in your command line you can run this in in whatever machine you like in the cloud as well if you like so but yeah you can upload your brain to the cloud right all those bugs all those buzz words that don't mean anything but you can see the gyro on the top right corner and when I move my head hopefully you'll see the action replicated there so if you want to do you know Mouse tracking with your head or something and your brain signals you know clicks with the eye blinks you can you can do those type of demos in fact the the quality is kind of not not bad right now all right let's go back to the presentation and the last one is the brain bits this is the application that lets you type with your brain signals that I demoed in the video it's also open source everything again is in JavaScript it's called a p300 speller because it makes use of these p300 waves or signals in your brain and it still needs a lot of help especially with the machine learning algorithm so if you are into machine learning please lend a hand I plan to port it to tensorflow Jess and and make use of it so maybe if somebody wants to contribute I'm open for contributions ok the tech stack is JavaScript all the way up this thing they didn't have native drivers so I had to write some native C add-ons for the headset to make it talk to JavaScript but then node.js is doing the processing all the machine learning algorithm is running on on node.js in real time in fact we use the electron as the wrapper for the desktop application because you can ship this as a desktop application and of course obviously you can also put it as a webpage and have something like a WebSockets or something I use VJs on the front end anybody uses vue.js only a few people yeah it's really easy it's it's a very very purpose-built fast front-end framework and all the lines that are being thrown are done with new JS I use brain DJ s that was an existing library for neural networks and basically you can swap in any algorithm that you want you can use neural networks or I use my own classifier from ten years ago that I wrote in MATLAB it's a custom Bayesian linear discriminant analysis something like that it's called payers in linear discriminant analysis and it's the classifier that that I showed in the demo that is again optimized for for this brain task and I had to port it from MATLAB right anybody knows MATLAB raise your hands perfect one single character like the star character for matrix multiplication in MATLAB is like a thousand lines in JavaScript I had to write a lot of JavaScript forming transforming all those functions of metrics transposition and and eigen vectors and everything and had to write or find alternatives in JavaScript but I did it worked and unfortunately I couldn't find a very good function to give me the the eigen value of of a piece of data and I still use MATLAB for it I built a web server in MATLAB to sir the eigen eigen function so I function so all the processing all the data crunching is in JavaScript and there are no web service and MATLAB has the web server so it's the the roles are switched between JavaScript and node.js and MATLAB and it's serving one single function if you don't have MATLAB on your computers that's fine you don't have to it's a it's a very expensive purchase then you can use the JavaScript fallback which is not that performance all right so what do we do we get to roll electrode data that looks like noise and if you remember the graph that I showed you earlier it's a section of 1 seconds after the flash so after we flash each letter we take one single second we an epoch and we try to look for at peak right after 300 milliseconds but obviously the brain has a lot of information of a lot of different frequencies so we have to filter them out especially the low and the high frequencies so we get a specific bandwidth of frequencies that we are looking for we then cut the outliers out by a process called installation so the top 5% and the low 5% are kicked out by the way I'm telling you the secrets of my research which is publicly published anyway but nobody wants to read 150 pages of math right but if you implement this algorithm you can already start typing with your brain signals and then we normalize data because obviously the amplitude of each electron is different from time to time it changes and you have to identify what the peak is right maybe you see a peak but the actual amplitude is very small maybe it's just noise so you have to make sure you're actually looking at the brain signal and not a radio cell tower or something so we normalize data and then we do something called decimation we don't need that that many that many samples to decide actually does anybody know the Nyquist theorem Nyquist theorem a few people all right tell me please if we are interested in the signals between 1 and 12 Hertz how many samples do we need to be able to faithfully reproduce the signal of two offered smacks 24 yes because it's like a sine wave you need an endpoint and a start point to actually or a mid point to actually be able to figure out a sine wave so at the minimum you need 24 samples if you are interested in 12 Hertz I know this is a little bit technical but please don't let me lose you yeah so you remove most of the samples because nobody can crunch that metadata not even MATLAB and then you apply machine learning you use either neural networks or custom algorithms whatever you wish to identify the red and the black black signals right alright so the conclusion is people say javascript is powerful when it comes to reading JSON API so when it comes to consuming Jason api's and what I claim is it's yes it is powerful enough to read and parse JSON API is but it's also powerful to read and parse your brains API so this is a demonstration of that work and I kind of open sourced the path into your brains and now I'm looking for contributors to make brain bits or JavaScript shine again please raise your hands if I were able to change your minds about JavaScript ok a few people that's good I call it a win this is this is a good day cool yeah because I claim JavaScript can't do anything I also do music with it but that's there's the topic of another talk so thank you for coming today [Music] 