 Dear Fellow Scholars, this is Two Minute Papers with Dr. Károly Zsolnai-Fehér. Due to popular request, today we will talk about Neuralink, Elon Musk’s neural engineering company that he created to develop brain-machine interfaces. And your first question likely is, why talk about Neuralink now? There was a recent event, and another one last year as well, why did I not cover that? Well, the launch event from last year indeed promised a great deal. In this series, we often look at research works that are just one year apart, and marvel at the difference scientists have been able to make in that tiny-tiny timeframe. So first, let’s talk about their paper from 2019, which will be incredible, and then, see how far they have come in a year, which, as you will see, is even more incredible. The promise is to be able to read and write information to and from the brain. To accomplish this, as of 2019, they used this robot to insert the electrodes into your brain tissue. You can see the insertion process here. From the close-up image you might think that this is a huge needle, but in fact, this needle is extremely tiny, you can see a penny for scale here. This is the story of how this rat got equipped with a USB port. As this process is almost like inserting microphones into its brain, now, we are able to read the neural signals of this rat. Normally, these are analog signals, which are read and digitized by Neuralink’s implant, and now this brain data is represented as a digital signal. Well, at first, this looks a bit like gibberish. Do we really have to undergo a brain surgery to get a bunch of these squiggly curves? What do these really do for us? Well, now that they are digitized, we can have the Neuralink chip analyze these signals and look for action potentials in them. These are also referred to as “spikes” because of their shape. That sounds a bit better, but still, what does this do for us? Let’s see. Here we have a person with a mouse in their hand. This is an outward movement with the mouse, and then, reaching back. Simple enough. Now, what you see here below is the activity of an example neuron. When nothing is happening, there is some firing, but not much activity, and now, look! When reaching out, this neuron fires a great deal, and suddenly, when reaching back, again, nearly no activity. This means that this neuron is tuned for an outward motion, and this other one is tuned for the returning motion. And all this is now information that we can read in real time, and the more neurons we can read, the more complex motion we can read. Absolutely incredible. However, this is still a little difficult to read, so let’s order them by what kind of motion makes them excited. And there we go! Suddenly, this is a much more organized way to present all this neural activity, and now we can detect what kind of motion the brain is thinking about. This was the reading part, and that’s just the start. What is even cooler is that we can invert this process, read this spiking activity, and just by looking at these, we can reconstruct the motion the human wishes to perform. With this, brain-machine interfaces can be created for people with all kinds of disabilities where the brain can still think about the movements, but the connection to the rest of the body is severed. Now, these people only have to think about moving, and then, the Neuralink device will read it and perform the cursor movement for them. It really feels like we live in a science fiction world. And all this signal processing is now possible automatically and in real time, and all we need for this is this tiny-tiny chip that takes just a few square millimeters. And don’t forget, that is just version one from 2019. Now, onwards to the 2020 event, where, it gets even better. The Neuralink device has been placed into Gertrude, the pig’s brain, and here, you see it in action. We see the raster view here, and luckily, we already know what it means, this lays bare the neural action potentials before our eyes, or in other words, which neuron is spiking and exactly when. Below with blue, you see these activities summed up for our convenience, and this way, you will not only see, but hear it too, as these neurons are tuned for snout boops. In other words, you will see and hear that the more the snout is stimulated, the more neural activity it will show. Let’s listen. And all this is possible today, and in real time. That was one of the highlights of the 2020 progress update event, but it went further. Much further! Look! This is a pig on a treadmill, and here you see the brain signal readings. This signal marked with the circle shows where a joint or limb is about to move, where the other, dimmer colored signal is the chip’s prediction as to what is about to happen. It takes into consideration periodicity, and predicts higher-frequency movement, like these sharp turns really well. The two are almost identical, and that means exactly what you think it means - today, we can not only read and write, but even predict what the pig’s brain is about to do. And that was the part where I fell off the chair when I watched this event live. You can also see the real and predicted world-space positions for these body parts as well. Very close. Now note that there is a vast body of research in brain-machine interfaces, and many of these things were possible in lab conditions, and Neuralink’s quest here is to make them accessible for a wider audience within the next decade. If this project further improves at this rate, it could help many paralyzed people around the world live a longer, and more meaningful life, and the neural enhancement aspect is also not out of question. Just thinking about summoning your Tesla might also summon it, which sounds like science fiction, and based on these results, you see that it may even be one of the simplest tasks for a Neuralink chip in the future. And who knows, one day, maybe, with this device, these videos could be beamed into your brain much quicker, and this series would have to be renamed from Two Minute Papers to Two Second Papers, or maybe even Two Microsecond Papers. They might actually fit into two minutes like the title says, now that would truly be a miracle. Huge thanks to scientists at Neuralink for our discussions about the concepts descriped in this video and ensuring that you get accurate information. This is one of the reasons why our coverage of the 2020 event is way too late compared to many mainstream media outlets, which leads to a great deal less views for us, but it doesn’t matter. We are not maximizing views here, we are maximizing learning. Note that they are also hiring, if you wish to be a part of their vision and work with them, make sure to apply! The link is available in the video description. Thanks for watching and for your generous support, and I'll see you next time! 