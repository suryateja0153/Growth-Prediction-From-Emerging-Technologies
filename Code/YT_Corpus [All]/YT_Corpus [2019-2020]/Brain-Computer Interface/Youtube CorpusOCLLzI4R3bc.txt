 This episode is sponsored by Brilliant The capacity to link our minds directly to machines offers us the possibility of rapidly processing data and controlling those machines, but such a control interface might be a two way street. So today we’ll be looking at Mind-Machines Interfaces, often called MMIs, ways to link our brain more directly to a machine, emphasis on more directly because we already have mind machine interfaces and that’s a point that will be important for this topic. To some degree we are going to be talking about how we can jam wires into your skull, what we call invasive MMI, and why that might be a good thing, but we also want to look at non-invasive methods and those we already have and can extend on. You’ve probably heard of Mind-Machine Interfaces before, though possibly by other names, Brain-Machine Interface, Brain-Computer Interface, Neural-Control Interface, and many others, including Neuralink, Elon Musk’s new company that’s gotten a lot of attention and press for attempting to develop an MMI, and we’ll discuss some of the methods they’re using and challenges they’ll need to overcome. What we want to do today is look at those methods and challenges along with the potential advantages each might offer in both the near-term and far ahead as the technology improves, as well as some of the dangers involved. Make no mistake though, this is near-term technology, not the distant future or stuff just for a lab, I’d be surprised if we didn’t start seeing some mainstream commercial applications in the next decade, and we’ll discuss some of those today too. We should begin by considering what we mean by a mind-machine interface and my earlier remark about it allowing us to ‘more directly’ link to machines. It might seem like splitting hairs to refer to something as a MMI like my keyboard, on which I’m writing this, or your screen or speakers on which you’re seeing or hearing this, but consider just how much alteration your own brain and body undergo to utilize those. Learning to type or read or use a mouse or even just flip a light switch involves laying down new neural pathways to let you do it fast and with little thought, and it influences those thoughts too. Even far more primitive tools we used for shaping our world way back in antiquity also shaped our minds and bodies too. Our worldview altered around these devices and employing them alters us even in terms of calluses on our hands and muscle memory from employing them. Nor should we ignore that our opposable thumbs and hand-eye coordination, as an evolutionary adaptation, was doubtless a major factor in us getting where we are now. Why this matters for today though, besides serving as a reminder that MMI is not a path ahead but one we already set foot on long ago, is that most early MMI, especially non-invasive versions, are going to seek to take advantage of our existing inputs and outputs and interface methods. This has its pros and cons of course, as a quick example, one can construct a language that has only ten basic letters, and perhaps ten modifiers to create 100 symbols, or 8 letters and 8 modifiers for 64, and instead of having a keyboard that has a ton of keys and takes up a lot of space, just clip a sensor to each finger so a finger wave or knuckle bend generated that character and modifier. Needless to say if our written language had been set up with that in mind we’d all be able to learn to type easier and faster. Instead it was setup more around clear visual recognition and distinction of different handwritten characters, which is a lot less precise and uniform than typed characters, and cursive scripts were designed for rapid writing without lifting up your quill. We’ve started seeing wearable keyboards that just go over your hand like brass knuckles and I’d imagine if there’s a multiverse there’s some version of reality where some language of the number of characters I mentioned a moment ago existed and saw those wearable keyboards invented much sooner and catching on far faster and maybe never had the computer mouse become common in favor of moving your hand instead. Fundamentally MMI is all about faster and easy interface so as we go forward designing them it behooves us to ask first what the best method is, which will often be influenced by what we can do and what we’re already used to doing. That’s also critical to our first type of MMIs, non-invasive ones. A non-invasive MMI would generally refer to one where we don’t have to stick bits of metal into you to get them to work, and are generally going to be preferable, all things being equal, for a few reasons. First and most obviously, most of us aren’t too keen at the idea of having wires shoved in our skulls even if we thought it was safe, and secondly, it isn’t very safe, yet. One of our biggest problems with a lot of medicine to repair or replace damaged bits of our bodies is that our body is prone to infection and prone to treating anything foreign in it as a possible infection, causing rejection. That’s bad news anywhere in your body but especially in your brain, so it makes it more appealing to circumvent both those problems by not sticking stuff in it. A third reason, beyond discomfort and health risks, is that it’s also quite a pain to implement. It’s costly to go around shaving folks skulls and sticking stuff in those skulls for research, even assuming you can find folks willing to suffer and risk that, whereas some mind-reading hat or headband you could just take on and off is easier at every level, so research into non-invasive methods is likely to progress faster simply because there’s less resistance and hurdles to researching them or finding a market for them. More invasive and integrated options, which we’ll get to in a bit, would seem to hold many functional advantages, but as research and utilization of non-invasive options is likely to be more actively pursued, it may get a major headstart, and same as we’re not likely to change our various written languages to provide a more intuitive and speedy keyboard at this point, these non-invasive approaches might win the day simply from that headstart. All assuming you can get the job done. Reading a brain is not a simple process, especially with a skull in the way interfering with the electromagnetic signals the brain gives off. Accurate scanning is no easy trick as our brain is also 3-dimensional and thinking and memory are quite distributed and not even vaguely digital. There’s no uniform spot and set of neurons in which the word ‘the’ or ‘and’ are stored, even ignoring that those are specific to English language and do not always possess a direct and total analog in other tongues. If you’re looking for a fast way to type words from brain to machine, you might be better off just hijacking the tongue, or the nerves connecting down to it and the other key biological hardware used for speech or typing. You watch those and after a while, same as personalized self-learning speech-to-text software, you eventually get a very accurate database of which pulses are for which words for which people. Now, a quick note there, this is obviously handy for some situations but not really for speed. You are still thinking those words and saying them, and while you could probably train to think them without actually saying them but still give off the right pulses for the machine, that’s not really faster than just talking. It’s a good example of when the invasive versus non-invasive options are redundant, because in such a case you don’t even benefit from brain scanning since outside of options where actually speaking is bad or impossible, a microphone is just as fast and effective as a scanner. And of course speech to text is an example of a quasi-MMI we’re seeing grow more and more in use. A lot of times it’s where we can’t do something normally that MMI can be handy nowadays. Someone who is paralyzed or missing a limb or otherwise has some damage or limitation in play, and that can include being in a spacesuit where you can’t manipulate a keyboard or potentially in a liquid-breathing setup, as we often contemplate for very deep diving or high-acceleration space travel, where even speech, not just fine motor control, might be impractical in the suit. There’s also cases where you don’t want to move either, for instance in virtual reality you’d prefer only to move in the virtual environment, not the real world. Of course you’d also like to be able to stimulate those nerves for feedback too, so you could have touch and taste without needing to wrap someone in some very impressive suit or cocoon with a mask that could provide feeling of pressure or heat or inject smells, and that should be doable even non-invasively, as if you can read a signal magnetically you ought to be able to induce one that way too. Needless to say, it’s very handy for controlling prosthetics or drones, but again it wouldn’t seem too necessary in most cases to do this by anything invasive, and one could argue a brain scanner, even if it never involves sticking things into your body, is pretty darn invasive. Alternatively if you’re just reading the normal signals sent to perform an action, assuming the action is free to be performed, it’s just as easy to see that action instead. What good is it to intercept the thought commanding your finger to hit a key or your tongue to shape a word if you can just observe the actual act? Of course, there is some, even in unconstrained circumstances there’s a little lag time between thought and action, and the extra fraction of a second from when you think to slam the brakes on a car and actually move your foot can potentially be the difference between life and death. On the other hand, thinking in those terms, while that sounds like a great feature for improving driving reaction times, there’s also the time delay for the various data about some danger on the road to reach your brain and a decision to be made on it, so in such a case a self-driving car is likely to be even faster and better. That’s a regular issue with improving technologies whose use seems inevitable, a lot of times something that does the job better or in a more comfortable method can intercede in that seeming inevitability coming to pass. Non-invasive approaches seem better than invasive for instance, but they all rely on reading you in some external fashion, be it your brain waves, signals on nerves, eye movements, or so on, which strongly implies you can build a detector that can do this job covertly or from a distance. I don’t need to be able to precisely read your thoughts like with classic scifi telepathy to invade your privacy either. I’ve mentioned in some other episodes that one way we might improve teaching technology is if we had the ability to monitor a student for things like boredom or interest, or what they were reading or looking at when experiencing either feeling, watching their eyes and monitoring their heart rate and so on. Last week in high-tech search and rescue I mentioned how we can use low-power microwaves to pick up heartbeats and breathing while buried under meters of rubble, and of course your typical fitbit detects heart rate by shining light into your skin to watch the blood flow, rather than via electrical activity like ECG, Electrocardiogram. All very useful stuff, but a bit more creepy if you consider some of the other uses, like walking through a grocery store that’s watching everything you look at and measuring your interest, and you can take for given that if such detectors get good enough and cheap enough and routine enough that they are showing up in common personal devices, then they are going to be everywhere else too. Warning owners if someone just walked in the front entrance in a bad mood, letting salesman know if a customer is concealing interest in an object behind a poker face hoping for a better price, getting smuggled into poker games to read actual poker faces, alerting parents of concern with kids, building up profiles on individuals to be ever more and more accurate. With accurate detecting and data sorting, you don’t need to read people’s thoughts to make pretty good predictions of action or intent, and of course we ourselves learn to do this from birth. Ironically one of the most coveted applications of non-invasive detectors for MMI usage is likely to be detectors not pointed at the wearer, but rather everyone they talk to, so they can get fed precision info and predictions. Like if they’re nervous or lying or just sent a signal to move their foot or throw a punch. Now on the brain scanning point, contrary to what’s sometimes said, a MRI is not a lie detector, but neither is an actual polygraph, both can be used to detect lies fairly decently but hardly with total certainty. Similarly you can also influence thinking with a MRI, we can use magnetics to stimulate or suppress moods for instance. Both options might be improved with time of course but ultimately none of our brains are identical or static, so we don’t all use the same stuff for the same thoughts nor do we have a fixed set of connections we can’t change. That’s very handy for MMIs, invasive or non-invasive, because we can train people to new options, even laying down new neural pathways. A lot of our current methods for MMI rely on training the person in its usage to increase speed and accuracy and lower noise. Think of it like mashing your hand on a keyboard in the general location of the right letter then learning to move your finger to a precision strike of a key, then learning to do that rapidly with no real conscious effort, like those of us who type a lot learn to do. Of course these methods often require regular use and a refresher, same as many activities where if not performed for a while you need a little time to get back into the groove of it. That’s another reason I was focusing earlier on why sometimes these options aren’t all they’re cracked up to be. If I want to learn a mental command to answer my phone, that needs practice and repetition. It sounds handy and probably is, but just being able to pick my phone up in a way that indicates I want to answer it, like raising it to my ear, achieves the same thing, or a different motion which indicated I want it on speaker. Of course another alternative is just to bypass the microphone and speaker entirely by either wiring that into your head or having a detector that just picked up those signals for speech and induced the signals indicating sounds I was to hear. Potentially handy since it allows a much more real conversational experience even in loud environments. Given time and improvements, we might use such a thing for talking to people even in the same room as us, just to avoid ambient sound interference. Now non-invasive brain reading isn’t ever picking up individual neurons firing, just large average effects of thousands of neurons firing and is much harder to do deep in the brain rather than the surface. While we might get way better at that so we could pick up individual neurons, the worry about people spying on you that way means that if we do get better, everyone will start wearing the equivalent of a tinfoil hat to block that, or getting something woven into their skull to do it. So either way we’re not likely to ever see that application as mainstream use, and that means if we want high-bandwidth and high-accuracy MMI, we probably have to go invasive and start going for implants and wiring. Problem is, even if you can get a small wire to an individual neuron, which is not an easy thing, we have billions of neurons packed together, so you need something that can do surgery at the microscopic scale and with high precision and speed. If it’s only making one connection a second, your tens of billions of neurons would take thousands of years to connect to. Neuralink has been working on both the microelectrodes that might permit reading those neurons and the robots that might do the surgery, and they’ve been able to do this on lab rats to get over 3000 channels implanted in the critter’s brain and rather rapidly. I’ll link the paper where they review their efforts and discuss a lot of the mechanics involved in both their attempts and those of prior research and development. I don’t doubt they’ll be able to get more channels and faster surgical robots down the road too. Needless to say we might one day be able to get complex enough and miniaturized enough to monitor every neuron individually, rather than a handful of individual ones or small related regions, same as we might be able to replace those neurons or synapses with more artificial, compact, or faster options, as we’ve explored in our various episodes on Mind Augmentation, Cyborgs, Super Intelligence, and Transhumanism. But forget for the moment which neurons those individual lines are going to and think of it instead as a keyboard or remote with 3000 unique keys, that you could essentially program by practice, learning to flip each one with a thought, and this is technology that already works on rat brains and is already compact enough we can insert it into a skull or neck with it rather concealed and unobtrusive. 3000 is a lot of keys, and if we think of them as mental buttons, two-stroke combos would offer you 9 million. Your obviously not going to be able to memorize all those but you don’t memorize every muscle in your body either or the exact amount of signal necessary to lift your arm just a little versus strain to lift a heavy object. You don’t want these to be accidental thoughts or ones you do asleep so there needs to be a certain amount of deliberation and uniqueness to the interface, and I’d even argue that if there is not, it’s not an interface at that point, just an expansion of the brain and body. In general though, you’re aiming for as easy, fast, and imprecise as is safe, same as we usually have on more important or dangerous software actions and hardware controls. You’d practice with them and categorize them and probably get them wired into general areas associated to certain tasks and also probably be coupling this with a feedback system that could offer prompts, reminders, and key reassignment. And if you can detect a signal this way you can also send one back down, potentially producing a very unique and recognizable impulse that could serve a role akin to the pressure we get back on our finger to let us know we tapped a key properly or something a bit more sophisticated and specific. This might allow us to do even better than having a window pop up to ask if you’re sure you want to do something, since we could presumably stimulate an actual mental concern too, like tapping your brain to generate a danger-sense or mental red flag. Handy idea but an example of how you can accidentally open the back door to mind control in the sense that folks constantly getting their danger-sense tapped on decisions might become more or less cautious or anxious about life in general. It’s not the kinda of mind control we associate to coercion or malice, though could be used that way I imagine, but is an example of how a device for letting you control other things can start controlling you. Anyway, when it comes to these programmable mental buttons, more is presumably better but to be honest you can do so much with a thousand thought-keys already that it’s a huge game changer and more might just get in the way. Of course the learning goes both ways too, as mentioned there’s no single neuron on which a given word is encoded in your brain, tons fire to produce that word and if you’ve got a bunch of electrodes in there, you’re going to be able to sample with sufficient precision and accuracy to map out what was going on even though you’ve got nothing like a one-to-one ratio of detectors to neurons. It’s not going to take long to build up a pretty big and accurate database by having the person with the electrodes implanted go through a series of thought exercises. Critical notion throughout this though is that you’re not doing the classic scifi brain reader of what you think being precisely read, you’re training yourself and it to allow a new and specifically exercised thought to indicate a command. This is likely not only way easier but avoids lots of accidental commands, same as you don’t accidentally type on your kitchen countertop while cooking or accidentally dice vegetables while typing, though you’d presumably include a lot of confirmation commands same as we routinely have windows pop up asking us to confirm we’re exiting without saving or delete a document or want to complete a purchase. Now it’s very easy to imagine how the more sophisticated brain readers, potentially with very advanced artificial intelligence on the machine side, might start controlling you back, not just being controlled, or how such things could be hacked, but it’s less obvious in a case like this, where you essentially have a few thousand buttons you program by experience hardwired into your head and probably attached to a wireless transmitter that is basically just sending the number for each channel or the translation of that to a specific command on some encrypted transmission. Hacking encrypted wireless transmissions is a lot harder than fiction tends to imply and we’ll talk about that more in a couple weeks in Cybersecurity, but regardless that’s just spying on what you’re sending, not reading your actual thoughts or letting them be overtly influenced. It’s also not hard to imagine how more sophisticated versions might result in a sort of merged mind of that brain and the computers attached, but that’s less applicable when we’re just talking about that effective programmable keyboard of thousands of keys. And yet, same as our tools and technology shape our worldview in a very real and profound way, something like this is altering your thinking. Indeed, as mentioned a bit ago, we can presumably send a signal right back down an electrode to produce a recognizable sensation as a feedback. Combined with something like an earphone or smart glasses or contacts, or direct audiovisual nerve stimulation if you’ve gotten that too, it’s the thing that produces a very specific sensation that someone is ringing your doorbell or phone and lets you answer just by pushing that mental key, or dialing up emergency services and flipping them a connection to any life sign monitors, positional trackers, and camera feeds you might have on you. Or pinging a friend a ‘where are you?’ signal instead of a phone call that they can use to flip you their position with a quick but deliberate thought, or tell any cameras or microphones on you to flip on and record. Not really game changing concepts on first glance but think about the change in attitude that permeates through someone when for their entire life they know they only need to think one specific thought to summon help or check on someone, and if you predate cellphones you can probably remember how different it was needing to find a phone or try to flag someone down for a ride to town if your car broke along the road. But it’s not the individual things that really matter, it’s the whole impact of being able to turn your coffee pot on with a thought when you wake up or flip channels without needing a remote or peek into your fridge via its internal camera from your bedroom or while at the grocery store to remember what you need or just with a quick sequence of thoughts place an order for it to be delivered. You don’t lose your cars keys or have to push a button to unlock the car or start it up, you don’t mess around with a mouse or keyboard to scroll down pages or navigate or pull up a song you want to listen to, because the system is as fast and intuitive as controlling your own body. And it will get to be that way too, your own body. Even before we get really sophisticated you’d start getting a lot of apps built around expedited thinking, like the mental button you use to think ‘calculator’ that you follow up by thinking the numbers and operation and enter commands that results in it spitting out the answer into an earpiece or smart glasses or right into your brain if you’re getting good enough with the neural connections. But long before that, even with a mind machine interface that’s just a programmable keyboard, something we may well see hitting the market as early as this next decade, things change a lot. Now the non-invasive systems might, and indeed likely will, progress faster since surgery is a big step for most folks and a big liability issue for any company thinking about producing them, but those non-invasive systems offered a lot of options we already reviewed and potentially might offer something like that programmable mental keyboard too. Possibly a pair of smart glasses with earbuds and an EEG built into the frames. Fundamentally there are so many options, we’re only limited by our imaginations, what our minds can dream up and execute, and if we’ve got good mind-machine interfaces, we might get a lot better and faster at that too. So we’ve got some great episodes coming up in the next few weeks, and we’ll get the schedule in a moment, but a thing that we noted today is that any good MMI is going to be one you need to practice with, and that’s true of a lot of our modern knowledge and skills, which as we discussed today are themselves are type of mind-machine interface. It’s not only important to learn new skills but to keep up with practicing them and varying that too, you don’t want to just repeat the exact same exercises, mental or physical, but switch it up. It’s also important to have fun while you’re doing it, not just to make yourself more likely to do it but because our brains genuinely are better at developing around stuff we have enthusiasm for, and that’s where our friends at Brilliant come in. Brilliant is a problem solving website and app with a hands-on approach, and not only do they have over 50 courses to help you learn new science and math, but they also have daily challenges that can reinforce and strengthen material in your head. Personally, I love doing them with my coffee in the morning, gets the brain woken up and ready to charge ahead for the day, and starting off on the right foot too, by solving problems. They also have a mobile app with an offline feature, so you can still access the content on the go, if you tend to do your waking up while commuting. If you’d like to learn more science, math, and computer science, go to brilliant.org/IsaacArthur and sign up for free. And also, the first 200 people that go to that link will get 20% off the annual Premium subscription, so you can solve all the daily challenges in the archives and access dozens of problem solving courses. Our world is all about technology and problem-solving and it’s important to master those to succeed, in our modern world anyway, but is technology an inevitable path for intelligent species to follow or are we possibly the exception to the rule? Next week we’ll be exploring that possibility as we return to our Fermi Paradox Great Filters series to look at the idea that Technological Civilizations are a lot less common than intelligent species, in “Rare Technology”. One concern we had today when discussing MMIs was that they might be used to influence their user or spy on them, and in two weeks we’re going to take a look at Cybersecurity, and both explore the basic concepts underlying a lot of the arcane technospeak of the field and see where it might headed in the future and what challenges it will have to meet. Then in three weeks we’ll head back out to space to look at the ships that will hopefully take us to new worlds, and what sort of features they need to have and how we should design them, in “Spaceship Design”. For alerts when those and other episodes come out, make sure to subscribe to the channel and hit the notifications bell. And if you enjoyed this episode, hit the like button and share it with others. And if you’d like to support future episodes, visit our website, IsaacArthur.net, to donate to the channel or check out some of the awesome SFIA merchandise there. Until next time, thanks for watching, and have a Great Week! 