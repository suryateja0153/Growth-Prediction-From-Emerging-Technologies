 okay hello everyone I'm Victoria and we'll be presenting levy cursor today this work was done under the supervision of Professor York Mueller at the University of Beloit okay so what is levy cursor Larry cursor is a matter for dexterous interaction with a levitating cursor and the cursor can move in all three directions smoothly and it can be directly controlled by the user levy cursor as you might imagine can be implemented can be used for 3d selection of physical objects where all natural depth cues are important for the motivation of our work we go way back to the 60s - one well-known vision in HCI of Ivan Sutherland who envisioned the ultimate display as a room where the computer can completely control the physical matter so for example we can we can make a chair appear and disintegrate so it will be a truly a merge of the real and the virtual and this vision has been very persistent through the years and here we list some of the advantages of the ultimate display as opposed to for example augmented reality glasses first of all the content that it is displayed is real so we can see it touch it and the user does not need any device to interact with the physical content of the display and everybody who is in the room sees the same thing so it encourages discussion and collaboration and the 3d depth cues contrast focus illumination are all correct as we know them and also the physical matter is tangible and as we know people get up really early on to be able to process physical information so one of the implementation or one of the attempts at the ultimate display is with the method of active atoms so this is the work on programmable matter from 2005 from Goldstein and colleagues where the the physical content is created by using miniature atoms which can which can assemble and disassemble on a 2d surface now the challenge with using the active atom approach is that is the cost per unit the power supply and the miniaturization so that's why we move to a passive atom approach and here it's in the form of acoustic levitation so in our case we use a display composed of two opposing arrays of transducers which emit ultrasonic waves so the frequency of 40 kilohertz and the width in the nodes of this ultrasonic wave so we can trap small particles these small particles are the passive atoms and all the intelligence the power supply and the actuation comes from the environment and so of course you know if we want to implement this vision we want all of the particles to move smoothly at and at a high velocity and we want them to be stable but since this is a big task we start first with one particle so that's our Larry cursor and which can be used for selection in 3d space now for the HCI perspective of course interaction with such display is very important so we look at some related work so for example pixie dust pixie dust was a set up of four transducer arrays which by using the method of standing waves create a 2d grid of levitation traps and the user can interact with the system using a Kinect and that looks like this and the next example is of levee path where we have two opposing arrays with a smaller display area and the user can interact with a leap motion sensor so as we see there have been some implementations of interaction with a levitating matter however in order to create a cursor which will have the performance that the user expect there we have identified some areas of improvement for example the system needs to have low latency so of course if a user is moving the cursor we the user wants to perceive it as a real-time interaction so the latency needs to be very low there shouldn't be any jumpy particle movement or jitters and the cursor should move at high speeds and accelerations okay so now a bit of the technical side our implementation so when we have a levitating trap the spherical particle experiences acoustic force from each direction and we modeled this using an equation from a physics paper by Gore club using the work of potential which is a function of the acoustic pressure and the spatial derivatives and why this is important for the basis of our implementation we use the BFGS optimizer which was presented 2015 by mars own colleagues where we use the algorithm to generate a trap so to generate a trap at a specific point in the acoustic field we optimize the parameters for the transducers in such a way that at this point we have maximum acoustic force and minimal pressure in order to have a greater stability of the particle so - as a summary of our contributions with levy cursor we achieve a system with low latency high frame rate and smooth interactive control of a levitating cursor then we develop a mechanism such that the levitating particle always stays in the main limitation trap there are also secondary limitation traps we'll go back to this and to validate our findings we conduct the first 3d fits law type pointing study with a levitating cursor and physical targets and now I hand on to my colleague miroslaw hello so I will tell about the actual problems and how we sold them so first concerning the continuous movement of the particle in order to achieve as smooth and continuous movement as possible we need to be able to place particles at arbitrary positions and optimization algorithm is able to do that however optimization takes a lot of time to be in real time so the most real time implementation could look like the one here when the particle would jump only after 2 seconds so our solution to this problem was instead of running BFGS optimizer in real time and trying to respond as fast as possible we select our limitation volume we discretize it in a 3d grid and then for each grid point we compute phase values using BHS optimizer and we store this values into a lookup table then we can use lookup table in real time to specify transducer value right phase values to the transducers and control the levitation trap in in real time so all discretization we can do it as small steps with in our case it was half millimeter steps it still is not continuous so in this creation grid the particle would move between different points of the grid and we wanted to achieve smooth movement so I wanted to be able to move the particle in between the vertices the grid in order to achieve that we apply three linear interpolation scheme so basically we take eight neighboring vertices and compute interpolated value based on them as a prerequisite for this interpolation we need to ensure that the phases are smooth in that small region so to evaluate the smoothness we have related it for the hole limitation volume and we have identified that in 95% of levitation volume the phases are smooth as you can see on the left plot however there is still five percent of the volume and in particular closer to the transducer arrays in which the phases have abrupt jumps and interpolation in such regions with abrupt jumps would result in inconsistent phases and dropping the particle so in our algorithm we identify this abrupt jumps before interpolation and if we have this abrupt jump in the local position then instead of interpolation we fall back to the places containing the nearest verities [Music] [Music] but there are problems because we cannot actually see where is the primary trap and where are the secondary traps as you can see there is one primary trap in which the particle is enclosed with the forces from all sides and there are secondary traps which can support particle against gravity but when we try to move it the particle would drop because of lack of forces from different directions so also such secondary traps can disappear during the moment and this would again lead to dropping of the particle so our solution to this is using optical motion capture so first we create ultrasound field using transducers then we put the particle into the levitation volume the particle is observed by motion capture system so we know where it actually levitates and at this point we don't care whether it is primary trap or secondary trap we can use the place identified by motion capture system to specify where the primary trap should be and control system would identify the necessary phases for primary trap to match the position of the particle and rest at the primary trap to the position of the particle so we do this particle stabilization in the initial phase when we place the particle into the field however often when we move the particle to fast it can jump from main trap into the secondary trap so in order to avoid with jumps we would still regularly reset the main trap to the current position of the particle using the same method so our system Hardware consisted of two opposed transducer arrays with 252 transducers in total both arrays were connected to a single ultra haptics controller board using single word was necessary in order to achieve synchronization of both arrays because even if they the sound would be unseen unsynchronized fraction of milliseconds it would lead to uncontrollable behavior so the other part of the system was motion capture system from optic tract with six cameras three of them were control were checking the particle and others three were checking the fingertip so both parts of the system were connected to two workstations and between them they were connected by a local network so the workstations were optimized first one for real-time response because levitation hardware required our system to respond within one millisecond and other workstation was optimized for processing throughput to evaluate the system we performed two types of Feliway evaluation first evaluation was evolution of stability at different speeds so we have moved our particle multiple times at different velocities and we have computed frequency of particle dropping and different velocities so we have identified that at 0.8 meters per second we can have 100% stability and it drops to zero at 1.2 meters per second and up to this point this is the highest velocity reached by a levitated particle and then we have elated latency of the system using a high frame rate camera the camera was observing levitation volume we have generated an optical event and recorded the response of the system in terms of dropping the particle and then we computed the number of frames between these two events to identify the latency and on average the latency was 15 milliseconds with maximum latency 17 milliseconds which are actually both below 20 milliseconds which need to be forced this system to be considered real-time then we have performed a bit slow pointing study just to evaluate how the system is performed performing in interactive tasks so the targets were represented as spheres centered at the tips of the needles and when the participants need to move between this two needles and as soon as a levitated cursor reaches the target the participant would hear auditory feedback what we found out that the point in this levitated cursor behaves similarly to pointing with the mouse and it follows a hit slow model and fit slow model has goodness-of-fit of 0 92 and the users achieved with the system effective throughput of 4.9 bits per second which is comparable to Mouse and is only slightly below uninstrumented point in with the hand so as future work you can see there are a few directions one of them is trying other algorithms for real-time phase generation or the transducers other direction is control of multiple levitating particles for example if we have 3d object represented out of them then third Direction is using levy cursor as a selection technique to select among other statically levitating particles for example if we have some particles represented 3d visualization and we want to select parts of visualization to conclude we have implemented 3d pointing system with levitating particle which allows interactive and agile control of the particle we have evaluated the system in two technical evaluations and in interactive it's law study and we have solved our challenges of low latency smooth continuous movement and keeping particle in the main trap using pre-computation of transducer phases interpolation scheme and particle stabilization mechanism thank you [Applause] yes hello Michael Kipp from Oxford University of Applied Sciences amazing work thank you very much for the talk I was wondering about the Fitts law task which is really hasn't been done in 3d in the proper way how do you signify the targets and how does the user show that he or she has hit the target how do you clutch in a way so the targets it was a bit hard to represent them in 3d so he used needles what what about the diameter or width of the target diameter or width were not really visible but the user know the targets are the spheres centered around the needle tips and we had spheres of three sizes of two four and eight millimeters and the user would hear auditory feedback as soon as the levy cursor reaches the target okay got it okay so but did you use depth or is it basically a 2d or even 1d task so the cursor can be controlled in 3d yeah so before the actual levitate pointing task the users would try to move the cursor and control it in 3d but other challenging tasks can be considered as 1d so they are on a plane and on a on a on a single line basically so the needles that the moment of curser is 3d the task is 1d basically the task is 1d okay thank you very have spherical target Stacy Scott University of Guelph I have a follow-up question on the Fitz law test was it always this like a side-to-side motion did you do any front to back I'm just wondering in terms of the understanding of the mapping of the the input space to the emotion space is there any difference in how users are perceiving I can side to side how accurate and and depth perception so as I already told users were able to move the cursor in all three dimensions so they were also able to move it in depth and in height but we observed that that they moved basically between targets in one dimension mostly but for the specific user test you did the Fitz loss as was it just I decided or did you do any front to back target motion this was only small feet slow study so we had only this to target you she studied okay so we haven't performed studies with this type of pointing or vertical pointing thank you one last question yeah thanks for a very impressive work so how was this control display gained was said when you conducted experiment it was set one two three control to display ratio so the movement of human fingertip was observed by motion capture system and sometimes it might be a bit shaky so that's why we set it one two three so basically a bit larger movement of the hand was mapped to smaller moment of the particle okay thank you very much let's thank the the speakers and congratulate them for their an honorable mention award 