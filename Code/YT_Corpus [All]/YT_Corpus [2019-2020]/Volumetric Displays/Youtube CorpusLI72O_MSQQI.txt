 thank you good morning and thank you for coming I'm here to present light be a self levitating light field display for hologrammatic telepresence this was thesis work by Zhu Ying Lee Jung who was unfortunately could not be here she's now working for Broadcom we'd also like to acknowledge the work of Shawn Braley and Calvin Rubens in this project I'll be presenting more the background in this work one of the issues with VR helmets is that they are heavy cumbersome and the field of view is rather small and poor resolution we also lose the ability to see the world and to be seen the occlusion of the head and eyes make co-president face to face communication difficult and we don't capture the facial expressions when teleconferencing there's a need for 3d displays that live in the 3 in the real physical world so what's going on here well nonverbal cues are actually richer than you would think and more difficult to convey eye contact is crucial to multi-plug multi-party conversations and we want to preserve the head orientation and we need to render multiple perspectives as well as allow for management of personal space according to hall between 1.2 meters and 3.6 meters is the area known as social space and this is where light B operates we need to move or we need movement to convey proxemics however robots may represent the head too small or they may not be fast enough to convey those head movements accurately so now I'd like to highlight some previous systems who which have tried to address some of these issues here in early system we see Erik Paulo's there with prop series of telepresence robots that include real robots and blimps um the form factor of the wheeled robot is something you'll see in various other examples later where there is a screen mounted on the stick and moves around on the wheeled robot here are some commercial examples Ava 500 by Cisco and iRobot and on the right double - from double robotics and in terms of controlling these systems this is typically done with touchscreen however there are some examples as well where this ismy robot Brazil at all where they could capture some of the richness of the facial expressions and movement and translate that into expressive movements of the robot here's an example of tracking the head position for remote viewing through a drone and then here we see a corollary with a flying display in bit roans there are also multi projection systems so multi view was a third party or a multi party video conferencing system uses a retro-reflective screen with three distinct viewports however it did not provides terrorists stereoscopy and nor did it can did have continuous motion parallax telemon was then a system that allowed for the remote person to be represented by a 3d volumetric video it relied on shutter glasses and as such was not multi-user then we have Telus our tell us our floor actually is a system and used retroreflection projected on a robot but the robot itself didn't move beside the arm then we have pain indeed they presented an experimental setup with a cylindrical retro-reflective surface nine projectors capable of projecting nine distinct viewports the problem with this was that nine cameras were needed to capture these views so then until human two which was presented at Kai last year put all of these elements together into a light-filled electrical display that rendered the full-sized human however was not mobile has anybody seen my legs below my waist where I know Rimmer's Lex come on ladies this way over it fools 592 that's where the hologram simulation suite is so that was a clip from the British sci-fi show Red Dwarf recognize that the show features a flying hologram technology called light beam so a light beam is a small hologram projector that projects hologrammatic recreations of the dead and continues the personalities of the deceased crew members it busts around inside the projection like a b and hence the name of the device and we named our system after that so the problem is we cannot project in midair but if we fly a projection surface we can project multiple views on that surface by using lots of projector spaced apart we can create many view ports that are retroreflected by a very lightweight fabric that can fly and thus a flying light field is born each eye thus picks up a different image from a different projector no matter where you stand and that also means to get serious copy and motion parallax for free as you move along the projectors so here's light B now I just want to say it looks awful but that's because the shutters of the 45 projectors are interacting with the shutter of our camera and we haven't really been able to synchronize that you don't see that when you actually experience the system but it's very difficult to film so here's the drone it represents through a head of the remote interlocutor as a projected on light field and that means the users can see the head of the person flying around in 3d and it appears as if it's actually inside the drawing again that's not something I can show here in TV video so here we see a user interacting with the remote participant and the social proxemics are actually quite natural not only does it conserve eye contact but it's it modulates intimacy by moving forward and backwards just like you do in a regular conversation users can step forward see head orientation or make eye contact and if you have multiple users they will see natural eye contact at orientation two words their location and all that is preserved so the system is multi-user by nature alright implementation so the drone is a cylindrical retro reflective surface which is mounted on a 30-cent 38 centimeter diameter frame the drone has four brushless motors a micro multi-leaf life controller board and an esp8266 Wi-Fi board and the controller is a customized version of multi Lea software that's modified to work with the brushless motors and with our customs communications protocol because we need very very low latencies like an order of ten milliseconds roundtrip kind of time power is provided by a 1300 milli amp hour battery that sustains approximately four minutes of flight because this thing is actually quite heavy and then a unique pattern of icon markers you see those those little dots there they allow us to track the drone in real time again that goes very very fast very low latency and all that is optimized to be able to control the drone precisely within the space of the projection system one real issue with this is that the cylinder provides a lot of drag and so you don't want this kind of messy air pressure pattern underneath the drone because you really want to have a jet coming out and for that reason we use special crops that are not as efficient but they are angled and so they push air down faster it means the drone flies a little bit shorter but it does mean it flies the retroreflector fabric is very lightweight it allows the drone to reflect a projection from a particular angle precisely into 1.3 degrees so that was engineered as such one part of that that's critical is the vertical diffuser it helps diffuse the light vertically but it limits the light being horizontally and we use an RPC photonics diffuser with a fifty six degrees of vertical scattering scattering angle and that allows the drone to move up and down without a loss brightness it also allows the projector rate to be amounted above the heads of the user so then as they move along the brightness of the projection changes 50% by degree by degree in so that's how you create the light field a smart projector array is mounted on the rail of 45 Pico Pro 72 P smart projectors with each road system that renders its perspective so this is a massively parallel computer with 45 viewport renders that render in real time 45 inches each 1/10 of a second it's all the light from the projector is rect reflected in their era in a narrow area that means the pico projectors are actually quite right even in broad daylight the surround video of the remote person is produced using three stereoscopic cameras one per 20 degrees do you want to do full 360 you need nine and that constructs a 3d volumetric media of the head each that camera is connected to a high-end GG X 1080 graphics card which then computes depth images and texture maps these are them send over UDP and then software on the out roads receive that to calculate their own offset for the projector so these are the six images that you would have to send over Skype and then projector clusters of 15 projectors will go in there and calculate the plus seven or minus eight depending on where their location is in the array using a relief mapping algorithm here's how the algorithm works each pixel in the image represents a light ray coming from the back of the screen towards the 3d objects in the scene and so it's bounded by the depth map which we see here as on the top a and at the bottom B so we then try to intersect the depth map with that that light ray and so we see that there's an intersection here at number three which is incorrect because really what we want is the top intersection so we do some searching in this in the steps map until we find C which is the correct answer here and then we look up the color in the texture map and that becomes the took the color for that for that pixel mark is on top of the light be drawn aloud so patient be tracked with eight Vikon motion cameras the waypoints are set but for remote head movements by a Kinect so the Kinect measures the head movements as the person is talking PID loops them control and adjusts the quadcopter thrust along the XYZ axes and then two cameras on the drone allow for the remote person to also see the scene on to displace that means the system is only one way of present but that's not a fundamental issue it's just an issue of money we did a very limited user study of mainly because we didn't want to kill our participants with this drone so six that for dapper participants took part in the study ever asked to move around the gray area in the image here and we asked them to engage in a triadic conversation for about three minutes with an actor who is represented on the drone and in each conversation this actor made sure that whenever he was talking to the right but just when he'd be looking at them and leopardus of looking at them so making sort of clear what his intentions were with head orientations then after each session the participants were asked to reflect upon their experience initial impressions were positive most participants noted that the movements of the light be help them facilitate turn-taking better p4 claimed that the movement of the light B gave me a better idea of what the remote person was doing and p6 claimed that the light B's movement was easy to understand and smooth in terms of proxemics p1 claimed that he felt a kind of pressure when it approached me and that's exactly the kind of thing that you'd want there's very few video conferencing systems that are capable of giving you that eerie feeling that something's gonna happen when a person gets closer the drone definitely helps with that the p6 also noted eye contact was really helpful like in a class or a meeting and p2 noted that it was convenient to show the person around by moving herself and that it was cool to look around the person by moving around the light beat surprisingly only two participants complained about the noise the system currently is rather noisy for an application like this all right so some limitations well currently the system only runs at 10 frames per second that's mostly due to the Oh droids they're just not fast enough the system on chips they as they get faster that will improve it's not a huge problem ghosting is visible that's due to imperfect retroreflection when you have multiple projectors retroreflecting on a surface you might see the other projectors slightly that can we solve by using a limited form of face tracking that turns off the projectors where there's no face by directionality of course that we'd love to have a system that's fully reciprocal and that could be done by placing Zent cameras around the pod and of course I already mentioned the noisy propellers we've been looking into things like ultrasonic designs that speed up the propeller so much that the noise is actually no longer audible and of course there's also anti sound solutions or we could just change the whole design to use for example gas propellants or something like that so but that's something to look into for the future for sure alright so concluding we presented light be a drone based hologrammatic video conferencing system that uses a retro-reflective multi-view projection system to create a high resolution light field transmission of 720p it supports multiple participants without any need for glasses or headsets and allows for moving proxemics as well as 3d facial expressions to be transmitted fully and with that I'll take questions [Applause] thank you very much I already see a hand up I'm Claude - pianist from IBM research first I mean congratulations and cred remount of work there and I guess he have done much less that I know but one thing I was thinking is what the drone gives you that I mean give you an installation it could be using a tethered arm from above or for our wires this kind of extension what what you get em get more time a lot more flights a good question yes we could suspend this on the wire I think one of the reasons is the drums because we've done a lot of drones work this comes out of bit drones and so we have to control so we had all that but I think also there's there's a lot of benefits to having drones first of all the face appears inside the drone so the drone disappears because it's just a retroreflector so the whole thing disappears and with the wire you don't really get that sense so the moment you introduce an artifact that's not real people just know that this is not real and it just pops the whole telepresence thing drones are also very responsive in the way that a tentative system would be difficult to build so there's a bunch of reasons and finally if you fly out of the room you can actually go and inspect your building site for example so you can have a communication with someone and then go off a fly off around and talk about what you or that's not the projection what your that but not the projection but the projection would not be visible then yep hello that's for a media Innovation Lab in Israel um so first very very cool and I was wondering if your participants gave more general impressions whether they liked it or not did they compare it to the regular video conversation just about the experience in general and not the details of the movement and understanding yeah I'm not gonna make any grandiose claims because literally we just had you know people rushed in there and rushed out but it did seem that they were definitely getting what this thing was doing and I think one of the really interesting elements that I would love just to investigate further is that the you know I've always said telepresence will will never be a thing until there's the threat of killing someone right and proxemics is actually based on arm length right - arms length is d is the maximum distance one arm length is the minimum distance so this drone seems to be amplifying not only doesn't convey it but it amplifies it because it is slightly dangerous and people are aware of that so I thought that was really cool it'd be very nice to see what you could do with that design and see if you could dial up the social presence you know but yeah so people did like it they did think it was kind of like a natural system thank you my name is Utica Rome University of Sussex I have a question about material or the rhetoric already Hector so I thought the problem was the most amazing because of you may be using the microbeads baster but it's also the corner cube baster is that it's not sharper much more precise territory extra have you ever tried or have you ever considered to use that kind of material also spray based the little hit yeah so it maybe you don't have to stick to this physics material you can design to any shape or like you just like spreading I just wonder this kind of the design space was the material yeah there's another thing that's a wonderful question thank you for the suggestions I I think that's just something like I mean there was a lot of work involved again in the system to work to begin with so you know we didn't look at sort of optimal materials I think we really did like the fabric because it was so lightweight and it were really well with the drone I will also say that the there has to be that combination with the diffuser not just for diffusing vertically but the diffuser also controls the angle very much more precisely than the microbeads would so there's a huge design space there for trying to optimize retroreflection so you don't get the ghosting and you know so I agree with you maybe we can talk after thank you so much thank you any other questions from the floor just a quick reminder that if you are sticking around for a few talks please move towards the center so that anyone else sneaking in late can grab a seat we do have time for one more question which I do have I was interested to notice that you've got a patent for what is the appropriate distance but does that take into consideration that there can be cultural differences between what is appropriate yeah absolutely and you know that's a good question I think that you really do need the reciprocal system likes of both sides in order to be able to convey that so my intent has always been that if you just mimic the cues that are or convey the cues that are coming in the natural world people will figure it out so we don't have to control for that but in our system because it's only because they symmetrical you would still have issues because you know on the on the IMAX the faces aren't exactly correct and the social proxemics don't work so anyways III think it's a very interesting area of research just you know even just investigating whether that does or does not work but I think it does thank you okay random 