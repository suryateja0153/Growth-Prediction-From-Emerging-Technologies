  NARRATOR: Tonight--  The race to become an A.I. superpower is on...  NARRATOR: The politics of artificial intelligence...  There will be a Chinese tech sector and there will be a American tech sector.  NARRATOR: The new tech war.  The more data, the better the A.I. works. So in the age of A.I., where data is the new oil, China is the new Saudi Arabia.  NARRATOR: The future of work...  When I increase productivity through automation, jobs go away.  I believe about 50% of jobs will be somewhat or extremely threatened by A.I. in the next 15 years or so.  NARRATOR: A.I. and corporate surveillance...  We thought that we were searching Google. We had no idea that Google was searching us.  NARRATOR: And the threat to democracy.  China is on its way to building a total surveillance state.  NARRATOR: Tonight on "Frontline"...  It has pervaded so many elements of everyday life. How do we make it transparent and accountable?  NARRATOR: ..."In the Age of A.I."          NARRATOR: This is the world's most complex board game. There are more possible moves in the game of Go than there are atoms in the universe. Legend has it that in 2300 BCE, Emperor Yao devised it to teach his son discipline, concentration, and balance. And, over 4,000 years later, this ancient Chinese game would signal the start of a new industrial age.     It was 2016, in Seoul, South Korea.  Can machines overtake human intelligence? A breakthrough moment when the world champion of the Asian board game Go takes on an A.I. program developed by Google.  (speaking Korean):  In countries where it's very popular, like China and Japan and, and South Korea, to them, Go is not just a game, right? It's, like, how you learn strategy. It has an almost spiritual component. You know, if you talk to South Koreans, right, and Lee Sedol is the world's greatest Go player, he's a national hero in South Korea. They were sure that Lee Sedol would beat AlphaGo hands down.      NARRATOR: Google's AlphaGo was a computer program that, starting with the rules of Go and a database of historical games, had been designed to teach itself.  I was one of the commentators at the Lee Sedol games. And yes, it was watched by tens of millions of people. (man speaking Korean)  NARRATOR: Throughout Southeast Asia, this was seen as a sports spectacle with national pride at stake.  Wow, that was a player guess.  NARRATOR: But much more was in play. This was the public unveiling of a form of artificial intelligence called deep learning, that mimics the neural networks of the human brain.  So what happens with machine learning, or artificial intelligence-- initially with AlphaGo-- is that the machine is fed all kinds of Go games, and then it studies them, learns from them, and figures out its own moves. And because it's an A.I. system-- it's not just following instructions, it's figuring out its own instructions-- it comes up with moves that humans hadn't thought of before. So, it studies games that humans have played, it knows the rules, and then it comes up with creative moves. (woman speaking Korean) (speaking Korean):  That's a very... that's a very surprising move.  I thought it was a mistake.  NARRATOR: Game two, move 37.  That move 37 was a move that humans could not fathom, but yet it ended up being brilliant and woke people up to say, "Wow, after thousands of years of playing, we never thought about making a move like that."  Oh, he resigned. It looks like... Lee Sedol has just resigned, actually.  Yeah!  Yes.  NARRATOR: In the end, the scientists watched their algorithms win four of the games. Lee Sedol took one.  What happened with Go, first and foremost, was a huge victory for deep mind and for A.I., right? It wasn't that the computers beat the humans, it was that, you know, one type of intelligence beat another.  NARRATOR: Artificial intelligence had proven it could marshal a vast amount of data, beyond anything any human could handle, and use it to teach itself how to predict an outcome. The commercial implications were enormous.  While AlphaGo is a, is a toy game, but its success and its waking everyone up, I think, is, is going to be remembered as the pivotal moment where A.I. became mature and everybody jumped on the bandwagon.      NARRATOR: This is about the consequences of that defeat. (man speaking local language) How the A.I. algorithms are ushering in a new age of great potential and prosperity, but an age that will also deepen inequality, challenge democracy, and divide the world into two A.I. superpowers. Tonight, five stories about how artificial intelligence is changing our world.     China has decided to chase the A.I. future.  The difference between the internet mindset and the A.I. mindset...  NARRATOR: A future made and embraced by a new generation.  Well, it's hard not to feel the kind of immense energy, and also the obvious fact of the demographics. They're mostly very younger people, so that this clearly is technology which is being generated by a whole new generation.  NARRATOR: Orville Schell is one of America's foremost China scholars.  (speaking Mandarin)  NARRATOR: He first came here 45 years ago.  When I, when I first came here, in 1975, Chairman Mao was still alive, the Cultural Revolution was coming on, and there wasn't a single whiff of anything of what you see here. It was unimaginable. In fact, in those years, one very much thought, "This is the way China is, this is the way it's going to be." And the fact that it has gone through so many different changes since is quite extraordinary. (man giving instructions)  NARRATOR: This extraordinary progress goes back to that game of Go.  I think that the government recognized that this was a sort of critical thing for the future, and, "We need to catch up in this," that, you know, "We cannot have a foreign company showing us up at our own game. And this is going to be something that is going to be critically important in the future." So, you know, we called it the Sputnik moment for, for the Chinese government-- the Chinese government kind of woke up.  (translated): As we often say in China, "The beginning is the most difficult part."  NARRATOR: In 2017, Xi Jinping announced the government's bold new plans to an audience of foreign diplomats. China would catch up with the U.S. in artificial intelligence by 2025 and lead the world by 2030.  (translated): ...and intensified cooperation in frontier areas such as digital economy, artificial intelligence, nanotechnology, and accounting computing.      NARRATOR: Today, China leads the world in e-commerce. Drones deliver to rural villages. And a society that bypassed credit cards now shops in stores without cashiers, where the currency is facial recognition.  No country has ever moved that fast. And in a short two-and-a-half years, China's A.I. implementation really went from minimal amount to probably about 17 or 18 unicorns, that is billion-dollar companies, in A.I. today. And that, that progress is, is hard to believe.  NARRATOR: The progress was powered by a new generation of ambitious young techs pouring out of Chinese universities, competing with each other for new ideas, and financed by a new cadre of Chinese venture capitalists. This is Sinovation, created by U.S.-educated A.I. scientist and businessman Kai-Fu Lee.  These unicorns-- we've got one, two, three, four, five, six, in the general A.I. area. And unicorn means a billion-dollar company, a company whose valuation or market capitalization is at $1 billion or higher. I think we put two unicorns to show $5 billion or higher.  NARRATOR: Kai-Fu Lee was born in Taiwan. His parents sent him to high school in Tennessee. His PhD thesis at Carnegie Mellon was on computer speech recognition, which took him to Apple.  Well, reality is a step closer to science fiction, with Apple Computers' new developed program...  NARRATOR: And at 31, an early measure of fame.  Kai-Fu Lee, the inventor of Apple's speech-recognition technology.  Casper, copy this to Make Write 2. Casper, paste. Casper, 72-point italic outline.  NARRATOR: He would move on to Microsoft research in Asia and became the head of Google China. Ten years ago, he started Sinovation in Beijing, and began looking for promising startups and A.I. talent.  So, the Chinese entrepreneurial companies started as copycats. But over the last 15 years, China has developed its own form of entrepreneurship, and that entrepreneurship is described as tenacious, very fast, winner-take-all, and incredible work ethic. I would say these few thousand Chinese top entrepreneurs, they could take on any entrepreneur anywhere in the world.  NARRATOR: Entrepreneurs like Cao Xudong, the 33-year-old C.E.O. of a new startup called Momenta. This is a ring road around Beijing. The car is driving itself.      You see, another cutting, another cutting-in.  Another cut-in, yeah, yeah.  NARRATOR: Cao has no doubt about the inevitability of autonomous vehicles.  Just like AlphaGo can beat the human player in, in Go, I think the machine will definitely surpass the human driver, in the end.  NARRATOR: Recently, there have been cautions about how soon autonomous vehicles will be deployed, but Cao and his team are confident they're in for the long haul.  U.S. will be the first to deploy, but China may be the first to popularize. It is 50-50 right now. U.S. is ahead in technology. China has a larger market, and the Chinese government is helping with infrastructure efforts-- for example, building a new city the size of Chicago with autonomous driving enabled, and also a new highway that has sensors built in to help autonomous vehicle be safer.  NARRATOR: Their early investors included Mercedes-Benz.  I feel very lucky and very inspiring and very exciting that we're living in this era.      NARRATOR: Life in China is largely conducted on smartphones. A billion people use WeChat, the equivalent of Facebook, Messenger, and PayPal, and much more, combined into just one super-app. And there are many more.  China is the best place for A.I. implementation today, because the vast amount of data that's available in China. China has a lot more users than any other country, three to four times more than the U.S. There are 50 times more mobile payments than the U.S. There are ten times more food deliveries, which serve as data to learn more about user behavior than the U.S. 300 times more shared bicycle rides, and each shared bicycle ride has all kinds of sensors submitting data up to the cloud. We're talking about maybe ten times more data than the U.S., and A.I. is basically run on data and fueled by data. The more data, the better the A.I. works, more importantly than how brilliant the researcher is working on the problem. So, in the age of A.I., where data is the new oil, China is the new Saudi Arabia.  NARRATOR: And access to all that data means that the deep-learning algorithm can quickly predict behavior, like the creditworthiness of someone wanting a short-term loan.  Here is our application. And customer can choose how many money they want to borrow and how long they want to borrow, and they can input their datas here. And after, after that, you can just borrow very quickly.  NARRATOR: The C.E.O. shows us how quickly you can get a loan.  It is, it has done.  NARRATOR: It takes an average of eight seconds.  It has passed to banks.  Wow.  NARRATOR: In the eight seconds, the algorithm has assessed 5,000 personal features from all your data.  5,000 features that is related with the delinquency, when maybe the banks only use few, maybe, maybe ten features when they are doing their risk amendment.  NARRATOR: Processing millions of transactions, it'll dig up features that would never be apparent to a human loan officer, like how confidently you type your loan application, or, surprisingly, if you keep your cell phone battery charged.  It's very interesting, the battery of the phone is related with their delinquency rate. Someone who has much more lower battery, they get much more dangerous than others.  It's probably unfathomable to an American how a country can dramatically evolve itself from a copycat laggard to, all of a sudden, to nearly as good as the U.S. in technology.  NARRATOR: Like this facial-recognition startup he invested in. Megvii was started by three young graduates in 2011. It's now a world leader in using A.I. to identify people.  It's pretty fast. For example, on the mobile device, we have timed the facial-recognition speed. It's actually less than 100 milliseconds. So, that's very, very fast. So 0.1 second that we can, we will be able to recognize you, even on a mobile device.  NARRATOR: The company claims the system is better than any human at identifying people in its database. And for those who aren't, it can describe them. Like our director-- what he's wearing, and a good guess at his age, missing it by only a few months.  We are the first one to really take facial recognition to commercial quality.  NARRATOR: That's why in Beijing today, you can pay for your KFC with a smile.  You know, it's not so surprising, we've seen Chinese companies catching up to the U.S. in technology for a long time. And so, if particular effort and attention is paid in a specific sector, it's not so surprising that they would surpass the rest of the world. And facial recognition is one of the, really the first places we've seen that start to happen.  NARRATOR: It's a technology prized by the government, like this program in Shenzhen to discourage jaywalking. Offenders are shamed in public-- and with facial recognition, can be instantly fined. Critics warn that the government and some private companies have been building a national database from dozens of experimental social-credit programs.  The government wants to integrate all these individual behaviors, or corporations' records, into some kind of metrics and compute out a single number or set of number associated with a individual, a citizen, and using that, to implement a incentive or punishment system.  NARRATOR: A high social-credit number can be rewarded with discounts on bus fares. A low number can lead to a travel ban. Some say it's very popular with a Chinese public that wants to punish bad behavior. Others see a future that rewards party loyalty and silences criticism.  Right now, there is no final system being implemented. And from those experiments, we already see that the possibility of what this social-credit system can do to individual. It's very powerful-- Orwellian-like-- and it's extremely troublesome in terms of civil liberty.  NARRATOR: Every evening in Shanghai, ever-present cameras record the crowds as they surge down to the Bund, the promenade along the banks of the Huangpu River. Once the great trading houses of Europe came here to do business with the Middle Kingdom. In the last century, they were all shut down by Mao's revolution. But now, in the age of A.I., people come here to take in a spectacle that reflects China's remarkable progress. (spectators gasp) And illuminates the great political paradox of capitalism taken root in the communist state.  People have called it market Leninism, authoritarian capitalism. We are watching a kind of a Petri dish in which an experiment of, you know, extraordinary importance to the world is being carried out. Whether you can combine these things and get something that's more powerful, that's coherent, that's durable in the world. Whether you can bring together a one-party state with an innovative sector, both economically and technologically innovative, and that's something we thought could not coexist.  NARRATOR: As China reinvents itself, it has set its sights on leading the world in artificial intelligence by 2030. But that means taking on the world's most innovative A.I. culture.     On an interstate in the U.S. Southwest, artificial intelligence is at work solving the problem that's become emblematic of the new age, replacing a human driver.     This is the company's C.E.O., 24-year-old Alex Rodrigues.  The more things we build successfully, the less people ask questions about how old you are when you have working trucks.  NARRATOR: And this is what he's built. Commercial goods are being driven from California to Arizona on Interstate 10. There is a driver in the cab, but he's not driving. It's a path set by a C.E.O. with an unusual CV.  Are we ready, Henry? The aim is to score these pucks into the scoring area. So I, I did competitive robotics starting when I was 11, and I took it very, very seriously. To, to give you a sense, I won the Robotics World Championships for the first time when I was 13. I've been to worlds seven times between the ages of 13 and 20-ish. I eventually founded a team, did a lot of work at a very high competitive level. Things looking pretty good.  NARRATOR: This was a prototype of sorts, from which he has built his multi-million-dollar company.  I hadn't built a robot in a while, wanted to get back to it, and felt that this was by far the most exciting piece of robotics technology that was up and coming. A lot of people told us we wouldn't be able to build it. But knew roughly the techniques that you would use. And I was pretty confident that if you put them together, you would get something that worked. Took the summer off, built in my parents' garage a golf cart that could drive itself.  NARRATOR: That golf cart got the attention of Silicon Valley, and the first of several rounds of venture capital. He formed a team and then decided the business opportunity was in self-driving trucks. He says there's also a human benefit.  If we can build a truck that's ten times safer than a human driver, then not much else actually matters. When we talk to regulators, especially, everyone agrees that the only way that we're going to get to zero highway deaths, which is everyone's objective, is to use self-driving. And so, I'm sure you've heard the statistic, more than 90% of all crashes have a human driver as the cause. So if you want to solve traffic fatalities, which, in my opinion, are the single biggest tragedy that happens year after year in the United States, this is the only solution.  NARRATOR: It's an ambitious goal, but only possible because of the recent breakthroughs in deep learning.  Artificial intelligence is one of those key pieces that has made it possible now to do driverless vehicles where it wasn't possible ten years ago, particularly in the ability to see and understand scenes. A lot of people don't know this, but it's remarkably hard for computers, until very, very recently, to do even the most basic visual tasks, like seeing a picture of a person and knowing that it's a person. And we've made gigantic strides with artificial intelligence in being able to see and understanding tasks, and that's obviously fundamental to being able to understand the world around you with the sensors that, that you have available.  NARRATOR: That's now possible because of the algorithms written by Yoshua Bengio and a small group of scientists.  There are many aspects of the world which we can't explain with words. And that part of our knowledge is actually probably the majority of it. So, like, the stuff we can communicate verbally is the tip of the iceberg. And so to get at the bottom of the iceberg, the solution was, the computers have to acquire that knowledge by themselves from data, from examples. Just like children learn, most not from their teachers, but from interacting with the world, and playing around, and, and trying things and seeing what works and what doesn't work.  NARRATOR: This is an early demonstration. In 2013, deep-mind scientists set a machine-learning program on the Atari video game Breakout. The computer was only told the goal-- to win the game. After 100 games, it learned to use the bat at the bottom to hit the ball and break the bricks at the top. After 300, it could do that better than a human player. After 500 games, it came up with a creative way to win the game-- by digging a tunnel on the side and sending the ball around the top to break many bricks with one hit. That was deep learning.  That's the A.I. program based on learning, really, that has been so successful in the last few years and has... It wasn't clear ten years ago that it would work, but it has completely changed the map and is now used in almost every sector of society.  Even the best and brightest among us, we just don't have enough compute power inside of our heads.  NARRATOR: Amy Webb is a professor at N.Y.U. and founder of the Future Today Institute.  As A.I. progresses, the great promise is that they... they, these, these machines, alongside of us, are able to think and imagine and see things in ways that we never have before, which means that maybe we have some kind of new, weird, seemingly implausible solution to climate change. Maybe we have some radically different approach to dealing with incurable cancers. The real practical and wonderful promise is that machines help us be more creative, and, using that creativity, we get to terrific solutions.  NARRATOR: Solutions that could come unexpectedly to urgent problems.  It's going to change the face of breast cancer. Right now, 40,000 women in the U.S. alone die from breast cancer every single year.  NARRATOR: Dr. Connie Lehman is head of the breast imaging center at Massachusetts General Hospital in Boston.  We've become so complacent about it, we almost don't think it can really be changed. We, we somehow think we should put all of our energy into chemotherapies to save women with metastatic breast cancer, and yet, you know, when we find it early, we cure it, and we cure it without having the ravages to the body when we diagnose it late. This shows the progression of a small, small spot from one year to the next, and then to the diagnosis of the small cancer here.  NARRATOR: This is what happened when a woman who had been diagnosed with breast cancer started to ask questions about why it couldn't have been diagnosed earlier.  It really brings a lot of anxiety, and you're asking the questions, you know, "Am I going to survive? What's going to happen to my son?" And I start asking other questions.  NARRATOR: She was used to asking questions. At M.I.T.'s artificial-intelligence lab, Professor Regina Barzilay uses deep learning to teach the computer to understand language, as well as read text and data.  I was really surprised that the very basic question that I ask my physicians, which were really excellent physicians here at MGH, they couldn't give me answers that I was looking for.  NARRATOR: She was convinced that if you analyze enough data, from mammograms to diagnostic notes, the computer could predict early-stage conditions.  If we fast-forward from 2012 to '13 to 2014, we then see when Regina was diagnosed, because of this spot on her mammogram. Is it possible, with more elegant computer applications, that we might have identified this spot the year before, or even back here?  So, those are standard prediction problems in machine learning-- there is nothing special about them. And to my big surprise, none of the technologies that we are developing at M.I.T., even in the most simple form, doesn't penetrate the hospital.  NARRATOR: Regina and Connie began the slow process of getting access to thousands of mammograms and records from MGH's breast-imaging program.  So, our first foray was just to take all of the patients we had at MGH during a period of time, who had had breast surgery for a certain type of high-risk lesion. And we found that most of them didn't really need the surgery. They didn't have cancer. But about ten percent did have cancer. With Regina's techniques in deep learning and machine learning, we were able to predict the women that truly needed the surgery and separate out those that really could avoid the unnecessary surgery.  What machine can do, it can take hundreds of thousands of images where the outcome is known and learn, based on how, you know, pixels are distributed, what are the very unique patterns that correlate highly with future occurrence of the disease. So, instead of using human capacity to kind of recognize pattern, formalize pattern-- which is inherently limited by our cognitive capacity and how much we can see and remember-- we're providing machine with a lot of data and make it learn this prediction.  So, we are using technology not only to be better at assessing the breast density, but to get more to the point of what we're trying to predict. "Does this woman have a cancer now, and will she develop a cancer in five years? " And that's, again, where the artificial intelligence, machine and deep learning can really help us and our patients.  NARRATOR: In the age of A.I., the algorithms are transporting us into a universe of vast potential and transforming almost every aspect of human endeavor and experience. Andrew McAfee is a research scientist at M.I.T. who co-authored "The Second Machine Age."  The great compliment that a songwriter gives another one is, "Gosh, I wish I had written that one." The great compliment a geek gives another one is, "Wow, I wish I had drawn that graph." So, I wish I had drawn this graph.  NARRATOR: The graph uses a formula to show human development and growth since 2000 BCE.  The state of human civilization is not very advanced, and it's not getting better very quickly at all, and this is true for thousands and thousands of years. When we, when we formed empires and empires got overturned, when we tried democracy, when we invented zero and mathematics and fundamental discoveries about the universe, big deal. It just, the numbers don't change very much. What's weird is that the numbers change essentially in the blink of an eye at one point in time. And it goes from really horizontal, unchanging, uninteresting, to, holy Toledo, crazy vertical. And then the question is, what on Earth happened to cause that change? And the answer is the Industrial Revolution. There were other things that happened, but really what fundamentally happened is we overcame the limitations of our muscle power. Something equally interesting is happening right now. We are overcoming the limitations of our minds. We're not getting rid of them, we're not making them unnecessary, but, holy cow, can we leverage them and amplify them now. You have to be a huge pessimist not to find that profoundly good news.  I really do think the world has entered a new era. Artificial intelligence holds so much promise, but it's going to reshape every aspect of the economy, so many aspects of our lives. Because A.I. is a little bit like electricity. Everybody's going to use it. Every company is going to be incorporating A.I., integrating it into what they do, governments are going to be using it, nonprofit organizations are going to be using it. It's going to create all kinds of benefits in ways large and small, and challenges for us, as well.  NARRATOR: The challenges, the benefits-- the autonomous truck represents both as it maneuvers into the marketplace. The engineers are confident that, in spite of questions about when this will happen, they can get it working safely sooner than most people realize.  I think that you will see the first vehicles operating with no one inside them moving freight in the next few years, and then you're going to see that expanding to more freight, more geographies, more weather over time as, as that capability builds up. We're talking, like, less than half a decade.  NARRATOR: He already has a Fortune 500 company as a client, shipping appliances across the Southwest. He says the sales pitch is straightforward.  They spend hundreds of millions of dollars a year shipping parts around the country. We can bring that cost in half. And they're really excited to be able to start working with us, both because of the potential, the potential savings from deploying self-driving, and also because of all the operational efficiencies that they see, the biggest one being able to operate 24 hours a day. So, right now, human drivers are limited to 11 hours by federal law, and a driverless truck obviously wouldn't have that limitation.      NARRATOR: The idea of a driverless truck comes up often in discussions about artificial intelligence. Steve Viscelli is a sociologist who drove a truck while researching his book "The Big Rig" about the industry.  This is one of the most remarkable stories in, in U.S. labor history, I think, is, you know, the decline of, of unionized trucking. The industry was deregulated in 1980, and at that time, you know, truck drivers were earning the equivalent of over $100,000 in today's dollars. And today the typical truck driver will earn a little over $40,000 a year. And I think it's an important part of the automation story, right? Why are they so afraid of automation? Because we've had four decades of rising inequality in wages. And if anybody is going to take it on the chin from automation in the trucking industry, the, the first in line is going to be the driver, without a doubt.  NARRATOR: For his research, Viscelli tracked down truckers and their families, like Shawn and Hope Cumbee of Beaverton, Michigan.  Hi.  Hey, Hope, I'm Steve Viscelli.  Hi, Steve, nice to meet you. Come on in.  Great to meet you, too, thanks.  NARRATOR: And their son Charlie.  This is Daddy, me, Daddy, and Mommy.  NARRATOR: But Daddy's not here. Shawn Cumbee's truck has broken down in Tennessee. Hope, who drove a truck herself, knows the business well.  We made $150,000, right, in a year. That sounds great, right? That's, like, good money. We paid $100,000 in fuel, okay? So, right there, now I made $50,000. But I didn't really, because, you know, you get an oil change every month, so that's $300 a month. You still have to do all the maintenance. We had a motor blow out, right? $13,000. Right? I know, I mean, I choke up a little just thinking about it, because it was... And it was 13,000, and we were off work for two weeks. So, by the end of the year, with that $150,000, by the end of the year, we'd made about 20... About $22,000.  NARRATOR: In a truck stop in Tennessee, Shawn has been sidelined waiting for a new part. The garage owner is letting him stay in the truck to save money.  Hi, baby.  (on phone): Hey, how's it going?  It's going. Chunky-butt!  Hi, Daddy!  Hi, Chunky-butt. What're you doing?  (talking inaudibly)  Believe it or not, I do it because I love it. I mean, you know, it's in the blood. Third-generation driver. And my granddaddy told me a long time ago, when I was probably 11, 12 years old, probably, he said, "The world meets nobody halfway. Nobody." He said, "If you want it, you have to earn it." And that's what I do every day. I live by that creed. And I've lived by that since it was told to me.  So, if you're down for a week in a truck, you still have to pay your bills. I have enough money in my checking account at all times to pay a month's worth of bills. That does not include my food. That doesn't include field trips for my son's school. My son and I just went to our yearly doctor appointment. I took, I took money out of my son's piggy bank to pay for it, because it's not... it's not scheduled in. It's, it's not something that you can, you know, afford. I mean, like, when... (sighs): Sorry.  It's okay.     Have you guys ever talked about self-driving trucks? Is he...  (laughing): So, kind of. Um, I asked him once, you know. And he laughed so hard. He said, "No way will they ever have a truck that can drive itself."  It's kind of interesting when you think about it, you know, they're putting all this new technology into things, but, you know, it's still man-made. And man, you know, does make mistakes. I really don't see it being a problem with the industry, 'cause, one, you still got to have a driver in it, because I don't see it doing city. I don't see it doing, you know, main things. I don't see it backing into a dock. I don't see the automation part, you know, doing... maybe the box-trailer side, you know, I can see that, but not stuff like I do. So, I ain't really worried about the automation of trucks.  How near of a future is it?  Yeah, self-driving, um... So, some, you know, some companies are already operating. Embark, for instance, is one that has been doing driverless trucks on the interstate. And what's called exit-to-exit self-driving. And they're currently running real freight.  Really?  Yeah, on I-10.      (on P.A.): Shower guest 100, your shower is now ready.  NARRATOR: Over time, it has become harder and harder for veteran independent drivers like the Cumbees to make a living. They've been replaced by younger, less experienced drivers.  So, the, the trucking industry's $740 billion a year, and, again, in, in many of these operations, labor's a third of that cost. By my estimate, I, you know, I think we're in the range of 300,000 or so jobs in the foreseeable future that could be automated to some significant extent.      (groans)      NARRATOR: The A.I. future was built with great optimism out here in the West. In 2018, many of the people who invented it gathered in San Francisco to celebrate the 25th anniversary of the industry magazine.  Howdy, welcome to WIRED25.  NARRATOR: It is a celebration, for sure, but there's also a growing sense of caution and even skepticism.  We're having a really good weekend here.  NARRATOR: Nick Thompson is editor-in-chief of "Wired."  When it started, it was very much a magazine about what's coming and why you should be excited about it. Optimism was the defining feature of "Wired" for many, many years. Or, as our slogan used to be, "Change Is Good." And over time, it shifted a little bit. And now it's more, "We love technology, but let's look at some of the big issues, and let's look at some of them critically, and let's look at the way algorithms are changing the way we behave, for good and for ill." So, the whole nature of "Wired" has gone from a champion of technological change to more of a observer of technological change.  So, um, before we start...  NARRATOR: There are 25 speakers, all named as icons of the last 25 years of technological progress.  So, why is Apple so secretive?  (chuckling)  NARRATOR: Jony Ive, who designed Apple's iPhone.  It would be bizarre not to be.  There's this question of, like, what are we doing here in this life, in this reality?  NARRATOR: Jaron Lanier, who pioneered virtual reality. And Jeff Bezos, the founder of Amazon.  Amazon was a garage startup. Now it's a very large company. Two kids in a dorm...  NARRATOR: His message is, "All will be well in the new world."  I guess, first of all, I remain incredibly optimistic about technology, and technologies always are two-sided. But that's not new. That's always been the case. And, and we will figure it out. The last thing we would ever want to do is stop the progress of new technologies, even when they are dual-use.  NARRATOR: But, says Thompson, beneath the surface, there's a worry most of them don't like to talk about.  There are some people in Silicon Valley who believe that, "You just have to trust the technology. Throughout history, there's been a complicated relationship between humans and machines, we've always worried about machines, and it's always been fine. And we don't know how A.I. will change the labor force, but it will be okay." So, that argument exists. There's another argument, which is what I think most of them believe deep down, which is, "This is different. We're going to have labor-force disruption like we've never seen before. And if that happens, will they blame us?"  NARRATOR: There is, however, one of the WIRED25 icons willing to take on the issue. Onstage, Kai-Fu Lee dispenses with one common fear.  Well, I think there are so many myths out there. I think one, one myth is that because A.I. is so good at a single task, that one day we'll wake up, and we'll all be enslaved or forced to plug our brains to the A.I. But it is nowhere close to displacing humans.  NARRATOR: But in interviews around the event and beyond, he takes a decidedly contrarian position on A.I. and job loss.  The A.I. giants want to paint the rosier picture because they're happily making money. So, I think they prefer not to talk about the negative side. I believe about 50% of jobs will be somewhat or extremely threatened by A.I. in the next 15 years or so.  NARRATOR: Kai-Fu Lee also makes a great deal of money from A.I. What separates him from most of his colleagues is that he's frank about its downside.  Yes, yes, we, we've made about 40 investments in A.I. I think, based on these 40 investments, most of them are not impacting human jobs. They're creating value, making high margins, inventing a new model. But I could list seven or eight that would lead to a very clear displacement of human jobs.  NARRATOR: He says that A.I. is coming, whether we like it or not. And he wants to warn society about what he sees as inevitable.  You have a view which I think is different than many others, which is that A.I. is not going to take blue-collar jobs so quickly, but is actually going to take white-collar jobs.  Yeah. Well, both will happen. A.I. will be, at the same time, a replacement for blue-collar, white-collar jobs, and be a great symbiotic tool for doctors, lawyers, and you, for example. But the white-collar jobs are easier to take, because they're a pure quantitative analytical process. Let's say reporters, traders, telemarketing, telesales, customer service...  Analysts?  Analysts, yes, these can all be replaced just by a software. To do blue-collar, some of the work requires, you know, hand-eye coordination, things that machines are not yet good enough to do.  Today, there are many people who are ringing the alarm, "Oh, my God, what are we going to do? Half the jobs are going away." I believe that's true, but here's the missing fact. I've done the research on this, and if you go back 20, 30, or 40 years ago, you will find that 50% of the jobs that people performed back then are gone today. You know, where are all the telephone operators, bowling-pin setters, elevator operators? You used to have seas of secretaries in corporations that have now been eliminated-- travel agents. You can just go through field after field after field. That same pattern has recurred many times throughout history, with each new wave of automation.  But I would argue that history is only trustable if it is multiple repetitions of similar events, not once-in-a-blue-moon occurrence. So, over the history of many tech inventions, most are small things. Only maybe three are at the magnitude of A.I. revolution-- the steam, steam engine, electricity, and the computer revolution. I'd say everything else is too small. And the reason I think it might be something brand-new is that A.I. is fundamentally replacing our cognitive process in doing a job in its significant entirety, and it can do it dramatically better.  NARRATOR: This argument about job loss in the age of A.I. was ignited six years ago amid the gargoyles and spires of Oxford University. Two researchers had been poring through U.S. labor statistics, identifying jobs that could be vulnerable to A.I. automation.  Well, vulnerable to automation, in the context that we discussed five years ago now, essentially meant that those jobs are potentially automatable over an unspecified number of years. And the figure we came up with was 47%.  NARRATOR: 47%. That number quickly traveled the world in headlines and news bulletins. But authors Carl Frey and Michael Osborne offered a caution. They can't predict how many jobs will be lost, or how quickly. But Frey believes that there are lessons in history.  And what worries me the most is that there is actually one episode that looks quite familiar to today, which is the British Industrial Revolution, where wages didn't grow for nine decades, and a lot of people actually saw living standards decline as technology progressed.      NARRATOR: Saginaw, Michigan, knows about decline in living standards. Harry Cripps, an auto worker and a local union president, has witnessed what 40 years of automation can do to a town.  You know, we're one of the cities in the country that, I think we were left behind in this recovery. And I just... I don't know how we get on the bandwagon now.  NARRATOR: Once, this was the U.A.W. hall for one local union. Now, with falling membership, it's shared by five locals.  Rudy didn't get his shift.  NARRATOR: This day, it's the center for a Christmas food drive. Even in a growth economy, unemployment here is near six percent. Poverty in Saginaw is over 30%.  Our factory has about 1.9 million square feet. Back in the '70s, that 1.9 million square feet had about 7,500 U.A.W. automotive workers making middle-class wage with decent benefits and able to send their kids to college and do all the things that the middle-class family should be able to do. Our factory today, with automation, would probably be about 700 United Auto Workers. That's a dramatic change. Lot of union brothers used to work there, buddy.  The TRW plant, that was unfortunate.  Delphi... looks like they're starting to tear it down now. Wow. Automations is, is definitely taking away a lot of jobs. Robots, I don't know how they buy cars, I don't know how they buy sandwiches, I don't know how they go to the grocery store. They definitely don't pay taxes, which serves the infrastructure. So, you don't have the sheriffs and the police and the firemen, and anybody else that supports the city is gone, 'cause there's no tax base. Robots don't pay taxes.  NARRATOR: The average personal income in Saginaw is $16,000 a year.  A lot of the families that I work with here in the community, both parents are working. They're working two jobs. Mainly, it's the wages, you know, people not making a decent wage to be able to support a family. Like, back in the day, my dad even worked at the plant. My mom stayed home, raised the children. And that give us the opportunity to put food on the table, and things of that nature. And, and them times are gone.  If you look at this graph of what's been happening to America since the end of World War II, you see a line for our productivity, and our productivity gets better over time. It used to be the case that our pay, our income, would increase in lockstep with those productivity increases. The weird part about this graph is how the income has decoupled, is not going up the same way that productivity is anymore.  NARRATOR: As automation has taken over, workers are either laid off or left with less-skilled jobs for less pay, while productivity goes up.  There are still plenty of factories in America. We are a manufacturing powerhouse, but if you go walk around an American factory, you do not see long lines of people doing repetitive manual labor. You see a whole lot of automation. If you go upstairs in that factory and look at the payroll department, you see one or two people looking into a screen all day. So, the activity is still there, but the number of jobs is very, very low, because of automation and tech progress. Now, dealing with that challenge, and figuring out what the next generation of the American middle class should be doing, is a really important challenge, because I am pretty confident that we are never again going to have this large, stable, prosperous middle class doing routine work.      NARRATOR: Evidence of how A.I. is likely to bring accelerated change to the U.S. workforce can be found not far from Saginaw. This is the U.S. headquarters for one of the world's largest builders of industrial robots, a Japanese-owned company called Fanuc Robotics.  We've been producing robots for well over 35 years. And you can imagine, over the years, they've changed quite a bit. We're utilizing the artificial intelligence to really make the robots easier to use and be able to handle a broader spectrum of opportunities. We see a huge growth potential in robotics. And we see that growth potential as being, really, there's 90% of the market left.  NARRATOR: The industry says optimistically that with that growth, they can create more jobs.  Even if there were five people on a job, and we reduced that down to two people, because we automated some level of it, we might produce two times more parts than we did before, because we automated it. So now, there might be the need for two more fork-truck drivers, or two more quality-inspection personnel. So, although we reduce some of the people, we grow in other areas as we produce more things.  When I increase productivity through automation, I lose jobs. Jobs go away. And I don't care what the robot manufacturers say, you aren't replacing those ten production people that that robot is now doing that job, with ten people. You can increase productivity to a level to stay competitive with the global market-- that's what they're trying to do.      NARRATOR: In the popular telling, blame for widespread job loss has been aimed overseas, at what's called offshoring.  We want to keep our factories here, we want to keep our manufacturing here. We don't want them moving to China, to Mexico, to Japan, to India, to Vietnam.  NARRATOR: But it turns out most of the job loss isn't because of offshoring.  There's been offshoring. And I think offshoring is responsible for maybe 20% of the jobs that have been lost. I would say most of the jobs that have been lost, despite what most Americans thinks, was due to automation or productivity growth.  NARRATOR: Mike Hicks is an economist at Ball State University in Muncie, Indiana. He and sociologist Emily Wornell have been documenting employment trends in Middle America. Hicks says that automation has been a mostly silent job killer, lowering the standard of living.  So, in the last 15 years, the standard of living has dropped by 15, ten to 15 percent. So, that's unusual in a developed world. A one-year decline is a recession. A 15-year decline gives an entirely different sense about the prospects of a community. And so that is common from the Canadian border to the Gulf of Mexico in the middle swath of the United States.  This is something we're gonna do for you guys. These were left over from our suggestion drive that we did, and we're going to give them each two.  That is awesome.  I mean, that is going to go a long ways, right? I mean, that'll really help that family out during the holidays.  Yes, well, with the kids home from school, the families have three meals a day that they got to put on the table. So, it's going to make a big difference. So, thank you, guys.  You're welcome.  This is wonderful.  Let them know Merry Christmas on behalf of us here at the local, okay?  Absolutely, you guys are just, just amazing, thank you. And please, tell, tell all the workers how grateful these families will be.  We will.  I mean, this is not a small problem. The need is so great. And I can tell you that it's all races, it's all income classes that you might think someone might be from. But I can tell you that when you see it, and you deliver this type of gift to somebody who is in need, just the gratitude that they show you is incredible.  We actually know that people are at greater risk of mortality for over 20 years after they lose their job due to, due to no fault of their own, so something like automation or offshoring. They're at higher risk for cardiovascular disease, they're at higher risk for depression and suicide. But then with the intergenerational impacts, we also see their children are more likely-- children of parents who have lost their job due to automation-- are more likely to repeat a grade, they're more likely to drop out of school, they're more likely to be suspended from school, and they have lower educational attainment over their entire lifetimes.  It's the future of this, not the past, that scares me. Because I think we're in the early decades of what is a multi-decade adjustment period.      NARRATOR: The world is being re-imagined. This is a supermarket. Robots, guided by A.I., pack everything from soap powder to cantaloupes for online consumers. Machines that pick groceries, machines that can also read reports, learn routines, and comprehend are reaching deep into factories, stores, and offices. At a college in Goshen, Indiana, a group of local business and political leaders come together to try to understand the impact of A.I. and the new machines. Molly Kinder studies the future of work at a Washington think tank.  How many people have gone into a fast-food restaurant and done a self-ordering? Anyone, yes? Panera, for instance, is doing this. Cashier was my first job, and in, in, where I live, in Washington, DC, it's actually the number-one occupation for the greater DC region. There are millions of people who work in cashier positions. This is not a futuristic challenge, this is something that's happening sooner than we think. In the popular discussions about robots and automation and work, almost every image is of a man on a factory floor or a truck driver. And yet, in our data, when we looked, women disproportionately hold the jobs that today are at highest risk of automation. And that's not really being talked about, and that's in part because women are over-represented in some of these marginalized occupations, like a cashier or a fast-food worker. And also in a large numbers in clerical jobs in offices-- HR departments, payroll, finance, a lot of that is more routine processing information, processing paper, transferring data. That has huge potential for automation. A.I. is going to do some of that, software, robots are going to do some of that. So how many people are still working as switchboard operators? Probably none in this country.  NARRATOR: The workplace of the future will demand different skills, and gaining them, says Molly Kinder, will depend on who can afford them.  I mean it's not a good situation in the United States. There's been some excellent research that says that half of Americans couldn't afford a $400 unexpected expense. And if you want to get to a $1,000, there's even less. So imagine you're going to go out without a month's pay, two months' pay, a year. Imagine you want to put savings toward a course to, to redevelop your career. People can't afford to take time off of work. They don't have a cushion, so this lack of economic stability, married with the disruptions in people's careers, is a really toxic mix.  (blowing whistle)  NARRATOR: The new machines will penetrate every sector of the economy: from insurance companies to human resource departments; from law firms to the trading floors of Wall Street.  Wall Street's going through it, but every industry is going through it. Every company is looking at all of the disruptive technologies, could be robotics or drones or blockchain. And whatever it is, every company's using everything that's developed, everything that's disruptive, in thinking about, "How do I apply that to my business to make myself more efficient?" And what efficiency means is, mostly, "How do I do this with fewer workers?" And I do think that when we look at some of the studies about opportunity in this country, and the inequality of opportunity, the likelihood that you won't be able to advance from where your parents were, I think that's, that's, is very serious and gets to the heart of the way we like to think of America as the land of opportunity.  NARRATOR: Inequality has been rising in America. It used to be the top 1% of earners-- here in red-- owned a relatively small portion of the country's wealth. Middle and lower earners-- in blue-- had the largest share. Then, 15 years ago, the lines crossed. And inequality has been increasing ever since.  There's many factors that are driving inequality today, and unfortunately, artificial intelligence-- without being thoughtful about it-- is a driver for increased inequality because it's a form of automation, and automation is the substitution of capital for labor. And when you do that, the people with the capital win. So Karl Marx was right, it's a struggle between capital and labor, and with artificial intelligence, we're putting our finger on the scale on the side of capital, and how we wish to distribute the benefits, the economic benefits, that that will create is going to be a major moral consideration for society over the next several decades.  This is really an outgrowth of the increasing gaps of haves and have-nots-- the wealthy getting wealthier, the poor getting poorer. It may not be specifically related to A.I., but as... but A.I. will exacerbate that. And that, I think, will tear the society apart, because the rich will have just too much, and those who are have-nots will have perhaps very little way of digging themselves out of the hole. And with A.I. making its impact, it, it'll be worse, I think.     (crowd cheering and applauding)  (speaking on P.A.) I'm here today for one main reason. To say thank you to Ohio. (crowd cheering and applauding)  I think the Trump vote was a protest. I mean that for whatever reason, whatever the hot button was that, you know, that really hit home with these Americans who voted for him were, it was a protest vote. They didn't like the direction things were going. (crowd booing and shouting) I'm scared. I'm gonna be quite honest with you, I worry about the future of not just this country, but the, the entire globe. If we continue to go in an automated system, what are we going to do? Now I've got a group of people at the top that are making all the money and I don't have anybody in the middle that can support a family. So do we have to go to the point where we crash to come back? And in this case, the automation's already gonna be there, so I don't know how you come back. I'm really worried about where this, where this leads us in the future.      NARRATOR: The future is largely being shaped by a few hugely successful tech companies. They're constantly buying up successful smaller companies and recruiting talent. Between the U.S. and China, they employ a great majority of the leading A.I. researchers and scientists. In the course of amassing such power, they've also become among the richest companies in the world.  A.I. really is the ultimate tool of wealth creation. Think about the massive data that, you know, Facebook has on user preferences, and how it can very smartly target an ad that you might buy something and get a much bigger cut that a smaller company couldn't do. Same with Google, same with Amazon. So it's... A.I. is a set of tools that helps you maximize an objective function, and that objective function initially will simply be, make more money.  NARRATOR: And it is how these companies make that money, and how their algorithms reach deeper and deeper into our work, our daily lives, and our democracy, that makes many people increasingly uncomfortable. Pedro Domingos wrote the book "The Master Algorithm."  Everywhere you go, you generate a cloud of data. You're trailing data, everything that you do is producing data. And then there are computers looking at that data that are learning, and these computers are essentially trying to serve you better. They're trying to personalize things to you. They're trying to adapt the world to you. So on the one hand, this is great, because the world will get adapted to you without you even having to explicitly adapt it. There's also a danger, because the entities in the companies that are in control of those algorithms don't necessarily have the same goals as you, and this is where I think people need to be aware that, what's going on, so they can have more control over it.  You know, we came into this new world thinking that we were users of social media. It didn't occur to us that social media was actually using us. We thought that we were searching Google. We had no idea that Google was searching us.  NARRATOR: Shoshana Zuboff is a Harvard Business School professor emerita. In 1988, she wrote a definitive book called "In the Age of the Smart Machine." For the last seven years, she has worked on a new book, making the case that we have now entered a new phase of the economy, which she calls "surveillance capitalism."  So, famously, industrial capitalism claimed nature. Innocent rivers, and meadows, and forests, and so forth, for the market dynamic to be reborn as real estate, as land that could be sold and purchased. Industrial capitalism claimed work for the market dynamic to reborn, to be reborn as labor that could be sold and purchased. Now, here comes surveillance capitalism, following this pattern, but with a dark and startling twist. What surveillance capitalism claims is private, human experience. Private, human experience is claimed as a free source of raw material, fabricated into predictions of human behavior. And it turns out that there are a lot of businesses that really want to know what we will do now, soon, and later.  NARRATOR: Like most people, Alastair Mactaggart had know idea about this new surveillance business, until one evening in 2015.  I had a conversation with a fellow who's an engineer, and I was just talking to him one night at a, you know, a dinner, at a cocktail party. And I... there had been something in the press that day about privacy in the paper, and I remember asking him-- he worked for Google-- "What's the big deal about all, why are people so worked up about it?" And I thought it was gonna be one of those conversations, like, with, you know, if you ever ask an airline pilot, "Should I be worried about flying?" and they say, "Oh, the most dangerous part is coming to the airport, you know, in the car." And he said, "Oh, you'd be horrified if you knew how much we knew about you." And I remember that kind of stuck in my head, because it was not what I expected.  NARRATOR: That question would change his life. A successful California real estate developer, Mactaggart began researching the new business model.  What I've learned since is that their entire business is learning as much about you as they can. Everything about your thoughts, and your desires, and your dreams, and who your friends are, and what you're thinking, what your private thoughts are. And with that, that's true power. And so, I think... I didn't know that at the time. That their entire business is basically mining the data of your life.      NARRATOR: Shoshana Zuboff had been doing her own research.  You know, I'd been reading and reading and reading. From patents, to transcripts of earnings calls, research reports. And, you know, just literally everything, for years and years and years.  NARRATOR: Her studies included the early days of Google, started in 1998 by two young Stanford grad students, Sergey Brin and Larry Page. In the beginning, they had no clear business model. Their unofficial motto was, "Don't Be Evil."  Right from the start, the founders, Larry Page and Sergey Brin, they had been very public about their antipathy toward advertising. Advertising would distort the internet and it would distort and disfigure the, the purity of any search engine, including their own.  Once in love with e-commerce, Wall Street has turned its back on the dotcoms.  NARRATOR: Then came the dotcom crash of the early 2000s.  ...has left hundreds of unprofitable internet companies begging for love and money.  NARRATOR: While Google had rapidly become the default search engine for tens of millions of users, their investors were pressuring them to make more money. Without a new business model, the founders knew that the young company was in danger.  In this state of emergency, the founders decided, "We've simply got to find a way to save this company." And so, parallel to this were another set of discoveries, where it turns out that whenever we search or whenever we browse, we're leaving behind traces-- digital traces-- of our behavior. And those traces, back in these days, were called digital exhaust.  NARRATOR: They realized how valuable this data could be by applying machine learning algorithms to predict users' interests.  What happened was, they decided to turn to those data logs in a systematic way, and to begin to use these surplus data as a way to come up with fine-grained predictions of what a user would click on, what kind of ad a user would click on. And inside Google, they started seeing these revenues pile up at a startling rate. They realized that they had to keep it secret. They didn't want anyone to know how much money they were making, or how they were making it. Because users had no idea that these extra-behavioral data that told so much about them, you know, was just out there, and now it was being used to predict their future.  NARRATOR: When Google's I.P.O. took place just a few years later, the company had a market capitalization of around $23 billion. Google's stock was now as valuable as General Motors.      And it was only when Google went public in 2004 that the numbers were released. And it's at that point that we learn that between the year 2000 and the year 2004, Google's revenue line increased by 3,590%.  Let's talk a little about information, and search, and how people consume it.  NARRATOR: By 2010, the C.E.O. of Google, Eric Schmidt, would tell "The Atlantic" magazine...  ...is, we don't need you to type at all. Because we know where you are, with your permission, we know where you've been, with your permission. We can more or less guess what you're thinking about. (audience laughing) Now, is that over the line?  NARRATOR: Eric Schmidt and Google declined to be interviewed for this program. Google's new business model for predicting users' profiles had migrated to other companies, particularly Facebook. Roger McNamee was an early investor and adviser to Facebook. He's now a critic, and wrote a book about the company. He says he's concerned about how widely companies like Facebook and Google have been casting the net for data.  And then they realized, "Wait a minute, there's all this data in the economy we don't have." So they went to credit card processors, and credit rating services, and said, "We want to buy your data." They go to health and wellness apps and say, "Hey, you got women's menstrual cycles? We want all that stuff." Why are they doing that? They're doing that because behavioral prediction is about taking uncertainty out of life. Advertising and marketing are all about uncertainty-- you never really know who's going to buy your product. Until now. We have to recognize that we gave technology a place in our lives that it had not earned. That essentially, because technology always made things better in the '50s, '60s, '70s, '80s, and '90s, we developed a sense of inevitability that it will always make things better. We developed a trust, and the industry earned good will that Facebook and Google have cashed in.  NARRATOR: The model is simply this: provide a free service-- like Facebook-- and in exchange, you collect the data of the millions who use it.     And every sliver of information is valuable.  It's not just what you post, it's that you post. It's not just that you make plans to see your friends later. It's whether you say, "I'll see you later," or, "I'll see you at 6:45." It's not just that you talk about the things that you have to do today. It's whether you simply rattle them on in a, in a rambling paragraph, or list them as bullet points. All of these tiny signals are the behavioral surplus that turns out to have immense predictive value.  NARRATOR: In 2010, Facebook experimented with A.I.'s predictive powers in what they called a "social contagion" experiment. They wanted to see if, through online messaging, they could influence real-world behavior. The aim was to get more people to the polls in the 2010 midterm elections.  Cleveland, I need you to keep on fighting. I need you to keep on believing.  NARRATOR: They offered 61 million users an "I voted" button together with faces of friends who had voted. A subset of users received just the button. In the end, they claimed to have nudged 340,000 people to vote. They would conduct other "massive contagion" experiments. Among them, one showing that by adjusting their feeds, they could make users happy or sad.  When they went to write up these findings, they boasted about two things. One was, "Oh, my goodness. Now we know that we can use cues in the online environment to change real-world behavior. That's big news." The second thing that they understood, and they celebrated, was that, "We can do this in a way that bypasses the users' awareness."  Private corporations have built a corporate surveillance state without our awareness or permission. And the systems necessary to make it work are getting a lot better, specifically with what are known as internet of things, smart appliances, you know, powered by the Alexa voice recognition system, or the Google Home system.  Okay, Google, play the morning playlist.  Okay, playing morning playlist.      Okay, Google, play music in all rooms.      And those will put the surveillance in places we've never had it before-- living rooms, kitchens, bedrooms. And I find all of that terrifying.  Okay, Google, I'm listening.  NARRATOR: The companies say they're not using the data to target ads, but helping A.I. improve the user experience.  Alexa, turn on the fan. (fan clicks on)  Okay.  NARRATOR: Meanwhile, they are researching and applying for patents to expand their reach into homes and lives.  Alexa, take a video. (camera chirps)  The more and more that you use spoken interfaces-- so smart speakers-- they're being trained not just to recognize who you are, but they're starting to take baselines and comparing changes over time. So does your cadence increase or decrease? Are you sneezing while you're talking? Is your voice a little wobbly? The purpose of doing this is to understand more about you in real time. So that a system could make inferences, perhaps, like, do you have a cold? Are you in a manic phase? Are you feeling depressed? So that is an extraordinary amount of information that can be gleaned by you simply waking up and asking your smart speaker, "What's the weather today?"  Alexa, what's the weather for tonight?  Currently, in Pasadena, it's 58 degrees with cloudy skies.  Inside it is, then. Dinner!  The point is that this is the same micro-behavioral targeting that is directed toward individuals based on intimate, detailed understanding of personalities. So this is precisely what Cambridge Analytica did, simply pivoting from the advertisers to the political outcomes.  NARRATOR: The Cambridge Analytica scandal of 2018 engulfed Facebook, forcing Mark Zuckerberg to appear before Congress to explain how the data of up to 87 million Facebook users had been harvested by a political consulting company based in the U.K. The purpose was to target and manipulate voters in the 2016 presidential campaign, as well as the Brexit referendum. Cambridge Analytica had been largely funded by conservative hedge fund billionaire Robert Mercer.  And now we know that any billionaire with enough money, who can buy the data, buy the machine intelligence capabilities, buy the skilled data scientists, you know, they too can commandeer the public, and infect and infiltrate and upend our democracy with the same methodologies that surveillance capitalism uses every single day.  We didn't take a broad enough view of our responsibility, and that was a big mistake. And it was my mistake, and I'm sorry.  NARRATOR: Zuckerberg has apologized for numerous violations of privacy, and his company was recently fined $5 billion by the Federal Trade Commission. He has said Facebook will now make data protection a priority, and the company has suspended tens of thousands of third-party apps from its platform as a result of an internal investigation.  You know, I wish I could say that after Cambridge Analytica, we've learned our lesson and that everything will be much better after that, but I'm afraid the opposite is true. In some ways, Cambridge Analytica was using tools that were ten years old. It was really, in some ways, old-school, first-wave data science. What we're looking at now, with current tools and machine learning, is that the ability for manipulation, both in terms of elections and opinions, but more broadly, just how information travels, That is a much bigger problem, and certainly much more serious than what we faced with Cambridge Analytica.  NARRATOR: A.I. pioneer Yoshua Bengio also has concerns about how his algorithms are being used.  So the A.I.s are tools. And they will serve the people who control those tools. If those people's interests go against the, the values of democracy, then democracy is in danger. So I believe that scientists who contribute to science, when that science can or will have an impact on society, those scientists have a responsibility. It's a little bit like the physicists of, around the Second World War, who rose up to tell the governments, "Wait, nuclear power can be dangerous and nuclear war can be really, really destructive." And today, the equivalent of a physicist of the '40s and '50s and '60s are, are the computer scientists who are doing machine learning and A.I.      NARRATOR: One person who wanted to do something about the dangers was not a computer scientist, but an ordinary citizen. Alastair Mactaggart was alarmed.  Voting is, for me, the most alarming one. If less than 100,000 votes separated the last two candidates in the last presidential election, in three states...  NARRATOR: He began a solitary campaign.  We're talking about convincing a relatively tiny fraction of the voters in a very... in a handful of states to either come out and vote or stay home. And remember, these companies know everybody intimately. They know who's a racist, who's a misogynist, who's a homophobe, who's a conspiracy theorist. They know the lazy people and the gullible people. They have access to the greatest trove of personal information that's ever been assembled. They have the world's best data scientists. And they have essentially a frictionless way of communicating with you. This is power.  NARRATOR: Mactaggart started a signature drive for a California ballot initiative, for a law to give consumers control of their digital data. In all, he would spend $4 million of his own money in an effort to rein in the goliaths of Silicon Valley. Google, Facebook, AT&T, and Comcast all opposed his initiative.  I'll tell you, I was scared. Fear. Fear of looking like a world-class idiot. The market cap of all the firms arrayed against me were, was over $6 trillion.  NARRATOR: He needed 500,000 signatures to get his initiative on the ballot. He got well over 600,000. Polls showed 80% approval for a privacy law. That made the politicians in Sacramento pay attention. So Mactaggart decided that because he was holding a strong hand, it was worth negotiating with them.  And if AB-375 passes by tomorrow and is signed into law by the governor, we will withdraw the initiative. Our deadline to do so is tomorrow at 5:00.  NARRATOR: At the very last moment, a new law was rushed to the floor of the state house.  Everyone take their seats, please. Mr. Secretary, please call the roll.  The voting starts.  Alan, aye.  And the first guy, I think, was a Republican, and he voted for it. And everybody had said the Republicans won't vote for it because it has this private right of action, where consumers can sue. And the guy in the Senate, he calls the name.  Aye, Roth. Aye, Skinner. Aye, Stern. Aye, Stone.  You can see down below, and everyone went green, and then it passed unanimously.  Ayes 36; No zero, the measure passes. Immediate transmittal to the...  So I was blown away. It was, it was a day I will never forget. So in January, next year, you as a California resident will have the right to go to any company and say, "What have you collected on me in the last 12 years... 12 months? What of my personal information do you have?" So that's the first right. It's right of... we call that the right to know. The second is the right to say no. And that's the right to go to any company and click a button, on any page where they're collecting your information, and say, "Do not sell my information." More importantly, we require that they honor what's called a third-party opt-out. You will click once in your browser, "Don't sell my information," and it will then send the signal to every single website that you visit: "Don't sell this person's information." And that's gonna have a huge impact on the spread of your information across the internet.  NARRATOR: The tech companies had been publicly cautious, but privately alarmed about regulation. Then one tech giant came on board in support of Mactaggart's efforts.  I find the reaction among other tech companies to, at this point, be pretty much all over the place. Some people are saying, "You're right to raise this. These are good ideas." Some people say, "We're not sure these are good ideas, but you're right to raise it," and some people are saying, "We don't want regulation." And so, you know, we have conversations with people where we point out that the auto industry is better because there are safety standards. Pharmaceuticals, even food products, all of these industries are better because the public has confidence in the products, in part because of a mixture of responsible companies and responsible regulation.  NARRATOR: But the lobbyists for big tech have been working the corridors in Washington. They're looking for a more lenient national privacy standard, one that could perhaps override the California law and others like it. But while hearings are held, and anti-trust legislation threatened, the problem is that A.I. has already spread so far into our lives and work.  Well, it's in healthcare, it's in education, it's in criminal justice, it's in the experience of shopping as you walk down the street. It has pervaded so many elements of everyday life, and in a way that, in many cases, is completely opaque to people. While we can see a phone and look at it and we know that there's some A.I. technology behind it, many of us don't know that when we go for a job interview and we sit down and we have a conversation, that we're being filmed, and that our micro expressions are being analyzed by hiring companies. Or that if you're in the criminal justice system, that there are risk assessment algorithms that are deciding your "risk number," which could determine whether or not you receive bail or not. These are systems which, in many cases, are hidden in the back end of our sort of social institutions. And so, one of the big challenges we have is, how do we make that more apparent? How do we make it transparent? And how do we make it accountable?  For a very long time, we have felt like as humans, as Americans, we have full agency in determining our own futures-- what we read, what we see, we're in charge. What Cambridge Analytica taught us, and what Facebook continues to teach us, is that we don't have agency. We're not in charge. This is machines that are automating some of our skills, but have made decisions about who... Who we are. And they're using that information to tell others the story of us.      NARRATOR: In China, in the age of A.I., there's no doubt about who is in charge. In an authoritarian state, social stability is the watchword of the government. (whistle blowing) And artificial intelligence has increased its ability to scan the country for signs of unrest. (whistle blowing) It's been projected that over 600 million cameras will be deployed by 2020. Here, they may be used to discourage jaywalking. But they also serve to remind people that the state is watching.  And now, there is a project called Sharp Eyes, which is putting camera on every major street and the corner of every village in China-- meaning everywhere. Matching with the most advanced artificial intelligence algorithm, which they can actually use this data, real-time data, to pick up a face or pick up a action.      NARRATOR: Frequent security expos feature companies like Megvii and its facial- recognition technology. They show off cameras with A.I. that can track cars, and identify individuals by face, or just by the way they walk.  The place is just filled with these screens where you can see the computers are actually reading people's faces and trying to digest that data, and basically track and identify who each person is. And it's incredible to see so many, because just two or three years ago, we hardly saw that kind of thing. So, a big part of it is government spending. And so the technology's really taken off, and a lot of companies have started to sort of glom onto this idea that this is the future.  China is on its way to building a total surveillance state.  NARRATOR: And this is the test lab for the surveillance state. Here, in the far northwest of China, is the autonomous region of Xinjiang. Of the 25 million people who live here, almost half are a Muslim Turkic speaking people called the Uighurs. (people shouting) In 2009, tensions with local Han Chinese led to protests and then riots in the capital, Urumqi. (people shouting, guns firing) (people shouting) As the conflict has grown, the authorities have brought in more police, and deployed extensive surveillance technology. That data feeds an A.I. system that the government claims can predict individuals prone to "terrorism" and detect those in need of "re-education" in scores of recently built camps. It is a campaign that has alarmed human rights groups.  Chinese authorities are, without any legal basis, arbitrarily detaining up to a million Turkic Muslims simply on the basis of their identity. But even outside the facilities in which these people are being held, most of the population there is being subjected to extraordinary levels of high-tech surveillance such that almost no aspect of life anymore, you know, takes place outside the state's line of sight. And so the kinds of behavior that's now being monitored-- you know, which language do you speak at home, whether you're talking to your relatives in other countries, how often you pray-- that information is now being hoovered up and used to decide whether people should be subjected to political re-education in these camps.  NARRATOR: There have been reports of torture and deaths in the camps. And for Uighurs on the outside, Xinjiang has already been described as an "open-air prison."  Trying to have a normal life as a Uighur is impossible both inside and outside of China. Just imagine, while you're on your way to work, police subject you to scan your I.D., forcing you to lift your chin, while machines take your photo and wait... you wait until you find out if you can go. Imagine police take your phone and run data scan, and force you to install compulsory software allowing your phone calls and messages to be monitored.  NARRATOR: Nury Turkel, a lawyer and a prominent Uighur activist, addresses a demonstration in Washington, DC. Many among the Uighur diaspora have lost all contact with their families back home. Turkel warns that this dystopian deployment of new technology is a demonstration project for authoritarian regimes around the world.  They have a bar codes in somebody's home doors to identify what kind of citizen that he is. What we're talking about is a collective punishment of an ethnic group. Not only that, the Chinese government has been promoting its methods, its technology, it is... to other countries, namely Pakistan, Venezuela, Sudan, and others to utilize, to squelch political resentment or prevent a political upheaval in their various societies.      NARRATOR: China has a grand scheme to spread its technology and influence around the world. Launched in 2013, it started along the old Silk Road out of Xinjiang, and now goes far beyond. It's called "the Belt and Road Initiative."  So effectively what the Belt and Road is is China's attempt to, via spending and investment, project its influence all over the world. And we've seen, you know, massive infrastructure projects going in in places like Pakistan, in, in Venezuela, in Ecuador, in Bolivia-- you know, all over the world, Argentina, in America's backyard, in Africa. Africa's been a huge place. And what the Belt and Road ultimately does is, it attempts to kind of create a political leverage for the Chinese spending campaign all over the globe.  NARRATOR: Like Xi Jinping's 2018 visit to Senegal, where Chinese contractors had just built a new stadium, arranged loans for a new infrastructure development, and, said the Foreign Ministry, there would be help "maintaining social stability."  As China comes into these countries and provides these loans, what you end up with is Chinese technology being sold and built out by, you know, by Chinese companies in these countries. We've started to see it already in terms of surveillance systems. Not the kind of high-level A.I. stuff yet, but, you know, lower-level, camera-based, you know, manual sort of observation-type things all over. You know, you see it in Cambodia, you see it in Ecuador, you see it in Venezuela. And what they do is, they sell a dam, sell some other stuff, and they say, "You know, by the way, we can give you these camera systems and, for your emergency response. And it'll cost you $300 million, and we'll build a ton of cameras, and we'll build you a kind of, you know, a main center where you have police who can watch these cameras." And that's going in all over the world already.      There are 58 countries that are starting to plug in to China's vision of artificial intelligence. Which means effectively that China is in the process of raising a bamboo curtain. One that does not need to... One that is sort of all-encompassing, that has shared resources, shared telecommunications systems, shared infrastructure, shared digital systems-- even shared mobile-phone technologies-- that is, that is quickly going up all around the world to the exclusion of us in the West.  Well, one of the things I worry about the most is that the world is gonna split in two, and that there will be a Chinese tech sector and there will be an American tech sector. And countries will effectively get to choose which one they want. It'll be kind of like the Cold War, where you decide, "Oh, are we gonna align with the Soviet Union or are we gonna align with the United States?" And the Third World gets to choose this or that. And that's not a world that's good for anybody.  The markets in Asia and the U.S. falling sharply on news that a top Chinese executive has been arrested in Canada. Her name is Sabrina Meng. She is the CFO of the Chinese telecom Huawei.  NARRATOR: News of the dramatic arrest of an important Huawei executive was ostensibly about the company doing business with Iran. But it seemed to be more about American distrust of the company's technology. From its headquarters in southern China-- designed to look like fanciful European capitals-- Huawei is the second-biggest seller of smartphones, and the world leader in building 5G networks, the high-speed backbone for the age of A.I. Huawei's C.E.O., a former officer in the People's Liberation Army, was defiant about the American actions.  (speaking Mandarin) (translated): There's no way the U.S. can crush us. The world needs Huawei because we are more advanced. If the lights go out in the West, the East will still shine. And if the North goes dark, then there is still the South. America doesn't represent the world.  NARRATOR: The U.S. government fears that as Huawei supplies countries around the world with 5G, the Chinese government could have back-door access to their equipment. Recently, the C.E.O. promised complete transparency into the company's software, but U.S. authorities are not convinced.  Nothing in China exists free and clear of the party-state. Those companies can only exist and prosper at the sufferance of the party. And it's made very explicit that when the party needs them, they either have to respond or they will be dethroned. So this is the challenge with a company like Huawei. So Huawei, Ren Zhengfei, the head of Huawei, he can say, "Well, we... we're just a private company and we just... We don't take orders from the Communist Party." Well, maybe they haven't yet. But what the Pentagon sees, the National Intelligence Council sees, and what the FBI sees is, "Well, maybe not yet." But when the call comes, everybody knows what the company's response will be.  NARRATOR: The U.S. Commerce Department has recently blacklisted eight companies for doing business with government agencies in Xinjiang, claiming they are aiding in the "repression" of the Muslim minority. Among the companies is Megvii. They have strongly objected to the blacklist, saying that it's "a misunderstanding of our company and our technology."     President Xi has increased his authoritarian grip on the country. In 2018, he had the Chinese constitution changed so that he could be president for life.  If you had asked me 20 years ago, "What will happen to China?", I would've said, "Well, over time, the Great Firewall will break down. Of course, people will get access to social media, they'll get access to Google... Eventually, it'll become a much more democratic place, with free expression and lots of Western values." And the last time I checked, that has not happened. In fact, technology's become a tool of control. And as China has gone through this amazing period of growth and wealth and openness in certain ways, there has not been the democratic transformation that I thought. And it may turn out that, in fact, technology is a better tool for authoritarian governments than it is for democratic governments.  NARRATOR: To dominate the world in A.I., President Xi is depending on Chinese tech to lead the way. While companies like Baidu, Alibaba, and Tencent are growing more powerful and competitive, they're also beginning to have difficulty accessing American technology, and are racing to develop their own. With a continuing trade war and growing distrust, the longtime argument for engagement between the two countries has been losing ground.  I've seen more and more of my colleagues move from a position when they thought, "Well, if we just keep engaging China, the lines between the two countries will slowly converge." You know, whether it's in economics, technology, politics. And the transformation, where they now think they're diverging. So, in other words, the whole idea of engagement is coming under question. And that's cast an entirely different light on technology, because if you're diverging and you're heading into a world of antagonism-- you know, conflict, possibly, then suddenly, technology is something that you don't want to share. You want to sequester, to protect your own national interest. And I think the tipping-point moment we are at now, which is what is casting the whole question of things like artificial intelligence and technological innovation into a completely different framework, is that if in fact China and the U.S. are in some way fundamentally antagonistic to each other, then we're in a completely different world.  NARRATOR: In the age of A.I., a new reality is emerging. That with so much accumulated investment and intellectual power, the world is already dominated by just two A.I. superpowers. That's the premise of a new book written by Kai-Fu Lee.  Hi, I'm Kai-Fu.  Hi, Dr. Lee, so nice to meet you.  Really nice to meet you. Look at all these dog ears. I love, I love that.  You like that?  But I... but I don't like you didn't buy the book, you... you borrowed it.  I couldn't find it!  Oh, really?  Yeah!  And, and you... you're coming to my talk?  Of course!  Oh, hi.  I did my homework, I'm telling you.  Oh, my goodness, thank you. Laurie, can you get this gentleman a book? (people talking in background)  NARRATOR: In his book and in life, the computer scientist-cum-venture capitalist walks a careful path. Criticism of the Chinese government is avoided, while capitalist success is celebrated.  I'm studying electrical engineering.  Sure, send me a resume.  Okay, thanks.  NARRATOR: Now, with the rise of the two superpowers, he wants to warn the world of what's coming.  Are you the new leaders?  If we're not the new leaders, we're pretty close. (laughs) Thank you very much.  Thanks.  NARRATOR: "Never," he writes, "has the potential for human flourishing been higher or the stakes of failure greater."      So if one has to say who's ahead, I would say today, China is quickly catching up. China actually began its big push in A.I. only two-and-a-half years ago, when the AlphaGo-Lee Sedol match became the Sputnik moment.  NARRATOR: He says he believes that the two A.I. superpowers should lead the way and work together to make A.I. a force for good. If we do, we may have a chance of getting it right.  If we do a very good job in the next 20 years, A.I. will be viewed as an age of enlightenment. Our children and their children will see A.I. as serendipity. That A.I. is here to liberate us from having to do routine jobs, and push us to do what we love, and push us to think what it means to be human.  NARRATOR: But what if humans mishandle this new power? Kai-Fu Lee understands the stakes. After all, he invested early in Megvii, which is now on the U.S. blacklist. He says he's reduced his stake and doesn't speak for the company. Asked about the government using A.I. for social control, he chose his words carefully.  Um... A.I. is a technology that can be used for good and for evil. So how... how do governments limit themselves in, on the one hand, using this A.I. technology and the database to maintain a safe environment for its citizens, but, but not encroach on a individual's rights and privacies? That, I think, is also a tricky issue, I think, for, for every country. I think for... I think every country will be tempted to use A.I. probably beyond the limits to which that you and I would like the government to use.      NARRATOR: Emperor Yao devised the game of Go to teach his son discipline, concentration, and balance. Over 4,000 years later, in the age of A.I., those words still resonate with one of its architects.      So A.I. can be used in many ways that are very beneficial for society. But the current use of A.I. isn't necessarily aligned with the goals of building a better society, unfortunately. But, but we could change that.  NARRATOR: In 2016, a game of Go gave us a glimpse of the future of artificial intelligence. Since then, it has become clear that we will need a careful strategy to harness this new and awesome power.  I, I do think that democracy is threatened by the progress of these tools unless we improve our social norms and we increase the collective wisdom at the planet level to, to deal with that increased power. I'm hoping that my concerns are not founded, but the stakes are so high that I don't think we should take these concerns lightly. I don't think we can play with those possibilities and just... race ahead without thinking about the potential outcomes.      Go to pbs.org/frontline for more of the impact of A.I. on jobs.  I believe about fifty percent of jobs will be somewhat or extremely threatened by A.I. in the next 15 years or so.  And a look at the potential for racial bias in this technology.  We've had issues with bias, with discrimination, with poor system design, with errors.  Connect to the "Frontline" community on Facebook and Twitter, and watch anytime on the PBS Video app or pbs.org/frontline.      For more on this and other "Frontline" programs, visit our website at pbs.org/frontline.     To order "Frontline's" "In the Age of A.I." on DVD, visit ShopPBS or call 1-800-PLAY-PBS. This program is also available on Amazon Prime Video.     