 Good morning and let me add my welcome  to the AI Summit Silicon Valley for 2020.   We are meeting here today with an amazing lineup  of speakers, great opportunities to network, and   learning more about the latest state of the art  in AI. My name is Tim Ensor and I'm going to be   your host for today's sessions taking you through  that great lineup of speakers. I work in the team   at Cambridge Consultants and our role is to help  clients to innovate to create new to the world   technologies and services and experiences, and the  aim of that is very much to allow them to be the   leaders in their markets. Now my personal  interest is working with business leaders   to help them do that in the area of artificial  intelligence. Now it's a great time to be talking   about artificial intelligence, AI is very much  changing the way we're interacting with the world,   it's allowing machines to start doing things we  have really never thought possible and of course,   because of that it's starting to create winners  and losers in many markets, So a great time to be   getting together to think about these issues, but  I think at this time more than any it's probably   right that we take stock and reflect on where are  we, where have we come to, and where are we going   now. I think the first thing to say is that this  is a virtual event, you know mostly we are at home   joining this and over the last several months  I think we've all become familiar with scenes   like this, juggling and integrating work and  life probably in a way that many of us haven't   had to do before, and I've certainly become  a fan of the opportunity to meet the kids   and the families of my colleagues and clients as  we're on video conferences for a lot of the day.   It's also probably worth saying that we owe a  great thanks to the AI Summit team in bringing the   great experiences of the physical event into this  virtual context and of course we have the same   great opportunities that were presented by the  physical events we have the same great lineup   of speakers, and we have the same amazing  opportunities to network with one another,   and there are the same opportunities to meet and  speak with the exhibitors who we have through the   platform who are able to explain how they can  help move us all forwards on our journey in AI.   So as well as being a virtual event of course  I don't think we can go much further before   we realize that we are also in the midst of the  greatest upheaval in a generation. So this is the   image of the Zuckerberg hospital in downtown San  Francisco where the event was hosted physically   last year in the palace of fine arts, and right  now the officials in San Francisco are starting   the process of setting up temporary medical  facility right across the street from where we   met physically for the AI Summit last year. And so  it has been a tragic period with a great loss of   life and significant upheaval to our daily lives.  For our part Cambridge Consultants has worked   very intensively early on in the pandemic to help  the UK government to develop a new ventilator to   ensure that health care professionals around  the world would always be able to give us the   best care. And in six weeks our team worked flat  out around the clock and were able to produce,   from a blank sheet of paper, a fully functional,  fully tested regulatory approved ventilator to   give those healthcare professionals the tools they  needed. Now we're very thankful that that hasn't   been needed yet but I think during this period  we've seen many teams do extraordinary things to   help the world keep going and look after those  who are most vulnerable, so I suspect that over   the rest of today we'll hear most of our speakers  comment on how the COVID pandemic has impacted   them and their teams and their customers and so  we'll hear much more about that i have no doubt. In terms of how technology has played a role  though I think one of the exciting things that   we've seen is that the world's very much has  become a flatter place almost than it has ever   before, and the use of video conferencing  and similar facilities like this event   has very much meant that we can work  across boundaries and time zones more   fluidly and more flexibly than I can remember. So  technology is helping us in the current period.   I've been on projects very recently where  we've had the team working across 13 time zones   from Boston Massachusetts right the way through  Tokyo with Singapore and the UK involved as well   and that project worked just like we were all in  the same office. This screenshot here actually   shows an example of where 150 of my colleagues  from the Seattle and San Francisco offices   all met to try and sing happy birthday to one  of our colleagues over Zoom, so you can see that   technology is helping us to carry on even if 150  people singing happy birthday is not that pretty. So then moving on, thinking about AI it's  worth recognizing that in 2020 this year is the   65th year that we've been talking about AI since  these first coiners of the term used it right back   in 1955. Now this definition for me is still  pretty much the best one I know of where what   we're trying to do with AI is allow machines to  behave in a way which would be called intelligent   if a human did it. I haven't seen a better way  of encapsulating the objective in the heart of AI   all these years later, and then finally of course  we are one year further on into the current AI   renaissance, so much has happened recently and  things continue to move at quite a frantic pace,   and for some of our customers we offer an AI tech  watch service in which we do continual screening   and scouting of what are the emerging trends and  exciting themes in the world of AI, and I thought   for us today I'd just pull out a few, and two of  them are quite high impact and one of them I think   is a sign of things to come. So the first one is  around the area of AI growing up, and we've seen   a huge amount of work over the last, certainly  12 months maybe two years, in the area of the   engineering practice of artificial intelligence.  The topic of ML ops that is machine learning   operations, has really come to the fore recently  and a lot of thought and a lot of work by many   teams has been going into how to develop those  practices and processes to allow us to get machine   learning AI into service and starting to deliver  value. So that's been a big thing. The other one   is probably the major capability announcement of  the year which was in the era of learning language   more like humans do and this is around the open  AI's gpt-3 model which many of us may be familiar   with so this is one of the largest, in fact it  is the largest, machine learning language model   released to date. You know 10 times larger than  the previous examples and this really surfaced   some quite impressive capabilities for a language  model where it was able to do language to language   translation, it was able to start generating  content which were in some areas was difficult for   humans to tell the difference between AI and  human-generated content. It was able to correct   the grammar in English text and it was even able  to learn three-digit arithmetic purely by looking   at the word association. So quite incredible  step forward in language learning capability.   The last one I'll mention then is looking slightly  further forward and this is in the context of AI   making AI, so this is drawing on some of the  research recently published by the Google Brain   team looking at Auto ML they called AutoML-Zero,  and this is around moving the area of getting   algorithms to create new algorithms by doing so  with some of the fundamental building blocks of   maths going right down to some really simple  pieces and allowing AI to construct some quite   sophisticated algorithms using only those basic  mass building blocks. So I think AutoML is a thing   thing for the future, it is definitely moving fast  and I think it'll be here with us for some time   and it's certainly a topic that we're going to be  keeping a close eye on. If you'd like to know more   about this we've published a white paper on the  AI renaissance thinking about where we've come   from and why it's taking off and where it's going  and you can get a copy of that from our friendly   team on our Cambridge Consultants exhibition  booth, so do go and have a talk to them.   So that's some background of where we are  but I think one of the things I wanted to   talk about this morning is the question of how  do we scale up AI. As we met together last year   a lot of the discussion was around proofs of  concept, how do we get past proof of concept,   how do we get through into value for  our our work and I think the question   of how do we scale up the AI is very much the  question that we need to deal with this year. So here's some recent research which gives  me great cause for enthusiasm and optimism   this is from Capgemini and this was published  just this year which shows that we are seeing   many organizations starting to push their  AI innovations through into service and   delivering value. So this research shows  that 11 percent of those organizations   are seeing AI in production in multiple  areas and pushing significant business value   and it shows that further 41 percent of  organizations are on the beginning of that   journey, they're seeing AIi in production on  a limited scale but they are getting it there,   and so that shows that over half of the  organizations in this survey are getting   AI into production which I think is a great  step forward for us on where we were last year I do have an observation though on the sources of  innovation which are being pushed into production,   and I believe that many of those great products  and services getting into service are largely   based on third-party innovation, you know they're  organizations that have brought in AI expertise   and products from outside and they're scaling  those up to value which is fantastic. I think   one of the opportunities that we're presented with  now though is as AI becomes democratized, as teams   are getting more to grips with what you can do  and how you get it to work in the real world,   there is now the opportunity for organizations  to increasingly use original innovation developed   in-house to give them unique value. So I think  that's quite an exciting time for us to be at now.   In that context then, for me, there are these  three areas that we should be thinking about   as business leaders we're thinking about how  do we develop that original innovation in AI,   and there are these three. Firstly building firm  foundations, how do we get the basics right,   the infrastructure tools and team. Secondly, a  mindset of delivering increments, so an idea of   pushing for minimum viable intelligence  and incrementing from there.   And lastly an area I think is often  overlooked, which is the topic of continuous   invention. AI continues to move fast and to  keep investing in research, I think is critical   to continue improving the performance  of our systems we're building. So each   of these is probably a presentation in itself  but I'll share a few quick thoughts on them.   First of all firm foundations, so all of your  work in AI is very much about the team that   you put together and the tools that you give  them. So firstly the team so I think critically   the team we're discovering is more than one team  it is multiple teams. So the data scientists   at the center developing algorithms but then  working with the data engineering team to be   able to format the data and get it in the right  arrangements for your algorithms to work on.   But also then machine learning engineers  who have to take their implementation   and put it often into embedded AI at the edge, in  product or running at high velocity in the cloud.   Secondly then the infrastructure so we run this  super compute on site in our offices in Cambridge   and that really allows our team to do two  things, it means that they can get really rapid   turnarounds and exploring many different options  and permutations in the models they're building.   But it also allows us to get right up close  with what does it really take to build this   infrastructure to run these experiments. Finally,  then the tools that you give them and this is   definitely an area which is fast-moving, new tools  are emerging all the time, and it's something   which is worth some thought because choosing  a particular toolset is not always easy to   switch afterwards, but the capability which these  allow your teams to have is continuing to evolve,   and the combination of this these tools this  infrastructure and the team, is very much the   foundation you build your innovations on. Then  thinking about that continuous delivery mindset   and I see very much the idea of minimum viable  intelligence as this iterative approach of setting   an ambition, proving that concept with the data  and the data science that you have available,   building the first version of that, and then  launching it into the market, and the key thing   about that is it allows you to iterate around  this cycle, get your service into market, and   then crucially collect more data which would allow  you to get around the next iteration with improved   performance for your models. The last thing I  want to talk about is this idea of continuous   invention, how do we add research into this cycle  so that each time we iterate round we can actually   do more with the data that we've got and I want to  share a few examples of the kind of research that   we've been doing at Cambridge Consultants to give  our clients the edge as they're trying to do this.   So firstly is an example of some work we're  doing in the area of autonomous driving and   autonomous platforms and this is about pushing the  economics of AI to allow scale-up. So one of the   best quantities for autonomous  platforms to make decisions on   is high-resolution depth sensing, as you would  get from a relatively high-cost LiDAR system,   but what we try to do here is say, can we develop  a system which gives you the same information by   using a camera and low-resolution depth? So as you  might get from radar. And we've built a model here   which essentially does just that it fuses that  high-resolution image with low-resolution depth,   and then that gives you a high-resolution  depth output, allowing the AI to make decisions   using sensors which are a fraction of the cost The next example I wanted to talk about  was the area i'm particularly excited about   which is what I refer to as teaching AI to have  a sense of intuition, and that's critical where   they have to deal with some tasks which have  vast numbers of options so as bit of background,   there are 10 to the power of 80 atoms in the  visible universe, but as a human we deal with   games of chess on a regular basis so there  are 10 to the 120 numbers of games of chess,   equally for the Amazon delivery driver doing  200 stops a day they have to deal with the   problem which is 10 to the power of 375 numbers  of options. And then we've seen AI dealing with   games like Go, one of the most complex games in  the world and winning against the world champion.   And there, there are 10 to the power of 10 to the  power of 48 possible games of Go to deal with.   So as I've mentioned these kind of problems are  things that as humans we learn to solve with a   sense of intuition. We learn through experience  what options work and what options don't and which   routes we should choose to get us most quickly to  our answer without having to consider everything.   And we've been thinking about how do you teach  AI to do the same thing so this is a shot of one   of our agents solving the problem of building  a bridge and here it's thinking about where to   place the blocks, and it's been through a training  process where it had to learn - what is a bridge,   how do they work, how do they feature when you  have to build in a physics model with friction and   gravity, and what does it need to do to place the  blocks to be able to build a successful bridge.   And even building a bridge that simple has  many many options, so for that size bridge   there are 10 to the power of 14 options that it  needed to consider. But because we trained it,   it had developed a sense of intuition and  experience, and so it only had to consider   and compute 480 different options and so you  can see taking this kind of approach means that   this model was 10 to the power of 11 times more  efficient than brute force. And so this is an   example of the kind of research where you can  start scaling AI in real-world complex problems,   which otherwise we haven't been able to do. So my  view on how we scale innovation in AI is around   building firm foundations, it's about that mindset  of continuous increments and continuous delivery,   minimum viable intelligence and also being able  to have a process of continuous invention so that   you will continue to add the latest research to  get the highest performance out of your models.   So with that, I think I wanted to just draw the  threads together then as we open the conference.   So I'd love us to be discussing amongst  ourselves with the speakers and with each   other, how do we work together to scale original  innovation in AI? Let's share amongst ourselves   what are we doing to push AI innovations into  scale what are the learnings we've each had   from our experience of doing that? And also  what are our experiences of developing that   original innovation, taking our own teams and  creating unique and new capabilities in AI.   I hope we have a great conference all  today, it's my pleasure to open the event,   and I hope you all have a great event  over the next two days. Thank you. 