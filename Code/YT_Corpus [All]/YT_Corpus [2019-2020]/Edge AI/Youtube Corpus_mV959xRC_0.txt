 good afternoon it's great to see so many people here especially right after lunch on the last day of a conference I'm chapala Street and I lead the program management team for azure IOT edge and today I'll first get start this by giving a quick overview of azure IOT edge and then hand it over as some of our colleagues Emanuel and venkat will give you the latest on AI on azure IOT edge and then how we're providing hardware resiliency through kubernetes for IOT edge workloads and increasing observability of IOT edge workloads if you're new to edge analytics the first question is sort of why is it needed and traditional IOT patterns have had devices create large amounts of data and send it up to the cloud in the cloud you use high value artificial intelligence or machine learning to derive insights and those insights drive actions that you most likely send back to those devices however the industry's learned that there's some issues with this pattern primarily if you have a flaky internet connection you want your IOT solution to work regardless of whether the Internet's up or down if I have a smart fire alarm system I don't only want to detect fires when I have an internet connection I also want to detect fires when the Internet's down data also has gravity and these devices are creating lots and lots of data so often it makes more sense to find those insights locally on the device than shipping all the data up to the cloud and a great example of this is like a smart doorbell you don't want to stream video to the cloud 24/7 just to identify faces for the two minutes that someone's in front of your door you'd rather do that facial recognition locally on that smart doorbell and then finally some IOT solutions need real-time responses as opposed to near real-time responses that you can get by sending data to the cloud finding insights and then sending the actions back down so edge analytics allows you to move those insights and actions down onto the local device so that you're independent of your cloud connection you don't have to send data all the way up to the cloud and you can respond in real-time it's also interesting because once you start doing these things locally there's some other side benefits like you can do protocol translation translation data normalization locally before sending to the cloud you can also increase your data privacy so for example you could remove personally identifiable data locally on premise before you send anything across the Internet and that's really important for industries like healthcare that have to abide by HIPPA regulations or even more stringent regulations in the EU so let's take a look at how azure IOT edge enables this sort of world of edge intelligence and we'll start with a workload that's processing data from a camera and the first thing that you have is some custom code that massages the data into a format that your cloud intelligence can use and in this case we'll just say it's image recognition from cognitive services cognitive services will deliver some insight and then you'll have some custom code to take action on that the first step towards moving this to the edge is to package those things up into containers put the containers into a container registry and then define a workload description in the cloud this workload description just says this smart workload is consists of these containers and these are the types of devices to which I target this workload and that's really important because your IOT solution probably has many types of smart devices and it's a problem if the workload designed for your smart cameras starts running on your smart oil pumps I don't think that would end very well so what's cool is that you can create your workload description targeted devices and then when an azure IOT edge device connects up to IOT hub it will say hey do you have a workload for me and if a workload matches the correct type of IOT edges device the workload description will get sent down the runtime will download the correct workload from the cloud and start them up and running and now you have your custom code your machine learning your business logic all running locally so that it's independent of your cloud connection and you can get all those values of edge analytics the other really cool thing about azure IOT edge is that it doesn't only deploy workloads it make sure that those workloads continue to run and report status back to the cloud like deploying workloads is great but you really want to know is your are like your millions of IOT devices working as expected and so reporting that health back to the cloud allows you to understand if there's any issues in your deployment and take preventative actions the runtimes also smart enough to detect if that internet connection goes down and if part of your workload is trying to send messages to the cloud wallet it doesn't have an internet connection the runtime will cache those messages and sync them with the cloud once the internet connection is restored so at a very high level azure IOT age but you create workloads which can include high value cloud intelligence target those workloads at different types of devices in your IOT solution run those workloads locally in a disconnected manner and then monitor the health of those workloads security for IOT devices we feel has a higher bar because these devices are remotely deployed in who knows where and when those you have remotely deployed devices attackers have physical access to those devices and may have unlimited time with those devices and that increases the number of threats to which these devices are vulnerable and so azure IOT Edge has a industry-leading security framework to prevent against some of these these threats it starts with secure boot so if your device of support secure boot you're guaranteed that the image you burn on to your device in the factory is the same image and code that starts up when your device boots every time if you've added a hardware security module to your device like a TPM the runtime will store secrets into Hardware such that an attacker can't get access to those secrets if they have physical access to the device the runtime will then use those secrets which stored in hardware to encrypt configuration information from the runtime onto disk so even if the attacker does get your disk the data is encrypted so it's useless to them the runtime will make sure that the correct workload is running on the machine it will also provision identities to that workload such that they can communicate in an encrypted manner either interred like between the containers in your workload or between the cloud and the edge device trusted execution environments are a feature of devices that ensure code doesn't get changed at runtime after boot and if you want to find more about secure execution environments I suggest you look at breakout 3034 but if your device supports a trusted execution environment you can run the edge runtime part of it in that trusted execution environment to make sure that code doesn't change after boot so that would protect against something like a code injection attack and if your workload has sensitive compute you can also run that sensitive compute in the trusted execution environment and finally we have a security service that runs on IOT edge devices which will allow you to enforce security policies or detect anomalies that are happening on your devices so you can take some further action creating these workloads for IOT devices often takes a lot of expertise that individual developers or even an individual company may not have and so Microsoft is trying to create an ecosystem around edge intelligence and a workload for these edge devices is nothing more than units of compute which are implemented as docker compatible containers and so like a workload often needs to interact with the device and these devices speak many different protocols and we have people in our ecosystem who have spent 30 years understanding how to talk to the devices and so this ecosystem allows them to provide their expertise to a solution developer who may not know the intricacies of every different device and every different protocol these IOT workloads often have analytics so we're working with our cloud partners like cognitive services or as our stream analytics to provide parts of their services to be able to run on IOT edge devices and we encourage third parties to provide analytics that they've developed over the years of their business specialized towards different scenarios to share these analytic capabilities in the marketplace as well so as is V if you contribute a module to the marketplace it helps highlight and help other people discover the hard work and IP that you have to share with the community we've seen awesome progress and momentum with this marketplace back in July of 2018 we source started testing it with first party modules and then a couple months later we opened it up to third party modules in February of 2019 just a couple months ago we let the first first party module start charging for their services , that was as regime analytics and so I believe they charge like $1 per device and that's something that we want to open up to third party modules as well by the end of 2019 and the key point here is that you instead of just sharing your IP which is sort of core to your business you can now sell your IP to this ecosystem and rely on that as your billing pipeline to charge customers who are using that as opposed to creating your own sort of billion infrastructure which isn't really core to the IP that you guys create Microsoft provides the most comprehensive set of edge computing capabilities from our recent acquisition of express logic so now we have a real-time operating system to secure by default mcs with Azure sphere all the way up to private on-premise full cloud with Azure stack and azure IOT edge runs across a spectrum of these devices choosing what device you run is really dependent on the workload that you'll be using and the example I like to give here is person recognition the scenario in which you do person recognition may require a very different class of device so in the sort of construction or smart workplace safety scenario where I have a area of a construction site where I don't want anyone and I want to be notified when I detect a person there you could put a camera there that needs to run some pretty rudimentary person detection just detect two legs two arms a torso and a head and then fire off an alarm and hopefully you really don't have to detect too many people because people aren't there anyway compare that to a person detection system in an airport where you want to identify people there you're doing thousands of recognitions per minute and you have to do it at very high accuracy like you need to recognize the same face whether it has a beard mustache hat glasses what-have-you so even if though both scenarios are doing person detection one can run on a smaller class of device whereas with your in the if you're an airport doing high volume and high accuracy person detection you're probably gonna need to run on server class hardware and Azariah T edge lets you choose what type of hardware you run your scenario on we have flexible architecture so we put support both amd64 and arm thirty-two and in a couple weeks we'll preview arm 64 we run on both Linux and Windows and basically the OS that you're constrained to is something that supports containers but as we mentioned we'll be going to smaller devices in terms of the footprint of the of the runtime and we'll also be supporting smaller devices that don't necessarily support containers in the future I'm speaking of Windows as a Monday as your icy edge is now ga-ga on Windows IOT Enterprise will be shortly GAE on a Windows Server 2000 19 and IOT core but IOT Enterprise is GA today so great like there's a ton of devices to run as rightie edge how do I find one that I know works without the edge and that's the sort of the point of the azure IOT edge certification program and if you buy a device which is a Zarate edge certified you're guaranteed that the runtime works with the device and that the device ships with the runtime on it if you're a device maker we've streamlined the certification process so that most of it can be done remotely through a cloud service so that that streamlines the process and the effort that you have to put into to certify your devices and everything that certified shows up in our device catalog so folks are looking for an edge device have one place to go and device makers who want to sell the device have one place to highlight their IOT edge certified devices so we released azure IOT edge like a little less than a year ago and it's been amazing to see the market reaction to the product as ratty edge deployments have been growing by over 40 percent each month since we released we have over 50 certified devices in the catalog and we have great engagement on our open source github project so as our edges we'll talk about in a second is an open source and you can find all the code on it on github and interacting with the community has been a great experience customers are starting to create solutions with a Zarate edge and go to production and give us a great feedback so we're super excited to see all the progress that's been made in less than a year when we shipped as your IT edge was open secure intelligent and Enterprise ready so in terms of open it's an open source project where you can go see all the code on github we use industry standards like docker compatible containers and have an open marketplace for people to share modules it's secure we provision these device securely through our device provisioning system and as we talked about there's an industry-leading security framework that underpins azure IOT edge and we enable trusted computing via the open Enclave project which is another open source trusted computing project it's intelligent we've on-boarded a ton of services both first party and third party and I mean this is more of like an eye chart you can take a picture of it you can go back and look at it or you can just go to the marketplace and see all the modules that are available as your edge is also Enterprise ready you can scale your deployments to millions of devices you can write your workloads in languages that are familiar to your developers you can use industry-leading development tools like Visual Studio and Visual Studio code and you can do multi person deployments through CI CD patterns with VST s that's where we started some of the places that we're going are things like integrating with Azure plug-and-play that Sam announced earlier this week so that devices can more easily self describe the type of telemetry that they send to the cloud and commands that you can run on those devices will be enabling DPS provisioning for edge devices via x.509 search and that should be available in a week or two in the 108 RC and we'll continue to make advances in trusted competing through the open Enclave project will continue to onboard news new services and some of the ones that have been announced already are up there and we'll go through and Emmanuel go through some of them like nvidia deep stream and will continue to push the bar forward for our enterprises in terms of integrating with digital twins integrating with IOT central allowing you to manage OS settings on a device so said changing network configurations remotely updating the actual OS itself and supporting more platforms like Yocto Windows IOT core and Windows Server 19 so that's a very sort of whirlwind overview of azure IOT edge and now I'm a turnover to a manual and he'll tell you a lot more of interesting details of a eye on IT edge fellow hi everyone I'm Han Yeol I'm a program manager on Israel th and today I'll speak but what's new about AI running at the edge so whenever I start thinking about a at the age I have those categories in mind about first the type of input data and second about the types of use cases and in IOT is the one that which is the most often first is a based on telemetry types of data sound of vision so for today I'm starting with telemetry so sensors collecting like temperature humidity pressure the hero story nighty and has been for several years now is really predictive methods so based on those like data building and small AI model that tries to predict when a machine starts having an issue so that we can prevent it the second use case that we start saying there is a newer is about our asset configuration so think about a complex machine like your MRI it takes a lot of time for an operator to set it up initially there's a lot of configuration and complex optimization algorithm to set it up and so with AI you can speed those optimizations up and set up the Machine quicker about sound so clearly two types of IOT use cases first one is around speech so emitting so building boats in general that's like building a ball in a car for instance so in a hotel room so that you can they can have their own voice agent and the second one is to do predictive maintenance as well both based on sound so listening to a metal cutting cell to know when it should change its blade or listening to the engine of a an elevator to see if it needs some eye clinic technicians to be sent over on so these types of these cases and the last one installed is largest category where we see a really a lot of demand is around vision scenarios and all of those vision scenarios in the end they try to detect pixels in from a camera so images and then convert them into sensors data like a box is is a variable on the belt or there's a missing product on a retail share of cause is a car passing by and so in the end all those vision scenarios about our bound transforming the cameras into sensors so that then you can apply those telemetry based AI to find other kinds of defects right so I'll start with the telemetry types of data types and see what's new there so as your three matrix has been as yet for since we launched so a year ago but the new thing now is that they've got built-in anomaly detection so what this means is that in your sequel query language you just invoke a pretty simple function that will do animation for you so it will it's based on and supervised learning so it's working with your own data and it will find five types of anomalies in those types of data like spikes and dips or like a train going slowly going up or down and deliver change so it's all built in with Si and a variable as yet ii using for telemetry is at this build we've announced asier cycle data box database edge which is very combination of a true sequel with issue stream analytics and packaging them together you know form factors that works really well with ads eh so making it work cross-platform on arm 64 on neck 64 making it work on a pretty small phone print so less than 500 megabytes working with time series data tell me two types of data and keeping the same great features from sinkhole to bring your own model even more complex ones an anomaly detection from a say but like bringing your own Python code or spark occurred in your sequel queries so you can join the early adopter program if you want to the interested in this one so the next type of data type is sound and I'll talk more about speech today so use case is to build a voice board whether it's running into a room on your car and so some for like always connected scenarios and some are for light intermittent connected scenarios so depending on your use case you may want to go for like two options today one is to use Cortana available as it containers that called cotton as back-end and the other one is to build their own board with its own brand and personality that can works intermittently offline with pre-built ai models complexity models by the cognitive services team and so for this last example the three building blocks are like the speech-to-text AI model from the cognitive services team which converts speech into text newest cognitive service which detects intent on based on text and finally the text-to-speech service we which like speak about the replies that your body wants to give back to the user all contain your eyes and a variable I th you know if you join this private preview program so just to give you a small sample a small demo about like Cortana working on a small edge device so I've got a Raspberry Pi here and it speaker so let's see if it can recognize me hey Cortana what's it was a like today the forecast shows Sun with a high of 71 and a low of 54 okay so what it just did is we brought cotton eyes DK as a module on the edge device and it did all these authentication and and call the cloud back-end you could have your own cotton ascii on so it could be fitted to your sinaia to fortify back to the users on like spoken back to the by the edge device and so this cotton is DK does the integration for you about speaking with with the microphone and the speaker of the actual device so there are other cognitive services and just to show you like how easy it is to deploy couldn't leave service on under night eh device I'll pick an example that has already been published in the Asian market place and I'll use as a developer developer tool chain vs code to do that so yet so just before showing the demo I will deploy going to service that is already in the Ezra marketplace by writing at the point manifest from a hub pushing it down to the edge device which you know in that case will be a VM and that will tell it to download this cognitive service running on the VM and will look at the results by logging into this VM VR browser so just so I'm looking into vsq and so here I've got a blank solution so you can see that it's only the edge agent and the job already specified in my in my solution and no modules are available this is my VM running in the cloud and today's it only has right now it only has agent and their job running so I had going to service module to it and so for that I'll use a ith extension from be skewed as an ith module select my deploy manifest I want to add a module from the market place and the module I want to download is a certain sentiment analysis from going cheap services import so what he did it it created for me is my deployment manifest so how did the imagery awry but also all the default container create options like the port bonding and also the route to have the message flow and so what I'll do the only two into that I need to add our Nappi Ikey so I've pre-loaded here and then a bidding endpoint okay and so now just saving this file generating the EPS deploy manifest pushing the deployment to my edge device which is our VM refreshing it so it downloaded the container and started the container so now let's log to this container of your browser so this is the IP address of my VM it was not raining before and now I'm looking to the VM and I guess the IP changed okay so here's a the container that is up and running so all community services look the same they expose this REST API and they expose a swagger fire that tells you as a developer I have to use these cognitive services and so what we'll do is we'll use so this is a sentiment analysis container that we've deployed and so we'll we'll run a a sample query just to prove that it works so here they're trying to replace oh yes try it out first so I've prepared document here so we'll send two queries to this container like we asked this container to tell us what is the sentiment behind the sentence I love live demos and I can't understand French speakers so let's try it okay it executed the query and for the first one it gave me a squirrel back of 0.9 so it seems very positive and second one 0.23 pretty negative right so in just 2 minutes we deployed the cognitive services to a blank edge device from the user marketplace using obvious code toolchain so that's how easy it is to to use cognitive services so now I'm going back into PowerPoint but jump more cognitive services and just as a sentiment analysis also speech ones that I've mentioned so they are ones from vision so custom vision is one that has been around for from the beginning of ith initially custom vision only supported image classification to be exported as a great news is that as of months ago they've added the possibility to export object detection types of model so now we can find objects in pictures and train your model with this no code solution that custom vision gives you so it's it's great to get started with with vision EAJA and there are two pre-built going tip services like face detection and face recognition and text recognition you can pre-register on this URL to get access to them so I'll deep time now little bit more about vision scenarios and first talk about topologies are the two types of topologies we're saying and and when to use each of them and also the types the two types of software architectures that we sing and we would come in so the first apology is an intelligent camera so device like like this P body camera sorry people is a good name the public name is AI vision deaf kid and it has enough power to run in the eye model on the camera so it is an edge device itself that as hardware accelerators that can support a vision model so it's recommended when you don't have high density of cameras you only need a few per side or when you you don't your internal network doesn't have a great bandwidth that case is better to use smart cameras but it only works when you can put new cameras on your side because they need hardware accelerators the second topology when you find some swen you can't add new cameras is to use an intelligent gateway power so you have like regular cameras which may be existing or that you add to your site when you need a high density of them that you connect to an intelligent gateway and the interns and Gateway will do all the processing vision processing for those cameras so this works better when you've got a high density of cameras besides or a very poor internal network or existing CCTV camera that you want to use so now talking about the software architecture for those solutions so you essentially have like two ways of doing it what I've shown you with the cognitive services is primarily as one on the Left where you've got separate containers so first container is that data capturing of all the frames and then sends all of those frames there's also pre-processing as well like down sizing gray scaling and so on everything that I need model needs and then send those frames over to a separate container which does the rent a visual model so it gets a results back and then share it with the ith runtime and so this is great because it's really simple to get started can get started in minutes I've just shown it to you it's very modular you can reuse the same AI components at the edge and at the Claire and that's our cognitive services walk today but you do have a perfect when you do that and because because of those two containers you need to transport those frames and only one of those container can access a hardware accelerator so it's for non real-time applications when you need true real-time application so processing 30 frames per second for each cameras then you need to have more optimization and the way to do that today is to have like one container with several plugins in it so that you keep some level of modularity that is very efficient in to build your video pipeline so it will capture all the frames from the camera dance down skills and do all the pre-processing and then pass them over to the AI plugin but in that case is no in-memory copy the plug-in just reuses the frame just uses a pointer in memory to the initial frame so that's a kind of optimization that you can do by having everything running as one container the second one that you can do is now you just have one container so you can push everything into the hardware accelerator like a GPU so you don't have any hardware conflicts when two containers try to access it and so a good example of that is a deep stream which I'll show in a minute also downsides of it is that it's a bit more complex right here introducing extra tools you need a video an extra video framework that manages all those plug-ins for you so it's a bit more complex so let's deep dive at the demo of like Nvidia deep stream running on i-th and the use case we'll use is one of a retail distribution center so typically big retailers they've got these distribution center where they've got tracks coming in and out boxes and then the boxes needs to go to a different track to go to Washington State Oregon State and they use conveyor belts to merge and salt and and censored boxes to in the right track so if the belt if the packages on the right belts then it will go in the right track if not and they lose some money by because they'll have to worry about it they also lose some money if like package is damaged and so that something that you would like to catch as early as possible also packet is falling off from the belt simply is another thing that they are trying to they want to automate so here we've marked like an integration with RT central to show like how this and which a deep stream integral without integration with HGH could walk and so Nvidia de stream here is processing 16 video streams so 16 cameras all at 30 frames per second on one single edge server and so this edge server is in that case was a the one that we use in our lab was a Lenovo edge server is a Nvidia t4 and and because of this highly optimized container provided by Nvidia and integrated right edge we were able to get to those types of performances so that's a lot of influences to do every second that's like for 480 influences and not just in France is actually for 480 frames to completely process every second so that's a lot to ask to your little edge server and just to complete the story if you zoom on one of those simulated conveyor belt so here's this box with the tag is okay this box without the tag is raising in al-ahmadi this box is not raising in almería this one is okay as well and i think the next one yes it's not supposed to be on this conveyor belt so an Anna Marie is raised yeah so here really we've demonstrated like how to the intelligent gateway to process many video streams on on with without eh and so this summer Lenovo will certify the at the new edge server which will include and t4 GPU and NVIDIA will publish the software the video antique software to be able to reach this kind of performances so the last thing I wanted to talk about is whenever you're dealing with a i1 in important piece of it is how to manage your data because the AI is built with data so you need a lot of training data to begin with and even once you have you a I model you want to retrain periodically or your model and you also want to keep some snippets for key events so how do you deal with your data so for Timmy tree data start with using the storm for what which you baked in ith but if you need like store and query functionalities then you'll need to bring your own database and we've got several options from our Asian marketplace like with this agency collides and edger sequel database age will be another one but how do you manage large finds like images and videos so either you've got an appliance that already does that for you like data box age oh you use for any other types of hardware you can use this blob storage module which exposes the same REST API is in the cloud so you get consistency between your edge application and your cloud application and the new things that they've just added is cheering from the device to the cloud so what this mean is that as soon as it has internet connectivity it will start moving those blobs from the device to the cloud automatically for you and it will you can set some type to leave settings so that you can keep the device clean and not explore the hard drive and so this will be jiaying soon into moons on linux and windows alright yeah so that's all I wanted to share any I and now I'll turn it over to Venkat we'll tell you a little bit more about resiliency and observability hello everybody so a quick show of hands how many of you have heard of or played with kubernetes before okay it's like so last year I got up on the stage and we introduced IOT edge integration with the virtual cubelet a IOT edge connector that allowed you to manage your IOT edge deployments from a kubernetes cluster in the cloud now based on customer feedback we are taking this to the next level where you can actually run your IOT edge workloads like a manual showed an IOT edge workload running in a VM in a kubernetes cluster so why is this useful why is it interesting so one word which is resiliency so to give you a quick overview of what kubernetes is it's a compute distributed computing platform that takes a bunch of discrete compute nodes and creates a layer an infrastructure layer that is highly resilient now this infrastructure layer an API is exposed on top of this infrastructure layer an API to which applications can submit workloads and these workloads have to be expressed in the kubernetes application model but once they do that kubernetes assumes the responsibility of placing those workloads on the write node on the cluster based on current load also probably more importantly keep them running so it is continuously monitoring the cluster doing health checks on all the different nodes and making sure that workloads are moved off of unhealthy nodes and on to healthy ones and IOT edge and kubernetes make a great combination because they are based on the the very same underlying technologies which is the open container technologies and they build on each other's strengths a kubernetes provides that infrastructure layer underneath and IOT edge brings the cloud manageable application model that enables easy bi direction communication with the cloud offline operations a modular architecture everything else so it's the best of both worlds now the second point is really important where we are talking about the exact same management and the module experience that you would have for a normal device even if you are running on kubernetes that's because what we do is we do not distinguish we do not expect that the developers module developers or the module writers need to learn a new runtime a new way to build a module etc right they manage it just like any other IOT edge device and the magic happens in the IOT edge runtime which is now enlight understand that it is in a kubernetes cluster and it's going to do automatic translation between the IOT hubs easy to understand application model to a more kubernetes native language and then benefit across benefit from all the cool all the advantages that kubernetes brings to the table it does some unique things as well where if you have one kubernetes cluster all the resources for that edge device are actually names based into a isolated namespace specific to that device so that means you can have let's say you have a large kubernetes cluster on Prem you can have multiple edge devices sharing the same compute fabric and this is not possible in our native use case or a VM use case right now right and just to show you how the architecture looks like from a high-level this is how it looks like please go to that link where we spend a lot of time documenting and giving you examples of how all of this works but if you see the workloads that are running in the blue and red boxes so those are the workloads that you've defined from the IOT hubs application model and it's all working seamlessly because when we're doing the translation when the edge runtimes doing the automatic translation it's using the pod which is a scheduling unit and kubernetes and starting a new container alongside it which is the proxy container the proxy container proxies all of the communication to IOT HD so the modules themselves can be can don't need any changes they just talk to the proxy and the proxy takes care of wherever the i/o THD is in the in the cluster and proxies communication and gets all the details so let's see a live demo of this in action right I'm going to use a KS because it's just easy to do and I want to show you high availability and actual resiliency as well but you can use any kubernetes cluster it could be an on-prem cluster as long as you have a certified kubernetes api that the cluster is exposing it could be a single node cluster also and we would run just fine so what this is going to do is it's going to browse up to the AKS dashboard which is running a coupon which is running up when it is clustered this is a newly bootstrap cluster it's not nothing running on it so if I go to the nodes it has three nodes a KS VMs and then the namespaces are just the system namespaces they don't have anything running except the system namespaces now let's go to so now you have a cluster you have you have that resilient compute fabric that I talked about which is ready to accept applications so how do you deploy applications onto this so in this demo here demo hub here I have one particular device which is the B demo device as you see it is doesn't have any modules created it's just the device identity is created it has a device connection string but that's all so now we want to associate our edge device to the kubernetes cluster that I just just showed you so go back here and here we using helm helm is like a package manager for kubernetes it allows you to to install applications into your cluster so that's what we are doing if you see the connection string this is the very same demo device that I talked about we are getting its connection string and passing it to kubernetes and we are also providing a persistent volume which is a kubernetes concept where you can store state this is in this example it's storing state for the edge daemon so as the edge daemon moves over to an other node it takes its security context along with it to another node so that it can now authenticate requests from various modules so now this is done that's all I just had to run one command and let's go back to our kubernetes cluster and see if anything has happened I talked about namespaces this was a system namespace as soon as i refresh it right here you have this is the IOT hub name be demo hub and be demo device it is magically shown up here you we will now go and see what's running on here so we go to this namespace change from default to the device namespace and look at the pods in this namespace so as you see the edge agent and IOT HD are already up and running they've been running for 45 seconds they have been assigned node 0 to run on so now you are you for workloads so here's where the other magic that I talked about happens right so you don't need to install or understand any kubernetes commands to deploy workloads on here so in in the example I will take the very same sentiment analysis cognitive service that a manual should but this time show you the view from our portal right and the the marketplace itself so here's our marketplace as chapala said it's you know super popular and growing all the time every time i refresh this page this number increments every week so that's super exciting so I will go in here and find my find the sentiment analysis right here so okay this looks good so I will say get it now so this is just like I would interact with any other device correct so I this will go through the process and associated with the Azure subscription that I have and tell me where I want to deploy this there you go be demo hub and it says ok which device do you want to apply to I'm doing a deploy to device B demo was the one I talked about and I select this and hit create so now it takes me to the detail so this is the exact view a similar view to what what emmanuel showed you but this is from the portal so the same billing endpoint is something that I will put in and my API key that's it save here next okay this is the default route submit that says it's done and if i refresh here it's saying it has three modules right so what I can do and now it says okay run time status is okay just change to okay so what happened in our cluster so let's go back to our cluster look at the parts and i refresh this they are the sentiment analysis and the edge hub have automatically deployed to the kubernetes cluster without me interacting or in doing any cube CTL commands i just went through the portal and they're magically running on my kubernetes cluster here and if you see where they are running they're running actually on different nodes the sentiment analysis is running on 0h hub is running on node two and then the other two are on zero as well right so now the the workload has deployed on to my cluster but in kubernetes to give it external axis i need to give it an ingress point so that's what i will go into fine right now so i go back to my demo and i do i use this command so basically this is since since we don't want to wait for a load balance or IP to be a sign that takes a couple of minutes i have gone ahead and done a static IP but if you see this is just exporting exposing the port 5000 which is the cognitive services port and then this is the cognitive services external lab that is doing so I will go ahead and issue this command and then this service has been created back to our cluster a service would be created in the default namespace so I go to services here and you see right away that I have an ingress with an external endpoint that I can hit so let me click and pray but there you go it's the very same cognitive services container which is running on kubernetes and it's it's working right here and if I go to the swagger is the same swagger I can just expose I can post whatever sample data that they have here it just works I think it's at them there was D ya I do try it out and I do execute and it just works because it's just the same one now this is just like the server I mean this is just like the VM that we saw what extra do you have so let's push this a little further and see if the demo gods are with me so I go back to the pods themselves so this is the pods are in the name space of the device like I mentioned and I have this part here and I notice that this is the sentiment analysis is running on part on load 0 so I will copy this go back to my demo and I will simulate that I need to bring this one because it has a horrible security patch security issue and we need to bring it down immediately to patch it now if this were a VM and I needed to patch this your cognitive service container is down until you reboot and apply the patch your edge deployment is done so let's see what happens here so I will drain this node which is kind of saying push evict all the pods from this node make it unavailable to schedule and let's see what happens so I'm so no this is going ahead and it is evicting the pods from that particular from from from that particular node which is not 0 it takes a minute or two but everything is gone so let's go back to our cluster and see what happened so just remember this was running on node 0 i refresh this kubernetes automatically detected that that node is down and right now you see it's on node 2 right and this has the exact same stable endpoint that we previously had so this is the same one so I will go in here refresh it let me try that again there you go it's up and running it's the same IP address the same stable IP address it did not and I can actually go to the swagger definition right everything just works it's almost like the client never realized that an entire node is out of commission here right and this is the resilience that kubernetes gives you and brings to the table so that's the end of my kubernetes demo but I would like to talk a little bit about observability as well and before we talk about observability I want to talk about some challenges that Edge has that cloud deployments don't have right so edge is deployed in a variety of different conditions and hardware unlike a homogeneous environment that is cloud edge can run on Windows can run on Linux can run on arm on 32 m60 for Windows arm whole variety of things and a whole bunch of environments as it's from everything ranging from a lockdown factory floor to literally and I have talked to a customer this in the middle of a Malaysian rainforest right so connectivity is not a given by any stretch of the imagination lots of times people are customers or early customers had trouble bootstrapping the device because certain ports were not open or connectivity was not there and they had to resort to going and looking at logs to figure out ok what went wrong what port didn't have access so we took this real-life learning as well as learning from our own support that we provided over the last nine months to production customers and packaged all of that know-how into an easy-to-use built in tool called check now what this does is with a simple command it will go ahead and perform connect to your first configuration checks to make sure that the device is configured they know they no errors in the way that device string or the DPS provisioning has been set up also it checks those configuration against production best practices that we have documented and raises warnings to say hey some of these best practices like in this example a logs policy or a DNS where has not been specified so this might cause some problems down the road for you right and then finally the connectivity checks where all of the port's that the edge device may require based on the IOT hub that it was configured in it will go ahead and do those checks and immediately flag any issues so this is a simple but a really useful tool in our customers toolbox to get boot start with edge and it helps us also in in helping support issues and tree to them as well right so and this is available right now in 107 so which cut which was released the release 107 came out on Mondays so we're looking for feedback on that and this is just like our first version of this we want to use the community feedback to improve this add more checks that are more useful but in some cases logs are still useful right but again edge is unique normally if you're in the cloud you would set up a logging agent that ought that continuously streams logging data from there from all of the modules to a cloud endpoint and then you would go ahead and browse the logs from that endpoint but there are many challenges in edge right so edge you could be deployed in a you know on a satellite connection where the bandwidth is very expensive slow or scarce and so you don't want to use that to be pushing logs all the time plus the cloud injection takes time to for it to process and actually process the logs so we've been experimenting with this and we've leveraged and IOT have feature called device streams which lets you communicate Stu services communicate with each other with the IOT hub acting as the broker for trust and ensuring TLS connections and security standards between these two things so you can learn more in this device streams but I think a good analogy is if you remember the telephone exchanges or the yesteryear right you would have if a wanted to call be a would call the operator and say hey I want to connect to B and then the operator and say okay verify that it is a who is calling call B and say hey a wants to talk to you do you want me to connect and if they say yes then you plug them in in the dashboard and they can communicate with each other so that's exactly what the IOT hub is it is that operator who is sitting there establishing trust between these two parties and what that gives you is a real-time logs from the H device end-to-end security which is broken and guaranteed by the IOT hub and zero config on the device you don't have to open any ports you don't have to install any additional agent it just works so let me show you we've prepared a video let me show you of the the demo of that in action now just a word of caution this is coming soon we intend to bring this to the market soon but there's there are some other dependencies that have to be met so this is literally what I'm showing you is what we came up at a at a hackathon a month ago right so we want to get this to market but I cannot promise that the UI will remain the same or the experience will be exactly the same but I wanted you to get a feel for it and let me know what you think so here's the video so you have a normal age device you click it right and get into the edge device details it has three modules set up normal like it normally does right including a simulated temperature module but notice it has a device logs preview right so you so you let's click on that and then now you get the very same module list from which you can select the module that you want to get logs from in this case edge hub specify how how many log lines in history you wanted from and say start streaming that's it no inbound ports no extra agents just pull the logs directly from the device which could be in the middle of the rainforest and as showing you in real time in on the portal so if you actually see notice the 110 offset you will see that increment because this is real-time logs from the device right and because I asked for a tail of 100 that is hundred log lines in the past I can actually see all those hundred as well so it's it's that simple and that's that's the kind of power we can bring by using all of the services that azure provides so what do you think do you think this would be useful to people yeah right thank you so we can use this in our planning meeting and see how many people clap so let's prioritize this but yeah so that's pretty much the content for today for resources please look at our documentation we've spent a lot of time to organize this and make it as simple and easy to get started and go into more advanced scenarios like chapala mentioned we are an open source project we have great community engagement if you encounter an issue feel free to open a bug and we are we manically many actually monitor that as well and then if you have feature requests the feedback sizes are some more IOT sessions like we're on the last day so most of them are already done but you might want to check out the Windows IOT one in in about half are they have a H demo as well and all these are recorded and available for your later viewing and that's it thank you [Applause] 