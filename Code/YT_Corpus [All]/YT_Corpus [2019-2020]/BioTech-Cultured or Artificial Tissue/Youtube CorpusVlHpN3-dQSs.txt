 (upbeat flute music) - [Narrator] 3D printing and stem cell research. One of the top 10 science discoveries of 2019. And, a look at robotics. All, on this addition of On Beyond. - [Narrator] The human brain is one of the most studied subjects in science but still much is a mystery including the interplay between the brain and other organs, like the eye. At the UC San Diego stem cell program researchers are growing tiny brains from stem cells in order to further their understanding and they're not the only ones using this approach. - in order to get the complete picture of how the brain develops we need to understand what happens when the brain receives and process sensory information from other organs such as the eye. And that's where Karl Wahlin comes in. - [Narrator] The connection between the eye and the brain has fascinated scientists for hundreds of years. It seems miraculous that rays of light can be transformed into a complex understanding of the world but sometimes the system breaks down leaving people in the dark. - Photoreceptors or ganglion cells can die and once those sells are gone, those cells are gone permanently. And so we're looking at new ways to restore function to the eye. - [Narrator] Karl Wahlin is the director of the Richard C. Atkinson Laboratory for regenerative ophthalmology at UC San Diego. His lab uses stem cells to create tiny human retinas in order to study eye disease and hopefully one day, cure blindness. - One of the powerful things that we can do with retinal organoids is to introduce patient specific mutations and this is something that's been made possible over the past five years by new gene editing techniques. - [Narrator] Wahlin's lab uses the crispr gene-editing technique to create retinas with the exact mutations found in people with eye disease so he can study how they develop and what treatments might work on each mutation. - [Karl] Previously, most of the studies that we would do to study inherited retinal degenerations would be done in animal models which take a long time to develop and you're not very scalable. The ability to make human organoids with diseases relevant mutations means that we can have many mutations, we can have thousands of samples and we can test many of these with different drugs. You just simply can't do this with living animals in the same scale. - [Narrator] He's teaming up with the Muotri lab which builds brain organoids to study how the brain and eye influence each other during development. - [Karl] But we know from decades of researching other species that sensory input is very important for brain development and vice-versa. The information that we can get from this kind of approach, the cerebral organoid retina co-culture system will allow us to understand how those connections are made. There're diseases such as Leber congenital amaurosis in which photoreceptors died very early stage so this is childhood-onset. It's not clear what happens to the brain connections once those photo receptors are lost at a very early stage so if we're able to cure blindness this is going to require knowledge of photoreceptor protection as well as to understand how those connections in the brain could potentially be perturbed. So over time as we've developed this cerebral organoid retinal co-culture system we've recognized certain technical limitations and one of them is that the retinas and the brains, they tend to be absorbed by one another. And so we need physical structures in order to separate them. Shaochen Chen's group has a lot of experience developing biocompatible materials so they've been building three-dimensional scaffold systems for us to separate, physically separate the retinas and the brains and this is going to be one of the critical components that we use in order to build a better integrated brain-retina circuit. - [Narrator] At the same time, Wahlin's lab is looking into a treatment for eye disease straight out of the animal kingdom. - [Karl] There's a new area in retinal research and it's a very fascinating area, it's called endogenous regeneration and this is the process whereby specific support cells in the eye can be reconverted into other retinal neurons such as photoreceptors or ganglion cells. When you think about endogenous regeneration probably the most powerful example is a lizard or an amphibian that has lost its tail. A lizard that losses its tail can grow a completely new tail in a relatively short period of time. In the eye, there is a similar situation. Some types of fish such as Zebra fish have been shown to regenerate an entirely new eye once when lost. In mammals we seem to have lost this capability, at least naturally, to do this. There is recent literature that suggest that this can actually happen if given the right instructions and so our lab very interested in taking knowledge from other species, using this in our system in order to endogenously regenerate retinal neurons. In 10 years from now what I really hope we'll be able to accomplish with this system that were developing is a platform to test new therapies. There are hundreds of mutations which need to be addressed and we can't do this on a case-by-case basis. If we can have a system where we can study many different mutations in a system that physiologically relevant coupled to a brand. We would have a system where we can test new therapies like drug discovery or gene therapies, or in the best-case scenario, endogenous regeneration. And if it did work, to cure hundreds of mutations. Now this would be something that would be extremely powerful and would transform the way medicine works. - Karl's work show us the potential of stem cells for not only restoring vision but also for understanding how our eyes and brain work together. Next we visit with a bio-engineer who is helping to advance this work. - [Narrator] Measure twice, cut once, the old adage goes. An inch here or there can make a huge difference in a construction project but when it comes to building a human body those measurements go from inches to microns. One millionth of a meter. Scientist at the UC San Diego stem cell program are working at a scale that small to answer some of life's biggest questions. - Our mission to understand brain development requires we study the connection between the brain and the eye. Bio-engineer Shaochen Chen is helping us thanks to his work connecting damaged spinal cords. (ghostly music) - [Narrator] The human body is a massive network. Signals traveling along neural pathways allowing us to see, smell, hear and move. But what happens when those connections are severed? Can they be repaired? Or are they lost forever? - [Shaochen] For the case of spinal cord imagine you can, using this kind of 3D printed live tissue for that patient and they can get recovered within couple months and walk again. - [Narrator] Shaochen Chen is the founding director of the bio-materials and tissue engineering center at UC San Diego. His lab create functional biological tissue using stem cells and a complex 3D printing process. - In bio-printing we print cells with gel and then we build a functional biologically active materials. So in the case a heart, when you print this tissue, it can beat, it is not just a plastic model. We have been working on this topic for the last, almost 20 years. We start from scratch and we build our own printing machines. - [Narrator] Those machines shine light into a gel full of stem cells using patterns derived from CT scans to match liver, heart and nerve tissue. Any spot the light hits becomes solid. - These cells that are from patient's own skin. So you can take these cells and reprogram them into functional cells like heart cell, liver cell nerve cells. And then we can print these cells into the structure and in that case the piece is the patient's specific and you can put it back into patient and hopefully it will help to grow the heart repair the livers and also we grow the nerve tissue. - [Narrator] Chen's lab has already found success repairing severe spinal cord injuries in rats. Now Chen is partnering with Alysson Muotri and Karl Wahlin to help hem understand how brain and eye development influence each other. He's devised a way to keep the tiny brains and retinas they're studying separate, just like they are in the womb. - [Shaochen] Is a very exciting opportunity for us to work together with Alysson's lab and Karl's lab. All three of us are maximizing our strengths to build this complex organoid system that has the retina in one end and a brain on the other end. Then there's a channel with the bio-material that we studied over the years to bridge these two together in a very precise fashion. - [Narrator] That channel allows the brain and retinal organoids to form connections so researchers can see how those connections influence brain development. And the Muotri lab is also hoping to use Chen's bio- printing techniques to create tiny blood vessels allowing brain organoids to become larger and more complex. - [Shaochen] In our case we use a light and it can really focus the light into a tiny tiny spot or patterns and then we can re-recreate this very fine bio-creation network. - [Narrator] And bio-printing has other revolutionary possibilities from speeding up drug testing. - [Shaochen] It takes average 12 years and 2 billion dollar for one drug. Now since we can print these human tissue they can directly test whether this drug will be toxic or whether this drug will be effective or not in the situation of a human tissue. - [Narrator] To perhaps one day, patching the human heart. - [Shaochen] Imagine yourself in the future that we can create this functional human tissue that can be used as a patch to put on the patient and repair that heart damage and then the heart go back to normal. That's, I think that's very exciting for me and I'm so excited to be involved in this kind of research work. (upbeat flute music) (funky electronic music) (upbeat flute music) - [Narrator] Acclaimed by Discover magazine as one of the top 10 most significant scientific achievements of 2019, researchers with the UC San Diego stem cell program working at the Sanford Consortium for Regenerative Medicine witnessed and then investigated the emergence of complex neural signals in self organized colonies of cortical neurons. They're called cortical organoids or brain organoids because they have many of the characteristics of a developing brain. The researchers have been generating and working with brain organoids for some time but what they observed was a surprise even to them. - [Alysson] My lab has been working with brain organoids for a while now and they mimic human development at the molecular level as well as the cellular level. The organization of the cells resemble some of the organizations that we see during development. As these organoids mature we can identify different cortical layers being formed. We have been measuring the activity of neuronal networks by using mute electrode arrays or MEA's. after about four to six months of culturing these organoids, Priscilla and Cleber from my lab, they came to me and said, "we have a big surprise." - The whole well was synchronized and there was a lot of activity going on. We were never able to see so high levels of activities so we were just very surprised. So was very unexpected result so that would motivate us to further investigate what was going on. - [Narrator] The researchers performed single-cell analysis on the organoids looking at gene expression in nearly 20 thousand cells to confirm the cell types necessary to make a functioning network. They verified the presence of neural progenitor cells and their subsequent differentiation into four other classes of neurons as the organoids matured. Intermediate progenitors, glial cells and both glutamatergic and gabaergic neurons which are critical for the production and transmission of neural signals. In particular, after 6 months, the neurotransmitter GABA was detected. - These results suggest the presence of the basic components for the generation of a neural network in a developing human cortical model. - [Narrator] The researchers conducted functional tests at the single cell level which confirmed that excitatory neurons were functioning and larger-scale observations with MEA over a 10-month period, revealed increasing frequency, complexity and organization of signals as the organoids matured. But what could all this signaling activity mean? To understand the significance the researchers turned to collaborators who specialize in understanding neural electrophysiology. - So that's when we turned to our collaborators in the Voytek lab, this is Brad Voytek at Cognitive Neurosciences, here at UC SEG. - In the Voytek lab we look at a lot of the human electrophysiology. So signals like EEG, ECOG and MEG and the reason why these oscillating organoids are interesting is because oscillations are a ubiquitous feature in animals as well as humans so that's why we think the organoids that are oscillating are special. So what you're seeing in these traces are the total number of neurons that are firing at that time. A higher peak means there are more neurons or more action potentials are emitted. At six weeks the neurons don't really synchronize, they fire sparsely and randomly. Starting at two months, they start to synchronize in these burst events. They have these periods where all the neurons in a network would activate at the same time. Starting at four months, they spike really quickly once and then they spike again within a couple hundred milliseconds. So that's what we call an oscillation. And then at six months, there are more and more cycles in this oscillation. It's very regular, you see the same oscillation. But eight months, the trajectories become less stereotypical. - [Narrator] The Voytek lab revealed multiple frequencies of oscillations nested within each other on scales from 10's of seconds, down to milliseconds, which was an important revelation. - [Richard] So this nestingness or cross-frequency coupling is another feature that we see in human as well as an animal electrophysiology. - [Narrator] With the oscillations exhibiting known characteristics of neural signaling, the researchers went a step further in their investigation. - If we have that much activity it is possible that these networks will generate brain waves similar to the ones captured buy EEG's. - [Narrator] To investigate this, they developed a model from existing data to which they could compare the organoids signals. - So we were able to find this clinical data set actually of preterm infant EEG data. And so this model is basically saying if we just trained a very simple machine learning model on the baby's EEG features to predict how old the babies are. Could we then use that to predict directly using the organoids features, how old the organoids are? - [Narrator] While on the surface the EEG data and the MEA data look wildly different the researchers looked closely at agnostic characteristics that both data sets shared. Namely, duration of an oscillation event and the interval between the events. The model was trained using data recorded from actual neonates aged from 25 to 38 weeks. What did the model reveal? - In the time span where the model hasn't seen the EEG data, so before 25 weeks, it predicted really poorly for the organoids. Whereas starting from about 25 weeks the prediction became a lot more correlative with the actual developmental time of the organoids. Therefore from the models perspective, there are similar features in the EEG data from the preterm babies which it has seen, compared to the ordinary data, which hasn't. When we use only those features, this model was able to predict what the actual culture age was. It might suggest that we can use them as models of neural development for example or patient-specific models to test out drugs or disease interventions. - [Narrator] This is one of many things that makes this discovery so significant. It holds the promise of changing the future of neuroscience while improving the human condition. - They are an attractive model to start exploring these early stages of human development. There are several neurological conditions and psychiatric conditions where the problem relies on network for example autism, where the genes that are implicated in autism actually are very active in these very early stages of fetal brain development. These are conditions that affect millions of people in the entire world so having a model is instrumental if you want to create better quality of life for these individuals. (upbeat flute music) (upbeat electronic piano music) - [Justin] SALTO is a little 100 gram robot and it's only about one foot-long all together. But we think it can do a bunch of really exciting tricks. I have been working on SALTO for almost four years. it's been so much fun the whole way through. With the first version of SALTO we demonstrated that it can jump once off the ground and then again off the wall. Now with the newer version of SALTO, it can run for up to 10 minutes and time or even a little bit more and do hundreds of jumps in that period. Its maximum jump is about four feet high and can run eight or 10 miles an hour which is pretty fast for a little guy. It can clear obstacles by making really large jumps or by jumping far. It can even follow a moving target if we tell it what it is. The robot can also chain these maneuvers together so that it can jump up onto things and clear obstacles very quickly. - It's worked probably better than any of our other robots we've had so far. These fast accelerations let us move on surfaces where a conventional robot would just fall right off. - [Justin] Three, two, one. (rhythmic tapping) The motion-capture room is one of our experimental test setups where we have almost a dozen cameras on the ceiling, all watching the robot. This is the motion capture software we use to track where SALTO is in the room. All these green lines point to where the cameras see it and this is how we can figure out how fast it's moving and what angle it's at. This is SALTO's control board, this carries the little tiny computer that's doing all the processing and runs the algorithms that we have written for it. My ground station laptop listens to the motion capture system to know where the robot is and then calculates what we want the robot to do and sends a radio signal to let SALTO know what angle we'd like to reach and how to extend its leg. You will see it tilt over forwards so that it will bounce up onto the platform. Then in the air it will redirect itself backwards so it will jump off of that platform onto the one behind it so that it can get to the spot it needs to very accurately. Now that SALTO can go to a particular spot, It needs to know which way it's pointed and so to do that, the robot has to use its on-board inertial measurement unit which kind of works like a humans inner ear essentially giving it a sense for which way is up when it's jumping so that it doesn't fall over. (rhythmic tapping) When we take SALTO out of the motion-capture room and out into the real world it has to do all of that on its own measuring where it is, and which way is up and how fast it's going. (rhythmic tapping) Next there is a lot of things that we'd like to get SALTO to work on. We'd like it to move on more complicated surfaces besides things like concrete or wood. Maybe better things like grass or gravel. - There's lots of things one can do by adding on pairs of legs or adding on arms. So we would extend SALTO to add ability to, for example grab onto branches to land and launch from those things. - There's lots of things that go into making the robot work and all them have to work together. The LED mechanism and the algorithms and the control and me as the person with the joysticks. Now if you can get them to all work together and get the robot to go places it's super exciting and really fun. - Three, two, one. (rhythmic tapping) (wood knocking) - [Audience] Yay! - [Audience] Wow! - [Observer] Nice job! - [Observer] Oh, man! (upbeat flute music) - So I work in human-robot interaction and the goal is to design robots that can help people and their everyday lives. So my work focuses on designing algorithms that enable robots to understand its surroundings and learn about humans, more specifically, multiple humans at once. So my work actually looks at how do we detect groups of people in real world environments so that robots can work in teams with them and the reason why this is important for computer science is because this is actually very challenging to do this from a mobile platform. So if you imagine you have to actually account for the robot's motion, you have to account for the people's motion and robots need to be able to do that whenever they enter real-world settings. And in the field of human-robot interaction they focused a lot on one-on-one interaction between a human and robot and so it's important that we start looking at the interaction between robots and multiple people at once and then start to work our way up to multiple humans or multiple robots at once, right? And how do the robots actually work effectively with these groups of people. So the way it works is that we use a telepresence robot. We used it to collect data in a local public park and we can remotely operated it from our cellular device. We mounted this ZED sensor on top of it and the ZED sensor collected RGBD data, so that's color and then distance data from the sensor to objects in the environment. So the next step of this project is actually to be able to detect and track people over time so say for example, if it can see how groups emerge then our hope is that it will actually improve our detection over time and the part that I'm really interested in is looking at group social interaction. How do humans communicate in groups? How do humans work together in groups? As humans we can naturally see what people are like together based on non-verbal behaviors such as gaze and orientation. What kind of non-verbal behaviors can robots use to learn about this kind of interaction? And then how can the robot be useful to the group so that's the ultimate goal. It's a good time to be a UCSE because we just started the Contextual Robotics Institute directed by Henrik Christiansen and there's a lot of cool research going on right now. There's a lot of work being done in self robotics, surgical robotics. My advisor Laura Rick, she's actually working to build robots from scratch to help older adults stay in their homes longer. We're actually trying to design technology that will help people. Working to make people's lives easier and better and for me that's what's most valuable about it. I feel like the work that I'm doing is actually gonna go towards something that's gonna be put into people's homes, be put into the hospital, be put into all these different public spaces where people find it useful. (upbeat flute music) 