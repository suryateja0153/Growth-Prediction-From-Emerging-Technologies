 so my name is rose Joaquin and I'm a professor at UCL knowledge lab and I'm going to introduce our speaker for today and it's a real pleasure for me to come here and introduce a me because I first met him when I gave a lunch hour lecture here about eighteen months ago and since then we've collaborated on a grant application and finding various ways of working together so it's really lovely to come back and introduce him to you and when I said to Amy what would you like me to say about you he said and I thought this this was classically modest he said oh well I guess in your introduction I'm happy for you to say that I'm definitely not an expert in AI and I thought yeah but you are an expert an amazing number of things so only is definitely an expert in evidence-based healthcare and informatics and most of all patient-centered care and when I looked at his CV it reads like what I imagine any budding medic would want their CV to look like so yes he is a senior clinical lecturer in the clinical data science department in the Institute of health informatics here at UCL and also an honorary consultant in cardiology at UCL and is also leading the UCL Medical School's EE health curriculum which is quite a lot to be doing and then when I look through his CV it has all of the names that you would love to see you know I studied medicine at Oxford Medical School did a master's in public health at Harvard a PhD at Oxford we've worked for the World Health Organization you are a clinical cardiologist and still practicing and you're the education lead at the health informatics unit for the Royal College of Physicians a fellow of the Royal College of Physicians of London and of Edinburgh and the European cardiology society and the American Heart Association and a higher education Academy and the new faculty of clinical informatics what else can I say I can't think of a better person to come and talk to us on this topic in our lunch hour so as the sign says bring your lunch and your curiosity I haven't brought my lunch but I have brought my curiosity and I no you're going to enjoy this talk so it's over to you Amy [Applause] many thanks rose for your kind words so I am based at the institutes of health informatics UCL my name's Amy Banerjee and I am also a cardiologist at University College Hospital and Bart's this is the conflicts of interest slide I like to call it the limitations slide as Confucius is credited as saying that real knowledge is knowing the extent of your ignorance and I want you to be aware that I'm a clinician 30% at the time 70% I'm on researching and teaching I've previously worked with these pharma companies there's a digital technology company called medopad which is funding research that I'm doing at the moment and I'm also a trustee of the South Asian Health Foundation I am NOT an expert in AI I'm very interested in its applications to healthcare I am interested in evaluation of new technology in healthcare these two health evidence based medicine so I guess I'm at that stage of life where my mum is sending me kind of inspirational and aspirational quotes it used to be by email I get them by whatsapp sometimes and she sent me this one when my daughter was a bit younger saying that children are made readers on the laps of their parents and when I tried to explain this to my daughter she said daddy it's it's not laps it's laptops so so that's that's how big computers and AI is and when you look in my Amazon feed the books that I should be buying for her this comes up so you know everybody needs to know something about AI so what is it well for a simple doctor I would say that ai is importantly about performing a given function you're using that intelligence to perform a task machine learning is a subset where from the input datasets the the machine is learning how to get to the out by how to get to that task and deep learning is a further subset still of machine learning where you have several layers of neural networks to reach that task so I knew my bill to you her task is to get Santa to bring her the gift that she wants which is a Lego dolls house so the machine learning was that she realized that just sending a letter to Santa isn't enough and also putting a bit of push on dad as well seemed to work last year so she did the same this year but the deep learning is that she asked Alexa can you uh can you ask daddy to buy me a doll's house so she cut out the middleman that Santa that's deep learning and of course our current health secretary Matthew Hancock within a week of joining as health secretary he had signed a deal with Amazon Alexa to to partner in delivering information so you can ask Alexa for health advice ai is is one of the most written about topics I don't need to tell this audience and you know here's two heavyweights so Mark Zuckerberg founder of Facebook is of course optimistic he feels that there's going to be lots of improvements in our quality of lives Elon Musk serial entrepreneur CEO of digital entrepreneur feels that there's actually a risk to the existence of civilization so and this is characterized and almost everything you read about AI it's either friend or foe it's good or bad there's there's not a middle ground and right here in your University in the hospital opposite we're really investing heavily in skills and in in terms of both clinical practice and in research how we can apply AI to healthcare what we're seeing a lot of is industry interest interest industry presence this is a series of co-sponsored articles that seem to be appearing in the Evening Standard with Babylon a company which is all about virtual GP consultation but it has AI as part of what it does in terms of symptom checker and this was a report last year led by Lord Ozzy by the Institute of Public Policy Research which said that we could save 12.5 billion a year in the NHS if we better used AI and Teresa may latched on to that and said in the next decade or so we're going to save thousands of lives using AI in terms of cancer now I'm a clinician I said that this is somebody I saw a couple of weeks ago in my clinic in Whitechapel at the Royal London Hospital 53 years old Bangladeshi gentleman he's been more breathless over the last couple of months now it's so bad that he can't walk from here you know to the the middle row of this hall he had a heart attack ten years ago he's diabetic he's got high blood pressure he's on a pile of pills he stopped smoking five years ago so with this breathlessness I organised what's called an echocardiogram a scan to see if his heart is pumping well and it showed this number ejection fraction EF of 10% that should be more like 55 or 60 percent so this is not good a mixture of his questions and my questions what's the likely course of my disease doc what's my risk of dying in the next five years I've got two kids our particular drugs more or less effective in this case should I refer him for a heart transplant he's a youngish bloke if so when and what information should I be that on so heart failure is on a continuum your heart pumps normally there's a phase where you might not have symptoms but you do have heart failure we just don't know yet and you don't know yet and there's a phase like this man where he's symptomatic means breathless and what my job is or the health systems job is to try and stop him having the worst complication of all dying but also being admitted to hospital and the point is at the moment we're not very good at predicting how things progress along this line so one thing I can do as a good evidence-based doctor is look at the literature so this is a study done in Sweden last year 45,000 patients they looked at how good a particular machine learning algorithm was at predicting one-year survival what they found was that the C statistic which is a measure of how good a tool is at prediction where point 5 is like tossing a coin so you want it to be as close to one as possible so that we think as cardiologists is a good predictor which is that ejection fraction the the measure of how well the heart pumps that is as good as tossing a coin but actually machine learning improves that vastly to 0.8 in this particular study but this is a Swedish study do these patients map to what I was doing sitting in Whitechapel so with one of my colleagues Nick Chen we've done a systematic review and look through the literature to see what what other studies have been done about heart failure and machine learning and there are 22 of these studies they never other than one have gone to another data set to see if these same results are found in another data set they use different methods of machine learning and mostly they're in patient groups of 1,000 or less so there's small studies a couple of them have involved industry and it's not always declared and the conflict of interest so for me and my patient it's not clear how representative these data are to the patient that sitting in front of me so that's the prediction how well am I going to do in the next five years part this is the other question in my head about heart transplant so when heart failure is bad you get put on a waiting list for transplant you have a transplant and then you have hopefully a long survival after you've had a transplant we only do about 200 of these a year in the UK and so these are precious organs so we need to do as well as we possibly can picking the people who get a transplant and doing our best to predict how well they're going to do in the long run the point is that the risk scores that we have at the moment are pretty poor at predicting both pre transplant survival and post transplant survival they use a limited number of features and they're not individualized so with my colleague mihaela van der Shaw and and team we applied a paradigm of machine learning to a u.s. database of heart transplant patients over 50 thousand of these patients over the period of 1985 to 2015 to see if we could improve the prediction of survival so this this algorithm that she's developed called trees of predictors uses more features on average the existing tools use normal no more than eight to ten risk factors or features so by using new features hopefully you'll have a more personalized approach to predicting risk and you you also want to be able to predict risk in a particular window so we've been saying one year but really patients want to know five years ten years so instead of you know eight or ten risk factors we ended up looking at 50 risk factors and without going into detail what this algorithm does is splits that fifty-thousand gradually into smaller and smaller clusters so that you're predicting based on which cluster a patient is in and what it showed is that from the existing risks cause an existing machine learning in short we went from again 0.6 C statistic a bit better than tossing a coin to more at point eight pre transplant but still around point six two point seven and post transplant whether you were looking at three months or ten years so our approach did improve things significantly for both pre and post transplant survival prediction and the reason it did is because it takes into account the variations of the population so this is using big data it takes into account interactions between those different 50 risk factors and it takes into account variation across different time horizons but it's still far from perfect I told you after a transplant it's still a si statistic of 0.6 to 0.7 when you want that to be point eight two point nine we need prospective studies this is a retrospective study and we need to do this in other data sets possibly in a trial setting to see if this actually works in the wild and most importantly is this usable by doctors like me and is it usable by patients going back to my gentlemen and clinic what does good healthcare looked like Kim what does it mean to him well there's lots of different variations this could be a lecture in itself but the WHI talks about health as being more than the absence of disease it talks about social physical mental well-being definitely he'd like some of that universal health care is something that we've tried to do the NHS since its inception so that's about access and about having cost-effectiveness evidence-based yep that sounds sensible so we want something that is proven to be effective and validated with reproducible results we want something high-quality so that it's got value to the individual value to the health system and then mule gray and others from from Oxford have developed this paradigm of right care so the right care for the right patient at the right time in the right place which kind of captures all of the above I like to think in the in the information era of learning health systems which was a term coined originally by the National Institute Medicine in 2006 where they talked about this wastage when you go from science research insights are wasted they don't get into guidelines and evidence wasted again they don't get into care and so they produced this virtuous circle the learning health system where data is flowing freely between these three silos and it's that electronic data the digital data that really makes this work and that's where AI each of those steps can make good healthcare but in order for that to happen what do you need well you need data at the individual level you need personal health records you need it at the system level electronic health records population public and so on but it has to be used and fed back all the way to the individual so you need good science good evidence and good care so do we have the science for health care well this I believe is one of the best attempts to gather all the evidence for AI in health care and whether we are there in terms of science and just note the last sentence here over time marked improvements in accuracy productivity and workflow will likely be actualized but whether that will be used to improve the patient-doctor relationship or facilitate its erosion remains to be seen I'll be coming back to Eric Topol in a moment but in this article he very neatly shows all the exciting things that ara is being used for in healthcare and actually have been studied so you've got in pathology it's been used to diagnose or check diagnosis of breast cancers of lung cancers in ophthalmology it's been used to look at retinopathy scans in cardiology my own field it's been used to read scans the echocardiography scans but if you look there are only three or four studies which have actually been done prospectively the rest have been looking in the rearview mirror retrospective studies and probably the best data we have so far is in ophthalmology but there are only two prospective studies only one trial to date so our talk will conclude that we're far from demonstrating very high in reproducible machine accuracy let alone clinical utility for most medical scans and images in the real world clinical environment and he's coined this term the AI chasm where even if you have a really good predictive accuracy with an area under the curve of Nohr point 99 you still do not have clinical utility unless you prove that and that's where the holy grail of AI is and where we should be focusing he talks in this paper about the accelerated fda approval so the body that approves the things that we do in healthcare to check that they are effective and safe and there's now an accelerated different pathway for AI algorithms interestingly only two of these have published data to match with them that you could do or I can access so this is a worry that you've got an exceptional treatment treatment of AI in a way that wasn't happening with other new technologies and to answer the question whether my job is in danger from robots he says human health is too precious relegating it to machines except the routine matters with minimal risk seems especially far-fetched so it's widely said that AI isn't the problem it's the data that's feeding into the algorithm that's the problem and I tend to largely agree with that so you know even if AI is ready is the data in the NHS ready the answer is maybe not you know I be M Watson is one one of the most famous applications where they said they were going to transform the diagnosis and prognostication of cancer and it hasn't done that it hasn't lived up to the promise in the last decade by any measure so I've divided up these different types of problems with the data that might contribute to this I mentioned Babylon earlier and they exemplify what I want to call the digital divide so if not everybody has the ability to provide their data then how are you going to be put into the algorithm for AI this is a company that has symptom checkers for disease but has initially been piloted in well patients in people without the comorbidities who are younger than most of the patients who I see in clinical in hospital so you're you're potentially making a divide producing more inequalities there's a data divide if you look at genomics one of the most optimistic areas of big data in 2009 only 4% of the studies in genomics concerned patients who had non-european ancestry in 2060 we're not yet up to 20% so how can i benefit from an AI algorithm when my data was never in there who owns the data this is arguably one of the most contentious issues so the Royal Free Hospital got into a lot of trouble with the Information Commissioner because google deepmind accessed 1.6 million people's records this is in the public record now the issue is consent the issue is who owns the data is it for research what's for commercial purposes and there are further concerns because deepmind and Google were arm's length from each other and they are no longer so so is is any research going on in that setting or otherwise going to be liable to linkage of health data and non health data it's hard to imagine not in a huge multinational company such as Google quality of the data so that's in terms of is there missing data but also is there evidence of quality of an intervention so this is mobile phones for diagnosing melanoma this is one of the most exciting developments where people don't have to wait to go and see their dermatologist they can take a picture of their tumor and the algorithm can can tell you what's worrisome about that and whether they need to seek referral so there's plenty of evidence in the in the press and in the literature that this is a good thing but actually when you look at the totality of evidence the Cochrane review the systematic review the best way of looking at all the data for this application for melanoma shows that at the moment smartphone applications using AI based analysis have not yet demonstrated sufficient promise in terms of accuracy and are associated with a high likelihood of missing melanomas so that's the important bit with AI is are we missing important things and are we telling people they're unwell when they're not are we over diagnosing those are the two areas like any doctor as well there's standards that we need to maintain so if you take heart failure my patient has this disease heart failure it's defined differently across different study designs across trials across observational studies it's defined differently in clinic versus the hospital it's defined differently in research and hospitals and it might be slightly different in America this is European data sets so how you going to cater for all of that in your AI algorithm because the data is messy so the science is a question mark what about evidence well here we've got some interesting work going on and led by my colleague Harry Hemingway also the Institute of health informatics where we've we've got a consensus document of what good looks like one of the questions we should be looking for in any application of AI to healthcare for transparency replicability ethics and effectiveness and they've developed a set of 20 questions this is in open archives in the public domain and we should be using this to ask if if data is usable and whether a eye is ready and fit for purpose and the NHS has also sat down got together a load of key stakeholders from nice from the tech sector and thought about what are the guidelines what are the standards that we should seek for digital health technologies and including artificial intelligence what I'd say is that unfortunately this is just guiding principles there's no requirement for any industry any company to meet these guiding principles as yet so I've talked about science of I've talked about evidence care so that's what I do in my clinic we've got several problems here for AI the first is training the second is transparency the third is clinical credibility and the fourth is patient centered well we know that in this complex way that we train doctors from the five years at medical school through to the 10 plus years it takes to get specialized that at the moment there is very poor provision of training in Big Data methods in informatics and definitely in AI for doctors at the moment so at the moment we're working with the Royal College and with medical schools to see how we can develop this this training because the doctors of today and tomorrow gonna have to use this technology and evaluate it and at the moment we're focusing on whether a hospital or your GP surgery is digital digitally mature rather than whether I as a worker in the NHS and digitally ready and that is obviously going to restrict what you can do with AI so there's lots of work to be done in that space and there's lots of big promises but at the moment this is not not not reaching reality yet so the World Economic Forum feels that this is the answer to China's shortage of doctors in particular I think this is the biggest issue for AI going forward is transparency the this company Babylon has had several big stories about it one of them which we've seen in healthcare many times is a silencing of whistleblowers so those involved in care who were worried about how data is applied aren't able to talk about it and ultimately if you're in this business it's not like selling jeans or cars if you are looking after people's health there's certain principles that you have to follow and so if you aren't able to call people out when the data is showing that you should that's a problem this is a story hot off the press from yesterday night on Twitter so Juliette Bauer digital lead NHS England has led to a new term in the Financial Times the new revolving door from the health ministry to the health app industry so this is this is a problem there's nothing like this freedom of movement for people to work where they want but she's not had a period of gardening leaf she's not declared an interest when she's been promoting this app is that a problem yes potentially any conflicts of interest any potential limitation on the use of knowledge and output needs to be declared so the da Z review of healthcare I mentioned this this has said that 12 billion pounds can be saved across different professions across various functions in healthcare that's a massive amount of money 12 billion pounds this is widely said to be an independent report that's in the public domain it's not on the front page of the report but maybe we should know that so Eric Topol a cardiologist from the US a real thought leader in the use of technology and digital technology in healthcare and in how AI is going to change things he's been invited to do a review about how we train people in the healthcare workforce Rose has been involved in that and this is very exciting there's a panel that's very August there for various domains to look at how we are going to train the workforce of the future but again these are the ones that I could find that aren't declared in the document there's people working for companies that are very interested in this space who are on the on the board and also there's nobody in that lineup who's clinically active at the moment not one so neither a nurse nor a doctor nor a physiotherapist nor anybody so would you do that if you were talking about AI in the air industry in in in in the plane industry sorry where we often compare health care with planes would you have a panel of doctors of people from business but exclude pilots from the panel I don't think so do you think so so this is this is a concern and also we don't have any patients they're the only people we do have is these clinical fellows who were the trainees the younger doctors who I believe should be more involved and they are only invited to contribute to the board's thinking as helpful and then Matthew Hancock our health secretary has set up this technology expert panel which is again very much focused on how we we can run our digital technology particularly AI so it's led by a champion of evidence-based healthcare a researcher and a clinician Ben Goldacre but if you look down the list there's not one person there who's clinically active in the NHS there's lots of people who are in finance and investment and venture capitalists and you know from industry but where are the patients where are the clinicians where are the people who are doing research in AI are you going to be surprised if this health tech board says let's roll out a particular AI technology of course not so Ben gold X next book might be bad Digital and the bit that I think really might suffer is patient centeredness we use this word very fluidly in research and in clinical practice we are for patients that we're seeing it a lot in the AI space and digital technology that it's more patient-centered but actually you just saw three boards government-level which involves zero patient input the only way patients get involved in that is by putting in comments afterwards and we know they won't do that so we have to get out there and produce resources like led by the Wellcome Trust there's this initiative understanding patient data which I've advised them but actually it doesn't tackle AI really and we need much more of that to give good quality information about what AI is how to know how to evaluate and know the wheat from the chaff what else might we do with patient-centeredness well who's heard of this website they sold it anyway okay so they sold it anyway d look at this later on this is the NHS digital's data release registers it lists every single company Hospital clinical condition Commissioning group University that might have broken the rules it said that if people opted out it wouldn't use their data and actually they have unfortunately you'll see my institution UCL is listed there it's also listed in terms of the other side of organisations that have not breached the rules but this is constantly updated so it's not so much a problem that people have reached the rules of course that's a problem but at least it's in the open you can see what the breaches are what the organizations are doing about it this is what patient-centered or public centred or patient facing looks like so back to my patient I've got to say on the basis of what I've told you I don't have evidence yet that I can drive risk prediction and tell them anything on the basis of AI hits heart failure I've got to say that at the moment we are over height rather than underused and that's because we don't have the data to get the most out of the AI we don't have the ways of evaluating that we'd like and we don't have the training for people like me and my patients to actually understand what it all means and then perhaps most importantly a lack of transparency in the culture so we need to move all these three spaces along the science needs to go from unrepresentative data to representative data we need the evidence space to go rather than breaking up each patient clinician encounter into little widgets of care we need to think holistically about a patient's pathway and take advantage of the data that might be available and answer questions that are relevant to the whole patient pathway and then these these words data driven technology centered you know I lose more and more hair every time I read these terms because actually where we want to be you know I've never had a patient ever say to me I need more technology in my health care I've seen I've been doing this for 20 years now I've never had somebody say I want more technology I have heard people say I want my data I want to know what's happening I want better communication I want it to be about me that happens quite a lot so that tells me that we do need to be more patient and centered and more data guided this is one of very few pieces of work to my shame that I've done but co-authored with patients where we talked about what actually does using patient data look like data so their data saves lives well how does it really save lives and how could it for patients last two slides so my Christmas reading included this this is this is a really excellent book and this quote says in the a 21st century the train of progress is again pulling out at the station and this will probably be the last train ever to leave the station called Homo sapiens those who missed the train will never get a second chance in order to get a seat on it you need to understand 21st century technology and in particular the powers of biotechnology and computer algorithms this other book that also read over Christmas is why we can't afford to get this wrong we can't have another thoroughness another technology company which was based on bad data or bad evaluation we have to do better thank you very much Thank You Emmy so many parallels with my world of Education and AI really interesting especially all those points about ethics and transparency now time for questions and if you'd like to ask a question please wait till you get the microphone before you ask your questions so any questions must be some yes there's one up the back there hi thank you very much for your talk Thursday saw a sellout lecture of alley pass or the fan of Babylon speaking to UCL Mercy medical students most medical students and scientist will be familiar with the book how to read a paper which basically tells you how to correctly critically appraise evidence and research so how would you what would you say to those medical students about how to critically appraise or how to challenge or assess someone like Ali Paso or Babylon when they come and present so they can make the best decision about whether to use that technology whether to even leave medicine and join the company thank you so I think firstly you need to have published evidence if I'm not publishing my evidence or putting it somewhere where people can see until proven otherwise I've got something to hide and there's plenty of evidence that the symptom checkers and so on from Babylon are substandard they're not safe and so number one look for published evidence that you can see number two is if the claim is too too good to be true it probably is and thirdly what we're seeing worryingly in the digital tech space is there are some people or companies that seem too big to fail or too big to question how is this company allowed to carry on the way it is without these simple questions when you know there's certain hoops that I have to jump through as a researcher to do a very small piece of research for you know a you know one one-millionth of the amount of money that they're turning over so I think all of those as well as the training they've had in evidence-based medicine would easily help them and thank you Amy for a wonderful lecture on yeah whether it's a hope or hype I'm Ganesh I'm a physician myself and I have developed interest in artificial intelligence in healthcare I mean a couple of weeks ago I've been to one of the Google artificial intelligence conferences and the tech world is now calling data as a new oil and artificial intelligence has a new electricity so that's the kind of hype which is being promoted by the tech industry then it comes to the next question is the algorithm I mean a comment rather the algorithm is as good as the data so the good the data the collection is and the standard how its collected will determine how good we could train the algorithm the problem with energies is the data is fragmented and the data which is collected is not standardized so which then begs the question do we then have to educate the doctors like you said the clinicians and healthcare professionals how they collect and I mean kind of quantify I mean collect the data for future use in artificial intelligence so my question is when it comes to the medical schools there are coming graduates in medical school should they not have any course in health informatics like a module in health informatics which will teach them how to collect the data I agree yes and the various people are working on it so I mean the reason I wanted to ask you is because you are in health informatics and you are in the college as well so how soon are we looking at for it to be implemented I think we're still we're still at least a year away thank you very much for a most interesting talk he mentioned that there might be a difficulty in having firewalls between various companies such as Google and and deepmind I read last week about one company that claims to be able to perform certain diagnosis particularly in cardiology diabeetus as as an example on voice alone now our voice is something that we give away all the time and how could this ever be regulated we think so I would give you the same answer as I gave to the last question that until I see a published study with proper analysis and independently done rather than a claim from the CEO of that company I judge whether it's good or bad and the likelihood is that you know there is no data one of the reasons if you're skeptical that people are looking for all of those kinds of non health-related data sources is because they can be gathered by the Alexa sitting in your front room by your mobile phone and so on which are already and being captured in a way that is not regulated like your electronic health record so the really clever thing would be when they can link that to your the clever or worrying thing is when they can link that to your health data this is their last question thank you very much for a very good lecture I don't know if you're the right person to ask but this is basically regarding global health so in global health we have this huge hype in M health and mobile application the two recent one I've heard of ah speak for the eye for scanning the eye and safe safe delivery up my question is how do we get people to be accountable for what they promote in these countries because we're talking about accountability here where we have big organizations to safeguard patients but in the in developing countries we don't have that so how can we get these industries or these companies promoting their app accountable for whatever they're doing with patients who do not have anyone to protect them yeah thank you that's a great question and so I an interest I'm doing a project using mobile phones to track whether people are taking their medicines or not in South India and the first the first check on what you've just described is the the culture of academia not just industry also of university academics that stops you doing that kind of work whatever you're doing here the same rules apply in another country secondly it has to get through ethics committees which are they're having to follow international standards and thirdly I would say that you need to look at how these things are funded so for example Babylon has done a lot of work in Rwanda and if I was you know involved in that I want to know what are they funding exactly what is the evaluation of what they're doing there because the algorithms that they've developed here which are not I've already described how they're not necessarily fit to be used I would argue they can't be fit to be used in Rwanda so how are they how are they developing their data and their applications there so it's that that mixture of things so if that's a mixed up answer so that was the last question we'd like to thank y'all for your questions and for coming to this really well turned out lunch hour lecture and obviously we'd like to thank dr. Emmy for his fantastic lecture as well [Applause] 