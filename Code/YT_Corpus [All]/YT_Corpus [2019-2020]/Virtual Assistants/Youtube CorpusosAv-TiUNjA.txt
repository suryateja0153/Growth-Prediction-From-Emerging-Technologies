 Today, the term “artificial intelligence,” or “AI,” has become widely used in the media, often in connection with virtual assistants like Siri, Google Assistant, or Alexa. But are these assistants truly intelligent? We happen to know what people expect from a truly intelligent assistant. In one of our studies, we asked people to pretend they had a perfect intelligent assistant, and track “activities” that they would expect this assistant to help them with. We discovered that they wanted everything that  they may want from an observant human assistant. For example, notice that they have not taken a break for a while and remind them to get up, and then more. For instance, alert them if someone stole their identity online. Today’s virtual assistants are intelligent in that they can  speak and understand some human language. They also have some limited agency. They can make unprompted suggestions for directions to work in the morning, or they can alert you to leave early to get to an appointment in time. They excel at simple, one-step tasks: trivia questions,  weather, timers or reminders, turning on lights. They were optimized for navigation and directions. And they are most useful when the hands are busy — in the car, in the kitchen. But there are many ways in which these devices are not intelligent. First, they are not very good at understanding real language; for example, multi-clause sentences, such as, "Find the status of an American flight from San Francisco to Vancouver that leaves today at 4:55pm." They are not able to carry out a conversation, and the sentences must be self-sufficient, with no pronouns or other implicit referents, most of the time. They don’t always get polite language, accents and hesitations, repeated phrases. A pause in a sentence often is misinterpreted as the end of it. They’re not at all good at research tasks, putting together multiple sources of information or multistep sequences, such as, “Text my next meeting that I will be 10 minutes late,” or “Remind me to call the restaurant when it opens”. And the agency component is quite weak — there is very little learning that is being done based on observed  user behavior patterns, and almost no suggestions. The greatest danger in believing that these devices are truly intelligent is that of the mental model that gets formed of “AI”. People learn very quickly that they need to behave in a certain way to get results from these assistants and that these assistants are good only at certain types of limited tasks. They adjust behavior and avoid other activities. As a result, they are happy without exploring the potential that the technology has to offer. So one day, when these systems get better, and they will, people may not discover the great features of these assistants. 