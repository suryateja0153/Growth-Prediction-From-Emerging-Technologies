 [Music] this is IOT 204 connected robots IOT in the warehouse Paul Cap'n Eddie I'm an IOT solutions engineer with Google hi I'm Christopher Cacioppo I'm the CTO and one of the cofounders of 6 river systems 9 joseph Hughes director of DevOps at 6 river systems we'll be talking about collaborative robotics and how it helps companies meet the ever-changing needs of today's consumers so quick agenda I'm gonna take some time initially to try and frame some of the problems that warehouses are trying to solve today I'll also go through through some of the cloud solutions that help I'll then hand over to Chris Cacioppo here for a double click on the business case for collaborative robotics and a little more information about six river systems and then Joe will finish up with all of the tech behind six river systems and the products that they offer so there is a Dory for today's session and I'm told if you go to the app and go to our session IOT 204 you can see a link down below Dory is an internal tool built at Google that's being made available at next you can go here to post your questions for us while we speak you can also see the questions that others are posting you can upvote and download those questions as you see fit the idea is at the end of the converse at the end of the presentation we'll have a bit of a stack ranking of what the audience wants to hear from us we're gonna aim to add and 6 minutes 7 minutes early to try and get as many of these questions answered as possible and afterward we'll be able to answer questions questions offline so a quick survey so I know who's in the audience today how many people out there by show of hands are developers architects people that are building systems you have quite a bit that's great there's definitely content for you how many people are in the warehouse space working with warehouse management systems show of hands got good we got a bunch how about robotics working with Ross great there's a bunch of those too how many people have ever bought a physical product on the Internet all right good captive audience so in all seriousness this is the audience that we built the talk for hopefully you find some of this useful so what are the needs of the warehouse today and as an IOT developer that's been working on a lot of different connected products working with a lot of different IOT cloud solutions the first thing that strikes me is the sheer amount of data available so there's products there's product locations there's lidar points there's all sorts of things that without the technology you had and now adding robots you have things like batteries robot statuses many many many different types of data and as a person that's managing a warehouse I want to know that there's a way of obtaining this data there's a way of reacting to it formatting it and Google Cloud has you covered if you're able to connect your edge devices and your sensors to cloud IOT core you can quickly securely and easily get that data to the cloud from IOT core you get your data into pub/sub pub/sub can act as a kind of central point in your cloud architecture from there you'd be able to trigger cloud functions to react to your data or data flows data procs to be able to try form your data into an optimal format and then ultimately sync it to bigquery and I say bigquery there's a lot of different data persistence mechanisms available on data cloud but bigquery I believe is uniquely well-suited to the problems warehouses are faced with today bigquery is Google's server list data warehouse in the cloud and it's built to excel with analytics workloads so let's say you have your data publishing to the cloud and you have it formatted you have it synced to bigquery you're quickly faced with the next daunting task there's so many things that you could potentially change in your warehouse to try and optimize your pick rates or find bottlenecks or just overall get your throughput up you could potentially be spending man months on a part of your system that even if done purple perfectly would only shave a small amount of time off your average pick rate where there may be a bottleneck elsewhere that if you've spent a couple man-hours you would unlock a whole bunch more throughput the quickest way to get to this insight is since your data is in bigquery you can hook it up to data studio or many of the other business intelligence suites out there to visualize your data and understand where the time is being spent armed with these visualizations you'd know that spending man months trying to make your user interface on your robot more effective for the picker might not be as impactful as maybe increasing the speed of your robot or your object avoidance for your your slotting of your products because move time Dwarfs the amount of time that it takes to pick a product out of a box so there's a certain level of insight you could get to with dashboards but to potentially move beyond you can try and employ a machine learning machine learning might uncover different patterns in the data that might not be readily apparent with a dashboard or visualization it also may help in not only leading you to the opportunities for improvement but be the improvement itself you can potentially create models who can deploy on a robot and have that robot be more effective in its day to day job one of the best things about Google cloud and machine learning on Google cloud is you don't need an army of data scientists or tensorflow developers to be able to start to take advantage of it since your data's in bigquery you can use bigquery auto ml to write a sequel statement that's a returns your pick times and all of the different facets that might affect that pick time and then with two extra statement two extra lines of code you can generate a tensor flow model that forecast snap pick time when you change some of the other parameters around it and just like that you might know the change the effect of the change that you intend to make under your system you can take it same data and bigquery and return robot failures and come up with a model that gives you predictive maintenance you can use none of that data and use a pre-canned model that would give a robot the ability to see whether an obstacle in its way is human or not and for those of you that aren't in the robotics space this is valuable because a robot moving very fast in close proximity to a human would make that human very uncomfortable very understandably so but if a robot can't deduce whether or not a human obstacle is human it would have to slow down for every road cone every piece of box or anything in its way and that could dramatically impact it in the pic race so let's say you have your data it's in the cloud it's in bigquery you have your visualizations and you started to pick things that you want to change about your system to optimize it now you're faced with another problem because to be able to get the data you need to validate those changes are in fact having a positive impact on your system could be costly you can't change the size of your warehouse very easily or scale up your robot fleet for one day two three four or five X it's pretty cost prohibitive to do things like that so this is where Google kubernetes engine can help you can spool up simulated robots and simulated warehouses and fuel bigquery with the same types of data you would get if those robots were real that then fuels the same dashboards that you used to pick what optimizations who wanted to take so this is how you can quickly validate your change and iterate on to the next now before i hand over to chris i wanted to quickly introduce six river systems six river was founded on the idea that the technological advantages that are seen in the the large million square-foot warehouses by the e-commerce giants should be available to all so not only should these robotic systems scale up very well they should be able to scale down traditionally to get a fleet of robots in five hundred thousand square-foot warehouse you're talking about six months to twelve months you're talking about many many years before the ROI pans out these types of upfront costs don't work for the 50,000 square-foot warehouse so six River has a system that can be installed and up and running in weeks and fluctuate the size of your fleet for peak times and get ROI a lot quicker what they're trying to do is in effect democratize robotics and level the playing field with that I'll hand it over to Chris thank you Paul so why did we decide to use collaborative robotics to solve a warehouse problem and at the end of day I wanna give you a quick idea of the problem space and then we'll talk about that up until about ten years ago distribution centers were places where manufacturers bought a lot of cases of products they were then separated out and then shipped off to stores to then fill their socks so there was pretty much moving cases from place to place which is reasonably easy to automate there nice touch and square and it doesn't require a ton of labor but in the last ten years things have changed when you guys order things online you never want to case a toothbrushes you want a toothbrush and a toothpaste maybe an iPad and some diapers right they're all differ for everybody and so it requires a little break me open cases taking things apart dealing with odd shaped items and so the warehouse does look more like this so there are people working on automatic hands and arms and you've probably seen picking challenges and they always took off nice clean pick faces but it's clearly for us at least five or ten years off before they have robotic arms and go in take things apart pull things together gift wrap all that south requires laborious there's a tremendous labor impact for the foreseeable future in this area to make matters worse when I was a kid I it was my birthday my mom will you order something the Sears catalog and we've mail it in and it would take six to eight weeks to show up and I would have forgotten what it was but I'm sure was excited to get it anyway well in the 90s early 2000s shipping time for about two weeks he ordered something online for early e-commerce they show up in two weeks everyone was happy it was great but today's day and age people expect things entry-level as two day shipping then it's like one day and like it'd be nice to be sure there's an afternoon and so the pressure that puts on to fulfill centers to get things out the door is tremendous so like many things as latency goes down the efficiencies get worse and so there's even more pressure on labor these fulfillment centers and distribution centers are located in places where land is inexpensive and before there was didn't need a lot of labor but they've kind of sucked up all the available labor I was with a customer about two weeks ago and they said it's not so much I care about the price of labor they'll try to do its that I literally can't get people to reliably show up anymore I could get enough people to do so what we've done is to solve this problem with with Chuck and Chuck do I come over here so Chuck is is dressed up in its Google best Chuck it's a collaborative robotic robot and the thing I want to point out here is this makes the the associates lives much easier but everyone in our company is super excited about robots and I think most people in this talk would think robots are pretty cool some cameras out there so that's pretty cool but people that are often associated working warehouses robots can be scary for a number of reasons and so one of the things we did is when I started this I didn't want a little circle or rectangle or square in a warehouse that wasn't obviously was gonna do so I put on my in Dussel an additional engineering hat and said okay we got a good designer and said I want this to be obvious so this is Cleavon modeled after a car it's got Ted headlights and taillights it looks like a car and when you look at it you know in here things could go that way it's gonna go that way and if it backs up which it does very rarely it's gonna beep and look like a truck so we want to do is get people comfortable with the concept so that they're comfortable if people are not comfortable work with your collaborative robotics they're not going to use it and nothing's gonna work well so we've had very good luck and everyone loves using our robots so the way a typical warehouse works for car pick operations an associate will walk over to an inductor area with a big heavy cart and they'll put a whole bunch of boxes on it and get a whole bunch of paper tickets and walk over to their pickin racks it to look like Costco or a backing from Ikea or Sam's Club except much more dense they're then gonna walk up and down Tahoma tiles for filling the order so these paper tickets and finding everything where they remember and they're gonna bring it over to a takeoff area or possibly multiple ones and there's a big loop okay at six River we decided what's most important that the associates can do is that much better than anyone else it's the grass in the hand so we want to try to alleviate as much of the other stuff to doing as possible and these aren't small places as we talked about these are 500k 50k to 500k or more warehouse is there tremendous amount of movement so what our system does is there's a person who sits in an indepth area on top and they put work on the robot and then the robot takes off okay the robot will then meet someone in the picking area they will then walk with them through the area showing the pictures taken from place to place and the best method possible and then where they're done that robot will take off and deliver it to multiple places essentially and another what we waiting for them so we'll keep them localized in doing what they do best in the picking aisles what we can do is improve pick rates two to three x over traditional car pick okay and we do this by number ways we reduce the long walk some people to walk across giant warehouses we have very effectively pick orders that go together in a nice clean way so they walk as little as possible we pick them awfully from place to place and we also have very clean you eyes which lets them get the data fast and they can pick faster they can lower error rates and they can ruse training time from weeks to hours and this has been hugely positive our customers the next thing about Chuck that's very interesting is it's a disruptive technology so there's a number of technologies out there that allow car picking that enhance carpet or replace carpeting so but most of these operations have three to five years ROI and are bolted in the floor and I don't know about anyone in this audience but I have no idea my cup is going to be in three to five years like technology changed so fast it is a tremendous investment to do to make matters worse there's generally in this industry there's a huge seasonal change so right around holiday season most of our customers see a three to 7x change in their operation right tremendous changes so not only do you have to predict potentially five or more years in the future but you also have to scale up so that your operation is running pretty much at peak to peak time and then eighty percent of your time it's significantly under utilized so what we allow it happen is we have a two to one year ROI for our products they can instead of being installed a lot of opera most automation is six months to a year of installation time we get up and running in one or two weeks okay it also allows you to scale your operation if your operations getting more and more going up and up you just buy more robots we just deliver them they work as is if your operations feelin's scaling down well if you've another DC or another fulfillment center just move the robots if you have seasonality just instead of building our system from six River that works for your peak for the entire year just build for your average for the air and we'll leash you more robots for your peak time so we allow a tremendous amount of flexibility that it's just not possible anywhere else in the tree so from the first day I sat down on the my dining room table of my two other co-founders to the day we had a small fleet of collaborative robots picking live order to blues toys and a customer warehouse was nine months which is looking back on it felts much longer but it's an amazing feat and I don't think this is possible ten years ago even with the the best group of people you could ask and the reason is I think there's three key technologies for the last 10 years that have made a tremendous change one is ubiquitous computing power so we've invested invidious jetsons tx2 platform until that gives a tremendous amount of processing power at very low energy consumption and a reasonable pipelines and so we've done a lot of work with them but it's not just that it's all the centers and all the things that allow robotics to work have come down tremendously in price it wasn't that long ago that the spinning lighters you see on top of the Google cars they cost like 50 grams but and now we can have one to the robot that cost less than a thousand so there's a huge change of technology that allows that's enabling things that just weren't possible for the second one is open source so I'm sure everyone here uses it's gotten better and better over the last ten years I want to call up Ross Ross is Colt is a robot operating system for your non robot assists it allows you to bootstrap robots really fast so you can focus on the things that your business cares about and not focusing on the plumbing and infrastructure so we could very quickly get a robot up and working and then pile more stuff on topic to optimize it for our environments and last but not least is ubiquitous cloud platforms and we've embraced Google cloud from day one this allows you to like scale the operations leverage your engineers we have do a lot of testing stuff we have a lot of security things it just allowed us to go so much faster than we would have otherwise so given the audience I think what's been the rest of the time talking about the Google cloud so one thing that's very important to me personally is data-driven decisions pretty much this entire conference is about data right and so collecting data and everyone knows data is good but how do you use data how do you make it effective for you so let me go through some of the ways and we use it and we have a lot of data both from a logistics side and also from the robot side if you have a workers robots robots generate a tremendous amount of data and make lots of decisions and it's very hard to turn through all the data otherwise the first thing we do is operational intelligence we have a ton of data on all of our customers operation and we can tell them how much work they're doing how much time they have left the rates they do things a whole bunch up we can say which which of Associates imploring better and worse but even more than that instead of saying Chris is underperforming I could say Chris seems we doing pretty well he's just really slow at scanning maybe he doesn't have that section works and to associate can come to me and help coach me through something that I'm weak act as opposed to just dealing with it or deciding they should get to my other employee if that's even possible the next thing is visualizing data this is one of my favorite things so this up here is a picture of a robot go through the warehouse all the time they report back wireless signal strength constantly so every second or so and so this is a map of the wireless signal strength at various ports the warehouse so people do wireless surveys and they're sort of ad hoc and occasionally happen we are constantly real-time showing a wireless survey of the warehouse so you can tell them this warehouse is a big area in the center that's probably pretty weak and if the customer cares they should probably update that but I think what's more important is how we use it for our internal engineering personally so when you're starting to build a robot you get a robot and you get wave to you first you have to make it move check it moves and then we don't just want to move we want to move from A to B so we want to move over there excellent check we have to have a to be and then you want it not to hit things all right check and you go through this whole list of things whether it's robots or any product you guys do until you get an MVP and it's in front of the customer at that point it's great we get some feedback and we work on the most important things next how do we choose the most important things in most operations it's done at one of three ways one the manager or whoever is in charge decides to the loudest engineer decides or three if you're doing things probably correctly you have a consensus of engineers that decide together but the problem is even in the even a latter case we have a consensus it doesn't mean you're working on the right thing or most important thing first you just all agree you could all agree on the wrong thing so this is a graph up here about the time that the associates are spending on our product which is important of of labor management and labor savings so the big blue box here is movement says the large amount of time about 44% is spent on the robot moving from point A to point B with the associate in intohe there are other things down here too just scanning right and so one of our interns may have a great idea we can just remove scanning entirely and that sounds like a great idea we can just skip that step and be awesome let's work on that and someone else have an idea it says we can reduce movement 20% that doesn't sound is good but if you look at the numbers it's way better to spend time reducing move it by 20% and is removing a stage even though it doesn't intuitively feel like just removing something isn't just a better idea so I'm gonna give an example that this is another customer warehouse and instead of plotting Wi-Fi signal strength we're putting average movement speed of the robots so you can see right a slower green is faster so if you look at some of this and analyze a little bit at the end of aisles things are slowing down it makes sense there's there's cross traffic there's blind turn so you gotta be a little more careful around that but they're slower is in the middle of the aisles but doesn't make a lot of sense right robots should be humming along they're to be fine so we can do two things here and we do both them one is we can push back into customers and say hey you guys should clean this up the robots move faster and your rates to go up but really it's better of like why are we slowing down like so because everybody wants a robot suit faster so I think obviously the next thing we do is just make the robots top speed faster or is it so silver engineers Chuck's over robots and put it in a test track and instead of just reporting the maximum speed in robots they report the internal choices of robots and essentially crash course in robotics here we have a bunch of different tasks that determine how fast a robot can go and the slowest one wins because we believe in safety and everything else so whatever chooses the slowest and that's the one that we go at so if you look up here red says I'm near an obstacle yellow says go top speed so if you look up there and we increase our top speed really wouldn't have had a giant impact on our robot right now because mostly we're having around objects and we're slowing ourselves down because we're being extra careful so the engineers took this data in tackling that problem instead of trying to make the robot respond faster to go faster and analyze that problem and after a couple weeks they did the test track again and this is what they got you'll notice instead of being like 85% red it's not like 40% red and there's a lot of it yellow which is the top speed the robots just cruising along at top speed so there was a huge impact of diving into this problem and Ulta about a 15% movement speed increase and now that the interiors can look at this and say okay should we keep pushing on that problem should we look at that at the teal over here which is a pathing issue should we think about raising top speed but it allows a data-driven decision when obviously - everyone says we should just make the robots move faster and that was actually the wrong decision so that's my part of the talk I'm gonna hand off to Joe who makes all the magic happen here thanks Chris so you just got hired at the next IOT robotics company and you wake up the next day you're feeling good but then you think to yourself I need a robot infrastructure lucky for you you're here Google cloud next and we're gonna help you understand how we've used Google cloud to address some of the most challenging aspects of this problem the first and most obvious problem is you have all this data you have hundreds of robots in the field you have robots that are in your test environments and your customer environments you have to get all this data and you have to make some sort of sense out of it so we're gonna talk about this slide for the next 30 minutes all right you guys didn't run away we're not gonna do that but I think here there's an important thing that I want to point out about this architecture we don't just use cloud IOT core for everything we also use Google Storage for a couple of things and the reason we do that is that there's some data that is really important to have in real time but there's other data that we may need later that is really dense and and Chris talked a little bit about that data that's your lidar scans your point clouds the robot Isis if you're not a roboticist that's really kind of what the robot is seeing and vlogging all of that and we need to put that into Google storage because those files are big they're dense then we need to run it and break it down so we make heavy use of pub/sub and cloud functions to massage that data get it into the format that we can consume some of that data comes all the way back through to a web you know a web page where people can consume it some of that data goes to bigquery and that's what drives some of those interesting graphs that Chris showed you before what we're going to be doing next is using that data in bigquery as as Paul alluded earlier to drive some machine learning models so we can get better and think more about the data that we're collecting but this this infrastructure for us this design has survived the test of time and scaled with us with no intervention engineering intervention at all so the so one of the things that you want from this data is real-time location you may think to yourself well what that seems important but I'm gonna explain to you why it's very important if you're managing a million square-foot warehouse and you can't have line-of-sight to everything so you need a bird's eye view of what's going on you have 25 trucks in the field you might have 50 employees in the field and you really need that real-time feedback so most obviously you just need to know where Chuck's are if you can only see 10 trucks at a time you need to know where the other 10 are and make sure they're doing the things that you expect that they should be doing in your warehouse you also want to see if chucks in trouble you'll see two trucks here blinking red if a warehouse manager was to click on one of those they could see that there's an obstacle in Chuck's way or that there's some other unexpected event maybe some sort of maintenance that needs to be done to chuck in any case it really calls out very clearly that there's a problem it needs to be resolved they can get on a radio talk to someone and ask them what the problem is or they can make the decision to walk over but if you're constantly walking around a million square foot warehouse looking for problems most likely you're not going to be able to find them lastly you want to understand the operation so if you see Chuck's queueing up in a weird way or you see that chucks and your your operators are not in the right part of the warehouse for where they need to be at that point of the day then you can correct that and make sure that your rates you still hit your rates and that means that everyone in the audience gets their shoes on time or their toothbrushes on time or whatever you might be ordering off the internet the next big thing that you want from all this data is real-time monitoring our customers run 24/7 the Internet's up 24/7 people are ordering 24/7 and you expect your stuff in two days so we have a tech support team that also runs 24/7 and when something comes in they need to really quickly respond now for our cloud software that's running in the cloud stackdriver was a clear choice out of the box gave us alerting it gave us all the monitoring that we could possibly want and we didn't have to invest any engineering time into instrumenting which came with the platform we use Google core IOT to feed data into influx DB for time series database and then also drive the dets dashboards like you see behind me this gives us our CPU metrics our memory metrics and our temperature metrics some of these warehouses get up to over 100 degrees so the temperature of their CPU becomes super important your fan fails and your CPUs overheating you're gonna have a very unhappy robot and eventually you'll have a very unhappy customer but this really all drives preventative maintenance if we can take a chuck out of service before it fails and clogs up the works then we can save our customer time they may be running a degraded system for a little bit but hopefully we can pull the chuck out of service replace apart from a spare part kit and get Chuck back in and doing its job lastly when we touched on this little earlier but enabling technical support super important they're really the front line of defense and they need tools to help the customer resolve their problems quickly and not interrupt engineering if engineers are spending all their time solving customer issues in the field then they're not going to be able to build the next great feature and make Chuck better and we're constantly doing the experiments like Chris showed you earlier to make Chuck faster and to continually raise our customers rates through just software and better engineering practices so this is the second type of data that we were talking about in that architecture slide this is data that's not really valuable in real time from every single Chuck because it's very dense and it's very it gives you the whole picture of what Chuck sees in the world but you may want this data because you want to replay Chuck travel you get a something from the field and say hey Chuck is moving strangely around this shelf or Chuck can't see this particular thing on the ground or something of that nature and that comes to our engineering team and we need to be able to see that and so we have two options we can get on a plane we can fly over the warehouse go take a look at Chuck and say oh well I guess I can hook in and take a look at the sensors or maybe it's not even doing that anymore by the time you get there but planes are expensive and engineering time is also expensive or you can replay this truck Chuck travel from Google Cloud you pull that down and you can replay in real time so what you're seeing on the right of this is you can actually see Chuck seeing other chucks on the left you can see shelfs that's what's called a point cloud you can see it's made up of a lot of points from this our engineers can deduce a lot of interesting things there's your test environment what you have in your warehouse where you do all your tests and you try really hard to make Chuck move the right way all the time inevitably though you get out into the field and there's things you didn't expect these you know we call the movement issues they're caused by some interesting things some customers shine their floors so or they have skylights and that feeds back into the sensors and makes this point cloud much different than it does look at our headquarters on our test track help improve efficiency Chris kind of alluded to this earlier but if there's a specific specific place in the warehouse where the Chuck's just always move slow sometimes what we can do is clearly just see that the wide R or the camera is seeing something that it shouldn't and with a little bit of adjustment by the customer or a little bit of adjustment in the map that we use to navigate we can alleviate those problems so you have all your data but now you have a hundred a thousand a million robots in the fields and you need to upgrade them at some point so how do you do that traditional software management ansible saltstack puppet they're great tools for managing servers you have an always great internet connection and you always and you and you can kind of rely on either a connection to you know make things good for you the great white whale of Chuck is reliable Wi-Fi warehouses just don't have reliable Wi-Fi there's a lot of racks there's a lot of interference and so what we end up with is half applied States so almost worse than an upgrade just failing is a half upgrade an upgrade that looks like it went good but it didn't go all the way and we battled a lot of these problems early on so we said to ourself there has to be a better way you have to be able to reduce the complexity of these things we have to be able to be be able to minimize than the amount of data that's being pulled down and do it more deterministic so we shoehorned everything into docker docker containers are pretty great at solving this problem if you have a container it either downloads or it doesn't if you need to roll back your roll back to a different container you have a very good view of the world of where your software is updating and so if you need to update a thousand of these things you all you need is a good internet connection to download a single file versus what you would have to do in the other situation which is a bit of a back-and-forth between a lot of different services we really leverage Google cloud platform to make this possible and don't get scared it's another architecture slide but we're gonna go for it quickly Google has to go a lot of great tools for building containers cloud builds scales with our developers as they need to make containers and we're rushing to finish releases then you know we can have 20 developers doing 20 different builds and Google Cloud builder scales up we push all those to the container registry and then then we have our custom solution to this problem but really Google has a great toolkit with kubernetes engine that you can run software that that just consumes a lot of this stuff and finally this software allows us to push things out through IOT core IOT core can't just collect data but it can actually manage the configuration of the robots so essentially the message goes out to one a thousand a million robots saying we need you to download this container from container registry and then they go into action so I'm gonna show you how that works here's an actual upgrade so let's just sped up a little bit but these containers download the the robot gets the command gives us the does it the signal that it downloaded and then we can apply that upgrade and so you'll see we do three at a time here they download and they apply and so we're taking three trucks out of service we're downloading a container that container gets applied they go back into service but we know exactly if it if something didn't work if it did work and the nice thing is going from build X to build Y it's just as easy as going from build wide back to build X because I think all of us know that sometimes software upgrades don't go well so almost as important as your upgrade path is your downgrade path but with docker kubernetes to drive this to drive this software and IOT core we can really manage this problem very well so we have all the data we have thousands of robots and now our customer comes and says to us hey we think we need to rearrange our entire warehouse we have 100 trucks and we think that this design might work better and you're like ok well so we're back into kind of a problem here so we can either fly out to the warehouse bring another 100 trucks get another warehouse set it up the way they want test and make sure that it works or we have to do something else and I think we all kind of realized we pretty much just have to do something else so going back to our docker adventure here we we were really pleased when we got to this point when we said okay we already have everything in docker so all we really need to do is change a few things in this container and we'll actually have a docker container that can be run in a simulated world so we have the robot operating system running completely inside of the docker container all we do is simulate the sensor data and so what's really powerful about this is that the sensor data coming in is going through the same pipeline that it would go through in the real world so as we make adjustments we can be very confident that those adjustments are going to behave the way that we expect them to in the real world and that really just gives us that extra bit here where things are things when we go to deploy them behave they're the way that we want so why would we want to test with hundreds of robots the warehouse layout change is one thing but another thing is algorithm changes you know we have a lot of logic and algorithms as Chris alluded to earlier that batch orders and to try to gain more efficiencies in the warehouse and so when we change those algorithms it's not really great for us to test them out on a customer because you can imagine what a customer's gonna call us and say they're gonna call us and say hey Joe that software upgrade you gave me now my rates just fell by 50% and that's not a really great conversation to have and that's not what we want to do for our customers and so with this sort of infrastructure we can prove algorithm changes before we deploy them and we can confidently tell a customer when you take this release you're gonna get X number of X percent of improvement you're Pickers will be this much more efficient your warehouse will be able to get this many orders out the door and be very confident that's an accurate estimate and lastly and I think which is kind of an interesting way to use the system is that we have cloud systems as well and we can do synthetic load testing in those cloud systems and throw you know fubar data at it or we can run real robots again real simulated robots against that system and do load tests for warehouses that are even impractical to build in the physical world so we can really put our other software and the cloud through the paces using a very large deployment of simulated chucks so scaling with kubernetes engine is super easy auto scaling works great and that is really important for this problem you don't want to have to call up DevOps engineer and say hey I need a cluster with 100 simulated chucks you just want to tell your software I need 107 simulated chucks and then minutes later you have a hundred simulated chucks stackdriver monitoring is built in and so you can see your simulated chucks and see trends in their CPU usage their memory usage and see all of that and feed it into bigquery as Paul alluded earlier and make sure that your dashboards perform the way that they should and that you're seeing the algorithm improvements that you should you can scale up and down quickly scaling up is super quick scaling down is also super quick because this is expensive resource and you don't want to be spending money with a simulation cluster that someone forgot to shut down for like a weekend and your Google Cloud bill all of a sudden is a little bit higher than you expect it so here's a real simulation this is a pretend warehouse in the cloud we have pretend robots running around doing robot things they're picking orders they're inducting orders they're even they even go to charge they even have simulated batteries so because charging can actually take out of the efficiency of the system so we simulate all of that and we can put all the things I talked about into this and so very very flexible system another thing that happens is that when you start simulating things if you spawn 20 robots in the corner of a warehouse they kind of form a mosh pit and they don't really do very well and so these are some of the fun things that you start to discover when you build a simulation platform is like oh wait a second they all can't just spawn in one place they need to actually spawn at randoms points and we need to kind of figure out how we scale this up and down but yeah that's a fun little video of a robot mosh pit if you ever wanted to see one so the last thing we need to talk about is integrating with your customers you didn't just build this robotic IOT platform for yourself you built it because you wanted to bring it to the world and you want people to use it and companies to use it and so you have to kind of discover who your customers are discover what kind of technology they have and and you have to integrate with it so in traditional in warehouse man warehouse management systems are the systems that handle all the orders handle all the inventory they kind of determine like what that day's picking is going to be and they give us our work and so we have to innovate with them our customers I have older systems there in the logistics business they're not in the IT or the tech business and so when they find a solution that works for them they stay with that solution and and we want we don't want to go into our customers and say well we wish we could work with you but you have to update all of your IT systems to adhere to you know rest standards or into our api's we have to do something different so we adapt artists our rest api's to our customers technology they use socket communication with fixed with messages are you soap they use SFTP I mean they use everything and so that means we have to build everything and we have to adapt our api's to everything and so that's a big challenge but luckily when you're using Google cloud platform you have a lot of tools at your fingertips to help you with that challenge we reach for cloud functions for the simplest of integrations and kubernetes also makes super quick with things like hey native and other tools that are coming to the kubernetes platform well we can build these little micro services like their only purpose in life is to translate our API messages so that our customers can understand them there's a lot of challenges still with but with these tools without these tools we wouldn't be able to do what we do today at the pace and at the scale we do it today Google kubernetes engine on prim is the next great thing that six our river systems is really looking at and some of our customers have such tight regulation you can think government and those type of things where they just don't have the option to have anything outside of their four walls and so with these type of deployments we're really excited to experiment and to use Google Cooper nazy on Prem to solve these problems so you know these these regulation and concerns are definitely one part of it another part it's of like bringing the sensitive sent latency sensitive things that need to happen to the edge and the edge being the customers own infrastructure and so if we have to validate something every single time we scan it and we can't afford the trip up to our cloud back to their data center back to chuck then some system like this makes things a lot easier for the customer and for us to get that integration done and to really have a great customer experience from our point of view it's so great that we can have the same deployment tooling that manages all of our normal cloud deployments these on-prem deployments as well and so that can reduce our overhead for you know DevOps tooling and for and to keep the interface that we use for our software engineers and for our tech our tech support engineers the same [Music] 