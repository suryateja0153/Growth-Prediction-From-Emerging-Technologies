 All right. Hi everyone. Welcome to IoT Show: Deep Dive. We are really excited to have you here. I'm also equally excited to have Erich here. He is the head of Azure IoT Industrial IOT.  Yes.  He's going to be here talking about Industrial IoT. So I'm excited. Erich, do you want to talk a little bit more about your position.  Sure. So we started the Industrial IoT Team in Azure five years ago. We've been building up the team both in Redmond and in Munich. Certainly, in Germany, there's a lot of industrial automation going on, so it made sense to setup the team distributed. I have been leading from the engineering side together with my partner in crime, Christopher Lin. We've been working on a platform based on Azure IoT that is specifically geared towards industrial automation, industrial IoT, work with manufacturers, machine builders, automation companies, and helping them achieve their digital transformation.  As I mentioned before, I'm excited. One of the reasons why I'm excited is because this is one of the top requested, deep dives that we've had. It is actually for us to deep dive into offerings for industrial IoT, but what is our strategy, some of the best practices and some patterns, and then also show some demos as well. So with that said, if this is your first time coming to a deep dive, what it is, is one of our live events where we answer your questions in the chat room. So if you have a question, feel free to add it to the chat, we'll get to you during the event. If you're watching this on-demand, don't worry. You can still talk to us on the tech communities, which we'll show towards the end of the event. So not to date myself, but over a decade ago, I was working in production line and it was notorious for always going down. This is the time before devices were actually connected to the Cloud. A lot at the devices or a lot of the machines were pick and place all the way from certain waves, all that fun stuff. I always remember when any of the machines go down, I would be the one that would be have to fix it, but the rest of the assembly line would just stand around because there was nothing that they could do at that point once the machine and the line goes out. Not only was it one assembly line, it was multiple assembly lines. So you can imagine if I'm working on one machine that's down and if other machine goes down and other assembly line, you have one of those workers walking around trying to find other maintenance person to actually make sure the assembly line starts up again. So this is why I'm very passionate about this because the improvements on the factory floor have been so huge over the years. I'm excited for us to talk about those improvements. Hopefully, no one will have to tweet out their thumbs, like I did a lot, over a decade ago with these connected factories.  Right. Yeah. So certainly, we see a lot of demand for this product, especially the manufacturers who obviously want to produce as efficiently as possible are very interested in both detecting failures, but then also being able to run some simulation in the Cloud or using machine learning to predict failures, and then try to avoid them in the first place.  Yeah. Then when if it does happen, actually been able to send alerts and getting the right people to fix it as fast as possible.  As fast as possible. Exactly.  Exactly. Well, I won't hold this up anymore. I'll let you start giving overview. Then after the overview strategy, you'll deep dive into that demos.  Excellent. Yeah.  Perfect.  So with that, we're going to do a quick introduction, just an overview of what we're doing and why we're doing it, and then we'll do a little demo of our solution accelerator called Connected Factory.  That's great.  So really what people realize is digital transformation in the industrial space is quite complicated, and people need good partners like Microsoft to achieve this in a step-by-step fashion. A lot of people jump in and do predictive maintenance. But obviously, there's a process to getting there. We have the tools to make it as simple as possible to connect machines, then start collecting data from those machines, then analyzing that data both on the Edge and in the Cloud, and then finally making predictions regarding possible failures. Also getting getting field technicians quickly to, like you said, when you're pick-and-place machine goes down, getting the right people there quickly to fix the problem is essential.  Exactly. You don't want so and going on break and you want to be able to alert them wherever they're at, so they can go fix the machine.  Right.  Exactly.  Yeah. So what we've done is we've, this is actually borrowed from Kagermann who was kind of the godfather of platform industry for all in Germany. He created this seven step process or seven-step model to doing digital transformation. Obviously like I said, back in the '70s when PLCs came out, they started using them to control machines, but they obviously have a digital interface, which makes it attractive for doing Industrial IoT because you have that digital interface to interact with. Then you need connectivity, you really don't want to connect your machines directly to the Cloud, but you want to connect them securely using things like our IoT Edge gateways, and then you can start collecting data and building telemetry dashboards. For the first time, those can be global dashboards where we can really compare production lines distributed around the world to one another and see why is one more efficient than the other.  Exactly.  Then once you have that telemetry and you've been collecting it for a while, you might be able to see some trends, some patterns, but you're still human eyeballing the data at that stage. So you're not really using machine learning, but you have an expert looking at the data on a dashboard, sitting somewhere in the world, and being able to see, "Okay. There's a trend here. Maybe this machine has a problem." Like you said before, it only takes one machine to stop an entire production line. So you want to be able to identify those problematic machines in a production line as quickly as possible. So then you start collecting data from lots of different machines coming from lots of different vendors. I mean, usually, production line is like 30 years old. It's been retrofitted 20 times.  So many different protocols, so many different types of machines.  Right. It's not, let's say, a simple task to really be able to get everything to a common data model, but you need a common data model to be able to compare the data in the first place.  Exactly.  So you need to start doing some data modeling and you need to start normalizing the data in the telemetry stream from the machine to the Edge to the Cloud as early as possible. What we decided is that people that know the telemetry best because they probably were involved in setting up the machine in the first place are actually on the factory floor. So we want to really standardize the data, normalize the data on the Edge, in the factory before it gets sent to the Cloud. So by the time it arrives in the Cloud, it's nicely formatted, nicely uniform using the same semantic model and all of those things. So the data modeling really is happening at the Edge. Then, once you have that, let's say, hierarchical data model, you can then start running machine learning and stream analytics on it automatically and start looking for issues by computer rather than a human having to eyeball the data all the time.  Exactly. You can have the machine learning either live on the Edge side or in the Cloud side.  Exactly.  For both.  Exactly. So in some scenarios, for example, in an oil rig where connectivity to the Internet is super expensive, you want to do as much as possible on-prem. So it makes sense to do that machine learning model possibly in the Cloud and then download it to the Edge and run it there.  Exactly.  Exactly. Then finally, once you have those automatic insights, you can again get a human to make a decision what to do with it. Or even better, you can make a machine do that decision for you and create that self-healing system that everybody likes to have.  That's the dream.  That's the dream. We're a little bit away from that in most scenarios, but we're getting there and there are some examples where they've started to get these digital feedback loop going and making some simple decisions by machines rather than waiting for humans to say, "Oh, yeah. There's an alarm here. I better do this or that the other thing." For example, when certainly, safety critical things are always done locally. So if somebody's about to get hurt, you press the "Red" button and that's it.  Yeah.  But for a less critical issues, for example, machine might be running hot. You might want to predict well is the machine going to take damage at that temperature or not. If the machine builder has built a machine learning model and say, "No, it's all good. You can keep going," then nothing has to happen or you throttle it or something. That could be something, for example, where that digital feedback loop comes in and be helping. Then really, once you have all that, you can start making predictions or making decisions based on predictions that guarantee that your production line will never go down or you create a product and you know that product will always be at a certain quality. Once you're there, you can start offering this as a service, because then you have that guarantee. You can create a service and this is what people like to be called the pay-as-you-go model with outcome-based products, or between you and me, it's machines that never break. That's basically what everybody wants to achieve, but there's a process to it, and that's why we're saying let's do it step-by-step, start with connectivity, then the telemetry, then the inside, study the analytics, and then finally the machine learning.  Exactly. You do have to go through that process. Because if you don't get that connectivity first, then, I mean, you can't continue on.  Right.  Yeah. It makes sense.  Quite often, connectivity is the hardest part because the other parts are usually Cloud-enabled and Cloud-driven, and we have great tools and great dashboards for it. But the connectivity really with the vast majority of diverse systems in production lines, it's non-trivial to connect them.  Yeah.  But I'll talk about that.  Firstly, I had a factory floor.  Yes, exactly. But we have a good strategy there. Obviously, Microsoft is a great ecosystem company and partner enabled company. So we have a lot of connectivity partners that we work together with to really get the best in class connectivity solution for Azure.  Sounds great.  Okay. So what's Vendor Lock-in? So a lot of companies that we talk to, especially the manufacturers are used to these large ecosystems that were built over years and usually based on proprietary technology, and they've been forced to buy into this ecosystem. Once you're in, it's hard to get back out.  Yes. service agreements too and everything.  Exactly. Once you start buying hardware from a certain vendor, chances are it's not going to be super compatible to the next vendor. So it's more difficult to really get the best product. Manufacturers have clearly told us they will not accept a vendor locked in product, right? So we've decided a long time ago to have a set of business principles and a set of technology principles for our industrial IoT offering that prevents vendor lock-in as much as possible.  That's great. I mean, especially a lot of companies popping up, you don't know how long those companies will last. But there are so many reasons why people are a little shaky on vendor lock-in sometimes.  Yeah. The 30-year support, once you put something on a production line, you reading with the supported for 30 years or up to 30 years. So that you really want to have the right mechanisms in place to allow that to happen. So a long time ago, we decided well, obviously we want an open platform, we're using our Azure pass components of course, we're building an abstraction layer on top using open standards, well-established industry standards such that people can have that layer of abstraction and only use the open industry standard for interacting with the platform, we've built a partner ecosystem of connectivity providers, of gateway hardware vendors to make sure that people have choice. Of course, we're partnering also with the IoT companies to offer their products like the automation companies; Siemens, Rockwell, Schneider, Mitsubishi, etc to build their products and their Cloud enabled products on Azure too, right?  Ye ah. It makes it easier especially when you have multiple different machines, maybe some of the machines have different vendors or different types of gateway appeals these. It's great that we have support across those different ecosystems.  Exactly. It also fosters interoperability, right?  Exactly, yeah.  So you want to give people as much choice as possible and stuff should just work together, right?  Yes, ideally.  So then of course, we also have a set of technology principles and we've embraced open source from the start. Everything we do in the industrial IoT space is open source, it's all on GitHub. It doesn't mean that we just throw it out there, but we develop it in the open, but we're responsible for the quality. There are products just like any other Microsoft products. So we have regular releases, we fix bugs, but we also accept contributions from the community. Ideally, "Oh, I found a bug and here's the fix," or, "Oh, I found a bug is good enough." So fundamentally, we want to encourage participation, and that's one of the reasons why we also set up the open manufacturing platform where we're really building an ecosystem of manufacturers but also suppliers, automation companies, and so on to solve common problems in an open way such that everybody can benefit and not everybody has to fix or find a solution to the same problem.  Yeah. I loved that you mentioned we're also maintainers as well because you do see that with open source projects and huge open source advocate. Sometimes, you see projects go to the waste size because they don't have strong maintainers to help out and contributors from the community.  Exactly. Then finally, of course, I mentioned it before, we want to use open data models as much as possible because fundamentally, when you're modeling a machine that's been around for 20 years, chances are the information model built into the machine is not open, but you can convert it into an open data model such that you can do that analytics and compare the data from that machine to other data you may already have. So final points can make changes to the machines. I hear that all the time. They say, "Erich, connect my production line to the Cloud, but for God's sake, don't make any changes."  I hear that all the time when encoding with partners and customers. The same thing; we can't actually touch this, but how can we connect it?  Exactly. So that's to be non-intrusive.  Exactly.  So we say, "Okay. Can we add a gateway?" Yeah, okay, gateway, fine, you can add a gateway. So we say, "Okay. Then the connectivity will be in a secure way through the gateway, don't connect your machine directly to the Cloud, don't do that, go through a gateway, use a hierarchical network segregation with ISO 95 compatible network layout, and then you're good to go. So that's basically what we've decided to do. In a nutshell, I have this little diagram here where it summarizes our strategies. So we use open source, we use an open platform, Azure, we use open standards, and of course, we use Open Data Models. Specifically, what we're gravitating towards is the common data model, which is part of the initiative, together with Adobe and SAP. So CDM is now supported in Azure Data Lake Gen2. So we're using that, and that gives us that common store in the Cloud for data models coming right off to machines. So in total and in summary, obviously, there's a layer to the platform. At the bottom, we have the infrastructure layer. Then on top of that, we have the PaaS layer that I talked about already. So things like Azure IoT Hub, Azure Data Lake, Time Series Insights, all of these things, Stream Analytics would fit into that layer. Then on top, we have our Industrial IoT layer based on standards like OPC UA and CDM. Then of course, should you choose to use it, we have an app platform layer, IoT central. Then finally, that's where it stops. We don't claim to be manufacturing experts although we do have our own production lines too for things like surface. So we do have our own production lines and we use our platform in those production lines. But for the general partnership, the idea of partnering with the manufacturers for specific use cases and specific business problems, the partner or a contractor would actually build things like an OED dashboard or a predictive maintenance application for machine builder or so. That will always come from the partner, not from us.  It makes sense. They know their industry the best.  The best.  Yeah. Exactly.  That's why I say winning together because really it's a win-win, everybody can concentrate on the bits that they know best, and you create product together. So one of the things that we standardized a long time ago is OPC UA. In Europe, it's really everywhere. Also, in Asia and US, we still have some work to do to increase awareness, but it's slowly getting better. The reason for standardizing an OPC UA is again for interoperability for the common data model and for security reasons. Because a lot of the older proprietary protocols used in machines don't have security built-in. OPC UA in my opinion has the best security that I've certainly come across. So we use it as a firewall between the machine and the Internet.  I'm curious on where you'll be speaking a lot about OPC UA. How does that tie in with the work that we're doing with Azure IoT plug and play and open modeling language. So for those who are not aware, we did release Azure IoT plug and play. It's open language modeling language to make it easy to connect devices to the Cloud with very little code or no code for the solution developer. So I'm very interested in how you see that mapping to industrial IoT, and what was your strategy there?  Right. So we've decided a long time ago for industrial scenarios we use OPC UA.  Okay.  Plug and play has its right in other verticals, for example, health care, and consumer products, and so on. It's mainly used for modeling specific and customer devices, and for OPC UA or for industrial scenarios, OPC UA is the common language and the common standard. That's why we decided for industrial scenarios, we continue to use OPC UA for other scenarios where there is no open standard or established industry standard. Plug and play fits really well and really accelerates data modeling for a lot of folks because, like you say, very little code. Very little effort.  It's great for the solution developer. Yeah.  Exactly, for the solution developer, it's great and they can get going with the data modeling quickly. Like I say, in our case, there is already a data model in most machines.  Yeah.  You basically just translate to OPC UA in a predefined format. I mean a lot of the companion specifications already do the mapping automatically, but OPC UA has this concept of companions specifications were you map from things like MTConnect, or BACnet, or lots of different protocols. You can easily bring existing data models to that common format.  Yeah.  We're also going to do a mapping in the Cloud for things that require plug and play. So we can map from OPC UA to plug and play.  That's god. At least you have that option.  Exactly. So it's really a question of what do we need to do to enable certain features or certain services, and we're doing that mapping so the customer doesn't have to.  Perfect.  Right. So obviously, when we looked at data modeling or industrial machinery, we needed to solve certain problems. So we said, okay well, we need a telemetry stream. So we needed to pick up the data from the machine, convert it to OPC UA.  Yeah.  Then send it to the Cloud. Well, the OPC publisher does that.  Yes.  That's exactly what it's for. Some GitHub like everything else, so there's a link. Really, what we've done is we worked with the OPC Foundation to extend the SPEC to cover Cloud scenarios. So they decided to work with us on this extension to the specification. It's been released a year and a half ago, and it's called publish-subscribe or pub-sub. So the idea is that if we pick up the data in the old OPC UA client server model, we convert it to pub-sub format which is just JSON, including UA binary which is the compressed binary format is also supported. Then we send it to the Cloud using things like MQTT or AMQP. So that's basically what the publisher does, it's our telemetry plug-in or telemetry converter, let's say.  I loved the fact that we're working with OPC UA Foundation and not just create something completely on our own.  Exactly.  I'm a huge fan of that just because there's a lot of people, a lot of community member is part of this standard, it's been around for a long time, and it's great that way, we have a part of it.  Right. So that's the new Microsoft tried to win them, actually supporting open standards is definitely the way of the future.  Yeah.  I mean, yes, it takes a little longer. But I mean you can develop the product as you're developing the standard; that's what we did. So we were the first to actually support OPC UA PubSub with the publisher, and as when the standard was finally released, we already have the product available.  Yeah.  Similarly, we created what's called the OPC Proxy. Now, OPC Twin actually supersedes OPC Proxy. It has the same functionality, plus there's more performance. So OPC Twin does multiple things. There's a Edge component and a Cloud component to OPC Twin.  Yeah. The Cloud component gives you that REST interface that people want to interact. I mean people want REST interfaces when doing Cloud development. So we have that REST interface now, and you can browse a machine, you can interact with a machine as if you are in front of it, from the Cloud, of course, in a secure way. So we use services to communication, the firewall stays closed.  Yeah.  So that is what the Twin does, and it also discovers machines that support OPC UA automatically, for the ones that don't, obviously we need that plug-in, that adapter from a third party, from one of our partners. So how that work? So I'll talk about in a minute. But fundamentally, we have the ability to automatically discover OPC servers because believe it or not, a lot of folks can't remember what the IP address of their machines are because it was set up 20 years ago.  I like that. I've seen that before. Yes.  Yeah. You got to find it somehow, right?  Yeah.  So that's what we decided, and we need an automatic mechanism there. Of course, it also helps if people don't need to type in IP addresses manually. But a lot of network operators don't like scanning on their network, so we also support actually typing in the IP address. But obviously, that requires the IP address to be well known. Then finally, we also can in a secure way execute methods on the machine, the ones that the machine exposes, and again, through the OPC Twin from the Cloud. We're the only ones who have that technology. So that's something that certainly for the digital feedback loop you need. Then finally, we've discovered that there's no good certificate management solution because obviously OPC UA's certificates for authentication and so on. So we built one also based on the standard on OPC standard. We call it OPC Vault because it uses Azure Key Vault under the covers, and again, it's open-source available on GitHub. So that gives you for the first time a truly global certificate management solution for your OPC certificates.  For folks who are familiar with Azure or Key Vault, is there any big difference between folks who've worked with Key Vault before and what we just released?  So there's a new REST interface. So OPC Vault wraps Key Vault.  Okay.  It uses Key Vault as a private certificate authority.  Okay. I see.  We keep the private key obviously in key vaults. If you want hardware-backed storage, secure storage, so HSM modules basically.  Yes.  So if you use OPC vault in that way, it's just a configuration setting, the private key stays in special secure hardware. Obviously, it's never exposed and you can send a certificate signing requests to key vault through OPC vault and get your signed certificate back, which you can then install on the machine.  Makes sense.  So that's basically how that works. Then finally, I talked about the adapter modules already. We're working with all the major players that support connectivity to industrial devices, and they're all obviously supporting connectivity to Azure. We're also working with them to support that connectivity on our Edge platform. So very soon, we're going to have some Edge modules. They've already been announced on the Edge marketplace from those players such that installation can be done from the Cloud. So you have to have your Edge obviously up and running to make the Edge configuration and Edge setup as simple as possible. We build an installer, such that it's like a single-click task and you don't have to sit through pages of documentation.  Yes.  So that obviously helps just to make that experience as seamless as possible and have that easy button experience where you click on the installer and it does the setup. Then once available, those modules can come down from the Cloud. They're all containers, docker containers, they can come down automatically. Then I mentioned already, because obviously a lot of hardware vendors as well that obviously built industrial grade hardware or you can just use a VM. In fact, most manufacturers that we work with have a little on-prem data center, and they can just spin up a VM too. That works.  Now, you can find in any of those type of certified devices that has a device catalog. I love that you mentioned the partners, because anytime you're building an IoT solution, it's a partner ecosystem. There's that one person all the way through who's just building something.  Well, and they are set up to do this properly. They've been in this business forever. So it totally makes sense for us to leverage and work with partners rather than trying to do this ourselves. Makes some sense. So that's what we do here. Then finally, this is the overall architecture, where we have obviously our Edge components, the OPC publisher, the OPC Twin, like I talked about, the OPC adapters for the machines. Obviously, we connect at the PLC level. We stay away from the sensor level. So it does usually at PLC or gateway, a sensor gateway, somewhere on the machine that we can connect to, we convert it to the OPC way common data model. Then we make that data model also available in the Cloud using CDM, the common data model. Then obviously, all our services that are available in our past platform, just plug into it and are available for you to use.  Easy peasy.  Easy peasy. Yes, easy peasy. That's exactly right. What could go wrong? So then finally, I mean, we started developing these components, these modules, these containers, and people said, "That's all great. Job well done, but how does it all fit together?"  Yes, you have all of these different services. That's a question we get a lot.  Exactly. So we said, "Okay. Well, we got a show the starting point." I mean, we're not in the industrial solution business. We have partners like PDC who do that really well. So we said, "Okay, but we need to show people the way." So we built this solution accelerator, that we called, surprise, surprise, connected factory. We basically show people, "This is how it all fits. You can try to set using your own Azure subscription. We've optimized on costs. So it's not this super scalable architecture that you want to go into production with, but it shows the way." Then we obviously also use our security mechanisms that we've put in place to really show, "Okay. This is how you would secure the telemetry path, the connectivity to the Cloud, and all this." So this was important to us to really show. Actually, building connected factory, we did find quite a few holes that we fixed and we used an external company to do penetration testing. So we really feel confident that the security aspect has been addressed, and we really wanted to show people, this is how you do it because we get that all the time.  Yes. With Connected Factory Solution Accelerator, how is this one different between our remote monitoring and predictive maintenance?  Right exactly. That's a good question. Remote monitoring, predictive maintenance are horizontal solutions, second applied to almost any vertical. Connected factory is specific to the industrial vertical. It's actually based on remote monitoring. So we took remote monitoring and extended it with our industrial components and build a dashboard. The most obvious one was to do an OEE calculation for equipment efficiency, and you can see that in the bottom here. I'll do a demo in a minute. But fundamentally, doing simple dashboarding is the step 3 in my seven-step process. So we said. "Okay. We'll take it as far as that."  One question I get a lot is that, your solution accelerator, how's that different from IoT Central? The one thing I try to explain to them is that, IoT Central, we're managing those services for folks and for the solution accelerators, what you were highlighting before, it's really like this reference architecture of these past services coming together to show you an example of a particular scenario. For this one particularly, connected factory. So if you're trying to think of what is really the differences between the two, that's really what it is: managed services versus their services. You're still managing yourself with this solution accelerator, but we help you deploy all of them.  Exactly. So the main focus again for connected factory, was not to build a SaaS offering, but just to show people how they get started building their own dashboard, how the past components fit together, how our industrial IoT components fit into it and then do some basic alarming and inventing stuff like that. Of course, it's all open source. So you can just download the code and start modifying it to your heart's content.  I remember when we first released, there's definitely some changes of connected factory, when we released and now, because we have IoT Edge support now. What are some other differences between when we released long time ago the connected factory, so people who played around with it at that time versus now?  Well, the biggest change that we made, is the integration of the OPC Twin. So obviously, that didn't exist when we released connected factory. I mean, yes, we changed the colors. That's also important. But to get that consistency with other solutions, but really, the biggest change that we've made over the year is the integration of the OPC Twin to have that simple one-click experience for setting up the Edge, Edge support obviously. So I can do a little demo now.  Yeah. That would be great.  Let me just change this over.  This is always the fun part of the deep dive.  Yeah. So here is the connected factory and then we can just go back to homepage. So fundamentally, the homepage hasn't really changed much from the beginning, part from the color scheme. We did integrate the Azure map service here. This now Azure maps. OEE calculations down the bottom as usual. So this page is pretty much the same but it gets different here, where now we have, Edge integrations. So these are all IoT Edge gateways. Actually, all of them, in this case, are from our simulation. So we have a simulation built into connected factory. So we can actually show something. Otherwise, all the dots would show zero. That's boring. So we added a little simulation of seven different production lines building virtual products. That gives us OEE and so on. So that's basically what we've done. This is discounting functionality for OPC servers that I showed or I talked about. Basically when you connect your own gateway, it just shows up here. Then you can hit the "Scan" button, and then eventually you'll see some endpoints here and those are already actual OPC servers. So then OPC server can have multiple different endpoints, like you see the same OPC server but different end points here.  Sorry to interrupt you, but do we have a limit of the amount of end points you can have with the servers?  No. There's no limit. Most have five or six. So that's the standard. Some only have one. It really depends on the machine builder to make that choice. So then obviously, the OPC Twin also supports browse just like before. But now, you can see it's a lot faster than what it used to be with the OPC proxy, because we've made quite a lot of improvements to the performance and you can browse the OPC way server namespace or basically the data model. Then you can also, like before, browse in here and then see the telemetry that's already getting published. If you want to publish more telemetry, you just click on it, hit "Publish", and then that's it. Now, you have a little check box here and data starts streaming automatically using the OPC publisher to the Cloud and that's it. That's the only thing you need to do. Then if you look at Time Series Insights Explorer, which is still integrated, you'll start seeing this additional telemetry show up in the stream. Do you have a question?  I was actually going to ask, once you're done with the demo, was customization. If people want to start playing around with connected factory but they really want connect their own devices and just start somewhere after they play with connected factory, what would you recommend?  That was the thing, I was going to get to next.  We didn't plan that.  Totally. If you hit this button, it gives you instructions on what to do to connect your own production line.  I just needed to wait five seconds.  Well, there you go. You were a little ahead of me. But anyway, because people say, "Well, what gateway should I buy?" I mean, that's a fair question. So we said, "Okay well, here is a pre-filtered list of our device catalog, you click on that." Actually, that's not the right link.  Let me just find it here.  But if you want to see supported Edge you go to that link?  Right. Exactly. So this is basically what Edge supports. Let's see, this is the installer. So we also have a link to the device catalog. I can't find the right now but it's there, and then finally, you can click the "Installer" here immediately. So you run this page from the Edge, once you buy your Edge divisor, so set up your VM your browser's page. You click on it immediately launches the installer to install the Edge runtime and all the components that you need for the industrial scenarios, and then all you need to do is go back here to the other tab and you know your Edge device to this tab, and then your Edge will show up, right?  Yes.  Then you can start browsing endpoints will start selecting telemetry in that set.  I love that. That's a great starting point. I get the idea of what's possible, with the different services. You mentioned a little bit about Scalability, when you first talk about the connector factory? For folks who are thinking about scalability, what are some factors that they need to think about? They won't be using the connected factory for scalability but what are some best practices when they're looking at the end-to-end solution?  Right so for cost reasons, we basically deployed both the Dashboard and the Microservices like the OPC Twin and the OPC Vault in application host, and obviously you wouldn't do that in a scalable environment, you use things like Azure Kubernetes Services that would be a change, and then also I will say we use the most basic IoT Hub skew that you can afford and then as you're scaling to hooking up multiple production lines you would use a higher skew of IoT Hub and similar for Time Series Insights the same. So again it's more about growing your architecture as you start adding more devices, adding more factory lines in this case again to keep the costs down. They really wanted people to be able to look at connected factor using the free Azure account.  Yeah.  Where you have $250 a month credit, and that's why we try to squeeze everything into that $250 limit, and this is why some of the scalability topics haven't been addressed but that was on purpose to keep the cost down.  Yeah. So more people can get the idea of how to build the solution and have a starting point?  Exactly.  Yeah.  Yeah.  It makes perfect sense. Yeah.  On those classic trade-offs.  Yeah. Good trade-off though?  Exactly.  Yeah.  So then we have some resources. Here's all the source code for our components. Again everything's on GitHub including instructions of what they do and how to deploy them. We have pre-built Containers in Container Registry. So Azure deploying Edge you don't need to build anything, the install does that automatically but you can also use Docker to just pull down the images or the Azure portal to reach a deployment script. That's all done for you.  The Beauty of Containers?  Beauty of Containers, there's also some high-level instructions on Microsoft Docs. You know what's Industrial IoT and why is it important etc. Gives an overview of the components what they do. Then of course we have to connect a factory source code, like I mentioned it's all there, it's all on GitHub. Finally, we have some resources which allow you to browse some of the past services that we obviously also use like IoT-OPEN, TSIS-1.  Exactly. I love that you have pulled up the IoT Tech community. Because after this deep dive if you're interested in learning more, and all of the links that we showed you, all of that information I'll make sure to post on IoT Tech Community, it's a great way to ask questions. I'm on there, if there's any questions we'll make sure that we ping it to you as well. But it's a great way to talk to engineering, and also other people in the community who are also building solutions.  Right.  So if you have questions, or if you have blog posts, or things that you want to share, some learnings that you've had, maybe you built this really great IoT solution and you want to share, and some of the best practices that you've noticed yourself, feel free to go ahead and just post on there, it's free. We won't tie you into eternity. We won't share your information to anyone.  Right.  But it's just a great way to get that direct communication back and forth, and then also if you have ideas for future deep dives, this where you post or you can tweet at me @aldaohms. Before we close I'm very interested in is there any other top questions that you get a lot from customers, and partners you're working with, developers who are building with Industrial IoT that we didn't cover today?  Well, one of the questions I get sometimes is, can I use all of this even if I don't have OPC Away in my machines yet?  Yeah.  Of course, you can and that's the whole point, you need to get to a common data model somehow. That's why we use OPC Away, and because of this security aspects. But of course you can connect every machine I've come across using our partners adapters, this is not a requirement, and of course the adapters are available and different skews as well. So depending on what size production line you have, you know you're not going to break the bank just buying an adapter. But fundamentally it's the best architecture that we came up with is to use those existing adapters, and those existing industry leaders to come to our platform support Edge, support the Azure Cloud and connect things just like you did in the old days when you create you're Scatter Dashboard or your MES System. It's exactly the same way. It stays the same. The only differences now we have Edge involved and of course the Cloud, and possibly even Azure Stack.  That's a question I get a lot.  So there's nothing stopping you from creating an additional layer. So you have Machine Edge Stack, Public Cloud, and not Edge Public Cloud. So you can run most of the services that we have on Azure Stack, and of course we are adding new services all the time, and we get that all the time actually that we create this solution to run either on Stack or the Public Cloud.  Yeah.  The customer can choose or even run a hybrid scenario where depending on the workload they choose one or the other.  Well, great. We're excited that you joined us.  No, thank you. Thank you for having me.  Yeah. Thank you. Thank you for being here, and thank you for joining. We'll have this on on-demand and will continue to answer your questions and chats. So thank you again, and we continue to have these bi-weekly. So if you have any suggestions, feel free to ping as on tech community. So thank you.  No. Thank you.  Thank you.  Cheers.  Bye.  Bye. 