 ARTIFICIAL INTELLIGENCE. THE PENTAGON’S ARTIFICIAL INTELLIGENCE, OR A.I. STRATEGY DEFINES A.I. AS THE ABILITY OF MISSIONS TO PERFORM TASKS THAT NORMALLY REQUIRE HUMAN INTELLIGENCE. LIKE RECOGNIZING PATTERNS, LEARNING FROM EXPERIENCE, DRAWING CONCLUSIONS, MAKING PREDICTIONS, OR TAKING ACTION, WHETHER DIGITALLY OR AS SMART SOFTWARE FOR AUTONOMOUS SYSTEMS. THE AIR FORCE IS WORKING TO UNDERSTAND A.I., TEST IT, AND MAKE IT A REALITY. A MAJOR GOAL IS TO PUT ARTIFICIAL INTELLIGENCE INTO FLYING VEHICLES LIKE DRONES OR JETS. SOMETHING LIKE A SELF-DRIVING CAR, A.I. WILL PROVIDE UNMANNED OR AUTONOMOUS SYSTEMS THE ABILITY TO EXECUTE MISSIONS. A TEAM CALLED THE COMBINED TEST FORCE, OR CTF AT EDWARDS AIR FORCE BASE, CALIFORNIA IS WORKING TO COME UP WITH A PROGRAM THAT CAN SAFELY TEST UNMANNED VEHICLES, AND ANSWER A BURNING QUESTION: CAN WE REALLY TRUST ARTIFICIAL INTELLIGENCE? HOW DO YOU MEASURE TRUST? ONE WAY WE’RE DOING THAT IS WE’RE DEVELOPING A SUB-COMPONENT CALLED TACE WHICH STANDS FOR ‘TESTING OF AUTONOMY IN COMPLEX ENVIRONMENTS. THIS HAS A WATCH-DOG CAPABILITY WHICH ALLOWS US TO SET THE BOUNDARIES WITHIN WHICH WE’RE COMFORTABLE WITH THE A.I. PERFORMING ITS DUTIES. IF IT TRIES TO BUST THOSE BOUNDARIES, FOR EXAMPLE, AIR SPACE BOUNDARIES, THEN THIS TACE SYSTEM WILL BASICALLY TAKE OVER CONTROL OF THE AIRCRAFT AND BRING IT BACK TO A SAFE POSITION. THIS IS HUGELY IMPORTANT BECAUSE IT ALLOWS US TO OPERATE THE SYSTEM SAFELY WITHOUT PUTTING HUMAN LIVES AT RISK OR PUTTING RESOURCES AT RISK. WE CAN SIMULATE CERTAIN THINGS WHILE WE’RE TESTING THIS PROGRAM AND RAPIDLY GET AN UNDERSTANDING ON HOW THE A.I. WILL REACT IN CERTAIN SITUATIONS. IN ADDITION TO DOING THINGS SAFELY THE AIR FORCE ALSO WANTS TO DO THINGS SMARTLY. THE CTF USES SMALLER, CHEAPER DRONES FOR TACE PROGRAM TESTING. IT PROVIDES A COST-EFFECTIVE WAY TO WORK OUT KINKS AND IMPROVE TACE WITHOUT RISKING HIGH-COST EQUIPMENT. THE ULTIMATE GOAL IS TO GET THE TACE PROGRAM SOFTWARE TO A POINT WHERE IT BECOMES A PROTECTIVE SAFEGUARD FOR FLYING VEHICLES THAT WILL HAVE FULL AUTONOMY. I MEAN AUTONOMY IS SOMETHING THE AIR FORCE HAS BEEN TESTING IN VARIOUS SHAPES AND FORMS FOR PRETTY MUCH DECADES AT THIS POINT. IT’S ALWAYS ONE OF THOSE THINGS THAT SEES LIKE ‘OH YEA IT’S FIVE YEARS AWAY. WE’LL HAVE SOMETHING, RIGHT?’ AND I THINK TODAY WE’RE GETTING TO A POINT WHERE IT MIGHT ACTUALLY BE ONLY FIVE YEARS AWAY. USING A SYSTEM LIKE TACE TO ACTUALLY LISTEN IN ON WHAT THE AUTONOMY IS TELLING THE AUTOPILOT TO DO, AND HAVING THAT AS, SORT OF, LOOKING OVER THE SHOULDER, THAT’S WHAT WE’RE DOING RIGHT NOW IS WE’RE TESTING THAT SYSTEM. WE’RE TESTING THE SYSTEM THAT’S GOING TO BE OUR SAFETY NET WHEN WE GET TO THESE MORE ADVANCED AUTONOMY ALGORITHMS, AND WITH THAT SYSTEM IN PLACE, WE’LL BE PRETTY SAFE. 