 This video shows our collision avoidance policy running on a robot. The robot uses 2D Lidar and RGB-D cameras to sense its environment. The sensors only occupy about three inches of height so there could be plenty of free space above to carry cargo. All computation is done on board. The robot navigates autonomously through a crowd of six people driving at human walking speed between two destinations. The map in the lower left corner is only used to tell the relative position of the goal. As it drives around, the onboard sensors are used to estimate obstacles' positions and velocities and sizes, as visualized in the orange circles. Even with noisy low-cost sensing we were able to bring the collision avoidance algorithm directly from simulation (where it was trained) to a real robot driving among pedestrians. 