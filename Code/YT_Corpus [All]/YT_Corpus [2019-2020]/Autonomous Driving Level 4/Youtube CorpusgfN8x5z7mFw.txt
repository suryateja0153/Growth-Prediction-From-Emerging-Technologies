 [Music] the history of autonomous vehicles actually goes back quite far the oldest example where we had autopilots that's actually airplanes and the first autopilot was already in 1912 where people were using an autopilot in an airplane to stabilize the flight and make it much easier for the pilot to fly the airplane maybe the most exciting right now that's actually self-driving cars in self-driving cars we are not yet really at the full potential of self-driving cars we're not driving completely without drivers there are different levels of autonomy we are actually making big progress with artificial intelligence in in these vehicles that will hopefully get us soon to higher levels of autonomy [Music] what we need to do is we need to collect tons of data sets images of people in different situations images of pedestrians on the road images maybe of hidden pedestrians behind cars and we need really thousands millions of these images ai is trained on examples to train a network to recognize objects on the road of images where something is labeled as a truck or is labeled as a car and if you have only been training on cars and trucks then you will never be able to recognize a bicycle so you will have to provide examples of recognizing a bicycle the whole point is to teach the computers to to mimic the computation that happens in the human brain when we do object recognition right because it's very easy to for us to tell if this is a dog or a or a cat but it's very difficult to write down the code that actually captures what is a dog and what is a cat traditionally trust has been among people it's a social phenomenon that relates to how people interact with each other but now that we are looking at the trust between humans and machines then the trust gets a slightly twist in its meaning so for example it has been shown that if people ride an autonomous train they are more likely to trust the autonomous train than when they ride an autonomous car and interestingly it has been shown that if there is a human-like body with his or her hand on the steering wheel that could also positively influence the issue of trust although that human body is not going to steer the autonomous vehicle we want to show that if people understand how the ar works in the autonomous vehicle and and they can explain how it works then they're more likely to accept it from a trust point of view these cars they have sensors that look all around the car they might have information from other cars that they are sharing so they are much better in detecting some situations where there might be pedestrians on the road or hidden or other cars driving in in a strange way or there's an accident behind a corner so the problem with the data on how much they will reduce accidents is um that there was one statistics i think which is quite credible which says that it's 40 but then there are ones that say well basically 96 of the accidents are based on human errors so self-driving cars can rule out 96 of the accident another advantage is that there are still some people who don't have access to either their own car or maybe they cannot drive themselves for for various reasons maybe because of age or disability and all these people they would have a wider access to individual autonomy by self-driving cars a lot of people perceive ai as something which has its own ideas and emotions and feelings and can perhaps show initiative in situations that it has never encountered before have initiatives on their own how to act and this is quite inaccurate at least at the level of aid that we have today i think the the current perception of ai is really much influenced by the media by science fiction movies they think ai has its own intention it does what it wants to do basically and also at a certain moment it may basically go beyond the human capabilities and then rule over human beings it's nothing but an algorithm that looks at the past examples when based on that makes a decision ai does nothing but what you have programmed and in that sense it's not magic when it comes to autonomous vehicles making sure that they are safe and also we can explain why they are safe to the public that also can contribute enormously to the issue of trust hello i'm jan oliver from the university of leicester and the team driverless so you might remember our team from last year at the royal society later we were also at the science museum and at the royal institution and some teen tech events we had this nice model car that was about this size and it was driving around the track and you could push a pedestrian in front of the car and it would stop hopefully we demoed some artificial intelligence and the sensors of self-driving cars and also we had a driving simulator where you could measure the quality of your driving so since then we have been continuing to do research in the area of trust and trust for us the definition that we follow is trust is a situation where a human believes that a system is doing something beneficial and helpful for the human in a critical situation so self-driving cars they are very good example because critical situations are in traffic where you might have other cars driving around or going at very high speeds and trust is required because the user must believe that the system does something safe and beneficial so that the car gets you to where you want to go as my colleague jan just explained we have been continuing our research on establishing trust in autonomous systems since the last year's summer science festival what i will do next is to explain two concrete projects that we've been carrying out since then and explain the results that we have been achieving in the past year the first project is about technology called platooning you might have heard of several active projects that allow for a convoy of heavy vehicles like lorries and trucks or passenger cars to drive very closely to each other with a human driver in the leading car and the following cars driven autonomously using a kind of autonomous controller the idea is that because the air drag is reduced there will be saving on fuel costs and environmental effect of driving and also potentially some saving on driver costs because the leading car is driven by a human being and the following cars may not need a human driver what we have been doing in the past year was to analyze the protocols that let the following cars know about the status of the leading car and find those design parameters that lead to a safer technology for platooning we have been doing this using artificial intelligence techniques and also a rigorous testing technique called conformance testing this testing techniques technique allows us to push the technology to its boundaries and find out under which parameters the technology behaves more safely this project leads to more transparent design and hence hopefully to a more trustworthy design for such a platooning technology the second project that i would like to explain briefly is it is a project about environmental effect of autonomous systems we have been looking at some undesired behaviors by some vehicle manufacturers where they implanted certain devices or algorithms in their cars so that when the car is on the test they emit less particles and when it's on the road it actually pollutes the air more drastically so what we have been doing is to use different types of search algorithms artificial intelligence techniques to find such behavior and reveal whether there is such an undesired behavior implanted in the car another application of this research is about finding those profiles that are more environmental friendly and then using those profiles to design the controllers of autonomous vehicles in order to make them more environmental friendly as well both of these projects have been carried out with different partners and they have led to scientific papers which you can read from our web pages if you're interested in the details of this research hello i'm jenova quefalido lecturer in human computer interaction at the university of leicester my work within the context of self-driving cars lies in user experience and passenger experience and in designing innovative interactive services systems and ecosystems to its support and enhance experiences but also to help us make better decisions when we travel now where does trust come into play as you may already know or using indeed there are technologies currently that we use when we travel by car every day example of such include sat navs now these kind of technologies are designed to to help us travel faster by providing us um suggestions about our route planning based on a number of factors such as road closures accidents and general traffic information now the success stories from using such technologies led us to over rely on those technologies and have high levels of trust in them but when such technologies fail our dissatisfaction disappointment is also high now within the context of self-driving cars we have very very much similar interaction and experience scenarios and these are the ones that i'm particularly interested in especially the failure scenarios now my work within the context of self-driving cars has been focused mostly on identifying what kind of feedback uh and what type of data visualizations can actually enhance our experiences when we are interacting with self-driving cars but also enhance our levels of trust technology acceptance but also the feelings of safety now i'm testing all these within different safety scenarios because we all know that we people when we are facing crisis situations we act differently but also we have very much different needs so now the last example about trust through transparency and this is basically the software that we have in self-driving cars it's written by humans and humans they tend to make mistakes so now the question is can we have a very powerful computer that writes the software so we just tell the computer our expectations and then the computer writes the software for us and this idea is not very new so it has been around for decades and recently we've been looking into what is still missing why is this not taking off and we have seen some examples where maybe the expectations that we formulate for the computer to write the program they kind of have issues with them so for example we could tell a computer we want a program where the car always drives at the speed limit but it also stops for obstacles that's a contradiction now there are other examples where we might tell the computer to slow down but we never told it how to use the brake system so this is another example and that's a bit more difficult to find so we have been looking into that one where it's basically that the expectations that we tell the computer they're missing critical information to be able to write the program and we have come up with a research prototype that allows us to find this missing knowledge to find what have we not told the computer but that is necessary for writing a program that would control the car in the way that we expected so this was a quick overview of the research that we've been doing recently on trusted autonomous systems and we hope you liked it thanks for watching and hopefully see you soon in one of the exhibitions you 