 so I titled my talk a lighter in every garage and hesitated at putting a question mark at the end of that because it's still a technology and development so people think of this in the context of self-driving cars but there's actually a whole series of innovations that are being developed under the name of a TAS or advanced driver assistance systems and there's a level structure it was developed by the Society of Automotive Engineers and level 1 and level 2 are actually quite common an example of level 2 would be the automatic parallel parking function that some cars have level 4 and 5 or more the self-driving car that's a vision that I think is still quite a ways out but level 3 is coming very quickly and those are vehicles that can drive themselves but the software really isn't able to handle all the circumstances so the driver is still in the loop but one thing it's important about level 3 is that you need the entire sensor suite for autonomous driving at that point and so that is not very far away to get an idea of how this business is developing there's a prediction at the market for automotive or light ARS in general will be about six billion dollars by 2024 and 70 percent of that would be the automotive market another interesting number is right now in the last year this year the estimated market for lidar is about 300 million dollars and I would guess most of those are still going into automotive applications none of those are going into cars they are on the market that you or I who would purchase they're all going into software development platforms which gives you an idea of how big a challenge the software development is so the consensus is that you need a sensor fusion approach with multiple sensors that complement each other as well as providing some redundancy and the big three for the exterior of the vehicle that longer ranges our radar cameras which are basically CMOS imaging technology and lidar the radar has the advantages of being a longer range sensor immune to weather phenomena is very important but inherently a lower resolution technology because of the longer wavelengths involved cameras are very high resolution in terms of spatial resolution but they're inherently a 2d technology and for these kind of navigation applications requires a lot of signal processing after the sensor ladar is actively illuminated can operate day or night has relatively high resolution and long range and is a very low latency technology and the depth information is available very quickly there's a big cost difference the radars have come down to sort of this 50 dollar range and high-volume cameras are quite a bit less and the light ARS are still rather expensive so I want to give a quick introduction to the history of automotive lidar lidar goes all the way back to the the invention of the laser almost but in the autumn of context it's actually a fairly recent history and it started with the DARPA Grand Challenges and the first one was in 2004 it was near Barstow California out in the Mojave Desert a closed course there were no finishers of all the teams that were entered they did it again in 2005 people had done a lot of improvements on their sensors and software and there was one winner of the 2005 Grand Challenge which was an autonomous vehicle called Stanley developed at Stanford University and it actually had five industrial sort of line scan light ours on its roof as you can see but the other end another entry that was in that competition that didn't finish was from villa Dino cou sticks and David Holub belt on acoustics had built this rotating light our system that you see on the roof of the vehicle again they didn't finish but people were so impressed with the the sensor he was asked to commercialize it and make it available to other teams the next and the last DARPA Grand Challenge was in 2007 it was an urban environment and much more complex and there were six finishers five of whom had the villa dine lidar as a primary sensor system and this became more well-known to the public around 2011 when the Google cars started showing up with that feldheim lidar on the roof the light are costing quite a bit more than the car again these are software development platforms so let's take a closer look at that lidar system it's an ingenious design it actually spins 360 degrees and there's a an optical module that's a transmit assembly and there's part of it that's a receiver assembly and there are 64 hand aligned individual lasers in the transmit assembly and again 64 hand aligned photo diodes in the receiver assembly and it's real claim to fame in terms of its utility is that horizontal resolution number of less and attentive degree and as you see on the right of the screen that's what's called a point cloud that's a visual representation of the data that's collected by the lidar and that high level of resolution is why it's been sort of the gold standard for more than 12 years now to be fair to Vela dine there later offerings are much more compact that system at the bottom of the slides about 75 millimeters tall so there are critics who wonder what you really need light are and only a couple of weeks ago Elon Musk said at a investor conference that light hours of fools and or errand anyone relying on lidar is due dude and then he went on to say some more things if basically are making the real issue which is the lidar was too expensive for an early adopter like Tesla they went on ahead without it so just to give you an idea of the difference here I want to show a short video clip this is 77 gigahertz radar data it's courtesy of a company called autonomous stuff who not only engineer the software development vehicles but they develop software and this is a visualization software that's really a guide to the engineers as to what the sensor is doing and so these are the radar returns now that the size of the balls are not the real indication of the spatial resolution that's more like the spacing and they're color-coded to show Doppler information and that sign went over you saw a flash at different colors so let's compare that with a current state-of-the-art lidar this is a elster system this is a similar system to a fella dine and it's a spinning mechanically scanned lidar and you see the very high spatial information and how that would correlate very well with video data and the upper frames are the raw data feeds the lowest of the great frames being the the actual spatial or depth information so our company actually does not build wide ours we're lower in the food chain we supply illumination systems to various types of live our manufacturers we get to talk to a lot of people and one thing we noticed a couple of years ago there was a remarkable consensus around the requirements and you know assuming you're not going to have a light are on the roof of your car that's spinning 360 degrees you're going to have a long-range forward-looking light our system and then ones around this side and back of the vehicle that are much shorter range so that's that two different resolution requirements and the more challenging one of course is the long-range one 200 leaders is kind of the canonical number but we have seen some requests for even longer range out to 300 meters the autumn of environment emotive environment is very severe and one of the most difficult things is the temperature range of minus 40 225 see but the thing that surprised us was the cost expectations for that longer range light are less than $200 per unit and that was the high end some people are were saying it had to be lower than that for it to actually get widely deployed so that brings up the question will there be a lidar in every garage it won't be from lack of trying there are estimated to be about 90 startups right now developing lidar technology of different kinds on top of that all the OEMs the actual car manufacturers have their own R&D programs and most of the what are called the Tier one suppliers who do most of the real technology development for automobiles are developing their own lidar systems so almost all the industry thinks that it's necessary for autonomous driving and fortunately there's many ways to build a lidar and the race here is not really for a better lidar they're already pretty close these rotating systems do pretty good but for a good enough cheap lidar so we can classify lidar s and the two basic types flash or scanning and a flash system is basically a camera no moving parts you have a 2d detector array that defines the field of view of the system and the spatial resolution and then you need the illumination from the laser system but it's not necessarily a high brightness laser but it does need to be very high peak power because you're illuminating the entire field of view of the scene at relatively long ranges the other types of systems including these rotating ones are scanning systems and they're the spatial resolution is defined by the divergence of the laser beam in the far field and the field of view is defined by the scan angle of the system it does require a higher brightness laser system and they come in either one axis or two axis versions and the one axis version is really a line scan so you need a linear detector array as well so scanning has a lot of issues mechanical scanning of course there's weight reliability if you compare the different mechanical options the rotating systems actually look pretty good that's a very robust system that will probably be around for a while to come but almost everybody agrees that ultimately it's not going to work for wide employment there are systems based on MEMS scanning mirrors MEMS imposes some pretty severe optical constraints if you want to be vibration resistant you have to have a very small aperture and have limited scan angles any of the folded path architectures with you know more than one scanning mirror you've got a very difficult manufacturing challenge so there's a lot of work going into solid-state scanning approaches using various types of electro optical even acousto optic and other phenomenon all of those have their limitations usually having to do with the usable aperture or particularly low scan angles sometimes high loss and almost across-the-board challenges with managing extreme thermal extreme temperature ranges and then you can classify light ARS by the type of detection and almost everything out there right now is a direct detection system using a photodiode or an APD biased and the linear gain range these are pulse systems it's a direct time-of-flight measurement you need a very fast rise time pulse and your electronically measuring the time of return from the objects and your noise limits or the background light and the amplifier noise of the system and all the current scanning and flash systems based on direct detection our eye safety limited in the near-infrared range that pushes a lot of the competing designs to look at longer wavelengths and of course if you go past 1.4 microns the flu in your eye is absorbing the light and the tolerance goes up quite a bit so you can be AI safe at long range however you still use a lot of optical power and those wavelengths that pushes a lot of the designs towards dial pumps solid-state lasers or fiber lasers or fiber amplifiers and there are flash systems that's what's shown on the right of the screen that was published recently by Vox tell these are very nice high performance systems but it's a very expensive technology DPSS illumination laser and an in gas based array so the big innovation that I think is going to make a difference here is the rapid development of silicon based APD arrays sometimes called spatter arrays operating in geiger mode for photon counting this has been progressing very rapidly they're developing high resolution arrays and examples in the lower section of this slide that false color image is a 300,000 pixel spatter ray and it's operating at 940 nanometers which is a pretty expanded red response for this kind of technology and they're getting with a flash illumination out to passed 250 meters now they are very background system sensitive so that image was actually taken at night the other frame on here is from that same house tur scanning lidar that I showed the footage earlier and it has a spatter ray so it's also being that technology is also being used for scanning systems now 940 is especially interesting for silicon compatible lumination systems because there's a water absorption dip in the solar spectrum at 940 but it requires that you have a relatively narrow band pass filter and you have a laser that can stay within that band pass over these temperature ranges the other system that is being developed by many companies are our coherent detection systems and this is my simplified depiction of a coherent lidar people are building demo versions of these using telecom components at 1.55 you have all the parts you need and then you put a 2d scanning system in front and you have a very high performance lidar if coherent detection you can reject background light very efficiently you have your noise limit is basically the shot noise of the local oscillator which is part of your primary beam that gets split off and mixed on the photo detector and something I haven't talked about your immune to crosstalk from other light arms so there is concern about if everybody's driving around with the lidar and you're going to be pinging each other so for direct detection schemes there's an assumption there probably has to be some additional coating in the lidar system however the coherent detection we also requires a very high performance tunable laser diode that can do a linear chirp and has coherence links sufficient to handle the automotive ranges so how do you make this kind of system inexpensive well there's a major advance going on in the area of silicon photonics over the last few years and for coherence systems this is especially attractive because now you've got a monolithic guided wave structure that eliminates a lot of the possible issues with acoustic and thermal phase noise in the system and some of these processes are CMOS compatible they're built in eight or 12-inch silicon processing lines so you have economy of scale there's still a lot of problems to solve you need still this high performance laser currently the demonstrations that's an off ship laser there's a lot of work from the communications world on heterogeneous integration putting those ladies errs on silicon but you know if you do an optical phased array which is very practical now for this very high coherent source you end up with actually a relatively large chip with you know three five parts grafted on to it so it's still an expensive proposition and it's going to be a while I have to see how quickly this matures now there's another category that's usually not thought of in this context and that's the time of flight cameras these are based on fairly conventional CMOS imaging sensor technology the original players in this or companies like PMD and soft kinetic which got by bought by Sony Panasonic people that make digital imaging sensors and what you do is you have an integrating sensor now so you're not looking at the return pulse rise time you're integrating light with different time delays between the integration windows and from there you can do a ratio and reconstruct in a depth map of the image information so originally these designs were multiple pixel designs like shown up here in the corner so obviously you take a hit and resolution because you've got subpixels that take up more area than single pixels with the advent of global shutter cameras which are you know popular for consumer use with fast global shutter technology you can do this in a frame-by-frame fashion and have slightly different timing delays as you have a pulse laser illumination so and of course the other thing is they've migrated these two having longer infrared response so they're usable outdoors at 940 nanometers instead of the original 850 nanometer type application so they're very inexpensive and another big selling point these are multimode sensors they can do visible monochrome or igb as well as IR illuminated monochrome and the time-of-flight sensing the disadvantage is they're inherently a short short distance sensor due to limitations on the integration times so this is probably the solution to that short range light art of 10 20 30 meters out so let's say a little bit about what we do and where we fit in the food chain so we are a fabless cemeteries your company specializing in vertical cavity surface emitting lasers we have a unique proprietary flip chip bonded architecture where we can make both the anode cathode contacts on the same side of the die so we're back emitting the back of the die is electrically completely inactive so we actually fabricate in some cases micro optics sort of single micro lens per laser and that allows us to do beam shaping divergence control and also we can do addressable arrays with multiple zones here's an example this is actually now an obsolete part for us this is a 300 watt peak power we now have a 600 watt peak power with the same footprint device it's for low duty cycle running 10 nanosecond pulses specifically for flashlights our applications at 940 nanometers and it's really two devices on the same substrate these are two by two millimeter dye in this device each one has 150 lasers on it and they're connected in a row in series it's depicted down here and that's for high slope efficiency for this very low duty cycle operation and in many ways this is a can be thought of as a long-range LED with narrow line width and narrow divergence and the reason for that is there's 1500 multimode pixels all mutually incoherent and so you get a far field like this it's very low speckle very smooth illumination like you would get from an LED system and another aspect of this approach is we can engineer in ice safety because it's an extended source and using the IEC standards as you get closer to this device these sources no longer contributing to an exposure in the same area of the retina and they become effectively independent sources so you divide the problem by 10 as you get in closer and this looks like the same part but it's a completely different animal based on the same technology so this is a device optimized for those time-of-flight cameras I talked about and it's a parallel series architecture still Tendai but they're connected electrically different through the sub mount and optimized to give 100 watt output but much longer duty cycles and the 1 to 5 percent range so in conclusion I think it's highly likely that automotive light ARS will come down and cost enough to be in every vehicle and it's really improvements in silicon detection and integration that will be the key it's also likely there's not just one because of the nature of the automotive business wanting independent supply chains there's a lot of historic relations from OAM to tier 1 so they'll be competing technologies for quite some time and of course at these price points these sensors would be applied to many other applications so I've shared a number of opinions that are my own I would recommend you don't take these as investment advice because that would be a fool's errand and I'd like to thank our my colleagues at Tri Lumina and also autonomous stuff and ouster for sharing that that data [Applause] 