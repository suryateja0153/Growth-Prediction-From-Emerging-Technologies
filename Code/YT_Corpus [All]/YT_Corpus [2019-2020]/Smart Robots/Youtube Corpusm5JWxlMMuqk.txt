 Welcome to the second FIWARE webinar on robotics. This one is entitled "How to develop the FIWARE user interfaces for robots." We are going to introduce the underlying technologies and enablers to develop interfaces for robotic platforms. The agenda for today is as follows: We will start with some introductory material in which we will talk about the type of platforms we are considering robotic system, then we will introduce some concepts of this topic named "digital twin" in connection with robotic systems. Then we will focus on on the development of FIWARE NGSI robotics interfaces and how The FIWARE Generic Enablers allow their implementation and afterwards, we will go through some of the use cases that are currently going on regarding FIWARE and robotics and to conclude we will present a slide with a summary of the relevant links to the contents that we have presented. Well, when we talk about robots, it is hard to find our clear definition of "What a robot actually is". Let's say the more traditional approach is to identify a robot as a Robotic arm, an AMR or AGV, and more recently including drones, but One robotic platform with a single specific end-effector or a single specific sensor to be able to accomplish a particular task and it's also considered as a "robot" or "robotic platform" for us. Hybrid platforms in which an AGV can be combined with a robotic arm or a robotic system that relies on a Fleet of robots and it's also An interesting and robotic platform for FIWARE-based applications. Besides this, the concept which is a more controversial concept within the field of robotics is when a "robot" is seen as a distributed platform consisting of multiple sensors and actuators that may or may not be integrated or encapsulated in a in a unique hardware platform. This can also be considered a "robot". Let's move on to the concept of "Digital Twin" for a robotics application. In particular the concept of "Digital twin" aims to solve The needs of a particular robotic platform for a given use case. For instance we can have an use case, in which we want to solve or automate palletization operations and for this we can acquire palletizing robot. Regarding the palletizer itself, it is more than likely that when we acquired the palletizer, it is not only the "hardware platform" But the "hardware platform" with some kind of high-level or low-level robotics operating system or real-time controller, high performance middleware or something like this that allows us to interact properly with the hardware. Besides this part (of the software  attached to the robot) It is also typical that Robot manufacturers like AGV or KuKa or Universal robots provide us with some kind of high-level framework or programming suite that allows us to let's say Derive value from the robotic application which is providing us with some features for HMI implementations, simulations, virtual reality, augmented reality etc. However, when we face the actual problem in the real world often the default Solutions are not enough to cover the requirements of the real use case. As we start to move up Focusing on the on the software part of the robotic application we start to build a digital entity around the robotic application that aims to support all the use cases. We are building around the robotic application this concept of of having a digital representation of the physical element is named after the concept of "digital twin". To deploy digital twin features often these robotic platforms tend to offer a Base API or real time API which operates at a low level. This offers limited usable functionality, or let's say APIs that require expertise in robotics or in software development and then a high level API that is connected to this programming suite and provides a more user-friendly abstraction for the development of these twin features. Today we will focus on how these "digital twin" features can be powered by FIWARE solution architectures or particular enablers and also on how the interfaces to interact with the real-time API and the high level API can be created. Let's use this insights from the industry internet consulting about "digital twins" to contextualize our vision regarding these digital twins. Paying attention to the left part of the slide, contextually they present this digital twin for sensors actuators or robotic systems as an analogy to an object in object oriented programming. They say that the digital twin accounts for data for Computational models and services in the same way that an object accounts for members data methods and interfaces. You can see also different aspects the services can Provide value Descriptive features, diagnostic predictive maintenance, predict restrictive maintenance, visualization, augmented reality, even asset management and then the type of computational models can be very heterogeneous as well as the data and derived from them. On the right of the slide, we have two interesting aspects the "digital twin" is presented as a Multi environment Digital entity that can exist very close to the hardware and operating it in real time this also includes edge deployment but also in the cloud and Even in the cloud we can account for online features that are able to communicate to send commands to the real-time features of the digital twin and also offline features that allow us to process some data offline, acquire some knowledge, and then update the configuration of the asset. At the bottom on the right we have this concept of the composability and compositionality of the digital twin. Meaning these that we can not only focus on developing Complete digital twin for the robotic system But we can start developing building blocks - digital twins for its sensors and actuators. And they'll build a complete structure that will represent our overall robotic system. We can even go further, and group our composite digital twins and build the digital twin of our application In order to complete our base for the design of the digital twin for robotics We must also reference the concept of asset administration shell in industry 4.0 which tries to provide the meta information model for the digital twin and its API. in particular this asset administrative shell introduces the concept of a header that through URL or URI allows us to identify the asset - in this case the robotic system with a particular ID and then all the data and functionality is grouped in submodels. Each submodel is associated with a particular domain or relevant functionality of the robotic system. Our means to implement this digital twin concept are firstly NGSI-LD which is the latest FIWARE specification NGSI v2 which is the previous one. The the operations that this is specification Allow us to implement and the data models that can be implemented according to the NGSI-LD or NGSI v2 principles. Here I show on screen the links to the relevant getting started tutorial for for these specifications and I want also to comment that the Wednesday webinar "Introduction to NGSI-LD" is coming soon. So please be be aware and join the presentation. Here we have an example of an NGSI data model for a Robot submodel in particular we can map data. We are mapping here the geometric message from ROS that allows us to model the pose of the robot. If you see we can reference under  the provided JSON-LD @context a URL where We can provide the definition of all the context of the robot. We can also provide definitions for What the attributes are etc then we have the ID which will be uniquely referencing the Robot's digital twin, and then we will have the type of the data that it will be a stored. This is just a very basic example, and in the next robotics webinar we will be focusing on how these models are encoded and how the interfaces operate on them. The other key Block for us is our reference architecture  and it's generic enablers. Here This holistic view of the system of system approach in FIWARE allows us to identify many aspects of the digital twin. if you look on the left of the slide and also at the bottom, we have all the components that Rely on the processing units or or a physical assets. Then we have an acquisition layer for the agents, with IoT agents, real-time media  processors for camera and on the right-hand side, we have the particular agents that are focused on the robotics domain then we'll have the contest broker which is the layer that Implements the digital twin based on NGSI entities and then we start going up to the smart services Region at the top the implementation of smart solutions to solve a particular use case To conclude the first part of the webinar and I rely on this On this contribution of the most projects in which a separation between levels and constraints for the definition of robotic systems on these cases is given in particular As you can see an example with the blue arrow a blue arrow is an architectural pattern that defines how your system or which are the Concerns the concerns and levels that are actually associated with your system in particular currently the scope of FIWARE NGSI features is mainly aimed at dealing with missions, task plots, skills and services communication, coordination and configuration. If you look on the left side you have an example. This part is more focused on the high level interaction with the robot and then we have at the functional level an example like the inverse kinematics solver or some low level function that are closer to the real time. This part is Not at this moment the best alternative to operate through NGSI because the context broker only supports A REST binding to implement the API.  We will show some slides later an Approach that allows us to deal with the function use case But if we say which is the default role of NGSI in robotics applications, it will be related to services, skills task plots and missions. Let's focus now on the base technologies that allow us to implement FIWARE NGSI robotics interfaces Here is the mapping of the key enablers in FIWARE for robotics as I mentioned before the Orion context broker is our digital twin layer, that stores the digital representation  of every asset as an NGSI entity and then on top of the Orion context broker we can use high-level enablers for data services that Implement smart applications to solve a particular use case, but putting the focus on the lower part we are presenting the key technologies that enable our developer to implement FIWARE interfaces from left to right we have on the one hand  the OPC-UA IoT agent and OPC-UA is a very well known communication protocol for industrial robotics, then we have for the ROS ecosystem the FIROS component which Allows the implementation of interfaces  for ROS1-based robots, and then we have a third component which is called SOSS-FIWARE which is still under development and is continuously evolving, but the first version is ready. This component allows us to implement FIWARE NGSI interfaces for ROS2 architectures. These three enablers play the role of Integration agents, but FIWARE  is not limited to this layer FIWARE is also involved in the development of Core robotics technologies and in particular eProsima, one of the gold members of the FIWARE Foundation offers two specific products that implements DDS. DDS is a well known specification for Industrial communication protocols it is suitable to implement real-time middleware filters and Fast-RTPS and micro-XRCE DDS are components that belong in the FIWARE catalogue they are recognized as Enablers the difference between Fast-RTPS and micro-XRCE DDS is that micro-XRCE DDS deals with extremely resource constrained environments which means IoT devices and Microcontrollers that operates on top of real-time operating systems can Leverage on micro-XRCE DDS to  implement the DDS middleware. Let's focus on the fourth type of interfaces - ROS1. We must say that these interfaces should be considered high level. That is they are not Particularly designed for real-time operations. In ROS, the main interface is supported by ROS are topics, services and actions. And the  element in ROS architectures that offers these interfaces is typically a ROS node. At the moment, the FIROS component  offers interfaces based on the publish/subscribe mechanism that ROS topics offer. We are still lacking interfaces for services or actions But as I said, all the agents are continuously evolving. We will work on preparing the interfaces for this additional ROS features. And on the right side you have the links to the github for FIROS and also for the demo they Provide based on the turtle sim, which is a well-known demonstrator in the ROS ecosystem. Then if we focus on ROS2 - and we have the SOSS-FIWARE component, which plays the same role in ROS2 That FIROS does in ROS1, and here if you pay attention to the ROS2 main interfaces I Have a started the concept of topics and services and actions they play Practically the same role in ROS1 but they are not totally equivalent.  I have just added this note, and just to be sure that if you are interested in knowing more about topics, services and actions you should take care about the particular platform you are going to use  if it is either ROS1 or ROS2. Then the next type of interface is OPC-UA. It relies on the OPC-UA IoT Agent enabler. OPC-UA offers different interfaces for the discovery, subscription, query and node management. This architecture is starting to support publish/subscribe, but in general relies on a client-server architecture in which the OPC-UA server, the Gateway sets the interfaces for the hardware platform and different clients operate on these different interfaces. But Since we also can account for Fast-RTPS and micro-XRCE DDS, we are not just limited to the ROS or OPC-UA ecosystems. The straightforward mechanism to interact with Fast-RTPS or micro-XRCE DDS for now, is through the frameworks that provide ROS2 or Micro-ROS which we will talk more about this in a few minutes. But we can also think in Developing some bindings to start operating just on top of Fast-RTPS and micro-XRCE DDS and this is connected or associated with the current approach to Implement use cases that require a real-time solution. For instance in this view We have the concept of distributors to a robotic platform that maybe we need to synchronize and coordinate in real-time to follow a particular use case. Well, in this case a component that leverages on top of Fast-RTPS or micro-XRCE DDS can take care of the real-time middleware. They additionally, in order to integrate our solution with the REST binding of the context broker, it is necessary is to develop a smart agent with a FIWARE NGSI interface or a ROS-based  architecture or a tailored NGSI connector that Exports an API to operate at the high level so you can encapsulate Your logic for the real time in this component you can build on top of the Fast-RTPS or micro-XRCE DDS middleware and you can enjoy the benefits of having the digital twin in the context broker using the NGSI API. But we are not stopping here. In the FIWARE roadmap, we want to get closer and closer to the real-time operation of robotic systems. Our working group in which FIWARE Foundation members like: TIS, Fraunhofer IMF , eProsima, Engineering ATOS and NEC are working together to define the roadmap of FIWARE in robotics and in particular a working group has been assigned with the task to start with the definition and development of specific bindings to directly communicate OPC-UA architectures on DDS architectures with the Orion context broker, So in the future the Map I presented at the start of this section Will look like this - we will have our multiple robotic systems with heterogeneous low level operating systems and then we will be able to build on top of this ROS-based architectures, OPC-UA architectures, DDS ROS2 microROS architectures and we will have the alternatives to implement NGSI RESTful API based on the OPC-UA IoT agent, FIROS or SOSS-FIWARE and also direct bindings with the OPC-UA binding on DDS bound systems. One more thing that I want to mention here is the proposed approach to the integration of real-time features. In the short term we are working on the development of a new feature in NGSI-LD that will allow the Integration of raw data streams using the RESTful api so this will increase the performance of the communications  and the number of use cases that can be implemented using the traditional NGSI API will increased substantially. The third part of the webinar, the concluding part is going to show some of the use cases we are dealing with at this moment and within the robotic domain the first one is the concept of Industrial robotic systems for agile production. Agile production defined as is part of industrie 4.0 or the smart industry concept and in particular It has a focus on the usage of robotic systems to provide the industrial automation with extremely flexible automation skills and Proactivity It is this is especially needed Nowadays because The market in the industry is changing a lot they are moving from large mass production runs to highly customized products in a small sizes batches. In order to deal with these sudden  changes on the production line, the integration between all the levels in the factory even across the whole enterprise is needed. Through our "digital twins", we are aiming at covering all the requirements that factories have. The FIWARE Foundation, within the DIH squared project is mainly focused on the development of Interfacing features for the "physical" part of factories within the overall context, that is we are focusing on enhancing robotic platforms to be able to communicate with each other but also to integrate advanced features for planning, for monitoring and the robot operation, for convenient setup and supervisory control of the high-level features we are dealing with all of these structures and connecting it with the verticals in the factory and With other stakeholders that belong to the supply chain In particular the map that I have presented in the previous section is positioned between the native robotic platform API and the agile production maneuvers That will be implemented in multiple experiments that will be  funded during the DIH Squared project. On the right side. I summarize how our vision tries to enhance this interoperability on the implementation of advanced services based on the semantics of the context data that defines the production environment. And this type of context data ranges from the modeling of factory resources up to and including the modeling of human roles on the factory floor and putting particular focus on the robotic part modeling which are the robot tasks the robotic skills, which are the primitives, the functions, the states, the functional or quality parameters that allows us to model the "digital twin" and to define the scope of the use cases that can be solved with the enhanced system Here I am showing a deployment for these interfaces and in this example, we can have a factory in which multiple workstations can be integrated using the interfaces we have presented, then we will have the "digital twin" stored in the context broker. Additional platform services based on the implementation of Multiple applications to solve the different use cases and the Strategic point here Is that everything communicates using the same API. Building upon the NGSI specification. Before we skip it, I have highlighted here on the right the typical use cases for a smart factories and based on these platform capabilities and the development, The amount of customization needed to support each of these use cases should be significantly reduced. Evolving this idea. If someone deals with a particular Requirement in real time that cannot be covered by the NGSI enablers or by their first architecture I have shown It is also acceptable And for now it is the recommended alternative architecture to have an second processing unit that deals with the real-time features of the use case. This can provide the necessary communication mechanism and then it can provide the convenient interface to Operate with the digital twin. One important thing regarding this concept of the digital twin is that It should be understood just as this - as a concept that Comes to help and support the development and the implementation materialization of solutions for a given use case. Certainly, you can say "Ok, this digital twin concept is not suitable for real-time features" Ok, that's right. But in the end, what do you need is to Envision how your whole structure is able to meet the requirements you have. Then you will find a particular digital twin concept that acts as the glue for all the components to interact. The second use case we have is associated with a particular facet of the Smart factory use case and it is connected with the concept of smart warehousing and intralogistics based on AMRs. in this line the team from TIS in Japan is working on a very ambitious use case for smart warehousing and they are doing a very good job in the development and design of data models as building blocks to compose Complex instructors for modeling robotic systems. They already have a demo at the Laboratory level, let's say TRL number four They are evolving it Currently contributing to the robotics working group with their developments and on the right of the slide I'm showcasing part of the developments that Fraunhofer IML is carrying out In particular in connection with FIWARE and the FIROS component. They have participated in the L4MS initiative Which is focused on this particular use case Then the third use case I want to bring here is this concept of micro ROS which puts ROS2 on to micro controllers. In micro ROS, which is the a framework that comes from the development activities carried under the umbrella of a European funded project The only stack that it is necessary to implement ROS features in are microcontrollers that are lacking of an operating system, like for instance, Linux or Windows which are prerequisites to operate using ROS2. These are being developed in a particular stack and this stack is interoperable with ROS2  totally and fully integrated. You are heavily encouraged to visit the microROS web page. We have shared the address before I will show it again in the final slide. Because if you are dealing with real-time with microcontrollers with Extremely resource constrained environments, micro-ROS will offer what you need. Specifically, implementations of standardized solutions that in some way Avoids the need for continuously  re-implementating ad-hoc features. At the moment the integration with FIWARE In micro-ROS2 architectures relies on the usage of the SOSS-FIWARE component in combination with the ROS2 agent - that is the microROS agent, that lives in the ROS2 side of the stack. Here I'm showing you one of the demos that have been materialized in the under the umbrella of the MicroROS project and here one demo from eProsima shows a particular resource constrained drone platform - the crazy fly interacting with the visualization tools that ROS2 offers Additionally, This use case has been integrated with an older use case that is being developed by Bosch in which micro-ROS is empowering the second version of the turtle board the Kabuki platform to avoid the usage of larger processing units. What you see in the video is how micro-ROS with the light in small client allows the user to control the Kabuki Using the IMUs of the of the drone and at the same time providing information about the sensors and the geometry to the ROS2 environment. These frameworks both micro-ROS and ROS2 environments are empowered by the FIWARE enablers. In the micro ROS part we have micro XRCE-DDS empowering the micro controllers with the externally resource-constrained environment middleware for DDS and on ROS2 we have Fast-RTPS, which is the default implementation That allows the ROS2 environment to operate. To conclude here you have the summary slide, in which I am showing you that if you are implementing interfaces for ROS1 Robotics architectures, you should rely on FIROS and here you have the links to the code and to the example of FIROS and if you are relying on ROS2 architectures, you should use SOSS-FIWARE to implement your agent and integrate with the digital twin in the contract broker. Similarly, if your system is based on OPC-UA it is suggested you use the OPC-UA IoT agent. You also have alternatives to implement DDS interfaces by implementing a component or a real-time service that relies on Fast-RTPS or micro-XRCE DDS middleware plus an NGSI compliant agent that exports the high-level API. Then summarizing for microcontrollers we have the microROS frameworks (and here you have the links) To conclude you always have the alternative of implementing a tailor-made NGSI-Robot interface using the native robot interface plus the Library that is available to implement custom IoT agents or you can implement the NGSI connector yourself that solves your specific use case. At this moment, all of them will exploit the NGSI RESTful binding. The final thing to mention is that a further set of interfaces that are planned for robotics including NGSI-LD features for raw data streams, which is part of the short-term roadmap and the implementation of direct bindings  for DDS and OPC UA interfaces, which will require more time But we will provide you with information as soon as we have  An approximate timeline for this feature. Thank you very much for listening  and that was all from me for now. After this presentation, I'm open to questions or to discussion with you 