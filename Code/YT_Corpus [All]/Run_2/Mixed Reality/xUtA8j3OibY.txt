 hey everybody welcome we're gonna get started this is our talks a technical deep dive into a our recent application solutions showcase for mixed reality this is a holographic experience my name is Caleb cannon and this is my colleague Allie a cap yellow we're part of object theory mm-hmm this is our team as the old photo not everybody's in there but most of the crew is in there and they're all very nice people yeah we're a full-service shop we offer services from strategy design and through development and for this project we're fortunate to filter across the spectrum in partnership with Microsoft our roots are in Hollands development I forgot to mention we are 100% focused on Holland's development as a development agency in Portland Oregon one of our founders was a tech lead with Microsoft on some of these projects here including Maya Trimble the Autodesk in NASA JPL projects since then we've completed over 20 projects some of which are pictured here we're very fortunate to have worked with several fortune 500 companies and many others some of these are standalone holographic experiences some are integrations with existing applications and services like azor desktop applications and IOT devices here's our agenda Ally's gonna briefly overview the application and we've broken it out into three main topical areas guest presenters and creators those are our three user groups and also the three main functional areas of the application all right thanks Caleb to get started I'm going to tell you a bit more about the application and some of its key features so what is it the solutions showcase for mixed reality is a holographic presentation tool that supports co-located shared experiences across multiple platform including hololens and iOS enables presenters to quickly build a custom mixed reality experience in any room we also provide a coatless api for 3rd card party content creators that works within this framework and offer a distribution platform for sharing content both publicly and privately and who is it for so as this application evolved so did our audience there are a wide variety of people in various roles who could use this application Microsoft sales reps retail center employees partner companies with existing hololens solutions and enterprise customers who want to learn more about solutions that are relevant to them in their business so with all this in mind how did we create an application that supports all of these needs well after taking some time to think about it we were able to consolidate this down into three key audiences first there are creators these are companies like us object theory or Trimble who create content for the framework then there are presenters such as employees at the Microsoft retail centers that then use that content to build an experience for guests and guests are the end users the customers who actually experience that content and experience the demo each of these audiences has unique needs and goals that we needed to design for so today we're going to touch on our learnings while building features for these three key audiences first this is a quick video walkthrough of some of the primary user flows in action so right now I just uploaded some content that was created using the SDK to the Creator portal which we'll touch on in more detail later then unable to go into the hololens application and add that content that i just uploaded to the portal directly into my scene here and meanwhile it is downloading from the cloud this is the same bit of content that you just saw me upload i'm able to then as a presenter position and move that in the room and then i can use something that we like to call prompts which can help guide users where to look and where to stand in the experience so you just saw me create a very simple experience I'm going ahead and starting it so now I'm in the mode that your guests will see so now I'm actually experiencing the demo that I made as a presenter and there's my content so there's two types of content that we'll be talking about today in the application the first one we call scenarios and that's really what contains all of the content for the demos these are made by creators and used by presenters to basically create these experiences for the guests the scenarios contain all the content for the demo so there's 3d models interaction sounds videos and much more and then you can basically string a few of these scenarios together to tell one narrative experience then we also have prompts you saw me add one in there before that was called an air tap here and these really help presenters create an experience to get the guests to stand in the optimal view point or look in the correct direction to then experience that content and we'll touch on that more in the next section which is talking about the guests so guests are customers or people who are interested in learning about real world applications of mixed reality if you tried the solutions showcase demo out over by the lounge then you were seeing just the guest experience of it and that experience is all about storytelling in 3d space so guests need to be able to view and interact with content and learn about business solutions for hololens and with the recent addition of our iOS app even more people can enjoy enjoy the mixed reality experience today for guests I'm gonna focus on a specific design challenge which was helping people navigate in 3d space with limited assistance and this can often be a challenge for new hololens users and after buildings you know several of these storytelling applications for hololens we learned a bit about how to do this more effectively and have some recommendations for you if you're interested in telling your own stories in 3d alright so we've touched on this a little bit the prompts to basically to have the best experience in mixed reality you always need to design with 360 degree content in mind the next scenario made them be behind you or even around the corner in another room so how do we guide guests to the optimal place to view that content so we created something called prompts and it shows guests where to stand or where to look in the experience and as you can see here we also provide progressive feedback to reinforce that guests are doing the right thing as they're moving towards it so as you get closer there's a color change you can't hear it but the sound changes gets louder and then you finally see a particle effect so in addition to this being a really useful tool it's also a bit of a magical moment in mixed reality in addition we also use spatial sound to help guests navigate since the hololens has amazing 360-degree sound and you can hear in 3d space just like you do in the real world sound is an extremely helpful cue for grabbing attention and providing context so we use spatial sounds often and anchor them to 3d objects for rich immersive environments for example you can anchor the engine sound to a holographic car and as people move closer it's just as if they are moving closer in the real world and for navigation the prompts use a radiating looping sound so as you get closer you know you're heading towards the right thing and within the scenarios itself we also use spatial sound to draw attention to new or changed content in the scene so we always recommend using sort of these directional audio cues to help reinforce the visual cues that you're providing in the experience alright lastly we use attention directors to ensure that the guests are never fully lost in mixed reality it can be very disorienting in a mixed reality experience when nothing shows up in the field of view so attention directors our best practice to help draw guests attention to the next piece of content one specific learning that we had as a result of creating many of these self-guided demos for large tradeshow events is that the words look left and looked right often didn't help people find content that was on the other side of the room or directly behind them so we actually opted to use the words turn to the left or turn to the right and found that that would actually encourage people to turn their entire bodies and eat more easily find the next content a few other quick tips for 3d storytelling if you're interested in getting involved we recommend that you create a separate setup mode so that guests don't really see behind the curtain I kind of like to think of it as Wizard of Oz you want them to see the magic that you've created for them but not see how it was made we also use you know use sound to bring everything to life so use voiceover narration background music and additional sound effects to create that rich immersive environment and then we also recommend for self-guided experiences that you use timeouts for gesture interactions to make sure there are no bottlenecks in the experience and even if guests don't quite get some of the gestures yet they're able to complete it and experience the full story now let's talk a bit about presenters so if you again if you tried out the demo over at the solution showcase area around the corner here the person who helped you get set up and was walking you through the experience was the presenter so they're the ones who you know select what content you're going to use place it in the room and then start that experience for the guests the primary goal is to be able to create this new demo in a very easily and quickly so that it works in any space that you might come to and need to do a demo at the main hub for the presenters work is called the build your experience menu from here you can view and select content you can download that from the cloud you can change settings load a saved experience that you created previously and then actually go ahead and start that experience for your guests and when you go and select content from the build your experience menu we built in two different levels of placement to make it easier and faster for presenters to place things in their environment so the first step is a gaze to place it'll be initially locked to your gaze so when you look around that allows you to very quickly get the content into the general area in the room instead of having to drag it or rotate or move it all the way around to get over there and then the second piece allows you to make some of those micro adjustments where you're able to use the gesture interactions with six degrees of freedom to move and rotate your content into the exact place that you want and another important design challenge that we found for presenters was figuring out how do we show the order of the content in this 3d space and how do we allow people to reorder that content as well so they can modify their experience on the fly so we decided to place the order number quite largely on top of each of the calibration props that you're seeing here and those numbers billboard to face you so that no matter where you're standing in the room you can quickly look around and get a good feel for what your order is we also then reinforce that with a visualization of the flow through the different pieces you can see there's an animated line that connects them in the order and this allows you to very quickly and easily you know make a change see that order update and just get a really good sense of how your experience is gonna flow through the 3d space we also let people remove an object or lock it into place to prevent from moving accidentally while they're adjusting other objects in a Dishman in addition to the placement methods that we discussed before we also make use of the spatial understanding capabilities of hololens to better align objects to specific surfaces in the room so objects will snap to a floor or wall or table while placing and this isn't really important because proper alignment to services helps ground objects and mixed reality in addition it lets us sort of build in recommendations for how the content should be placed in the space and spatial mapping is also crucial for building effective shared experiences so I'm gonna pass it back over to Caleb to tell you more so when we're putting this together unfortunately I didn't get a good capture of our spatial mapping setup process but it is one of the important functions of this application like you saw in the previous slide you know we use spatial mapping pretty heavily in the application we use it in multiple ways in fact during the initial placement we do a snap to surface kind of behavior and here we have a different mode which is a gaze based placement the key difference between those two modes is that in the first one the raycast are coming from the center of the object in this case they're coming from the user's origin and the takeaway is that both of these are actually pretty useful when you're creating an application tribal what is gonna feel better for your particular use case or it might be a user preference there is a so a more passive but but very very important part of spatial mapping particularly for an application like this is that we use world anchors very heavily in the application and to use world anchors effectively your users have to create a good spatial map of the environment so you want to make sure that you give them good indicators of how much of the volume they scanned and where the where the gaps are why do we use world anchors so much they're very important for three main reasons here what is it they're used for stability in recovery if you if your device loses tracking for any reason or if you walk all the way across the room and come back any object with a world anchor attached to it is much more likely to stay where it's supposed to be we also use them for saving and loading layouts without the world anchors it would be impossible to create this application we couldn't save a disk save to disk or load from disk which reminds me why I should mention for those who are new a world anchor is essentially a position in real space and the world anchor is way we save that position to disk so that when you start to haul ends back up it knows where to put that hologram physically and finally we use world anchors for shared experiences and I want to point out that this app is a fully functional shared experience in that we have a to multi user modes and this is kind of how we set that up for the for the anchors we do a simple export we get an object called a world anchor batch and the key takeaway here is that we use an HTTP server to transfer the anchors this is probably one of the dumbest pieces of code I've ever written in my life this is HTTP server it has one job you open a socket on port 80 it starts sending that file the reason we did that is that on the client side it allowed us to use the existing download our party unity or uwp those download handlers are very functional they come complete with error correcting sake control delegate methods feedback the ability to resume things like that so on the client side it was very very easy for us to bring these anchors in now start the import process and then have a multi-user shared experience and this code also allowed us a lot of flexibility we can put those anchors on the cloud somewhere or on some server in the middle or deliver them directly from the device like you see in this image here now we're gonna move on to creators this is where we're gonna get a little more tech heavy when we started this project we knew that we needed to provide some certain level of functionality we had one major major constraint which is that to deliver this content down from a web portal somewhere we couldn't allow any third party developers to write any custom code for the application what that means is that internally we had to create components for unity that would allow a developer to do basically anything they needed so part of that is the creator portal like I mentioned and you saw earlier this is a pretty simple CMS that we built on Azure users login they upload their content then they create something that we call a showcase that's what these check boxes are about as a presenter you log in to a portal you're able to access the items in your showcase and those taught that content may be private to your organization or it may be public content that some more other organization created and shared we login with a QR code there's a particularly good reason we did this the alternative we looked at was assisted device login which is a very good mechanism for Hollens login and azure has a very nice package for set however what we wanted was the ability for a single presenter to authenticate multiple devices very quickly without any sort of user interaction that's what we got by using this QR code here so as I said for the SDK we had to provide a lot of functionality freezers without making them write any code and the way we did that was by creating a whole bunch of unity components the devs can kind of drop into their scenario or their content module and hook up in ways that you know gives them a lot of functionality like interactivity and the kinds of things you would traditionally do in code we did work in an interesting way on this project we we siloed our teams so to eat our own dog food so to speak we set up a dev team to work on the framework of the application and a design team to work on the initial content modules they would say okay we need a component to do this the developers would then create it and pass it over but by setting it up in a silo like that we were able to ensure that we didn't cheat and that we were actually covering all of the bases producing things that third-party developers would need as we were working on this I found that the components were starting to fall into a few categories very naturally the first one here is we call triggers and triggers are very important these are how we get interaction into the content modules we have triggers for things like air tap for gazing at an object for moving to a particular location and the way we expose the hook-up is through unity events and these are very simple to use what I'm doing here in this animation is adding a input trigger for an air tap to an object that's essentially going to turn that object off when you give it an air tap likewise in the sidebar the user air taps on that button that triggers an animation on the forklift to play in the background we also developed a lot of modifiers we call modifiers because they're more passive than triggers modifiers tend to work on on an able or on disable when they are activated they really tend to modify the behavior of the application itself so in this case I have a bunch of cursor modifiers that are activating when I gaze at those different objects we also have modifiers for things like background music and one of my favorites is the position modifier when you take a hand draggable start moving it around but attach a position modifier for snap to walls for example you get a snapping behavior when you get close to one of those surfaces identified in spatial understanding modifiers are also ridiculously easy to hook up here's me adding a cursor modifier to a gaze object to a game object that as you saw in the previous slide when I gaze at those objects it's gonna change the cursor to a red dot or a blue square that's how I did it was just this one second step here then we have to catch all other tools and I wanted to point this out specifically because in these content modules you do have access to a lot of existing stuff that we didn't even create for example the timelines and unity a lot of the stuff in the holo toolkit and a lot of other stuff that we created specifically to work with those modifiers for example changing materials so now we're going to do an end to end of the SDK in action and what I'm gonna do is starting from scratch create a new content module upload it to the portal download it to a hololens and view it in a shared experience without writing any code and without starting Visual Studio or deploying to hololens or anything like that to create this the only thing I brought into the SDK at this point was the raw assets there's a tire and some textures and an icon those are the only things I brought in and to prove to myself that this actually worked I set up a timer so this is running at an accelerated rate but it is it is literally going to take about four minutes for me to create this module with some interaction via that start rotation button and there's also a stop rotation button and some animation using one of those tools that I talked about so I've actually finished here took about three minutes and thirty seconds and I'm gonna start the build and the bill took longer than the actual creation you can see the time is gonna jump to seven minutes right about now when this finishes building unity is going to pop open a folder with the build results and I'm just going to zip this content up give it a nice name and pop over to the Creator portal where I'm already logged in but I can hit submit content select that zip that I just created in a way it goes and in just a few seconds here this is going to be available publicly via the application I'm going to add it to my showcase pop over to the QR code and and that's it we're done so now we're gonna pop over to the running hololens application now unfortunately I couldn't get a scan of the QR code scanning process because MRC doesn't work while the camera is active but I logged in and there was my content so I started downloading it and those last few bytes are always excruciating yeah right about now and I can start the experience save my layout and here comes that content and I can hit that start rotation button there's some animation now I can hit stop rotation and that was it that took a grand total about 10 minutes to actually get it on the portal and that content has all of the richness of the framework including the shared experiences the arca support for tablets and the saving and loading and the easy layout and everything else alright so quick summary here here are a couple of the key points we're running a little low on time so I'm not going to hit all of them but you know just remember to identify your audience make navigation in 3d space a priority make sure to build your application to be flexible and work in a wide variety of physical spaces really take advantage of all those unique features of hololens when creating your experiences learn the world the anchor system inside and out as Caleb discussed and code for today but designed for tomorrow we also have several other topics that are related to this application that we didn't get a chance to cover in detail so if you're interested in any of these come find us after this and we're happy to chat about it alright and with that from me Caleb and all of us at object theory thank you so much for joining us today and learning about how we built the solution showcase for mixed reality if you haven't had a chance to check out the demo yet we recommend you go over around the corner here and get a demo and enjoy the rest of bill thank you [Applause] 