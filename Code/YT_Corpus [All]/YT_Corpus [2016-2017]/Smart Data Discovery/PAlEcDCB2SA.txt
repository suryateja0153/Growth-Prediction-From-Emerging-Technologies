 well it's my pleasure to welcome you to this special Johns Hopkins Bloomberg School of Public Health Centennial lecture I'm Karen Van Dien Roach I'm the chair of the department of biostatistics and it's our great pleasure to host this event as you know we've been having a lot of fun looking back in our history as part of the Centennial but one of the most important aspects of the Centennial is really to look forward and then data science is emerging as an enormous ly important facet of the future of biostatistics and of all of Public Health in that spirit I'm tremendously pleased to welcome dr. Philip Bourne who's the associate director of data science the National Institutes of Health by way of a very brief introduction dr. Bourne came to the NIH from the University of California at San Diego where he was the associate vice chancellor for innovation in industry alliances of the office of research affairs and also professor in the department of pharmacology in the Scotts School of Pharmacy and Pharmaceutical Sciences he was trained as a physical chemist he obtained his PhD from the Flinders University in South Australia and his professional interests focus on the derivation of relevant health outcomes using algorithms data mining text mining machine learning metal languages biological databases health outcomes using algorithms and visualization he's published over 300 scientific articles and five books and these address problems as diverse as systems pharmacology evolution cell signaling apoptosis and immunology just to name a few he also is extremely committed to furthering the free dissemination of science through new models of publishing and better integration and subsequent dissemination of data and results as the director of data science at NIH dr. Boren leads the big data to knowledge or bd2k initiative the NIH director Francis Collins has characterized this program as quote an NIH wide priority initiative to take better advantage of the exponential growth of biomedical research datasets close quote I encourage you to visit the bd2k website to see how very impressive a program bd2k has become sponsoring research centers of excellence training initiatives consortium to promote the improved sharing of biomedical data as well as targeted software development dr. Bourne we look forward to hearing the thoughts you've prepared for us today let's go ahead and welcome dr. born of Johns Hopkins thanks very much and good afternoon everyone let me sort of jump straight into this first of all I should say you can't be an open science advocate without actually posting all your slides in somewhere so these slides are on SlideShare should you wish to have them at a later date in fact as I was saying earlier on there are quite a lot of presentations quite like this so there I used to we used to say in research I would never use say and the same things twice now I just say one thing over and over again so this is it more or less with a few new pieces and bits and pieces so just to I think it's always important when I what I'm going to tell you comes with a certain bias and that bias of course is my own background which you you've sort of heard about already so I won't actually go into that but there is a certain bias there I think it's important to sort of set the stage for where we've come from and where we're going at least from the perspective that I'm trying to bring to the NIH and I think that's shared at some level at the NIH and you know in the sense the talking about data science and big data is really just in some ways the same words for things that have already happened that were described by different words such as the emergence of bioinformatics the emergence of computational biology the emergence of systems biology so I think it's really worth looking back at that history to get a sense of where we're going and I have to say that what I'm going to say here is perhaps towards the end a little controversial but what was interesting is I actually used the same slide to walk to the advisory groups the NIH director which is sort of the leading oversight body at the NIH and no one disagreed with what I had to say so we'll see whether you disagree so it's the basic idea we started as a discipline and when I the time I was started doing this we were really weird we were these weird outliers that folks who took small amounts of data sequence data DNA sequences protein sequences and tried to do various things with them with the computer or we're trying to model proteins and doing all sorts of things and that really you know I think everything at that point was kind of experiment then we got to a point where things became more experimentally driven and what we did as computational folks and I think a leading point of that was the emergence of the human genome project I think that helped create with certainly what brought me to be standing here today and I think it in fact influenced a lot of what happened subsequently and it's the basic idea that what they said when they started that project is this so they created a series of centers to do the genetic and physical mapping and I was involved at Columbia University with the center looking at chromosome 13 and but they what was the NIH directed was that this is not going forward without proper data first of all data sharing which came from the bermuda record but also that that there has to be people not only you maintain the data but it are an integral part of the activity and I think that was what began a sea change and so people as bioinformaticians started to emerge and then what happened is people got really excited about the promise of the human genome which I also worry about by the way for big big data because it turned out to be quite oversold so half of the people at that time including myself they were taught calling themselves bioinformaticians moved it over to the private sector which suddenly gave a mode by all of this and what it could mean for health care and drug discovery and so forth and then about working on the timeframes the industry work on for years and not a great deal happen all these people were back on the street or many of them and essentially we went through this phase where we emerged we were oversold and then we became I think to some extent a service so traditional labs if you like looked upon the pill that the the guy or gal who did computing that's kind of a service provider to that organization to that to that lab or bigger organization and I think only today perhaps for the last few years because now you can become a tenured professor and you know doing computational biology or systems biology we came a real partner in the enterprise and that's you know that's history going forward and I don't know how long it's going to take but my sense is that within the next few years people who are cross-trained who who actually do analytical work as well as generate their own data perhaps but not necessarily they are going to be the major drivers of discovery and biomedical research and healthcare and you know that remains to be seen but that's at least my prediction so I think the room partly what it's also worth looking at it from the point of view the Remora material we had to deal with so I think starting off there was a limited amount of data in fact you know people who were really at the forefront of this people like colleagues like well-known evolutionary biologists they used to work with at UCSD Russ Doolittle I mean they used to first do the experiments to generate you know the sequences one one amino acid or one base at a time and then do some computer analysis of it you know it's it's just completely now the date of course you know endless streams of next generation sequencing data and then I think that we had limited and then as we got more data we started doing things to actually describe that day to represent that days from better ways which of course is important so and so ontology came into it came into some degree of fashion and I you know my standard joke is I could stand in front of an audience like this and talk about if I did this 10 years ago and I talked about ontology as I put you to sleep in like one minute now it takes ten minutes before you fall asleep so you know I think there's a remain estranged research enterprise even if their people are not necessarily doing it but they they see it is important and then I think another aspect of pretty much where we are today and I have to say in many ways the NIH has created or is one of the agencies has helped create this situation but we're in this position where the data is very siloed so we actually we we created we funded a projects it created a data resource that data resource exists and it's used but and that was fine when the majority of the research we did was on one or two or a small number of data types now what happens in a translational sense we're all over the place we're using data from everywhere and it's become I think my personal view a real problem because it slows us down because what even as as much as I'm against much of the the way journals operate the fact is that they do have a common interface there's an abstract there's an introduction there's some results there's as conclusions there's references and you know what you're getting that's right you go to a biological resource a data resource every one of those are strive to be completely different to everyone else so you essentially have to learn how to use each one individually and you notice they have different ways of different API methodologies it's it's not it's a problem so I think the idea of moving towards an open more open integrated system is something that is really important and I think we're we're certainly pushing towards that at the NIH and I'm gonna show you a little about all that means in a bit oops just and then of course I think how we are perceived and described has changed over time and I kind of covered that but I think there's still I think a disparity now between because what what is a value to scholarship is changing so you know the people who do a lot to generate the data do a lot of the analyst they're often within the system the academic system what you would call reef research professors or research scientists which frankly don't have the same street cred as being a tenured faculty member or tenure track faculty member and yet they have increasing importance to the system as what we value our scholarship changes so I think there's an interesting dynamic going on there I'm going to send more about that but it's something that it's one of my hot buttons I'd be happy to talk about it was any interest but I think all this points to what we what we're anticipating or potentially anticipating at the NIH which is this notion that there's this this is the beginning of a disruptive potentially the beginning of a disruptive phase and I'm going to give you an example of why of what's happened with which where there has been disruption and you know I think you know it it's just one example of where things have changed quite dramatically but and you know and understand it but I'm going to sort of present it in a slightly different way and then I'm going to ask you the question of whether in fact this is what you perceive going to happen in biomedical research and healthcare so what do I mean by all of that so first of all I think we've got to say that something is fundamentally changing and Big Data has got all this attention but I think what's important is it speaks more than just about the data it speaks to new methodologies new skills new emphasis and probably the most fundamental change of all is new cultures and new modes of discovery so if you accept all that or at least let's start looking and saying you know what what is what is what accept what is actually happening so I just like these two books for in different ways to illustrate the same kind of thing and one of them the one on the left relates to you know the notion that we're now in a new revolution that this is the you know the information revolution nothing new there but I think what's new and the thesis of this book is the idea that this is actually happening much faster than we anticipated Google car is good example of that the fact is that it processes 750 megabytes of data per second from sensors in real time to create an environment which is arguably much safer than a human trying to do the same thing and the fact is no one really doubted that this was coming but the fact that it came as quickly as it did you can argue this has to do with Moore's law you could argue it has to do with algorithmic developments all sorts of things but the fact is it's one example of things happening more quickly than we anticipated the other one which I'm going to emphasize is this notion of what happens when something goes digital and so let me illustrate that and it's it's this so-called 60s of development so and I'll use photography as an example and then let's relate that to something that's closer to our perhaps closer to our hearts so what was clear is Kodak invented the digital camera and then they shelved it because they saw it as interfering with their film business and they didn't actually do much about it even as the field of digitized images either through the cameras or whatever the technology is that that was in was starting to grow so the digital content was starting to grow at an exponential rate they didn't see it coming because it was very low on the exponential curve and as such change was still fairly happening relatively slowly and then what happened is we went into this so that's the deceptive phase then we went into this disruptive phase where the inflection point suddenly you know Rochester doesn't look like so a desirable place to live anymore things for Kodak have really gone downhill because the market effectively is collapsed and they were not in position in the business to actually take advantage of it and then for me being you know a Bernie Sanders fan a bunch of other things happened that you know there was that there was D monetization dematerialization and democratization is furthered eise right and what we ended up with was something a business model that was absolutely and utterly different than what we had before and it was exciting in a whole different way so instead of the act the production of the image being the business model it was really about communication using images that became potentially the business model so well Kodak is essentially I'm sure is worth noting effectively Instagram is valued and whatever it is 40 odd billion dollars so this was you know this was this was a complete change so what an earth has that got to do with biomedical research well perhaps nothing but on the other hand perhaps quite a lot in the sense that a lot of the research that we do there's been a fair degree of digitization for quite some time but the real sort of I think change is coming from the fact that the electronic health record through you know federal mandate has in fact become more and more prominent in what many of us do and will continue to do so and will so you could argue that in fact we're starting to see the same exponential growth in digitized content that it's going to impact biomedical research and healthcare now we the question is are we in this deceptive phase will we reach this disruptive phase and then see this there's completely different models of urge where you know one outcome from this could of course be what we're pushing towards in personalized medicine in any case which is the idea that the patient is really at the center of the healthcare enterprise as opposed to I would argue not the case right now so you know but there are differences here first of all digital photography photography is a free market economy biomedical research and healthcare is really not a free market economy the fact is you work really hard to get your next grant but you're not really being measured frankly my opinion by the product of your previous efforts but anyway we could get us a whole nother controversy but we could get into but the point is it may not be the same it may not be a fair comparison and maybe it is and you know I just leave that as an open question for you all but there are other aspects of what's going on which we consider which are really important to this the consideration that are we are we in this sort of disruptive phase are our things about to change and more than we anticipate and so the other drivers for this are things like sustainability now I could show this graph these two graphs to a first or second grader and they would tell you the obvious which I can tell you is you can see for yourself is on the left hand side we have the growth in the NIH budget actually it's got a little better because we've got a two billion dollar bump this year and in FY for FY 17 but on the right hand side is the growth just in the nucleic acid research which actually keeps track of biological databases that come online in the number of databases so we've got a flat budget and we've got data increasing at a very fast rate it's clear without some kind of change this doesn't scale either we take more money from fundamental research to support data we've already got or we find more efficient ways of managing the data we've already got or we come up with some other scheme and we have thoughts about this needless to say it worries some of the Institute directors and Jon Lorsch in the middle there who's the director of the NIGMS NIH and Eric green is the director of the human genome Institute we recently described some methodologies for how we're planning to deal with some of these things and you can you can read down I just want to say that this is another disruptive force that's the point the sustainability of the system another disruptive aspect is reproducibility which has come to the fore quite recently in a number of different forms and I won't go into a lot of this some of this ship I'm sure aware of but you know reproducibility has taken pretty seriously at the NIH you know it doesn't and it really speaks to another aspect I was talking at lunch about the fragility of the system so you can only imagine when a congressman congresswoman opens the newspaper in The Washington Post and reads that X percent whatever it was 60 70 percent of seminal papers in cancer research cannot be reproduced and they say wait a minute I'm just going to the Appropriations to give the NIH 32 billion dollars for work next year and they can't reproduce 70 percent of what they're doing it doesn't go down well so you know I think a lot of that perception is misconstrued but at the same time these are the speaks to things that need to be addressed and obviously data and how we manage data and how we make data available to enable reproducing as well as the analytics that go with it and the statistical analysis and all the other parts of it a key to all of this so this is potentially another disruption that needs to be dealt with and then there are the things that happen I mean this is you know this slide is now in a few months old we now have another new disruption and the newest disruption of course is the cancer moonshot so suddenly when things happen in government there's an immediate trickle-down effect you know that this is there's this response to it to try and make the most of this opportunity so a year ago a little over a year ago we had precision medicine initiative which I'll say a bit more about in a second and now of course we have the cancer moonshot and I was absolutely blown away to watch the video from Davos from a couple of weeks ago where Joe Biden was sitting next to my boss Francis Collins along with other distinguished scientists including Jennifer Doudna who's responsible for CRISPR and so on and partly responsible CRISPR and having you know this leadership speaking about the need for standards and data sharing I thought hallelujah this is this is so yeah I was I was totally overwhelmed by orcas this is something that you know some of us have been talking about for a long time and it's really hitting the mainstream so I think that's all evidence of further types of change the precision medicine initiative specifically there's two parts to it this year there's a 215 million dollar funding for that about 60 million or so is going into and National Cancer Institute to actually speed up the sort of genomic cancer types of efforts around the human genome or the human genome the the cancer the TCGA and other sort of genomic driven cancer initiatives and then the other part of it which has about 140 million dollars is this idea of establishing a cohort of 1 million people where that information will be shared as I think some of you have probably heard from Josie Briggs apparently came to talk about this where that information will be shared for research purposes and that includes everything from genotyping to electronic health records to M health data and so on I could say a lot more about that and the likelihood of where that's going to go but I'll let that go but the point is it's potentially another disruptor in what we're doing probably should go step so what are the some of the so if you take those whether you believe them or not you know I think it does have some implications for the future which you could also take or leave so I think that there's the notion open collaborative science has become of increasing importance both nationally and internationally I'll say little more about that in a different context but you know there's some of these problems are so complex and they're not going to necessarily be dealt with by single or one or two investigators in small labs that they need you know collective efforts perhaps by those people but towards the collective good so that all speaks to more sharing of various aspects of the research lifecycle so I think I've already said that out of all of this I think there's this notion that the analytics and the data are becoming more valuable to scholarship and we're certainly trying to push on that and I'll just give you one example some of us anymore about it but we're in the process of organizing a workshop with NSF to go out to leaders right chancers for research and vice-presidents research and so on and those chairing tenure committees to really say to them you know I think you really have to look at scholarship in a different way but it's not just about science and nature and sell papers it's about what the overall contribution is that people make we need better metrics for measuring that they're starting to emerge but we need to do more work there but I think it's just the notion of at least to begin to think a little differently about what's valuable and then I think there's no question that there's potential opportunities here through data science and other activities to improve the efficiency of what we do it's rather unfortunate that we fund things on these short cycles where something may just be getting going and it doesn't get refunded and it dies on the vine there are you know I think there's a lot of lot of good research and then the Associated data analytics and other things associated with it so pick myself that you'll get lost when the grant runs out we need better ways of preserving some of that so it can be reused even a lot of the negative data so you know that we need to preserve more of the research lifecycle we need global cooperation because what we do right now doesn't actually scale very well and it doesn't actually make a lot of sense in many ways so at the given organization and in a given country will fund the database or a data resource that's used by people worldwide now it's sort of a quid pro quo here but it really is not that equitable so we ought to have a more equitable way of funding these things for the global community and that's there it's easy to say and it's hard to do because funders you know there's a whole series of issues about funders just one example of that that's a bit of an aside not even a joint funding initiative for some kind of resource but just to have an open science prize which is what we're doing right now is a joint funding effort with the Wellcome Trust in the UK the NIH and the Howard Hughes Medical Institute the idea of that is to take open data open analytics and to use them in a new way or propose to use them in a new way that's going to advance biomedical research and healthcare and you'll get it'll be awards for that the teams have to be multinational so that's easy to say I've just told you the whole essence of that idea but it took a whole year a bunch of mo used to get that sort of thing in place you know so these things are not trivial to work through the bureaucracy but it can be done and once you've done it once it's easy to ramp it up and do it in many ways sorry I'm talking about bureaucracy but that's where I spend most of my time these days but and and so I think that will bring forward that says a lot it says that funding agencies are working together to address some of these problems and we're actually promoting the value of open data and open analytics so we'll be interesting this is running right now and would be interesting to see what comes of it then training and Michelle done who's here from our group could tell you a lot about training I'll say a little more about at the end but it's clear it's absolutely clear there's a massive short come shortfall between supply and demand the number of people who are needed and the number of people who are available we just had a workshop before fu UCSD on big data and you know there was essentially over just in in the San Diego area there was like a hundred thousand jobs that had some element of data science in them that could not be filled at that time we didn't even have a data science master's program or anything approaching there at UCSD so it's it it tells you that the needs far outpace the supply and you know I think getting we're doing what we can to help change that we spend about 20% of our budget on training and then of course there are other aspects which I would touch on too much today but there also I have to be taking account sick who I'm of course as more and more of us spend more and more time using human subjects data the issues of security versus access to that data become and when you start merging things together some very strange there are lots of possibilities that the the pet the provider would not be pleased with that have to be dealt with you can go on and on so how are we sort of trying to address these challenges but also in some ways these opportunities so we have approached a project called the big data to knowledge initiative which is the sort of main tool for dealing this is a trans-nih initiative so it's actually run out of my office but the we have council members from all of the twin nearly all of the 27 institutes and centers at NIH they form a multi council working group that actually oversee this whole program and we had our first All Hands meeting last November and it was really it was a very very vibrant meeting of course you know I'm very biased in what I'm saying but because I want this to succeed desperately but I think it was actually some there was a sense that something special is going on and I won't quote because a bunch of these people are actually PI's who get funded by it so they're going to say whatever I ask them to say but there are other people here who had no vested interest for example Janet Thorton who was the former head of the European buy biotechnology Institute in Europe came to the meeting just to see what was going on and she was really enamored by what's going on and I'm gonna give you a couple of examples from early stage work that was presented there to sort of try and illustrate at least my own point of view that something quite interesting is happening here there is to some degree different and what's happened before so just to say we have a budget for this through the end of the decade and it's a little over a hundred million dollars a year and we're pushing forward with a whole set of initiatives and those initiatives change with each funding cycle we funded a group of centers yes and I can see you're throwing your hands out there that it's not equitable across the US and what can I say that's not equitable across the US we in many ways we also have diversity programs and a whole set of other initiatives to try and address this but that's the way it is right now and you know these there's a 12 which pens how you count 12 or 13 centers and each of those has joint membership from a number of other institutions so it's it's quite a network even if it is not spread equally all over the country so we're responding to this by trying to support the community and policies that also push this these kinds of initiatives forward and then infrastructure that really helps it as well I'm going to give you a little example from each of all of these things but sort of illustrate that so let me start with just the work of what are the centers I'm going to show you three just very brief clips from for me from three centers that are working on this I should also say outside of the center's we're finding a lot of ro ones and apart from the training and things like that that relate to things that for example relate to particular aspects of software right that relates to provenance you know wrangling of data and other forms of analytics visualization and now we moved on to you know really modeling and other aspects of data this is an example from the Craven Center that's that really sort of illustrates a whole series of projects they're going across on that relate to different types of phenotyping you know maybe new image-based maybe EIA HR based epigenomics and you know and breast cancer screening and so on and then there are various labs that intersect with this different these different aspects of phenotyping to do stochastic modeling and so on and I'm just one example of that is this idea that they've already got some I think some pretty intriguing results on which relate to what they've what's been done in the past of course is so-called retrospective phenotyping so you have subjects they exhibit a phenotype of interest what they're now looking at is prospective phenotyping where you actually and in this particular example they took 1.5 million subjects they took all icd-9 codes in the EHR reported for those subjects and then they took a whole series of cases where they had controls and they had and the ones they were actually analyzing and they tried to look to see what how much they could predict that an outcome through a machine learning technique by looking at outcomes that had actually happened and then taking records and seeing if they could predict those outcomes and then going back to look to see if those outcomes actually happen and as you know most of you in this audience probably know better than I do but if you look at the area under this curve there's some statistical significant here apparently where you know in a 1-month prediction you know they can do they can do pretty well in terms of predicting what the phenotypic outcome is going to be this is very preliminary and beginning work but I think it's that it starts to show what you can potentially do with these large masses of data in this case electronic health records another initiative that we're funding that just illustrates some of this is around mobility and this comes from Scott Delp Center in Stanford where they've they've taken data from an app called Azumi oh and this is just the sort of distribution of people that they were actually looking at so they had two million subjects and they had a total of captured 74 million data sorry days of activity which gave them over a hundred billion data points which is a thousand times more than any other study that ever been done in Hanes was a study done by the CDC and on the right all that shows is that there's a distribution of in terms of age and in terms of what remount Stu you at least in the US and I'm not sure that's us data but shows we're essentially at 28 percent or so of the population is obese which is certainly true in the US but but this data is actually global so I'm not quite sure that if that's representative the world or just the US well anyway it's it's a subway representative data and then they've just started analyzing it in various ways so one thing that came out of this is that if you look at the BMI and you look at the number of steps that people take as you would undoubtedly gather that there's a correlation between that perhaps what's and it's this is not new new finding but it's that in fact you know there's a quite a differential around gender in terms of BMI versus the number of steps that people take and this is actually it turns out I didn't know this but it turns out to be relatively well known but that's just you know that's so that's something that's known what came that was somewhat surprising out of this is that is the bouts of exercise that people take that what they observed that the BMI drops pretty significantly when you actually have even one bout a relatively small amount of time of exercise per day and subsequent bouts don't change that very much I have no idea what the the validity of this data is I think what I'm trying to illustrate here is that there's potentially interesting findings and potentially a lot of interesting analytics that needs to be done on this kind of data to come to form you know to formulate real conclusions from it and so I you know it's just put this up as some sort of tantalizing at least for me tantalizing examples and then just to continue on there on a planetary scale so that the data I just show was for the US what we have here is we have a Gini coefficient which is essentially a measure of inequality between in this case it's where you have a lot of difference between obesity of people within a given country and you can see that you know countries sort of follow certain patterns and so it's interesting that there might be you know significant inequality in between in in Vietnam and yet the obesity level is still there still relatively small so that would imply that some different things are going on again I think something that just needs to be explored further and then the last one is I think just intriguing because it's a sense of a measure of obesity mapped to data that's taken from Yelp on and reporting effectively on the fraction of fast-food restaurants within a given radius in a given city so it's really about the concentration of fast-food restaurants as and how that in a given city maps to obesity and clearly there's some level of correlation there so you know you could start asking yourself well how do you you know how do you have proper hey if this is true and again very preliminary but the idea that you're putting together this mobility data along with data from Yelp and you're coming up with these kinds of conclusions or at least potential conclusions I think is intriguing and then the question is can you use that in some way to to actually do control experiments for intervention could you get the mayor of a city to say okay let's reduce the number of fast-food restaurants at this particular area and let's measure this data from people over a significant period of time we can do that to some degree automatically it's getting uploaded through various devices already and do we make a difference can we make interventions and affect people's lifestyles just by doing things that are not necessarily that apparent to them I don't know but I think it's intriguing and then lastly another example is just from which really sort of brings to the fore I think the complexity of these problems and but I think also points to you know why there are these challenges are worth worth pursuing so there's a sensor that's led by folks in Memphis Tennessee it's called the mobile center data to knowledge initiative and they do a number of things that including developing sensors they also use existing sensors they measure various types of exposures they look at behaviors and they try and predict or lead to different that Lisa this is the intent to impact outcomes and they're focusing on two aspects chronic heart failure and smoking cessation and I'll just say a little about the smoking cessation one just to sort of illustrate where I think there's a lot of analytical work to be done and a lot of real intrigue in all of this so the sort of modeling challenges I just like this thing on the right they're just the different ways people hold cigarettes it's quite I mean I think you could there's there's a whole lot of other studies that if you look to the how a person held a cigarette you could learn so much about their personality I just made that up okay so but you know the fact is that when you how do you what you're trying to do here is detect when someone drops off the wagon when it when they start smoking so how do you detect whether they they suddenly start smoking and how does that correlate with other fit other factors related to stress for example so first of all knowing when they fall off the wagon is even if they're wearing a device how do you determine what I'm just doing right now versus you know taking a puff of a cigarette particularly when I could be holding it in one of those intriguing ways on the right you know this is these are not trivial sort of things to actually unravel but you know I think there's it says there's various co-founders eating drinking yawning but you know and also the number of instances is relatively small against a lot of noise in the data when I'm waving my hands like this but you know already they seem to be able to detect first lapses based on this kind of data and they are they're looking at that in the context of what caused those lapses by measuring other things like stress that can be measured in various ways including sense of data that's embedded in glasses that looks at how your pupils dilate and such which is indicative in some way of stress so you start putting these things together again really leading-edge long way to go kinds of activities already at least producing some interesting data that requires you know a lot of analytics and you and to actually make real sense of it so that's but I think if we're going to support all these things at the NIH and continue to see these kind of things develop we need to also support infrastructure so they don't die out and so that they they can be reused and we're we've actually put in place and we're developing something and this is not a new concept others are doing it as well but the notion of a Commons so the basic idea here is we fund a whole series of centers and we're also funding we're operating off what we call the fair principles which is the but the ability to find access interoperate and reuse data or analytics because it's not straightforward right now so we're funding this DDI CC which is a way of finding data we're doing the same for software we're actually putting in place mechanisms to locate new standards and the whole idea is to put this into a framework which we're calling the Commons and so the idea is that you can go out there you can look up and find a particular data set that's useful for a task for example which you may not be able to find otherwise ultimately we want to see that of course sited in a way that it forms part of the citation network but until it does we want to be able to find it in that way we want you to act we want to see how much it's used and we want to see what people have to say about that and so that's the idea of putting that kind of thing in this environment and we can also measure in this environment because we've actually know where it is and we know how it's being used we can we can actually see how whether we ought to do something for the NIH which will be really radical should we continue to support this data after the grant that's gone has run out because right now it probably atrophies away over a period of time it was on a graduate students laptop and now it's gone so this kind of thing and of course we're over time are introducing other labs into this and I'm running a bit short on time so I won't go into the sort of architecture of this but I will just say one aspect of this which I think sort of a dick ative of how we're trying to change things and that is the model we're using to operate this so we're actually doing something that NIH has never done before we're using what's called a credit model and so what we're going to do so think about what happens now you write a grant you put a line item in there oh I'm gonna buy a couple of servers I'm gonna know I'm gonna need this software I'm gonna need a bit of this person and I'll let me put in $100,000 for that we give you the grant we have no idea what you do with that money and we have no idea whether it's used effectively right so what we might do and also to drive content into this Commons environment we're not going to give you money anymore this is so it's not that's an overstatement with we know where we're going to make a small experiment where we with a small number of people we try giving them credit instead of to spend wherever they want in a commons compliant resource we also already have the major cloud providers signed up to this and guess what we're not going to give you a hundred thousand dollars of real money we're going to give you a hundred twenty-five thousand dollars of credit to get you to try this out and then we're only paying for what you use right now we pay whether you use it or not so can is just one idea of how we might do some things more efficiently and we will evaluate all you know agile experiment and we'll see whether it works if it works we'll think about how to expand it or not so this is the kind of thing we're trying to be agile about I won't I'm actually running a bit short of time and if there's any questions I much prefer to have those but I just want to say that we're also working with communities one community is the Global Alliance for genomic health where we're actually running some with them and funding with them some experiments to to determine how much people are willing to share and to what lengths they'll go to share and what what are the benefits for them in doing so and this beacon project is an example of that and I won't go into the details of that and I describe the credits model and then the last thing I'll say is just about training we have different kinds of training initiatives including I just won't go into the details of that but weird except to say that we're not only training people throughout their graduate careers and beyond but also people are already trained in one discipline who want to at least embrace and learn more about data science we're also experimenting with different things around software carpentry and other types of initiatives and then of course the training materials itself which is sort of encompassed in what we do to the r-25 program and your own efforts are just one example of that which we're very pleased to see and obviously these things become very important to training the next generation so that was sort of a brushstroke of what we're trying to do and hopefully it has some relevance to you and thank you for listening and I should also say of course this is a great team effort which actually spans our own little office but also folks who contribute to this across all of the 27 icees institutes and centers of nih and including in that as our own Michele Dunne who's sitting here and there's been an enormous help in the training activities and beyond so thanks very much so we do indeed have some time for questions we are being webcast and so if you have a question we would like it if you could go out to one of the microphones that are on either side of the auditorium so feel free to to make your way to a microphone if you have a question maybe in the meantime all I'll just start out with one which is that you you show these great initiatives that are beginning to come out of the center's you know which which look like wonderful descriptive analyses and and data discovery but then a next step may be to find mechanistic relationships with the the fast-food example it could be that the fast-food is driving obesity or maybe you know fast food stores are smart and they're just landing where obese people already are it could be a third factor so what are your thoughts on where that sort of science will sit will it then come further out of bd2k or do you see some other mechanism for it well I yeah it's a good question and I think it's really a function of how what we're already doing is perceived at the NIH and I have to say that that you know I think that there's a sort of wait-and-see to some of this so I think if if there is compelling reasons to explore these things further I think that there will be other Institute's we'll pick them up and they're doing some of their own things as well the you know I think the issue is that within our own program it sort of sounds you know if you're pi-1 hundred and ten million dollars a year sounds like a lot of money that's not a lot when you're distributing it across a whole country and you're trying to you know do many many different types of things but I think that fought that sort of further type of analysis you know obviously this is an iterative procedure and I think you know I think a lot of this is sort of still very much in the data aspects of things and we're really trying to move towards the knowledge aspects but to do that we really got to take into account these kinds of questions so I'm doubtful II there will be more funding for this kind of an you know the kinds of things you're describing but you know where that's going to come from it remains to be seen if I don't like the question I'm just going to go and hide behind the poll okay data sharing being such an important part to this future we're we've heard for quite a while about the OSTP memo and some hints that NIH among the other funders may be coming up with their policies on what the next steps will be in data sharing policy data management plans have you heard any more details about what the timing of that might be I know and I think NIH is holding back and trying to get it right I've heard before but right I mean we're we're clearly intimately involved in and I have to say that you know I'm involved in the governance struck for date of science and how NIH at large deals with this of course it has to do with certainly policies are part of that and we course and have policy X we have a whole you know the office of science policy which deals with these issues and but then it's that that what we understand as data scientists and then of course there's how these actually get implemented but to be more more specific about your question so for those of you don't know the Office of Science and Technology Policy of the US government put forward a so called Holdren memo which speaks to the fact that data that's actually generated with public money needs to be shared and managed that's the good news to some of us the bad news is that it's in government parlance it's an unfunded mandate so somehow we're supposed to do all of this without actually any additional funding which of course presents challenges where we stand where it stands right now is that we were required as a federal agency as were the other funding agencies to respond to that memo in terms of what we were going to do it turns out of course that that we NIH is particularly fortunate I think in doing a lot of that already I mean the National Library of Medicine has been an absolute exemplar for making data available and will continue to do so but we there are other activities so first of all just to give you a flavor of some of the things that are coming down the pipe I won't say when but right now we have a policy that data management plans must be provided on grants of over 500k direct per year which to me as I said earlier this morning is sort of ridiculous because it basically says if you you have a small grant you're not producing any data worth saving which doesn't make any sense at all so we will be implementing in a certain time frame which I'm not sure exactly yeah I've got ideas but I don't want to say them that that will be required on all grants but the other aspect of it is what's the point of having that kind of plan if in fact you don't have a way to see that people are following the plan and and it's a value to the community and we're going to do all this if it's not if it you know these things don't happen so we need to take care of that as well so one of the ways because right now you can't you can't put all of that burden on some poor program officer who has to review those grants periodically to see whether there's compliance it just doesn't scale so what we need to do is to move towards a more automated scheme so that sort of thing is going into place where the idea would be is you write this plan first of all that plan is then formally reviewed as part of your application so if you don't have a credible plan it's going to affect your score but assuming the plan is credible then you say you're going to do such-and-such with this data on such a such a day so if you're putting this into a repository then we should be able to automatically extract it's ironic that right now we don't have any machine readability of data sharing plans but we would read from that plan when you're going to put the data where you said you're going to put it we look at where when and what and then at the other end which we don't have in place at all right now is that when you deposit data in a repository the grant number associated with that data should also be recorded so we could actually automatically go out and see if in fact if the loop is closed that you did what you said you were going to do with that data when you said you were going to do it and of course there'd be a million reasons for not doing that but at least we would have a measure of that and we could actually ask questions so it's it's really in some ways that sounds a bit heavy-handed I actually working on more subtle approaches where I'm trying to get NIH to and I think this will happen over time is to really support the notion of data citation so that in the way that you cite a paper now you will also be able to cite a data set and so that data set then could be included in grants it could and we would we would endorse that as being an you know you know a legitimate form of scholarship to report in grant applications and reports and so on the same time it will become part of the citation network that currently is predominantly papers but when datasets get built into that network not only can we measure how much how many citations those data sets get effectively but it also creates a much richer network where you can go from a data set to all the papers that have actually used that data set which could be valuable because it would tell you whether you want to use that data set or alternatively you go to a paper there's reference to a data set that you know where is it and this this would potentially lead you to that so I think that to me is a plus it says okay whoa NIH is actually valuing data as part of scholarship because we found but hey it would be great for example somewhere developers have access to say like how many grant applications are mentioning myself well I mean it's a big data problem to to fully appreciate the value of a given entity I mean I was saying this in a smaller group whether it be software or date or whatever is that we you know it's a big data problem to actually figure out what its network what its value is you know so because it comes in different forms you know if I have a data set I mean I can go to the data sets that I produced and I've discovered their reference for example in patterns and go to a pattern database and I can find because it happens to be in a database that has a unique identifier which is not necessarily a citation but but that I could at least find it in some cases and I can find it in the patent database and so well that's good it means somehow this data was part of this patent application but that doesn't really tell me still what value that has in terms of its its its value to innovation because that patent could just be sitting there it could be licensed it could have actually led to a product that's important or not so we can't yet put all the pieces together that's just one example but you know I think over time we are beginning to build you know there's there are resources like what used to be called total impact where we're starting because so much of the fruits about our scholarly Labor's is somewhere accessible online in digital form we can begin to gather the things that we do and measure how important they are in ways that we couldn't do before so you know this kind of tools go into figshare into SlideShare and things like that and they look at you know what you've produced what presentations you've made how many times they've been downloaded those things have some value to scholarship including you know what you do in social media networks you know the blog's you write how often blog you know there are people who it's clear in an informal way people get there's a respect level for some people related to blogs already and and and you know but that's not counted as part of the formal value you know you don't you know you but being really active and appreciated in the blogosphere is probably not going to get your tenure at this point but you know I think these all of these these are all about cultural changes but they're starting to happen in terms of how you you know how you you sort of bootstrap your way up in this system I mean I think the first thing is you need to get you know you need to get your Sitz software you needs to be out there it needs to have appropriate provenance it has to be you know and you know I think slowly but surely references to things that github for example are gaining some traction as part of being valued a scholarship but it's a it's a slow process and we're doing what I just described with data citation by the way also applies to software citation so overtime I think we will begin to see some progress here but yes your your at that at that points of change I think there any further questions well if not we will have a reception down in the gallery and we welcome everyone to join us there and let's thank dr. Bourne for a wonderful presentation a pleasure you 