 from UBC and I'm here to talk about how we can get crowd-sourced feedback about fiber tactile sensations and more generally haptic sensations too I'd like to start with a question how many people here have a device that buzzes pretty much everyone right how many buzzes do those devices make one yeah exactly not very many and this is another thing with haptic devices especially these low fidelity or these vibrotactile devices you really have to design these different sensations to make them effective when you do though you can do lots of different things so we're going to talk about vibrant tactile sensations those are vibrations that you feel in the skin when you do design them you can make a lot of cool things you can tell someone that they just beat their personal record or to run faster to catch up with a ghost if they're exercising you can communicate emotion adding a personal touch to your communication with others or you might be able to invisibly tell someone when it's time to move to the next slide but doing this of course requires a design process and haptics remains very challenging to design and one of the big obstacles is getting feedback so if you're a designer and you've created some vibrations you might bring some people into the lab to get some feedback and see if they are working you know if it's actually telling someone to move to the next slide now this is running in lab studies can be very slow it can be very expensive and we've seen a lot of work coming out of other types of design about how to do crowdsourcing and get lots of people running studies very quickly and this is what we want to do if you look at other modalities you can find that you can get feedback for example in graphic design so whether using contrast proximity color effectively you can generate ideas from the crowds you can come up with a message for a birthday card or something similar user stories you can even run perceptual studies at scale as long as their visual which allows you to you know collect lots of participant data very very quickly and very affordably so this is very attractive so what do we do to go from here to here what can we do it actually crowdsource haptics well there's been a lot of work on how to try and add haptics to broadcast media um you know such as adding it to a movie or a video so tactile movies here whatever I think it's spider-man is jumping from one wall to the other you can feel that motion on these gloves now the problem is I don't have a pair of these gloves does anyone here have a pair of those gloves one person okay one or two so we have a crowd of two so this is a little bit limiting and of course we can't ship out these devices to everyone because then it's slow and expensive and all the things that we're trying to fix and this is fairly consistent when it comes to haptics in other media I mean there's lots of different approaches you know adding the equivalent of camera motion to optics so haptic cinematography when something tilts you kind of feel tilted or adding something to YouTube we can do that in the software but at the end of the day we have custom or high fidelity hardware that we just can't send out not everyone has so this is challenging we can't send high fidelity haptic devices so the question is that we ask is what we send instead I mean you can send lots of things over the Internet to the crowd you can send graphics you can make someone's phone vibrate you can send audio and the key insight that we have here is that could these be used as proxies to stand in for the high fidelity haptic sensation and that's the idea behind half Turk you take a high fidelity haptic sensation in this case we're going to talk about vibrations you translate it into proxy vibrations you send them over a crowdsourcing tool like mechanical turk and then you use that feedback to inform your design so let's put this in an official research question can proxy modalities represent perceptual qualities of high fidelity haptic vibrations to the crowd let's break this apart we're going to start with perceptual qualities well that's the beginning of our journey so if you look at the literature there's lots of different dimensions to how we perceive touch they're still being developed some of the major ones are duration energy and speed which are very low-level physical cell qualities that contribute to our perception of vibration there are other ones like roughness urgency and pleasantness which are a little more emotional effective and high-level perceptual in nature now most of these are found using perceptual studies some of them are rating scales some of them are found through clustering and multi-dimensional scaling others are tags that people can use to describe vibrations we standardized i'm using a slider from 0 to 100 to keep it very easy for our participants in the crowd to be able to write these things all right so we have perceptual qualities the next thing we need are some vibrations to actually represent and that's where we went next we use the c2 takter I have one right here you're welcome to come and find me later if you want to feel see what it feels like this is a like a tiny speaker it's a voice coil tub actuator so it controls amplitude and frequency we used it together with a tool that we've developed in our lab called vibe is now this is a visualization of 120 vibrations along different perceptual facets and so allowed us to come with come up with a diverse set of ten different vibrations that we label V 1 through 10 and we chose these be representative of this wide space but also diverse in representing these perceptual qualities so we have our vibrations the next thing we need our perceptual are our proxy modalities and that's where we went next so if you remember the question that we asked is what can we send well the easiest thing that we might be able to send is graphics so let's start there and actually we came up with two different visualizations to represent vibrations the first is kind of the default a waveform when people worked with vibe is what we found is that they would use these waveform visualizations to skim or find similar or different vibrations so we thought this was a good starting point as a status quo but it's the default can we do better and so we decided to try and design a new one we began by exploring different shapes i'm looking at texture and color to try and see different ways we might be able to represent a vibration eventually we refined through piloting we eliminated color because it was a mole generally charged and we eventually had three different candidates that we then kind of had to show off in a user study finally we end up with this line based system and we have a key of how to translate a vibration into the system the roughness of the line corresponds to the roughness that you feel in the vibration the weight and height of the line correspond to the energy and we have a metro measure for how long and short the vibration actually is so those are our visual proxies we've got a waveform and we've got designed we tried to keep them relatively similar so they are comparable and of course now that we have a visualization I can show you all our vibrations and there they are of course you can consult the paper to see them in finer detail so that's trying to send graphics the next thing that we might try to send is vibrations if you're sending a graphic it's it's very easy to send but it's rather indirect whereas vibrations you know feeling it in your phone that's a much more direct translation of these high fidelity haptics we did consider going with audio or some of these other techniques but combining our expertise we didn't have an audio expert on the team and also the directness we decide to go with vibrations first and to do this we translated each of our high fidelity vibrations into phone vibrations now your phone has a very limited actuator it's an eccentric mass so all it does is kind of shake or not shake with different voltages and if you're controlling it through something like Android which is what we did you're even more limited you can only send it bursts you can say you know vibrate for 50 milliseconds 40 milliseconds etc and so we went through this process of piloting and translating these different vibrations into the phone and we had sort of this pulse width modulation approach where you kind of have shorter and shorter bursts to make it weaker but we really had to play with representing energy and rhythm effectively so now we've got our proxy modalities so right now we've basically got everything we need to start looking to validate this approach can we actually do this crowdsourcing thing to actually validate this we came up with a couple of main goals the first is we need to collect ground truth ratings of our high fidelity vibrations the second thing we need to do is compare these proxies to those ratings keeping everything else the same so doing an in lab study finally we do actually want to deploy it over Mechanical Turk to see if anything breaks down we organized this into two different studies a local study to collect the ground truth and compared to it and then a remote study to test whether anything breaks down when we go remote so let's go to the local study next we had two different between subjects conditions out based on the proxies so one was the low fidelity vibration proxy the other was the visualization proxy we had people rate both the high fidelity vibrations and the proxies that we could try and reduce some individual differences and they did this for every vibration for both of the modalities or all three in the visualization case and then our what we did is we compared the ratings of the proxies to the corresponding ratings for the reference vibration now if you run a t-test or an ANOVA you'd be able to tell if they're different but we wanted to show that things were the same and so we end anyone knows a lot about stats you know you can't try and prove the null hypothesis so instead we employed something called equivalence testing where you set a threshold level in this case a delta we use the standard error of the mean to try and set up at least try and keep it related to the amount of error in the system of the rating system and we found whether things could be equivalent whether we couldn't tell if they are equivalent or different or whether they were different and this is what we used in our analysis here are results there's a lot going on so we're going to zoom it in a second along the top we have a perceptual quality so speed duration energy and then etc and then on the side we have our different proxy modalities so the waveform visualization the design visualization and then the low fidelity vibrations so let's zoom in these are the pleasantness ratings for all 10 vibrations for the waveform visualization you can see that the colors we're going to focus on the colors right now not the location because that's what actually tells us what the valid so vibration one was well resemble as well represented it was equivalent vibration to we couldn't quite tell was uncertain and then read for several other vibrations meant that they were different so pleasant this was for most of these are for half these vibrations was not well represented using this visualization approach so let's zoom out and let's use that to try and look at this data now the first thing you notice is that there's a lot going on here some vibrations were well-represented some weren't so let's see if we can find some trends the first thing is that duration and pleasantness seem to be the most translatable you look at the duration column there's lots of green and most of the vibrations had at least one modality that accurately represented the ratings with pleasantness we had something similar there's more uncertainty but it comparatively was a bit better with speed and urgency we found that sending direct vibrations seems to be a bit better there's at least less and less difference and and more equivalence going on there so that means that sending something direct can be helpful but in other cases it seems like a visualization might be a bit better too and so we have this three-way interaction effectively of it depends on the vibration it depends the modality and depends on the perceptual quality that's challenging especially challenging with energy there's lots of red in that column if i had to pick i'd go with vibrations but this is something we can focus on in the future the other thing to notice is that the designed visualization tends to work quite a bit better than the way from one and so by creating new visualizations we can actually improve this process does not expect on this is not unexpected but it's encouraging to say hey if we design new visualizations there's a value than that so to wrap up and study one we saw that some of these translations succeeded and that's encouraging we saw that we can do better and we have some ideas of where to go from there but before we start to try and do better one to deploy online and see if anything breaks down with Mechanical Turk and that's where we went next to the remote study so remember the structure of the local study study too was very similar except we could only deploy proxies and we ran similar levels of participant numbers that it was comparable error rates etc 1 keep it as similar as possible to the local study and then compared to the same reference points trying again keep things as similar as possible here are the results from that study the first thing to note it's hard to tell right now there are more details in the paper on the whole it's similar results and if we highlight the ones when they differ there's only about ten percent of the vibrations actually different disagree between the remote and the local proxies if you can player the CIM compare proxy to proxy only in these cases does it actually change whether it was a quilt in turn on so that's great so eighty eight percent of ratings were consistent with local proxies we did see that some participants were unreliable in a vibration case so they said that they're using Android which is the platform we used for vibration but they were actually on like mac or windows so they're clearly lying we didn't include that in the analysis by the way we gathered more participants great so what are the takeaways from this let's go back to our first question can proxy modalities represent perceptual qualities of high fidelity vibrations to the crowd yes for some proxies qualities and vibrations and it depends on the combination to give them more detail and conclusion I we believe that proxies can be viable there's some evidence of successful proxies we've import more importantly we found what worked in what can be improved and about ideas of what to do next and found that there are no major breakdowns when you went to the remote Mechanical Turk situation so for future work we're going to try and improve upon these proxies we're gonna try and combine them together see if you can triangulate by sending a vibration and the waveform and a visualization maybe try and animate them where you sound and of course automatic translation is going to be very important to employ this practically right now we hand translated everything into proximate allottees that won't scale so we have to actually generate some tools we also want to look into how people give feedback here we looked at a very strict case of equivalence whether the rating scales themselves were very close but we ran something like inovas or t.t tester tags we might be able to get useful information that's more can assistant despite some of the noise of these rating scales and finally we do want to collect more data run a bigger study and try employing best practices for mechanical turk we were fairly purposefully naive we want to see you know anything that participants would do like lie or whatever but now I think we can start to structure our feedback a little bit better one thing I want to know is that this is in line with a larger trend of work that we've been doing in our group on online haptics we have vibe is which you saw which is free and available right now it's an online collection of visualized vibrations we also have an online haptic editor that you can use right now and I've got things that vibrate that you can plug into your phone your laptop to try these out if you'd like so come find me if you want to thank you very much thank you to my co-authors here and let me know if you have any questions hi my name is Paul I'm not a couple Hagan University so let's say you've you've done your follow-up study and you're really happy with your design and you know that the results you get our kind of what you want to get yeah what kind of study would you run with the system because you're using super high precision actuators so I would think you'd be investigating very subtle effects and what do you see yourself using this tool for right so I mean the case that I would imagine is if you think back to those use cases we showed the getting let's say the presentation one because i'm giving a presentation you might have a couple of different ideas of sets of icons to tell people to move to the next I the next slide or speed up or slow down etc you might said that that cluster out to get people say oh this set is better I like this vibration more than this one or this one's more salient so I think trying to like come up with right design language for your haptics is where we've been thinking you might be able some perceptual call these perceptual studies as well like we found it very difficult with all the noise and these rating scales to find out where other rating scales might be and what the perceptual dimensions of haptics were and we're hoping to scale those up as well to see if there's like even higher level things like emotional content is that help ok cool yes great thank you much we can follow up later hello this is pablo perez stanford university so can use plain how did you choose the the sigma for the equivalence testing because that's not a trivial parameter that you really need a lot of prior information to pick and also did you make any type of like correction because you ran a bunch of study do you do like any type of statistical correction yeah so we used one for any correction for multiple comparisons and then so typically you're right in a equivalents testing you have some sort of practical threshold derived from the field we didn't have this right now what we did instead we tried to just say within the standard error of the ratings that we collected so it's tied to the noise in the system of the ratings themselves which was about 15 to 20 on that hundred point scale which means that we could I think if things are equivalent I would say they probably map towards like a five-point likert scale so we didn't you know get some reasonable psychological results from some of these but you're right there's a lot of noise rating scales and this is actually part of the reason why we really want to crowd sources that we can start to find out where these means are okay yeah all right thanks thank you 