 my name is Steven by low and i work at Red Hat based here in Singapore just a little bit about myself my experience is split 50-50 roughly between development and operations and about five or six years ago I was wondering what to do should I focus on development socially just focus on operations and that's when I met amazon web services for the first time i found myself in a workshop and from that day onwards i was hooked so to why why was i hooked as Vanna Fogle said the CTO of Amazon Web Services he said cloud is liberating it breaks down barriers it takes away the constraints and that gives you freedom and the freedom to experiment make mistakes go back and try again and that in turn gives you a jilla tea and agility also spawns innovation and it's proven that innovation create more profit so I'd like to ask a couple of questions so I'd like to see a show of hands please don't be shy I will not pick you out and asked you up here but the first question is how many of you here have played with or just try docker containers please lift your hand so i think that's about thirty percent okay keep your hands up how many of you with your hands up have used ducker in or are using docker in production so put your hand down if you are not using dr. introduction that's about maybe five ten percent okay so one one more question before today before this slide was put up how many of you have heard of and understand a little bit about openshift wow that's twenty percent okay encouraging so if you are thinking about using docker technology or you are using it already what I want to show you today is how you can take your doc raised application and you can safely and easily deploy it into any infrastructure location of your choice be it the public cloud private cloud on-premise off-premise physical virtual or even on your on your laptop so briefly what is open shift so open shift is a platform as a service that begs the question what is a platform as a service a pass so I explained it this way developers like to or most developers like to or should can't focus on writing good code they want to write a great application they generally are not interested in all of the bits and pieces around the application the infrastructure for example which which are essential to make the application work so these are things like the network the storage load balancers firewalls logging and monitoring all of these things generally developers not interested in so the platform as a service provides all of this stuff so the developer can focus on writing great code and this leads on to the open ship provides a development environment on demand so self-service the developer can go into open shift and through the website web UI click together an application with all the dependencies with all of these and all of these best practices using docker images and such it also provides a whole set of dhaka images with all the languages you need all of the frameworks and you might need and also databases so you can take all that well of baked in goodness and click together your application you can also you can do that through the web interface or through the command line openshift will also automate your application lifecycle so for the developer it helps the developer with the build cycle and also with the deployment and also maintaining application on upgrading application and this is also enabling collaboration because these things can be shared dr. containers and definitions of applications in openshift called application templates can be shared amongst developers and amongst teams so you can share that those different those definitions from the elements through tests and even into production and open shifted based on the industry standards is based on Red Hat Enterprise Linux we call rail and it sort of based on docker and many others so containers containers have been around for a long time about five six years ago when openshift the project the open source project was started and red hat was involved they've decided from the start to use containers so they had that insight and that that vision already another example of that is Google they have been using containers for many many years so about two or three years ago docker came along and what did they do how did they make containers so popular I'm not going to go into detail about the features of Daka that can be easily read on the internet but they simply made docker containers consumable and easily usable by developers so they provided them for developers so that developers could easily use them to create their snacks in stanchak containers run them and also very importantly share them and reuse them and that on docker created docker hub that's the community today we're developers can upload their images share them and reuse them it's extremely pop so doc docker containers are generally immutable so what does that mean it means that once they created their set in stone then usually cut out do not and are not changed at all right and this unit forms a unit of collaboration between the teams in the pipeline so this unit can be passed through development testing staging and into production so Microsoft it also encourages microservices micro service architecture can be highly complex you can have dozens or hundreds of services and each service could have dozens of containers running this creates a highly dynamic and complex system you cannot manage that manually so you need cloud technology in a form of a pass 22 to automatically manage that system okay an open shift is designed for microservices architecture so red hat decided to use dakka dakka technology about 23 years ago and they also decided on an orchestration engine and they chose Cuba Nettie's which is an open source project by Google it's a highly active project has many many commits per week and it provides basically the orchestration when containers are started when how long they run for when they're stopped it also can group an aggregate containers together and act on them as one one unit it has self-healing so if a container should fail or the underlying host which is running the containers fails it's able to spin those containers up again and has discovery as well service discovery so a pod or sorry a container knows how to find another container and connected so if you take vodka and you take kuba Nettie's and you try to put together a platform yourself you're going to run into problems it's not easy especially how are you going to keep it maintained and updated what are you going to be able to add all the bits and pieces that are needed to make a true platform as a service it's going to be difficult so this is where Red Hat comes in you can do it the Red Hat way Red Hat will take the source code red hats always working actively with in the open source communities and takes the source code and turns it into a well-rounded product so red hat will test that code harden that code support it provide training etc so it becomes a product which an enterprise can consume so you have to ask the question how how you be sure that of security how are we sure that your container images you're using do not contain any security problems and defects like Trojans red hat provides red hat enterprise linux as a secure foundation for this platform and also provides images which it will keep up-to-date and patch for you how will you be sure about the scalability are you able to test your platform that it will scale and the performance will still be good red hat will be testing the software all the time including performance testing so you can be should sure that the software will scale what about integration will the platform integrate with external systems red hat does this testing and integration certification work what about management hanging into management keep it up-to-date maintain it Red Hat can help here as well so let's take a little bit look look under the hood these two layers here the contain orchestration and can cluster services that's and also a little bit more below is Q benetti's openshift adds a whole lot more to turn it into a rounded platform-as-a-service so you can see at the top here openshift self-service obviously developers need to access open shift and use it and create their systems and they can do that by reusing the middleware and data services they can also access the service catalog and build their applications there's also the open shift application lifecycle management applications can be can be built other tools and processes built in to build your applications and also maintain them deploying them and upgrading them there's also a little bit lower in the blue box networking open shift comes out of the box with an overlay network or in other words a software-defined Network it's it's built in it comes with it and it's also very transparent you can just how it's that you just know that it's there it really doesn't have to bother you but you can replace it if you want storage open shift also supports stateful applications so you can install your database in there it's not just for stateless or ephemeral applications a doctor registry comes with it and is built in telemetry what does that mean that means there's an optional you can optionally install logging aggregation and you can optionally install monitoring so matrix collection and monitoring security it's all backed by red hat enterprise linux and selinux and you can choose to run it on red hat enterprise linux or atomic host what is the time I closed the sonic case is a new distribution based on rel and it's being hardened and this small footprint and it's basically optimized for running containers so this is what redhat called community powered innovation in the open source way openshift origin is the open source project behind open shift right so we call this the up stream project on the left or all of the open source projects hundreds of them small and big that make up openshift origin they are the upstream projects origin and origin openshift origin is the upstream of the products on the right those three products on the right are weird hats hardened and round the products ready for the enterprise red hat will give back or what red hat is very involved with these communities so any fixes hardening work all that goes back into the open source community and this creates a cycle of innovation a cycle of open-source innovation and because it's open source by the pure definition of open source it cannot be broken and it cannot be stopped so on the right of three products openshift enterprise that's the version that you can subscribe to and you can install it on any platform or in on premise or in the cloud you would have to maintain it yourself of course the next one is open shift dedicated that is a cluster of open shift which is provisioned by Red Hat and maintained for you by Red Hat online open shift online is the usual type of cloud service it's on demand and pay-per-use interesting with the open shift online is that there is a free tier and it's unlimited with time so you can you can use you can deploy two or three containers with small applications and let them run forever so you can see from the numbers here how successful openshift online has me I'm not going to go through the numbers but you can read them for yourself now it's important to note that the current version of omen shift online it does not support docker it supports different type of Linux container technology version 3 which is which is in right now in pilot will be available after the summer okay so when you log in today to it to version 2 overshift online you're going to read about cartridges and not docker containers right so if you're reading about cartridges then you're looking at the old version i recommend you read about the newer version which is coming very soon and all of this is also running on amazon web services so let's have a little bit look at openshift dedicated it's managed built and managed by Red Hat so you can rely on Red Hat's engineering and operations and support this is what you get so for the base package you get four instances all of the hardware or the infrastructure which makes up the let's say the management of the cluster of the open shift cluster all the Masters and all the infrastructure knows it's there all highly available highly available and they're all included in the price you can attach EBS volumes to your containers and as usual the doctor registry comes included now it's important to note that all of this is provisioned and maintained inside Red Hat's virtual private cloud not in your v pc so you don't have access to that vbc buds you can connect to it you can connect your on-premise data center to the Red Hat vbc where openshift dedicated is running or you can create your own vbc and connect through the private network amazon web services private network to to open shift and accessing open shift dedicated developers and the axis admins are obviously access over the internet so this is a very high level architecture view of openshift i'm going to now go through a walkthrough and why do I want to do this because I want you to gain an appreciation of what or how openshift works so you can understand what it offers open shift will run wherever rell roll around on that is very flexible so it can be physical virtual private public or even on your developer laptop there are two main components to open shift the master and the nodes and the compute nodes that's where your application will run those nodes can either be rel or atomic host so your cut your application containers run on on those compute nodes and they are called pods so how do pods come about how are they created open shift comes with an ability in registry on the right when any container is instantiated the docker image is taken it's pulled from the registry and a container is created that container is then put into a pod and a pod is nothing else other than a container itself a pod can contain one or more containers so why why do we do that in many complex applications you need to have containers sometimes you need to have containers closer together so for example they might work more cohesively together they can share resources like for example a filesystem one my write to the file system one might read or they can use inter-process communication for example so that flexibility there the other thing is a pod works as a single unit when a when a container is created it's created as a pod with all the containers inside and if it's scaled all those containers within those pods are scale with it so it's one unit yes and that also a part gets a verte your IP address so it's like a virtual host that's essentially what it is a virtual host so then the other component are the master so these are the brains of the system they keep the state of the cluster so let's go through what the master does the master has an API against which you can authenticate everything all the requests coming into system go through the API so all the requests from the web interface from the command line interface from various developer tools they'll go through the API there's also authentication there's role based access control i can define specific access to the cluster for for developers which might be very different to the access from administrators there also you can also define projects which is basically just a namespace so that developers are from different teams can work in different projects and they don't stamp on each other's toes the master has EDD as a key value data store that's not persistent for your applications it's not persistent storage for your applications it's persistent storage for the state of the cluster for maintaining openshift now how it works is this some of the components of the system might write to EDD CD and some of them might be watching for changes and they'll see the changes and then change their state to that effect of one example is a user might request for an extra pod to be created an extra container the replication controller will notice that and then instantiate a new pod now the shedule now that's what decides where the pods should be launched onto which computer node now by default there can be more or less a random compute mode so how how else does the church of the decide where to place the pods onto which node so you can use metrics for example CPU if the CP utilization is not very high on a particular note then the pod might be placed there other ways are using labels so you can label a set or a group of nodes as an example see the top three nodes you could place them or label them to be in availability zone a and the bottom three you could label them to be in a veil ability Zone B and then you can use affinity and anti affinity rules to ensure that pods are placed into those groups so anti affinity rules would mean the pods would be placed into both evenly into both groups into both availability zones for high availability and affinity rules would mean that the pods would stay within a group so that they can work more cohesively together so if pods can seemingly be randomly placed onto nodes how does one pod know how to find and connect to another pod does a pod have to keep track of all the pods in the system no certainly not so that's where the service layer comes in the service layer is an object it's like kind of like a middleman or a proxy it keeps track of a specific pod or a specific set of identical pods and it provides a static address for other pods to use to connect to that address could be a static IP or a hostname the service also keeps track of all of the identical pods which is using which is managing and if a pod should go away or if pods should be added it takes away that it basically maintains a list of those are those pods and the service object acts as an in basically effectively an internal load balancer so you can use it for example if you've got an a multi-tier architecture that might be your internal load balancer between the tears or if you've got a micro services architecture it would be the load balancer separating the different services so the replication controller that's the part which decides when pods should be started how long they run for when they're stopped and should they fail so for example that pod there is burning down its failed that the replication controller will will discover that and it will ask the scheduler to replace the pod on a different node and whilst that's happening and eat the service layer will keep track it will know it will realize that pod is gone and it will take it out of its list and stop sending connections to it when the pod comes up on a new node it will add that pod to its list so you can use persistent storage in open shift and the way it works is this the administrator will carve out a pool of storage and the developer the very model is not really concerned about how that storage is managed the developer just needs 100 gigabyte and will request for that chunk of storage and connect that storage to it to his pod so that means that the application is reasonably separated from the type of storage so you might go through development the developer might be using very simple storage or NFS go through testing maybe we're using something more sophisticated and in production they're using something for example like a high skies ii like like i mentioned earlier openshift comes out of the box with an overlay network but from the out from an external network into open shift there is no route there is no route into this overlay Network it cannot be routed so we need a routing layer that it basically enables connections coming into openshift to be routed to the correct pardon or routed to the correct pods if its load balancing so developers administrators can access open shift through the API they can use the web interface the command-line interface and various plugins for example they can use their ide to interact with openshift jenkins is a great example jenkins plugin can do that or Jenkins can use the command line interface to interact with open shift as well so so that was the walkthrough now I'm going to touch on something else this is called source to image this is another open source project which is embedded into openshift this is a great way for developers to build images if they use this they do not necessarily need to create dhaka files themselves the way it works is this this build the image usually provided by Red Hat is specific to a language right it contains all that for example PHP needs all the dependencies and libraries when the developer wants to build a new image using this this image will be instantiated as a container and the source code will be injected and the application will be built but in the case of PHP nothing is built but it's just injected there once it's what the build is complete a new image is created and put back into the registry so once it's put into the registry it can also trigger automatically a new deployment of that image into the cluster there's another interesting thing about this is that the if these images are maintained by red hat and red hat catches these images because of a security vulnerability you can automatically detect that and set the whole process in motion again to rebuild the new image and automatically deploy that image into your development environment so I just want to touch on this DevOps open shift can be a driver or a catalyst for DevOps because it comes with a lot of the automation standardization and the processes which are needed for DevOps so if you had if you put your best team in front of open shift and you teach them open shift or you bring that team into Red Hat's incubation lab who you will learn how to use open shift and you will learn a lot of the DevOps processes I'm not saying it's the solution for dollops it's not a silver bullet but it can facilitate your journey through devops here's an example of one of our large customers if you make a flight an error flight booking or hotel booking in many countries of the world very likely that booking record will be stored in a MIDI haces data center in Germany and they have a huge load look over 1.5 billion requests per day for example and what do you know what design ideas get out of open shift they have this unified process and it basically means two things they can define an application made up of all of its containers and how they interact together and they can take that definition as an open shift template and they can move it through the through the development pipeline development test staging and even into production and they also because you can install open shift anywhere in the cloud on-premise for example they can be sure that they can deploy that application into any of those environments that's something that they want to do because they only have a data center own in Germany they want to be able to exploit the cloud so they can be closer to their customers and latency is very important for them so if you want to go away today and you want to try out openshift the best way to do it is using Amazon Web Services test drive you can go there fill in a form and a cluster will be spun up for you you can use it for an hour to another way is you can install it on your laptop and what I recommend you do is install the container development kit the cdk if you go to this URL tinyurl Red Hat cdk you'll come to a blog article which explains all about the cdk and how you can use it and I'm happy to say since a few weeks Red Hat have at last created a free developer subscription so with that developers of subscription it has a developer of course you can run the full version of Red Hat software and of course red hat is renowned for its training we have training available for for open shift there are also free ebooks available q benetti's dr. security from a variety there's also the three little pigs coloring focus the interesting read you can learn about docker when you finish you can give that to your kids to color in open shift has won many awards so I cannot even list them other way it so it's a huge project red hot it's really really active so you can rely on redhat because this is such an active project and red hat is basically supporting and maintain this very well so I hope that you've got out of this talk that a you know a little bit more about open shift and how it works what it can offer and especially that you can run your containers using open shift in any environment so I want to thank amazon web services for having meet to talk and i also thank you for staying here until now I'm not falling asleep thank you very much 