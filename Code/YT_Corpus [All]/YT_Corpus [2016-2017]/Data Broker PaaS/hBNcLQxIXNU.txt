 hi Alex Williams of the new stack here today with Casey Wes of pivotal hey Casey hello Casey today is going to show us a few things first he's gonna show us a developer centric look at cloud foundry and how it can be used by developers on a day to day basis he's also going to do a demo for how to deploy docker in the cloud foundry ecosystem and then he's gonna have a little surprise for us and so we'll save that one for later but Casey good to have you here tell us a little bit about yourself and what you do over pivotal sure thanks yeah I'm on the the outbound team at pivotal for advocacy and outreach so although my career has been about 16 years of building software mostly on Internet infrastructure and security I decided about six months ago to join pivotal and start spreading the good news about what it's like to to have and use and operate Cloud Foundry so that's what I do over there my title is principal technologist for a cloud foundry well excellent so why don't we get right into the demo yeah so we'll start by examining our gem file here a typical way to look at our vendor to put dependencies in Ruby we're gonna see that we're going to use a relatively modern Ruby version two to three Puma is a web server that will actually negotiate the web requests for us and then some basic Sinatra libraries so the first thing I want to do is jump right in and show you the the app again very very simple here we have some basic requires of Sinatra we're gonna bind to it the IP address that says we can talk from any incoming request that's so special 0.0.0.0 and then here's a demonstration of one of the tenants of a 12 factor application or an application that we like to refer to as being cloud native which is to get configuration information from the environment in this case we're going to get our port number from the environment and that's something that Cloud Foundry will provide to you so when spins up an instance of your application it provides a dynamic port for you to bind to and as long as you're listening on that port for incoming requests and sending your output in the same way then you'll be able to to negotiate Network communication for your application then we have one very simple thing that we do here which is when we when we call this web service at the root we will return a small amount of JSON indicated by the JSON keyword here and it will be a key of instance and then the value will be another environment variable CF instance index is an environment variable that Cloud Foundry also provides you to give you information about which instance number you're running so when you spin up an application you might begin with one instance but that's not very scalable it's not very high availability and it certainly won't let you do a lot of concurrency in in your application so as you spin up and scale out a horizontally scale we call that you'll spin up new instances and each of them will have a unique index this will allow us just to see that everything is up and running and working properly so this is a basic API and I think that what we should do now is probably go ahead and deploy it so to do that there's a command-line utility that's part of Cloud Foundry called CF and when you first attempt to you see if you get a lot of helpful information because there's an incredible amount that you can do with this command-line utility it's written in go it's easy to download you can get it off of github I should actually pause here for a moment and just let you know Alex that everything I'm showing you here today is actually all open source Cloud Foundry so if you wanted to download and get up and running and it's the Cloud Foundry whether it was on your laptop like I'm doing here for demonstration purposes or in AWS everything that you'll see today is actually fully open source and and you can do it without without talking to a vendor but if you wanted to you know we're always here so tell us where people can get access to the free version of class yeah so the the place to start really is Cloud Foundry org so for folks who might not be familiar with the Cloud Foundry ecosystem there is a foundation that owns the IP the intellectual property of all of Cloud Foundry core and the development that happens on Cloud Foundry on a day to day basis is provided primarily by members of of this foundation and that includes companies such as pivotal IBM HP and and many others and then some of these companies including the ones I just mentioned are also vendors that provide commercial distributions if you wanted to take advantage of additional function amount functionality they may bring to the table but you can start here and you can also go to github.com slash Cloud Foundry and that's a place where you can find many many repositories that comprise the entirety of Cloud Foundry the two that I would say to look at if we're going to highlight any would be the CLI which will be the command-line utility that you'll see me use that's our primary interface interacting with the Cloud Foundry platform and the other one would be CF release CF release brings together all of these components into a release that gets updated every week it's got a very confined Ria's a very tight and consistent update cycle and you can actually see that when you go to see all of the tags for releases every single week a new release is cut with whatever is stable and ready to go it's a very very mature continuous delivery model so we're up to version two to seven and I think there are more than a hundred releases just on github here from the last couple of years so that would be where I would go to go check it out so I mentioned that CF is our primary interface to interacting with the platform I want to show a couple of quick commands CF apps can describe the apps that we have running I do have a couple running as backups just in case live demos don't work out the way that I hope they would let me actually make this a little bigger so we can see it so this this describes the applications that we have running now I am in my in my cf env directory this has my application that we just looked at in fact if I look at app dot RB we'll see the same thing that we saw in our in our text editor and the way to deploy an application in cloud foundry the only thing that you really need to do on a typical basis is do a CF push so I will do that now and while that's happening I want to take a look at the manifest you'll see here at the top it says that it's using a manifest file in this current directory mm-hm I want to open that up and describe that a little bit Cloud Foundry like many other systems uses a manifest to describe some basic operating expectations for an application so it's a ml file and you can see that we list an application called CF env a basic memory expectation this is actually constraint and this constraint goes all the way down into the container layer because every application that runs in Cloud Foundry is running in a container and those Linux containers are to be able to isolate and constrain the resources used by a given instance of an application yeah yeah the mo file is like almost like the contract isn't it it basically describes everything so so the developer knows exactly what to do it seems to be becoming a hallmark of overseeing with the micro services that's right that's right and actually you can also compose a series of applications here that should all be spun up together which is very similar to a docker compose which has the same kind of qualities in terms of its its descriptiveness absolutely yeah yeah so we have an application up and running and what this did is it actually built a container using the Ruby build pack and the build pack describes all of the vendor libraries and software that needs to be laid down on a base operating system in order to run this application so it knew that it was a ruby app and it also installed all of the gems which is that vendor management component it added our application into the into the container and then once we had that container which we call a droplet within the Cloud Foundry because system then we were able to actually get that droplet up and running so we wanted to start one instance and we knew that we were going to run a ruby command in order to do that and now we have an instance running so what we can do do we could certainly go to this instance in our web browser and we'll see it here it's a relatively unexcited demo in this way I can also curl it if we want to and this will come in handy later and we'll see that we have instance 0 one of the first things that I always like to do as a developer is to see what happens when I have a few instances I found that the majority of problems that developers face when they're getting into the notion of distributed or parallel wear clothes those those issues arise whenever you go from one instance to two but if you already have two instances and you can get to you know three or 300 usually you know really see the same types of problems these are usually problems that manifests from not having a 12 factor app and just to just for completeness here it's always good to point out that there's an excellent website called 12 factor net which describes a series of constraints that you might adhere to as an application developer in order to reap benefits of platforms like Cloud Foundry it was actually written by their Heroku scheme and it was for their platform in particular but these are very Universal and generally considered to be best practices in the industry so for any developer who hasn't read through this there there's a lot of great writing here on this site so I highly recommend it but why don't we go ahead and scale it up so we've pushed an app we can see that it's running and scaling we'll go to two instance for example two instances for example is also very simple you just use a CF scale command and then we have a couple of instances and we'll actually take a look at that by using this CF app command CF app will give us some basic operating information for the application that we request in this case it's it's the CFA env app we can see that that we two instances running and I think that we can actually test that out in a couple of ways one way would be to come to our web browser here and reload a few times and you can see that our instance number changed from 0 to 1 so we're actually round-robin getting routed to to our each of our instances as as we excuse me as we go through and reload we can also use curl on the command line for example so we'll use a simple while loop and we can we can see that as we make requests we get a different instance numbers another important aspect of running in a distributed environment for developers is being able to get at logs if you can't read your logs easily especially among a plethora of potential instances then becomes really challenging to divide problems whether they're in production or in a staging environment or what have you so we have a solution for that in cloud foundry as well is there so how do you monitor those logs just what you're gonna show well so I'm going to show the I'm gonna demonstrate a particular aspect of that there are a couple of things when it comes to monitoring within distributed systems but one of them which cloud foundry does take care of for you is the aggregation of those logs to be able to get a single stream of logs from a multitude of instances so what we're seeing here is streaming of HTTP request logs these this is what Sinatra spits out on unstandardized and 'red air and we're seeing that live as we make requests here on the on the left side so your point Alex it's important to to note that Cloud Foundry does not have a built in log analysis or monitoring tool system but because the the streaming output is aggregated you're able to submit that to something like Splunk or variant house elk stack or a graphite system if you want and you can do that monitoring analysis on your own but that is one of those places where the line is pretty clear between what Cloud Foundry does for you as a platform and what you have to bring up to support you know you're you're monitoring operations it's a good yeah yeah I think so and it's also important to know that foundry itself as a platform of course it's a it's a collection of software and it's it's a distributed system all on its own and it has its own logging firehose if you will for all events that happen in Cloud Foundry which you can you can also send those out to to your logging system but that's that's at the operator level and that's not quite as applicable to your everyday developer this gets to the heart you know of what I'm familiar with about Cloud Foundry and that it's and it's opinionated for a reason right there's a you know you do want to have those different capabilities baked in but you have to have constraints too so yeah so it makes sense then to constrain kind of the capabilities of the application and know what it's good at right yeah I mean the constraints allow the platform allow Cloud Foundry to keep promises for you and as a developer what you want to do is be able to iterate quickly and reduce your risk and if you adhere to the constraints that Cloud Foundry asks of you as a developer you actually increase the power and the effectiveness and the and the resilience of your software so so there are some some clear upsides but there's no doubt about it that you have to be willing to accept the opinions of the platform as your own in a way yeah and and that can be challenging at times it's especially challenging for four teams with existing software especially larger teams or legacy software where they want to get them running on a modern platform like cloud foundry it can take some effort to to retrofit or there's a term that's used these days forklift your application into the cloud and so it's again I think important to note that you'll have to do some work there but it's often worth it in the long run mm-hmm so we have an application running it doesn't do a whole lot and I think that you know after you get a prototype out the door the next thing you do is start fleshing it out and so I like to say from here that what I'm going to do is create more integrate enterprise-grade functionality for this application it's a little bit tongue-in-cheek and you'll see why but I'm gonna check out a branch called enterprise features and we're gonna take a look at this very few applications that you run run in complete isolation and in fact most of applications have to interact with some dependent system and that's off in a data storage system and so in this case for the purposes of this nice simple demonstration we're going to include Redis and we're gonna use Redis in order to do some basic analytics so we are also using a gem called CF app utils which in in the Ruby ecosystem is actually a nice way of interacting with backing services and Otto's auto discovery information for connecting to those services and we'll see that we'll see that in the app here so the app has changed a little bit it's actually a little bit longer we have a class called analytics and I think that you know as long as you add analytics to something you can call it Enterprise grade as the job that I go with but we need to create a Redis connection and in order to do that we need to get credentials information this also demonstrates another aspect of a fully featured platform which is there will be a Redis running which this application can connect to but in order to understand its hostname port password you know other types of credentials you don't want developers hard coding that into their into their into their application and you don't want them necessarily putting it in in revision control we've all probably either been there or had a colleague who's been there when they've unintentionally committed an AWS key to the github repo for example which is a which is a sad day for everyone when you realizing yeah you're paying for for Bitcoin mining and you're not even getting any of the profit so so this this class will attempt to get credential information off of the environment the way that it will do that is with the CF app credentials under the hood what's actually happening here is that there's an environment variable provided by clouds we called vcap services and this is actually a JSON payload describing any backing services that you have bound to this application and we'll go through and show you how to do that in a second but if there are any for Redis and they have these tags so for ravenous reticent within pivotal then we will go ahead and get that information and and provide it to Redis if there aren't any then we'll just go with the default and in this case this happens to be a Redis URL environment variable that the library will read which is a pretty common thing across all Redis libraries and almost every every programming language and environment and that could be helpful for local development if you weren't running us on the platform but today we are so we can just we can just base this on the platform and then we have a method called visit and what this is going to do is increment the number of visits we get so we're using very modern technology to implement a 1997 era visit counter cgi but you know bear with me so we've updated our JSON payload not everything is brand new right that's right that's right everything that's old is new again so our JSON payload will have an instance as we saw before but it'll also list the visits now this will demonstrate nicely a horizontally scaled application bound to a central data store and the fact that the stateful information that you're prove that you're sending to that data store remains stateful across all all instances so if we want to deploy this so we actually have a little bit of groundwork to lay one of the one of the things that I think is really interesting about the Cloud Foundry platform is if it's broken down to two primary layers there's Cloud Foundry which is very application centric and we've been interacting with that a bunch and then underneath of Cloud Foundry is an infrastructure automation and lifecycle management tool called Bosh mm-hm and and you can go to Bosh I believe it's Bosh gorg or uh-oh you can go to botch that IO to learn more about Bosch this is also a fundamental part of the cloud foundry ecosystem so it's also operated by the foundation and the thing about Bosch is that you can release many things to it we release cloud foundry to it that's actually what the CF release repository is that I pointed you to earlier but we can also release things like Redis and we are able to do that in a relatively high availability way and with auto provisioning which is what I've done here the way that as a developer I can I can understand what services are available to me to provision and use is to is to use CF Marketplace so we have a marketplace in this case my marketplace only has an instance of Redis because this is a small environment I've set up for this purpose in a more fully featured cloud foundry environment you'll actually see the ability to auto provision things like Redis MySQL RabbitMQ Postgres Cassandra many other things that that you might need to take advantage of there's Hadoop and monitoring information for historic swith in the spring ecosystem that sort of thing and so what we're going to do is create a service instance so we what we can see here is that we have the ability to to create Redis instances but we don't have any Redis instances and we can we can actually demonstrate that with a CF services there are no services which have been created but in order for this application to work we need an instance of Redis so we'll create one and we'll use the create service command we want to create a service and it will be a type of P Redis and the plan that I'm going to use is a shared VM you can do shared or dedicated the distinction here is quite literal in that a dedicated Redis instance will use Bosh to auto provision a new virtual machine running Redis and the only thing that will run on it will be your version of Redis sherig will run multiple isolated instances of Redis on a single virtual machine so that really is a distinction we need to give it a name so I'll call it CF env Redis because it is in the backing service for the CF e and B application now we have a service and we'll look at our list here this is another interesting application for Cloud Foundry which is that just because you have a service doesn't mean an application can speak to it you have to explicitly allow an application to talk to a service and you do that through a binding mechanism conceptually this is similar to the idea of localized networks of pods and kubernetes however architectural e and the way that workloads are laid out within the cloud within cloud foundry it's it's not the same but but again from a developer centric point of view you can you can think about it in a similar way what are the distinctions then that would be a note for a developer the distinctions between the two you mean yeah yeah I think from a developer's perspective there aren't a lot of differences that you actually need to pay attention to I think the differences are primarily on the operator side the the plan of how to how to distribute work across a cluster of compute resources is something that should be left as an exercise to the platform it's not something a developer should really worry about too much and I think it's it's it's accurate to say that the plan that Cloud Foundry has is typically 2 to co-locate the pool of resources for application instances for cloud foundry within within one section and then you're backing services typically are provisioned in separate sets of virtual machines so you don't quite have the the location locality that you get from kubernetes which is more of an operational distinction but from a developer point of view as long as you're practicing reasonable practices around service discovery you shouldn't really see a lot of difference so let's go ahead and bind this service to the application which we just did there and we give this helpful tip that in order to inject information onto the environment for running instances about our new backing service we do have to restage or restart that service because environment variable information is only provided at startup time and then it's immutable and another key aspect of this to know is that what we've done is we've created a service through what we refer to as a broker and that broker means that there's a Redis instance and there's an application and in between the two is this binding and that binding actually manages the credentials and it keeps that those credentials encrypted at rest and it keeps them it's in Auto it Auto creates them it generates them and manages them itself so the broker is actually responsible for the authentication information between the service and the application and when you restart the application any bound applications the broker will provide that information to the application at that time now what I'm going to do is just push a new version of the app because I have this this more enterprise-grade version here ready to go I'm doing this manually but I think it's important to take a step back and recognize that the actual deployments that I'm doing here manually for demonstration should be done by something like Travis or Jenkins or another CI tool you should let your robots do this typically you wouldn't be doing it manually but if you're just playing around if you have a developer you know sort of sandbox area then it's more than fine to be doing this manually and so what we have here is we restarted our application we still have two instances let's scale it up a little bit for fun - for we'll say and I need to remember the CF at the beginning of that command and I think what we'll do is continue to tail the logs while while doing a little bit of a loop here and we'll see what we get so what we can see here is that while our instances are variable we're Cloud Foundry provides a router internally which automatically does load balancing for us so we don't have to actually configure anything when it comes to routing requests to however many instances we have but you can see that our stateful information about our visits keep incrementing so that's pretty helpful and then of course if we were in an actual browser we can see similar things happening here so that's pretty handy so that would be what it's like to sort of do typical development and pushing pushing things to Cloud Foundry some of the highlights here are that you can scale up your instances to respond to your incoming workload or your incoming requests load without having to reconfigure firewalls or load balancers or anything like that that's pretty helpful you can aggregate your logs to see what's going on there these errors are because I don't have a humans txt or robots.txt file and that's what you know chrome expects all the time and also the auto provisioning not only of being able to spin up the instances and get a get a URL for them make them routable but also be able to spin up services that back your applications relatively painlessly and then connect them to your application so I think that's some that's a pretty decent demonstration of typical work now the thing that I think we could move on to if you like is there's some new work it's still considered beta but I have it operating on on my instance here to be able to to spin up applications that are actual docker containers so it might be nice to take a look at that and see what that workflow would look like I mentioned before that the applications that I'm running now are running in containers there's a key difference between the Cloud Foundry ecosystem and the cycle of building that artifact the image in the docker world and then shipping it around and spinning it up in Cloud Foundry you do a CF push and Cloud Foundry as a platform behind the scenes it sends up a task to create a container for you and wrap all that up make it immutable put it in a place where within the platform it can be shipped around and spun up as needed okay within the docker ecosystem you're typically a little more hands-on in building a container pushing it into a registry or repository and then you know writing some automation or using you know tools like like kubernetes or dr. swarm to to pull them out and spin them up on your computer your sources so I think that the the primary difference here and one of the things to keep in mind is who's responsible for building that artifact and maintaining it which is very similar to the docker model is very similar to your operating system model with app repositories or you know rpms in the Red Hat world someone is building a package putting it into a central repository so that it can be pulled down and and installed in a distributed environment so the Cloud Foundry ecosystem being relatively self-contained the docker ecosystem operates in a different model and that's something to note but when it comes to actually running the containers and they and the benefits that you might get from from a platform like Cloud Foundry the workflow is actually very very similar and you get a lot of the same benefits so I think that might be worth taking a look at ok so this application that I have here I'll actually go back to mine on enterprise grade version and there is a docker file which I want to look at here so I've built a docker container for this application and and this is an example of the work that you would do in order to put together a typical docker container and I've already built it and it's probably not worth our time to rebuild on the show here but but I'll just run through it really quickly I start from Alpine Linux which is getting a lot of traction these days doesn't it it is very lightweight very security focused and so it creates containers that are much smaller which just simply makes them easier to strip around and easier to manage so when you say when you see a command like a PK if you're familiar with apt-get for example you'll find a PK update would be similar to at get update and similarly for installs but in any case we'll just run through this very quickly we set a ruby version and all of this work here is to install that version of ruby which is a bunch of work that you have to do and similar down here and then you also have to install bundler which is what provides the gem file vendor management and configure bundler appropriately and then you can add the application and run bundle install which installs all the vendor libraries and then provide it an entry point for actually running the running the application so this is a pretty lightweight docker file folks who are familiar with building docker containers who who are using them say in production or as a major part of their ecosystem would be quick to rightly point out that the bulk of this work would be done in to create a base docker image like a base Ruby image for example and then this entire docker file would be much smaller but for the purposes of demonstration I think it's worth it's worth at least seeing the work that goes into building a container from scratch right so there are ways to manage this that are a little more robust especially if you're doing a lot of work with with containers I think an important thing to point out here is that there's a lot of similarity because all containers are Linux containers at the end of the day there are series of Linux kernel constraints wrapped around a file system and and what cloud foundry does with their build pack model is very similar to what we see here in this docker file which is that we start from a base file system in our case here Alpine Linux we install all of our vendor information into into the container on that file system that's what the build pack is primarily responsible for and then we add our application and we explain how to run it almost identical frankly to the way that that Cloud Foundry builds containers the key technical difference is that we use a different file system format so the darker file system is a layered file system whereas the Cloud Foundry file system is kind of comprised of two layers of read-only layer and then what you have for adding your application but but those differences aside it's interesting to note that the way that you build containers almost no matter what format you're using are is pretty much the same so this would build a docker container and you can actually if you felt like it you could go to docker hub and take a look at this you can play with it if you want to but I have a container called CF env - docker and there are a couple of tags which actually just follow the big it branches that we're using today for this demo master and enterprise features but we can take a look at this and give it a shot at installing it so to deploy a docker container you do need a recent version of the elastic runtime for cloud foundry which is called Diego a couple of months ago it was released with docker support and you have to enable a feature flag to get that running you can see your feature flags with CF feature flags as a little bit about Diego for people who may not be familiar oh yeah sure sure so so when cloud foundry was first released the original the original scheduler was called DEA we had a whole theme around a law enforcement when it came to operating operating workloads and managing their constraints and making sure that they were within their constraints so we had we had this concept of with the EA and because developers are fantastic at naming things when we when we went to rewrite that and we rewrote it and go we decided to name it Diego and that's just what we did but Diego is is the version 2 of Cloud Foundry silastic runtime it it also built rebuilt our our API for running and managing workloads or containers which we call garden our format for containers is referred to as the warden format warden has been around for at least four years so it does predate docker as a format for containers which doesn't make it better or worse or anything it just just has been around for a while and so this rewrite was a rewrite to go which had certain operational benefits it was much faster very simple and that was helpful easier to build and maintain but Diego operates similar to many other workload scheduler so it can do long running tasks like server based work and it can also do short running tasks like but it's called Diego because is Diego and just written go right that's right yeah so it has almost all the same operational properties whenever we're thinking about a developer centric view but it was built with a few key benefits and one of them was this pluggable in architecture for running containers called garden so with garden one of the interesting things that we get from Diego is that we're able to run garden Linux containers and that can run word in containers or or docker containers and because it's all plugged into cloud foundry that means that you can orchestrate workloads which could be Diego or could be awarded based containers that are built with build packs or docker basse containers built in a in a docker ecosystem format you can orchestrate those and manage them and admin them from a single platform so that's a really interesting capability we were actually able to extend that working with HP and Microsoft to get workload orchestration on windows of dotnet applications so in addition to that when we when we think about this pluggable interface there's a there's a project called garden windows that allows you to do dotnet apps now in in Windows 2012 Microsoft is very clear and we're very clear to note that you should not do multi-tenant capabilities whenever you're trying to orchestrate net apps on windows because while you do have some ability to do some process isolation in Windows 2012 it isn't it isn't universally secure so you want to be you want to be orchestrating workloads that that are in friendly environments so that means you know don't run your your your public pass doing this or anything yet Windows 2016 will not only have a much better container support as part of the Windows 2016 kernel but also docker is working heavily with Microsoft as well so we'll see docker as a native capability in Windows so that's pretty fantastic so that's really that's the primary benefit that we get out of Diego is the idea that within any heterogeneous architecture and most architectures at any any level of scale especially in enterprise environments are often heterogeneous so you've got you know everything from Java to go to dotnet but laying around somewhere and the idea that you could actually manage them all from a single platform is pretty thought-provoking and I think pretty powerful so that's one of the things we get from Diego so we have these feature flags and you do have to enable the Diego docker feature flag right now it isn't on by default this will change over the coming months but but as it's still in beta we're we're still ironing out some of the kinks but I want to I want to show you anyway so the way that we deploy docker container and I'll just for review all show you the apps that we have running I do have a couple running as backups but I want to deploy a fresh version it's very similar to the way we deployed cf env and I'm just going to go to my home directory for example because I was in that source code we'll probably sore skoda directory and I just don't want it to some muddy the waters of this demonstration but we're gonna go ahead and do a CF push we do need a command line flag docker image and I'm gonna provide the information from the public docker repo that I have up there KC West CF env docker and I want to deploy the the tag the docker tag master in particular and the only other thing I really have to do here is provide the name of this application which will also provide an automatic domain name for me so this should be all we need to do to deploy a new version of this application but it'll be a version that was built as a docker container it does a lot of the same things that we saw from the build pack model except that it doesn't need to use a build pack in order to build a container what it does is it still creates a container and this is a technical nuance which I will explain so we have a running instance by the way so bill pack burst container don't you know is there the use cases that apply to either one can you use just both for whatever environment you want to what you're building in what is there distinctions that you guys are thinking about yeah yeah I think so so for most applications that you're building if you're the developer or the development team for an application I think it's important to say that the container format that you're using if you're going to use containers in order to build immutable artifacts that can be that can be spun up in a platform it's really inconsequential it's a consequential that you're using the darker format or the word and format or you know whatever format comes out in six months because there will probably be a new I think I think what is consequential though is what sort of supporting infrastructure you have to manage the running instances of those containers to be able to make it easy for you to not only develop but but operate your your application keep it up and running and healthy over the long haul and so when right now I know it's it's well actually about a year ago it was very fashionable to talk about the container format and to get everything into containers and as long as you had a container it seemed like everything was going to be alright and these days I think the same types of conversation are happening around the scheduler space because there's a lot more choice a lot more projects coming up and getting mature and actually being used in production you know you've got you've got kubernetes you've got nomads you've got doctor swarm mesosphere you know does a good job with marathon or you know Twitter stuff with Aurora and and all of these choices and all of them are really getting battle tested I think you know that's really where a lot of them unshare is that right now and they're talking about that problem yeah Cloud Foundry has an answer to that problem in in its scheduler with Diego but then adds a bunch of additional things and this is what we sometimes refer to as or I like to refer to as a minimum viable proper a tional characteristics your production environment needs to exhibit in order for you to be able to maintain a distributed system at scale so you do need a scheduler you need something that's going to do automatic health checks and failure recovery you need a log aggregation you need a dynamic router and load balancer you need something to be able to manage and distribute those immutable artifacts whether they're docker containers or you know droplets in the Cloud Foundry ecosystem and you need service discovery and automatic service provisioning and I think if you have these things and you've got a pretty mature operational model for managing a complex architecture so you know I I think I answered your question by taking taking it to a slightly different level but I think it's important to to say that you know having a container doesn't solve a lot of your problems but what you have to actually manage it manage that application and and scale it and keep it healthy is much more valuable and I think a more important conversation to be having yeah it's a progression that we are definitely observing you know in our own research of you know the ecosystem and just the container format itself you know has value but there's really now we're looking at building blocks more than anything for how you're building out these Malee's modern applications so they can be no flexible and you can use them you can develop them or you know business needs that may change or new features you may want to provide right absolutely and I do think that right now while you know we you said it before Cloud Foundry is is very opinionated and if you are willing to adopt our opinions as your own then you get a lot of benefits out of using using Cloud Foundry it's it's all of those building blocks put together in a way that that works day to day um but there's still a lot of value and a lot of excitement around get collecting those building blocks and putting them together on your own and certainly there are so there are some ways that that makes it better now when it comes to whether or not in Cloud Foundry you would run a docker container versus running running a build pack based container inside of the the platform like I said most of the time that that doesn't really matter one of the things that I hear a lot when I talk to folks about about cloud foundry and about docker support is the idea of not wanting to be locked in not having vendor lock-in so if I can build a docker container if I can run it in cloud foundry or I can run it in you know docker swarm or in kubernetes then that makes me feel a little bit safer about the idea that I'm not putting all of my eggs in the Cloud Foundry basket in case I don't like all of the opinions of Cloud Foundry now I argue that the work that you do on your application within its architecture to make it capable of running in a container in the first place running in a healthy way in the container that's that twelve factor cloud native application model all of that work is the actual hard work of getting an application to run in a platform or on a distributed scheduler and if you've already done that work whether or not you're building you're doing a CF push and letting the build PACs fill up your container or whether or not you're running a darker build that's an minuscule amount of work to go from one to the other so I often have to remind folks that the actual legwork that they've done is in making a cloud native application in the first place or potentially refactoring an existing application to be cloud native I had a conversation with Cote as part of this you know the seriously discussions were having with you guys and he also made the point that you know what you're trying to do is differentiate the application itself right that's where your time and energy really should go yeah I often ask folks who who want to you know build a great platform and intern inside of their own company I asked them how or I asked them what do you want to be the best in the world at right art is your company is your organization or your software is it building the the next great platform or is it building the next great you know uber or whatever it is that you're you're up you're up to and if if it is a platform that's great and you know maybe maybe you'll join you know pivotal or IBM or we're Google and in their effort someday but chances are the thing that differentiates you and makes your business great doesn't have anything to do with that right most people are just building software right they want to you know to do something that you know makes what they do unique that's right now I mean I think the important thing is that you want something that is going to work and let you sleep at night and feel comfortable and feel like you're not at risk and so as long as you whether you're not you're you're taking those Lego pieces and putting them together yourself with with an unstructured platform approach or you're using something like Cloud Foundry as long as it works every day and you know you can focus on on the task at hand at that differentiating value that you're creating I think that's that's where you get a lot of benefit so what we have here just just to jump back to this a little bit is we do have an application running that is a docker container there's a technical detail that I think is important in our current implementation it doesn't matter for the typical developer but people are often interested in hearing well how are you actually running the docker containers we're not running the docker daemon as you might typically run on a virtual machine part of that is is that that daemon is a potential single point of failure that you have to monitor and keep up and running and if the de mer daemon goes down all instances become unreachable and that's a concern that we really didn't want to have to deal with so going back to what is a container it's a series of it's a series of metadata about Linux kernel constraints wrapped around a file system you can also unwrap that so the approach that we've taken is to actually unwrap a docker container and convert it into a worden container because we've been running word in containers in production and at scale very successfully for years and years that was the approach we took today I'm pivotal and many of many of the foundation members the Cloud Foundry foundation members are also members of the OCI the open container initiative which is where docker placed in public trust the intellectual property around Dockers core core capabilities in format and one of the things to come out of the OCI that is really fantastic is run seek which is a much more lightweight stripped it on and no daman no daemon is required for run C to run a container and we are moving our Linux based container support for both warden and docker containers to using run C under the hood so that is an active development within cloud foundries ecosystem right now I'm not sure when it'll be when it'll be done but the development is at least progressing and it's a cool thing to look out for in the future but as far but as far as we're concerned we have an application running and we have an instance of it and it is a docker container based application and we can do the same sorts of things that we that we did before it operates in less the same way so CF scale for example to get a couple of instances running we can do that and we can take a look at the operational characteristics here with the CF app command so we do have a couple of instances running we should be able to demonstrate that with a simple while loop like we did before instead of hitting the original application we want to hit the application that is hosted at CF - docker and we can see a similar thing we cycle through the instances it's up to you if we wanted to we could also bind Redis to the enterprise-grade version of the docker container but I think that what you're gonna find is that because the workflow is so similar it will seem like it will seem like we're you know retreading the same water that we already saw the only difference really is that you use a command line flag for a docker image to push the app and otherwise they were closed the same well I want to get to the surprise oh yeah short short so when are we I don't want to rush things though or we do we haven't is there anything else you'd like to show here no I think this is good these are these are your your basic commands and everyday activities that you would do if you were operating if you were working with Cloud Foundry to develop and deploy software so that's really what I wanted to show great so I think my surprise is somewhat topical I don't know how many people who would listen to this show I've been keeping track over the last 15 years of language development in in the world but this past Christmas so roughly what maybe two weeks ago the Perl 6 programming language released its first version it's been an active development for 15 years incidentally basically since the beginning of my career and they started my career as a Perl developer so that's a pretty exciting exciting development and Perl 6 being a brand new language brand new to the world in terms of its first its first you know 1.0 release which they named six dot c-- which frankly i don't know why but you know larry wall has always been kind of a jokester so no one ever knows so what i wanted to show you is actually getting a pearl six application running on Cloud Foundry because why not get the most modern you know language released most recently released new programming language running on a modern platform so we can do that so I've created a port of this very small application called CF e NB to Perl 6 and let's just take a look at what we have here I'm gonna stash those changes let's take a look at what an application and pro six looks like so we have in Ruby land we have the gem file which provides information about vendor vendors that we're vendor libraries we're going to be using it in Perl 6 there's a meta info which is actually a JSON format file in this case for our metadata info we have an application named CF EMV Perl 6 and it depends on Theodore which I am NOT a very good Spanish speaker but this is a Spanish word for dance or dancer and what's interesting about that to walk this back in the entomology is that in Perl 5 there is a lightweight web framework called dancer which is based on a lot of the principles of Sinatra so we kind of go back there so the Ruby work inspired the Perl work and what I actually find fascinating about this in general is how often within programming language communities you get this cyclic effect of things in Perl or you know some other programming language influencing say Ruby and then Ruby influencing Perl and vice-versa that's pretty neat and we'll also use a JSON library called called JSON fast because we want to produce a JSON API so this very basic application uses Perl 6 and this value door library it it's information about which port to bind to off of the environment and this is the the Perl 6 syntax for getting information from the environment hash we call it hash in the Perl community some programming languages call it a dictionary for example or an associative array so when we get the base URL for this API we'll set the content type to application JSON we will get instance information again off of the environment or we'll just specify it as none and then we'll return JSON here and it'll again be this instance with instance ID so oh this is a very basic app we also have our manifesto ml because we're gonna use a build pack to build I had to jump through a few hoops here I'm not really willing to say that this is enterprise-grade because while I'm using a build pack that is for rikuo which is the the interpreter for perl 6 or the it's the code name if you will for the interpreter for perl 6 I'm using this build pack but I actually had to build a custom image whenever I first did this of Perl itself Perl 6 itself so I have to provide a few environment variables the build pack will use these environment variables to understand which which version to get and I happen to be hosting that and on Dropbox because it's what I what I did at the time don't run this in production ok yeah so we'll go ahead and and push this up and see what happens maybe we'll get Perl 6 running in in production here so we have a similar model to everything else it reads the manifest figures out what build pack that's going to use and starts building a container uploads our app source files and so now we're getting our binary of a pre-built Perl 6 distribution and we'll see whether or not it will download our dependencies and get them running all right so alright getting close mm-hmm yeah so so Perl 6 is an interesting language probably not ready for for primetime in most organizations but here we go we have an instance and let's see if we can do horizontal scalability of a Perl 6 application on Cloud Foundry and we'll just see what's going on here so we have three instances so when it one thing about Perl 6 at the moment and it is a young language is that it uses about ten times as much memory as your typical profile or the application but you know they'll work on that so we'll go ahead and tail the log file here just to see what what that looks like but so you're a long time Perl user what do you what do you find exciting about Perl six I mean it's it's it's new what is it about the you know in Perl six that you're finding yeah so I'm I'm tinkering around with it it is true that I've been using Perl in my career for a very long time and I've followed along with the Perl six development right now I'm tinkering with it and I don't think it's quite ready for typical business use cases but it does have a few key things that for language design I think are really interesting one of them is is a grammar syntax so we're always made a name for itself for being a text processing language of having very powerful regular expressions it's a double-edged sword because people often look at Perl source codes they that it's the old joke is and it's a right only language that you can't read the source code because it's so difficult to read and I'll agree that I've probably written my fair share of Perl that is impossible to read but but the grammars actually make it so that you can write very sophisticated parsers to do domain-specific languages or to parse rather complicated incoming text streams and I think that's going to be very powerful just and so the the syntax there is definitely something to go and check out there's also a lot of functional programming and higher-order programming concepts built into Perl six it borrows from everything from small talk on Haskell to you know Ruby Ruby borrowed from small talk as well but I think that they've done a really good job of building a language where you can do some pretty complicated functional programming techniques in order to cut down on the amount of source code you have to write to do to do rather complex workloads but I will say that the syntax is still something that I'm learning when it comes to that because it can be terse but that's kind of the appeal for rural developers yes so we have the logs that are streaming and we are seeing it instance changes here so we do have Perl 6 running on a platform I'd like to believe that this is the first instance of Perl 6 running on a modern scheduler in a modern platform so I'm kind of proud of that even though it's just for fun excellent well well definitely hi like that cool well I think that's that's what I had to show for you today that as I said is a very developer workflow centric view of what it would be like to operate with a platform and some of the capabilities that you get from things like Cloud Foundry well Casey thank you so much for for you know taking some time to go through what it's like for a developer to use Cloud Foundry on a day to day basis showing us a bit about docker and it's and how it's used in you know in cloud foundry and a the first time look at Perl 6 and and skin a scale down environment congratulations on that thank you very much that was a lot of fun yeah there's a lot of fun thanks a lot and we'll talk to you soon all right take care all right 