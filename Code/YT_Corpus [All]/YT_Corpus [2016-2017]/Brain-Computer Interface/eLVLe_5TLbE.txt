 you joining me now is Tim Mullen from cusp here in California at Tim you gave an interesting keynote and it was clear from that that you have a deep background in in academia but that's not what you're doing now tell us briefly about your background right so my background is in academia I was previously at the Institute for neural computation at UCSD as well as with a number of members of my team and we were focusing really on brain computer interfaces and on advanced methods for neural state decoding to interpret the signals that come out of our brains and relate them to behavior and cognition and we created a company cusp to provide tools API is really that allow anybody anytime anywhere to access that powerful mineral technology that comes out of laboratory environments but do that with very little expertise very little domain knowledge being able to ask me as simple as write one line of code that says give me your attention state or give me your emotional state and our system provides that through the cloud good so um you just said emotional state and attention state what are the kind of states that might have been interested in if I'm an API develop if I'm if I want to use your API and develop an app let's say oh it really depends on the application so let's let's take on one extreme let's say games so if you're an entertainment oriented developer you might be interested in for instance ActiveX control like being able to move or fly a quadcopter around based on you thinking move left move right so we have algorithms that can do that and have a bunch of students actually working on that too on the other side of the spectrum let's say you're in the digital brain health area and you might be interested in say tracking a particular pathological stage or maybe tracking wellness or for health and wellness tracking fatigue States or or depression those are some of the things that now research is starting to shed light on the brain mechanisms related to those kinds of states and and you'd be able to to access that information as well very good so what kind of states you think would be relevant for consumer devices or consumer applications not not the medical ones but the consumer ones yeah I mean I think that actually the what was previously in the medical sphere is now becoming more applicable to consumer applications in the area of digital brain health so if we're looking at for instance let's say just take as one example autism trying to look at what are the neural correlates of let's say a child about to have a meltdown that would be something would be very relevant previously in the clinical sphere but now you could imagine an app that just sort of says Oh meltdown approaching you know and then go into a little biofeedback or neurofeedback calm down routine you can imagine an app around that in the consumer sphere so this is probably a little bit off-topic but if I made an app like that wouldn't it need to go through FDA approval it's a sum in Somerset it would it really depends on the particular application what you're claiming so if it's used as a as a therapeutic device for instance that's actually used to diagnose or treat a disorder then yes it does have to go through regulatory pathway and there are you know the FDA has been accommodating increasingly the transition from the medical domain into the digital brain health arena and into personalized health care and making it easier to have that transitional pathway so it's not terribly frightening I understood in your talk that at the moment it takes quite a long time to calibrate these systems so regardless of what kind of bio signal that is coming in in order to to work out for a particular user what different states what different signals how these different signals correspond to different states requires a calibration and phase how long are these phases normally and and what new developments will help us to reduce these well I think that there it really depends on the individual and I'm a task but the amount of time required in terms of the calibration period can range from five minutes to thirty minutes and sometimes even longer because it depends again on the complexity of the task and how difficult it is to extract that little neural code that little signature that's related to the behavior you're looking for the cognitive state you're looking for sorry to interrupt so 30 minutes I think that's not going to be suitable for any ADHD not necessarily no today no no but so but a lot of work now actually in the neurosciences is about finding generalizable patterns and with big data analytics so now you know we're leading projects for instance with a consortium called the Kansas CTA that's involving carrying out experiments across wide like 20 different experimental paradigms collecting over 3 million dif and events over hundreds of different sessions from hundreds of individuals and then looking using sophisticated like deep learning algorithms and other kinds of big data analytic algorithms trying to find patterns that are specifically related to a state that you can then take a new individual who the model has never been applied to and you've never seen before and immediately have a sort of a good general representation of what the mapping is for that individual that will work right off out of the box with them I see so - rather than the kind of for each patient or each consumer de novo approach to have some a priori knowledge that speeds up this training phase exactly it's all about a priori knowledge and starting with that that prior information that allows your model to get a good guess of what that person's brain looks like and then it will learn over time exactly what that person's brain looks like and what's the relationship between the brain and the behavior so you mentioned having access to a lot of data from which collaborative you can get statistical inferences based on large amounts of data this requires having all this data in the in the cloud and you mentioned something before about your cusp having the Web API being able to put all this data into the cloud and doo-deen our analytics there exactly yeah so we provide a RESTful API framework actually we're I think the world's first platform for neural computation operating operating on the cloud through a Web API interface in real time so you can push your bio signals to the cloud through a few API calls then we have a large amount of sophisticated signal processing that's spun up to make sense of that data and then with a few more lines of code through again in a simple REST API you can get back a meaningful result and all that happening in real time so the reason I put all the data in the cart is because the computational requirements in processing that that it was too large to have on let's say a mobile device absolutely can you envisage a time in the future when we when the the power computational power of mobile phones will be sufficient to do this locally I can I can imagine absolutely a time when what we're doing today will have mobile phones powerful and for processing those signals but at that same time we will have more sophisticated algorithms so if you follow Moore's law that exponential curve well you see a similar curve for the complexity of the algorithms that are being applied to decode neural states twenty years ago you could do a Fourier transform that would be the state of the art now we could use compressive sensing and sparse Bayesian learning and you know all kinds of interesting and powerful algorithms in 20 years yes well more powerful mobile phones but our algorithms will be incredibly more sophisticated and there'll be a lot more data that we're crunching because we'll have sensors that are recording much more activity so I don't think it's ever going to be the case that you're going to be able to own a mobile well not ever I don't want to say ever but not for a while that on your mobile phone with the power requirement and the battery limitations that a mobile device has that you'll be able to do the state of the art in terms of bio signal processing and neural computation 24/7 on that mobile device okay that's a scary proposition to think that every by signal from us will be one-day measured but if it is I'd like to know that that I'm I'm in control of that data and not the NSA absolutely no absolutely and privacy is is extremely important and we work with standards bodies around these kinds of issues and trying to identify appropriate standards that can ensure security and privacy and safety and there's something called the Sarab a standards body that is really focused on ethics and privacy as well okay so that concludes the talking part of the interview we're going to try a little experiment now tim has brought a device with him and he's gonna we're gonna see if this works on camera most most demos work all the time except when you're doing a demo on camera so what this is this is the interacts on Meuse headset friends of ours up in Toronto and so if I put this thing on my head like so it's now recording my brain activity and what I'm showing you here so this is showing streaming through the cloud real-time my brain activity so if i zoom in I look around if I blink blink blink we can see the perturbations those are blinks there which are one of the artifacts that actually our algorithms can get rid of and these signals now are being streamed up through a pipeline that's able to make sense of it so that if I go to for instance this application this is a little game now that again through this Web API and here we go what assuming is calculating a measure of my attention and how much I'm focusing or concentrating and I'm playing with a few computer-controlled players and trying to steal the orb by focusing my attention on the orb so you can imagine I might be a child who has say you know ADHD and you could use a clinically proven or fda-approved algorithm there that's in a biofeedback sense known to enhance your level of focus and you could play with your parents or your you know teachers or or therapists and have this very interactive and fun but brain health promoting application and again this happens through just a few simple API calls and any developer can build an app like this on our platform okay so this was just one example of an app that could be built using the Web API from cusp Tim thanks very much for taking the time to not only give the keynote but also speak with us afterwards think of this give this great demo thanks a lot and thanks for watching I Triple E see silk TV you 