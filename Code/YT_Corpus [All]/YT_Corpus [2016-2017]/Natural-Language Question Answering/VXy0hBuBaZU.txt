 hello everybody thanks for coming it's a great great event it was great last year but not in terms of size certainly it has grown a lot it's really great great to see how how much interest and excitement that deep learning community creates and I think that's largely because of how well it works now and I'll start my talk we're talking a little bit about standard classification which is what deep learning has really pushed forward but then also focus most of my talk on what I think the future holds and that will be I think question answering and much more complex types of reasoning so let me start by saying that if done right as in with the right team or partner standard image and text classification can be extremely accurate now and I'm not going to spend too much time on the sales pitch and a lot of our customers actually see this as a first mover advantage and don't want me to disclose all the details but I can focus on two use cases where our customers were able to have a very quick time to market with enterprise-grade classifiers the first example of this is food classification you might think and I certainly thought I'm beginning how interesting good food classification be but there are a huge number of applications for this kind of application basically anything from appliances in your kitchen to health or foodie apps to diabetic patients who want to keep track of their calories there are a lot of different things you can do food classification and since we've seen that come up so many times we actually started building the most comprehensive and accurate food classifier in the world I don't think any other library out there has as many different kinds of food categories as this one and I just show you here a couple of the items that are in this list and we're still only at be so it's a lot certainly there are a lot of things that I I don't think I could even recognize this one for instance so just to show you here quick example those were strawberries it has different kinds of dishes so for instance identifies this one as a pat side dish the food is interesting but in some ways not as surprising that we're able to do well and actually have paying customers who are interested in that what I'm even more excited about is actually in the medical domain and here our partner be red virtual radiologic is really excited to share this I can't disclose doing details I don't want to take away their thunder and their press release that will come out soon but basically we're literally able to save lives with deep learning which is not a statement I thought I could make any time soon when I started this company two years ago so what does inter-cranial hemorrhage it's basically a brain bleeds and it's a one of the deadliest kinds of things you could find in a head CT scan when you come into mergency room it's really something that if you have it and it's bad and grows in 10-15 minutes you could die and if it's diagnosed you would want to have a hole drilled into your skull put a catheter and let the fluid and the blood out so it's a pretty urgent kind of thing and if the algorithm could identify that that is evident in a CT scan it could very quickly put that on top of the queue of any attending physician and of the radiologist and that's what we're doing and it's now classifying thousands of CT scans every day and from time to time has really urgent cases that actually prioritize this and potentially saves those people's lives so that's very exciting and that is certainly one of the use cases that I think will only grow in the future I think radiology will have a huge shift in the next decade where we can make them more efficient and maybe even provide that kind of technology in areas of the world that don't have as many amazing radiologists as the United States does so that works right now basically with deep learning again classification is too large degree solved creates very happy paying customers but not every problem is as simple as classification and several require reasoning and I think pretty much all natural language processing problems and maybe even all AI problems can be reduced or seen as a question answering problem over some input to give you an idea what I mean by this let me show you a couple of natural language processing tasks that have usually quite different sub-communities inside NLP that work on different problems so the first one here we have a problem that requires some logical reasoning Mary walk to the bathroom center into the garden then you went back to the garden Sandra trip to milk there where's the milk now we need to find out something about the milk for instance Sandra took the milk there but you still don't know where it is now you want to find out where Sandra is and she went to the garden so the answer is garden so some simple logical reasoning like this it's usually done with very different techniques to the next task which is sentiment analysis say everybody's happy and you ask what's the sentiment or Jane has a baby in Dresden and you ask what are named entities just location person and so on have some lower level tasks like part-of-speech tagging that you can ask or you can even ask what is the translation into French and the answer would be you know the sentence in French so this is just a small set of examples for NLP and i'll show you later some for vision to that really show how general the framework of question answering is for four different problems so maybe a reasonable goal for the future would be to try to build one joint model for general question answering and then maybe would actually have a more significant chunk of ave i solved in this tack so there are two major obstacles to this the first one is that at least the natural language processing there's no single model architecture even with consistency of the art results across different tasks if you try to do this question answering task I showed you logical reasoning you used to have this be the state of the art paper from facebook for sentiment analysis used to be three LS TMS so L STM's usually used as a recurrent architecture but in tree structures and tactic tree structures by Stanford I think Chris mentioned this yesterday Chris Manning and for part of speech tagging you would have some bi-directional lstm conditional random field kinds of models to combine that so up until we published at the paper I'll talk about next these different models were state-of-the-art in these three respective tasks the second major obstacle is to have actual fully joined multitask learning when ever we do this kind of thing in the community usually restricted to lower layers for instance and convolutional neural networks we take the first couple of layers of the convolutional neural network that just find edges and things like that and we replace the top classifier at the end or in natural language processing we use word vectors and we share those but we replace the rest of the architecture it usually also only helps if the tasks are somewhat related and in many cases hurts performance if the tests aren't related so for the next couple slides I will tackle the first obstacle and I will use a new architecture that we developed and our research team at meta mind called dynamic memory networks for this it is essentially in architecture for arbitrary question answering tasks so let me give you an overview and then I'll talk about each of the different modules separately one way to think of these modules is also to push the burning away from here are some intertwined equations to let's think about this in terms of software engineering a little bit too you can have each of these modules communicate all directly via vectors and essentially train them all jointly with basically all back propagation and the vectors both during forward and backward propagation be communicated between these modules so the task here to just illustrate this model is the problem of asking where's the football that's the question given these facts and ideally the model would give a correct answer which would be hallway and so the way this works is essentially we have an input module that reads all the inputs that are relevant to the current task the current question it will compute in the question module a vector Q for the question and then this question module will trigger a so-called attention mechanism there will pay attention to facts that seem relevant at the time to answer this question for instance for instance here when I ask where is the football the question the inputs that's irrelevant are those that mention football such as John put down the football so here is the sentence is paid attention to and then add it to the main novelty in terms of the research of this work which is the episodic memory module now the episodic memory module essentially collects all the information that seemed relevant at a time and then stores it in a vector N and at the end of each iteration over the inputs the model knows do I have enough information to answer this question yes or no and if the answer is no it will actually go over the inputs again with the newfound information so in the first iteration for instance I saw John put down the football but that still doesn't three tell me where the football is it just tells me now I need to figure out where Jonas so it goes over the inputs again and now pays attention to any sentence that mentions John and picks the last sentence here or John went to the hallway and then the final output of the episodic memory module is given to an answer module that will be basically just generating the answer so let's go over the modules a little more detail to spill the beans a little bit each of these modules is essentially a very complex recurrent neural network so let's start with the input module I'm not going to go into too many equations here but this is the only slide with some equations I probably think that if your have never seen any of these I'm not going to be able to really explain it fully now but what you can see is that these are essentially for the most part very standard neural network architectures you have a standard linear layer side and an element wise non-linearity and you take as input at each time step a vector usually these are word vectors in our case for NLP and you have the previous hidden state at the previous time step and you compute the new time step by basically computing two types of gates a reset gate and an update gate and those are just standard single layer neural networks there's no magic there then the main novelty here is that you have the reset gate and the interesting idea of this gated recurrent unit is that the reset gate can essentially tell you should I care about what I've known in the past for example if these ours here are all zero I will ignore all the stuff I used to know before in my hidden memory state so for instance if John moved to the bedroom becomes completely irrelevant once I know that John is now in the hallway so I can reset that memory and ignore it and then Z is related in that it can also just copy previous time steps forward so these disease here are all one I can just essentially set my new time step to the last time step and I ignore what my input is right now intuitively what that means is if John moved to the bedroom in the next sentence of Sandra I went back to the kitchen well my question now my attention that the attention i'm paying the fact that i'm paying attention to only care about john so i can essentially ignore all the facts about sandra as i go over the input and that's what these gates allow us to do so it's essentially a an advanced recurrent neural network architecture so if you're really interested in that and you thought that was the most interesting part of the talk and give a lecture at stanford deep learning for natural language processing and i'll spend many many hours just going into all those details its online right now and give it again next next quarter so basically now that we know what a gated recurrent unit is at least somewhat a standard recurrent neural network we can use that same architecture to compute the question vector again just have vectors of words as inputs we compute them with a jeer you to get the vector Q now the interesting stuff happens in the episodic memory module where we essentially have now this gates G that take as input the questions and the current time steps of the inputs and the only equation that is not very pretty and I promise also the last one of this talk is this one and you might think that it looks quite happy but really what it is is a bunch of similarity functions so you can have element-wise similarity you can have simple distance functions you can have bi linear products and things like that and then you plug those into a standard room that work again and that G function gives you essentially your gate and the gate says this for this question q is this sentence s actually relevant or not and it also takes into consideration the memory that I have so the previous facts that I've already looked over and then again if the summary the end state of that gated recurrent unit is insufficient which we can also train in a training time then I will go over the sequence again but now my memories have changed because i use the fact that i've already collected from previous time steps all right so usually I try to stay away from anything neuroscience because I'm not a neuroscientist that collaborated with some but here we did actually get inspired by neuroscience largely because the episodic memory is the memory of autobiographical events times places so I can ask you remember that first kiss you had or something like that and that brings back that time in your life where that event happened so it's essentially a collection of the past personal experiences that we all have that occurred at a particular time in place when it turns out the hippocampus which is the seat of the episodic memory in humans as well is active during transitive inference and transitive inference was exactly the kind of task I just described to you where we first need to know that the football is Red John and need to know what location John is in those kinds of inferences turn out to happen exactly in the episodic memory of humans and that's why we named it the episodic memory module and we've also run experiments and know that if you don't have multiple passes inside the episodic memory you can't do transitive inference the final module is the answer module at this point you'll have no surprises it's also a gated recurrent unit recurrent neural network that essentially has a standard classifier output at each time step that outputs a word now there are lots of different kinds of questions you can ask and the bobby task has several so some of single supporting facts or multiple supporting facts you can have yes/no questions counting questions how many people are in the scene or something like that you can have lists and sets it learns automatically negation coreference resolution so you can say he went somewhere and it figures out who does he refer to a lot of interesting subproblems and this model is right now the most accurate model in the world and outperforms the memory networks from facebook as well so I have a little live demo I put together so here is an example of a story of a bunch of facts and the question is what colors Bernard and so as we go over this we can essentially see and I'll give you a second to try to figure out the answer for yourself or figure out how to figure out the answer what we see here is that the model essentially does it the way we would do it with the question is about Bernard so it first pays attention to any sentence that mentioned through an art which is just for an art is a frog it now knows it doesn't know enough so that's good it's a known unknown then it figures out okay maybe we should look for frog as well the next important thing to pay attention to is that Lily's a frog and then we still don't know enough but now we know that lily is yellow and then it figures out okay now I know what the color is and this kind of stuff used to require a lot of hand engineering for different rules and you can hand engineer rules for simple examples like this but what it shows us this if we can now have more complex examples we actually have the training data for instance customer support requests we can now basically try to reason over the inputs and give better answers to customers and the way it did it is purely by looking at vector representations of inputs in words there's no discrete hand tuning of features now we can also have some other kinds of problems we can ask what is the sentiment sentiment analysis pretty popular task and here we basically to give it a pretty hard example so despite the glowing reviews this movie wasn't and especially engrossing experience it's tricky because it has glowing reviews which is very positive and an especially engrossing experience it's a very positive trigram too but with the negation it learns that it's negative we can also ask what are the named entities the task I brought up in the very beginning and we see here that it also very accurately identifies different locations and organizations and things like that like the key our motor corporation we can also ask what are the part of speech tags and this is actually the most accurate part of speech tag which I don't think is as relevant for some sort of industrial applications because these used to be sort of subtasks we need it but now that we have these end-to-end architectures I think we can solve the harder higher-level semantic tasks right away but it does give you a small amount of bragging rights because this task is about 20 years old status as 20 years old you've had thousands of linguists and computational linguists work very hard on this data set and the same model that gets state-of-the-art on question answering and outperforms Facebook and the same model that gets state-of-the-art on sentiment analysis and outperforms Google and lots of other researchers working on that sentiment analysis data said that same architecture also get state-of-the-art on part of speech tagging because the model makes zero assumptions about language we can also ask it about different languages again it's just a matter of having question answer and input triplets to train the model and then it will figure it out how to so here we have chinese i'm not going to fool myself by trying to read that out but it's it's a pretty interesting sentence and it also is a very accurate sentiment classifier for chinese it can also do machine translation can ask questions in fact just a couple days ago we now have one of the most accurate machine translation systems in the world and I mentioned that it's more than just NLP we can also ask questions about images and so here we go back really quick the only difference that we have as we change the input module instead of having word vectors and sequences / words and sentences we take mid layer vector representations from images and give those as input to the episodic memory module and remaining modules are the same and Kai Ming was one of our researchers at meta mind has now gotten this to be the most accurate model for visual question answering in the world on fact he outperforms anybody else on vqa the BQ a data set from Microsoft and here just a couple of examples so for instance we can ask what sport is shown and the answer by the model is tennis and I have a couple of other ones here so is the girl and athlete for instance the answer is yes there are a couple of other kinds of images you can use and ask different kinds of questions about it is really quite general purpose and you can ask any kind of question about this so is there a clock on the building and the answer is again yes and now imagine what I showed you in the beginning with food classification instead of just saying you know here a set of discrete classes it's either pad thai or pats you or strawberries and things like that instead having a model like this where you can say all right what's what's the food but then is it healthy how many calories does it have how long will it take to expire should I put it in the fridge or not how should I make it how should i create this dish there's so many things that are related to you know questions like in some ways questions are the most natural way we could possibly interact with future AI systems so that on a summarized essentially if you have a concrete vision task right now where you want to identify anything in images contact us we're building I think the most accurate custom solutions enterprise-grade anything from food to complex things like radiology and then for most the research side most natural language processing task and multimodal task and vision task can be reduced to question answering and the dynamic memory network is a very accurate model that solves a whole variety of different question answering tasks thank you 