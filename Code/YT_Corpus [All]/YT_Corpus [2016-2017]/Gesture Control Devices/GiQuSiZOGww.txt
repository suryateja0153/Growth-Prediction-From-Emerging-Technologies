 hello Budapest and good afternoon everybody I'm sure you all had a good lunch I hope you all don't sleep after the end of 30 minutes so I'll try my best to keep y'all awake alright let's get started so yes technology has already become more productive and more natural more intuitive the interfaces are more intuitive more natural now having interfaces this way makes the user understand the product better or like come closer with it so here I am Prince iam working for a solando in Berlin and to talk about natural user interfaces using javascript so we typed we clicked touched next what next next could be alright I will go to the next slide with a demo and the demo is highly dependent on light so I really hope it works okay so two slides again so we typed clicked touched next what yeah so this is what I am going to talk to y'all about natural user interfaces using javascript this demo will you go over your so let me just close it but yes it did its purpose and yes so it could be gestures right it could be a speech it could be anything natural user interfaces could include touch we typed we clicked touch was more intuitive than click because it was more direct next I would say gestures or speech yes evolution of user interfaces so somewhere this was coined somewhere back in the 90s wherein it started with CLI command line interface wherein user had to understand of an artificial medium that is the keyboard to input something and to interact with the interface next came GUI graphical user interface with the advent of the mouse users could interact more closely better than the keyboard with the interface and understand the interface more better and now we have this NUI with the advent of a are we are perceptual computing we hear that everywhere if we just do a search on the internet what is the state of art what we are AR or perceptual computing there are there is lot happening out there and anyway has more space and it is more direct it is more intuitive yes natural user interfaces to coin it it is a system for human-computer interaction wherein users interact more intuitively more directly perform more closer tasks these interfaces are yes are more natural and more intuitive yes a quick study about natural user interfaces revealed this sub info graph this was taken from the internet a big it was done and then yeah the results of a link of a pretty cool because the work areas where it's targeting that is entertainment education social connections health care environment natural user interfaces has its impact everywhere so here I am to talk about anyway plus jeaious and I would coin at us in you ijs JavaScript has its broad appeal and it's because of this broader appeal a lot of people like to try it and we admit it or not it is JavaScript which dominates the web today and yes here is what we are to celebrate javascript and may javascript be with all of us so let's talk about nu IJ s yes this is my the interesting slide I like to talk about motivation whenever I like to do something or I have to do something or I have to motivate somebody yes so how did this whole idea start any yjs how did it how all of this started so it started with me building trying to build a simulator for motion control devices or in other words 3d cameras I have a Whitney or leap motion today I will talk about more about it later but yes so the any yjs started when I was trying to build a simulator for 3d cameras or motion control sensors and yes there is another motivation behind as to how I started to come up with this idea of trying to build a simulator so of what what so happens oh say oh you are a go yeah Oh your ago I was trying to trying a talk about perceptual computing and then I was trying this intel's realsense sdk and two days prior to the talk and stole the story so please bear with me if you are listening again two days prior to the talk windows and my system crashed and then I didn't have a backup what to do and I didn't have backup of my cord and this SDK which I was trying to walk on solely relied on Windows and then that's how I started to think about how about trying to build some simulator where then maybe it is a platform independent or and whether you don't have to or it is not dependent on any platform or you don't have to use any device right so that's how this idea of simulator originated and then yes the simulator was there the next was what do I do with the simulator so next was try to build some apps for the simulator and down down those lights I'll be talking about two apps that is one is the slideshow which I just showed you all about using gestures I controlled my slide it's kind of bad it's like not very neat it's highly dependent on light and after to control the frame rates things like that but yes it's serving its purpose and the other app I want to talk about is draw how about imagine this you grabbing a device and you open an app do some doodles in the air and watch your art appear on the screen yes so I have I have come up with this app called draw and the other one is slight so yes that's about like how it all got started how any ideas started yes before getting started I had to like try and understand as to what is this all the hype about right of method reality virtual reality perceptual computing there are so many devices out in the market augmented reality as the word augmented says the reality or it is real the environment is real but there now it is augmented augmented as an added so I'm standing here maybe I want to show some background like Taj Mahal in India or something else arise on a desert so I'm mending the reality and that is what augmented reality is about that's why where we see augmented reality applications in real estate things like that right you're augmenting the reality next it's about virtual reality what is this virtual reality about virtual reality the reality doesn't exist at all you are like trying to create a virtual environment you are simulating you are trying to build an environment which doesn't exist at all so it could be assimilated environment then yes we have this perceptual computing bringing human-like senses to devices yes there are like so many devices out there with support augmented reality virtual reality perceptual computing applications and perceptual computing is making the device understand behave more like human understand gestures wise giving more of like human-like capabilities into the device and that is perceptual computing perceptual being able to perceive being able to see oh yes so I already said there are a lot of devices out in the market and so yes what next there is this motivation somebody standing here somebody got started and out of nowhere somebody like got into this new world there are like so many devices out in the market people are already talking about us there is so much hype about this everybody wants this baby to fly so there is perceptual computing and the virtual reality augmented reality devices everybody there's so much hype so what next what next next would be like how do I get started right so I will tell you about how I got started and yes how I'll show you the simulator and I'll show you the apps and maybe if you are interested catch me after the talk yes so as this great man says any sufficiently advanced technology is indistinguishable from magic before we get into some technical aspects related to this natural user interfaces I would like to make a statement here you after my attempt to build a universal simulator for all the devices out there with this one-woman army standing here I finally gave up and thought of you know focusing on something one and trying to really get it right and then maybe like you know use the same old thing and Here I am I have chosen this leap motion controller yes we are all here at a GS conf I'm not here to advertise about any device but please excuse me if I am talking about leap motion I don't want to talk about it in particular but it's a humble effort by a JavaScript enthusiast to try out something there and to share it with the community so if at all I have chosen leap motion it is just a random choice and yes I just got lucky I was gifted with this leap motion and that was the first obvious choice to try other sleep motion and try to build a simulator for leap motion now when I'm talking about simulator the simulator is nothing but so any of these devices they will come with your SDK even this leap motion comes with the SDK and my simulator what it does is you can try out the SDK without actually using this hardware so you have this service running or software running and then you can get the whole SDK running without actually using the sleep motion and you can see how to get started and who would get benefit out of this say you're trying to create a workshop or next tutorial for a larger audience and then people don't have the actual hardware or are really interested to try something and want to get their hands dirty first before like buying out something then yes this is the solution alright so irrespective of if it's a leap motion or anything we need to understand as to how the whole architecture works so there are all these devices which we connect with to a computer using this USB cable and what happens is this USB controller reads the sensor data and these are devices it depends on the device depends on the manufacturer depends on the company or manufacturing of the device as to how they want to yeah its left at them yes there would be like few 2d or 3d cameras there would be infrared sensors to sense your to recognize what's happening and so this USB controller reads the sensor data the next what happens this data is stored in local memory next data is then streamed by our USB to the SDK it is the streaming thing which is of prime importance and we need to understand what happens when we actually do the streaming so to understand more about how the sleep ocean would work yeah so what happens here is we have this USB controller and then there is sleep service running in there now once the USB controller reads the sensor data stores it in local memory and then again streams it back to the usb so what happens is once the image data is streamed to your computer then the whole of this mat world comes into picture the bunch of these algorithms which come into play which may be like eliminate noise and just give the region of interest to you so there is this lot of processing happening behind and then again it's device dependent as to how they want to process and how they were in what format they want to or give the data to the SDK so in this case what happens is there's a sleep service and the other good thing is all of these devices they are connected to the USB port and the way they stream data after reading the sensor data storing local memory are the way they stream it is happening through a protocol slide up so if it's a network or native than it is TCP protocol and then if it is web-based it is WebSockets and I'm here to talk about a web-based solution so it's all about WebSockets all of these SDKs they create a WebSocket server and then they do the streaming back to the application and that is how the application is able to get back the data in this case leap service would have its WebSocket server running in 6 4 3 7 port number 6 437 so next I'll show you some code and I have like uploaded it here I'll be sharing the slides and yes there were like few references which have used there were this good open source libraries out there webcam Swiper and GS object detector so the first thing what I'm here to show y'all about is the app called draw right so I have this app called draw which works the same code works with leap motion and works without leap motion and this draw what it does is right now I've just enabled it for like one finger I just move one finger and then I'm able to like you know track my finger movements and draw something on the screen so this is what the app does and it's able to run with the device or without the device now a little more about the simulator all these devices they use this web sock they use this WebSocket server for the streaming process and what I do is I create the simulate the idea of the simulator is to create a no J's WebSocket server and this WebSocket server can run on any port and all you have to do is you have to configure your SDK to talk to your WebSocket server instead of the SDK server which works which works if a device is connected so if your device is not connected we run the web server server and then we send in the or data so let's see how this draw works so first I will of shot show or draw with a leap motion controller so now I'm connecting the sleep motion I have this connected and I have my WebSocket server running on port number 3000 and sorry so now I'm using the leap motion so I don't want my WebSocket server so this part by default it talks to the leap motions WebSocket server which is running on 6 4 3 7 and let's do this so ok I'm not sure about the light yeah the demos okay now everything is good maybe because of the light yeah okay so it's moving okay please move sorry was that for me okay can someone turn the lights up on the stage please I thought somebody's angry I'm sorry okay let me just stand here and okay oh no no it has to walk let's make it walk please bear with me I think this is so unavoidable right no matter how short that your demo is when you are presenting it has to break this is just not moving okay let me just try the leap motion yeah okay so uh fine the motion is not working so I'll just try my simulator and let's see if that is working to make my simulator run all I have to do is I'll be telling look into the port 3000 I can obviously make my WebSockets overrun at 6 4 3 7 where in the leap motions default WebSocket server is running at but yes I prefer 3000 here so I save it and I have this my WebSocket running yes ok so now this application what I've done is it's basically WebSocket right so it is a client-server model so this screen what you see is a client and then there is the server which has to send signals to the WebSocket and then the WebSocket will send back the signals to all the connected clients so the architecture looks like my two browsers so long so and then it is so draw yeah okay okay this is not running either so the idea was right now what I'm doing is it's the same code but then I'll unplug the sleep motion it's the same code I just want to see the output but so the idea was I am passing the coordinates so I know what sort of data format the leap motion expects I have my server running so I'm you know moving the mouse coordinates I'm moving the mouse coordinates and then it's sending the data to the WebSocket server and then the WebSocket server sends back the data to the leaped line so in this case this is my application what you see or hear where when you see the blue dot is supposed to be the client and then this mouse part oh yeah all right so right now it's the same leap motion code I'm not using gestures so I'll come to the gestures part later I'm just a user using my mouse touchpad and then I'm able to do this doodles on the screen it's not a good noodle but yes the idea is they're being able to draw something so I have my this server sitting here which is taking coordinates taking the positions it would be the same way as though like you have your gestures and then the gestures are being recognized by the leap motion and then it's sure you know it's taken by the application yes so let's look into the code what happens here this is my WebSocket server few lines of code and this is all you need to create a WebSocket server and my application the server part which acted like a server which had to give data to the WebSocket server and then this web sockets over the one running at 3,000 would give back to the application the draw application so in this case yeah all I'm doing is I'm just up getting my mouse coordinates and then I'm creating this you know I'm sending through WebSocket server and I'm sending the hands and the point Able's so leap motion has this data or JSON format and this is the kind of API which the leap motion expects so it will look for like other any gestures are there hands hands yes leap motion is able to okay it's too much like leap motion is able to identify which hand it is if it is right hand or if it is left hand and the point tables refer to the fingers so I am referring to the index finger and this is how I'm walking the data so I tell you know the point Able's and I'm passing up the index finger right so it will be like an array of 5 or 0 1 2 3 and forth so I'm passing up the data for the first finger index finger and then I'm calling the tip position where it is the X and the y coordinates so the tip position is actually a vector in 3d space XYZ but then I'm capturing or 3 coordinates and then I'm giving to a WebSocket server and then this WebSocket server gives to the leap so in the sleep what it happened was it's the same code which you have to run if a device is connected or no and yes so if you're connecting the device just uncommon the second line it will refer to the default port which is running on 6 4 3 7 otherwise it will love there are four on three thousand so let the lights meet there I'll just try with leap motion again so I am NOT referring to my local server but then I am referring to my leap motion now in this case I would only need one because okay yeah so okay finally yeah so I think I don't know if I have time but yes the demo of just broke a bit and I got little nervous and but yes it did its job so this is the whole idea and you already saw how I control the slideshow with gestures so then what's happening is in the first draw app what I'm doing is I'm passing the coordinates okay excuse me from talking superfast now I'm excited because my demo work and enough running out of time but sure can I get five more minutes please okay okay fine so the idea is the way the slides are connected right so when I had to connect the slides it was gestures and not any mouse coordinates so here what happens is I had to learn a few things about computer vision and the library saw which I've mentioned are already out there there is also this ah good thing load OpenCV and two good libraries that is jeaious object detect which were like very good yeah so uh this is a very good object detection algorithm used in computer vision I'm not any open Seanie expert but then yes when I was doing this up I had to learn a little bit about this so up in the gestures in the slideshow there were like two things so I had this my app running on a browser window and then it obviously was talking to the leap motion or SDK but I didn't use the leap motion device I had to uh I gave the signals through my hand now this hand this hand signals obviously came from the load socket web server now how this hand was detected was using this wire Jones algorithm and first it was feature selection I have to understand what my hand and then creating uh you know we do the grayscale so that noise is eliminated then do some math on it get an integral image and do some other boosts training like you know train it and get some classifiers and make this up you know are features of the hand map to the classifier which is already trained and then yes you know it is a hand and then this hand coordinates of the hand I know I can locate the coordinates of the hand it was this coordinate of the hand which were sent to the WebSocket server and the WebSocket server a knew which position it was there was some logic written if it is this side then it is left or if it is this side it is right and then now give back to my slide application so this is all how it was about so yes this was a humble effort and then there were few other things about web sockets and getusermedia to know more about this I am doing this session at the Mozilla hacker launch tomorrow at 3:15 if y'all are interested so come and learn to learn to create a selfie or sharing session using WebSockets and get user media so you will understand more about this client-server architecture water which is used in the simulator and yes so this was a humble effort by a JavaScript enthusiast to do something and share it with y'all I hope you all enjoyed and I'm really glad this demo worked thanks to James Caan's VP of and solando for getting me here questions y'all can't eat with me or I'll be around today and tomorrow please up give me your feedback what you felt about it and yes solando is hiring you can come and talk to us alright thank you so much thanks for listening you 