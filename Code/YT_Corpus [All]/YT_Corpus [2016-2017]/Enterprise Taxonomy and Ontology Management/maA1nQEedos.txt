 all right i'm going to shift gears a little bit here um so i'm going to start off by explaining a little bit about who i am and then that's going to make a lot of sense about all the crazy things i'm going to say so my background is actually in philosophy and cognitive neuroscience that's what my phd is in so i moved from the philosophy department to the behavioral neurosciences department to study behavior genetics and primarily behavioral endocrinology and then moved in my post doc over to the department of industrial engineering to work on multi-sensor data fusion so philosophers talk too much and are too opinionated and engineers show too many slides unfortunately you get the most the worst of both worlds so with that what i'm going to talk about a little bit here is not only some stuff about technology what we're doing at austus i'm going to talk a little about the allotrope foundation which some of you may know about but i'm also going to talk a little bit about some things having to do with business value and aligning these things across different kinds of corporations and having worked in areas such as petrochemicals health insurance pharma medical device national defense and so on i see nothing but connections across all of these different verticals everyone has the same 10 problems my job is usually just organizing those in the way to attack them first so we're going to look at the current laboratory data situation which i think everyone in this room will kind of agree is a bit of a mess we're going to look at the growing importance of data as a corporate asset we're going to look at what semantic technology is and how it can help because i think there's a lot of confusion the word ontology already came up the word philosophy was used in the last talk two times and we're going to talk about moving beyond semantics because semantics is not the answer semantics is a tool and this is coming from a card-carrying semanticist i've been working in semantics since the 90s the reason semantics has not worked up to this point is frankly because we couldn't scale we couldn't scale we couldn't do anything more than solve toy problems but now with the dawn of big data with hadoop with cloud computing with things like this and the rise of analytics that are coming about i'm hoping to show you some ways that we can utilize the semantics in a reference data setting to be able to do some really really interesting things with advanced analytics and move beyond to what i think is going to become the smart labs of the 21st century so part of this is going to be visionary part of this is going to be innovative um that's i'm a part-time professor at nyu this is what i teach in is an innovation um so with that let's look at where we are many challenges exist today i mean we're all familiar with people's desktops that look like this right full of excel spreadsheets it's full of personal calculations people build their own data silos around themselves and then they're inside of a department which is perhaps another data silo which is in some division which is perhaps another data silo and so on and so on and so on so these data silos are actually insular they're inside of one another you also wind up with incompatible instruments and incompatible software types right this is what the pistol alliance and the allotrope foundation is trying to overcome right instruments don't talk to one another the chromatography machine doesn't talk to the weighing device and so on and so on legacy architectures exist we have to deal with these you can't throw your old systems out you can't throw your old data out but building bridges between them is incredibly hard doing point-to-point mapping is not going to work anymore there's too much data there's too many systems and those things are bridged i'm sorry are rigid and brittle when you build them with point-to-point mappings what happens in a few years you have to redo it and every time you have to redo it the cost goes up and so does the complexity because there's more things to integrate so we have to come up with something that's much more flexible sme knowledge resides in people's heads this is the biggest thing fortune magazine just put out an article this month asking why people are claiming that big data projects are not working even though they're investing millions and millions of dollars in them the answer was they're not actually solving the real problems people are are are using mapreduce they're using hadoop they're building nosql databases they're building data lakes to what end what's the problem they're trying to solve okay that's not often very well understood okay i've spent most of my career spanning the gap between the people sitting in the c-level boardroom and the people sitting in the laboratory because to my knowledge that's one of the biggest silos that are there that's one of the biggest gaps in any organization to overcome where's the company trying to go what are you trying to do where's the next innovation where's the next big driver and what are people who are down in the weeds actually building right are they just building things that make some job easier for themselves but not really part of a global process or path understanding this information is key you have to know what's in people's heads the reason why ontologies have also failed is because we've done a poor job oftentimes of building the models that allow people to really take concepts out of their heads and put it into the software into the data instead we just build data models that look just like all the rest of the data models we have except they're in a graphical structure so big deal but we all know from working with each other that concepts specifically as they're captured in language can be really really important i could point to anything in this room this this this this and i could ask someone to please raise their hand and tell me what it is and i bet that even though some people here are not native english speakers we come from different areas there's both men and women here we have different cognitive constructs different backgrounds different belief sets and so on we could come to some type of organized thought about what these objects are what they mean how they're used how they're not used and so on right this is communication this is how we work conceptually as people this is what we need to put inside of our systems but it's very very hard because machines are inherently stupid they they don't grow up with a background they don't have a childhood they don't have belief structures that come from something else and they don't really perceive things in the world the way that we do but what we're talking about here is really reference you have to have common reference when i point to this thing is it what's it called is it called a podium is it called a lectern what's it called it doesn't matter right we can give it different labels we can have different uses for it it can be the door stop if i need to hold the door open right it can be cover if i need to duck behind it it can be lots of things right it depends on the context it depends on my use value so if we can get this knowledge out of people's heads which is not impossible to do it just involves talking to them we can put this information into good models and we can use those models then to connect how different people in our organization are speaking about our data are talking about our experiments are talking about their jobs the business values the drivers and so on last the data schemas are not therefore explicitly often understood okay and therefore you get a lack of common vision between business units and scientists so because we don't get the information out of people's heads adequately we also don't really understand how it ties to the data we don't understand the structures that people are using we don't take the time to say what do you mean so here's a picture i like to show from a former customer of mine this is actually what happened inside of their r d shop they had to start an initial step if they needed to find something out about a product that was made they could only do a protocol search on a lot number period if you didn't know the lot number then you couldn't start the search you couldn't get any information for regulatory you couldn't get any information to go to production they didn't know which uh projects led to which product because on average there were seven to eight projects spread over eight to ten years that made a product and so this person had to find a lot submission and then had to go to this poor sorry fellow in the middle whose job it was to collect all the information for some regulatory body so this person had to go query lym systems had to go to a separate person for instrumentation to go query a whole different set of databases had to go to the marketing people to find out what's all the other uh packaging information and things that were done around this product they had to go to uh to get the lot in manufacturing info so there was an r d tech down there that of course had multiple databases that this person was in charge of they had to go then look for start and completion in the production data itself and then once they pulled all these things together they gave it over to their external regulatory affiliate who checked it handed it back it went over for verification to go to the fda or some other regulatory body and guess what it was 99 of the time wrong it was missing data it was incorrect calibration settings weren't there what have you so guess what it started the initial step go back now find more lot numbers and go through this process again this process took on average five to six weeks to produce one report we built a semantic system in a cloud for this customer that removed this barrier it basically took that person in the middle and it put a system in there put a machine in there this went to 12 to 40 seconds and anyone could do it from their laptop inside the company so it's not only about cost savings what we saw here was we saw a drive in innovation this customer went from all of these manual steps and all of this manual data correlation to the ability to pull it together quickly and easily and produce reports that were a hundred percent accurate and knew all the information it needed to know because it was all integrated on the back end right it took probably about a year and a half to do this but the outcome was r d suddenly was connected to regulatory r d had better connection to manufacturing r d had better connection internally and so on and so on and so on if this was a this was a fairly monumental step and was was one of the largest uh semantic cloud integration projects that i personally know of um and the the value of this is that it really changed the organization it just changed the way that these people thought about their data which leads me to the next point why does data matter data matters and i'm going to make a a probably a inflammatory remark here because i know how much your products are all worth but actually data is your most valuable corporate asset now companies that have figured this out a few years ago were amazon google these guys apple right they figured out facebook correct they figured out that having data right whether it's data on people data on consumers data on your products whatever is more valuable than the things you're making right because that's what's showing you the trend for the next things that's what's showing you how things come together furthermore your enterprise systems are increasingly becoming hybrid this means you have legacy systems you have everything back from old fortran systems cobol you've got databases relational databases hopefully not used touring machines and punch cards but you know you've got these old relational databases you've got this new technology coming in so people have probably said hey let's go to rdf and semantics and owl you've got excel you've got structured semi-structured unstructured documents text what have you now you've got things in social media which is one of the largest growing areas in in data these days right what are your customers saying about your products what are people liking and disliking you know what what's what's going on with your competitors what's happening out on the internet of things okay legacy data sources need to be combined with this new tech right this is just the way of the world so this is the way that gartner sees it this is the way mackenzie sees it this is the way that that many people in the modern world are moving towards therefore if these systems are becoming more hybrid the integration of this data is becoming naturally more complex the size of the data sources are growing i'm sure you've all heard the statistics 90 to 92 percent of all of our data now has developed in the last two to three years right and that that's increasing there's different user groups now within organizations different people now want to use data sources to make decisions answers need to reflect increasingly complex patterns okay this is no more about just basic storage and query finding and utilizing the key data within an organization is of increasing importance that's why the data is the most valuable corporate asset that you have the fundamentals therefore of the management of this data have changed basic storage and retrieval has given way to things like analytics and responsiveness people want near real-time decision making people want answers pushed to them they want automated queries right they don't just want to say okay here's the pile of data i have and here's a bunch of clunky dashboard tools and now you can spend half of your day you know driving around trying to find some answer in there right with with some probability of success right people want this stuff automated and they want it deliverable analytics and data science for the 21st century is taking off because the rate of this digital information is also growing exponentially so the type of information and the rate at which it's flying at you is increasing cloud computing is now critical for scaling enterprises you have to have some horsepower behind these things again this is why the semantic pushes has failed in the past i built some very cool systems when i was younger and i would always get to some point in the organization where i got in front of some big decision maker and they'd say okay but does it scale and i'd have to go not really it sells this neat little problem though isn't this cool look we have a graph and i can write this query and it's better than sql and didn't matter right the bottom line was it wasn't ready to go enterprise wide it wasn't ready for prime time cloud has fixed this we now have lots of horsepower we can run things in multi-node clusters we can have information through secure https web services micro services whatever you'd like to build that go right to your laptop your tablet your phone whatever you would like okay new data types are also being created and these things hold significant value a lot of the really important data in your company isn't in your raw data it's in understanding the patterns of how people are using your raw data it's an understanding how that data comes together and it's an understanding what it means that when we start pointing to things in the world we understand the referent that we're pointing to and therefore we know the raw data behind it if i point to the chair right and i ask a physicist what i'm pointing at he's going to tell me things about particles and waves and you know color doesn't mean color like it does in the regular world and so on okay that's just an explanation that's perhaps raw data my eyes interpret things it flips an image upside down in my brain it does all these different things that i'm cognitively unaware of but when i point at the chair i mean the chair and the key here is that your raw data has to mean something now right these new types of data that are being created are really data around patterns the patterns are what are important this is where we're going to get personalized medicine this is where we're going to get all this interesting stuff that people are talking about in the popular press therefore data is becoming more personalized and more context based people want their own data they want their own answers and they want things to make sense in some type of a context right so in order to do this we have to understand that the effect of data is therefore changing our business landscapes everyone is undergoing this process of change as i said 90 of the world's data was produced in the last two years so i always ask people how well can you mine and leverage this data what's it worth to your company to be able to do so right these are important questions asked an interesting statistic i found was that 900 billion dollars a year is the cost of lowered employee productivity and reduced innovation from information overload in other words big data is choking choking companies at the cost of almost a trillion dollars it's not because we don't have data it's because with all of that data how do you know how to use it how do you avoid that cost right so if we look at mckinsey and this is a bit of an old quote you'll notice it's from 2011 okay it's five years old now but i like it because it's prophetic because when they said this a lot of people went but increasing the volume and detail of enterprise information multimedia social media and the internet of things will fuel exponential growth and data for the foreseeable future correct that's happened and the use of big data will become a key basis of competition and growth for individual firms again correct i think that's happening so the key here is that we're seeing the rise of analytics a new kind of analytics we're seeing the rise of a new kind of data that we're talking about and the ability to harness and pull these things together requires a different approach a different kind of philosophical approach so enter semantic technologies and by the way i include semantic technologies as part of data science okay and i'll explain why in a moment semantics has its origins in philosophy it's generally understood as the abstract study of meaning okay so edmund husserl in 1900 1901 wrote this great two-volume book called the logical investigations and it was the first real treatise on formal ontology okay you also have a a host of other uh philosophers kant to heidegger who talk about things like being and they talk about how we understand things really has to do with meaning what do we mean by our data what are the concepts that are in there what are the things you're using that data for what does the data represent it's distinguished from syntax this is an important distinction syntax are the markings or the language someone uses as a rule-based grammar right so the letters we use in the english alphabet versus the the different characters you use in arabic or in russian or something like this that's syntactic right xml versus rdf is syntactic it's just a syntax it really doesn't matter what you care about is the meaning behind what you're representing so if i ask what do we mean by washington well we have a president we have a city with some nice monuments we have a state that by the way is on the complete opposite side of the country from the city with the nice monuments there's a bridge i can take in new york there's a football team that has an inflammatory logo that people talk about a lot there are people like washington who played for the jets and then there's a baseball team who does not have an inflammatory logo that many people talk about right so all these things mean washington so what do you mean how do we use the word washington i mean how do we ever do this well it's because of context if we're talking about presidents then we know we're not talking about bridges and monuments and things however presidents have something to do with washington dc right so lincoln was a president and lincoln has a monument so you can talk about lincoln as the president or the monument right but it's about the context it's about pointing at the thing and saying what do you mean and when we talk we use lots and lots of cues for these things the key for this in semantics is you have to build these cues into the models that go into your systems this is why it's not about just top-down bottom-up approach okay that to me is very old thinking it's both application-based formal ontologies i published a paper on application-based formal ontologies back in 1999 and said look you have to work from the top down and the bottom up at the same time that's what engineering is so if we look at the evolution of these items right we see that code used to be more important than data then you hit the relational data model era data became as important as code and now thanks to the semantic web era the data is more important than the code it doesn't matter what it's written down in anymore i can take my rdf i can turn it into xml i can shoot the file over to someone else they can open it up and then reconvert it back into rdf if they want it doesn't matter what matters is did the class structure stay in place are the relationships still labeled the same is the hierarchy the same the other thing i'll say about taxonomies and this has to do with some of the work we're doing in aletro there are two ways to build taxonomies this also has to do with the top-down bottom-up business if i take a very very rigid notion of a taxonomy as a class structure right with subsumption relations in other words where i have issa eric little is a human being human being is a is a homo sapien which is a mammal which is a carbon based life form okay that's showing me clear is a connection subclass super class relationships structured ordered right this is a top-down approach this is how i know we can use the same kinds of words but we also use things like scots definitions right where we use broader and narrower terms right we can say well this term is just a broader term or there's a whole bunch of synonyms that i can use for these terms for the same concept it's a different way of approaching taxonomy construction both have to be adapted so it's not just about subclass superclass and it's not just about word relationships both have to be used so in a subclass superclass you have acyclical tree graphs real hierarchies the other way looks like word net you have graphs right you just have words generally in a network related other words in allotrope therefore we're doing both so we have certain structures that we put in for things on equipment material process and result we do our work in metaphysics to make sure that we have the structure of the universe kind of correct right to say that a mass spectrometer is a spectrometer which we're calling a device but there are other devices which are not such things and we know that for example a process is an inherently temporal thing whereas a piece of equipment is not it's a spatial thing so i describe the parts of spatial things differently than i describe the parts of temporal things because temporal things are never standing still they're always going through some process they're in a state of constant becoming and fading away right and and for any of you who know about ontology research and you go look at the work in bfo basic formal ontology at a university of buffalo where i worked with barry smith this was the idea behind this snap and span so we are incorporating this into allotrope and then we use these basic structures and you can see how basic this is to then do this kind of scoss broad or narrow types of terminologies so where do we go we go from code and lists basic data to terms things like soil plant drug compound whatever then you build a controlled vocabulary so let's agree upon some terms are we going to call this thing podium or lectern which one we could take a vote and we'll say the preferred label will be podium but if you look up lectern it's going to point to the same thing right that's all we're saying control vocabularies give us taxonomies now we can put things in a hierarchical sense because things do in the universe exist where they should be we can then build thesauri we can then build rdf graphs we can move to owl ontologies and eventually get to things like reasoning rule based logics and new patterns so i'm not going to spend a bunch of time on the levels of semantic expressivity because i'm just about out of time but basically you have weak and strong and you can use your knowledge representation to separate the schema level from the data level this is what's really important here we're keeping the concept separate from the data we all know these benefits you get interoperability better searching and browsing reuse you can show architectural intent because i can put all kinds of notes in there i get automated reasoning if i want and i get a nice developmental life cycle and then when i move to analytics what i'm able to do if we look at this example from the the chess board you know this old fable of the emperor who brought in the peasant and asked him to perform a job for him and he said he would if he puts one grain of rice on the chess board and for every square on the chessboard just double the grains of rice so the emperor thought what a great you know what a great deal sure a few grains of rice right well until you get to the end of the chess board and you realize that uh what the guy is basically promising is 461 billion metric tons of rice which is roughly a thousand tons more than was produced in 2010 globally so what this means is that on the second half of the chessboard as you start keep doubling doubling doubling right you wind up with very big numbers this is where data is going this is where analytics is going the key here is that we used to worry about processing speed we shouldn't processing speed grew a thousand x between 88 and 2003 algorithm design grew 43 000 times in that same time period so it's a 43 to 1 increase in the complexity of the algorithms versus the the the complexity of what we're doing four v's of big data i'm not going to spend a bunch of time in this except to say where we're sitting with allotrope and with the semantic part is in the variety space volume velocity people know veracity has to do with clustering mathematics and uncertainty probability sits there the key here is to bring those two things together the variety and the veracity so why do the semantics matter because big data approaches require proper metadata all your algorithms run on classifiers what do the classifiers refer to they're going to refer to different things based on who built the classifier if you have a nice reference data model your classifier is now aligned relationships matter therefore understanding perspective in context is critical so you have to understand more about the data than what's in the data and you have to have better models and schemas therefore my last thought where i think smart labs in the future go is this list we have integrated data with common reference data structures in the form of vocabularies in these taxonomies we have shareable data so you have easier interaction across teams and business units you can now link the scientists to the business folks you get scalability because of big data applications you get conceptual representations so now you have context and perspective we can talk about things in a variety of ways and this all leads to ultimately advanced analytics which is a way to really blow up the world and talk about things in new ways and apply logic with mathematics at the same time something my team and i are working on right now so with that i'll be here both days if anyone wants to stop by and chat more about these concepts and thank you very much enjoy the conference you 