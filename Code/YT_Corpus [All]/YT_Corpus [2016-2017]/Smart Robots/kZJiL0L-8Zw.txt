 Smart robots are no longer the stuff of science fiction. But intelligence is more than besting humans at board games. It's basic physical skills, too — like turning door knob or opening a bag. Babies take sensory information from the world around them to figure out how to use their bodies and interact. Robots aren't quite as sophisticated. In the past, they've failed pretty epically at controlling their bodies. But new improvements could go a long way to help machines sense the physical world and learn new skills based on what they see, feel or hear. Some senses are more easily mastered than others. If you have an iPhone you might interact with Siri, an acoustically astute artificial intelligence that picks up on your speech patterns to better respond to questions. "Hi, Siri, are you alive?" "In the cloud, no one questions your existential status." Other senses are trickier. Take touch. Humans are bombarded with tactile information through skin — temperature, pressure, texture... Researchers at the University of Colorado took a similar approach with a robot named Baxter. They gave it smart skin that translates a flood of vibration data into simple messages. Baxter's sensors can differentiate between 15 different textures. Touch sensors also need to be tough. SAIL-R, a bot developed by a team at Stanford wears durable sensors on twirling legs. Soon it may be able to tell hard ground from grass or sand — and adjust the way it scrambles forward. But there's a difference between sensing the world around you and actually doing something with that information. Researchers at UCLA gave their robot squishy sensitive finger pads and a plastic bag full of cheerios. The robot actually figured out how to close the bag — on its own. Touch is a handy skill, but staying upright is a pretty important one. Your inner ear, eyes and feet all give you a sense of balance. Some robots, like Atlas, are equipped with body and leg sensors that do the same thing. Atlas might take a tumble now and then, but a new upgrade enables the bot to get right back up. So that's hearing, touch, balance... What about sight? Lasers can tell a robot how far it is from an object or obstacle Google's driverless car also uses lasers, radar, cameras and software to recognize the shape of a pedestrian or the outstretched arm of a cyclist. Other robots tackle even more complex visual challenges. Star is a surgical robot with senses that go beyond human abilities It has 3-D and near infrared cameras — like wearing night-vision goggles. Star can see glowing dots marked by humans on tissue, calculate a stitch plan and sew up a live animal — and maybe one day a human patient. Star's makers hope to add more superhuman senses, like measuring blood. Things that seem like baby steps for humans are giant leaps for robotkind, especially robots designed to work in the real world. Stickybot, for example, is a gecko-inspired robot that uses special toe pads to scale walls. MicroTugs are teeny tiny robots that can haul materials hundreds of times their body weight. Smart physical sensors can make these bots more aware of their environment and allow them to focus on more complex tasks. One day, such sensitive robots might not work for us or against us... but alongside us. 