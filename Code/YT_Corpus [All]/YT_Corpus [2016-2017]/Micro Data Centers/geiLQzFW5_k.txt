 hello my name is Val berkovichi I'm the cloud and big data czar at netapp it is my distinct pleasure today to present to you at the virtual data fabric event and we're going to talk today about a particular use case of the data fabric you're going to be getting lots of information about the data fabric itself but the lean cloud use case of the data fabric has become a very very popular way to really explain the value and of course this is my twitter handle there at the bottom of this slide if you're interested in live tweeting this virtual session so to speak please feel free to also tag me at Val boo which is spelled VI lb double zero first thing we're going to do is have a controversial brief discussion about the definition of cloud and the joke in the industry is of course there's as many opinions about cloud as there are people in IT but the reality is that cloud is fundamentally first and foremost about making money specifically new incremental business value and I speak today actually the day after we had Microsoft Amazon and Google all three of which announced fantastic revenue on the back of cloud earnings and cloud revenue to Wall Street yesterday so clearly it's very topical subject as we end October in a year 2015 what I'm going to refer to in this particular slide is something that's a bit more detailed and systematic it's an analysis in a report as a matter of fact that's published monthly updated monthly by a venture capital firm called bessemer venture partners and they published something you can easily google called the cloud index this index is comprised of brand new companies that are cloud native born in the cloud application so to speak and it documents the public accounting meaning either the IPO value or the merger and acquisition M&A value business valuation of companies and applications services that were born in the cloud they started measuring this about three and a half four years ago around 2012 and year-to-date up until now multiple years to date up until now we see that the actual business value the net new business value created by the cloud is already up to 178 billion USD and what's interesting to note are the companies that are not yet in the index because they're not public yet so uber rumor to be valued at about 50 billion dollars is not yet on this list Airbnb rumored to be valued about forty billion dollars I'm not yet on its list and of course companies like Facebook don't even qualify for the category and yet many of them consider Facebook a cloud service so my personal estimate is the reason we're all talking about cloud is there's been about four hundred billion dollars a new business value created by the cloud measured new business value and that's why it continues to be after all the easier is such a hot buzzwords it won't go away now of course for every bit of revenue there's also a cost and there's a second report that's really important to follow here as we explain a value of net apps data fabric this is by an analyst firm called a 451 they publish a report called the cloud price index as opposed to the cloud index from bessemer venture partners and the 451 s cloud price index highlights some very key information the two bars are the two lines you see actually progressing along this chart the bottom one the dotted blue line is a collection of the small number typically three to five percent of all cloud services offered by the major cloud providers but three to five percent of them are discounted heavily on a regular basis and that's what the cloud index clog price index excuse me tracks the cloud price index tracks the actual discount of various cloud services over time the bottom again dotted line index shows that there's a fairly aggressive price decline on some commodity cloud compute and commodity cloud storage services but notably they are the vast minority of all the higher level development and analytic and valuable cloud services that the service providers themselves provide the other ninety five to ninety seven percent of services are represented by the solid orange line at the top and you notice a stark difference in price reductions over time meaning the vast majority of cloud services that customers pay for our not heavily discounted over time and therefore particularly if you analyze the financial results of Amazon Web Services Microsoft Azure cloud and Google's cloud you'll notice that they run very very high profit margins high gross profit margins that are typically larger than a 60 odd percent I tea vendor gross margins and even higher operating margins than then systems vendors that sell both hardware and software so clearly cloud is a very profitable business and unless you're very very careful cloud is not a very cheap alternative to traditional IT so where are enterprises spending money on technology that is a question that gartner asks very often and it's a much smarter question than what your IT budget is what I'm showing you here on this slide is a result of a global survey of the global 2000 and again the question is where are you spending money on technology to improve business as opposed to what your IT budget is and the three categories that emerge our first a 14-percent category as a global average meaning particularly in the United States some of those numbers like fourteen and twenty percent might be higher but outside of the United States whether it's Europe or Asia China India and so forth those numbers might actually be lower the global average is fourteen percent on the initiative called business transformation and that is where all sorts of brick-and-mortar enterprises invest in new digital services to fundamentally digitize their companies to prevent from being Amazon's if you're a bookseller to prevent from being Netflix if you happen to be in a video business to prevent from being uber door prevent from being Airbnb effectively either digitized as a defensive maneuver to protect a significant install base and market share you might have or more aggressively digitized to capture new markets entirely or to capture market share from slower competitors that don't digitize their businesses that's the fourteen percent of business transformation budgets that we see right now following that is about a twenty percent category of technology spend and that's comprised of two different kinds of investments one is of the various business transformation efforts that succeed typically you employ a fast fail an MBA style fast fail approach to experiment with business transformation not every experiment succeeds but if you do of the ones that are successful and you want to deploy them at scale you invest some of that twenty percent in actually deploying those experiments that are successful at scale to recognize even more revenue and more market share from the various new product or service another example of that twenty percent would be virtual desktops where a lot of companies now want to take their knowledge workers which had a lot of power on desktops and laptops but make them much more mobile and closer to their customers via tablet and smartphone technologies so VDI is another great example of what goes into a 20-percent category and finally the traditional IT budget is actually that sixty-six percent what's left over is typically keeping the lights on or maintenance mode of legacy applications and the IT budget pressures on the sixty-six percent continue to be very severe a lot of IT departments you know surprised if you're if you're working for one of them or service one of them continuously have to do more with less today but it's a very different conversation for business transformation initiatives it's a very different conversation for growth of business transformation initiatives or growth of new applications for IT the other thing that gives us confidence about this data is it's not a brand new survey it's six years and running as we near the end of 2014 2015 Gartner will update the survey and let have seven years of data and we've seen a lot of consistency going back to 2008 in these three categories the numbers might go up and down a few percent but at the end of the day these are the three dominant categories and in proportion you see business transformation being strategic with no limitations really encumbered you see growth following that and finally the remaining portion of that sixty-six percent global average is the IT budget so let's take a look at life cycles now life cycles are very important and what I've done with this slide is simply map those three categories into a lifecycle visual that we're going to use for the rest of this presentation after project life cycles we're going to drill down specifically into application and application module life if you've heard of docker and containers which are a very hot buzzword in our technology industry today you'll notice that we can divide a lot of these life cycles into micro services which is another common name for container based applications or container based application modules and the three dominant categories of those life cycles are the dev and test life cycle followed by a deployment and scale lifecycle and finally at the end of that life cycle you have a maintenance mode for typically legacy operations and it's worth noting that you can have very tight loop here for agile development processes but you can also have a more waterfall elaborate style loop you know if you're doing a waterfall in methodology which takes a bit longer and you have much more distinct phases between these stages here's a final bit of information I will share with you before we dig into the data fabric itself and it's a very revealing survey very current this is IDC measuring what happened in 2014 with enterprise cloud spending and the good news is for cloud cloud service providers is that enterprises spent a fortune in the cloud particularly with public clouds in 2014 but what enterprises also realized is there's enormous innovation value in public clouds the development tools the development services are extremely rich extremely empowering letting you experiment quickly letting you again fail quickly with things that don't work and letting you deploy even as prototypes with very little code extremely rich mobile applications tablet applications internet of things iot applications with geolocation and so forth a lot of development and innovation is really enabled by public cloud but after the development phase is eliminated as I showed you in the previous slide after we pass through the development and testing phase we basically see that the majority already we're already after the first year at 51.6 percent of all enterprises surveyed the majority of enterprises repatriate data and workloads back to other service providers or other clouds and that's because of the reality of the cloud landscape if we look at the three categories again from a cloud category perspective we of the hyperscale public cloud to the top we have service providers or managed service providers over on the bottom right hand side and following the lifecycle we have hosting providers or on-premises data center as the third category and where innovation happens today in fact I like to say to be a little bit controversial if you're in charge of a business transformation initiative at your company and you're not using one of the public cloud vendors and some of the enormous capabilities they deliver to your developers you're actually practicing professional malpractice you're letting one of your industry competitors beat you to innovation by actually using the public clouds where they're extremely valuable and as we know development and test phase is really benefit from having an elastic infrastructure meaning you can predict how many servers you'll need to prototype a particular feature and you certainly can predict at scale how many servers you'll want to use for massive testing of any particular new feature or application and the elasticity of public clouds is unbeatable for that value that value of the life cycle where the workloads are fundamentally unpredictable however any professional application developer today any professional dev ops team instruments their applications and their workloads at a very detailed fine-grained level there's a whole ecosystem of vendors with companies like New Relic and others that deliver performance metrics to make sure that those applications for the mobile users a tablet users the web users are very responsive and quick so that they encourage and drive more user traffic and as you measure all that data you understand your workloads at a much better level and the workloads become less predictable therefore the value the economics of the elasticity has lower value when you work clothes go from unpredictable to very predictable and that's when you can become to realize that operating predictable workloads with efficiency with optimizations for performance with the ability to adhere to actual international regulations around data privacy as per the recent EU safe harbor ruling and from a overall control perspective it makes more sense to take workloads that are now predictable and move them onto custom is infrastructure that's designed for a more predictable style of workloads and this is why a thriving ecosystem now is emerging around the public hyperscale cloud providers with providers such as HP which recently announced their Helion service will no longer compete against amazon but be able to take workloads that move off of amazon that are more customized and tailored and more predictable Cisco's cloud service Rackspace a lot of openstack-based clouds are really tailor made for taking predictable workloads that don't need while the elasticity and operating them with better quality of service better governance and control and most importantly at a better bottom line cost and finally can continue this life cycle trend all the way through to hosting vendors or your own promise on on-premises data center for example well known SAS companies software as a service such as salesforce.com have been delivering applications in a cloud format for many many years now and many of their applications and application modules are themselves legacy cloud applications it makes a lot more sense for them to use a legacy operational model to continue to service those workloads and be able to free up money and free up developer resources in time to develop new functionality to continue to gain more and more market share so where does a netapp data fabric portfolio fit into all this what I'm showing here are actually two building blocks at the bottom the traditional hardware devices that we've sold a merely building blocks in the data fabric today and above them are a bunch of rectangles the blue rectangles are actually rectangles that represent virtual controllers that is software operating systems such as cluster data ONTAP storage grid web scale alter vault and even the Mars OS inside flash ray those are all now virtual controllers that sit on top of optionally our hardware building blocks or other supported third-party servers white-box servers if you will meaning that enterprise architects now can configure as many of these virtual controllers as they need on qualified hardware that is not net app on cloud service providers which of course you know have the hardware completely abstract 'add from the software itself as well as on netapp hardware where we predict that you'll have the optimal price performance the optimal reliability and availability and serviceability characteristics for predictable workloads and these rectangles the blue ones are netapp sold and supported the orange ones are open-source supported rectangles represent really useful virtual controller building blocks lego-style for enterprise architects again to deploy on premises in the hyperscale cloud as well as on qualified third party service providers and as you may know netapp already has a list of 275 qualified service providers that are part of the netapp service provider partner program and every one of those partners and more are now qualifying themselves to be data fabric ready data fabric certified so these virtual controllers now give us enormous power in terms of control points throughout the various cloud life cycles so that we can follow the lifecycle the natural life cycle of application and application module workloads which means now we give enormous innovation power to your developers to go and deliver true business transformation in the public cloud where those providers provide maximum value with their economics of elasticity and as those workloads become instrumented as they become much more predictable and as you can figure out exactly what infrastructure requirements are going to need you no longer have to pay that compound text for a very stable predictable workload in an elastic public cloud that isn't priced for that kind of workload you can certainly support it but the price becomes instead of something that's valuable literally an ongoing compound tax you don't have to pay that tax anymore in the hyperscale public clouds you can migrate those specific workloads to other service providers that are running vCloud air that are running OpenStack CloudStack or any other kind of orchestration environment and finally migrate those back to hosters or your own for on-premises data center and it's the data fabric it gives you the full visibility into where your data is throughout its life cycle across all these different service providers gives you the freedom to choose between all these three different kinds of categories of service providers and of course it gives you the control and data mobility to be able to easily use mature widely recognized leading technologies such as snapmirror for data mobility between the various cloud providers or native open a native object storage grid web-scale replication as well as the altar vault controller itself which is a natural data mover designed to stream workloads with compression and deduplication built in so freedom control mobility are the key values we bring with a data fabric portfolio to the modern application development lifecycle what we're showing here is that the back half of that development lifecycle more of the legacy mode and what I'll conclude with here today is the most advanced form of the data fabric and ironically this was the one that was available earliest about two years ago initially this is where you come to the realization that workload mobility is a necessary thing for a sustainable application in the cloud a sustainable application module in the cloud however workload mobility as we remember from our vmware days is far simpler than data mobility because of course data has gravity it's a well-known concept within enterprise IT architecture circles and because data is hard to move there's always more data available to move than bandwidth we can afford to move it well we end up bringing a lot of workloads to the data and the notion of moving gigabytes of data around seems sustainable terabytes of data around this life cycle seems manageable and may be affordable but it's becoming clear today that if we start to move applications at scale big data applications in particular and the calculation starts to include petabytes of data movement then that movement throughout the lifecycle is no longer sustainable it's no longer affordable and so the most advanced form within that a data file break is enabled by a product we call netapp private storage where we strategically co-locate the data adjacent to the compute data centers of the various cloud providers be the hyperscale public clouds tier 2 OpenStack style service providers or your own for on-premises data center and we use leading colocation partners like equinix for that and we actually leverage very advanced features that Equinix provides called a cloud exchange which lets you dynamically provision capacity to enable a storage connection from the compute side of a cloud data center to the storage side of your data which is controlled and managed and owned by you in your own private cage within a colocation facility these colocation facilities because they are geographically close and adjacent to the major cloud data center providers give you fantastic performance and latency between the compute side of what you want to do in the cloud and the storage side which you want to own in fact I've recently spoken to one service provider out of Germany called DARS which services a lot of financial customers out of Frankfurt and they have dark fiber connections between their colocation facility and all the major cloud providers and they're seeing performance as good as four hundred microseconds put another way that's point zero point four milliseconds of response time which is the kind of response time you'd expect to see with the best all-flash array solutions in the market place today so there's no compromise and performance here there's full ownership of the data and you're able to have control and governance and auditing enabled on your data but you're able to use the cloud for what its best at which is renting the compute while you own that data and fundamentally what this lets you do is accomplished what every business leader wants to do today in a global enterprise which is to innovate like a start up with the imagination the creativity the pace and certainly a lot of the exciting exciting user adoption amongst leading cloud users of data so innovate like a start-up but as a large global enterprise business deploy like an enterprise with mature security policies mature date availability policies through backup recovery in archived and very very sophisticated control and very very high levels of performance extremely low latency which means you can position your data globally what closest to where your users are so this is the end of the introduction to the lean cloud use case for the data fabric I hope it's become useful to you and once again thank you very much for inviting me to your data fabric virtual event this is Val berkovichi signing off 