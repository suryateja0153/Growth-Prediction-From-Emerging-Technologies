 and today we're going to talk about how we're using micro services and our road to migrating from amalah lift to a more micro service based architecture so that's essentially the first part of this presentation and then we have a second part where we will you know do some more deep diving into Cuban at ease if as anyone heard of Cuban Eddie's before okay cool is anyone using micro services okay that's good so you will have to I mean if you have any questions for anything we just ask away or if I say something you know stupid which which happens just interrupt me and yeah correct me I mean I don't know everything but yeah agenda will look something like this so we list briefly mention what pork store is and why we're using micro services and when we're talking about why were you so much service we will also talk a bit about what microservices Center pros and cons and all those kind of things and we will talk a bit about organizational or team structure as well just a little bit and then we'll talk a little bit about docker and why darker alone is it's not enough if you want to do micro services and then we will probably not talk about various kinds of orchestration frameworks if anyone is really interested we can talk about that afterwards but then this is the the next session where we will talk more about Cuban at ease and we'll see how far will how far will go so I'm going to start off here with a little disclaimer and I will be talking about a lot of different technologies during this presentation and unfortunately we won't have time to cover you know everything in in detail and there is you know a lot of things that you can look into here but this is actually not an introduction airy talk like there will probably be some things here that you might not have heard about butts I mean you just ask if you have any questions and we can you know maybe talk a little bit deeper about something but the main purpose of the presentation is to know present you know the road that we took of you know migrating from a model if to a micro service and get an overview of yeah what you need to think about when you're doing in micro services in production and yeah okay so pork stir this is where I work and we are a mobile parking solution company so I've as an end user you will probably use you know our app that looks something like this and you can use this app to start your parking or extend your parking and stop your parking and so on but this is just like one side of what we're doing there are other sites as well like front desk integration and if you're like a parking zone owner you have some back in interface to look at statistics and configure things and so on so actually we if yes you know you look at this like 30 seconds they think like oh how hard can this be you know like everything else is so you know everything is easy i mean this this takes a week something to create but it's actually a lot more complex we dig into this domain it's a pretty interesting domain as well so why is parks to reducing microservices well first of all let's you know look at what our micro service actually is like I don't remember where I stole this quote from what I think is pretty good so here it says that micro service is an approach application development in which a large application is built as a suite of modular services each module supports a specific business goal and uses a simple well-defined interface to communicate with other modules yeah I think this is a pretty good pretty good yeah definition if you will of micro services and microservices is leased from the developer point of view you know probably came about because of the frustrations that people were we're having with you know a monolithic system like monolithic systems are you know hard to change and I mean they're hard to evolve and so on and since they're hard to change and there you know then it becomes hard to redeploy I mean it takes it may take a long time I mean you do a little fix but that fix may affect you know other stuff in this big piece of software so with microservices you you want to like decompose like your big system into smaller parts so that's the idea of of a micro service and I think that this is actually really important I mean when you know microservices became like this hip thing a couple of years ago you know people were talking about Oh microservice should only be like 200 lines of code otherwise it's not a micro service and I've always been skeptical to that because I think that yeah or at least in my view I think that am I could mikrosil should be exactly as large as this needs to be it shouldn't be larger than that and it shouldn't be smaller so I mean it's nothing to do with the number of lines of code in my opinion it should you know solve one specific problem and do that well that's in my opinion a a good microservice so why would you like to to do this well one of the reasons is it fall it should follow this single responsibility principle and that is good for for many reasons I mean it's easier for you or any and simpler if you you know you have like a smaller problem to you know put in your head you can only fit so many things in your head it's it's harder when you have this like very big system and another idea with the micro services is that it should be more resilient to failure so if one part of your system you know one part of your you know big system shouldn't cause you know everything to crash I mean you should something crashes only that particular piece of the software should crashing rest of the system should continue working and microservices should also be easier to enhance and it kind of you know follows from the same you know principal from the single reponsibility principal me they're easier to enhance because there's you know not so much code or easier to understand and it's also yeah since the research understand and they have their own life cycle I mean you can deploy them at their own pace and yeah this is kind of related to the resilient part I mean it should have low impact on on other services so service should really be self-contained and easy to understand yeah he saw deployment will talk about that and one of the nice things with the micro services that you want to have is the freedom for the developers to choose technology I mean you probably you know shouldn't you know let it loose and like you know if you're if you're in a large larger organization you probably want to have some architectural baseline or something but you know in in essence you should be able to pick any technology that is suitable for the problem domain that you're working with ideally but there are of course also many reasons of why you should not use micro services so one of the problems is that if you if you're doing microservices all of a sudden you have a distributed systems system and distributed systems are hard and you know all of a sudden you will end up with like remote calls instead of having you know call status you know is in memory and and that's it's tricky and also your system will most likely become eventually consistent and it's really hard to have like a distributed system and I would almost say impossible to have a fully strong consistent distributed system i mean that's that's something everyone wants to have that but it's really hard so what this means but but you would like to have this eventual consistency as strong as possible so you would like to have some sort of strong eventual consistency but what you have to you know you have to take into account that messages can arrive more than once so systems will prob need to be idempotent and you're you know messages will arrive out of order as well and you should be able to to handle that and this is this is tricky and then of course you will have more operational complexity I mean before you had your mana leaf and you you know you deploy this I mean it was yeah you know that was pretty nice but now you have a lot of you know smaller parts that make up your system so you need a better like you really need to automate things if you haven't done that already you need some sort of automation you need is DevOps and continuous delivery and stuff like that and it's also really hard you know to find what you know we talked about you know what is the micro service like like how do you construct one how do you like what is the right boundary from for our micro service and that is it can be really tricky and getting that wrong will you know end up with you know you will have some shattuck communication and your system will be will be really slow if you get this wrong and this is really hard problem and then of course you have to deal with partial failures in your system because if you have now have systems like communicating with each other like if you know system a talks to system be a system be slow or down maybe you have to be resilient to that so you don't so system a don't you know accuse build up and stuff at that so system a will also crash that's because system B is slow so you have to protect yourself against all kinds of failures okay so before we we move on I just want to make some some definitions yes does everyone know who this guy is yeah at least yeah that's Ricky the closure closure guy and have you seen his presentations good and for those of you who haven't seen you know all of these presentations you should go home after this these two talks and watch all of them twice at least maybe three times they're all very good yeah I actually I think this one is or not yeah simple made easy i think for me that's my favorites and the value of value stores are really good presentations but I I will at least try to to to use these definitions of simple and easy that rich Hickey is talking about during this presentation so when I say simple what I mean is that there is no like interleaving of different things I mean like you know it should address you know one concept and it shouldn't be conflicted with other concepts so this is what Richie key means bye-bye simple and easy on the other hand it's something that is close at hand something that we know maybe like I don't know maybe you're a ruby developer and you pick a ruby on rails so maybe pick that because you know it's easy you're familiar with that but Ruby on Rails might not be the simplest solution and and this is important because the developers has a tendency to you know pick something that is easy something that we know and so we this is like a graph of stole from his presentation but i think that this is this is true so probably if you pick something easy you will get going really fast but then after a while it will like flattened out and if you have a larger system and a complex system you will actually be better off if you have you know shows in something simpler in the long run so let's look a little bit about pork store market services again so now i have a little animation so you will you know guess why we were or yeah why we are moving away from a monolith and now this is the monolith and can you see that it grows and grows and grows so like it's it's like a kind of big now so yeah oh this is this is the reason okay so yeah we started out as a model if and yeah this is actually this allowed us to move very fast in the beginning I mean we were using some think all the spring Roo in Java when we started out and this is like something similar to Rails where you lose scaffolding and generate a lot of stuff and yeah this is it's not supported anymore so I think it's a dead project but yeah it had you know it was easy we new job and this was like you know we got things up and running fast yeah easy and it also you know it allowed for experimentation we didn't we didn't know this domain very well you know we had to be able to experiment and I think that this might actually be a good thing like if you're getting you know your startup and you know you want to you know you need to learn your domain you need to learn what is it that you actually want to do when if we start off by you know doing too much of you know technical things like operations and you know spending all days with the Jenkins or or other stuff like we won't get any work done the most important thing like when your startup you need to get things out fast that works you need to try out ideas and being able to refactor fast but we definitely have run into two problems with this approach so we had this you know this is a classic example like the boundaries in amalah for really like blurred we didn't know the sub domains that we had in this this context so there's like that is typical like you have a person and this person is like used in many different contexts so I don't know it may be used in in payments and order and invoice and you know our core domain you know it's shared between all these different context so it becomes really you know huge and hard to to reason about and that you know it it makes the system complex it's not a simple system and I mean this works when the system is like when it's small it works but when it grows it becomes really complex so it's takes longer to add a new functionality so this was one of the things that we were suffering from but another thing that was that it was difficult to keep up with new libraries since we were using like spring roo it had some dependency on on aspectj which had some dependency on the java version so you know we couldn't use some libraries that depended on you know other versions of SBA and it became you know really hard to upgrade you know our core you know frameworks like spring it took a very long time it was really really painful to do that but if we want to like you know have some retrospect you know about this model if you think sure I mean you can always do things better when you look at it you know that's not always the case but I mean I still think that you know it's part of started off with a one-man show so I mean to go too much you know focusing too much and you know splitting the domain in blah blah blah blah blah I mean they would have taken too much time to get up to speed so I still think that I mean this was probably a good idea when you look back at it and it's also i think it's it's it's easier to to do this decomposition correctly off your big system if you you know you have an idea of if you understand your problem better okay so let's look a little bit into the organizational aspects of doing microservices and this is our new office in eluned that we're really proud of its it's actually it's a great place and yeah but but you may see that it's not like we're not a big company we are seven people working and working with this product so I mean we haven't run into all of these organizational our team issues that you may run into if you're working at a larger organization that will be completely different I mean we are sitting very close to each other you know we can you know talk to each other we can have direct communication and that is much easier when you're implementing something like this so it will it will be much harder if you're working in a building like this like in a bank or something similar that has something fancy like this so what you typically do or what you typically yeah should do is to organize your team's as independently as possible so quite possibly you will have one team that is developing one micro service and not only developing because the the team should be fully responsible for this service and that means that you you need to deploy it you need to you know make sure that it's up and running you should you should be the one that you know wakes up in the middle of the night if this service goes down you shouldn't just you know develop it and hack it and then you know throw it over the wall to some dev ops team because you should be responsible for this yourself and you know this may Mase you know seem scary but it also gives you a lot of freedom because you also need a lot of freedom in order to to do something like this your team should be you know it should be possible for you to choose whatever language you want to have yeah if you can argue for it at least so this guy is Ben Kristensen down there and he's worked at the netflix i think it's moved to facebook now but i think it has some you know some good litmus tests about organizations and micro services and it has a good talk called the don't build a distributed monolith that I can really encourage you to to check out as well and it has some questions that is you know you are required to answer yes to these questions if you are doing microservices correctly at your company and the first one is that yeah you should be able to as a team choose you know you're the language that you that you feel is wait for for this particular problem without convincing a central authority so this is one thing that you that you need to do and you should also be able to choose the concurrency model that you want to use in this micro service so this might be you know maybe it's good enough to have some Fred based model or maybe you want to use actors or rx or or fibers or something you should be able to do that and the protocol that issues in inside of your micro service I mean should be should be different to the one that you you know present to the outside it's important not to have like this highly coupled binary protocols for integration because that will not be a good choice like like Java RMI or something like that we're really coupled to the language inside of the micro service so that is something that you want to to avoid and another thing that you should be able to answer yes for its temporal decoupling and you know we all know that you know even if you write you know the perfect software after you know a year or a month you know our world moves so fast I mean after after a while I mean this won't be the perfect code anymore because things around us change the world change around us you know we get we get new libraries or you know new frameworks and you you know maybe I don't know tom cat what's the hip thing and now it's Yeti or undertow or something I mean do yeah you should be able to to adapt and should be able to upgrade libraries without you know be afraid that you will affect like your core system or other you know services in your in your big system and you should also embrace like this devops culture this is really important I've I've said that before but you need to be able to you know deploy frequently and yeah it's like you cannot really talk about organizations without mentioning this guy conway and it has this famous quote that says that any organization that assigns the system will inevitably produce a design the structure is a copy of the organization's communication structure and what this means is that your organizational or you know team structure will very much very likely affect the software that you're building so for example if you are like you're developing a compiler and you have four different teams you will most likely end up with a four pass compiler I mean this are you can google for this and you'll find a lot of different articles online so this is exactly what you know famous you know microservices companies like like Netflix they know this and they like they you know they had heard to these principles and they try to you know structure the teams around the services that they have so that is also really important so I stole this picture from martin fowler website and i think this is you know can you know summarize it pretty well I mean you should have some level of maturity in your team in order to do microservices otherwise you will you will probably have a good chance of failing okay so let's go back to you know model if two microservices how do we actually you know how do we get from among lift to a micro service so one way is of course to you know let's just you know is throw this you know thing that we have let's throw it away and we rewrite everything i mean that's like that's great i mean we you know we've all wanted to do that you know I suppose you know many times you know code your sucks let's rewrite it in something even better but I think that if you do this it's quite likely that you will you know hey you will encounter the same problems that you had before and you might not tackle them you know so much better in this new shiny version that you have you will have a lot of trouble but even worse I mean it's it's quite likely that I mean the old system at must still be able to you know function while you're writing this you know new shiny thing and now maybe have two different systems that you need to you know that you need to manage and that can you know be really time consuming and hard and you know the audio system maybe you know still evolving and you need to do bug fixes and so on so what I would do is to try to you know find this you know boundaries this subsystems of your domain try try to find them and try to try to find your your core domain try to find what's you know what is it that you know really what what is it that you're doing what is it that really you know makes your company excel compared to two other companies and like maybe so one way is to like start with this piece of technology but another way and this is I believe it's really a good way of doing things like if you if you get a new like like the business comes and say that yeah we should meant you know this new thing and you can you think like okay well this new thing I mean this you know it makes you know pretty good yeah this new service will make a pretty good microservice so I mean this is also a way to start so like if you get this like a new requirement I mean you can you know maybe start with this and maybe it's not like you know if something goes wrong maybe it's not the end of the world I mean you can you can try this out an experiment and see if this is you know something that that will benefit you and I also think that you know one way if you know that you want to move in this direction or maybe rewrite something one way it's also too you know really look at your you know maybe core domain and you know try to find what are the events what are they you know things that are important to this domain that I want to share with the outside world maybe you just you know start sharing these events like for example in our case that might be you know parking started or parking ended or you know parking extended and something like that and really and this is also a really good way to really understand your domain Plus even if you have been working with a project for a long time you may not you may not actually you know have a clear definition of what you know the vocabulary that you're using I mean what does it actually mean so this is a really good way of off you know both you know spreading your like you know distributing these kinds of messages to other systems to consume and also to get to know your domain better and 1a and and there are you know several hmm okay sorry about that it was not my fault I hope okay well one one way of you know pretty fast getting to know your different events that you may have in your system is to do something called the event storming and so I can encourage you to to look into that um another good approach nothing that can help us is domain driven design and the strategic design patterns from domain driven design and one tool that we can use from domain driven design is called the context mapping and complex mapping is essentially you know a way to visualize our current our current system and here we will you know you will see I mean here is an example of a some bank application I suppose and they have like this trading system and some online banking services and expense tracking and you know there may be different teams working on these services so in the context map you can easily see that you know the relationships between the different services and how you know they relate to each other so for example here we have a conformist relationship so that probably means that you know in this banking domain or the web user profiling service here or team they have to conform with whatever the banking team is doing here I mean have nothing they have nothing to say yes I mean they make any changes okay we have to conform to their changes so I mean so this is a good way if you're in a larger organization to really you know get a feel of what is it that we're actually doing what is the relationship of all of our services and teams and yeah there are a couple of good books about this that that you can read if you like okay but let's look at a little more concrete example so in this example this is like our you know mama life and we have our phone here that you know makes a request maybe he wants to you know park in this parking zone so what happens and yeah here we have another like this is a micro service that is running stand alone with its own database in its own data yeah so what you could start off doing it's you know send you know when he is parked in in this system here you know publish this business event parking started for example and typically you would publish this to some form of q and then this other system will you know integrate and you know builds up its local state or pre action from these events that you're publishing and yeah and there's actually a lot of different issues technical issues that can happen here I mean this is like the integration part of micro services from a technical perspective it's actually what's you know that this is where the hard problems are from a technical perspective at least so I mean you have like like if you're migrating you know you want to have consistency between your queue and maybe have a local database here and how do you do that you some kind of two-phase commit or some distributed transactions for example or how can you guarantee that you know something bad happens to this a cue that we will still be able to deliver the messages later and we don't end up with a inconsistent stage and this can be you know really hard yeah okay so in this example you know this traffic warden microservice builds up its its projection and then the traffic wardens that check if you're actually like do you have a valid ticket for this parking zone they will query this this system but yeah here we'll see another sample this is our what's called interactive voice response system so no you can phone it you know if you don't want to use our app you can like phone this service and you know here are nice well I shouldn't say nice at least a voice so you can use that to parking as well and that communicates with the this you know core mamaluv and also sends events but you know things can go horribly wrong if you have this kind of setup so for example this is not a good thing right I mean something burning is never almost never a good thing so and if we're not careful here now like I said before we have to be in a careful with these partial partial failures of the system because you know otherwise you might have you know maybe we have some cues here we have a lot of you know concurrent users and we fill up these cues and that may lead to you know out of memory errors or buffers filling up or other things happening so if we're not careful this can actually happen and this is you know this is not good and you know this is you know it's a nice app and this is some form of device and yeah they're they're I mean they're nice look at but you know without the server I mean you know they're not very useful you might argue at least not from our perspective as back in developers so you should protect yourself and what this thing here it should symbolize it's a circuit breaker and this is a very popular pattern that you that they use if you're like if you're communicating across a network or something like that so this gives this is history queer a Java fob so we're using hystrix from netflix for for doing this so this gives you like like a first-class concept to to reason about failure modes when you make these kinds of the connection remote connections to somewhere so for example like here we do a query to get like what is the give me all your currently parking cars at this parking zone so like if if our core server is down which is bad then we should at least you know return something we should return maybe an empty list or something like that so that at least you know this interactive voice response system you know can you know kind of work and not just to fail so that's something that is really important to think about because failures at least if you run this on scale I mean failures will will happen that's just I mean mathematical well my proof was likelihood mathematically it's very it's very likely that you will run into this issues but there are other things as well that you must consider for example how mean now if now if we have like we have web decomposer system and we have like our art service so how do we actually deploy it I mean if you can see this gray box here this should represent a node but I mean what should we install on this node I mean maybe you know we're using Java so no should we and of course now we have many nodes so should we install you know Java on all of these notes so we can deploy traffic warden to whatever node we have in our cluster but what if you know we have some other service that requires a different version of Java and I mean which version should we install and maybe we have some other runtime maybe we have closure or something and I mean should we or you know some other run time that we need to install should we install this you know on all nodes in our system so this is where we're darker comes quite handy actually and how many of you know about dr. already okay so that's like everyone so yeah it's essentially like this yeah like I contain a virtual machine that you can use to the package all of your your code and your library and all of your dependencies and your runtime environment so Java in for example you can like ship this container to a server and it will you know behave at least in theory exactly the same way on your production server as in your test environment and in a local machine and what's good with the darker is that yeah it's it's more lightweight compared to other virtualization techniques and it's immutable and that's that this is really good because if you start a container and you write something to to the disk of this container it will be lost on yeah yeah not necessarily but you know at least by default it will be lost and it builds on open standards and it's you know yeah it's it's secure in the sense that you if you are in this container you shouldn't be able to you know get out of this container and like mess up the invite the host environment or something like that that should not be possible so yeah difference between darker in a virtual machine you probably know this already but it's more lightweight so we don't need you know an entire guest operating system in darker that we that we need in in these virtual traditional virtual machines and we don't need a hypervisor and a hypervisor you know it's this program that allows you know the multiple operating system to share this you know one host but we don't need that if we're using a darker and that is a good thing but this in darker still need an operating system but typically the OS is very small so in our case we're running like a really small a linux distribution called el alpine linux of ink there's only five megabytes and that is pretty pretty cool so with darker what it allows us to do is to ya encapsulate the runtime and all the dependencies and everything you know into this container and you can actually incorporate state as well if you like and that makes sense you know for certain kinds of services but for most services you should keep state out of of docker if possible I think ya know it was just cool to have it on a slide so what doctor gives us is these reproducible builds and it's it's very yeah it's quite cool because you can like you can test things out locally and then you should be certain that it works you know in production as well and you can actually debug it at least some production problems you can debug that locally so that is pretty cool you got no problem with the you know configuration drift you know that the vm that you run in your doc container will be the same vm that you run your production server and so on but yeah we talked a little bit about that before as well and what you want to have is some form of continuous delivery so this is just a view of our continuous delivery platform that for each commit that we make to target repository will build this you know darker image and you know push this up to our private doctor registry and then it's gets deployed to our test environment so the test environment is always up to date with you know the latest commit things and then we just you know we click this yeah we click this button here and we just deploy to to production and that works pretty well and was pretty cool is that our yanking server actually runs in darker as well so it's like your doctor in Doctor and and this is pretty cool cos I mean you can make you know if you want to make like you big changes to to Jenkins and you can just grab the whole image and pull it down to your own machine and then you know you make this like-- hard changes and you fail and you start over and then where you're like happy with your changes you you know we push it back to your server and everyone is happy in theory but this is really difficult and I would definitely look into some some services instead like Travis or something instead of trying to do this yourself already over this blog that I created that will really help you i think if you want to go down this this route but one really cool thing with darker is actually integration testing and this is actually great in darker i'm sure that you you've all been like if you've been in a large monolithic system or worked with a large malefic system you may know that you know the tests you know they take forever I mean they can take like 20 minutes 30 minutes to run all of your integration tests and I mean I've seen many times you know people you know to make a change and then you don't you know you don't want to know ruin it for all your colleagues so you know you run all the recess locally before you push something to yank ins and you know you sit there okay well have a blah blah you wait for like 20 minutes then it failed and you have to you know start over not one thing that is really simple to do with the doctor is that now you have justice immutable containers so you can easily you know is create a container and copy all of your source into this container compile it and any run your tests and now you know you your source is now immutable so you can continue you know hacking with your with your local code while the tests are running in background and that is that's a good thing and yeah we have yeah yeah we have this script that we have for all of our services and this is you know the very same script that is executed by Jenkins so if it works locally it will work on Jenkins unless you have you know reef flaky tests and stuff like that and this is also really cool because it's you know it's no hassle you know setting up a new environment everything is just docker you don't have to download you know ten different databases and you know your mac or something like that I mean it's with docker you can just like get started very quickly but typically you want to to run multiple containers with dr. you so in this example we have our web app but it needs a Redis database as well for example when running the tests so what we used to do west or and we're still using this for our tests we're using docker compose which is you know this declarative Jamal formats for ya essentially an easy way to get get you know and doctor several docker containers up and running at the same time and it can you know figure out the dependencies between your containers so here it understands that you know Redis must be started before the web app is actually started so this is yeah we using this for integration tests and we used to use this in production as well actually but let's talk a little bit about why darker alone it's not enough so I mean we had a pretty you know before moving as you all know to to kubernetes we still we had a pretty decent setup I mean we you know we were running in the cloud and we had like this one script that can that could start up a new cloud server and provision it with all the stuff that we want it so for example you know installing the doctor didn't the right version of dr. demon and dr. compose and setting up and installing firewalls and unattended upgrades and you know New Relic agents and so on so that it was really easy you know to start up a new server and also provision the servers so if you wanted to you know upgrade door yeah the darker demon or something I mean that was also you know ansible was what's used to to provision the service so that you know it worked pretty well but the problem here was that in you know in our Jenkins a build pipeline we told yank ins to you know deploy traffic warden to server x you know server you one like a name server and we told it to you know deploying or other services you know somewhere else and so that was you know really you know up one of the problems so when we actually deployed a new version we you know we executed a little script on the server that's you know restarted in downloaded the latest or did the docker image that you specified in in in jenkins and yeah then we also deploy like a zip file with scripts and so that we knew which which firewall ports should we open up to the outside world and so on and you know yeah it works worked pretty well but then something that this can happen you know the fire comes back and now this guy over there is I mean he may look happy now but it's not so happy when you know Kingdom wakes him up in the middle of the night so and you know this happens you know server dice and what what we want is to be able to you know have our cluster to somehow you know deal with these kinds of failures automatically and you know of course you know term you know other things as well you know one time our cloud provider was d dost that's not good and there are other things like I mean how many containers can actually run on a server k run to or free or I mean how many I don't know no way we have to do like something in order to do you know to notice so we wanted something that could that could help us out and also help us out with scaling what if you want to run like several instances of our containers I mean now we had to do these things manually so what we want is something like this something that sits you know in the middle of our servers and our Jenkins server so instead of you know configuring Jenkins to push this container into you know a name node we just wanted to you know tell some some magic framework that please just I want to you know deploy send it a description like a demo file it's like deploy this service somewhere in the cluster that you find fit so we're you know that there are enough you know resources available that you can deploy this service and if a server dies make sure to reschedule this container and somewhere else in the cluster if a container dies on the server make sure to you know restart it and so on and we also wanted to yeah you know I love you know scaling and stuff like that so we started to look around for four different options and we investigated this five different well frameworks or services and this is what I was it called struck from the presentation because I don't have time to go into all of this but if anyone is interested to know more about anybody's we can you know maybe talk about it in the break to to my think it's called dr. cloud now they were bought by by darker but all of this earth I mean they were good but we came to the conclusion to use cout Benares on Google container engine and the reason if we want to cut a long story short was that it just felt that this was the most mature solution that we could find at the time and it worked for all of the things that that we tested so and it's also if you're running Cuban Aires on Google container and in Google will also make sure that you know the master node will talk more about this in the next presentation but Google will make sure that the master node is up and running and always you know update it and it will make sure that all your your minions as they called all your denotes that you're running in your cluster that they are like you know have something is compatible with Cuban Aires and they you know you will get monitoring and aggregated logging and all of these kinds of things but we'll look into that in the next session if you're still interested Cooper Nellie's is a way to manage a cluster of Linux node and you can actually you can regard it as being a single server that's the goal of cuban aries and yeah okay so this is i haven't prepared this part of the talk is much just the last one we'll see how it goes but ok so let's go with it with the Cuban artists is that you get a decade of google experience of building these kinds of systems and clusters essentially for free because cubanelle is open source and it's on github and I mean you can have done that as well I mean you can file issues so there is something wrong and you can like follow every everything on github so that is pretty cool and communities it's also it supports multi-cloud both in the sense that this is now this is not like coupled to to Google there are several companies that are working with Cuba Nettie's on github so you can run coo benetti's you know on your own in your own data center or on your laptop if you like yeah thank you make it ok but you can also run this on google google container ending so they have this like as a service which is a kind of nice and yeah it's also at least if you're running outside of Google container ending you should it should be possible to run this on multiple cloud providers for example simultaneously or in your own data center and in a cloud provider so that should be possible and it should be better as well in the future they're working with something called uber Nerys that will support you no more what you call it you know if you have two data centers that are far away from each other that is you know a whole different set of problems you know with latency and stuff then if you have data centers that are you know close by or just different availability zones but Cuban Ellis supports rolling updates both of you know applications and services that you run on Cuban a nice but also if you're using google container ending they also have rolling upgrades of the entire cluster so and that is a really nice feature to have so at least if you have multiple instances of your containers running in the cluster it will not you know affect the system hopefully and I have built-in service discovery and that works really well and you have support for auto scaling and this is think it's they just released a new version version one or two it was released last first day so I think this was in beta before 1.2 but I think that now it should be production ready yeah production ready sokku Benares should have been production ready since you know the summer since last summer when they released 100 and the current version is one or two I suppose that most are still using one dot one since one or two is so new and yeah it has a lot of features and more features are coming to Cuba nice and yes i said it's open source and yeah besides google i mean we have other companies like red hat the microsoft core OS and darker and mesosphere and you know i think yeah I don't know yeah no one's let's get that and this is actually quite nice with Cuban Eric's costs as i said before we were investigating some different alternatives Cuba natives as well but one cool thing akuma is was that they're completely open with their you know future plans in their roadmap you know we publish the road map from get up and you know everything isn't get up and this is you know this is really nice I think and I mean it it's also built to be extensible so if there's some part of communities that doesn't fit your you know your company for some reason like if you want a different schedule or something you should be able to to replace the scheduler with something else and that is even if you don't use this I think it's you know good to have that they have this that I've thought about these things and it it also supports besides darker it also supports a rocket I'm not used rocket myself and I doubt that the rocket support this you know on par with the darker but they have some sort of support for darker at least and I think google is also sponsoring rocket so i think that the support for rocket will increase in the future and this is just what i think is pretty cool I don't know if anyone else think this is cool this is this guy is working on Canaries Eric Brewer he was like the the founder of the cap theorem I mean he's like this hero you know okay maybe that says me okay so let's talk a bit about the concepts in Cuba Nettie's so if you know from my previous talk where does it this darker compose where you specify that you want to run move the poll containers kind of together and this is kind of exactly what I applaud this so a pod is a way to specify multiple containers and have them deployed as a single unit so this units I mean if you if you scale this unit you will scale all of the containers inside this pod container and then this is a very nice thing so previously google had something called Borg so they have taken a lot of experiences from Borg and I think they're still using Borg they are using Borg internally as well but they've taken you know lessons from working with Borg for ten years and they're trying to you know applied what they've learned to Tacuba Nellie's and I think pulse was one of the things that that they want to to improve upon and they've done so by making parts the first class concepts in Canaries and then we have a thing called a replication controller and this is what controls the replication factor for pods so for example if you want to have this you know pod group instance running you know on multiple instances you use replication controller to say that ok I want to run this and you know have three instances of this pod running somewhere in the cluster and then they make heavy use of something called labels and this is how many things work in cubanelle is under covers so for each part you can specify labels these labels you can use for example to determine how how load balancing will work for example and i will show you examples of this and they also have a good networking model i noticed some other services similar to this it can be tricky like if you have some containers that expose port 80 you have we have one container at exposed port 80 and have another container that also explore a spa just port 80 you cannot run them on the same node some services won't allow it to do that so kuba nellie's does a lot of you know networking magic to get these things just working you don't have to think about these kinds of things with Cuban Alice and that is that is really nice I think then they have a concept something called a service and this is you know essentially like you can regard this as a kind of a DNS so if you have pots that want to talk to each other you can expose a service because you typically don't want to talk to you know between pods directly because you know the instances can go up and down you want to talk to you know a cluster of pots so you deploy this cluster pods you know behind a service so the service knows how to route to the different the pods and the service can also be used to expose your pods to the outside world so there are different types of services some services that are just like internal if you just want to have you know internal communication or something and all the services can you expose things to the outside world and then we have ingress resources that are there they're still in beta but you can do like more advanced load balancing for example using yeah if you want to route like yeah but a host header you may have the same URI to a service but different host header in your HTTP request you can actually route on the host header or you can route you know like you like if you have this engine X a configuration where you're like yeah this path should go to this service this other path should route to you know another service some you can do these kind of things with an ingress resource so the architecture of Cobra it looks something like this yeah so you have a master node and this is I say a master air but you know you should of course have multiple instances of this I think there's only I mean one master at a time but you should have failover if the master goes down so if you run in in Google container engine day will you know make sure that this master node is always up and running and that's that's the nice thing but if you decide to run Cuban Eddie's you know your own data server you need to you know manage this yourself but then you have your notes that you have in your cluster and they're called minions and each node has a dr demon running and here you can see that yeah there are some pods on each node that has been scheduled to the notes in each pod contains one or more container so this is essentially at architecture so what Google container engine will give you is this sort of like managed hosted Q benetti's so you get this yeah the master node Google will take care the master node you will also get you know a problem that you have to deal with when using microservices it's that you know all the services they produce you know logs we don't want to you know use ssh into every container to you know see the logs you want them to you want all the locks we aggregated and the Google will handle that for you so you just log to to the console and you know Google have some fluency a demon running that will you know push everything to their servers so you can view them from the UI and we also provide monitoring so you can monitoring you can monitor your cluster and you can monitor individual containers we'll see if it works it's still in beta and yeah it also you know we run it in you know the Google cloud I mean we get access to all Google's services like cloud sequel and yeah I don't know data flow and all kinds of you know bigquery and stuff like that and so you can integrate with all of these services so that's you know that's nice the pricing is also if you're running a small cluster like I think it's up to five nodes then coo burnett is itself doesn't cost any extra you only pay for the notes that you have but if you run larger cluster than six machines then you pay some some amount of money and yeah google also offers support if you pay for the support otherwise you have to like ask questions on stack overflow and slack but if you want like rapid response you should probably pay so now my intention is to run some sort of a demo and about this demo I have kind of stolen it from a really great guy isn't it was he called Helsley hightower at Google and this is essentially you know his demo more or less and what I will show you I've built like you know hello world app that we will deploy to Cuba net is running on Google container engine and we will use some of the command line tools to do that and we will like yeah we will see how we can scale it up and down and so on yes we will google also provides a private registry for docker images so you push when you created your darker image you can push it to Google container registry so there is quite nice as well so then the binaries are stored on google cloud storage as well as pretty good and now i probably should have prepared because i need internet but i haven't prepared so this will take a little while for me to get internet let's see oh you can't see this I'm not waiting waiting waiting come on i will do my bouquet is this one ok seems to work let's see if i can access some page hey ok good ok so let's see so if you look at oh you can't see this Oh okay so if we go into the source code i will show you i'm in the code very briefly this is i don't know if you can see this but yeah it's like a very simple very yeah like I web resource that just returns hello world version 1 when you call it so it's nothing in fancy and it logs something to the console so this is the nice microservice that will be deployed perfect microservice one business capability right okay so let's start off with looking into here we go I had it open all ray so this is I don't know if you can see this so this is the replication controller that I was talking about and currently I think this is not optimal but you have you specified the replication controller and the pod in the same yeah Mel file as far as I know there is no way to separate them only to do some something yourself and it's a little bit confusing but the central this is like the jamo file so if we say that it's a kinda kindness replication controller we give it some name we call it demo 1 dot 0 dot 0 and here we define some labels and I was talking about as well I will show you how to look so this is on yeah and then we have a specification for this replication controller so we say that we want two replicas we want two instances of this pod running in or cluster somewhere in here we specify a selector and we will come back to the selector but this is really important we specify the name demo and the version 1 dot 0 0 and this is we use the selector because we want our load balancer or service to to find to identify this particular pod so this is why we specify the selector but we'll see how that works yeah and then essentially down here we have we have the actual pot so here we say that the name of our container should be demo and we should use this image Cuban Ellie's presentation 10 we specify aliveness probe and this is for Cuban Ellis to know if this service is up and running so here we say that we want cubanelle is to do a get request to you know the this path and we wanted to make this get request on the external port and okay if we go to port you can see that we expose in port 3000 from this container and we give it a name external so now we can refer to this port by the name we don't have to you know repeat 3000 on you know all over the place and this is this is really nice so here we say that you should run this like liveness probe on this port and they wait before you do it the first time wait 10 seconds and then you know have a time out of one second it should must respond within one second otherwise considered a spot to be none alive not working yeah okay so that's the replication controller and so if we try to now Miss coupling here but so what it what what you typically do is that you have something called I mean in in a closure you have lining in a boot or something but you build your your docker image you know using your bill to lure some script or something and yeah that takes a little while but once you have this as you can see you know it's creating the drawer file and it should create yeah I don't know if you can see this but down here it says that it has now created a docker image with the code and all the dependencies and put that into a doctor image so well that's pretty nice so now we want to you know you want to make sure that we can actually you know does this thing work so we can try this out locally so well oh this is sorry the resolution is a little bit small okay so let's try to run this locally first and see if it works and then now let's start it up so let's try it out it doesn't work you bastard let's see if do something like this yeah cuz i'm using a mac and we have to use dr. machine if you're using a Mac yay can you see this really cool okay so now we know that it works you know everything is fine so now we want to to deploy this image to to google and we can do that by using this command you issue yeah I can't you see this you run this command but this takes a while so i will not do that i have prepared hopefully i have prepared otherwise it will be a short demo so now we imagine that we ever you know just we're pushing this today to our private repository okay and it will just you know if you really want to see it and you know not hear me for five minutes then you should raise your hand otherwise we can continue okay thank you alright so Cuban Aries has the CLI interface it's called cube CTL so cube City i'll use that for all commands that you want to run towards your cube Nellie's cluster so what we want to do now is to create our replication controller and our pod from this jamaal specification and deployed at the crib nice so let's try and see if this works yay created that's cool so now let's go back here and maybe we can do cube can use the cube CTL get spots yay you should see here with the like he will have two instances of our hello world service running in in Canaries ok now they're running here and they seem to be working I hope it says running okay oh no so now what but yeah we cannot access these services now you know externally these are internal you know parts running in our cluster but you know we want to know expose them to the to the outside world so this is where services comes into the picture so if you look at our service well so this is also a general specification so this one is yeah half kind service and it also has some labels so we can identify the service and we declare the service to be of type load balancer and this means that when we you know deploy this or when we create the service on Google container engine it understands what type load balancer means and under the covers it will create a load balancer for us somehow and now comes the important part because we want this load balancer to access a report that yeah the external port that we define here external and we give it this could be any name but this is just the name of the port that we provide to the outside world in a way exposed port already we expose port 80 with the name external as well but this could be another name but I just put this name here to be the same as this one to confuse you but ok so we expose port 80 we call it external and we route to the external ports which is defined here which means 3,000 and the selector this is the important thing we want the selector to be demo so we want to route between all of our pots that has a label with name equal to demo and we have that here oh sorry here in the selector in our application controller we define demo end version one that oh but we don't here we don't care about the version and there's a reason for that but we could specify more you know key value pairs here at the selector level if we want to make sure that we only route between one that's 0 dot 0 versions but here we only route to to the name demo okay so let's create whoops let's create this service and this takes a little while okay now the service now it has created a service but it's a synchronous so we have to wait for the service to come up and we can do that by using cube CTL gets as we c minus watch I think yeah because now now it will watch for changes to this is yeah this is a shortcut for listing the services you don't have the right service you can write SVC but now we wait and we wait for the load balancer to to you know start up and to assign an external IP and that can take a little while minute or so so maybe if you have any questions you know it's a good time yeah so oh now the extra my p.o no but the question was is the load balancer type specific to google container Indian and I I think so actually i'm not sure i'm not a mature but i think so but I at the same time I don't think that it has to be I think that you know you can create some amazon specific you know hooks into this so you create an amazon load balancer but i'm not sure if that's supported but so you can probably look it up somewhere okay now we have our external IP so let's see if this works can you see this it's quite cool so now we have our super scalable microservice I've been running in the cloud and if it dies it will restart it okay so then i want to show you how we actually can scale it so i copy this command here so if we decide that you know we have so much load on this popular service that we need free replicas yeah we simply scale it's like this and say that we want free replicas okay so let's do that and it says that it's scaled so that's a good thing so let's see if it really is scaled yeah it seems to be starting up at least so let's see here if we do Q CTL logs ya know its upper running this is the logs okay that was pretty cool so now we can scale it up and down quite easily yeah so let's look at this now i'm going to start a little curl so now you should be able to yeah now this little curl script just yeah it every half a second it makes a request to to this service and what i want to show now is that you can do this like yeah now we want to build you know a new cool version of this you know this is so hip so let's continue with this like trend that we've started with this you know cool you know services that we have so we want to yeah maybe we want to change this to hello well too okay so this is the next generation of our hello world service but we're not sure if this will be as popular as as the old one so you know we want to start off you know a little bit you know take a little bit easy so let's try if we just you know I you know you build this the same way and you deploy the darker image and blah blah blah but I've already done that so we don't have to look into that again so let's just start one instance let's see if it is one instance oh no it's 51 so let's try to start on image or one instance of this number two service here so let's see ya so its up running oh can you see ah yeah good good that's pretty cool right this is you know now we could you know try this whether it is it every fourth request should they go to version number two or something and this works because you know we we configured with service to have with a selected for the name and not the version so this is why it works because the version is different but the name is the same sort of selector will will find it okay yeah yes yeah so the question is some it yeah this is very flexible I mean you can use these labels they're actually I mean they're very simple and you can do quite powerful things with them so exactly you can routes like you if you have if you have different versions of your services and you're not backward compatible and blah blah blah blah you can have different services for those kind of things for example you can do a lot of things but let's stop this thing because now i will show you how we can do let's do a rolling upgrade that's pretty cool so now we've decided at ya this new version okay we're ready to you know deploy this to the masses so what you can do or this is actually what you used to do until the last first day because now they have a better way to do that so i will actually show you so I'm a legacy stuff here but it still works and i will show you why it's or i can spray wise legacy but ok so here issue a rolling update and then you say that you want some update period of five seconds and this means that we will have a you know delay between every update will have some sort of grace period wait five seconds usually this is a bit longer but now we wait five seconds until we try to deploy the next diversion and we want to upgrade from our replication controller demo 1 dot 0 dot 0 to this you know to dot 0 dot 0 here so let's trice yeah so now it says that its scaling up from 0 to 3 and blah blah blah it it's at the same time scaling down I 1 dot 0 0 so now we should see more 2 datos here and in the end we will hopefully see that we will only have to that house and we will have no downtime and we can actually view the looks because yeah 11 pretty annoying thing is that you cannot as far as I know get you can only get logs from a single pod from the command line but you may want to get like logs from you know all of your pots from the command I don't know any way to do that so I've written my own script I called cube tail so you can download this from my github if you like so you can do github demo or sorry cube tail demo and you will see all the logs aggregated so that is pretty good but now it seems like it's done so yeah now we only have two dotto here so that is pretty cool but the problem with rolling update is that it's oh and before I said that is this prick I mean if things fail here in the middle you can you know roll back and stuff like that but the problem with rolling update is that it's client side so you know if something happens you know my machine were to die in the middle of this while we're execute is mentally rolling update will you know stop so in the new version and they have a concept of deployments so it's like this Jamo specification as well so you specify how the rolling upgrade should behave and then it's executed on the server instead so it's actually much better and I think there are more features than what you can do with rolling upgrade rolling update as well so I think that's a good improvement okay so i think that was actually they're dead the demo and so I'm not sure if you're if you're tired or maybe because it's not the last part is about you know the demo hopefully looked pretty cool and like yeah yeah you know let's just you know jump aboard and you know rewrite our monthly which you shouldn't do but you know everything is not perfect so I mean I can go through this fast so you don't fall asleep but yeah it's there are some caveats with the communities and so so one thing is that how do we get this like yeah so if we have configuration files how do we get our configuration files into the container in Cuba Nellie's I mean one way I mean because because what you usually have is that you build one image and you reuse this image in your test environment in your production environment and if you have other environments as well it's the same image but you have a different set of configurations you know and this was one thing that we had you know really trouble with because there were not good support for passing in like environment variables from the outside you know into the specification and yeah so we wrote this like bash script templating bash script to get this working but it's a good thing is that they have actually solve this in Cuba Nerys one or two so there they have something called yeah config maps exactly so this is if you are using you sure if you are thinking about using kunis you should probably wait a couple of days until they have you know really upgraded the cube latest version on Google container ending so you can avoid this already sucks but this will be better in I know that it's hard to wait I know but just yeah it should be better incriminates one or two you can yeah never mind another thing that we run into you know we're using this they have a sequel database that you can use to call the cloud sequel and they have written if you're using it from App Engine they have really good support for I mean you don't want to expose this a you know server to you know the entire world they want like an Amazon have these security groups and stuff and they have similar things on the Google cloud but I mean if you have this dynamic environment you don't know the IP address of the actual notes that you run in your cube name is cluster so how do we lock this how do we lock the cloud sequel server to only be accessible from Cuba Nettie's and they had no really good support for this so luckily there was one guy who had you know Hecht something up so you can like you know some little container that's you know Paul the IP addresses of the cluster and you know made some calls and upgraded configuration of the cloud sequel server so that worked pretty well but I think they have yeah and I blogged about this as well but they have something I'm not yet have something called nowadays called the cloud sequel proxy or something and I think that's the recommended way that they recommend today if you want to do this I'm not sure if this actually works on the old version of cloud sequel earth you know releasing it's in beta but i have a new version coming up pretty soon i'm not sure if the proxy works on the old version we're using the old version so and this works fairly well another project it's not a problem with the with cuban Eddie's this is a problem at least with all of our docker containers so many you want to stop a docker container or me yeah if a docker container stops gracefully I mean if you're running like Java you can add is shut down hook so you can gracefully you know stop the container but our containers didn't stuff gracefully there is you know killed but and this is I don't think this is Cuban Ellis fault either is our fault or doctors fault or not but what's good with darker is that you can specify this life cycle hook so you can specify and this is very cool I mean you can specify like a script that you want to execute before the pod they stopped so we created a little script that that killed the Java process and waited for it to to die so we you don't have that on each pot that is running java and yeah as we were migrating you know from our previous setup where we have this name nodes and stuff to in turku benetti's and therefore services gallery we were using like DNS in global DNS names that was our way of service discovery back then so that meant that all of our health checks and stuff like that all of our management resources were behind basic authentication and the liveness probes doesn't support basic authentication so either we had to rewrite some parts of our services to work without basic of education or yeah you can actually execute the line its probe you can execute your own command as well which is kind of neat so you can yeah you can fall back to using curl in the line let's check if you want yeah yeah I think this is pretty good actually that you have this ability but then it gets worse okay so did I actually showed you this you can only log as far as i know from one pod but you may want to log from multiple ports from the command line and yeah you can use this cube tail script decorated if you want to do that and yeah there are the links and yeah this is what we just showed in the demo but yeah i showed you this off rolling upgrade or rolling updates but the problem is in google you have something similar to in ms only have this EBS elastic block storage and Google you have something called google persistent disk but if you're using a google persistent disk you cannot do a rolling update Oh actually that's not what I wanted to talk about everything no the problem here is actually everything that's the next slide but okay yeah that's a problem you cannot do rolling updates on those so if you have a google persistent disk another problem is that like if you already have a replication control up and running then you should do a rolling upgrade right like the one we saw in the demo but the first time we deploy our service and we didn't do a rolling upgrade we just created rip the pods and the and the replication controller and that's the difference so like in so in our our Jenkins server I mean is you know the first time we deploy for my yanking service it should create it the second time it should do rolling upgrade so this is a little script that tries to find out if we already have with this service running if so it does rolling up great otherwise it just creates it and this I think is also improved with the Cuban Elias one or two with the deployment date guys at least that's what I hope yeah and this is what I was talking about this inconsistent it doesn't work if we have this persistent disks I don't think that this works in one or two either I think it's coming in one not free yeah yeah and also this is a little bit awkward we saw that you know the scheduler you know it's you know schedules to the pods on two different machines hopefully but if you only have to if you run two instances for example they may actually end up on the same node well okay that was not good this you can see here here we have two instances of the pod running but they were deployed to the same note that kind of sucks because we want some form of high availability but i mean i don't know i mean if you have free I've never experienced as this if you have three pods but sometimes you know randomly it just picks the same note and that's not what you want because then you will have downtime if you do rolling updates so puts it now no I take back it's not you may not actually have have that problem but it but it is still I think that it could be improved oh yeah this was this was the most crazy crazy thing yeah I don't know where to start have it is this has taken a lot of time because yeah you know you want to use HTTPS and ssl right for your services that you expose and in order to do that you need to use an HTTP load balancer in google container ending you cannot use this if you remember we set the service we set that the type load balancer what happens is that it will create a network load balancer under the hood and that is quite cool that means that you know you can use other protocols in just HTTP to talk to your cube nellis cluster so that is awesome but they have another kind of load balancer as well call HTTP load balancer and if you want Google to do your SSL termination you need the HTTP load balancer you could you know use in the next and stuff like that as well we knew that sorry in order to create an HTTP Live answer you need to use this ingress resource that I was talking a little bit about but ingress resource is in beta and it doesn't support SSL termination or it didn't support SSL termination until last first day so so now SSL termination should actually work I haven't tried it but this was a disaster because we hope that they will like get this out you know soon they I talked to actually some Google engineers and they said yeah we will you know this will be improved you very soon okay so let's let's try to but we had to do so many manual things to get this working blah blah blah create firewall rules and blah blah blah blah blah blah blah but hopefully yeah this will be better in India in the new version because yeah this is horrible yeah and we run into you know some other problems as well some various bugs and yeah yeah there's some various you know smaller issues I mean they're working constantly with their services and improving things but many of like like the monitoring API it's still in beta so yeah I should actually show that but now I didn't so now I don't have to but I mean you can like you have this you know nice monitoring things but you for this I mean I couldn't get it working for the demo so I mean is I don't know why it's still working in our production and testing environment but for the demo it didn't work so I know so it's still in beta yeah but now if you run home today and deploy your production system inc you brace one tip is to use something called the resource requests in resource limits this is actually really nice I don't know if you can see this but this is you specify how much memory is required in the cluster and how much CPU is required on cluster for this pod to even be deployed I mean don't deploy it to this node if we don't have this memory or CPU left on the note that is really nice and also so that is lower limit but you also have the upper limit if the service consumes more than 128 megabytes of RAM and more than fifty percent of the CPU you should kill this something is wrong with the service you should kill it yes this is it possible to scoop neck for storage you mean the monitoring API or they have yeah okay now I know what you mean yeah okay i know not sure I don't think so but from the monitoring you can set up a alarms and stuff from the monitoring a price we will get you know alerts when the disk is you know running folder and stuff like that and they also i mean the remorse I mean you can what's pretty cool it so you can have a you know like a cluster of persistent volumes and then you can have a what's it called I think it's called the resource claims so much or volume claims or something like that so you can say that I need a volume I need you know I need the 50 gigabytes just give me you know a disk that has 50 gigabytes and it will you know get this disk if it's available so you can do a lot of these things yeah and there I haven't shown this but you can do it maybe i'll show you later but there is a command called cube CTL describe this is a really good command because if your parts are not starting for some reason used to cube CTL described pod and the name of your pod you will get you know a lot of details on you know why it doesn't start for example so that's a good thing to remember and yeah it is cube tail script is also quite nice and yeah the slack channel I mean if you don't pay for support slack is your friend and stack overflow because they have yeah they pay people to answer questions on stack overflow and I think slack as well the guys who are working with this or you know active on a selection of and also on on the github page and I say this as a compliment actually but I know there I think there is like 15,000 issues that has you know been reported on cue brunette is on github and most of them have like been resolved and I mean if you you I mean you know is a small person you know I add an issue to Cuban Edison and they will you know be really friendly and they reply to you and really they take your issue seriously I mean I think that's really impressive with the amount of you know stuff that are actually doing so yeah stackoverflow as well so yeah we're actually yeah we are happy with it with Cuban Aires I think that we made the right choice even though yeah there are some caveats and I think that in my opinion one or two is the actual one that over ssion this is what should have been one dot one dot 0 but I mean we knew that we were going to have some you know do some workarounds with whatever you know you know framework and service provider that we that we chose and the Cuban Ares you know we did quite an extensive research before we we chose Cuban Eddie's and yeah it it even though there are some we need to do some workarounds I mean we we are able to do our work grunts that was not the case with the some of the other stuff that we some of the other frameworks that we tried so that's yeah workers yeah and the future for communities I think yep yeah yeah so the question was what other frameworks to communities compete with so I mean there are there it is so probably you know 50 different there is there are so many of these kinds of things now this is an explosion of different alternatives available but we looked into Amazon Elastic container service and to tomb that is now called dr. cloud and the mesosphere DCOs really that's a really cool but we didn't think that it was mature for example you couldn't do rolling upgrades on the cluster and I mean then you have to I mean what you do with you because in this aosu you run stateful things as well that's one of the cool things with the DSOs see so you can like install like this databases and HDFS and all these kind of stateful things into the dcs cluster really cool but if you cannot do you know rolling upgrades and they're releasing new versions you know frequently I mean how can we keep up if we if we use these stateful things if you don't use the state of things then it's it's probably you know just gonna create a new load balancer and you know you switch between yeah I mean there are ways to do that but you know in Cuba nary stuff was built in what else did we try now we didn't try fleet what was the other one you remember I don't remember yeah but we've of the ones that we tried this was the most mature because for example with the with the doctor or with tutim the issue that we found there was that it didn't reschedule containers if the if the cpu went up to a hundred percent on the node and there were some containers running at least note it didn't reschedule these containers to other nodes that's why we didn't chose tanem maybe they have sold it i mean we did this investigation in november and that's like I don't know it's forever in this in this world so there might have fixed that but that was that was actually the reason why we didn't use to tomb that I've actually been an easier solution for us because to tim is using we were using like dr. Campos and they are you know you seeing a doctor yeah I think now that they are actually using dr. Campos or at least the same jamo file format the stock imposed use so it was would have been much easier for us to just use totem but because of that we we didn't choose it and the reason I mean because that was big Dallas actually happened to us in production that we had run into this like hundred percent CPU and the service died so I mean we want that to work unfortunately it didn't work but of it i mean if you can read others a lot of things that they want to do in the future for kunis and i think it's it really looks really promising for example I really you know this urban eros as I mentioned before like so you can have multiple data centers 00 dad I should definitely mention this is a really big drawback of Cuban aires in google container engine you can only run it in a single data center right now and that's I mean that's not good if the Google Data Center dice our cluster will it will die but there are you can you know you can put two clusters behind the load balancer you can do that today but F and yeah I actually talked to some Google engineers and they told me that in one or two they should have like this mini version of urban areas that should at least work between multiple data centers so if they bring that into Google contain your engine and I don't I don't I hope so that would be you know awesome that's a great way forward yeah so Google turn your engine is nice so yeah I still think I mean if you I mean it's still pretty bleeding edge I would say but it's getting there and with the Cuban a nice one or two at least on paper since I haven't looked into it I think you know many of the issues that we had and it should be resolved so that is cool okay that was the end of the second presentation I have a third presentation but i suppose that you have to go 