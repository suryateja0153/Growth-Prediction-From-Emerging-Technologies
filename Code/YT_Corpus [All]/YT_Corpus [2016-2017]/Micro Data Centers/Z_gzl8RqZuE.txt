 so thank you Oh for coming I hope you all had a good conference so far I know this is the last day I actually stayed up until maybe I don't know if I came last night because I'm actually from New York and I had really really bad you out like so if I had coffee that'll be great but that's me I'm a developer advocate from Google I actually work with the Google cloud platform and yeah I'm from New York City it's my first time in Poland which is wonderful I love to travel I also like to take photo photographs and that's actually me that's my photo I swear that's me I'm probably the only speaker who doesn't use a real photo for my profile I'm probably the only person who has a camera in found my face the reason I'm doing that is so that I'm actually easily replaceable so you never know it's really me here why not that's my Twitter so part of my job is actually to bring some of the greatest and latest technology to all the developers and I love to talk with all of the developers about what you're doing and your experiences especially your experiences in the cloud whether it's Google or not it doesn't matter I love to learn what you're doing so if you can you know talk to me afterwards so I just talked to me on Twitter or or find me on email whatever I love to chat so like I said before Google Hey good night I think I did spill something wrong right before I've been with Google for about a year and a half and before Google had been a developer for a while and always been doing architecture stuff like I said I love to travel to society myself holding a compass in the middle of the desert now I told this story every time but I don't have so much time today but you know actually I was walking in a desert for about four hours in this specific direction Southwest direction in order to find an oasis in the middle of the desert so I can actually spend the night I was actually backpacking with this very bad pack here in Asia for about four months and I didn't have a place to stay in China I mean northern China so I actually had to do this but you know I talked to me afterwards but you know you can also find my photographs on Flickr which is really really awesome I like to take photos so alright let's get started so let me just do a very very quick survey as you all know this talk is about everything that you ever dreamed off which is spring poot how many people so the beautiful spring talk yeah very cool it's awesome it's a it's one of those tough that changed my life how many people actually sing a bunch of micro-services talks already yeah some yeah okay so so I think there are about three or four sessions on the very first day of this conference so I hope some of you already caught up on the whole microservices stuff and finally how many of you are Java developers or I'm in the right place good all right who who actually has already used containers just so I don't Barris myself okay all right cool so like I said I mean Marco services and it's it's definitely a train that's I'm going right now I mean we had at least a County like three four sessions in the first day of the conference here and every conference I go to you there are just a bunch of talks on that already so I'm not gonna actually going through all of the details about micro-services except when you write it with spring boot which I learned a couple months ago it's really really awesome I love groovy and when actually seeing one of these tweet from Josh long was here earlier this week when I saw this tweet in one of his conferences when he actually called his life which is like a groovy response service that can fit in a tweet that changed my life okay and I always loved groovy to begin with and why so does a hey that's really cool because I actually came from the architecture background and actually architected a few j2ee applications yeah EJB 2.0 right and that was that was it was different and now I see this is like wow just a few couple of lines with a couple of annotations but without any profile without any maven or grado you can actually deploy this and run this and and open up you know a web server that actually serve the request so I took that to heart and I thought that's really awesome and I actually created something else roughly based on this idea which is another very very awesome hollow world micro service of course you have to start from hollow world and I made a really awesome it's it does a little bit more than just saying hello so I'll show you that in a second but the problem with micro services have seen so far is that well first of all we are decomposing a lot of these features and things that you want to do into these individual micro services right each micro service is supposed to have only one concern or a couple of concerns that they deal with for you end up with you know is something that so on actually had seen a lot of time before it's how do you actually manage and deploy all of these services individually ok you end up with a bunch of services that you have to maintain you end up with all of them that you have to deploy somewhere and every single one of them you probably need to run more than one instance why because you don't want a single point of failure right it's it's it's not simple right so if you have like three services you're looking at at least maybe six instances that you have to execute and run and how do you actually do that you can do this manually right individual machines and just provision then like the old ways or you could use some kind of tools like puppet instable whatever to actually provision and deploy these jar files or application service i saw a talk yesterday just across the room where this is huge micro services architecture you know o designed to serve you know that kind of purpose and finally you have to be able to discover your services when they are deployed like where is the end point how do you figure out where the the IP addresses are what port do you have to hate that's something that I also have seen a lot of people do with tools like zookeeper and and you know there are tons of different tools to do that but today I'm going to show you something somewhat different and and we'll get to so that's my very simple architecture here it's got a really really awesome UI and he's probably the best hello world you are you ever seen I'm not falling apart from you saying and and it hits the surface behind the scenes of course you can imagine that I'm hitting a number of these different services or the service could be another service it doesn't matter it's pretty conceptual but you know no java application is complete without session or application of course for the UI so I toss that in there and I'm actually using spring boot with Redis as the recession of replication back-end okay so that's very simple how many people have some architecture like that very similarly to wait no well maybe yeah so probably more more complicated I hope so how do you actually deploy it previously I actually have done this of many many years ago I was working a start-up in early 2000s and we run everything on a single machine of course what could go wrong everything can be run on a single machine including our mail server Apache server a sequel our file server whatever we have everything all of the applications are running on a single machine of course if the machine goes down and that never happens so but the problem is that well if something do happen is that sometimes the application actually eats up all of the resources right I have seen this happen when you know she's it does happen I'm sure something's happened to you before is somehow in the code there's this infinite loop and just rips forever yeah it happens and and you know it is eats up all of the resources of the machine whether it's CPU or memory and and that's going to affect or affect all of the other applications that sound a machine right that's not something that you want to do another issue with this kind of approach is specifically you have you will definitely see it in in some of the scripting languages like Python or Perl where some of the times you deploy your dependencies into the shared libraries and this happens all the time I've seen this tons of times before and different applications may need different Genesis and what ends up happening is when you're doing your provisioning and deployment into the virtual machines or into your physical machines they overwrite each other and you just don't know what version you're supposed to use now whoa Java developers Here I am assuming that never happened to us right because we have nicely packaged or files and stuff like that and finally we are pretty tightly coupled to the operating system I remember laying down applications where in addition to the application server right I also have to make sure I have the right version of the JVM I need to have the right version of the Linux kernel and everything else has to be just just right and all the native libraries has to be just right and then you put your application on top of that so there's a pretty high coupling there now in the Java world there are a couple of things that we do one one thing is that well we do something very similar to that which is running multiple JVMs on a single machine right I think this down a lot how many people are doing that multiple JVM in a single machine yeah yeah some of you and sometimes you run one g vm on a single machine yeah or sometimes you run multiple applications on a single JVM as I do people still do that yeah some of you yeah it's okay yeah because I have seen this down a lot so you deploy multiple war files or even if you deploy a year file I mean technically they are like multiple war files or you HR files inside so in the natural you're deploying multiple applications in a single JVM now they actually give you some niceties because your g vm is capped in terms of memory somehow by the heap that you set and whereas you know previously here you don't write because you're just ice you're not really properly isolating but you still don't have full isolation here because every application can still be thrashed and you could still take up all of the resources in fact one application every one of these any one of these could have a memory leak somehow and just take up all the heap right in your JVM just dies and it just brings down your entire application server and then everything is gone right which is pretty bad again in Java we don't really have the whole shear library issues unless if you are using some old class loaders then you might have those kind of issues but typically we don't run into those issues anymore another way of thinking about this like I mentioned before is you know potentially running one application in a single JVM so what you end up happen oh sorry in a single virtual machine so you end up happening is that your physical machine like my laptop will probably have multiple virtual machines running into it in each VM would have laid down the Java JVMs and stuff and your application server and your application and you have a number of these things floating around in your managed data centers somehow but it is somewhat inefficient because I mean how most of the time I would say majority of the time is pretty inefficient because you know how many eyes have you actually booted at a virtual machine are you on your laptop right how long does that take to start it takes maybe 30 seconds 2 minutes and if you have to do this multiple times actually true it may be for virtual machines on my laptop before but still that takes a while but it is inefficient because you are actually rebooting a whole new operating system you actually have to spend the CPU cycles on the kernel that's actually living within that virtual machine and all of the memories you said yourself the operating system is you know you have to add it on top of the application that you're running and so it's naturally in efficient that way it's also harder to manage because then you end up with all these other machines you have to manage I mean they're virtual but they're still physical operate you know there is a operating system running into it and you have to manage the security you have to manage provisioning and all the other stuff yeah so how do we actually do that in the new world now how many people had I see a couple of hands on containers how many people had actually created containers and used it and running it a few okay very cool so for containers it's a it's a new way of packaging things to me continuous you know there are two folds one is that it is a format where you can put all of your dependencies put your application put your application server or whatever that you need a pack them in package them into this nice package like into this one file then you can ship and deploy that and the other part of it is execution so you can actually run containers and they can be running in this isolated manner so that within the container you get isolation in terms of resource which is how much memory you can use or how much CPU you can use and also in some way of security and he actually has its own view of the container itself so let me go through that very quickly so it is really lightweight why because you're actually not really another operating system within a virtual machine the way I would you know closely summarize container is which is I'm going to regret saying it but the best way to think about it is that it's almost like a virtual machine but it's not it is now because you don't you don't have to boot it like there's no operating system that needs to be booted within container it just runs I say existing process in your existing operating system okay and so you can actually start up in in seconds rather than say 30 seconds or more because it doesn't have to reboot the kernel or anything like that so it's relatively lightweight what I means is that when the container starts you know you are now taking up additional cycles to start the virtual machine and you're not actually spending additional memory to run your process either it offers you a pretty good process isolation so that in case that the application within the container is misbehaving that is taking up all of the CPU cycles but that's ok because it's it's running in a container where the CPUs may be only assigned say 20% of your CPUs so from within the container when the application is taking up a hundred percent of CPU usage that's only from its own view from the physical machines point of view that process is only maybe 25% of the entire CPU so whatever happens in that container stays there it doesn't trickle down and affect other containers so that's kind of nice I'm gonna go later ssh into one of these containers and i'll show you that you know as you can see its own network interface it can actually have its own dedicated IP address which is separate from your your physical IP address here and it actually has its own view of the filesystem what that means is that within the container you can do whatever you want with the filesystem and it will just be kept locally to that container in another container or your host machine will not see any of those changes unless if you are in that container namespace so a way to think about container images to me is you know in the old days when we actually had these static static binary files okay where you know you compile the static binary files and then you can just give it to somebody and say hey can you run this on your machine and of course they can't because they're statically linked so they don't have to install any additional dependencies what container images are very very similar in that concept why because in the image you have all of the dependencies all of the binaries that you need to run your application now again if you think all your application needs is the jar file that's not complete right because you need all the other things that go along with running that jar file as well so to me the continuity matrix like static binary and what does that mean that means that you can take that image and you can ship it and run it in any of the supported environments so this is something that Java developers had long wished for which I think we got pretty far which is to be able to write once write and run anywhere okay how many are able to do that right once and run anywhere no yeah maybe a couple okay yeah so I think I feel that container is another way of doing this in a more generic generic way where you can actually write once in any of the language it's not just Java but you can do it with scripting languages as well and package them up with all of the dependencies that you ever need to run your application and then you can ship it you can run it in the cloud you can run it on the Google cloud you can run it on other people's cloud or you can run it on your local machine you can run it your own virtual machine it doesn't matter because everything that you ever need is contained within the container okay so write yn wrong every word and English into doubt I mean how many people actually had this experience I had this quite a few times you know there's a bug in production okay and you get the call hey hey there's a bug in production I don't know what's wrong and then you go to staging everything is okay and then you go to your own laptop everything is fine - but why why is that happening well most of the time there is like a configuration issue between your environments right how many people had that happen to you yeah I yeah okay that more people can I feel safer now yeah it happens all the time and what do you actually find the one you find these bugs I I would say 80% of the time is environmental issues whether it's the wrong version of something or wrong version of the binary ROM version of the configuration or whatever the way that containers work is that you will be able to package you know everything into this image everything again everything that you ever need to run it of course if you miss configure your environmental variables like you know how you connect to your database you're it's not going to work right but you're pretty much confident that the the image is going to be the same no matter where you run it it's going to have the same underlying operating system base image it's going to have the same Java versions it's going to have the same everything that you say that the continuous you have okay so that you can actually do and deploy this in different environments and more than likely you're going to be able to reduce what we just you know so earlier so let's continue eyes since a lot of people hasn't seen what how container works inward being able to run in container I'm actually going to do this and show you how this is done and there's a couple of options to continue rising java application so let me get right to it how many people use maven all right rado okay cool docker Oh funny phew all right so let me get to it so here I have my awesome hello world application can I see it yes okay so that's my hello world application my my micro service as you can see does a lot more than just saying hi they actually say also say hi from the host name and the version yeah and that's important because we're going to see it later what this is running I mean it is important to version your micro services yes so you know and to run this in spring boot the easy way is supposed to spring it wrong and if I do this I can run this locally and there he goes yeah and it starts operate it safely quickly which is awesome for a micro service and I'm can actually go here date go reload hello DevOps all right so that's that's only returns yeah it returns a JSON payload okay so I'm gonna consume this later but that's running locally on my machine how do I actually continue eyes it so I can ship it anywhere and running everywhere along with the JVM that I want to wrong with okay so there are three ways of doing this the first way of course is the the most straightforward way which is to write a docker file now a docker file is a definition file where you can tell docker container how to actually package your image every single line here is going to be executed in a sequential order so imagine that you are setting this up yourself on your local machine where you have to set up say a spring booth environment you can actually write those instructions in a docker file so it's highly reproducible by by whoever is using it and once you have to package this up then that binary file will have all the binaries are you specify here everything that you run here will be in the same state you can ship it to different service providers or the from machines to execute now here in the dockerfile the very first line is actually a from statement so here I'm actually saying that well since this is a java application I'm going to use somebody else's base image that has Java pre-installed okay and I'm wrong in Java 8 here you can also do something like this you can say you can run Debian and call them Weezy so you can you know basically use a Debian based image but if you do it then you have to do something like a PP update and apt-get install Java JDK whatever and then you have to install everything yourself but if you look at it it's you know it's the same commands that you would otherwise run on your own machine to set up your environment ok so in this very specific example I'm using the Java 8 image so I don't have to worry about the Java underlying Java JVM because I will be provided by the image and and check this out this is um gvm tool so I'm installing gvm tool I'm using gvm tool to install spring boot and groovy and the instruction is actually here it's pretty straightforward you know you do a curl get the gear GV mTOR net in a rendezvous bash and then you can do gvn install groovy and so on and so forth so I'm doing exactly the same thing here in the docker file so I'm going to say curl and let's get g vm tool and running through bash right exactly what you would do on your local machine and then run the g vm install and that's it in the end i'm going to add my groovy file into this container image by using the add statement i'm going to expose the port 8080 which is pretty straightforward and finally i'm going to run spring spring boot by issuing the same command that you otherwise run on your machine as well now a big tip here is that when you run things in the container with say tomcat make sure you had this the last thing right here with - the java security if you d thing otherwise you will probably never start it will start in like 10 20 minutes it will be very slow okay so having this then I can do a doctor at Butte T Lyon container and dot and that's going to go ahead and interpret the doctor doctor file and go through all of the steps now because I have done this before so it's very quick because everything is cached locally but if you do this for the very first time it's actually going to go out and fetch everything that you need put them into a continuing image and then I can go ahead and say darker images sorry less there we go so I can go ahead and run it consider so another tip here is that when you run the container if you're just testing it running with the dash TI so you can actually kill it relatively easily so here we go so I'm going to run dr. Ron T on my container and what this is going to do is basically just as if you're running this on your local machine it's going to do Spring Run resolving the dependencies and there this so this is actually running inside the container how do I do know that well if I go to another screen here I do a docker PS you can see that this is a continuous running and the command line has been wrong and I can go ahead and hit this here oh sorry I did one thing incorrectly I forgot to map the port so let me do one more so port 8080 so when I expose the port that's also important and let me try that again okay so that's actually running eing doctor I said dr. container now for those of you who had used containers before are you using bhutesu docker yeah who's using food to docker yeah or just just doctor on Linux anyone know yeah some I'm actually you seen dr. machine who's anybody ever use docker machine no never seen it dr. machine is really cool it's another tool from doctor and you can actually create a doctor server on a cloud provider or locally so you can actually use talking machine to provision say a docker server directly on Google cloud platform or on other service providers now the benefit of doing that to me at the very least is that well it's very very fast to download things because every image that you download could be hundreds of kick-up hundreds of megabytes big so if you are actually running your doctor server on say a cloud provider you can download those images very very quickly not only that when you're pushing the images to a repository we also are using the providers very big in a bandwidth network to to do that so you don't have to do it from your own laptop boil your own network okay now the other options of deploying the service is because I saw most of the people doing maven so there's actually a maven plugin made by Spotify right here so you can actually use a maven plug-in putting in the Palmdale XML and you can specify the base images that you want to use which is right here I'm going to put in the top you can specify the name of the image which I did before which I coded my container but I'm calling it something else in fact you can use of course autumn avian variable as well and then you can specify the entry point which is how you are going to start your application so with that then what you can actually do is you can just simply do maven darker Butte and that's going to go ahead well assuming you have package to your application already that's gonna go ahead and generate the docker file for you which is really awesome and then with all of those arguments are you passing it's going to create a container image based on those information so there are this so very easy to use if you're using maven this is pretty nice it's one of the best plugging I've found so far and now it actually built that the image and I can of course run it as well so I'm not gonna do that but I can just go ahead and run it okay what's even nicer is that you can hook it up into your whole life cycle so you know for example if you want to build it into the image whenever that you do a package build then you can just hook it into the the face here another thing that's pretty nice about this is that you know every Pompey XML has you know the version version element right so every jar files versions you can also version your container image as well okay and you in here I can actually you know just take the version from the project and just tag it directly to the continuing image and if I want to do another talking images in I'm going to grab juciano here so here's the image right beaut and you can actually see that the version I have is 0.1 option 3 because that's the version I put in the palm to XML so it's a really easy and nice way for you to build your images directly from your Java projects and assuming you can do very similar things in Gradle as well okay and finally if you love spring boot in groovy as much as I do a third option which is actually built a docker file I hosted it on a docker hub so remember that the the base image that I use like from Java 8 well you can actually do something for groovy as well you can just say from what's a little own but from my repository and through a spring boot and anti version of that and the short form of this is just to UM boot and that's pretty easy to do now if you and this is all you need a darker file to run a groovy spring food application to create our image you don't even need groovy installed on your local machine to do this and what this is going to do is it's going to copy all the files into that it's going to create a new container based on that image okay and it's going to copy your groovy file into it and then during the container butte time when you're creating the image it's going to go ahead and create the jar file directly when you're building the image okay so so when you're deploying the image it actually has the jar file pre-compiled so you don't have to recompile them later another benefit of doing this is that the dependencies don't have to be redownload it over and over again in this also a lot simpler to use you just do that and you can do again darker Bute and tests here we go and that's it so it's going to do everything exactly the same way except that when you're building an image is going to go ahead and do the compilation as well and creating that jar file for you okay so I think we went through all of these things and now I have to run it now remember mice my my architecture is really you know how the UI and have the the service and then half the the Redis behind the scenes now if you order to run this on your local machine again you have to install every single one of those components right how many people are going to install Redis right or my sequel or whatever that you're using in the backend how many people are going to get it correctly I myself had tried to lay down infrastructure before and we always end up with this huge and long installation documentation so this is what you need to do to get your development environment set up okay and nobody gets right it's because they're so long everybody gets it around somehow in the steps but it's gonna be pretty simple with continuous approach because you are actually documenting exactly how you're going to lay down and configure your environment right with all of the underlying dependencies and so it's very easily reproduced so I'm going to go ahead and run this run a couple of things so remember I need to run three things I need to run the micro service itself I need to run Redis and then I have to run the GUI which is actually using the the Redis server for session replication so I have to run three things and I can do this a number of ways I'm going to show you the first way which is going to run the service and that's pretty long I'm going to run it with a name I'm going to run it with version 1.0 and that's one second let me do well now I'll just talk to it for now but I'll show you another way to do this so what you end up happening is you have to run the microcell race itself okay so you do that let me go back to the slide for now okay and then you have to run Redis and rather than stolen red is locally on your own machine you can just use docker again wrong a container that actually has red is pre-installed which is awesome you run the micro service but here's the tricky part you have to be able to let the UI know how to connect to the reddit server and you need to let me know how it can actually connect to your micro service and to do that when you do it just straight up container ways you actually have to specify this - - link thing okay so what it is going to do is actually it's going to expose the micro server expose the container end points from Redis and also from the surface itself expose those connection information via the environmental variable okay that's that's very important to know so so from within the UI what you can do then is you can read the IP address of the server's read the IP address in the port of Redis directly from the environmental variable okay so it's very configurable so you don't actually have to physically configure it in your spring configuration file anymore you can just read it from the environmental variable now that's a lot to do I just want to show you another thing that you can definitely do and you should definitely do when you're working with containers which is use docker compose so rather than executing those comment lines individually every single time you can capture you can capture your mini development environment directly within a young file which is a taco compost llamó file from this yellow file you can specify the three different containers you want to execute what images they should be using and also what ports should they be exposing and linked together okay so rather than executing those three commands which are relatively lone to remember that I will never do I can just do something like doctor - composed up and it's going to go ahead and read this file and it's going to launch oh three of the things at the same time okay so let's I'm gonna give this a try so right now it's launching the service the Redis server and also the UI and I think that's dominance that's a little bit too quick some a little scared haha so let's go see it and okay it works awesome yay whoo not worth so that's my awesome user interface of course for the hello world he can't get any better but you can see something interesting here you can see the session ID which is important when we validate session replication you can also see the host name and then you can see which service is returning the the payload to you okay cool so what does this matter well just about everything at Google actually runs in containers you probably have seen this slide before because we say it a lot of times probably two billion times but we start to clean containers every week which is quite significant right so everything that we ever use like Google search Gmail YouTube whatever they are all wrong within a container environment how do we manage that that you know I'm just showing you something on a local laptop here but when you're running at the scale right that's that's a lot of servers you have to run all these containers on and how do you actually do that yourself well Google we actually have an internal tool code Borg okay and Borg is our container orchestration tool so we have all these continuing technology internally at Google it's different from what you're using today but pretty similar and the concept is pretty similar and we are able to manage you know in orchestrate all of these containers by using the tool Cobourg what board does is that uh high-level is that it's going to be able to schedule the containers to run on any one of the machines that's made available to us ok so we have like so many servers I don't even know how many they are if you need to run a container running an application right you don't physically and say I need to run it on that specific machine no you actually just say hey go and find a place where I can run this and just run this for me ok and so we actually drew up on that concept and we make something called communities which is an open source project that's drawn upon a lot of the concepts and the experiences that we have had managing containers from within Google and it's an open source project that's we can go it's really a container Orchestrator how many people have heard about coop entities before yeah yeah very cool and some of you may even have seen this in action in the earlier sessions I'm gonna show you something similar but hopefully more sophisticated in a way for DevOps so what does actually do in communities there are two things you have to run one is the kubernetes master which is the the thing that actually oversees all of the nodes only every single know there's a couplet which the the kinetic master talks to to figure out well how much resources you have available and if you do have that kind of resource go ahead and run something for me ok so it's exactly it's very similar concept on how we actually manage containers within Google and what I can actually do then is you know I can say I got three containers have to execute I got the Redis container I have the service container I have the UI containers and kubernetes why don't you just go ahead and figure out where to run this in my cluster of machines okay so in a way you know if this the docker images are static binaries okay and the way you run these binaries is based on you know by using docker run so they become a process they kubernetes really is just a wait for you to schedule where to run those processes and it's actually you can think about it as a distributed scheduler okay like a scheduler on your laptop writes deciding how to run your application and trying to figure out what resources to take within that machine communities is you know going to be doing that for all of the computers that's made available in the kubernetes cluster so in a way you can actually think that all of the the machines that you have in your data center through the lens of kubernetes as a single machine okay that's a very powerful concept to remember because what that also means is that all of the resources that you have in your cluster is made available to communities to run your applications they are seeing as a single thing that you can actually use and consume so you don't have to physically go and decide oh I need to running on machine number zero zero one or zero zero two you don't have to do that anymore you just say go ahead and find a place for me to run it it just does it for you okay and it's open source project it's on version 0.1 9 which happens to be a release candidate there you know previously working towards the 1.0 release every time I check to this talk the number of contributors go up and so on and so forth we have quite a few partners that's actually you know using this technology or you know working on this technology including you know like pivotal Red Hat sauce stack mesosphere is not the list goes on okay and before I get into actually how that works and also how I can actually deploy my micro service into kubernetes I need to go through some of the basic concepts and these are very very important concepts that you have to remember in order to kind of navigate yourself within the kubernetes world the first concept here is called pods now we've been talking about containers for the past 20 minutes or so what is pod well pod is really just a collection of containers pod is the atomic unit that kubernetes can manage now that that's usually a hard concept to grasp because I always thought container is the atomic atomic unit that we need to manage right but in communities in communities part is the atomic unit that we can manage and part is a list of or a group of containers that have to live and die together okay what does that mean what kind of use case can you think about in the dye actually fits our use case well it's so imagine if you have a web application and you need to collect or a java application right and you have to collect statistics from say gmx trends or something else and you have to you know actively put the metrics from gmx right then get into run like a log collector or like a matrix collector so those two things will probably need to live and die together okay so in a pod you can actually say okay in this pod I need to run the application I also need to run the collector as well and they will get started together they will tie together not only that they also share the same ip address as well so you can talk to other services or other components within the pod very very easily they also are you know running schedule down to the same physical machine as well so for that you can actually you know potentially shear the volume share the filesystem between them now every part like I said has a IP address and that's really important especially in Java because you know sometimes we we do have these clustering technologies that we need to talk to each individual nodes independently from each other right and each part actually has an IP address and not only that when we have multiple machines that has parts running within it they are on navigable from one part to the other you can jump through machines to the pods private IP address now that's actually really hard to do if you you try this yourself why because you know imagine if my machine here has a virtual machine here with a private IP that only I can get to and somebody else has another laptop there with their own virtual machine how can I actually talk on my virtual machine to their virtual machine right you actually have to set up IP tables and routing rules in order for me to see the IP address and be able to be routed to it so kubernetes actually do this behind the scenes for you so you don't have to worry about it basically if you start the pot you get a IP and you can talk to other parts it's really easy to do another thing you have to remember is labels okay everything everything in could be Nettie's has labels apart and other things I'm going to go through has labels it's basically name the value pair you can have any name and you can have any value okay you decide on what you want to deal with the labels I'll show you a use case later but you can actually do whatever you want here yeah the use cases are something like well I need a label to say the environment is production or staging or I can say is the pot a good pot or bad pot it doesn't matter you can say whatever you want here you can also say the version is 1.0 or the version is 1.1 so we'll see use case of that so here we actually have the pot here we have two different labels we have the version this 1.0 and the type is from 10 because there is serving web requests and you can see within the pod we have multiple containers running here which is the application and potentially a lock collector and then we have the concept of replication controller what is that well it's basically a way for you to start parts and replicating it multiple times okay so here I can say replication controller I need to part of this type it's gonna go ahead and start it for you and if you tell the replication controller that I just need one it's going to take away one okay more than that replication controller constantly checks the state of the parts that's running so if you tell the replication controller that you need four instances running at any given time like your web servers and it's going to check periodically that hey how many how many instances we have right now how many possible I have that matches this condition and it's four okay that's why I'm not gonna do anything but disaster strikes I don't know if this ever happens to you somebody pulls the power cable I don't know Mouse running around eating up your CPU whatever whatever that is disaster strikes your machine is gone okay it took away a number of parts or your containers with it and now the current state is actually three okay now the replication controller is going to notice out and say oh no I only have three running but I need four so I'm going to start another one now even though the original machine is missing it doesn't matter because it knows how which machines are available to eight and just go ahead and do the same thing find the machine that has the available resources think you schedule it okay and finally you need a way to consume this part now again imagine if you had the old way where you have individual virtual machines you have dedicated IP addresses in your low balancing in front of it right in order to access or to access the website or to access the service in kubernetes this is a very similar concept which is called a small correctly named a service so a service is really you can think about it as a load balancer that sits in front of the part that runs the the request to the part that you want to route to and again the service you can have a label but you can also have what's called a label selector so in this case my service will only route to the part which has the label matching whatever I am selecting so in this case this service is only routing traffic to the part that has that's the type of front-end with the version 1.0 okay and or I can do something like this which is pretty cool we call this canary so we can actually deploy multiple versions of the service into the entire cluster and have some user hitting it and some users don't and to do that you need to be able to you know have the service routing it to all of the different versions that you have deployed and to do that all you have to do is to change this selector to say like I don't care about the version just I I just want to route it to the type of front end and regardless of the version of the pot it's going to be able to route the traffic to it okay so with that I'm going to show you a little demo which I built previously when you get back here so the first thing that you need to know is that you run your within kubernetes you have to make the image available somewhere now whatever I just did was not enough okay whatever I just did you know disputing that image is not enough I actually have to push it somewhere to a repository okay so so I need to push the image into a repository it can be on target hub or it can be on the Google private repository as well which has a different prefix which is GCR the i/o but that doesn't matter so the way that you do that is let me see here at darker images to see oh okay I have about ten minutes so if I want to push this into my Google repository I can just go ahead and do g-cloud darker push and the name of the container and I would just push it into the repository once you have two in the repository then you can actually consume it from kubernetes and to do that I'm going to start a visualizer which is pretty cool how many people I've seen this before what am i sorry okay that's too big okay cool and the scream solution really messed this up some gosh ride that can you see that yeah okay cool so the way that I can actually deploy these containers I dispute into kubernetes can be done like this well first of all yeah I have to create a definition file on how this deployment can can occur so I'm gonna open up say Redis so I want to deploy ready so I'm going to open up this demo okay so here's the definition file can make this even bigger so I'm saying that hate Redis is a kind of pod and the other the the two important things here are well the image name which is Redis and also the port that I want to expose that's very very important and once I have this I can go ahead and deploy to kubernetes and the way I'm going to do the ice cube CTO F in Redis pod okay and in the visualizer you can actually see the pod up and running okay and that's it that's pretty quick yeah there is no virtual machine booting or anything like that it's it's just like that okay and then I'm going to go ahead and start a service because I need other parts to be able to consume this so imagine if you had like a whole Redis cluster who you have one single mastery and multiples minions for the rights then you need like a low balance in the front so I'm just gonna put one in the front two other people can consume it so I'm going to go ahead and create the service which again is another Yama file that you can define and there are days that you started a service uh-huh it's it's very quick today I don't know why and that's awesome maybe it's not working so so remember every pot has a IP address and every service has an IP address as well and the service IP address is more or less stable it doesn't really change right pod can come and go and services the service here that's been defining in kubernetes is more stable which is right you can have a service with no pot it was just not routed to anywhere okay and now I'm going to deploy the micro service so I have a file for that and I have version v1 a multi version of that okay so again the difference here is that there's replication controller and I'm saying that here is the label versions 1.0 and the important thing again here is that image and pooling which is with the tag 1.0 and the container port okay so I'm going to do da cube City okay so what this is going to do is going to start up really quick now I'm really scared so so what this is going to do is going to launch to contain there's two parts each with one containers inside and as you can see if this is the the controller that's constantly checking how many pots I have running so whoa I just click on something I'm not supposed to okay so okay so what that means is that if I were to go ahead and say coop CTO get pods grab hello world service I should be able to see - yeah that's pretty long and and there's number one right that's a I'd say that's a pod so I can also do coop CTO delete pod so if something happened to one of the pod I can delete it and it goes so fast the controller actually just restarted another one for me so you can't really see it that's a really bad demo because it's too fast but but you know what I mean like if I do leave that pod if something happened to it the controller is going to know it is gonna go start another one okay now we have the pot I only have four minutes so I'm going to go ahead and create the the service for the the micro service okay yay and finally I'm going to go and deploy the application itself the UI the awesome you I showed you earlier the best you are ever okay I'm also starting to everything is going way too fast so I'm really scared now and I'm going to go ahead and do the service as well so where is this service so here still although our service now this service is a little bit different it will take a little time to create because I want to be able to hit the UI from the outside world everything that we have created here have internal IP address that's only accessible from within the Google cloud platform like if you are to SSH into one of these machines so for example if I were to SSH into that's not the one instances stylist so let me go heading ssh into one of these things so i'm gonna go to one of the nodes so i can do a g-cloud compute ssh like that and you know I can't actually hopefully try to hit this service URL so it's 1 0 3 2 4 7.1 46 Hey ok so it's working oh that's good yeah good to know all right so so what I'm doing right now is I'm just you know doing a while loop every second I'm going to fetch from the service and to say hi and as you can see it's going through the load balancer and every time I hit it it could be returning the result from a different pod right you can actually see the host name to be different but they're all version 1.0 which is nice ok and I can actually go to the UI now come on there we go and hello and that's all running within kubernetes ok now in the next two minutes I'm going to hopefully show you something else that's pretty cool which is something that you know devops guys would would love to have and there are three things rolling updates where you can actually upgrade your service while with no downtime and then you can upgrade it by you know pushing on new service into this ho ho-ho-ho cluster in there taking away out ok and criminales actually has butene features to do that and here's the script to do that but it's really just one line so I don't have to remember it basically does a rolling update it tells you the kubernetes what replication controller which version do you want to take away and then how long do you have to wait before you start a new pod with a new version in taking away the old one and then finally that the new version of the product you want to use so watch this this is pretty cool I'm going to run this script and hopefully it's not going to be that fast so you can actually see what's happening behind the scenes so here I'm upgrading it so watch watch the the the UI here the visualizer so now a new replication controller has started and it started a new pod 2.0 ok and after about 5 seconds it's going to go ahead and take away 1.0 there it goes so there goes one and while this is happening all the service is still working as you can see the load balancer actually can pick this and just relative to the right parts and you can see that it was 50/50 right it's like because there were just one version 11.2 and now we have two version twos and again after that period of time it's going to take away version 1.0 and that's it and rolling update done yeah now what happens if this is a bad version that you want to rollback have like two seconds and I will show you that very quickly to rollback is a very simple so I'm gonna go ahead and do it down great you can downgrade by rolling update as well or you can just kill all the parts and they just start the new ones so let me just do that for the purpose of completion so I'm gonna go head into the downgrade again you can see the service is continuous running and they have this new replication controller running oh this is actually going to the latest version and starting the new pod go to the next version another thing you can do very interesting with this is what we call canary so if I actually stop it right here which I should have when we have like two version ones running in the pod and one version two we call that canary because sometimes you are just too scared to you know get rid of everything and deploy the new version so if your version can actually run side by side you can just deploy you know one of the versions into one part with the replication controller in the entire mix of all the versions that you have right so the user by chance or have you know maybe a 25% chance of hitting the new service so you can actually validate and making sure that everything works okay and there's a lot of tip and tricks that I learned throughout you know creating the demo and you know through all my experiences with Tucker unfortunately I don't think I have time to go through it but definitely feel free to catch up because there is quite a lot especially the service discovery which I didn't get into just remember it's you can do this via environmental variables or be nice to a cop or you can actually use the API like what I've shown here before oh it's test locally you stalker machine oh this is very important this one thing you have to remember if anything else from this talk that you don't remember this one thing just don't write the law files into your containers that's just really bad because in my actually just you know take up all the spaces yeah so this tells all these things just come up afterwards we have some time I can go through some of these things with you as well now everything else down there are two ways to run communities you can run it on your local machine you can just go to community Scioto the website and give you this come in line you can just download and it's going to download like vagrant and VirtualBox and whatever inch is going to provision everything on your laptop or you can do what I do I like to host everything else elsewhere so I run doctor machine and for kubernetes actually run it within Google container engine which is what I've been using today which has been pretty fast today which is awesome and it's just seen paid out today so you can actually try this out if you sign up you get like $300 credit for 60 days okay so with that thank you very much yeah if you have time please do well you know take a survey a quick survey about how I did in stuff like that if you have questions feel free to come up Thanks 