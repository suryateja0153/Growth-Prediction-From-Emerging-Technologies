 hi there it's great to see everybody out here I'm excited to talk to you about kubernetes this today I'm Brendon burns I'm a software engineer at Google there's gonna be a couple other people coming up over the course and they'll introduce themselves so you heard a little bit about kubernetes in the keynote and so hopefully if you hadn't heard about it before you've got a little bit of context we're gonna go a little bit deeper today and try and explain both where we're coming from why we built it and what's the new awesomeness that we just built all right so I wanted to take a little bit of a step back and give you a little bit of the history of where we came from Eric went into this a little bit this morning so we're gonna kind of move through it relatively quickly so you don't get bored hopefully you saw some of that stuff in the opening keynote today but in some sense Google a long time ago was exactly like the way a lot of enterprise and a lot of other data centers are now every single app had its own machine you would use you know ticketing and things like that to find machines if it's hard to manage hard to scale painful for people to operate and so we started to figure out well what do we need to do in order to move away from the sort of one app per machine model and the very beginnings of that were things like CH roots putting using nice using some of the sort of traditional things that allow you to multi-tenant things but it wasn't sufficient right noisy neighbors are a significant problem in that world where you know some intern running a MapReduce can totally obliterate your search infrastructure and that's just not an acceptable way to run things and so moving forward we started to develop technology that enabled us to have better isolation of these processes and that eventually led to things like C groups that Google contributed to the Linux kernel alright and and what we found eventually was that actually these isolation boundaries really helped us you know maximize the utilization of the machines to the point where our utilization of machines is significantly higher than that of people basically throughout the rest of the industry and it's not necessarily because the people who use the machines are smarter about packing things but it's actually just that we have better isolation and that enables us to pack things for them and that's really what kubernetes is trying to do as well all right so then eventually docker came around and took a lot of these technologies and packaged them up in a really amazing way and Eric said that you know the container image that docker came around within the building tools around that that really sort of opened up the world of containers and some of the value of containers on the node to the broader world and suddenly we saw this explosion of interest in containers it was really gratifying I think for a lot of us because suddenly all of the stuff that we had been talking about and thinking about internally we could share with the outside world and so the time was right about a little under two years ago the time was right to start sharing some of the experiences we'd had over the preceding you know eight years and to start listening as well right we were starting to build out the cloud platform and we knew that our own internal experience wasn't necessarily the same as where our users were coming from and so we wanted to go forth with this project and share what we knew but also accept and build a community around where people were and that led to the development of kubernetes kubernetes it's an open source container management system again you've heard about it this morning from Eric so I don't want to belabor the point but it supports and you actually hopefully saw the demo as well in the keynote yesterday it supports multiple cloud environments it supports on-prem physical machines it supports the raspberry pi cluster that I have you know in my closet and it's 100% open-source it's written in go if you haven't checked out go it's a pretty fun language so that by itself is worth checking out and it's all available out on github alright the core principles of kubernetes I think this is really important we when we were going into it we really wanted to talk about what we are trying to accomplish when we built kubernetes and part of what we're trying to accomplish is that we knew that people were going to be using unlike in Google where everything is built from source people are going to take off-the-shelf software they're gonna take my sequel they're gonna take nginx they're going to put them in containers and run them and rewriting those applications just isn't an option for users and then the other important principle sort of runs throughout kubernetes is that coupling is really really bad when you take systems and you package them together tightly and so they're tightly coupled you end up making changes in one place that break things in another place that you weren't anticipating and that's leads to instability it leads to an inability to move your software forward all of the things that are necessary to build a scalable agile platform they go away if you couple your software really tightly together so we really wanted to decouple our software and then there's a lot about making sure that we are open making sure that we you know we really saw that this open infrastructure movement was happening it was something that was important to participate in you're even starting to see this on the hardware side on the data center design side with you know Facebook and others participating in open data center designs it's just that's the way that the data centers of the future are going to be built and we want it to be part of that and then also we really wanted to i what i like to say i don't know people have had a chance to take a look at the kubernetes paper that we published recently but one of the key insights there is that kubernetes and container cluster orchestration systems really allow you to change the primary key of your data center from being the machine to being the application right we want people to start really forgetting about machines and thinking about applications instead and so all of this sort of says we have experienced a lot of the things that are that are bothering people right now out there in software development and we've built some solutions that we really believe helped you move on and this is an image that I use in a lot of my talks and I think it really captures in some sense what we're trying to accomplish the challenge of driving something like this semi truck that fit that that crash in the middle here is the semi truck is a coupled system right there is the cab that is pulling it in the trailer and as anybody who's backed up a trailer knows you could be backing up in one direction and your trailer can be going in completely the opposite direction right that coupling that unintended consequence of some action because rarely do you take actions that you think are gonna fail right rarely do you like push a config because you know that it's bad and it's going to cause your application to go down but what you don't you know you have all those failures related to human error is that there's an unanticipated consequence and that unanticipated consequence almost always comes from this kind of coupling all right and to illustrate this a little bit more when you think about things in a machine oriented way when your data center is machine oriented and you think about physical infrastructure you end up with things like this right where your services are splattered across three different machines and when you think about the Machine you think okay you know I really need to upgrade lib see on machine number one because you know my back-end needs this new version of Lib C and so you go in and you upgrade you know Lipsy on that on machine one and your back-end is like I'm awesome I'm happy to go and then it turns out your front end is all crashed because they use that library too but they used a slightly different version of that library and there's a bug in the library that you just upgraded that caused them to start crashing that's the unintended consequence right that's why coupling in in this world is bad and so what we would really like to do is show you how kubernetes enables you to create what we call logical infrastructure and logical infrastructure basically says forget about the machines right the machines disappear below the kubernetes api below this unified substrate and you start thinking about your applications it's an application oriented infrastructure all of your front ends are the same the thing that you're going to change is your front-end the thing that you're going to upgrade is your front-end and in this way and you've decoupled all of these systems from one another and you don't have those unintended consequences that cause stability problems all right another really important part of being open and being transparent is this idea of workload portability right there's all sorts of reasons for people to be in multiple kinds of data centers be at their own on-prem data centers private cloud public cloud colocation whatever it happens to be there's a lot of reasons why you're going to be in a lot of different places and we profoundly believe that the future of cloud is hybrid right and so in that world it's important to have a system that spans these things right and enables you to move your application from vendor to vendor if they're having stability problems if they're having pricing that you don't like if a different vendor comes along and has better pricing whatever the motivation happens to be not being locked into a particular vendor by using their api's is really powerful for you as an end user in kubernetes with its open source aspect and its ability to run anywhere means if you write applications to the kubernetes api is those api's are available and can move with you wherever you choose to go or indeed can normalize your environment as well and so this comes down to the sort of idea of write once run anywhere which you know by now kind of has sort of a bad reputation I guess at some level because of course there's the asterisks right it's it's the this is mostly true this isn't a hundred percent true but really if you build in a container which encapsulates all of its dependencies into this hermetically sealed box and you deploy and you use services provided by the kubernetes api you really are targeting a runtime that is pretty independent of the infrastructure that it's running on top of right in the same way that if you write a program in a higher-level language usually and that's where the asterisks comes in of course that program can run on a variety of architectures from your arm in the raspberry pi to x86 - you know mips on a router or whatever it happens to be and some examples of this inside the kubernetes api where we've really tried to put in some effort into making these things portable include things like our networking model where we really tried to be agnostic we didn't just sort of say like oh hey this works great on GCE nobody else can do it anywhere else ingress is another really great example of this where we created an API object for doing HTTP load balancing and actually the implementation of how that actually produces a balancer is developed outside of the kubernetes core code base so if you want one for your favorite cloud provider you want one for your physical you know hardware load balancer you can build all of these things and there's one API object but the implementation can be in a variety of different ways our services exam are examples of this as well as well as persistent volumes where I think at this point we support twelve different volume types different distributed storage technologies different cloud storage technologies really enables you to be isolated from the specifics of the platform that you're running on and then finally I talked a lot about this coupling we really think that the kubernetes api allows you to build these systems that are coupled from each other right so that you can actually have different teams doing rollouts at different layers your front-end team can roll out a new set of the front ends without ever communicating with the middleware or the backend teams at all right or the middleware team can do a rollout and never communicate with the front-end team or the back-end team that's hugely important for distributed teams for scaling teams up and all of these things are made available by you know the ability to isolate things behind you know a service IP that is unchanging right it doesn't matter that the actual pods that implemented a particular service have come up or gone down the front-end still just talks to the same service IP likewise we also want you to be decoupled from kubernetes itself we didn't want to provide tools so that you know if you have a configuration that looks for a particular environment variable you don't have to teach nginx that it's running inside of kubernetes you can use things like the downward API to project parts of the kubernetes api into environment variables that engine x already knows how to consume right this is part of meeting people where they are as well as ensuring that that application that somebody wrote isn't a kubernetes version of the application it's the same application whether it's running inside of kubernetes or any other kind of environment and then the other part of this is you can do this kind of lift and shift right like maybe you're not hybrid but you don't want to be stuck and you can if you get to a place where the platform doesn't work if you're in gke and you you reach that place where you're like no you really need to be on prem for some reason you know we'll be sad of course but you can do that right you can take your workload out of the gke roll it on over to you know the on prem pluster or likewise if you're in a different public cloud provider right now right we understand lots of people use different public clouds you can start with kubernetes in that environment and build a place where you know as as we demonstrate to you the value of running inside the Google cloud platform you'll be able to easily move that application across or you can gradually move your app from one platform to another and that's also a key component of being open and being hybrid all right so that was sort of a prehistory hopefully wasn't too redundant with the things that happened in the keynote I'd like to take a step forward - now - what's what's next what's going on here so one thing I really like to highlight here is the velocity and Eric's sort of mentioned this with a high level 27,000 commits but this graph I think really speaks to it in a more dramatic fashion you know we're doing 46 commits a day and that's averaged across the weekend and so and we don't actually do that many commits on the weekends because we all have lives and so the velocity with which we are doing this is just amazing and as well at the same time we're seeing new people come into the community that's fantastic as well really excited to see that really excited to see all of the companies that are contributing not just using but contributing as well we really want to build a community that isn't just a bunch of Googlers throwing code over the wall but is really a holistic community as part of that you may have also seen the announcement that we've contributed kubernetes to the cloud native computing foundation so the intellectual property around kubernetes is now actually out and available and available to the Linux Foundation and as part of that I want to introduce rich Steinberg who's the principal engineer WePay who's going to talk a little bit about how they use kubernetes to power we pay so rich thanks thanks hi I'm rich and I'm here to talk about we pay and on our experiences kubernetes so we pay I know it's good to find it hard to believe but we're about payments we do payments we start up down in Redwood City and what we do is we do payments between individuals we allow our partners to build the relationship between the individuals and then we take over the payment from there and as part of that we hold credit card data and we're PCI certified and we do this using a PHP monolith application that is been kind of changing with different business models and now that we're taking off like crazy this PHP monolith needs to be taken apart it needs to be broken into smaller services and and we need a way to deploy these services so we took let me move forward so he took three swings of this back or at this ball the first was we had some bad sequel that was running against our database so we need to move that off so we we knew we want to do docker and we put this load into a docker container and we started it manually and we had it going and it wasn't great but it really helped the second was ansible and deploying to individual machines and we didn't really know how to do topology at that point so it was really one VM per I'm sorry one docker container per VM and and that was it and we were in Google Cloud and kubernetes we were part of the community we were part of the beta program we had developers inside we pay that are really excited about kubernetes and and as soon as it became GA in July of 2015 we were on board and it really dramatically changed our whole business because now we're able to spread our workload across multiple machines it solved canary deploys it solved being able to do rolling deployments it really just sort of changed us and it's been great and one of the things that I want to underscore about kubernetes is that it's changing rapidly the the problems and things that we've dealing with we can look in a road map and actually see that are gonna help us but more than that it actually is real use cases that we have problems with so I want to talk a little bit about some of the things that we've done with kubernetes that have been sort of outside of what kubernetes can do and then then we'll go from there so because we're PCI certified and we talked the keynote talked a little bit about this but about not having a gooey Center everything that communicates back and forth must be encrypted and that's just from the early stages of community wasn't available so what we did is built a sidecar in the pod with nginx in it and Kubb DNS gives you a domain name it's like a private domain and we built our own in-house EA that serve that C n as the domain name and that's how we terminated us to sell another example is since we're PCI certified when the PCI auditors come in they want to look at the smallest number of machines possible they do not want to look at hundreds and hundreds of VMs they want to be basically down to the smallest that possible and a piece in kubernetes terms what that means a dedicated cluster for PCI and with a dedicated cluster for PCI we then need two dedicated clusters because we need high availability across zones and so the need for dedicated clusters and and these clusters need to communicate with one another so there's a need for some sort of inter cluster service discovery and what we're doing now is we're just hard coding those service endpoints but we're looking forward to open Eddy's and we've also looked at buoyant but kubernetes is really cool and being able to solve this problem lastly is secrets and there's a lot of talk about secrets today they talked about it in the keynote and it's a it's a it's a big thing too you got to consider so the way we're taking care of it at this point is using hash a court fault and that's just encryption as a service and there's API calls that are scoped to the application so the really good thing about this is that it's not putting secrets unencrypted anywhere on disk ever it's memory to memory communication and it's basically leased out so that's been sort of some use cases and a I want to say again that kubernetes doesn't really put you into a box you can really kind of do what you want with it and take what they've given us and and build on top of it and at the same time it's constantly changing these problems are being solved by the equipment IDs team and I'm gonna hand it over to Tim right now to tell you about that that's rich hi everyone I'm Tim I'm one of the software engineers working on kubernetes so this is next so let's talk about what's next so I want to talk about a few features that were pushing out in our kubernetes one to release which was launched last week and I want to talk to some depth and I'm gonna do some live demos and we'll tempt the fates and see what happens so the first thing that people experience when they have these distributed applications they need to figure out how am I gonna update this thing this has been a topic at a couple of the talks I know Eric mentioned it this morning it was part of the demo yesterday at the keynote we're improving on what we've done so the goal here run an application updated with zero downtime zero visibility to your end users we built our rolling update process completely on our core primitives of kubernetes there's nothing magic there's no backdoor api's if you don't like the rolling update that we've built you can build your own this comes from a direct lesson from board where the update system was really built and tightly coupled into our system and it turns out updating different kinds of applications there's different kinds of requirements so in version 1 and version 1.0 and 1.1 of kubernetes we had this built into our Cube control or cube cuttle command line in version 1.2 we have a new object in our API called the deployment and a deployment is updates as a service you tell the deployment I want you to update from version X to version y and you take your hands off and the deployment object will do it it's all done server-side you give it a bunch of parameters that tells you how fast you want to go and what happens if there's a failure and you let it run if you add this with graceful termination of pods what you end up with is a clean draining update from your system and you open to connections users will finish their session and that said that the old pod will go away and the new one will come up I want to walk through a little bit of the update so imagine for a moment you've got your service you're wonderful my app right and backing my application I've got a replication controller which has three pod instances that are running it this is the blue version of the application if you notice here you'll see replicas three and the selector is my app version one right so the first thing you're gonna do in part of an update is you're gonna bring up a new replication controller note specifically this is my app version two now there's new replication controller you're gonna take it from zero replicas to one and now you've got a new replica running the service if you notice the selector on the service is app my app it's version the independent so at this point 25 percent of my users are gonna be experiencing my new application this gives me a really good signal if I can watch my monitoring that you know maybe my application is bad and I want to roll it back well let's assume that you got it right because you guys are all smart people so you bring up a new one and you bring down an old one and you bring up a new bring up a new one and you bring down an old one and you repeat this process until the old version of the replication controller has zero replicas left and then you can just throw it away like I said this is all done server-side now in the deployment object which you're gonna get for free if you run cube cut' will run its new new and the version 1.2 API the next thing people tend to run into is scaling I need my application to be responsive what happens if if famous celebrity dies I need to be able to respond with my application and this change in load so in kubernetes 1.2 we have launched something we call it horizontal pod autoscaler that's a mouthful but what it does is it takes metrics currently we do CPU utilization or custom metrics which are alpha but they work you take these metrics and you feed it into the replication system and the replication can say hey you've crossed a threshold let me scale you up or yeah you've dropped below a threshold let me scale you down obviously you give it some in max bounds and it operates within those bounds but again you said it and you forget it this you from having to worry about what happens if something happens on a different time zone and you're not at a console and you don't aren't there to provision new machines this is the ethos of kubernetes you don't have to worry about it next thing that people tend to run into persistent storage right we'd like to talk about treating your stores or your servers like cattle right everybody knows this analogy don't worry about them they're fungible if they go away it's not a big deal but the reality is somewhere at the bottom of your stack you've got a database right you've got files you've got storage that you need to run your stuff so we have an abstraction called persistent volumes in kubernetes which lets you create durable storage in your network or on NFS or you know you know any one of a almost two dozen there I'm correct Brendan it's not 12 that's actually a closer to 20 different volume types you store your data there and then as user you can claim that data that data is yours so new in kubernetes 1.2 we have auto provisioning if you ask for data and there's nothing in the system that can satisfy that request will go off and will make it for you assuming you're in a cloud provider that supports it like GCE or Amazon or OpenStack we can automatically go out and make this new volume for you what's really cool now is you can write all your data to this persistent volume and then you can kill your application tear it down you know what my sequel service is done but I need to offload all that data into my monitoring system you can then handoff that data to a different pod because you still own that data it exists until you're done with it we never destroy it until you tell us that it's ok this is an application oriented use of infrastructure don't think about the disks don't think about the I scuzzy don't think about where they actually are think about what you want to do with it so let's do a live demo if we can switch to the demo guys so I have to apologize first of all I cannot type and talk at the same time so I have the self typing demo but I promise you it is running live against my GCE cluster right now so here we go so this script first thing I'm going to show you there are no claims PVC is a persistent volume claim it's a shortcut I'm showing you with our Cube control command there are no claims in our system so let's go off and create a claim to do this we're gonna look at this little blob of Y amel you can see here the claim is called a PV provisioning demo it's existing in the demos namespace what I'm asking for is something that is read/write accessible and I want 10 gigabytes of space and so just like that it's been created and we're gonna take a look at what we've done with the describe command and it shows you here that we have a precision volume claim that is already in the bound state what that means is has already gone off and created a volume for us and bound it to this claim and it has satisfied it with 10 gigabytes so this loop is actually going to do nothing because it happened so quickly so here you can see the short form it happened 33 seconds ago that's my proof that it's real so here I ran g-cloud compute disks list which shows me in the Google compute engine here's the list of disks I grabbed for the ones that I know that it's gonna match and it's gonna match this dynamic disk so now I'm gonna go use this again here's a little blob of yeah mole that shows me a pod the important part here is what the pod does it does an SH see which says go run this shell command it's going to touch a file called /pv slash whatever my current host name is we set the host name to the pod name so you can see that this file gets created on the pod and then it's just gonna go to sleep and just like that my pot is created and it's probably already running before I can finish typing it out so you can see its schedule that's been assigned to minion I a 9n and we'll wait for it to give us a running status so that we can actually go poke at it okay it is running so I'm gonna use cube control and exec into this to give me a show so I'm now live into this running container if I LS and the /pv directory you see that this file is demo bla bla bla that is it so I'm gonna say so I've now created this file so I'm gonna exit this shell and then I'm gonna go ahead I'm going to delete that pod now this pod has gone from the system that running process is gone just to prove it but my claim still exists I still own this data and it is still there and it is still bound and in compute engine maybe oh there we go still exist so now I'm gonna run another pod right my my sequel finished I want to go run the post-processing I want to I want to analyze my user logs or something that I want to do here so I've gone and created another pod and that's gonna check that it's running and I'm gonna shell into this one again and what you're gonna see cross your fingers is that those files that we wrote before still exist so there you can see now I've got two hosts two files that are specific to the host name and the hello file that I wrote before now I can do this any number of times I can keep handing off the pod from container to container or the the volume from container to container until I'm done with it so let me exit this and say I'm done with it so I'm gonna go delete my pod you can see again that the pod is gone this is all happening real this is how fast the system actually operates I've deleted my claim and my claim is gone and the persistent volume that was backing that claim is also gone and if I were to look at G cloud which I don't think I did if I were to look at G cloud one more time it would show me that that persistent volume has been erased what this means for you is you are free to work on your application and not worry about who's managing the infrastructure not send a ticket to provision a new volume can you switch back to the slides please demo number one it worked I'm gonna tempt the fates and do it twice so new also in kubernetes 1.2 multi-zone clusters you guys you were asked and we heard and we answered so you can now bring up a cluster that spans multiple zones gke czar GCE zones or multiple Amazon availability zones we'll label those the the nodes that come up on those zones and when you schedule work we're gonna spread them across those zones now if the zone blows up you're safe your applications not gonna go down kubernetes will say oh damn what happened to those copies and it will bring up new ones on these other nodes this is what it's all about 2:00 a.m. Sunday night you're sleeping do you want your pager to go off because Google brought ozone down heck no just handle it for me right so I'm in email in the morning I'll take a look this is what it's about so there's zero changes to the communities API you don't need to know about zones all you need to know is that when you provision this cluster you brought it up in multiple zones this is GA in version 1.2 the code name for this project has been called uber Nettie's an uber Nettie's is going to continue to evolve we're gonna build out a more federated cluster model in upcoming versions of our system this is what we called uber Nettie's light so the next thing that people talk about Brendan mentioned this ingress l7 load balancing we built the core of kubernetes around the idea of l3 and l4 load balancing because we wanted to be really agnostic to applications it turns out unsurprisingly a lot of you are building HTTP based applications and you want a way to get HTTP into your cert into your clusters so again you asked and we listened we've built a new API object called ingress ingress will allow you to describe a map based on hosts headers or based on URL paths that will take incoming HTTP traffic and route it to various kubernetes service backends so now again you can build out your micro services you can have your contact manager as one application and you can have your email box as another application and they can come in through the same URL and be spread out into these different services this is literally how Google operates we have implementations of the end the ingress API against GCE there's one against Amazon that's being developed right now H a proxy and nginx what this really means is if you want to run on premise you can totally do it you can run H a proxy on your premise you can pick up your application you can move it to GCE and you can get all the awesome power of the GCE load balancer API if you saw that talk yesterday the reality of these cloud provider API is that sometimes they're complicated and if you learn the GCE look at load balancer API and then you want to move to Amazon then you have to learn the Amazon load balancer API and these two things can't be any more different and you don't you don't want to deal with that that's that's a mess that's coupling so ingress gives you a way to uncouple from that the next thing people talk about and rich mentioned this with respect to his his stuff that we pay his secrets you've got to authenticate your applications you've got to give them access to a secured something I don't care what it is maybe it's an SSH key maybe it's an API token maybe it's a password in plain text in a file you have access you ever need to access these things but we've all read the 12 factor manifesto right 12 factor says you put your configuration in the environment right well kubernetes is the environment this is where you're getting stuff so we are now giving you an API to manage your secrets through our unified communities API through the same cube control command-line interface through the same yamo objects with the same semantics as everything else you inject them into your application late bound you you know you write in your API you run your application you join these two things at the very last second they are written in a temp of s so you never write to the disk they're only in memory and you can then access them as files or environment variables from your application so let's do a live demo we switch to the demo slide our demo screen thank you all right so like everything else there's a little bit of llamo behind it I'm going to go off and create a secret it is called my secret password it is a type opaque it's not a TLS certificate or anything that we might know about the username in the password our base64 here simply so we can stick binary data into this Yambol file I like everything else we just run cube control create - f it goes off and creates my secret now I'm gonna go off and create a pod again all this pod does is go to sleep but it mounts this secret you see the volume secret here it's going to mount it at the slash data directory so let's create the pod and the pot is there and it's running and again I'm gonna shell into this just to show you what we've got so if I look in /data now I've got this virtual directory that is password and user name so I can cat slash data and you can see that it's me and I can show you my password and I log out of that pod that's it my pod is now running if it was an SSH key I could then use that credentials to get into my SSH the other peers or I could use it as an API token to go into Twilio or whatever I needed it to be you can switch back to the main slides now demo number two so I've only got a few minutes left but I wanted to talk about some of the things we've done and are doing around performance and scalability of kubernetes we started 1.0 and we said cumin ID runs on a hundred nodes and a hundreds a kind of underwhelming number right people said Google what are you doing a hundred nodes the truth is I'm gonna look out in this audience I'm not gonna do a survey but how many of you think in your head how many of you have more than 100 serving nodes right now right and I mean to see how it's not that many people but we heard people said actually there are a lot of there are enough people out there that need more than 100 that we decided were gonna ramp it up so the first thing we did is we defined an SLO a service level objective we said we're not gonna ramp it up unless we can do it the best right so we set our objective 99 percent of all of our API calls returned in less than one second and 99 percent of pods start up in less than five seconds and that has to be true on a fully loaded cluster the first pod and the last pod and then we use that to test how high we can go in kubernetes one two I'm happy to say we're doing more than a thousand nodes at more than 30,000 pods in a given cluster with our API server meeting this SLO now if you don't mind about the SLO you can probably double or even triple those numbers and you know things will get a little bit slower but this is this is where we are with one point to a thousand nodes now all those people who thought yeah I have more than 100 nodes do you have more than a thousand nodes I bet there's a very very small number of you out there right which is fine when you need it when your startup hits it gold we're there for you other things we've done in the 1.2 release we vamped r-cube proxy system which is the backbone of our virtual IP services model in the 1.0 and 1.1 release it did a user space copy which we knew is a little bit slow and was gonna be limiting to scalability 1.2 it never moves to user space it's purely done in kernel man is it fast for the demo that we did for the keynote we were getting ready to get set up and we were realizing that the load testers were causing problems and the first thing that we did was we switched to the IP tables proxy and all the problems were gone so if I didn't believe it before that's it additionally in 1.2 massive reduction in the usage of CPU and memory that our own components use on the system this 4x number comes from the guys at Red Hat so don't take my word for it this means there's more memory and CPU left for you to run your applications right we want to be as slim as we possibly can be for you now this of course isn't good enough so what's next 1.3 we're planning to massively increase the scale again I don't want to talk numbers just yet but it'll be big we're talking about moving to a binary encoded protocol JSON it turns out kind of slow when we ran a profile against our system the number one hit was JSON Marshall and unmarshal so we're gonna move to a binary encoding protocol you'd still be JSON there if you want it but we're gonna use our component to component stuff will all be done through protobuf and G RPC we also are adding a bunch of caching and parallelization in our scheduler so our scheduler throughput will be massively faster will be massively more scalable you can see here our graph from our current performance metrics we're publishing a blog post on this I'm not sure if it's out yet but it'll be soon and you'll be able to read a lot more about what we've done with performance and scalability on kubernetes 1.2 all of this is available right now kumaradas 1.2 is in the middle of rolling out to gke right now in fact it might be done this very day if you want it you can go to your container engine you can run the upgrade command and you can get all this goodness right here right now so all that said we have a ton of work to do we have 800 man years of work on our roadmap I'm not even kidding and that's if we only do the things we know about criminai Diaz is an open project we built it from the very beginning to be open source open ideas open standards open community we do everything in the public if anybody here has click that watch icon in github on mokuba Nettie's repo I feel bad for you because there's so much going on it's exciting I'm I'm passionate and excited about this we need your help we need people who are using this thing to come in and tell us what works what doesn't work what do you need out of the system because we are listening we want to make it work for you guys so you can see here we've got our URL the code of course is on github all of us hang out on slack all the time come and ask us questions we have dedicated people who sit there and answer user support questions all day we're also on Stack Overflow and we're on Twitter you can find Brendan to myself and many other people there and come and ask us questions so I understand we are not doing a Q&A session now but at the end of these sessions we will all be hanging out in the playground we'll grab a quick bite to eat and we'll be out there to do QA talk to people come tell us your story tell us what worked what didn't work I want to hear from you so thank you all very much you 