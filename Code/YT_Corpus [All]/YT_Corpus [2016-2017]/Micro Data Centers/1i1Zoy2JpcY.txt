 my name is Samantha can be honest I'm talk to you little bit today about data pipelines a little bit about me if you're not familiar with me i'm a software engineer I've been in the business since about nineteen ninety-seven I usually just be a cobol programmer so I can talk to you about COBOL I just did about JavaScript some Java maybe even a little Python my could be talked a lot about PHP just up maybe a little bit I've been in the media space since 2012 so I spent the first half of my career in financial services i worked for visa for a decade left financial services and and moved into the media space and they've been with AOL which is a digital media company since 2014 i'm also the organizer of the washington DC PHP user group so if you're ever in in Washington DC in the States please come by we'd love to have you if you're interested in following me on Twitter which is the best place to reach me I eat killer bees or you can find me on my website if you can somehow remember how to spell my last name so i mentioned that i work from AOL i can kind of see you guys over the lights who is not at all familiar with AOL awesome who thought al went out of business years ago yeah so uh AOL was merged with time warner and then in 2009 the two entities separated and AOL was spun off as its own company and we are in the the digital media space so we actually own a bunch of media properties like The Huffington Post and gadget TechCrunch we're also a big player in the the video advertising market all right so we do demand-side advertisement stuff yeah we're why did we have those annoying interstitial video ads on your mobile devices that's like all us sorry we're actually a very very large company but for the last few years we've kind of put the brands like being gadget brand Huffington Post brand in front of the AOL brand so most people haven't heard of us although we are still one of the large players in digital media space so the reason that I asked that question when AOL reached out to me a few years ago or a year and a half ago to come and join them I said why I don't why would I do that I don't really I don't really want to work for a dead internet dinosaur um but actually I i took the interview because actually the person who reached out to me was really very interesting and in my interview was that's a really interesting question so who here like hires engineers I see a few hands this is a really great question to ask engineering candidates in my opinion and I kind of like to ask questions like this when I'm interviewing candidates how would you let editors test how well different headlines perform for the same piece of content it's a cool question because you can kind of look at how a person works through a problem technically without kind of relying on like weird CS questions and silliness that we like to do in this industry but I want you to keep this question in the back of your mind because it's actually turned out to be a very important question when it comes to my time at AOL obviously that's an example of multivariate testing multivariate testing is one way that we can use metrics to improve our applications right so there's a lot of different traditional kind of metrics that we look at stuff like request response time cache hit rates resource utilization things are we're looking at to make sure that we're using the hardware that we have efficiently that we're providing a good level of performance for our users we use tools like New Relic I feel like this is perfect cuz we're in the new relic room new relic track right we used tools like New Relic to look at things like our CPU time per request versus throughput so how much as we as we were having more and more throughput how is our CPU times per request changing so we see that it kind of reduces as caches get hot right so you can you can get a lot of really interesting insight into how your application is performing we can look at our full stack see where we're spending a lot of time yay PHP actually a lot of this is is actually caching layer stuff so we have a very complex caching thing that I won't get into but we can kind of look and see where potential bottlenecks are in our stack this is all really important because perceived performance is vital so when users are interacting with your application anything under 100 milliseconds is almost imperceptible to the to the human brain as you move up to about 300 milliseconds there's a small perceptible delay but it doesn't rarely register as a problem it's when you get to around a second that the brain starts to think that there is a that maybe it's not just the system working hard and actually that kind of delay area can sometimes be important so have you ever worked on an application where you maybe you've not worked on an application but it's not uncommon for applications to inject an artificial delay during log in when password hat and password negotiation is too quick right when you get past a second up to about 10,000 up to about 10 seconds the system is perceived as slow eventually broken and after 10 seconds generally suck at 10 second response time generally speaking girl you'll have lost your user this can have a real impact on revenue so Amazon did a study in I'm trying to get my notes they're so so super tiny 2006 where they looked at the effect of latency on sales they saw that with each hundred milliseconds of increased latency they saw about a one-percent drop-off in sales so I don't know what I don't know what Amazon makes every second probably two or three thousand dollars i would imagine in revenue that can be a huge amount of revenue lost right and for a company like Amazon that actually keeps you know stock like those margins are very very small for google they did a search experiment where they into the injected artificial latency into some of their search search responses and found that as the latency increased the number of total searches went down right so Google makes their money the same way that AOL makes our money right we put ads for you know Honda Civics on the internet and the more of those ads we put in front of your eyeballs the more money we make right so Google's in that same business so for us all about page impressions right so you can see that you can have a tremendous drop off in your revenue by having a very small I mean this is talking about you know additional milliseconds 150 milliseconds of latency can actually have real bottom bottom line impact and then to go back to what I talked about a few minutes ago multivariate testing right this is where you take your users you sort them into groups right you have a control group and you have treatment groups and you give them different content and then you measure behavioral statistics like click-through rate and abandoned rate right to see how different types of content are received by the end user right so this is a way of looking at the performance of design elements or even the performance of content itself something that doesn't often get talked about when we talk about metrics state monitoring all right so logging so who has a distributed application but does not use centralized logging I'm glad I don't see any I see a couple hands it's vital to understand it is a vital aspect of performance monitor monitoring to understand what exceptions are being thrown in your application what is the general load at the at the individual web head right what is the system performance what is the cache performance so we get a lot of this out of having applications that log to a centralized logging repository and a big thing for us especially because we're in the advertising business and I'm going to try not to make it sound like we're too creepy just a little creepy a good amount of creepy traffic metrics so trying to understand the people that are interacting with our content like who they are what are their maybe what's their gender what's their age what's their income range are they more interested in seeing ads for Honda Civics or you know for nice Bentley right we want to look at the user behavior user behavior and experience so we want to understand like what is the user clicking on just off my microphone off what does the user clicking on where are they coming from where do they visit when they hit the site where is their mouths going right so we can click we can follow where their mouse is on the page we do a lot of really user monitoring so monitoring how long it takes for the JavaScript on the page to load how long do all the dns lookups take are we causing an excessive delay when users browsers are loading our content right how many of you have seen this this is the dreamscape multimedia did this I think in I don't remember it was awhile ago where they did this is actually not mouse tracking this is eyeball tracking right so they're tracking the where the eye is looking at the screen and the kind of found that this pattern that this pattern exposes itself over and over again we're sort of the eye is drawn to the upper left corner right so if you look at the way that Google kind of lays out there their page their search results which is I mean this is where google makes their money right this is there this is their money page there their most important stuff is right where the eyeball goes first all right so this is a way that we can use you know user monitoring to understand how we can improve the performance in this case the revenue performance of our applications and we do a lot of demographic collection so we collect information about like I said the that you know the an anonymized user information so we're trying to figure out who a user is not like who that person is like it's Joe Smith but like this is an individual human being and well maybe try and figure out some facts about that human being we're not really that interested in who that person really is what devices they're using what is peas they're using the geographic location that they're in if we can't get that at least the region are they in the UK are they in the EU or in the United States right so we do all this as part of something called the AOL media platform all right so I mentioned the before that we have a whole bunch of brands all the brands of this big multi-tenant system called the AL a media platform so it provides content management distributed rendering wow so this is a PHP stack sort of a couple hundred million page views a day we don't use any front side caching so every time you hit one of our properties you there's PHP being executed right so this big big massive rendering farm these websites are developed generally speaking using a custom dsl inside of an IDE that we develop and maintain we have a content aggregation platform we have a machine distributed meat machine learning platform so we we aggregate content from all of our brands and also from external partners and then we run it all through a machine learning platform to try to understand what it's talking about stuff like that and like I said this is a big multi-tenant system so we've lots and lots of brands living in there together at the same time I want to talk to you about basically what I was brought into a ll to work on right so when I started with AOL these are the four things that we had from metrics and analytics so we use omniture for revenue analytics New Relic for application performance monitoring we also have a lot of elk infrastructure is everybody familiar with elk elasticsearch log stash and cabana okay so it's kind of like an open-source way of collecting like open-source belonged if you're familiar with splunk and then we have a perp I a proprietary data platform called the called the data layer which is used for collecting rum and demographic traffic information right this is a massively distributed data collection network it's based on Hadoop so essentially we have a big giant data store where we just collect petabytes and petabytes of data we use Cassandra to slice some of that data off to make it more readily accessible to different consumers part of this is a vertica installation where we ingest a lot of data from Omniture and then sort of massage it to make it fit with the kind of reporting that we need and then there's also a streaming interface for raw data alright so it ends up looking like this at the very front we have these things called beacon servers and if you hit one of our websites you might see in few open like the chrome inspector connections to something called ba ll com or beaten gadget com these are the the beacon servers and these are just web servers that are sitting there connect their internet facing you throw JSON payloads at them and they push them onto a RabbitMQ but be there fairly simple they have some kind of filtering like to try and filter out garbage but they're fairly simple so all of that goes into a giant RabbitMQ farm and then from RabbitMQ there are services that pull that data out push it into couchbase push it into Cassandra push it into vertica everything gets logged into Hadoop and then all that stuff also gets pushed into a stream or farm so this is what what drives these data layers streamers right over here on the right side is a I said that raw data streaming interface so all that data that's coming into the be considered beacon servers up here comes out over here exactly as it came in the beacon payloads themself looks something like this now they're generally much larger than this but they're just JSON objects if you see them in your chrome inspector you can see what's in them there's nothing particularly interesting will capture the user agent this makes sense to us has a Content vertical kind of information everything gets assigned an anonymous ID if you if you allow cookies that will persist across different AOL properties we get the refer locate your geographic location if we can figure it out from your isp information stuff like that and then we can actually inject things like multivariate test payloads into here so we collected this tremendous amount of data each one of these these payloads which we call events contain about 40 different keys they're roughly about 1.6 kilobytes in size so they're fairly sizable we get 15,000 of them a second writes about 25 megabytes of data every second and in the course of a day we log about 1.3 billion events or about 2 terabytes of data it's just a very large amount of data not very large I in the terms that in the maybe in the sense of the whole internet but for us pretty big so this is all great and all of the stuff goes into do but you can go into Hadoop and you can rob bread and I'm you can run hive jobs in Hadoop and like extract amazing amounts of data out of the system but it can take a long time so that's a time shared system we have to share that with other developers for trying to get at this information sometimes it takes a couple of hours to pull information out generally speaking from the time that data hits a beacon server until the time it's available in Hadoop is a couple of hours right so realistically speaking to get information if you go right now to to engadget com and click on something for that data to be available in a report coming out of Hadoop could be six hours right our editors don't care what happens six hours ago right they care about what's happening in the past hour two hours they want to know social engagement trends like who's tweeting about something right now they're very very time where every time oriented and then also we have to remember we have all of these developers who are our customers so we're not just developing a product for content creators we're developing a platform for for software developers right so they need to understand a lot of those application performance things that I talked about earlier how are their API queries performing are there is how is their cash rate cache hit rate what kind of exceptions is their code throwing right so they need to have this information to and they don't have the luxury of direct access to something like you relic or elk right we live in a 24-hour media cycle so you know media trends change hour to hour and it's very very important for us to be like the difference for for a breaking news story like if if some some information comes out about Miley Cyrus I will talk about Miley Cyrus so much I'm sorry if there's a breaking news story about Miley Cyrus if cambio calm gets to it first or or gawker com gets to it first whoever gets to it first is going to make the money from that story so it's important to be on top of these things so anyway I joined AOL because of this project I thought it was a really really interesting project and this is actually a unique experience for me and that in the weeks leading up to my kind of between my old job and the new job I was in daily communication with my new boss and we were planning and designing and and discussing kind of what this new platform would look like this real-time data platform would look like so i had the really cool experience of going to work on my very first day getting my software so i could sign it and then immediately starting to work on this project and the first question we want an answer was how would you let editors test how well different headlines perform for the same piece of content so that's that multivariate testing quite a question right so I want to tell you how we did this with just three easy failures started with a proof of concept so over here on the left side of the screen we have those streamers so those are the real time data layer streamers that I talked about earlier connecting to that we have a receiver so these things generate an HTTP stream you connect to them over HTTP and they just start sending you lying delimited JSON objects so you need something that's going to actually do that can make that connection and consume that data and then my initial thought was to push all of that into a stats d question it's familiar with stats d okay I see a lot of hands so stats t is Canada out of a etsy it's actually a really cool little tool it's very very simple node.js application that just runs collects data aggregates it in memory and then pushes it off to something else you usually graph I but you can push it to elasticsearch or a bunch of different backends and in this case I was pushing it into elasticsearch and I wanted to use elasticsearch because we already have a lot of familiarity with cabana right so cabana's the visualization tool that lives on top of elastic search from a logical perspective it kind of look like this so we have a streaming HTTP client this is built-in nodejs so it's using a native node stream we receive the data layer stream break it off at each line break create new records for each data layer event push that on to a message bus and then a bunch of event listeners that look for those events to get created and then edits them right so it extracts the information out of them that it wants and generate statistics objects which then get pushed out to stats d right there was one good idea here that we had and that was to kind of encapsulate this editing it's tiny little services that were shareable and reusable this is the only code in this entire system that that survived from prototype to production it's just parsing out a you a user agent but using this method in about a week I was able to produce something that was fairly usable in that so I took the screenshot on my seventh day in AOL where we could actually see on a map this is not a video unfortunately the different countries the darkness would change as there were the number of hits in the past second would change for each of those different countries right so if nothing else it proved that we could do something somewhat meaningful with this stream of data right so the proof concept while it did work we were only able to consume 300 messages a second so remember we're talking about a total of five hundred fifteen thousand messages a second sometimes that spikes up to 20 so we would have needed around 70 receivers in order to do this which is an unwieldy number of receivers and then stats t actually imposed a bunch of other limitations so we have these very rich payloads and these payloads will tell us that someone in into in Denton Texas on an iPad looked at this content what we see once it gets broken up into stats T is that someone in Denton Texas looked at this content and someone on my iPad looked at this content we lose that connection between those data points it was around this time that I realized that in order to build an efficient real-time data pathway you had to have a network transits and terminals this is not any kind of real terminology this is BS that I made up the idea here being that you have no single know that acts both as its transit and a terminal at the same time that is to say transits are short-term volatile or data lives date with a very short lifespan while it's in route to something else and terminals are where data goes to either be destroyed stored or retransmitted so the first thing that we needed to do was replace that's D as a transit right so two of the tools that we looked at work Kafka and RabbitMQ so who's familiar with Kafka and how about RabbitMQ okay so a lot more people continue it familiar with RabbitMQ than Kafka i'll talk about Kafka first so Kafka is a pub sub message broker it came out of LinkedIn a number of years ago it's an Apache project now it's very similar to rabbit and cue in that it's it's a you know a publish and subscribe message broker but it's very focused on message integrity so it's persistent first message order is preserved so you get messages out of it and the same order they go in and it's highly fault tolerant rabbitmq on the other hand as a little bit more mature it's been around since 2007 it's kind of considered the de facto amqp implementation it's much more general purpose it allows routing you don't necessarily have a guarantee of message order integrity although you can you can get that it uses Federation for high availability as opposed to persistence and sort of sharding so when you think about our our requirements we're getting these payloads they're very rich payloads and they're time-stamped so it doesn't matter what order we receive them in when we analyze them they're going to be analyzed they're going to be if we like do a histogram obviously we're going to use the timestamp anyway so the order doesn't matter some data loss is acceptable right we're collecting 1.3 billion events every day if we lose ten percent of that we still have a significant sample size to do analytics against we have different consumers that may want small subsets of the data right so being able to take data and and route it based on different parameters is something that would be very very useful for us we need to have a broad support for different languages right so generally speaking our big three languages at ARL or Java Python and PHP we have a lot of know Jas lately too so having support for those languages would be really really for us and we need to route data between lots of different data centers and like we're right in the process right now closing our physical data centers down and moving everything to AWS we've got like one foot in each world so we're constantly like shuttling data back and forth over this network bound reasons it's every bit as horrifying as you're imagining right so I ended up choosing rabbitmq right because the priorities were very similar to mine rat I had the Federation over at least once delivery I don't care if I lose a couple messages it's not a big deal I can route messages I Confederate over network boundaries even though like you really shouldn't do this you can especially if you're if you're routing very specific chains of messages across very small volume there were mature clients for all of our major application stacks right and obviously pivotal's behind it so that makes it attractive to a big companies right so that was the first decision so we just I decided to replace stats d with RabbitMQ right so now we have the data layer streamer the receiver the node.js application pushing into RabbitMQ and then elasticsearch on the other side made a couple of other changes in version one I moved away from the observer pattern so if you remember before I showed you each time a message came in we would generate an event and there would be a bunch of event listeners that would pick that that event up extract data out of it and generate a stat record moved away from that why so no Jas is really really great at handling events it's a very very fast engine but when you're generating a tremendous number of events all at the same time you can cause a lot of memory blow right so while that's tunable and like if you go if you go to the J's community and like say hey I got this problem with like I'm generating too many messages like well you can write a native module and you like okay you can you can't get around this limitations but rather than doing that I wanted to just use the backpressure method mechanisms in the native node streams to sort of regulate the input rate so it ended up looking kind of like this we have streaming HTTP client just like before we're still breaking apart messages as they come in now they go on to a process chain and each one takes the record performs an edit to it and then passes it on and then we get this enriched edited record that comes out the other side and goes in to grab at mq right so this was fine this work great you do start running into weird things where you're kind of like looking at operations like I need to pull the first element off of an array in a tight loop which one is faster right and just as a general rule in software engineering when you find yourself kind of thinking about this either you're a systems programmer or you've done something horribly wrong this is a this is this is am I telling this should be the picture next to micro optimization in the in the dictionary so very the one I've actually doubled the performance 600 message is a second inversion one which means we cut the number of receivers down to 35 which is too bad but two main problems having to do this micro optimization of code was getting really really sketchy and also was having to constantly add code to handle weird edge cases like we would get weird data especially from from some of our users in east asia where sometimes like people with older computers they're sending data that's encoded strangely we're not strangely but just encoded in non UTF formats and it would I mean it literally just cause node to crash because there would be like something that node thought was it no and they would just we would fall over so constantly having to like like write code to handle these weird little edge cases so like I said when you're when you're having to constantly deal with good edge cases and micro optimizations you know as an engineer that you've done something horribly horribly wrong so you have to kind of reevaluate and I want to point out that me not knowing how to use node to its fullest extent doesn't mean there's anything wrong with note and i mean i realized i don't have to defend node to you guys because you're mostly mostly you are PHP developers sometimes it's very easy to dismiss a tool i think this happens a lot to PHP right like people like say uh PHP's garbage because their experience with PHP is 10 years out of date right doesn't necessarily mean the tool itself is broken so throughout this time that I realize I needed to get very very serious about what I was building receiving data editing it and routing it all on the same step violates my transit in terminal separation policy right so I'm doing that over here right this guy's doing too many things the receiver should be simple should just be a transit that consumes data off of the high-pressure RabbitMQ are the high pressure data streamer and pushes it into the low pressure RabbitMQ farm that we control right it would be really nice to build this in something that has static and dynamic optimization a nice multiprocessing model because would be much more efficient if we could do this sort of in-memory edits in a number of multiple threads and something would that's good at managing like very large very volatile data sets in memory right so I had a different number of different choices I could go with obvious I could stick with nodejs which is very simple and fast and that we have a lot of institutional knowledge about you know deploying and distributing we could use Go Go is really attractive for this because of its native concurrency model right so if you're not familiar with go like it's very very simple to do like very lightweight threads and go a good memory management it compiles FAFSA for a compiled language like go is really really very interactive goodies rust could use Java Java has got a very very powerful static and dynamic optimization it's got really great memory management it's got multithreading especially if you use libraries we could use C or C++ also really really fast there's good libraries for handling concurrency and for handling memory management a lot of downsides though for nodejs I just need too many instances to manage production flow without hyper tuning the the v8 engine right while I was really pumped to use go and some of the people on my team were like yeah that would be fun it's kind of selfish to like I want to build this and go and then I'll be the only person who can support it rust very very similar except no one was like I said hey who wants to learn rust and just cricket chirping I know I cuz so I speak a lot of PHP conferences I know if I did this in Java I was going to be fun of me and I just don't hate myself enough to do it and see I think it's really important as a software architect to understand other people's vision before expressing your own I think like kind of like growing into that role means learning to understand how other people see a solution to a problem when I first started this project and I was talking to the data layer team so they're the people that manage everything to the left of those streamers in that early diagram they said you know what you're probably going to want to build this in Java and I said no it's 2014 people don't build things in Java anymore I don't smell my right my life writing giant XML files it's an oj s world you know they beget with it yeah I use Java so version 2 same streamers before receiver now written in Java rabbitmq a new component called the process of router on this side so the process of router is essentially all of that nodejs logic that does the editing of records the massaging of data extraction of data encapsulated in its own processes over on the other side so I what I guess what I'm trying to point out here is that this is a very high pressure connection like there's this is we can't back that up that is a fire hose over here this is a very low pressure connection we can drop records out of this if we get backed up and drop some records it's fine no big deal so having the the nodejs server processes over there we don't run into that same performance issue of trying to keep up with this massive stream of data and the Java itself who hasn't worked in Java ever or hasn't worked in Java in a long time yeah so job is actually not that bad actually looks a lot like PHP i should say PHP looks a lot like Java this application is written in very very bare-bones Java no frameworks simple route wrapper around a native Java inch dreamer create a bunch of threads each thread maintains a connection to rabbitmq we have a very very simple pass through so we just basically read the record off the stream attempt to parson is JSON if it parses we push it over the rabbit the rabbit very very simple I described it as a bunch of ketchup bottles we have net work input a bunch of cues and then network output so it's a very very minimalistic application from a logical perspective it looks looks very very similar to what it did before so we have a streaming HTTP client we cut records at new lines push it onto the work queue worker threads pick them up and generate the wrong send the rail records onto amqp if they're valid JSON so I expected to get some performance benefit out of this new version and I did that it's about 2,600 records a second which means I only needed would need about 10 receivers in production and I in production now I have 12 it's pretty close validity filtering is almost free in the Java receiver if it can't parse JSON we just drop it right and then the processor the router service can select only the messages that it wants everything else gets dropped on the floor or left for another service to collect right so huge win right we're getting that data out of this massive fire hose and into a pool where we can use it but this is where it just starts because without consumers this pipeline is useless we have all this data now flowing through RabbitMQ we going to do with it so I want to talk to you about some of the applications that we're building on top of this pipeline first thing is our real-time analytics service so we want to do math at all this data I guess i should say mass it just sounds so weird so the goals here provide real-time statistics metrics and analytics for the editorial staff so these are the people for the secured mostly towards the people who are generating content they're writing stories we want to allow them to do a statistical evaluation of arbitrary variables right and we want to provide a simple interface for the developers who are working in the publishing stack so these are PHP developers so we want to provide a an interface that lets them get at this data without having to go through too many hoops right so you know it's been kind of like hanging on the right side of the screen all day elasticsearch that big bubble who's familiar with elastic search awesome i love elasticsearch i give like 18,000 talks about elasticsearch i kind of want to marry it elasticsearch has a high performance no SQL documents store right that has it does a high-availability Vidya intelligent clustering it's like got rack awareness data center awareness built-in it's got a really really powerful query DSL I guess it also does some full-text searching or something I don't know it's a very very powerful analytics engine it clusters out really really nicely so remember before I was saying that one of our big issues is moving data around between all of these different data centers and AWS right so we can have clusters that live in AWS we can ask them that live in elle's us data centers in our EU data centers it does replication and it does elastic replication and so if you decide to add nodes to a cluster it will rebalance the location of these individual shards right so it's a very very powerful very easy to to scale out data store for search applications it's got a really simple dsl right so this is uh this is actual real code from from there's Miley again hey Miley from one of our sites cambio calm which is a site a US based site that's a kind of geared towards teenage teenage girls analytics queries are a little bit more complex so we do things like multi-level aggregations so in here what we're doing is we're searching for specific types of events that happen in specific post so these are referring to individual articles that live in the system and then we're extracting out what search referrals led to those individual articles and then or should say we're parsing out the actual referrals and then making a decision if it is a search refer trying to get the search terms back out right so we can do these multi-level aggregations this stuff lets us build dynamic interfaces inside of our CMS that look like this so this comes from engadget I took the screenshot a couple of months ago where they can come into our into their dashboard and they see these numbers just scrolling live showing the the page views and then for us internally these columns you see over here on the right social search internal and other refer to where the referrals came from so whether it came from a social or a search site or internal meaning from another AOL property right so we try very hard to maximize how much we drive traffic from TechCrunch to engadget and stuff like that right client access is really easy so we can we can we index on the on the no j s side of things alright so we can index a whole bunch of stuff just create big bulk index requests and shove them off with a wire PHP super simple to connect to elasticsearch using they have a really great library that that elastic search actually maintains so you can perform searches so very very early on in this talk I was mentioned I mentioned a multivariate testing all right so allowing editors to test the performance of any concrete element so things like Dex leads headlines sub leads hero images right so all the different things that aren't a page and we wanted to be able to let editors to do editors do this create tests start them stop them and evaluate them without actually having to talk to one of their developers right because developer time is expensive so what can we do how can we do this well each new visitor that comes into a site gets cooked that's how we assign them to a test group we used to inject test markers into that beacon payload that comes back over and then we compare the click-through rate to calculate performance right so we have a test population identifier on a test ID so this makes it makes sense to our back-end databases that understand what these tests are these are again user-defined tests so as a content editor or content writer I can come in here and create a test i could say i'm going to write an article i'm going to give it two different headlines and i want to see which headline gets more clicks so then on the on the analytic side from all that raw data we can look for page views we can create a nested aggregation that looks for records that have multivariate tests pulls out the test ID pulls out the population ID and then determines whether it was a clicker or a a page view and then we can do some very very complex mathematics to calculate the click-through rate and we end up with an interface like this so they can actually come in here there's no developer involvement here this works automatically on any one of our content plath in one of our content brands any editor can come in there and create four different headlines for their article so what's why this is important for them it's not we couldn't do this under the old system before they could look they can create an article and then maybe six hours later or tomorrow going to see how the different headlines performed now if you go and click on one of these headlines these numbers change within five seconds it's five seconds from browser to browser right another big thing mostly that my boss was was interested in my boss is a really interesting guy he's he's all about real-time native real-time native real time he wants to see things moving and popping and shining and making noise he wanted wall maps right so how can we create wall maps with this raw data well we can create a socket i/o server use a WebSocket server let browsers connect to that with a JavaScript client and stream data right into the browser now obviously we have to select a subset of messages you can't stream 15,000 messages a second to a browser I've tried it crashes chrome right so this is where RabbitMQ comes into play we can select out a small subset of messages push it out to the visualization service right and then we can pump it into d3 who's used III okay see a few hands so we can pump this into d3 we can use d3 to create a map projection and then draw on that map where each of these geographic points are and it ends up looking like this right so I showed this to my boss is like oh wow that's really cool and I said yeah that sure is a cool map of the english-speaking population of planet Earth which is what it is I shouldn't say that I mean we do have like we do have actually like a like Korean like language properties and japanese language properties but actually this is this is this means a lot more to our editors they put a lot of heart and soul into writing this content and for them numbers don't mean as much this feels to them much more live and real they could have an emotional connection almost to this sort of living breathing visualization of their content out there on the internet being consumed it's kind of cool I tried to make this a little bit more useful by color-coding the dots right so I color code them based on the property but you don't really I know I mean like the green dots are of dailyfinance calm so that covers like the stock market's international currency markets and stuff like that so I mean big surprise popular in London New York San Francisco right autoblog like really popular in like Russia they're like super into cars there for some reason one thing that's really cool is like the ability to create embeddable visualizations right so this is a tiny little visualization that we can actually embed next to a post inside of our CMS right I know if you can see this with the light it's kind of dim can you guys see this okay now I won't call this a graph because if you'll notice there's no numbers on either axis this is not a graph all this is is I'll show you what this is all this is is we're counting the number of events that happen each tick and then we're moving the line up and down and doing a spline transformation so that it goes all squiggly right it's very very simple but this allows people to have a connection to this data sitting right next there to next to their posts they could say wow people are really like looking at my stuff look at it it's moving this point here like jumps really really high and it looks really impressive it's probably a network glitch where like we kind of missed counting for a second it's not a really big deal but these kind of visualizations have a huge impact you know what here there it is in a way that I think sometimes we as engineers miss right because we tend to be much more like evidence-based and I want to give some love to the developers to so like I said we have all these developers we have about a dozen developers who work in my team working on the core platform and then probably you know a couple of hundred developers who are actually building on top of the platform actually building user-facing sites right so they're really very important to us want to give them the ability to profile their code live right so they use our API they have two ways of building on our platform they can connect to our HTTP API and they can build using whatever stack they like they can use PHP they can use Ruby they can use nodejs whatever but they have to manage their own infrastructure if they want they can use our managed hosting platform right so we handle all the scaling we handle all the cash and we do all the hard work so they can focus on their stuff so the vast majority of our customers do this right the only downside is that you have to work in a custom dsl now it's better than it used to be used to be you had to work inside of our IDE now we have the ability to let people create their own git repositories they write their code they use these this thing called the amp client and then they can sink that to a live machine that's out there on the internet or they can do testing is it's really really cool I keep trying to get Ralph still I give and talk about this really really fascinating it's all built in PHP all built on twig like the other user facing language is just based on twigs to the extent instead of a series of twig extensions that generate all this stuff so to profile this code what we do is essentially the dev starts up a profiler session so they're in their management console and they started a profiler session that gives them a query parameter so they hit their website we used with this query parameter appended to the URL they can do this in production or they can do it in divot and development it doesn't matter using that token activates the profiling so all of these event messages that get generated by activities that are happening inside of the system get tagged with that profile session ID anything that's tagged appropriately gets routed by RabbitMQ to the profiler service alright so the profiler service just sits there waits for messages when it gets messages that its Caesar meant for a logged in developer it routes them to the console so they can view a waterfall of their code executing right it's not baby the best example like wow that is a really slow HTTP request nine seconds bad times but they can do this like i said i think it is in production and they can do this in development so they can actually go and look at their code executing live on some you know one of our 1200 render servers they're sitting out there without knowing which server it's on without having to go and look at logs the last piece I'll talk about is cross-platform eventing right so I mentioned that we work in a bunch of different stacks and one of the things that we thought would be really cool be allowed developers to dispatch native events in one stack and then observe them on another right so in this case our CMS is built in PHP it's not built using symphony but we use a lot of different libraries one of the libraries that we use is a symphony event dispatcher right so we want to allow a PHP developer to dispatch events using the symphony event dispatcher and then maybe have another developer who's working in nodejs somewhere consume that event natively right so to distributed event handling without PHP workers so this is kind of how that routing happens and we've added in another another direction so we have these messages that go out to the event handler service right The Dispatch works basically just by overriding the native dispatch that comes out of the symphony event dispatcher so we look for events that are forwardable that implement this forwardable interface and when we see them we push them out onto the RabbitMQ I talk before I clicked right so that we forward them out onto rabbitmq so then over in in the know Jas world all we're doing here is creating a listener so there's some bootstrapping code that actually comes in here and reads this out of the exports but we're here dispatching an event name damp post save and then here in a lot in in nodejs we are listening for an event called aunt post save right when that event gets sent out over the pipeline it gets picked up by the event handlers and can be consumed natively in nodejs so we have a bunch of other stuff that we're building on top of this to kind of summarize what we're talking about where we are right now 1.3 billion events that we're consuming a day we're out all of this stuff through through rabbitmq two different microservice consumers right we're doing real-time analytics on a data set that's about two hundred and fifty gigabytes of raw data per day so of that two terabytes that we consume 250 gets ratted into our real-time analytics service we're visualizing 1.3 million events a day and generating live profiles 450 property so we have about 50 different developers at any given time that are in there doing live profiling of code and we're using we're using cross-platform eventing to handle that 10,000 elasticsearch search index updates every day all this is built in Java nodejs a lot of PHP is especially in the front end pieces Python on the backend Hadoop and RabbitMQ elasticsearch and vertica 4 2016 and the rest of the year so one of the big things is cool is that we're moving this all into AWS which in the one hand is horrifying because petabytes of data so we give you one of those cool companies that gets like FedEx like boxes of hard drives to Amazon that's going to be exciting a lot of this is going to change because amazon kinesis right so I don't feel familiar but amazon has this really really cool new streaming service called Kinesis some of the things that we're looking to do a real-time sentiment analysis and predictive performance analysis so we have this plan to create content bootstrapping to let our content creators know what topics are trending heavily out there in the media world right now that they're not covering so if they're a cambio and there's like hot Justin Bieber news that cambio needs to get on now right we want to be able to tell them hey like we don't know what it is but there is some gesture Justin Bieber stuff going down right now you need to get on it right so we can do predictive analysis social sentiment analysis of what's kind of happening in the social world in real time and continue with some bed embeddable visuals visualizations the pipeline if you look at it as map ends up looking like this so we have different the AOL media platform in the AL data platform that are generating or inputting into the pipeline and then the analytics service visualizations profiler religions is our machine learning platform so we're in the process right now connecting these two things to actually take this real-time data and push it into that machine learning platform that I mentioned earlier so 2016 is gonna be really really interesting year I would love hopefully to come back next year and tell you where we are then because I think it's really very exciting it's a very very exciting topic and it's really kind of cool to be at the kind of the bleeding edge of of media right so that's really all that I have we have a couple of minutes for questions please make sure that you take a moment and hit joined in give me some feedback leave feedback for all of the other speakers that you've seen is really really very important to us helps us make better talks for you guys oh thank you many questions that's a very interest talk as the very good to hear the experience we're using Kafka as well so and we're using spark streaming for the real time not analytics but statistics with the latter sir so just have a question of interest the you still use rubbing and cute have you considered to replace this with cup cards for all this good use cases for probably am q in these other scenarios um I mean we kind of compared the two when I was building the part of the system i went with rabbitmq mostly because i don't need the persistence that rabbit that Kafka gives Kafka's actually can handle a much larger load of data but we're not at the point where we're kind of pushing up against rabbitmq limitation so it didn't really matter in 2016 like I said we're going to be moving all this stuff into Kinesis in amazon so it's going to be interesting to see how that how that plays out but probably not Kafka anytime soon any others sweet go eat lunch okay that's good 