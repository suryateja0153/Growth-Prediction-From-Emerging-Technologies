 thank you guys I was here last year giving my first ever talk a lightning talks around last J Hong Kong so I'm really glad that I can be here again this year and give this talk to you guys and yeah I'm late to the gym no party I'm going concluding this party today so let's start that's me I'm a developer Jim do I am NOT a machine learning expert or a data scientist data engineer I'm neither of those I just did that project in my free time because I wanted to so if you have specific machine learning questions please don't direct them to me ask your local data engineer you can also reach me on twitter at jimmy 40 to get up and if anyone's still on Google+ just check if I'm there too I think so okay so let's start with a funny quote this is actually a former football player and he said I never predict anything and I never will so neither am i I already put the predictions up for this match today today tomorrow yesterday I put them on the back side of this wall I think and I will be updating the results as they come in I think the game will start in 15 minutes so let's see how well my neural network actually does things okay so first things first we have to understand neural networks and this will conclude some math but I hope that most of you will get it because it's really not that hard but let's look at neurons first those are naturally occurring neurons - and the sneaky fuzzy stuff to the left are dendrites dendrites received the input then the neuron does stuff with it sends a signal to the next dendrite via the axon and then the whole thing is done again and the very interesting thing about a neuron is that neurons could do which to one thing can learn to do another thing so let's say those are neurons for seeing and then the person gets blind for some reason so those neurons aren't useless now because they can learn to hear for example and they will just get some input do some stuff and then just send another signal to the next neuron and it doesn't matter really what the signal is so the thing how it how neurons do that is by experience so they they get a lot of input over time and they there's a lot of repetition and iteration and by by that neurons learn to see the pattern or the logic behind things so what neurons do need is a variety of training training examples and that's the most important thing so let's look at an artificial Network that is a simple multi-layer network we have three layers here the first is the input layer that's where we receive our input then we have a hidden layer I just chose to have one hidden layer it doesn't really matter or you can just try it out what works for you and then we have an output layer so in in this graph the arrows would be our dendrites or more axons and the circles would be our neurons okay so let's look at it more closely so in the first layer we get our input like I said we call those X for the purpose of things so we have three different inputs two different features X 1 2 X 3 and if we look at the first neuron or the first layer we see that it puts out 3 different values from the neuron so this is the math part I was talking about I put a legend to the side so you remember what I'm talking about so X 1 would be our input and theta 1 1 1 is just a weight so theta in this case is a matrix if you don't know what a matrix is just imagine it as being some kind of JavaScript object and the 1 1 1 would be the keys to access the value behind so I could just say x1 times or whatever pony unicorn and so then we send another signal x1 times another wait and then another and the way that we choose theta here the weight is actually that for our initial run for the first iteration we just choose it randomly just we don't know what the way it would be and we just initiated randomly okay so if we look at the first neuron the hidden layer and the second layer then we see we get three different features multiplied with three different weights so we get X 1 times something X 2 times something and X 3 times something so this neuron actually gets all the input with some weight and then it just sums it all up so it just adds the three input values and then it does something activate there's in fact of an activation function and that is the magic that's happening so there are different activation functions I won't go into them because that takes a lot of math important to know it's just that we sum up all the input and then do stuff with it and then get to our new value which would be a 1/2 but again this is just a value in a matrix doesn't really matter what it says so the same thing actually also happens in our last layer now output layer we receive our input so we get now have a 1 to a 2 2 and a 3 2 and then again some Thetas again initially random randomly initialized and then we get our last value a 1 3 which is just the sum of everything we have and then we activate it with something ok so what we have in the end is we have values we do stuff with it get new values to do stuff again then get a third value that is the result of our hypothesis so our hypothesis is kind of like the model that we try to build to represent the logic or the pattern we're trying to learn and so what age theta of X means is like you put excess in like X 1 X 2 X 3 would be 3 values in a vector or an array if you want and then so the function says this is the logic that I think it's gonna be and then we get our result this would be a numerical value probably and it's ideally really close to the reality and the reality is called Y in this case ok so there was really a lot so let's pause with a funny quote this is by George EP box and he says all models are wrong but some of them are useful ok so let's say we did all that stuff with our neurons and become fewer all that those things with their magic activation function and now we have a result but the result is actually probably not that good probably not that close to reality because we initialize data randomly so we just said just to random stuff whether for this case which is called supervised learning because we have we have a output that we know is the truth so we supervise our machine while it learns and supervised learning is used for for example quota for betting places the P win quota there is one where there are supervised learning and also that is a really nice example as housing price predictions where you say this is the square meters and this is a number of rooms and this is the price amount of money that I have to pay for and so you train your neural network with stuff that you know is the truth there's also unsupervised learning that is for example the Netflix recommendation system so there is no real answer that we the people who build it know about we just say probably there's some pattern here maybe you can try to figure it out and clustering is one of the most often used methods to do unsupervised learning but I won't be talking about that only to be talking about supervised learning okay so like I said we initialize data randomly and this could be an example of our training data so we have four training examples let's just say this is housing prices so x1 would be the number of I don't know square meters and the other one would be the number of rooms which is weird but doesn't matter so XS are the inputs Y is the result that we know it is and H of X would be the result that our neural network just gave us so as you can see it's off of course because we just did it randomly and the question now becomes is how do we actually learn the correct patterns or the correct weights for our theta so what we can do is calculate the cost so we have our output 60 and our y which is 43 and the cost would be the difference between those two and this cost is also described described by another function it's called J of theta doesn't really matter what you call it it just means this calculates the difference between our result and the actual thing that the reality okay so what we do now is we use a very complicated mathematical function and then we take our cost and then propagate back through our network that's called back propagation and try to change the values for theta in a way that minimizes the cost because we wanted the error to be small as small as possible so we try to minimize J of theta and the way that we do that with synaptic it's called gradient descent there are other ways and other functions to actually do that but I will only talk about gradient descent for now so this is very complicated so I'm trying to make in a very basic way so let's say this is a graphical representation of our cost function we have theta 1 we have theta 2 and then we have a circle which is stay of theta so what that means is that all the combinations of theta 1 and theta 2 that are on the circle have the same value for theta J of theta so let's say the the the the bottom dot there is theta 1 2 and theta 2 1 that's not a very good example but so there those will have the same value for J of theta or like the upper point where theta 1 would be 2 and theta 2 would be 4 maybe okay and then if we calculate J of theta 4 a lot of combinations of theta 1 and theta 2 we have something that looks like this and the way you have to look at it is actually that there is a third dimension going into the back which is there of theta so the value of J of theta becomes smaller to the back so imagine you're looking into a funnel now we can see here that where the Red Dot is that would represent the minimum so where J of theta would be the smallest and this is what we want to reach and what gradient descent does is now that let's say the gray dot I hope you can see it yes and the way dot is where we come out initially and we understand basically checks for the values of theta 1 and theta 2 that will get us closer to the minimum doesn't have to go there directly sometimes it will wander around a little bit but eventually it will try to reach the global minimum it doesn't happen all the time sometimes we just wander around it but you you will reach the vicinity of it and the size of the steps actually is called the learning rate you can change that rate you can make the size as bigger or smaller and usually the learning rate gets smaller the closer you are to the minimum so what you can't really see here is that the steps will get smaller the more you approach the red dot okay that was a lot of theory so let's implement something and you will see it's really not that hard so I use synaptic because synaptic does all that stuff that I showed you already and I don't really have to care about it it's a framework to do exactly - then do stuff with the neural network and it gives us everything we need to build a simple network and we have an architect and the architect will build or a network and then we have a trainer and that will train our network with the e training examples that are not included we have to provide them - for our neural network and we can make predictions with our trained network by calling the function activate ok code I will give you a moment to parse it so I have two objects there one is the historic match it has an input array those are market values for the team I just thought that market values are a pretty good approximation of how strong a team is so I just chose that one but feel free to choose anything else you want and so the first is for the home team and the second value is for the relay team and if you always provide the home team first then the numeral network will also learn from that because that is also a pattern that it will pick up if there is something like a home team advantage then maybe our new network will learn that and then we have an output that is a vector or an array where we have basically three classifications so the first value would mean the home team win if it's a one over the zero no the second value says that it is a draw and the third value would be that the away team wins so we actually we do three types of classifications one for each of the possible outcomes and in this example the home team won because there's a one as the first value then we have the match in the future which basically looks exactly the same just except that it doesn't have an output that's logical because we want our annual network to give us the output so then we have our training set that is consistent of the historic matches and we have our network that is trained by the architect perceptron actually means the smallest possible network which is just one neuron input and output but it doesn't really matter it could also say in it it's just the way that we build the network and so we give the perceptron the number of nodes per layer so first is two because we have two input values I chose two hidden layers of six nodes but it doesn't really matter you can just try it out actually that's what I also did I just try out what would seem to work best and then we have three nodes four output layer because we have three values in our output then we trained our trainer the training set and I just chose a learning rate that you can see there there's learning rate the steps that we take in gradient descent and that is also something I just figured out with some trial and error and then there is a number of iterations so you say I want to iterate through my whole training set a hundred thousand times in this case and after we trained or trainer or network we can actually make predictions like I said before we give our network the activations or the input with the function called activate and this is what the output could look like so here you can see the activations the inputs the market values and then the output and as you can see there's no output like 1 0 0 0 0 1 this is a probability distribution so all the values added up in this array will come to one so there's a hundred percent possibility that one of those outcomes will happen and then there's a distribution of how likely it is so for the first one you can see that the team who has 320 1.15 euro Paulie millions of euros will more likely win than the other team ok this is a lot of code and it's also a thinker so take your time everyone got that good okay so now we have our network we have our output it looks pretty good so far but how do we know how well it performs I will explain some error rates that I personally focused on but as when I try to learn how to improve my algorithm but feel free to think come up with your own errors it's just what I did so there's something called the synaptic data error and that is already provided with synaptic and I call it data error because it just did the name is arrow and I call it on the data object and what we do here is we add a schedule to our trainer and we tell them that every ten thousandth iteration I want to log the current data error to the console so this is bad okay and this could be the output and in this case you can see actually that the error actually goes down a little bit over time and over iterations and that is really really good to see and also 18 percent is also pretty good because we only give it our market values and as seems to perform pretty good but the error doesn't really tell us anything it doesn't really translate to anything that you can then interpret so I thought I need to display a different error that was more of an intuitive representation of how well my algorithm actually performed so what I did then is come up with something called the classification error so give you a moment to parse this okay what i'm doing here is in our do function for every 10,000 iteration i want to actually make the prediction because now i only first i only have the probabilities but i don't actually say so the home team's gonna win so this is what i'm doing here the predict from probability function that you can see actually just looks for the key where the value is the biggest in the array so if the home team won this would be 0 if it was a draw would be 1 and the weighting 1 would be 2 and then i just look just make the prediction actually and then do the same thing and then compare whether the prediction actually met the expectation count up my errors and then divided through the length of the training set and what we actually see here is that the error rate is much higher with 45% and this is actually what i had suspected and i will probably tell you later why and also you can see that it doesn't continuously go down it just seems to hover around 44% but i still thought this really wasn't telling me how well my algorithm algorithm performs because i make those predictions with the training set so i already know about the data that i get in and then i make a prediction from it doesn't tell me anything about how well my algorithm performs for future predictions so then i came up with a thing called the cross-validation error and what i do there is actually first split the data set into a training set and then a cross validation set and the reason i do that is because i want the training data to only train my neural network and then I take the cross rotation data I act like it would be the future and then check how well algorithm performs so I'm doing the exact same thing as I did before just I make the predictions on the cross-validation set and not on the training set okay so this is the output and you can see that it seemed to perform even worse a little bit but also this is something that I already suspected would happen and what's weird is that it seems like the error rate goes up for at first and then goes down and then up again just like the arrow we saw before so the question now becomes why what what does this mean what what do these arrow rates tell me actually so the thing is if we have one example where our result would be this probability distribution and then we have the actual result which would be this 0 0 1 so they're waiting 1 what the data error gives us is called the mean squared error and the squared error is this so what this means is the probability distribution would be a vector and we measure the we get the length of the vector and then to the power of 2 which would come up to 0.98 about 0.9 and then the mean means we take all training examples not just the one and then calculate the average squared error so probably the average would be somewhere close to 0.98 let's say it's that now for a classification error we only have one because you can either be a hundred percent wrong or a hundred percent right there's no in between there's no probabilities so in this case our error would be just one and also for a cross-validation error it would be one but still it's it's logical that our would perform worse with data it doesn't know about it's just not in the experienced realm of the algorithm okay so what does it actually mean when my cross-validation error is bigger or greater than my classification error so that could mean that we have over fitted or model or have high variance and I'm trying to explain that let's say this is our training data so this one is X 1 and X 2 we have two features and this is our training data and now our model is the line there so the model describes the training data pretty good but maybe it's not that good for future predictions because it's really it just follows this exact model and it doesn't really generalize very well and that is called overhead over fit or high variance and the other thing the other extreme would be if you have the same training set and this would be a model it's a straight line it's it doesn't fit so well on the existing training data but it might perform better with future predictions than the one on the left and that is called under fit or high bias so what we maybe can do is try to get more data or more features so either get more historical data go to the last year the year before that also get the data from I don't know Premier League or the Super League or whatever or we can do some or we can get more features like the match day or the table position or I don't know that a number of sexy coaches in the team and then there's this other thing called regularization and that is basically another parameter that we add to our cost function ya know to the gradient descent function and what does actually does is trying to keep the Thetas as small or big as possible it depends really on what you value you choose for your regularization parameter if you think about the model I showed you before keeping the theta small would mean to straighten out the line and making a big would mean to curve the line more so this is how you could counteract overfitting or underfitting and also the hovering that we saw before that the error rate seemed to hover around a number but never seem to get anywhere could could mean that we actually already reached our minimum it's just not very optimal so maybe it's just we're not that we didn't describe our feature pretty good pretty well so hmm sorry what I actually did is I chose to go with more features and I want to show you what happened so I this is for the market values you can see the error rates it's kind of basically what we saw before and now I have two five features matched a the market values and then the table positions and now we can try to interpret there seems to be something that is going there was a little bit better other things seem to be a little bit worse but I personally decided that the variation in numbers is just too little to really read anything into it so the only thing that that really told me was that investing time and maybe money in getting more features might not be that beneficial because it just doesn't have that effect on the error rates that I hoped it would be I would have so my next step would just be to try get more data and see what it does to my error rate so another funny quote prediction is very difficult especially about the future and as you saw not even for the future just for the faked future just for the present it's not that easy at all okay so now you hopefully know how neural networks do their magic and how to implement a machine learning algorithm with synaptic and you don't even have to do all the math stuff just go and do stuff then you might have learned how to check the performance of your algorithm and how to interpret your error rates so before I said I would make a prediction for this matchday and I did I already gave this talk yesterday ahjuma so they can actually vouch that I made this prediction and I got the first game right already that's awesome like I said I had the predictions over there and you can check for yourself how well my algorithm actually performs I'm using data from the last four years of the bundesliga so it's really not that good depending on the error rate it's probably worse than a coin toss maybe okay if you want to know more the first link would be to the repository it's called positronic brain every Star Trek watcher should laugh now okay no one fine the second link is to the slides I will also tweet them and then you can just check it out sorry for the slight mess up I don't know what happened there oh sorry and then there's this funny page called coding games where it's actually super fun you can code for fun there and they have a machine learning section now and there's stuff you can read about and there's also the link the second one to synaptic the framework so check it out and highly recommend it and finally I want to thank my master was not here he's actually my boyfriend and he helped me with implementing a lot of data pausing stuff transfer mark we crawl our data from their page and I don't really ask them I just did also I want to thank Jim drew for providing me the time and the resources to actually do that and of course all of you for your interest thanks a lot you 