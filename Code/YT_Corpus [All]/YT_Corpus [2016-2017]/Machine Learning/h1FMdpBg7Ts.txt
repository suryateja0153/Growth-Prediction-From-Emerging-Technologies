 each year Microsoft Research helps hundreds of influential speakers from around the world including leading scientists renowned experts in technology book authors and leading academics and makes videos of these lectures freely available you now the next speaker Chris Bishop is going to talk about machine learning Chris Bishop is a distinguished scientist from Microsoft Research Cambridge lab in UK and he hits the machine learning and perception group over there he is also the vice president of the Royal Institution of Great Britain and professor of computer science at University of Edinburgh his fellow Froy Academy of Engineering a fellow of the Royal Society of Edinburgh and a fellow of Darwin College of Cambridge his research interests include machine learning and it's applications neural networks pattern recognition and natural language processing and their applications request Chris to come and tell you whether talk thank you very much good afternoon everybody excellent so I spent all of my career so far in research and my plan is to spend the rest of my career in research and there's just one simple reason for this if you solve the problem in research then it stops being research so as a researcher you move on to the next problem which means no matter how long you spend in the field of research you're always working on new things it's always fresh being a researcher I think is tremendous fun it's exciting to solve difficult problems it's exciting to see your work have an impact on the lives of millions of people and I consider it to be one of the greatest privileges in life actually to be paid to do something you enjoy doing if you enjoy what you do you have a happy life so that's why for me research is the best career even better than a rock star so in this talk I'm going to tell you a little bit about my research field which is an area called machine learning it's been mentioned several times it's the idea that computers instead of being programmed to solve a problem they can learn how to solve the problem by seeing data they learn from example they learn from experience knife when we first moved into computer science about 20 years ago the field of machine learning was very small it was kind of in a corner of the field but today it's it's mushroom today machine learning is one of the hottest and fastest moving areas of computer science in fact in Microsoft Research quite a significant proportion of our research is either research into machine learning or research which builds on which depends upon machine learning in one way or another and the aspect of machine learning that I want to talk about this afternoon has to do with the problem of dealing with uncertainty and I'm sure you know computers are built not on uncertainty but on logic so the hardware engineers with design computers work very very hard to remove uncertainty they want everything to be true or false zero or one and that's fine if you have a small computer working in isolation but today we connect thousands and millions of computers together and they become a very complex system we have computers that interact with people we're always interacting with computers all day long and people are not 0 or 1 they're complex they are full of uncertainty and the garrity contradiction and especially in the field of machine learning we get computers to learn from vast quantities of data data collected from all kinds of places that data is full of uncertainty it has noise it had errors it has gaps it has contradictions let me just give you one example of what I mean this is X Box this is Microsoft's game console and it's connected to a cloud service called Xbox Live now millions of people use Xbox and Xbox Live to play games against each other you can go on the Xbox and you can play a game against people from all around the planet so Xbox Live has to choose which people to match up to play games against each other now if you wanna have a good game you want to play against somebody who is a similar skill level to you so you don't win too easily you don't lose too easily so a critical thing that Xbox Live has to do is to make an assessment of the skill of each of the players and the problem is we don't really know how skillful somebody is especially if there are a newcomer to Xbox Live so we're uncertain about a player's skill but Xbox Live knows the outcomes of games and of course if somebody wins against somebody else they're probably more skillful not necessarily but they're probably more skillful so as we see the outcome of each game Xbox Live gets relevant information that helps it improve its estimation of the players skills but no matter how many games it sees it can never be completely certain about a player's skill so somehow to solve this problem we need a way of dealing with uncertainty in a principled way something equivalent to the logic of traditional computer science some sort of mathematical framework that allows us to treat uncertainty in a way that is optimal and it's not just on Xbox uncertainty is everywhere in the modern world of computer science if I want to suggest a movie for you to watch I may now know something about the movies that you like and don't like but I can never be certain if you're going to like a particular movie or not in speech recognition we can never be completely sure what a person said if I'm trying to sell you something I have some idea of the things you like but I'm not certain if you're going to buy a particular product these examples are everywhere so the mathematical foundation that we use to deal with uncertainty is something that's actually very familiar to everybody it's the idea of probability you've all come across probability the weather forecaster says there's a 30% chance that it's going to rain tomorrow but if it's Jaipur it's probably not 30% in Cambridge it's probably 90% but it's a number that sort of quantifies the degree of uncertainty so rather than talk about the the mathematics of probability what I thought I'd do is to show you a little demonstration so this is a toy example and it's built with a piece of technology called inferred net that I'll mention a little bit later but in this example the system is going to learn about my preferences for movies now the system has already undergone some machine learning it's been shown hundreds of thousands of ratings of movies made by tens of thousands of people it doesn't know anything about the movies it doesn't know whether they're romantic comedy or action-adventure it doesn't know anything about the people either it's just being told that person fifty three light movie number one didn't like movie number fourteen that's the only information it has so it's analyzed all that data from those thousands of people and now what it's going to do is to learn about my movie preferences so I wasn't one of those people it knows nothing at all about me so I'm going to do is first of all imagine that I've watched a movie let's serve watched this one pretty woman and let's say I like this movie so I'm going to drag this across into the green region and what it's doing is reordering the other movies according to the probability that it thinks I will like that movie so we explain what's going on on the screen here the the vertical position of the movie on the screen doesn't matter we've just sprayed them out so you can see them what matters is the horizontal position so a movie which is down the right hand side is one which the the computer thinks I'm almost certain to like if it's down the left hand side the computer is very confident that I will dislike that movie and if the movie is in the middle it's 50/50 it's really just not sure whether I like that movie or not now look what we have at the moment we have all the movies down the middle we have a little white space down the right-hand side a lot of white space down left hand side so the system at the moment is very unsure it's very uncertain about which movies I like and which movies I don't like and that's not surprising because it's only seen one piece of data I've only rated one movie so far what I need to do now is to give it a little bit more data so let's take another movie and let's say that I don't like this movie okay what we see is the movies are starting to to spread out left and right the movies are moving towards certain see on the right hand side that I like them cerfancy on the left hand side that I won't like them so this if you like is the the modern view of machine learning it's a computer that becomes less uncertain as a result of seeing data in other words it's learned something from that data now the moment it knows very little about me there's one movie I like one movie I don't like let's see what happens if I have another movie that I like another movie that I don't like now what you see is a very different pattern most of the movies are either down the right hand side these are ones it's fairly confident that I'm going to like these are the good ones to recommend to me to watch these are ones it's pretty confident that I won't like and and down the middle there's a lot of white space so the white space is in the middle now it's much less uncertain as a result of seeing data it's not completely certain no movie is exactly at the right or the left so there's always a bit of uncertainty and there are one or two movies in the middle it's really just not sure I'm just briefly going to show you one more thing about this demo because Jeanette mentioned information and information is such a key concept I'm just going to take a moment to show you something neat using this demo to illustrate what we mean by information the field of information was invented by a researcher called Claude Shannon and he defined information as the degree of surprise so let's see why that is let's take a movie down the right-hand side so a movie down the right-hand side is one that the system is very confident that I will like so let's take one of these movies and this suppose I watch the movie and yes indeed I do like this movie so watch what happens I let go of the mouse button watch very carefully to the other movies here we go hope she didn't see that we take another one here's another one that I like watch what happens when I let go did you say that just very very little change that's because the system is confident that I would like the movie so when I told it that I did like the movie there was very little surprise let's take another one that it's confident that I'm gonna like and that's as I watched this movie and actually you know I don't like this movie so I'll drag this over here watch carefully what happens now when I let go of the mouse button there we go okay a very big change it was confident I would like the movie but I didn't like the movie so there's a huge degree of surprise in other words there's a lot of information now in each case I'm just giving it one bit of data I either like the movie or I don't so the amount of data is the same in each case the amount of information is very different on the right hand side the amount of information is zero and it actually goes to infinity logarithmic Li as you go across to the right hand side so that's the difference between data and information okay so that's a very simple demonstration of the idea of probabilities and the idea of learning from data now this was just a toy demonstration that was written for the purposes of giving talks but actually the exact same technology the same software which powers this demonstration is in use on Xbox for the purposes of making recommendations so recommendations of which games you should buy and which movies you should watch and so on and made using this exact same technology so we call it collaborative filtering it's mahiette patterns of likes and dislikes from other people and using that to to make predictions about things that you alike and so this is making teams of millions of predictions for Xbox Live users every day so I want to talk a little bit more then about this this mushrooming field of machine learning it's been around for many decades many people have worked in the field and so over the years many different techniques so many different algorithms have been developed are though all sorts of fancy names and you can see lots of them here so it's quite a big in complex field the thing that I'm interested in is in a sense of new approach to machine learning or at least a new way of viewing many of those traditional algorithms I call it probabilistic modeling so the goal of probabilistic modeling is actually very ambitious imagine the following imagine we just had a single environment within which we could create a bespoke solution a special solution for each and every new application that we need to build and imagine that could be done with very little effort and the result was a very efficient and effective algorithm so in the past to solve a problem with machine learning we've taken or data you've taken our problem and we've looked to all of those algorithms that people have invented and we've tried to find one that looks like a good fit for our problem and we've used that to solve our or application and many times that works and there are many many successful applications of machine learning thousands of them already in Microsoft products in virtually every Microsoft product in fact what we're trying to do is something a little bit different we're trying to do here is what we call a model-based approach in other words you start from the problem and you design a specific solution that specific solution might happen to be one of the methods that you saw on the previous viewgraph or it might be slightly different but it's tuned to the specific problem that you're trying to solve and I should say that this is really an aspiration this is very much at the research frontier and we don't yet have all the answers in place to be able to do this but we have made some very interesting progress as you'll see so the way we're approaching achieving that vision is using three key ideas so the first one you've seen already the idea that we're going to use probability as a way of measuring uncertainty and you saw that in the movie recommended mo the second idea is a rather nice one it appeals to me a lot it's the idea of using pictures instead of doing mathematics it's not exactly instead of doing mathematics it's really to help us deal with very complex mathematics so instead of doing the mathematics by hand we draw these pictures these graphs and these graphs help us to visualize the model that we're constructing the solution that we're creating to some new application and then the third thing we need we need this to be very efficient we want to apply this a large data set millions or billions of data points we need it to be very efficient and we need clever and efficient algorithms that can actually do the machine learning we call this an inference problem and so having those algorithms as efficient algorithms is essential if we're to achieve this vision so to see how this works I want to go back to the example I started with the problem of Xbox at Xbox Live and how is Xbox Live going to estimate the skills of the people playing on that certified service so the problem of estimating the skills of people playing games against each other of course is a very old one it's been around for a very long time and if you consider a game like chess in a game like chess one person plays against another person and we want to use the outcome of all of those pairs of games to work out the skills of everybody involved in the chess tournament this problem was actually addressed by a physicist named elo and he came up with a a proposed solution to this problem and Ehlo is very popular emo is used worldwide in the game of chess anybody who plays chess has an e low chess rating and it's used in many other games as well now e low seems to work but there are various problems one of the problems is that it's fine for two people but if we have a game involving many people then Ehlo simply doesn't apply and obviously that's no good for xbox because on xbox we might have four players eight players playing in the same game another limitation of Evo is that it doesn't address the problem of team games eventually we have four people in a team over here playing against four people in a team over here let's say this team is the winner we think that this team is therefore more skillful than this team but how do I change my estimates of the skills of the individual players it's called a credit assignment problem how do I know which members of that team really contributed to the victory again elo doesn't address this so at Microsoft Research we've developed a probabilistic machine learning solution to this problem which is called true skill tree skill overcomes those limitations of elo but it does something else which is even more dramatic and I'll show you that in a moment so how does this work how are we going to solve the problem of estimating skills in these online computer games well we're going to draw a little picture of our solution but he is one of these graphs so the first thing we need is to imagine our situation let's start with the simplest case of two players playing against each other we'll call them player one and player two and we'll start with a variable I've called an S one it's the skill of player one will represent that by that little piece of graph now that represents what we call a probability distribution it's a probability that expresses our uncertainty in the person's skill now skill of course is a continuous skill is a continuous quantity you can be a little bit skillful very skillful extremely skillful and so this is really this is the probability of different values of skill and this little shape we call this a Gaussian distribution people in my field are very fond of these we use these over the place it's a little bell-shaped curve which says the most probable value of skill is in the middle here but it could be a bit higher it could be a bit lower but it's unlikely to be very high or very low it represents uncertainty rather like the uncertainty and whether I'm going to like a movie or not so that's the skill of player one I would that's the thing I want to know and I don't know it has some uncertainty we do the same thing for our second player here's the Gaussian distribution for all for the skill of the second player you'll notice that this in this case the the distribution is narrower there's less uncertainty in the person's skill this perhaps is somebody who's played a lot more games we've seen a lot more data and therefore the true skill system is less uncertain about their skill the next problem we have to face is the following if two people play a game against each other the more skillful one is more likely to be the winner but sometimes the less skillful person can beat the more skillful person it's a noisy problem and so we model that effect by bringing in another quantity pi PI 1 we call this the performance of person 1 on this particular game and that if you like is rather like they're still value but with a bit of extra uncertainty added reflecting the fact that sometimes a person plays a bit better than their average skill and sometimes a little bit worse we do the same thing for player 2 and then finally we simply say the winner is the person with the higher performance value so most of the time it'll be the person with the higher skill sometimes it'll be the person with the lower skill and then finally another little piece of pictorial notation when we actually measure a quantity we shade in the node on the graph so this quantity is the game outcome it might be 1 if player 1 is the winner and 0 if player 2 is the winner so the thing we measure is the outcome of the game the thing we want to know are the skill values we want to use the data to improve those estimates of skills to modify the uncertainty just like we did with the movie example and it turns out that there's a very elegant solution to this problem remember I said we need an algorithm that's going to be very efficient that's going to scale to millions of variables well it turns out that the algorithms which are efficient are ones which can be expressed very simply as passing little messages around on the graph so the actual computation that we do is equivalent to the nodes the circles on this graph sending little messages to each other so these little messages are a sent around the graph in a way that's very efficient and when we finish sending these messages we can now compute the revised skill distributions so if you look at the player to look what happens when we update their skill distribution you'll see in this case player 2 is the winner so this distribution shifts to the right the system is increasing the the average value of the estimate of their skill the other thing that happens is it becomes narrower there's a little bit less uncertainty because the system has seen some more data just like with the movie recommender when I recommend a movie the movies move towards left and right there is less uncertainty in this case the distribution gets narrower meaning there's less variability there's less uncertainty so player 2 was the winner so player 1 must have been the loser so let's see what happens to player 1 well that distribution shifts down a little bit because they were the loser and so the average of their their skill estimate is reduced a little bit also that distribution again gets a little bit narrower the system has seen some more data it's learned from the data it's become less uncertain and so the spread in that distribution is a little bit less so let's look at some actual results and you know one of the things we do in research it's not enough just to come up with an idea and then get it working we often do comparisons we want to know is this technique better or worse than some other technique perhaps is better in some respect perhaps not so good in other respects well the obvious comparison to make here is between the true skill algorithm the true skill probabilistic model that I've just described and that Ehlo system the system that's used in chess and in many other games so this is some data taken from an x-box game called halo and this data actually involves thousands of players but what we're going to do is just plot the results for just two of these players so these are their sort of user aliases and on the axis here this is the number of games they've played so notice this is 100 games 200 games 300 games and so on and this is the estimate of the skill values of those two players and in this case everybody starts off with a skill of zero so under ello you see what happens every time a game is played there's a little formula in ello which updates the skill value so the skill values are increasing and you can sort of see they're starting to curl over and eventually they'll flatten off if we take exactly the same data and we process it using the true skill system what we see is this we see dramatically better convergence the convergence is something we've seen a factor of ten and a factor of a hundred faster I'm not talking about compute time although the compute sign is actually it's maybe half the speed of e low it's certainly very fast what I'm talking about here is how many games do you have to see in order to have a good estimate of the of the skill value so you see after about a hundred games Ehlo is still changing its mind increasing the skill value in tiny steps true skill is getting a very fast estimate just after a handful of games this is really important on xbox live because we need our users to be playing against people of a similar skill strength so that they have a really good gaming experience if you have to play hundreds of games before you start to be matched against the right sort of people you could get fed up and give up playing on xbox and that would be a very bad thing so instead we can get a good estimate of your skill value just after a few games I think I have just enough time just to try and explain why this is why is it that by using uncertainty we get a dramatic improvement compared to the elo system which doesn't take a hand of uncertainty so we try and give you some intuition for this let's suppose that you and I are going to play a game of chess let's consider ello first of all in ello I might have a skill rating of let's say a hundred and twenty you might be a hundred so either thinks I'm the stronger player now let's suppose we play a game of chess well let's suppose that you're the winner sometimes happens that the lower rated player is the winner well in ello there's a little formula that takes my hundred and twenty and reduces a little bit takes your hundred it increases a little bit and that's all you lo can do because it doesn't have any more information to go on now imagine that we analyze the same situation using true skill which takes a count of uncertainty so let's say that my skill is a hundred and twenty plus or minus one what that means is the average is the same as in the elo case but now the system has some uncertainty but in this case the uncertainty is very small perhaps I've played lots and lots and lots of games the system has lots of data about me it has very little uncertainty in my still value so in 120 plus or minus one now imagine that you're a beginner you've only played a few games so your skill value under true skill is a hundred plus or minus thirty the same mean value 100 but if much bigger spread much more uncertainty what is true skill do well true skill makes only a very small change to my skill level it goes down a tiny bit and it gets a tiny bit narrower still but you've just beaten me and intuitively if my skill value is a hundred and thirty sorry 120 plus or minus one and you've just beaten me your skill value must be 119 or thereabouts so true skill will automatically make a very big correction to your skill value move it up to something more like 119 in a single step and it can do that just using one at one game outcome because it has a measure of uncertainty so the data is the same but in in if we have the uncertainty we can extract much more information from that data and therefore the system can make much bigger changes and the other key point to notice here this is tremendously important it's why I use the word principles when I talked about using probabilities to quantify uncertainty you could imagine hacking something together you can imagine saying well if I'm a hundred and twenty plus or minus one will make yours 119 you could imagine sort of coding up your intuition like that if you do that kind of thing it might work and it might not work but you're sort of let's see without a compass and if it doesn't work you don't know how to fix it so we don't all instead we use the rules of probability to express everything as a probabilistic model and when we run the rules of probability we run these inference algorithms these message-passing algorithms they do the right thing automatically so if it's appropriate that your skill value increased by a big amount that's what will happen and if that shouldn't happen then it won't the algorithm just does the right thing that's the advantage of having a mathematical foundation for when you're creating algorithms and solving problems so the last topic I want to talk about is really at the cutting edge of research it's a field called probabilistic programming and it's something which really has only been around for the last couple of years but it's been growing in popularity and it's a way of achieving that vision that I painted that vision of being able to create a solution to any machine learning problem very quickly and be able to create a solution that's precisely tuned to that particular application so you call this probabilistic programming so what is this well let's think about how we would go about and coding up true skill if I sent you off to code up true skill what would you do well you might do something like the following you might take a programming language let's say C sharp or some other programming language and you would write out the the whole true skill algorithm all those inferences all this message-passing algorithms you code them all up in c-sharp it would take you well first of all you'd have to derive all the equations by hand on a sheet of paper that would take you in a week or two and you might make some mistakes then you'd have to code them all up that would be thousands of lines of code would take you some more weeks and you'd make some more mistakes but eventually you would end up with your code you run it through a compiler to produce machine code that combines with the data of the game outcomes in the case of true skill and the output will be probability distributions distributions over the skills of the different players but a measure we could do the following I've just explained to you roughly the trueskill algorithm by drawing a little picture okay I was able to explain it to you in a very simple way by just by just drawing a little diagram imagine if we could explain that to the computer if we could take a picture or more likely a very short piece of code which doesn't talk about inference and message passing it simply talks about player 1 and player 2 and the Gaussian uncertainty in their skills and their performances and who was the winner very very simple piece of code you call that a probabilistic program so the idea is to have a very compact description of the model and then choose a very clever piece of software called a probabilistic programming compiler which will take that model and automatically generate the thousands of lines of c-sharp code or whatever it may be that represents a coding up of trueskill so that's the vision we have by no means achieve this vision this is very much at the research frontier I was listening to an excellent talk earlier this week by one of the researchers in MSR India who has made some very exciting advances towards achieving this vision but we are by no means there it may take a number of years before we really achieve this and perhaps by then well we can recruit the help of some of you to tackle some of these very difficult but very exciting problems we have various technologies are mentioned one of them in Fernet in MSR there are other tools as well that are trying to achieve this goal of probabilistic programming we've made some very exciting steps forward we're certainly not all the way there yet so let me illustrate probabilistic programming by going back to our example of true skill this is the graph that you saw earlier which represents two people playing a game against each other how would we represent this as a probabilistic program well this is what it looks like in Infonet so it's extremely compact we've got some some declarations at the top and then essentially each line of code represents one piece of this graph so this line of code says that this skill of player one is a Gaussian that's this piece of graph this line says the performance of player one is a Gaussian another Gaussian at the center of that Gaussian is equal to the skill of player one so that just says that there's another variable it is connected by a line in the graph to the first variable and so on so you can take that graph and we can translate it into a few lines of code so that's very exciting but what's really exciting about probabilistic programming is that when you want to change something you can do it very quickly you know in machine learning we would like to be so clever that we could just solve the problem directly and that very rarely happens what usually happens is we have to try out lots and lots of different things and compare them we do that all the time and machine learning so it would be great if we had very quickly construct lots of different solutions so we could compare them quickly and so you could take a good solution and tweak it to make it a little bit better so let's see how that might work so let's look at one of the problems I mentioned that ello doesn't address remember ello only works for two players what if each of us want to get together and have a game on xbox well it's actually very easy we draw the graph this is the case of three players playing a game against each other here are the three players here their performances how well they did on this particular game and these are game outcomes perhaps player to be player 1 player 3 beat player 2 what is the probabilistic program look like well it's very similar to the previous program they it's the lines highlighted in yellow though those are the pieces of code that are different from the first case so those are the changes that we have to make to implement this case here's another problem that elo doesn't address teams what happens if we have teams so here's a simple example there are two teams the first team involves two players players 1 and 2 and the second team as it happens also involves two players players 3 and 4 the performance of team 1 depends upon the skills of the two players so in the simplest case it would just be the skill of player 1 plus the skill of player 2 if it's a race in its first to pass the finishing line it would be the max of the skill of player 1 and the skill of player 2 and so on and then the two teams play the game and this is the game outcome maybe team two is the winner by sending messages around the graph we can update the individual skills of these players not just this not just the skills of the team as a whole and again that can be expressed as a probabilistic program so again the lines highlighted in yellow are those items which are different from the simple two player case in a very simple change very simple to change the code and then recompile the actual inference code itself is is very different it's much more complex in this case the probe list ik program is very simple and then finally everything I've said so far assumes that the skills of the players are fixed so in those distributions moved the skill of the play was fixed what was changing was the uncertainty that the computer had all the trees still has about the value of that skill that's too simplistic if you've if you new to xbox you start playing a game you won't be very good to start with probably because you haven't got much experience as you play games true skill is estimating your steal value with a greater and greater precision but your fuel value is changing because you're probably getting better because you're gaining experience or perhaps you don't play for a few months and your skill goes down again how can we model that well again here's the graph this is two people playing a game against each other and this is the game outcome a little bit later the same two people get together and they play another game previously we would have assumed that the skill of player 1 on the new game was the same as the skill of player 1 on the old game this time we introduced another of these gasps Ian's we just introduced a little bit of uncertainty it's all we need to do allow for the possibility that the skill of the player itself might evolve through time and again this is the change to the code that we need in order to implement that now of course there are some extra lines of code to read in the data and write out the answer and so on that's very straightforward but the code I'm showing you is real code that actually compiles and this is the actual code that you would use in infant net to implement these models and finally what I've been describing this true skill is not just an idea it's actually a system it's been used on xbox live now for for many years it is the only supportive system on Xbox Live for estimating the skills of players Xbox Live currently has 48 million users and continues to grow and everyday trueskill processes the outcome of millions of game outcomes millions of games results from millions of players so this is a real system that's in actual use and I think it's just a very nice example of going all the way from beautiful mathematics to efficient algorithms to real-world impact on millions of people and with that let me say thank you very much you 