 last episode we trained an image classifier using tensorflow for poets and this time we'll write one using TF learn the problem will start on today is classifying handwritten digits from the emne Stata set and writing a simple classifier for these is often considered the hello world of computer vision now M NIST is a multi-class classification problem given an image of a digit our job will be to predict which one it is I wrote an I Python notebook for this episode and you can find a link to it in the description and to make it easier for you to configure your environment I'll start with a quick screencast of installing tensorflow using docker first here's an outline of what we'll cover I'll show you how to download the data set and visualize images next we'll train a classifier evaluate it and use it to make predictions on new images then we'll visualize the weights the classifier learns to gain intuition for how it works under the hood let's start by installing tensorflow you can find installation instructions for docker linked from the getting started page on tensorflow org and I'll start this screencast assuming you've just finished downloading and installing docker itself but haven't started installing tensorflow starting from a fresh install of docker the first thing to do is open the docker QuickStart terminal and when this appears you'll see an IP address just below the wale copy it down we'll need it later next we'll launch a docker container with a tensor flow image the image is hosted on docker hub and there's a link to that in the description the image contains tensorflow with all its dependencies properly configured and here's the command we'll use to download and launch the image but first let's choose the version we want the versions are on this page and we'll use the latest release now we can copy paste the command into a terminal and add a colon with the version number if this is the first time you've run the image it will be downloaded automatically and on subsequent runs you'll be cached locally the image starts automatically and by default it runs a notebook server all that's left for us to do is to open up a browser and point it to the IP we jotted down earlier on port 8888 and now we have an eye Python notebook that we can experiment with in our browser served by the container you can find the notebook for this episode in just corruption and upload it through the UI okay now on to code here the imports will use I'll use matplotlib to display images and of course we'll use TF learn to train the classifier all of these are installed with the image next we'll download the M Ness data set and we have a nice one-liner for that the data set contains thousands of labelled images of handwritten digits it's pre divided into train which is fifty five thousand and test which is ten thousand let's visualize a few of these to get a feel this code displays an image along with its label and you might notice I'm reshaping the image and I'll explain why in a bit the first image from the testing set is a7 and you can see the example index as well as the label here's the second image now both of these are clearly drawn but there's a variety of different handwriting samples in this data set here's an image that's harder to recognize these images are low resolution just 28 by 28 pixels and greyscale also note there properly segmented that means each image contains exactly one digit now let's talk about the features we'll use when we're working with images we use the raw pixels as features that's because extracting useful features from images like textures and shapes is hard now a 28 by 28 image has 784 pixels so we have 784 features and here we're using the flattened representation of the image to flatten image means to convert it from a 2d array to a 1d array by unstacking the rows and lining them up that's why we had to reshape this array to display it earlier now we can initialize the classifier and here we'll use a linear classifier will provide two parameters the first indicates how many classes we have and there are ten one for each type of digit the second informs the classifier about the features we'll use now I'll draw a quick diagram of a linear classifier to give you a high-level preview of how it works under the hood you can think of the classifier as adding up the evidence that the image is each type of digit the input nodes are on the top represented by X's and the output nodes are on the bottom represented by Y's we have one input node for each feature or pixel in the image and one output node for each digit the image could represent here we have seven eighty-four inputs and ten outputs I've just drawn a few of them so everything fits on the screen now the inputs and outputs are fully connected and each of these edges has a weight when we classify an image you can think of each pixel is going on a journey first it flows into its input node and next it travels along the edges along the way it's multiplied by the weight on the edge and the output nodes gather evidence that the image were classifying represents each type of digit the more evidence we gather say on the eight output the more likely it is the image is an eight and to calculate how much evidence we have we sum the value of the pixel intensities multiplied by the weights then we can predict that the image belongs to the output node with the most evidence the important part is the weights and by setting them properly we can get accurate classifications we begin with random weights then gradually adjust them towards better values and this happens inside the fit method once we have a trained model we can evaluate it using the evaluate method we see that it correctly classifies about ninety percent of the test set we can also make predictions on individual images here's one that it correctly classifies and here's one that it gets wrong now I want to show you how to visualize the weights the classifier learns here positive weights are drawn in red and negative weights are drawn in blue so what he's weights tell us well to understand that I'll show four images of ones they're all drawn slightly differently but take a look at the middle pixel notice that it's filled in on every image when that pixel is filled in it's evidence that the image we're looking at is a one so we'd expect a high weight on that edge now let's take a look at four zeroes notice that the middle pixel is empty although there's lots of ways to draw zeros if that middle pixel is filled in it's evidence against the image being a zero so we'd expect a negative weight on the edge and looking at the images of the weights we can almost see outlines of the digits drawn in red for each class we were able to visualize these because we started with 784 pixels and we learned 10 weights for each one for each type of digit we then reshape the weights into a 2d array okay that's it for now of course there's lots more to learn about this and I put my favorite links in the coming up next time we'll experiment with deep learning and I'll cover in more detail what we introduced here today thanks very much for watching and I'll see you then 