 machine learn it be well I was just saying that personally I've always been very interested in how machine learning crosses over into the real the physical the tangible world and so I'm very happy this month we've got two speakers who've taken time out of our busy schedule to talk about machine learning and how that crosses over into robotics so Matthews from King's College London and gonna talk about machine learning in software products and also I just worth mentioning Matthew also organises a bit robotics lecture series at King's College I'm not quite sure how you get on the mailing list I know I am I forgot how I got onto it but it's really interesting so people interested in kind of robotics research and what's going on it's definitely worth joining ok anyway thank you very much and over to Matthew thank you very much thanks very much also for the advert yes we have robotics lectures pretty much every week at King's College go to my home page there's a link through you can get onto the mailing list we have a calendar and you can see what's what's going on so please do come along it's open to all it's free it's in the middle of the day so maybe some people find that tricky but well there you go so imitation learning for soft robotics I'm not Michael Howard's and I don't have strong opinions about the EU so yeah so I am pretty much a roboticist I'm leaving the king's robot learning lab and we sort of have a foot in both machine learning and robotics I probably say I have a bit more weight in the robotics side these are a few kind of keywords of what we're interested in but this diagram really summarizes it we're interested in how can we get human dexterous compliant robust behavior from the muscles from the joints into advanced robotics systems so so that's our main main thing we are among many people in the robotics community who are interested in how we can get robots that imitate nature and at the moment there's a big trend towards soft robotics so soft robotics are essentially robots that have softness built physically into the device in the same way that you do so there's a guy a friend of mine in Germany he always demonstrates what is a soft robot well a soft robot it's something you can do that with right and you don't break your hand if you if you do that with a traditional manipulator something like you see in a car factory you would either break the table most likely if there's a car robot or you break the robot itself okay but we have tendons we have muscles we are soft with stretchy okay and that's what makes us robust okay so a lot of people in the community are interested in building robots that have that same kind of design having muscle like actuators these are pneumatic muscles here this is the DLR hand arm system that has something like fifty six motors within this small part here that are controlling the compliance of the hand you can hit that thing with a baseball back in it bat and it won't break okay but it's extremely difficult to control so let me just give you an idea of what this looks like in practice so what we're doing here is we're taking EMG signals this is measuring them the the nerve innervation of the of the muscles I don't know how much of a biological background people in this room have but essentially it's measuring the the muscle activity okay and we're feeding these into we have sense for an outside we're feeding these into this biomorphic robot okay this robot has a little two little motors two little motors here attached to Springs and the nice thing about that is you can control independently the position and the and the stiffness let me replay so you can independently change your your joint talk or your position and you can Co contract the two muscles and that makes you stiffer okay and there's a lot of interesting issues about how humans control their muscles that we're trying to learn from yeah so a lot of people are interested in this area one of the reasons is we're hoping to reproduce the human level of agility human levels of performance and another thing is that we're interested in safety so at the moment a lot of people are interested in having robots and humans work together on tasks so similar to what you saw in my talking about when you've got a self-driving car you know you're driving the robots learning from you we're doing the same kind of thing but with manipulators with arms and legs and hands and fingers and so on okay so when we've got these questions you know about improving agility the question is what are the control principles what can we learn from from how humans are controlling their muscles in order to make our robots do the same kind of thing and the other thing is this programming by demonstration issue now when I talk about programming by demonstration this is more or less what is current so here you can see we're just doing simple basically through you press the button the robots in teaching mode you show it the movements like that and then you press the button again and then it manages to reproduce that same movement so that's a fun little toy we we're kind of interested in tomato picking at the moment for reasons I won't go into it's a little bit slow look there you go right so you chew at that one movement and then it can do that 100 times you know 10,000 times it doesn't get bored so this kind of thing people are very interested in in industry but the thing is it's it's not that smart so that's literally just recording and playback so we want to go beyond a little bit and understand for example not just how do you do that thing in terms of just what are the positions but what are the forces that we need to apply so that we don't squash the tomato or what happens if I bash it halfway through the movement am I going to get knocked out of the way is it going to knock me out the way I don't know so really what we've come across is this is what we're calling this winning combination which is a combination of compliance physical compliance in the robot so having soft actuators which are designed to have Springs and and tendon light properties and optimal control okay so this is a optimal feedback control formulation again so you can just write down system dynamics is it's just a function we have some control function and then we come out with some optimal solution which is crucially a combination of feed-forward and feedback control and there's recently been a few nice algorithms out versus I like you our PI squared visions called optimal feedback control algorithms they're a little bit like reinforcement learning and they give you this this solution out of the box of three and it's interesting because firstly it allows you to reproduce something about human behavior which is this effort accuracy trade-off now let me explain what that is so let's imagine that you're reaching to a target okay and let's imagine you're reaching for example to a broom or something like that so it doesn't actually matter where on the broom you're reaching to but it does matter whether you're you know at the broom or not okay so you have redundancy in your target so you can see so essentially you change your stiffness such that you are particularly accurate in the direction towards the towards the broom and you don't care if you get knocked off when you're going parallel parallel to the broom and this has been proposed as a theory of motor coordination and it actually falls out of the optimal control principles that you saw from from the previous slide so imagine this is probably familiar to any control theorists here imagine you have a simple linear system where you have a quadratic cost and you can so the cost functions up at the top there and you can write down analytically the solution for this which is this feedback controller here so the controls that you apply dependant on your your current estimate of your state and this epsilon factor and so this epsilon factor here as I go zip towards zero that's the factor that's weighting the accuracy cost then that that dimension in that dimension note you no longer create Corrections that means you have no stiffness in that direction so so you can see that that falls directly out of out of the equations of these optimal feedback control system but the interesting thing is so I'll skip this plane the interesting thing is that that appears when we when we test it with people so for example here we have a case where a person is reaching to this this target and he's holding on to this manipulator this robot manipulator and that's applying force fields to him okay and as he tries to reach so in the sort of ordinary case you try to reach in a straight line you end up you know doing these fairly straight line movements but then when you apply a divergent force field that means when you go off slightly you'll get a big force one direction or the other direction well to start off with you end up just going all over the place but you chained yourself up so after a few trials of doing this reaching movement you start to return to doing these nice straight line movements and what it shows is that you're you're stiffening up selectively in these directions that prevent these perturbations basically so we can see that that humans selectively change their their stiffness according to the particular task context and this falls out also with with the optimal feedback control system so if we so this is for example some trajectories of reaching to a target where we've we've done the optimal control you can see the joint angles over time on this side but here we have this antagonistic muscle set up and you can see towards the end it co contracts the two muscles so it increases the activation of the two muscles stiffening up and that causes it to be robust against graduation as towards the target end so that's kind of interesting that this this kind of setup allows us to reproduce human behavior on this quite fundamental level it's also interesting from the perspective of an engineering perspective is that because we have elasticity built into our joints we can exploit less to to make quite powerful movements so let me see if I've got a video to show you what I mean by this so here we have again a robot with physical elasticity compliant joints with Springs and embedded into it and we've set it up to do this both for any task so this this pumping motion falls exactly out of this optimal feedback control formulation none of this is pre-programmed what we give it is a target of how throw the ball as far as you can and this is what comes up now the interesting thing is here is the strategy of what it's doing so I don't know if we can get a close-up it has one motor at the top there one motor at the bottom one of them is controlling their talk and the other one is pre-tensioning that spring so this spring here and it's basically pumping energy into that spring during the movement so that eventually it can throw the ball okay so this is kind of nice because this allows us to manage energy efficiently and also it allows us to achieve high power throws with with quite small motors there you go there's the as the close-up so you can see this is this is one motor that controls this pre-tensioning this is adjusting the stiffness of the joint and this is the other motor controlling the joint torque so this is this is just some evidence about how that how that works but this is the plot that's quite interesting so you can see here with plotting power over time and this is the zero line okay so you can see that the energy that is being supplied to this to this robot is zero zero zero positive positive and then suddenly it becomes negative okay so that's kind of weird right so why is that that's because the energy is going into the springs for that period of time and then it's coming back out again once it goes back into the positive to me and so it's building up that energy in and out before it makes that explosive throw okay so enough about enough about that what we're really so what I really want to talk to about today was this imitation learning programming by demonstration paradigm so this is the standard setup for programming by demonstration is that you have some set of data which controls which contains states and actions for example trajectories and what we want to do is we want to find some kind of policy mapping that tells us well given some state of the world what are the controls that we ought to a apply at that time okay but the problem is that if we have compliance then we have a very complex problem we have very complex nonlinear redundant actuation you saw the two muscle robot that's quite complex dynamics and it's extremely sensitive to mismatches in embodiment so so so this is just one way of designing your robotic system and you think well in one case it's kind of easy right so transferring the human behavior onto the robot we already saw that right so we if we design our robot so this is biomorphic that it has muscle like actuation then you can exploit that fact to directly imitate at the muscle level what what the person is doing we already saw that but the problem is that we we generally we don't want to design our robots to be like that so the biomorphic one is is nice but it's a bit complicated to build into a multi degree of freedom system so you couldn't build a humanoid that way very easily and so people are looking for solutions about how you can include this compliance into these more compact designs so for example this is called them the keppa robots it uses just a single spring for adjusting stiffness this is the same robot that we saw throwing the tennis balls okay and that's nice because it's compact and it's easy to design into a robot but it's not so nice because it's not clear from the human behavior how can we get that robot to move this is just illustrating that a little bit so these colored plots here are actually equilibrium position and stiffness plots against the motor commands of these of these different robots so you can see for example here as you cope contract the two muscles you go along this diagonal line and the stiffness increases in the antagonistic one but when you go to the case of the McAra you have this very complex nonlinear setup for stiffness so the question is how do we go from from the human to all these different types of robot so I would say that in general so there's not really a lot of theoretical work in this area it's still quite open but I would say that there's probably three main classes of approaches that you can that you can take so firstly we have the direct what we can call direct polity transfer so we have a direct correspondence between the robots action space and the human's action space and you just make that direct transfer but the next thing that we can do is maybe go to a higher level and look at interesting features of the behavior so we can take the features of the human behavior such as the stiffness profile the damping profile and we can define equivalent features on the robotic system such as well for example in this case we can adjust stiffness as well so we can track the stiffness profile too and we can see how that that pans out for us so this is what we can call feature based sorry I can hear the video playing but I can't see it okay so now we have again we've got the setup where we're measuring the EMG from from the forearm they're from the antagonistic muscles and in this case we're defining the stiffness is the extent of Co contraction of the hand and the asymmetry as the the equilibrium position and we're feeding these back to the robot as references have feature references basically so you can see we can do exactly as what we did with the biomorphic device we can Co contract we can increase the stiffness of the of the robot we can move left and right but now we can do it all with a much more compact system so this is what we call feature based transport I won't go into the technical details about how it works but essentially you you need a model of your stiffness and your equilibrium position and then you can go into the velocity domain of those functions and compute control velocities that allow you to track those those things so that's feature based and that's okay in in some sense if you've got those meaningful features but maybe we can go one step beyond beyond so the third approach is what we can call let's say the inverse optimal approach or the apprenticeship learning approach so I don't know how many people here have worked with apprenticeship learning but what we're interested in here is that well how can we take a representation of the human behavior that captures somehow the goals or the objectives of what the person is trying to do okay so the the setup is we take again recordings of the expert behavior we feed them into an apprenticeship learner and from that we learn the cost function or the reward function if you're a reinforcement learning person and then we take that cost function and we pass that over to the robot and then we allow the robot to optimize that with respect to its own dynamics okay so what that means is potentially the robot could outperform the person because if the robots dynamics are more suitable to the particular task then it's and it will optimize it well it will potentially outperform so that's kind of interesting and yeah gaming just lots of so the technical stuff there but let me give you a kind of a sort of intuitive example of this so imagine you're trying to learn this punching task okay so let's say we've got you know examples of a human doing some sort of punching and you want to apply it to some robotic system that has stiffness and equilibrium position control again okay so the one way to do this is that we can define some cost phone cost model so let's say we we care about target accuracy when we're punching we care about the sort of impact velocity we can care about the energy or the efforts used during the punch and we can basically yeah so those are the three main terms use these as features of our cost function and we can learn the trade-off between them okay and we can do this taking account of what the experts dynamics are and apply them to this this other system so let me just highlight the fact that in the in the human muscle system you have stiffness and damping coupled so the joint talks that you have is a combination of the of the stiffness and the damping whereas in a robotic system that's not necessarily true so we have control of the stiffness in the joint talks but we have a dumping and so if you apply this approach where you do the inverse of or control the apprenticeship learning type thing and we compare that against directly imitating on the feature level so copying the stiffness as we did you know just before the video you get quite different results so in this case we've plotted out red as the experts movement position and velocity and joint talks and in green what happens when you directly imitate the stiffness and the joint talk but we you know we know that there's some difference in the dynamics there because one of them has damping couples to the stiffness and the other one doesn't and what happens when we apply apprenticeship learning okay and you get this very high oscillations in the case where you're just imitating stiffness so I think the take-home story of this is that it's extremely sensitive to the mismatch in the dynamics if you if you want to just do ordinary direct feature-based transfer behavior okay where is that's not a problem that we we experienced with the apprenticeship learning so it's is kind of interesting in that in that way okay so just to say that we don't necessarily need a model of the human dynamics to be able to do this you can totally throw all that away and use a cloud of data so we can use it model free reinforcement learning in place of let's say the optimal feedback control approaches and still get pretty much the same result so careful consideration of correspondence is the key okay so so those are some things that are kind of happening at the moment in terms of the programming by demonstration and especially what's happening in terms of the software products I just want to talk a little bit about what's occurring sort of coming up what's next in that area so one thing is that I've talked a lot about stiffness controllable robots but you can also so there's also at the moment and move towards including damping into this so this is versus I device that we've developed which is a compliant in the Kappa robot but it includes something a bit like a restorative break at the joints okay and so you can see that we can achieve different levels of damping there just through this ping test right so the number of oscillations will tell you how much damping is so that that's a totally passive device and all it all that we have to do is we both take a simple motor short the two terminal leads together and then you get get this damping effect and if we change the resistance across that we can change the level of damping okay so we can actually suck energy out of the movement if we need to move rapidly to position the interesting thing also is that you don't necessarily need to use damping to be able to do this rapid movement so so we can actually rapidly move to our target whether or not we have damping variable damping capability but the difference is that with the damping we can instantaneously apply it so we actually so in simulation you don't need the difference but in in reality because the servos are slower they're not as effective as moving moving to break you basically so dumping is instantaneous so that's one one thing another thing that we're quite interested in is the sensing side of this okay so I've talked a lot about actuation and controllers we're interested in whether variable stiffness is is important for sensing so one area that we are currently trying to investigate is whether we could use something like a little robotic finger for detecting cancer okay so this here is picks kidney wrapped up in wrapped up in some cling film but inside there we've embedded a little rubber ball and we're basically running the finger over and trying to find where is the ball and this is what surgeons do every day they palpate parts of your body and they try to locate the ball but the interesting thing is that when you look at how surgeons do it they adjust the muscles on their forearm during the palpation tasks in very specific ways to try to know locate the the nodule more quickly and essentially as we've as we've learned so that involves you know that's actually essentially changing the stiffness of that of that joint and what we can see is that likewise with a robotic system we can find a specific stiffness level where where we get this response when we run over run over the nodule so there's something to do with the excitation and the information that you get in mouse through that spring that allows you to be more effective and more sensitive for these for these kinds of tasks okay so the other area that is kind of coming up and which is which is kind of interesting in the moment is wearable technology one of the things that we've been working on in the lab is actually how can we embroider these into clothing to be able to get you pick Curtis measurement of your muscle control okay so we've got digital embroidery machine sitting in the lab and we've got these what we're doing is we're sewing out these patches of conductive threads and we can actually build in these EMG sensors into out of these materials let me show you a quick video so we've got this little sleeve this is about the size of a penny and here you can see it in action so this is the muscle activity being shown online we also have motion sensors embedded into this thing so so that's that's kind of interesting that's kind of nice and we and when we've compared those against gel based medical electrodes it's almost identical in terms of the response that you get so it's kind of incredible that you can you can just sew these things out but of course there's some issues when you're working with clothing okay so one of the problems is that you well clothing is very complicated system to to model you don't really know the dynamics of of your shirt sleeve as its as it's flapping around you know when you move it moves with respect to your body and you know the the actual material properties of clothing is are quite hard to pick out from data so another area that we have recently been working on is how can we extract sort of features of the of the human behavior ignoring all that all I was motion artifacts all that noise and it's it's incredibly simple idea of what we're applying here so we're trying to predict how the limb is moving from a sensed data and it seems to be amazing to me how much the machine learning literature looks at things where you have noise on the outputs but our problem is that we have noise on the inputs so it's a question about how to deal with that okay but one very simple way is to to use orthogonal regressions so you're doing something like your ordinary least-squares which is now this one here you're minimizing your errors in your in your output variable instead you can reformulate that so that you minimize your errors in in all your inputs and output dimensions and it's actually quite we've been quite surprised about how effective that has been for picking out motion and eliminating these aspects so this is our little experimental setup you can see there's a box it's got two identical accelerometers on there we just do some random sort of shaking motion around and from that we've built a model predicting the the box motion from the fabric motion so the fabric motion is is the yellow signal there as you can see so as I said all it takes is a simple modification of a standard least-squares learner and we can get quite a close match in close prediction of of the box motion from the fabric motion you know purely from like a half a second of shaking the box around so again is it seems like a incredibly challenging problem but actually quite simple methods that have been we've found to be quite powerful in this zone and so what that has now allowed us to do is to take motion analysis outside of the lab so we can now so what we have now is a pair of jogging leggings we have men's men's and women's are available and we've been quite interested in what can we see from your muscle data as you're running around outdoors ok so we haven't quite gone to the full you know lidar setup for these guys but we're at least measuring their their their leg muscles and we're sending them around Hyde Park and the nice thing about Hyde Park is that it has the rotten road which is where you train your horses there's also where we train our undergrads to run along some tracks so so we've we've looked at this we've got people running on on the rotten road we've got people running on on sort of the standard you know tarmac tracks and we've also looked at people running around like a proper athletics track with a probably a spring base and despite the fact that this is a nasty sort of not together prototype system we can see a difference we can see a difference in the level of muscle fatigue that people exhibit when they're running on these on these different tracks so essentially what you need to look at is how the muscle recruitment increases over time so there's some specific physiological factors about why that happens when you get more fatigue but we do see that running on sand is more exhausting as you expect than running on an athletics track so that's kind of a nice result okay so so those are just a few kind of thoughts and ideas so I'm very much sold by this idea of optimal feedback control and variable impedance actuators they both predicts the way that people are behaving but they also have some nice properties that we can exploit in an engineering sense for imitation learning it's really challenging in this area because of the complexity and the sensitivity of the dynamics of these systems but I think you know we're making some headway there and you know this is what is is really you know at the current state of the art is where variable physical damping actuators so including damping as well as stiffness into your into your robot which is the same as has how what people have unless you big critters capture of behaviors for example through through wearable sensing so I just want to acknowledge the many people who are not all pictured here and the many sort of organizations that that have sponsored this this work and I say thank you for your compliance stuff if you've got a full mathematical model of the the way you want it to be can't you simulate all of your springs and dampers and then then just apply that in software with with various sensors to to provide the necessary talk inputs yes the answer is yes if you have a full mathematical model of all of those things but you don't that's the problem so it's really hard for example to measure friction and you know the manufacture of of these of these systems is not perfect so in theory yes but in practice no it seems like in the invitation any problem a big part of difficulty is modeling the reward or cost function between what your your imitator is doing and the kind of thing you're actually trying to get it to imitate so but the actual control problem is actually not as complex is that what one is that correct and is there are there any things that you've tried to kind of get around the modeling of the cost function so it's so it's not a trivial problem to go from a cost function to create a controller from its firstly especially when you start to have you know full humanoid scale motors but you know that's an aside let's assume the problem is solved the cost function in some sense it's a bit easier because so our approach throughout has been to make things interpret a ball and you know understandable so so we design our cost function to have meaningful features if you want to go to a you can you know apply a free-form you know nonparametric model of your cost function but so far I haven't been convinced by any methods that that are able to learn that freeform cost function model effectively and there's some you know good reason for that one of the reasons is that it's actually an ill-posed problem so the zero cost function no cost or anything means that everything is optimal respect to the zero cost function so there's one cost function that every behavior can be explained by basically so so I think that at least from our perspective because we're working in a very specific you know domain we're very much you know interested in human human control and we know something about how humans are doing things we can use that you know domain knowledge essentially I'm not yet convinced by totally freeform data-driven thing for that yep you use we don't use springs damp but we can because from your videos I can see them just want to consider alternatives never eaten and most of these you should go towards optic haptics yes okay so firstly we we don't use springs to damp but you can control Springs to have a damping like effect so essentially you can if you imagine with a with a spring when you extend it you store energy into it and if we while we're moving these what's the word contract it you lose that energy and so that essentially allows you to damp in some way sorry for the feedback but we so this activator very soon is actually using something like a dynamo effect to suck energy out so that's a separate damper what was the second question I forgot so with the sensing stuff we are going in that direction to some extent because if we you know we want to be compliant so that we can interact with people and if you're being palpated you want to have a have a soft interface to you you don't want something hard necessarily you know pressing into you so yes we are going in that direction to some extent I'm not sure but as I said there hi just a question about robot learning do you really think that the best way to teach a robot is to get it to imitate a human I think that humans are the best example that we've got at the moment of being a fully capable and many many tasks so some people so that there is a little bit of a debate about whether we should be bio inspired or bio aware so should we directly copy the human or should we just know what they're doing that design it better and to some extent we we follow that approach to so having decoupled stiffness from damping for example humans have damping and stiffness linearly related and we can avoid that we don't need that so we can do better on that note we can do better all right I think the next Meetup we're not quite sure whether it'll be July or the month after may very well be well may even be earlier but in a case thank you very much for coming and 