 hello everyone my name is Damien and I feel very lucky today because two great artists Cyril diagonal and my Oakland man will join me on stage in a few minutes so you can see what they will you can see what they do when they use machine learning so if you want to go to the bathroom or text please do it while I'm doing the intro but when they ourselves is a real meet it there so I'm working for the Cultural Institute in Paris and the mission of the constituted to help to museum an institution to digitalize and to share their culture they are a set online we are working with more than 1000 museum and it means that if you want to discover a new museum every weeks it will take you 20 years to do so what we do at the Cultural Institute is this app it's named the Google look future often culture app it's really a beautiful app and if you have not downloaded yet you should do there are ton of really incredible features and one of my favorites is named gigapixel the gap excel is done using the earth camera and the earth camera is able to catch every detail in the paintings so every crack every blue stuff you can see them in the app you can zoom in very deeply in the app to see France and steri night but I'm not walking on this app I'm walking in space than the lab it's in the middle of Paris it's a beautiful space I feel lucky every day when I go there and it's a space dedicated for creativity and just the fun fact is that it's where the cardboard is born David goes and I use the laser cutter there to create a very first cardboard the one that was and violet I you 2 years ago that's why I have this t-shirt today and last year we also work at the laughs and sometimes we speak sure you can see some a prototype of the cardboard that wasn't violated in the last year but enough for the cardboard today even if I have still a string relationship with the VR team I also have a small team in Paris that is named Silex it's ten for Cultural Institute experiment team and what we do we do experiment with creative coders and artists we are very passionate about three different axes it's we try to engage more people to enjoy culture so we try to find fun way to for people to watch more paintings we try to find also a new way to organize the information so our user can have a journey and in our database and hopefully she can learn something out of it and obviously because we have seven million assets in that abase we try to analyze them through a discover new insight so this talk is about machine learning obviously and just take 30 seconds to to remind us the definition just to make things simple imagine that you are writing an algorithm to to check if a picture is a cat picture you can do it yourself by try to analyzing all the pixel one by one but obviously it's difficult or what you can do is using machine learning having an algorithm that will learn by itself what are the good features to check if the picture is a cat picture so the key I think is this is happening now machine learning is not the future machine learning something that everybody is this audience can do can try if you know how to code you can try machine learning for example did you know that you can create some my own boss levels just using no ahead and networks or you can make color movie from a black and one white or you can make a 3d movie from a 2d movie so things that seems difficult or impossible it's something that you can do now using machine learning and neural networks another example this one is inside the brother it's david from japan designer or an artist and it just decided to make these simple games with two volley player and in fact they play extremely well just using a very very simple neural network that I display on the screen so because machine learning is so useful and widespread now there is no doubt that it will have a huge impact on art and on artists so that's why we decide something like 1 years ago to create a machine on green machine learning residency in the lab so we asked artists to join us and to create great experience so now I will lead to Mario my Oakland man with our latest artist in residency ok thank you very much hi everybody my name's Mario Clingerman and I'm a code artist and might sound like I kind of really good at indentation or right beautiful code but that's not really what it is it just says that I'm using code and algorithms to produce things that look interesting and some of them might even be called art I not know I'm not the one to decide that like any other artist I have this problem like you look around you and it looks like everything has already been done I mean yeah in times of Google you come up with a great idea you google I didn't think oh well ok done already so it seems there are no empty spaces anymore no white spaces where you can make your mark where you can kind of be original on the other hand if you look at it there are no real or humans are incapable of having original ideas ideas are always just a recombination of something some other people have done before you take concept a and concept B and the idea is finding a new connection between them and so this is where for me the computer can help me finding these connections so in theory all I have to do is go through every possible permutation and the computer will offer me new combinations that hopefully not have been done and all I have to do is sit back and let the whatever it has created pass by and decide if I like it or not so in a way I'm becoming more of a curator than a creator I'll show you a short example so this is a tool I call Ernst it's a kind of an homage to Max Ernst enough artists famous for his surreal collages back in the early 20th century and what he did he created these collages from things he found in papers in catalogues etc so I decided well maybe I built my own collage tool and in this case I'm using assets found in the vase a collection of public domain images by the Internet Archive and I wrote me a tool that helps me to automatically cut them out and then I say okay if I give you these five elements what can you do with them and then it produces me stuff like these and unlike Max Ernst I have the possibility to also scale material so and once then you get these if you have like pipes you get fractal structures things that look like plants and the process is really like this I have this tool with all the library elements and then it just starts combining them in random ways and sometimes I see something that I like very often I see things that are just horrible or just total chaos but yet sometimes there's something that looks like this I call that for example run hipster run and I must say coming up with funny titles or interesting titles is of course a nice perk of this way of working but of course there's still this problem that I still have to look through a lot of images which are just well just noise just chaos so wouldn't it be nice if the machine could learn what I like what are my tastes are or even better what other people like and then I can sell them like that so I realized I have to first understand what do humans find interesting in images what is it that makes an one image more artful than another one and this directed my view to this growing amount of digital archives and those are now there are lots of museums and libraries out there that start digitizing all their old books and paintings just like the Cultural Institute helps museums doing that and so I first stumbled upon this about two years ago when the British Library uploaded 1 million images that were automatically extracted from books spanning from 1500 to 1899 there was only a little kind of a problem with it because all these illustrations and photos were cut out automatically so there they had OCR scans and then they knew there would be an image in a certain area but unless you didn't look yourself at the image you wouldn't know what's actually on it so if you were looking for let's say a portrait of Shakespeare you would have to manually go through every image until you may be stuck upon it so I thought that's a bit tricky maybe I can help them with classifying their their material and training the computer ok this is a portrait this is a map so I started in a way figuring out ways how I could do that and eventually I I was able to tack about four hundred thousand images for them I mean this was a kind of a group effort everybody could join in but working with this material I realized is such a joyful experience because in the beginning I was just interested in learning but actually you suddenly realize there is this goldmine this huge mine of material and sometimes really you you go through lots of things that seem to be boring or you're not interested in and then you stuck upon a beautiful illustration or something and I I realized that is that is actually a huge part of the the fun of the process so for example take this rock or stone axe so well once you go through this material you start recognizing patterns and so sometimes there comes this rock by and you see okay well I don't care but then the second one and they say oh maybe I should start a rock collection or rock category and then what happens is suddenly you are happy when every time you come another one of those and then well what I do is I start arranging them and putting them kind of in a new context and then you start actually starting to appreciate the craftsmanship that went into this and also you can like once you put lots of very similar things together you can much better distinguish between the the slight differences in their yes so I start doing this for example here on the left side you see a piece called 36 enormous profiles it's there's all these hundreds thousands of geological profiles which again you probably if you're not interested or geologists you would don't wouldn't care but like this it becomes really interesting field or well it's just a way to to bring these things that maybe sometimes have been hidden for a hundred years in a book and nobody has watched them and now you can bring them back to life or on the right side of his I call 16 very sad girls again I don't know why they have so many sad girls in there but of course again that makes you question what was happening at that time so it actually motivates you to search back and well what's the story behind this but this all I started kind of on my own and this it was not I wouldn't say it wasn't deep learning what I was doing it was more classical machine learning because I was always a little bit afraid of going down this path I heard like oh we need expensive machines and it's kind of hard to set up the machine so I needed something to to get me like motivated to go through the painful process of installing everything to get a machine learning system luckily about a year ago this came along I don't know if you had seen this picture but when I saw it that oh my god this looks kind of weird and I have never seen this before fortunately about a week later before after this leaked it was clear Oh from some engineers at Google have come up with this new technique called deep dream and it's based on machine learning so of course I wanted to know how can I do this myself fortunately what they did they actually shared an eye Python notebook on github with all the source code even the Train model and it was able to to dig myself into this back in the days there was no tensorflow yet so this was still in cafe but this allowed me to finally kind of go by baby steps into into learning this technique and obviously I started like probably a lot of us we I started to having a lot of fun with this like you put in an image and you wonder oh my god what will I get out of this because that's what it is you you put something in you had no idea what what you would get so this was fun for let's say a few a few weeks but then I started thinking okay I think I could make some improvements to this code and well I would call this lucid dreaming so maybe get a little bit more control or change the outcome so I figured out there are three points I might be able to well to turn it into a different direction so the first one I'm not sure if you noticed it these pictures are all kind of a bit psychedelic colorful so that's like I'm from Germany we are kind of very earnest people so I like it rather a bit toned down so very simple thing desaturate it a bit and this saturation is super easy so all I needed was to add a single line of code which is the one you see at the bottom what you do is you take the average between the RGB values and then you can have a linear interpolation between the grayscale version and the color version and depending on how crazy you want it well you pick a factor in the middle and so as a example here on the left side psychedelic Mario on the right the well puppeyface grayscale one so well but second thing well that issue about that you don't know what you will get out or when you get something out it we can get a selection of slack puppy or eyes so can I get a little bit more control well in there order to do that we have to have a look at how this thing works so this is the classic a classic convolutional network for which is the Google net in this case that was also the architecture that was used for the early deep dream experiments so what did what you do you put something in on the left and image and it passes through all these convolutional layers and softmax and well we don't go into depth there in the end you get out what the machine thinks a probability for certain categories what we dream does is you put in an image at the beginning but then instead of going all through all the network you stop at a certain layer and at that layer there are certain neurons activated so depending on what the network thinks it sees there it will some neurons will get activated and others will not and what it does is then it emphasizes those activations even more and sends it back up the chain and then this will in your way oops it will kind of emphasize all those elements where it thought it has discovered let's say a cat then it will improve the cattiness of that image so well if you look at it at this what actually happens inside this network and I'm coming from the candle let's say a pixel art background or I'm doing lots of with bitmaps so I look at it this way then it's actually bitmaps all the way down so in the top layers you can still see there is some convolutions going on that remind you of sharpening filters or something the deeper you go down the net actually it gets more and more abstract but for me even those dots are still little bit maps and then I can do stuff with them I can increase the brightness reduce or increase enhance the contrast blur things or what I also can do I can treat it like a brain surgeon in a way like I poked in and say okay when I poke in here does the finger wiggle or to-- so and what i can do then is i can just say well how about if i turn everything every neuron off instead of maybe for example that ten most activated ones and send it back up the code to do that is again rather simple so again each of these little bit maps is just well well for me it's a bitmap or it's a little array of numbers so what I can do for each of these cells I just sum up all the pixels in there then I sort them by how much they summed up to and in the end I just keep the top ten for example or if I'm just as interested in a single category Gouri the most activated one and replace all the other values of zero and send it back up what I get then is something that looks like this so it's kind of just reducing everything to a single category the network thinks to have seen and I'd like these really because they are again totally out of this world some remind me of organic patterns sometimes you can see okay this might have come from an eye detector or so but definitely it doesn't contain any any traces of slugs or eyes again so but of course there's still this other issue and I call it the puppy League or rather I kind of reveal why are there so many puppies in like why why does deep reme have like such a love for puppies well the reason is that their network the original network that was used for the the first release of debris was based on the image net large-scale visual recognition competition which is kind of the Olympics of of image recognition and in 2014 what they did they added a hundred and fifty new categories and it was all dog breeds so that old rule applies gerbil in gerbil out so whatever you train it with that's what you will get so well then I thought okay maybe I just have to train this day this network with something else but then I'm kind of new to it I I heard heard these stories that it takes like four weeks on a super powerful GPU to train a network and well I'm a pool artist I can't afford like an Nvidia wreck with these things so but then I came across this technique which is really astonishing it's called fine tuning and what it does is you can take an already trained network which for example the Google net and all you have to do is to cut off the bottom layer and on and then you can retrain it with new material and what happens is all the top layers are pretty much the same no matter what you train it with because they look for abstract elements like edges curvature things like that so that doesn't need to be retrained so doing that you can take a train Network you feed in new images instead of taking for weeks you can train a network overnight and the way I do it well I tried it with let's I call it amnesty with a twist it's kind of I in my works with these archives that come across a lot of these decorative initials and I thought like okay is there a way I could actually train it to recognize ABC in Indies that come in all different kinds of shapes well I tried and I must admit there is a manual process involved because what I have to do is well the way i do it i really start folders on my hard drive and go manually and drag and drop whatever i find in this i'd say oh in la i drop into the a folder i don't have to do this with the thousands of images actually it turns out i can just start with its enough i take 50 for each category if i'm pretty sure there's people who know much more about than me about machine learning they say oh my god i will never work and it will totally over fit it doesn't matter actually it works so i start with just like let's say 20 to 50 images per category and then train the network using the fine-tuning technique i let it kind of simmer for two hours so so it gets a little bit customed to the data and then i use this to show me what it thinks these letters are so it I train it a bit it give it a bunch of random images and it says oh I think it's an A I say no it's not an A and then a B oh yes and actually it gets better and better because what I do is whenever it finds something it gets added to my training set and I can repeat this process so and to or in order to to kind of help me with this process of saying yes no I realized that the that kind of left swipe right swipe is a real popular way to decide if you are into a specimen or not and it's actually it's a super fast way so I can go back and forth and in one hour I can already I think I can go through a thousand images and say if I like if they if it's correct or not and as a result so for example here this is stuff where it has correctly recognized that it's an A and as you can see it's quite I mean it's it's really surprising like it comes in so many different shapes that well it's just amazing how powerful these networks are then sometimes it gives me something like this and I don't know it looks like a ruin to me so the Machine said it's a B and then I'd said no it's it so I actually went to the original scan in the book to check it out and indeed it is a B so this is really magic and but of course if everything you have is a hammer everything looks like a nail it starts seeing letters in everything so it gives me these things and well but again it's beautiful right so maybe something I have not been looking for but of course I was about deep dreaming so this is then what happens if I feet use this newly trained network on on material and you could definitely see it takes an entirely different twist it suddenly has this typographic feel to it and another example not sure if you recognize the lady on the left and the right but it's actually the Mona Lisa in let's say yeah well it has a linocut aspect to me but yes there's no more puppies involved at all but Oki oh one more thing yes the dream has had this great opportunity in the in spring this year where the gray area foundation located in San Francisco was doing a charity auction to fund their projects and I was really honored that to be invited to contribute some artworks there so I kind of ate my own dog food and created like try to create something that is not obviously deep dream so I created this piece called the Archimedes principle which well it reminds me of a ball floating in water but the one thing I didn't mention yet is my residency and the reason is it just started but I can tell you I feel like a child in a candy store it's really amazing I have this huge amount of data to play with I have kind of metadata I can have super smart people much smarter than me that I can ask extremely stupid questions and I've already started working but it's still as something I want to fine-tune but I also had the privilege to see what Cyril is actually doing there for a while and so no further ado I let's get Cyril on stage too so he can show you some awesome things thank you thank you Mario Wow okay so my name is Cyril Jiang and I'm digital interaction artists so a question I get often is what is a digital interaction artist so it's actually very simple I try to create poetic moments for people when they are interacting with digital systems and the process is also fairly simple it's basically boils down to two steps one step is just playing really just like a kid getting my hands on some technology and playing without any goal just for the pleasure of learning new things and having fun and then sometimes I poetic outcome appears and what that lets you do is for example swing through the stars or having your face covered with some generative masks or creating a video of people dancing together and so on and so on and all the things that I've been doing over the last years but you might be wondering okay what about machine learning it turns out one year ago I didn't know anything about machine learning it all started when Damien came to me asked me hi cereal how are you I'm good thanks and how are you not too bad and he asked me okay what can you do with 7 million cultural artifacts ok I had to stop for a moment what do you mean seven million cultural artifacts what can I do said yeah well the Cultural Institute has been working for several years with thousands of partners we have this great database with amazing content well what can you do with it well I really had to stop because those are 7 million opportunities to learn something new about the culture about some events really incredibly high quality content so in order not to panic I did what every coder would do in this situation I loaded all the assets and plotted them in a sin wave because then I did not have to think about it anymore that was done and from there well I did the most obvious things I started to plot them by time by color by median and well you find some interesting things along the way but you can't help but think there's got to be more all this great material all this great technology there's got to be more that we can get out out of it and so this is where machine learning came across especially when you go to Google every day it doesn't take too long until someone points you to some amazing things and so the first the first one of the first experiments that we did is using a popular technology now which is the of machine learning annotation so it's the technology that allows you to find the photos that you took in the forest by tapping trees my photos of the photos of my friend Tony etc but what about the less expected labels the labels you would not think in the first place right down and what about less expected images as well and images that she would not expect to find and you were there well we were curious as well so we send it all over to the to the service and where we got the results back where well I fell off my chair I will show you can we hand over to the get them to the demo so basically what we can see here is that we got back around 4,000 different unique labels and well we we had to spend hours it was too amazing the things that were detected were really incredible let's let's go over one example that you would expect work because it does but in quite an amazing way so let's look for horses there okay so as you can see some beautiful artworks of horse let's let's take this one for example beautiful painting from exacta one well it's quite incredible because I don't know how he got his inspiration to picture horses from this angle because I didn't even know it was possible or how the Machine managed to to detect that it was a horse but it doesn't and well it's quite amazing and also you get examples after examples of well really incredible things like this for example calligraphic artwork of again a horse but that really goes toward the abstract representation from unz Kuhn and again a beautiful artwork but it quite blows my mind that now algorithms are capable of distinguishing this much amount of details in these images so I will unfortunately I can go over all those examples but we are gonna release this online soon so please take a day off to go through all of them because there are some pretty amazing examples and we said now okay now that we realize it really works what about more trickier examples like for example let's put something that lean toward emotion like calm for example let's have a look calm ooop they're so well yeah there is this thing where we didn't know what expect when when you click on the label and when you look at the continent indeed yes I see I understand your reference computer these are indeed calm sceneries beautiful landscapes with yeah it's peaceful so as we went over and over we came across also labels that we would have not thought to write down like for example one that I quite liked I didn't know it was the thing but we found this lady-in-waiting collection automatically created and create and sent back by the algorithms but look at this beautiful collection of incredible artworks from various centuries of I don't know maybe I guess it was the thing lady-in-waiting oh well apart from that one maybe ok and then maybe one last example this one I really fell off my chair I had no idea what to expect I was like oh what's gone that must be some some glitch but then when it appeared well it just made sense yeah yeah that's that's right so yes we will release this online soon we have to polish a few things first but what you can see is yes before the neural net is able to label all these images first here is representing all the images in highly dimensional world let's say but it really qualifies as the world basically the neural net to be able to apply those labels he position every assets at a particular position in this world well I don't know about you but I want to visit that world what does it look like are is there I don't know and I the impression is blue with blue hats or the highway of Roman statues I don't know but what I suggest is you hop on with me and we just have a quick tour I will give you a quick tour okay so let's start from these two assets here well they seem to have in common that there are a landscape but let's take a step back we can see other artworks appearing with well it looks like some series of landscapes more landscapes but if you look around then we can see that we are actually surrounded we really literally woke up in this I don't know the island of art and well let's let's have a look let's have a tour actually so here we can see Yassine with animals I guess as we continue I think it's this direction so let's let's give it a little while for it to load people start to appear in the picture along with those animals and if we step back even more actually let me take you to one of my favorite spot directly this one I call it the shore of portraits look at this let's give it a little while to load and so this sorry I'm going really quick because we have a lot of things that we want to show but this is a t-sne map so t-sne stands for a tea distributed stochastic neighbor ending which basically takes all those 128 dimensions and flattens it to just two dimensions so that you can plot them and make make it interactive and easier to to travel across so here is a simple that very simplistic diagram that shows how you can create the map so basically we take the image we fit it into the neural net which extracts the row features which is a hundred and twenty eight dimensional vector then in two steps we reduces these dimensions to two and then it becomes you you choose the way you want to plot them but this you can do now today with eight lines of Python so it's not something that is yes reserved for scientists or researchers with thanks to some amazing open-source libraries like SK learn it is something you can do with eight lines of Python you just let the CSV of your row features you well I won't go over all this line but you do a truncated SVD which is the first step that reduces to fifty dimensions and then the t-sne is able to create this nice map of two-dimensional vectors and then as we we saw the the shore of portraits we we got an idea which led to what we call the portrait mature so basically the Cultural Institute has about we detected in the art art project channel about forty thousand faces so the question came quite naturally what if you could browse this database with your own face and it has to be real-time otherwise it did not happen so can we switch back to the to the demo all right let's try that let's see if it works all right so let's see oh wow okay I think we met okay so we still have to polish this one a little bit but if you come to our lab in Paris we have a much refined set up which works much better but anyway let's move on all right thank you okay can we still get back to the to the slides all right but one good thing is that this experiment led us to another iteration came from another popular thing that happens when you're in front of a painting and you see someone drawn and you feel like oh I feel like I know this person or oh that definitely looks like my neighbor Tony and actually as it turns out there is this great model that's been done by some researchers at Google which is called face net and this model is able to achieve ninety-nine point sixty three percent accuracy on the label face in the white which is the academic de facto for this type of research so basically this neural net embeds in a nuclear deal in space faces that are from the same identity closer together than faces with the addition Miller identities so basically same people are closer in this space than different people and what it sends you back basically is again 128 dimensional vector that represents the embedding and so well we had to give it a try so who knows these guys okay I was ok they're very popular in Europe too so well we took them as a starting point let's try to find let's see how well this model performs but let's not including the mix other pictures of them because I'm sure it would work so that would be boring what if instead we forced the system to send us only pictures that are paintings well again I can tell you when I saw the result I fell off my chair and yes I did spend a lot of time on the ground this residency okay I'm really excited to press this button okay all right this is what we got back I mean Jared in the middle even though there is a huge I mean there is a gender mismatch that could be his sister or even which 100 just on the right of him like it even got the curliness of the hair it is just amazing so of course you can imagine from there how many tries every one wants to find his doppelganger in the database so and here who would have known that Richard Hendricks had a half-naked man painted at the Tate region right now let's take these guys for example some of my personal heroes let's see what we get and there again even though this beautiful artwork from Shepard Fairey of Obama campaign in 2008 is highly stylized with only four colors the algorithm still managed to find the matching and yes the that is quite amazing well it would have not been fair not to try it with ourselves so we gave it a try here at i/o and sorry Mario the blue suits your so else so yeah this is really fun and yeah it's a thanks again for Adam yeah and everyone at the Cultural Institute for offering us this really great opportunity and I will hand it over to you again so thank you very much Thank You Cyril thank you my oh I'm I'm very happy to to work with this guy and I'm very lucky I guess so what's next so if you want to stay in touch with us please download how hat it's a it's a way to to keep a link with you and our bodies to inspire you to try machine learning too so if you want to give it a try I highly recommend tensorflow it's an open fire open source framework easy to to start with as a tutorial the one did by mister cast patty is really really good it really helped me to understand what's going on with machine learning and the constitute is not the only team within Google that is really passionate about machine learning so for instance there is the MEI initiative and the this link is really good reading so I encourage you to try it and the last one is about team names magenta completely dedicated to generate out using machine learning so thanks you thank you everyone 