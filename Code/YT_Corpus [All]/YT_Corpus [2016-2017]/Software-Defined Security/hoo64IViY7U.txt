 I'm Adrian Westmoreland product manager on the SCP cloud for analytics product and this morning session I'm going to cover a little bit of background information around the infrastructure aspects of cloud for analytics some of the common questions that come up that that people ask I'll try and give you information that will allow you to find the information that you need to answer those questions and then will will dip into the administration side of cloud for analytics and take a brief look at really how you administer a system looking at user and group management at some of the other aspects of the administration there as well to give you an idea of how a system is is administered so without further ado our I'll begin just got my usual disclaimer upfront to to obviously say these don't we producers without our permission and also but I'm a they of course measure some forward-looking statements they be be aware of that although most what I'm going to be talking about is that its current that were just going to cover very quickly an introduction just to recap on where cloud for analytics fits then we'll take a look at the data centers data infrastructure topics quite a lot so to look at their lot of this is ridges pointers to help you go and find the relevant documentation which is out there but not necessarily easy to find to give you the information you need around how we manage our data centers and when financiación information about compliance and security information then we'll go in and look at users roles and teams from the administration perspective so how do we manage the users on our cloud for analytics systems and then finally we'll look at things like access controls content management some of the auditing and monitoring that is available to you as a cloud for analytics to an administrator then we'll wrap up with the QA at the end of the session so let's look at the general for the background on this again recap here so cloud for analytics is one of many of the SAT cloud applications those are our acquisition and cloud applications for example concur Phil glass and Arriba and also some of our native applications for example as for Hanna the sweet running in the cloud plus many other smaller ones there our friend latex of course that running on the Hana platform in the cloud so we can leverage the benefits of running on that on that Hana platform and I'll be talking about that in just a second as well this is just two three cement if you see any of these seminars I'm sure you all have seen this slide we cement we're cloud analytics fits into the overall SCP cloud portfolio and also again to to remind you that this is a single cloud solution for those classic bi but also planning predictive and others going forward within this single analytical framework so we get to the benefit of sharing those pieces within cloud for analytics of course what that means is that we have our bi capabilities but also our planning a versus within there as well and then going forward predictive and in the longer term view adding in some of those grcc governance risk and compliance solutions inside there as well they're based around a core set of shared capabilities so for example of concern for administration would be things like auditing and monitoring where you can audit monitor the usage of your tenant regardless of the type of capabilities that are being deployed within there with Livi planning or bi then with data connectivity and modeling to defeat either be some of these cases there from the admin side to understand how we model and manage that data Connect and of course all this runs on top of the and a cloud platform and the HCP is our in art but for was a service that we run our application on and make available as a SAS solution on top of that so where can you find additional information around some of these and what I'm going to do is when you just point and this deck you can you can go to these URLs this is just to say the information is out there typically like a it's spread around with the ASEP corporate sites of the SDM site so I'm trying to pull this together and give you an indication of where you can find this additional information so there is an overall SCP a data privacy policy called the data privacy and security data controller data processor agreement well worth a look through if you are concerned about how s ap manages the data privacy and how we work with our sub processors around that and how we then work with ourselves on the data privacy aspect so that's all covered in this in this one a long winded but useful PDF document that listening to here is all the background and as well answer all your questions around our privacy policies around your how we manage our county and how you can feel we're sure that we have fairly robust processes in place around the data privacy for our cloud of solutions so this is the link to that particular document around the data privacy and security policies our dinner overall in effect for s AP the next one is around support a lot of people are a common question with our cloud solution is where do I find information on on the support of this particular solution and again we have that information available so again similar location and there is the customer support cloud customer support information this gives the formal definition of how we support the product the time of that support etc and the various aspects of that support policy against worth a glance to ensure that you understand how we support our frontage and the fact that the support policies are very similar to our classic on-premise solutions but again people often have questions around these these topics final little piece of useful information is is usually around the cloud for analytics supplemental policy so we do have again this is a very useful site the product use and support terms site you can type in on the little picture on the right hand side of this slide you can see there it's got a search box if you search for clown phonetics you'll get doctorates coming up there where we add them in and the cloud for analytics supplemental agreement contains additional information that is above and beyond or different to the standard clauses and conditions in the prior document so this is where you'll find specific information around cloud for analytics around the license types for example of cloud for analytics around some of those supporting connectors for example for data connectivity and how we apply to the cloud for analytics landscape so again if you're looking for that additional information this is a document you should have if you're looking to explore with FEP with an RFI type response then this is a good place to take a look at this one that background information will answer all those questions we'll about how we apply those policies to cloud for analytics then the final piece that I want to mention here is around the update cycles so very easy place to find this one here it's on help on s AP comm within the documentation you'll find the basic documentation is on health care SCP comm cloud for analytics and then alongside that you find that every two weeks we put out a release note so that release note will contain all the new features and the update information for those particular releases this is where you'll find out what exactly was in a release and you'll see there that our release cycles are now numbered so this is a little bit out of 8 2016 and forms the fourth release of 2016 but you can quickly see where we are there are these cycles there and find me information around what's in those latest release it's a good resource as well if you want to understand what's in cloud for analytics today and both the documentation and these release notes okay so let's now switch a little bit to the more detailed pieces around the data centers and this is again just to give you the the reassurance that the the data centers are secure so what we have is our HCP data centers where we we run our cloud for analytics on top of the HCP infrastructure and we inherit therefore some of those certifications that come with the data centers we have so we have for example our ISO and slot compliance as part of the data center infrastructure so we can take advantage of the work that's being done there around our HCP data centers now we only run on the HCP today the Hana cloud platform and I will say that allows us to leverage some of the scale of SCP the fact we do have these data centers around the world if you want to find out more about the data centers about what these specifications mean and how a data center operates and how we fit within that there's a great resource called on the www SCP data center calm and that will actually take you through a look at the data center so it takes you through some of the physical security aspects and then the internal aspects of security around that data center the infrastructure we use around the data center for our compliance and it also gives you some good background reading there around the security and and how we manage and run our data centers to keep them secure so a very good resource that's available to learn to all of those today and because we've run on the HCP data centers we're currently running in in four of the five current HCP defense today so we run east coast and west coast of the US a Phoenix in Ashburn and we also run out of Amsterdam and the Frankfurt the raw data centers there and and when you provision or ask for a cloud frantic system to be provisioned you can specify the data center that you would like that to be provisioned it so I see people then if you have a preference with running your your parents in North America at Weejuns we can provision their or preference for a European data center we will of course provision in that going forward we will be adding additional data center support so I see HCP infrastructure it's fans around the world we are also looking to expand with that infrastructure again we're looking to add additional data centers throughout 2016 this is not a fix these are still plans where we're also looking at investing other other options because we understand that other countries have I'm quite specific rules and regulations and data privacy and data center locations so we're trying to ensure that we can meet those with our data center locations as we go forward let's talk about the the data aspects and when it comes to data we're talking now allowed beyond the the infrastructure type data questions so the assumption now is the data is it could be in the cloud the cloud the datacenter keeping that secured then we get down to the next level of questions around how we manage that data and we look after that later inside cloud for analytics now there's a couple of ways that we can access data this is a very high level diagram to give you a feel for the types of data we can access and also how we can access that data so we can access cloud-based data sources whether they be typical cloud solutions such as Salesforce or Google sheets and we can also access a data that is stored in the cloud in other cloud solutions or for example for example an HCP a vast database as a service and through that we can also access other sources with their data connected so we can access pretty much any source by that mechanism we can also import data into cloud for analytics and that allows us to take data from on-premise solutions via a direct connection or universes so we can access hammer VW we can also access Phi the business object universe and the business objects plan a platform bring that data into cloud for analytics as well so we can or beta pets and we also have the ability to do online access to on-premise data with SCP Hana as well where the data stays on premise and only then the results are in the browser only the metadata viewed is moved into cloud for analytics that's a lot of people allow them to keep their data close to their data centers on premise and gives them the peace of mind of that data is not moving into the cloud but it still allows them to have a cloud-based and bi solution available to them now it's a couple of reasons why you may or may not choose the various data collectivism mechanisms I think the the online access they're really the key there is that we don't replicate that data anywhere else we keep that data in its source so that sources Hana either on HEC HTTP or on-premise we leave that data where it is the data of course will be modeled in that system and is modeled and managed centrally to repiy by ID and so the structures that are in place there are the structures you would be using to query with cloud for analytics to build your content in cloud for analytics of course it does protect that investment in that in that source system it also allows that sensitive data to stay on premise because we're not moving that data anywhere but between that system and the browser there's a benefit synaptic there there is also the data acquisition model where we take that data this is more of the classic acquisition type where a business user potentially could take data from multiple sources of that be Spreadsheets Google Drive found sources manage sources bring that data into a new model and then remodel do data preparation into blending data linking are on that data and then build their content on that model there so that typically has the benefits of allowing that business user more flexibility in the sources and more flexibility in the types of models and the data preparation and cleansing they can perform it also includes Business Objects universes as I've mentioned so I is now an available connective type I just saw one of the questions come up in the window out of the corner of my eye around BW and s4 so I think the plan for BW s for time line I say soon there and yes I did keep that fairly vague the plan will be I believe we're still targeting a first half for this year for the initial builds on those and then we'll be rounding those out in the second half of this year to give you a richer set of functionality against both BW and s4 that I see at the rough timeline for that so expect to see those very soon natural thing and then from and just before leave the data preparation piece safe and non SCP non Hana you don't need to replicate that data into the HCP the business of this universe if you have one way to connect to any data source pretty much out there if you don't have an existing business objects bi landscaping you enter that then you would have to replicate that data to some other place I leave out an on or off premise hammer solution to the weaker than access that there are various tools authorized to do that now we are looking to increase the number of connectors we have I've not got this on this slide vision focus particularly on the data slider to give an introduction but we are looking to an other non hammer data sources in the very near future as well so it's going to see that middle of this year when we're going to add a lot more data sources to the the options there or connectivity's the reason I wanted to bring up some of these data sources is readers to to highlight the different security implications around this and it is informed for a security side because typically if you are uploading that data so a business user using the standalone or acquisition type workflows will replicate that data to the cloud now there are clear benefits of that because then cloud for analytics does store that model and additional security can be applied to that model so we generate a model on the HCP infrastructure that they can then be reused by any number of users in cloud for analytics and you can apply security as an administrator to that particular model now an integrated or remote ID connection the live connection would be that local I say local meaning in the cloud versus really being on premise that base alone always stays typically on premise Matt is in HCP it stays within the SI p cloud but it's not so it's not replicated into cloud for analytics but the modeling is done on the source mail on premise the data stays within the remote landscape so it stays within your your landscape as a customer and it doesn't move off that landscape it's not replicated the modeling would have to be done on that source system so that source would have to have the capability to produce some sort of model that we could access for example there Hanna you need be accessing the the calc the graphical companies for example the analytical views within the Hana environment and then that's what you would surface to that to those you and Jennifer I leave the data connectivity piece and move into administration the actual investigation of the plan for analytics there's one question there on the window just I see they're coming in to around HCI so ACI is there to allow connectivity if you have if you would like to use a device solution social using a CPU you have a running your your Hana answers in HTTP then you'd be using HCI to move that data from whatever source that would be into your managed cloud-based Hana d-bus and then we can connect to that as just the same as we would to any other hand system so it gives us and we're leveraging that capability to allow us to build out a complete end-to-end cloud solution if required where we can take advantage the fact that the ACP can give us that device and those connectors to connect to those other data sources there gives a lot more flexibility from data ok so I'm now going to move on to the administration piece that is straightforward for administration now typically the people to attend this sort of webinar around administration are usually administrators or they have some familiarity with administration concepts and you'll see when we start to go through this very straightforward no surprises as you'd expect with this like the only thing to say I'm from here is so that Italy the assumption here is that you would have a tenant provisionally so it is a SAS solution si would have a tenant provisioned and then within that tenant if you were administrator leader typically be the things you would need to know to manage that particular tenant so we have within that tenant we have our users as you'd expect we have that the basic within the system basic user management so you can create delete and change the roles of a particular user in there if you choose to we you can also import bulk users from either a CSV file or Active Directory so you can bring those users in we can also synchronize with other IDPs via salmon as well and that gives you the flexibility around that too there's various ways of bringing those users into the system and then like I say when you brought that user in and you can create delete change and manage those users within the environment now for small environments for tests or departmental switches you can directly enter that user information and create those users on the fly a couple of things just to note here so it seems like the display name that's what would be displayed on the screen when a user logs in to cloud for analytics the email would be whether get notifications so if they were invited to a discussion or if for example a manager was able to agree to roles then then that would be the moment of use there as also the email that would be used when they notify them that their account has been created so that's also important there the license type is determined by the roles that are assigned so you don't actually actively assign a license type in this window what you do is you assign the roles and we'll talk about those in a second and then the license type is calculated based on those roles so depending on the type of deployment you have that that could be important if it's a basic VI deployment you don't need to worry so much about that at 5:09 if you do have sam'l and we sound what is available for our authentication actually need it and then planned actually is the storage of it for um user storage use so the forward-looking piece of it you can set the initial password so when you do set of that user you will be asked to set that initial password if you need to reset the password you'll see there the lock and unlock so you can't set that reset that password for a user and when a user's created their first logon they get asked to change that password will always have to change that to their own personal password beyond that the roles themselves so when you create a user you can assign those roles you'll see a list of roles that are available if you select all roles and that user will get all the roles unlikely you'll be selecting roles unless it's a test environment because your beginning everybody had been right and then you get a list of roles that can be applied to that individual the user cannot assign the roles themselves so they can't escalate their privileges I am adding additional roles they can request those roles and you can find those roles addition again oh they're real surprises in the way you manage here you can also import users from a CSV file so if you need or bulk upload to set up a system you can do so I use one I have a one-off upload you can do that and you can also import from again similar you can porphyrin Active Directory for a one-off bulk upload from ad into the system the user also has to use a profile this has additional information certificate in user would fill this out themselves post creation so when they log in they can go in that information to they use a role and this can also be populated by some of the sam'l field depending on your IDP ID so you can set that up as well with your sample size thing now when we talk about that there's a couple of things to mention so we do actually by default you have basic form based authentication some of your login prompt sounds not enabled by default if you need sam'l enabled and then you would raise a ticket with that with DevOps and they will step you through the process of setting up that sourc side of things depending on your IDP and ensure that works and going forward we're also looking to set up the default integration so soon we'll be a default integration into a CPS cloud identity sei SCA is our sam'l IDP that will simplify this by default you will be able to use that service as your identity provider that will give you a lot more flexibility in being able to have more complex controls around your your user management and also the SCP parent entity will allow you to have more complex synchronizations with other identity providers with on-premise solutions etc ease and build out a richer set of them education with them and also allow us to set up the single sign-on across multiple systems and again masterfully where people would like to see this they want to have their single sign-on enabled so it's seamless when they go into the data access to those source systems so using a third-party IDP will enable that the by default it comes with just the standard form based authentication so rolls effectively again some very surprises in what a roll is about a roll lets you define that the the activities of the user can conduct within the application and it also if you are using acquired data it will allow you to control the data in that model so in two parts to this what the user can do and if you're using those data acquisition models it will let you assign and manage the data access to those individual models so the user gets those privileges defined in the role they can have multiple roles that have a union of privileges by default typically a user will have the roles that are assigned but if you choose to you can have this we have the concept of these self-service roles where a user can request access to a role and I'll talk about that in just a second in idea how that works so there's a lot of flexibility there in allowing users to request additional privileges if they need to and the final piece around roles is if a role is concerning a piece of functionality on a menu and roll does not have the priviledge this than that functionality that menu will not appear in the system so for example the users menu allow me to add and remove users it's unlikely you're going to give that to anyone but your administrators so that menu would not appear in most users scripts they would not know there was a user management window available to them and user magnets disappear if they don't have the appropriate privileges so out of the box there are our various roles and I'm not going to go through these individually but it will give you a feel as you read the slide that we have various default roles for everything from the sort of admin everything roll down to basic bi viewers who can only view content within the system and a couple of example roles in between there for both planners and content creators and administrators now this this list of roles will grow so as we add more functionality for example predictive that list of roles is going to expect so they're going to create more difficult roles and then within those roles we can then assign the different privileges and you'll see in the role management window there it's difficult to see on the slide I've had this one before that the one those the watermark is actually quite difficult to see but per typically those watermarks let you know that certain elements and privileges are four very specific user types of planning professional is a particular user type for planners who want to have the full set of privileges for a certain license type so that's watermark to structures to let you know then the rest are fairly self-explanatory and we'll talk about that in just a second with the various rights that are available you can use an existing pre-existing right as a template which is quite useful so you can take for example a basic bi viewer we use that as a template and then tweak that to be more fitting to your type of deployment where you would create these individual roles is unlikely you would use our default roles for us for a deployment then you would just assign those those roles to individual users throughout the box again more for reference and for me to go through these and these are the various rights that are available within the within the landscape for you so what you have here is the ability to control at each of the individual pieces within the landscape so there's for example things around both functionality and also aspects of the modeling as well so you can control individual dimensions that are available to users within that particular model and then any of the other elements of the system are controllable there with device that you can set into an individual role so when you maintain a role and if you choose to you can enable that role to be self-service what that means is that you can request that what role so again this is an option within the system that you may not you may choose not to use self as well but if you do you can then enable a role to be self service then a user can request access to this role at any time typically the default role will be the minimum privileges that will be given to all users that'll be just the basic role and then either can request additional roles via self-service as and when they need them just to be aware the full data access when you're setting a role is allows readwrite so you'd be careful with that because another one has the rights to write back to a model in my home once that but be aware that that's something to be be careful of because some of because whether the planning nature of this you can create white back models and so you need to be aware of of those pieces there then the approval will be either default the manager the user signed in the user window or other users who need to set someone else to be me approver for that so as an individual if I was logging into the system I can go in and I can request a role so underneath my user picture in my profile there and there's request roles if I go in and hit that button that allows me to take a look at the roles that are available to me within the environment so I can then list in this case here this example only has one role available base yu'er I can then request access to that role I will then hit the send request what happens is that request gets sent to my approver and as my as the approvers are here I am logged back in as the administrator what this is is I can then see that someone has requested access to a role and I think that approve or deny access to that role so that gives me the flexibility for example if somebody wants to have an additional role for additional privileges they really want to write back to a model to do some planning type functionality they can request that and then I can make the call and whether I'm gonna allow them to to do that within the system the next affordance we have for user management it is teams it teams a group of users so again as is typically in most environments there's an affordance to group users that in the case of cloud for analytics as a team so a user a team as a group of users users can belong to multiple teams importantly roles can be assigned to teams and then all members will inherit now better roles and then that gives you an easier way to manage individual roles within environment you can assign those to teams and then equally each team has a private folder that can only be accessed by members of the team so a team can keep their content within that team folder that allows them access to just that set of content within the environment so again very similar to users you can go in create change and delete teams when you create a team you can see the name you can then also it will also create the the private folder in the file library so you'll see in file so we teams and then it's all teams will have a private folder in their available to them and then users can be added to that particular team and you can also assign roles to a team as well so again similar to a user user little key there to assign roles what you'll see is the teams appear before the users in the list of the originals for role so here I could assign a role to a particular team in this case so next topic is very briefly going to dis about access control and content management and then the auditing and monitoring aspects so that's the first part covered the user management piece and now we'll just talk about some of the the other controls are available as an administrator and there so there is no concept of as another user like in BW so one because those requesters as another user so know that the user is using you can't you can't impersonate anybody everything must be that one there is getting out and the other question about GRC I don't know the answer that yet we'll have to wait and see user management means everything in C phrase is changing all the time with our rapid development cycles it gives us the opportunity and being in the cloud to to refine and optimize the software as we go forward I think it would almost certainly be some changes around this as we go forward some improvements especially as we add in the GRC capabilities to give us that additional flexibility so when it comes to to data access there's a couple of ways to define data access you need to do that dimensionally see you can assign an individual's ability to view a dimension within a model or you can apply filters to an individual sort of that's the sort of classic sort of the we're course on on a road to give an individual different views of that so two types of mechanisms there to give you fine-grained control of data in an acquired model and so you can like I say either go in there and you can apply the data access on to give it individual access to individual dimensions and also then the readwrite access can be assigned on to that model as well so users can go in and write back into their planning model if they needed to and you can also define at a filter level and the filter I think is put on a piece book very familiar with especially from a bi background where you would want to apply a row level walk on to a set of data so you would then in here say you would define that filter so individuals would have their own filters so effectively aware clause on a row level next line will this give you me and the idea there so you say where that unit equals something then only give them access to certain rows within that particular model so two ways of controlling that within the environment again that's one of the benefits of the the acquisition mode model is you do have that fine-grained control so unless you apply that that layer on to those models when making great things and for analytics of course if you're not using this mechanism you would be relying on the source model so in a online model mode typically you would be using the individual and in their roles with the assignment bias would be applied when they access that underlying model and that's managed outside of cloud for analytics there's also the concept of files within cloud fronting so any Content you create within our final tips be that a dashboard a file that you've uploaded and stored in in a folder you can also assign permissions to those files within an environment as well so permissions can be defined in any file the owner of course does have full permissions and then you can push those into other folders and assign rights on who can see that at set of content so that can activity the ability to control who can view for example output reports and dashboards because you can control the lights on those on those objects within cloud for analytics cloud run is also supports that import/export so you can move content into and out of the environment and it does take those dependencies between that content so when it comes to if you're moving for example content between two systems you could export that content and then re-import it there's private editions there I didn't talk about that but we do also have available if you so desire the concept of a private Edition which is a single tentative box or additional costs so there's only one of the pieces there you can do the use the transport if you do have a private audition that's a multi-talented you just use the standard import/export majority of people have so you can select your content whether that be individual dimensions models dash boards etc users rolls rights can all be exported that that content can then be exported to a file and then we will then and then the upload or import is the reverse you can take that exported file and you can re-upload that into the system itself those can be used like I say if you create some content you need to share back you can you can take that content out using this import export potentially could be used for lifecycle management depending on how you choose to deploy cloud for analytics that we do again offer test and des type penance for a different costing structure so you can build a classic sort of dare view eighty and prod environment and this potentially could be used to move content if for example you had data sensitivity where you needed to ensure your developers couldn't see the actual production data you could do that using this type of mechanism to move that content between between those environments in that context finally the last sort of piece around this presentation is is that admin you may want to understand what your users are doing what the system usage is so we do have a fairly comprehensive set of audit logs available so as an administrator you have access to those you can you can take a look at who's been doing what within the system some basic filtering it's available in there and it allows you to understand who is using the system who is doing various operations within that system etc we also have the data change audit log so there's two types of audit logs in cloud from this one was a usage what is the data change if you do have those acquisition models we brought that data in you can then also audit data changes so again if someone is writing back that you can audit who wrote back when what was changed in those particular models so that's captured in data change log as well particularly important around the planning scenarios where you want to understand who is there doing those write back operations on those planning models and then the final piece here is around the system usage so this gives an overview of the use of the system but only from a licensing perspective so you can get an overview of the type of licenses you've deployed now in this particular screenshot I've over deployed my VI users so I'm highlighting in red there I'm actually only got five I've deployed 14 so I've deployed too many licenses in this case it'll give you a few of that I'll give you a view of the map memory you're using on your system and you know that today now for analytics is sold by user with memory so they only sort of parameter sort of an administrator you need to worry about from a usage perspective it's the number of users and the amount of memory you have available T and then there is some usage information there at a high level and then you can drill down and look at usage by the individual models how much memory those models are consuming the usage of memory by individual users so you can see which users are consuming the most memory the most resources in there and find there is ability to access the trace log first for example there was a support issue you can go in here and pull the trace logs out to help us if there's been an issue with with the with the landscape there in that particular environment and again we're looking to as we go forward to to overhaul a lot of these pieces here to improve some of the functionality around this we use for like cloud for analytics technology to give you a cleaner way of accessing the system usage information within within your cloud for analytics environment today so that really wraps up my my quick overview there on both the infrastructure side where the fines were the information around security around some of the policies and privacy the data center security etc a lot of good information out there it's just sometimes a little bit difficult to track down I did note in the I think Adrienne put the links in there and then some you said they one of them doesn't work that could well be true I'll verify that and if any changes I'll I'll post those to Adrienne Paul and I get those put into SCM those links to make sure those links are still current because often that information does move is at the corporate level those policies change so it's worth keeping abreast of it and then finally the last few sales around that the basic administration now see phrase a cloud-based system so it is you know multi-edge we take care of a lot of the aspects of running the system so you don't need to worry about those as an administrator so a lot of the elements you may be familiar with things like performance tuning they're not really part of the c4a administration portfolio no that's that's taken care of by ICP and on our DevOps side of things and really we need to worry about its managing that the individuals in that landscape from the content within that landscape itself in the integrated scenario where the data only resides it keeps moving it when then only resides at sources that function at it import existing analytical privileges on the source data safe from models and/or views so I think the question would be so in the integrated scenario so the answer is is you if you're if you're accessing an online source so in the if I don't where you are you're not actually moving the data into alpha analytics doing online access then you effectively the user who is used to log into that system their rights and roles will be applied so you know if you have a set of roles in your Hana system when you access that that they will be respected through that connection from an importing model perspective when we import data the again the same rule would apply in that if we were doing import we were bringing that data in whatever roles were set for that connection type and would be respected at the time of connection but that would be it but we those we don't have the ability to take that and then translate that onto the model when it's been acquired so you do have to recreate that security on an acquired model question there yeah to mention that data always remains in the source system so how are we able to create models and reports on the data into cloud for analytics if you hadn't explained that before yeah that's so that's um that's so in the context of a lack of a live connection yeah the data absolutely stays on that source system and we just take the metadata so we can understand the shape of that data and then we use effectively it's beyond the scope of this presentation I think there may have been a data access presentation that would explain how we were then effectively we build a meta model so we know what's in that model we know the information measures for example there would have the values over there we can use that to create the content and then when that content is populated that data just moves into the back into the structures that have been defined within the browser on on on the customer landscapes that we never move that data up into the cloud for analytics landscape would you know the metadata like I say but we don't know natural values of ages the data remains on-premise we're not moving it up and then moving it back down it just moves within within the customer market so that's how that works we just have the structures that we maintain and then the actual data is used a live connection when that dashboard is open that dashboard content will be populated against that connection and that's what that data will move through to that structure to you would there be separate tenants for dev QA or production environments or will this be single instance directly for production yeah sort of question and I think ideally the answer is is it can be both Iife I've heard and seen of both type scenarios being used particularly if there's sensitivity in the data for example if you have you don't want your developers to necessarily see the production data and you you could set up dummy data in your dev environment and move that through to the QA and prod for the typical sort of management lifecycle management perspective equally I've heard it been that the people are happy just to have a single production environment and then maintain the separation of duties using the user roles and rights within the single system because some of the reasons they used a dev box was because they were worried their developers would you know bring down the production environment now in a multi-tenant it's off as a service solution that's that shouldn't happen you don't need to worry about the formulas you don't need to worry about the fact the developer can bring down the environment cause the elasticity of the cloud will hide that from you so in theory again you could just use a single a single environment so I think the answer is going to be it depends what you're most comfortable with and it's going to depend on on the type of landscape you're trying to create we certainly offer there's a QA type licenses if you require that so we can give you a we can spin you up those type of tenants that are used for non-productive use but you don't have to necessarily do that I think in this type of landscape I counted that one 