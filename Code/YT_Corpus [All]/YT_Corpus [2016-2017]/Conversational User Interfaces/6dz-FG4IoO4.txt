 Just to correct, I graduated in 2014, not 2004. Thanks everyone for showing up. Full room this year again. I'm hoping to get a bigger room next year. As it was said, my talk is about the future of interface design. Before getting started, here's some info about me: My name is Tony Aubé. I'm from Quebec city. I graduated in design at Université Laval in 2014. Since my graduation, I moved to California to work at a startup named Osmo where I am pretty much a everything designer: Interface Design, UI, UX, Motion, Physical, Marketing, whatever. Osmo is an AR video game platform for iPad for kids. I recommend having a look at our website afterwards. You'll see it's a truly unique product. Today's presentation stems from a year-long reflection where I ask myself the question: where is design going? This reflection led to publishing an article on TechCrunch which was popular and somewhat controversial So I'm using this opportunity to clarify and expand on my thoughts. Everything began a year ago, when I shared on Facebook that I thought startups like Magic and Operator were going to be the next big thing. That they were going to be the next step in user-experience design. For those who don't know them, Magic and Operator are startups who built their product offering entirely on a chat interface. For instance, Operator is an app who let you purchase things online. Just like Amazon except rather than using a traditional user-interface You just chat with the app Explain what kind of product you are looking for and get recommendations which you can buy Same thing for Magic Magic, unlike Operator, doesn't even have an app It's literaly a phone number which you can text right now and you can use it to get pretty much anything as long as it is legal and you have enough money. It's mostly an app used by millionaires. Justin Kan, Twitch co-founder explain on his blog how he use the app every day to buy plane tickets, organize events and even buy a Ducati To understand the significance of these startups it's worth taking a step back and look at the history of HCI. It's unclear which was the first computer but some people believe it's the Babbage Engine. Which was a machine built almost 200 years ago to solve math problems and print the result. It was similar to the Gutenberg machine except that, for the first time in history you had a machine who could produce any possible output depending on its given input. 50 years later, Punch Cards appeared. These were perforated paper sheets that were mainly used as a mean of storing data but eventually were used as a mean  to give instructions to computers. Here's it's interesting to see that you would literally code using paper and that most of the first engineers were actually women coming from the phone industry. Alongside WW2, we saw the first electronic computers appear. I don't know if anyone in the room has seen the movie "The Imitation Game" which showcase Alan Turing who was one of the father of modern computer science It's a really good movie, I recommend watching it. At the time, the way you would interact with such a computer was with the hardware. With a series of switches and cables, etc. Over the years, things evolved. In the 70s, we saw appear the  Command Line Interface - CLI where for the first time, computer interaction moved from hardware to software. This made interacting with  computers much more flexible Then again, the problem was that,  to communicate with computers you had to be able to speak the computer's language. You had to know a programming language. And despite all the efforts to  humanize programming languages they were still reserved for specialists,  people who could code. The GUI changed all of this. You probably know the story with Apple and Xerox. For the first time, you could interact with a computer without knowing a programming language. This innovation allowed to  democratize computer science everywhere in Occident and it's also a super important event for us designers because it led the creation of the UI designer job. In 2007, Apple revolutionized the world again with the touch screen and the smart phones. And just like how the GUI democratized computer science in Occident, smartphones democratized computer science everywhere else in the world. Today, it isn't rare to see, even in developing countries where people don't necessarily have much money or access to basic ressources but they will still own a smartphone because it is such an essential technology. When you look at the history of computer science we can see that it has been pretty much a constant battle to facilitate HCI Over time, every invention facilitating HCI led to a worldwide increase in tech adoption. Today we're in the top right corner of this graph. Just like Mike Monteiro will tell us this Friday: this is the golden age of design. Today, everyone wants a website, everyone wants an app. Everyone wants to hire designers. Furthermore, a recent research done by LinkedIn showcasing the 25 most in-demand skills worldwide in 2015 and 2016 ranked User-Interface Design at number 10. So it could be said that design is the  10th most in-demand job in the world. As a designer, this is really cool but the question I'm asking myself is for how long will it be like this? During today's presentation, I'll show a series of new technologies Artificial Intelligence, VR, IOT, EEG, who, I believe, will fundamentally revolutionize the way we interact with the screen and at the same time, revolutionize the interface designer's job. Let's start with Artificial Intelligence. Anyone in the room saw the movie Ex Machina? Very good movie, I recommend watching it. It is a science fiction movie in which a mad genius creates a robot endowed with artificial intelligence. And he wants to test his robot's intelligence with a series of tests. So he hires a programmer named Caleb to execute a Turing test. Again, Alan Turing, way back during WW2,  considered the possibility of artificial intelligence. At the time, he devised a test to express what he meant by AI. A Turing test is really simple. It requires someone doing a blind interview between two participants: a human and a computer. The computer's goal is to fool the interviewer into thinking he is the other human being. Unfortunately this movie remains science fiction and we can't create robots that look and act human enough to fool us. But we are now able to create AI in "Narrow Contexts" Narrow contexts are things which are simple enough to be fully understood by a computer. Chess is a good example of a narrow context. For decades, people said a computer could never match the human genius at Chess. But as history showed us, 1996 was the first year where a computer beat the world champion. And 2005 was the last time where a human beat a top computer at Chess. Then people said, Chess isn't that hard, but no computer could ever beat a human at Go which is a million times more complex than Chess. If you have been following the news lately, Google's AI just beat the world champion at Go. which was another major AI milestone. Another domain where we can do AI is messaging. It's another "narrow context" where we can create AI good enough to can fool people. Why is messaging such a good fit for AI, compared, for instance, to Siri? One reason is that messaging is already a digital medium Also, messaging doesn't carry as much ambiguous information as other mediums. Compared to talking, which include a ton of non-verbal communication, intonations, accents, etc. Messaging is much more straightforward. So it's not a surprise that since last year, a ton of new startups appeared who offer their product using AI and a messaging interface. We call these "Conversational apps." We also call these "Invisible apps" in the case where there is no app. When there is just a phone number or email address you can write to. and we call these "bots" if they live on another platform such as Facebook Messenger or Slack. Why did I brought up messaging and AI? Why is it something that matters to us designers? First off, the messaging market is huge. At the beginning, people didn't understand texting, they didn't think they would use it. But today, it's extremely rare to see a kid or teenager making a phone call. Everybody just text all the time. And if you thought that Internet was a worldwide revolution Well it doesn't even compares with SMS. For instance, in 2014, there was 3 billion people using Internet and at the same time, you had 6.3 billion people sending text messages every day. This is also why there is so much money in messaging. A few years ago, Facebook bought WhatsApp for $19 billion. WhatsApp is a messaging startup which, at the time, was just a few year old, and only had about 60 employees Do the math, 19 billion dollars divided by 60 employees this is a ton of value per employees. and if we look at the stats today, with WhatsApp nearing a billion monthly users we can see that $19 billion wasn't such a crazy amount. The second reason is that the App Store as we know it is broken. Apple is very proud to say they have over 1.5 million apps on the App Store. And that's awesome if you are Apple but if you are a developer making an app and you are trying to get downloads it is extremely hard to stand out among the million other apps. And similarly, on the user side Maybe you are like me.  I got a ton of apps on my phone. and I only use a handful of them in my day to day life. Maybe it's overkill to create so many apps for services I only use a couple of time anyway. The third reason is that messaging is a perfectly human medium. As I said, I already got a ton of apps on my phone and every time I want to use a new product or service, I need to download another app. Then I need to learn a whole new system of menus, buttons, labels, navigation, etc. Which gets really exhausting. Conversational apps, on the contrary, are always the same. Everyone know how to use messaging. It's very easy. A 5 year old kid can use it.  A 90 year old adult can use it. A huge benefit of conversational apps is that they make your product very accessible. and that is very important if you consider reaching developing countries such as India where people aren't really technologically literate. Here we'll see an case study of a traditional app  versus a conversational app. How it can become super useful in day to day activities. I live in San Francisco and I'm watching a Giants game. On the seat in front of my I can see an ad saying I can order drinks at my seat. With the current app ecosystem. What I would do is find my QR code reader. I would scan the code which would bring me on the App Store. Then I'll need to download the App. But the app was badly designed, it's huge. It takes 5 minutes to download over my 3G. Then I get a bunch of notifications. Am I over 21 years old? Yeah. Then I need to connect myself. But I don't have an account, so I need to create one. Thank god they don't force me to confirm my email address. Then I select a beer. I want a Bud Light. Quantity: 1. Then I need to enter my credit card information. Finally I can get my beer. What we see is that it took a ton of steps to do something that is ultimatly very simple: order a beer. In the end it would have been easier to just stand up and get it myself. Let's see the same situation with conversational app. Same scenario. Order drink from your seat. Text us. In a fictional future where Apple is doing conversational apps. I would just need to open Messages scan the QR code which would open a discussion with the Minibar bot. One Bud Light please. I make spelling mistakes. It doesn't matter. The AI understands my request. "One Bud Light, $8.95, Ok?" Ok, sure. Apple already has my credit card so I can quickly pay with Apple Pay. "Payment Confirmed. Your beer will be there in 5 minutes." Then maybe a drone would bring me my beer. We can see that an interaction that takes over 5 minutes with the usual App ecosystem become super quick and easy with a conversational app and I'm not stuck with another app on my phone that I will never use again. There's a rumor that Facebook will soon launch it's Bot Store which according to some people, might be as transformative as when Apple launched the App Store. The Bot Store will live on Facebook Messenger. It will allow developers to create their own AI bots which users will be able to download easily. A lot of people believe that bots will be the next platform. Looking at the history, we can see that every 10-15 years, a new platform comes along. From software to the Web, from Web to Apps and some of people believe that bots will be the next step. After having published my article on TechCrunch a lot of people reached out offering job opportunities to help design conversational apps. And the main question people asked was: "Tony, how do we design conversational apps?" And this is a great question because when you think about it once you are done designing the icon and you have chosen the bubble color all the Photoshop work is pretty much done. So I don't really have an answer for this question. You can have a look at some startups like X.ai whose two main designer don't even have a design background. One of them is an author, satirist, comedian. The other one used to be a theater director. Rather than create information architecture, maybe we'll be creating conversation architecture. Maybe we'll start using applications such as Twine to create branching conversation systems. Concepts such as Mailchimp's Voice & Tone will become super important. At every moment in the discussion, ask yourself, what is the user feeling right now? How can I best help him with a subtle choice of words and expressions? Everything related to branding will come down to the bot's personality. Again, with a subtle choice of words, the type of humor, the type of punctuation, etc. So we can see working on bots will change the designer's job dramatically. Why am I talking about this today? I think conversational apps reflect the beginning of a bigger trend which is a bit scary as a designer. It seems as technology progress, it is increasingly making the GUI as we know it irrelevant. Here are some of the new technologies coming up. I'll go quickly over them; I had to cut some content to fit within the time. VR, IOT, EEG. Virtual Reality is another very important technology coming up. It is backed by nearly every major tech giants. Facebook, Google, HTC, and even some rumors about Amazon and Apple entering the field. According to Goldman Sachs, the industry could be worth $80 billion dollars by 2025. This is an industry that is going to be huge,  it's going to create a lot of jobs for designers. I went to GDC this year, which is one of the biggest video game conference in the world and it was all about VR.  It was the main topic of discussion. One of the most interesting talk was "Menu Sucks" by Colin Northway. His message was pretty much  the same as what I'm telling you today: 2D user interfaces as we know them today, using menus and buttons, will need to drastically change with VR. For instance, Colin was working on a 2D game named Fantastic Contraption and he was given the task to bring this game into VR. The problem was that menu located at the top of the screen didn't work at all in VR. After a ton of failed prototypes they were ready to give up until someone suggested that the menu could be a cat that follow you around. This sounds like a silly idea but they tried it and it turns out that the cat was a much better interface that anything they tried before. So you have this cute cat allowing you grab tools needed to play the game. In the same game, the home screen is actually a helmet that you place on your head. When you wear the helmet, you arrive in a new world where you can select your level and then you remove the helmet, you are in the new level. In Job Simulator, another game you have this thing called the Exit Burrito. When you bite it, they ask for a confirmation, and when you finish the burrito you exit the game. All of those are fun examples but they reveal how VR has the potential to drastically change the way we approach UI design. 2D interface will go away. This is a super interesting field for designer because every design principles and design pattern have yet to be figured out. Another example, one of the engineers at Osmo created a virtual world for Reddit where every subreddit becomes a pillar with which you can interact. There are many more examples I could show here. I'll go quickly over the Internet of Things. Good examples are projects like Soli by Google which use radar technology to detect micro-movements with the hand and use them to interact with connected object without the need of a screen or GUI. Which brings me to EEG. EEG I believe will be the most transformational new technology in the future. EEG stands for "electroencephalography." which is a fancy way to say "reading the mind." And this isn't magic. It's very real. The human brain is just like a computer.  It uses electrical signals and with special sensors we can detect those signals and use them to communicate with computers. Emotiv is startup that I've been following for a while who make EEG helmets allowing to read brain activity. Again, this is very real. Here I have an example of someone using the headpiece to remotely control a Sphero robot. And if, like me, you are a fan of Science Fiction having grown up with the Star Wars universe this is extremely exciting Thinking that one day you could control the world around you using your thoughts. This is a technology that I have personally tried about two years ago. I was wearing this big headpiece and I was using my brain to fly a drone. How does this works? It's very similar to plugging a controller in your computer. If you ever played an emulator, there is always this step where you need to map buttons to in-game actions. A is "Attack", B is "Cancel", C is "Object" It was the same with the drone, but the controller was actually my brain. To control the drone, I had to think about stuff. Think about my hands to fly the drone. Think about my feet to move forward and think about nothing to land it. And this is a very weird thing to do. It's very unnatural. How do you think about your hands? Do you close your eyes and visualize them? No you need to keep your eyes open. Do you move your hands? No your hands need to stay still. It really takes a while to get used to this. And this made me think about seniors who are completely lost when it comes to using an iPad. While I, having grown with technology, find it very easy to use. When using EEG for the first time I really felt overwhelmed. It's going to be funny seeing kids grow up with that kind of tech when they come back home and use their brain to open the television, open the Playstation. and we're going to think "in my time,  we had iPhones, it was much easier" Right now, EEG is mostly used for research and medical purposes. It has a lot of potential to help disabled people but I'm really looking forward for the company who will do the same thing Apple did with the computer in the 80s and will bring this specialized technology to the masses There's a great quote on Twitter which says: "Your UI is your product's humble compensation for not being telepathic" And this is completely true. If you think about it: the sole purpose of your UI design is to give a product or service to your user. It's about solving their problems. So what happen the day when your product can literally read your user's mind? When we can solve their problem without the need of a screen or GUI? Which brings me to the "Technological Tiller" idea. This is a concept that was explained by Scott Jenson at CHI 2014. Tiller is an English referring to the bar  used to steer a boat. For centuries, this was the main method of steering something. At the time, people were also using horse carts to move around. Then, the first automotive cars were invented which didn't have a horse to do the steering. A bunch of designers had to figure out how to steer a car without a horse. They looked left and right, saw the boat tiller, and thought, there you go! So the first car literally had  a boat tiller at the front to steer. And you can imagine, this was a disastrous design. Cars were extremely hard to control  and very prone to crash. The designers quickly had to go back to the drawing boards and they came up with a revolutionary invention named the steering wheel. And this probably one of the best  design lesson I've learned. Whenever we're confronted to a new technology as designers, we have the bad tendency to look for existing designs and just copy-paste them on the new technology. What the technological tiller teach us is that a change in technology usually requires a new design approach. Businesses who understand this usually have great commercial successes. Apple is probably the best example. Think of the first phones designed for messaging. What designer did is that they looked left and right they copied the idea of a plastic desktop keyboard and simply pasted it on the phone. On the other hand, as Apple showed us the better approach was to create a digital keyboard which could appear, disappear or change shape as needed. Same thing for the tablets. A lot of people critisize Apple saying they never invented the iPad Microsoft did it 10 years earlier. But has anyone ever used Microsoft's first tablet? No. The tablet failed because it was badly designed. Microsoft's designers were given this new technology and they simply copied and pasted Windows XP on it which led to a horrible experience. Apple designers, on the other hand, understood that this new technology required a different design approach which was, in this case, to build  a whole new finger-friendly OS. And today, I believe the technological tiller is pasting an iPad screen on every new IOT product. whether it is a watch, a fridge or a trash can. I've been following a Twitter account recently named "Internet of Shit" who makes fun of every new silly IOT products such as this interactive wine bottle. As a designer, it is important to internalize that the UI isn't the final product. Design is not the point, it's simply a mean to get the product or service to the user. After publishing my article, I met Golden Krishna who is a design strategist at Google. He wrote a book namd "The Best Interface is No Interface" He pretty much have the same conclusion as I: As a UI designers, we have this bad tendency to solve every new problem with a UI. But we're in a world which is slowly moving away from GUI and screens It will be crucial for us to gain some humility and understand that a GUI isn't always the best solution. What future for UI designers? Recently, I made the strategic decision to quit Web Design. I was working in a Web Design agency in Quebec and I was charging 5 to 10k to design someone's website while services like Squarespace, Wix or Weebly were offering fully designed and coded websites for less than a $100 per year. I didn't see the point of doing this anymore. I don't know if any of you have heard about The Grid? It's similar to Squarespace as it let you create custom websites for cheap except that it uses AI. How it works is that you just give it your logo, your images and texts. You tell the system what is the purpose of your website. Is it a blog? Is it to sell? And the AI will actually design you a website taking all of your content and goals into consideration. This kind of services make me think about Uber and Google AI powered self-driving cars which are making taxi drivers freak out. Rightfully so. As designers, it's easy to think that this will never happen to us because we have "creative jobs." but what we're seeing is that over time, tech is increasingly taking design market shares. "Tony, you're telling us that we're all going to lose our jobs?" No It's important to take a step back and not take everything too literally. Most of the technologies I've shown are about computer input. They will perhaps replace buttons, menu and forms but there will always be a need to design for output whether it is data visualisation, entertainment, etc. The big take away from my presentation is that as designers, its important to understand that the GUI is just one step in the lengthy process of humanizing HCI. There are other steps that will come after the GUI and as designers we'll need to adapt to those if we want to remain relevant in the future. If anything, this will force us to focus even more on UX. This transition has already been going on for years In 2004, if you had asked a designer what was his job he would have said that it is to make things look good. And today, especially in the valley, he would say that it is about making things delightful and easy to use. So I would suggest that you try to step away from Photoshop and Sketch. Leave your interaction pattern book away and try to get a higher level view about your job as a designer. Try to think about where it could go in the future. And always think of the Technological Tiller. Ask yourself the question: Am I designing this interface because I'm a UI designer? Or am I designing it because it is truly the best solution to the problem? I'll conclude by talking about collaboration. which I believe will become extremely important as technolgy progress. Designing for conversational apps will require collaboration with authors, psychologists and linguists. Regarding VR, there is so much we can learn from architects who, for centuries, have been thinking about how to design spaces to make people feel certain emotions. Same goes for interior designers. IOT. Probably we'll need to collaborate  with fashion and industrial designers. EEG. Who knows? Maybe Neuroscientists? That's the end of my presentation. There you have my contact info. Osmo's website. If you want to try out Osmo come and see me later. Also tomorrow I'll have a EEG reader if you want to try the brain reading tech. Thanks everyone for showing up. If anyone has questions, this is the time. We have a microphone. Any questions? Here's a question. My question is about conversational apps. Quiet please. I tried conversational apps a little while ago but they weren't easy to use. User were usually lost and didn't know what to do next. They were very confused by the lack of buttons. How would you solve this? Good question. I went a bit quickly on conversational apps because I was afraid I would be short on time. But you're right, one of the biggest challenge with conversational apps is what we call "discoverability." Most types of affordances are lost in a chat interface. Buttons and menus usually help to guide the user within a normal app. When a conversational app is badly designed it's easy to get lost because you have a blank page. You don't know what to do next. And because AI isn't quite there yet you might ask something and it won't work. The key is to always start the conversation. The bot should always begin the conversation and it should give tips and hints about what kind of input it expect. We call these conversational app and they use a chat interface but you can always add buttons and quick actions I forgot the name but there is a startup specializing in designing interactive conversation with a series of widgets. I'll try to remember their name and tell you later. But don't limit yourself to the idea of a chat interface. There is a lot of room to innovate here. For instance, when you share a link on Facebook Messenger you get a smart preview of that link. That's a first step in making richer chat interface. and it's going to go much further in that direction. Any other questions? Very interesting presentation. I'd like you to talk a bit more about these conversational apps can it be a good approach for the entire retail market? No No? Because last year you wrote about Operator did it evolve since last year? I haven't heard of them recently. I'd say that there are a few issues with Operator. One of them is that the AI isn't quite there yet. It could be argued that using Amazon is still faster and more efficient than Operator. That's why it's important to take a step back. Not every app will become conversational by tomorrow. It always depends on the use case. Bots are great for micro-interactions, micro-transactions. For instance, I wouldn't see a conversational app to read my Facebook news feed. But then again, a year ago I would have said I wouldn't see a conversational app to read the news then Quartz came out and I use it almost every day. So I guess nobody knows. It is the designer's job to think of the use case and come up with the best solution. Hi, I'm a Back-End developer. I have an observation and a question for you. It's funny that, in the end, we come back to the Command Line Interface. Maybe we have AI that understands us better. So it's like a CLI but better. This is a funny loop. We went all this way to come back to the CLI ultimately. That was my observation. My question is: rather than have a bunch of bots... Everyone has seen the movie "Iron Man." Have a JARVIS? You could ask him anything. Ask for a taxi at a specific time. Are we not going to get some sort of "master bot." That was my question. About your observation: it's entirely true. And it is kind of funny. But ultimately it all comes down to humanizing interfaces. As you know, the first programing language were shit. At the core it was binary which was super hard. Then they built on it. At some point you got Fortran which evolved into other languages as they tried to humanize them. When it wasn't working, they came up with the GUI. The entire desktop metaphor was also a step in humanizing HCI. You have a desktop, a wallpaper, a trash can. And now, conversational apps are the next step in humanizing interactions. You will be able to chat with your computer the same way you would chat with a friend. That's why I believe in this tech. And that's why I believe in VR too. VR is another big step in humanizing HCI. Interactions on VR will feel truly human. You could interact with a computer just like you would with any human. And hmm... I forgot your question. What was it? My question was, rather than have a bunch of bots... Oh yeah, the personal assistant. Mark Zuckerberg from Facebook gave himself the challenge to build a fully functional personal assistant by the end of the year. When I mentioned that Operator and Magic were the next step in UX, I believe the next logical step afterward is to have one bot to which you could ask anything. You could request a ride, a room, some food, etc. And the bot would take care of all the logistics needed to make this happen. It would be the middle man between you and services such as Airbnb, Uber, Sprig, etc. So you can get a seamless experience no matter what you need. I think it's going to go in this direction. But then there's a lot of conflict between all those companies. Who is going to own this magical app? Will it be Facebook? Will it be Apple? Will it be another startup? It remains an open question. Thanks everyone for showing up! 