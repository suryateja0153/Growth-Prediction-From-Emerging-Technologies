 (music) - So, yes, in the interest of time, I'm going to skip through some of the slides, but I want to give you a good impression of what we're doing. So, we're working with actually Boeing, who's established a secure mobile platform, and we'll get into where that comes in. So, this is our team, including our Boeing subcontractor. So, the use case is really to continuously and unobtrusively authenticate a user to prevent unauthorized use with minimal drain on power and computing resources. So, this is a physical intercept of a phone. An authorized user may have a phone, it's somehow taken and the phone needs to identify based on behavior of the person mostly elicited from device sensors, inertial sensors, specific signature that is different than the user signature. So, our approach is really threefold. The first stage is, we realize to achieve the low power and the efficiency of being able to do continuous authentication, we need a different hardware solution. So, HRL's developed a neuromorphic chip, which is basically a chip that's based on neurons, artificial neurons as the computing units, rather than traditional transistor logic. So, these act as spiking neurons, which mimic the neurons in the brain, but they are at much larger scale. This particular chip has 576 neurons compared with the brain which has billions. But, there are really nice emergent behaviors that come out of this, and it's also a package that runs at extremely low power, like the brain does. It runs at roughly 50 milliwatts. So, this can be on as a separate processor. Sort of as a neural processing unit that is running independently of the CPU on board the device. So, its application's much different for low power, very specific detection of unauthorized use. I'll skip that slide. So, this is just more detail on that 1st stage. The cell phone sensors would transmit to this neuromorphic chip. We actually had a demo on Wednesday showing this, through a wireless connection. The signals from the sensors are converted into spikes for the neuromorphic chip spikes, are how information is encoded on a neuromorphic chip, intervals between spikes. And then, our 2nd stage uses essentially standard computing platform, the CPU on board the device, to do additional sort of filtering out of false alarms using what's called early-warning signal, which we have a number of publications on that. The basis of that was an IR program called Open Source Indicators to look at correlations between usages and Twitter feeds. So, our benefits are primarily this low-powered neuromorphic hardware, which we think is really a critical solution into doing continuous authentication on a device without draining power. This early warning system, which needs essentially continuous pattern classification in multimodal time series data. So, it's very efficient at making classifications on multidimensional time series data. And then, the other thing I didn't talk about is neuromorphic plasticity. So, built into our chip, this was developed for the DARPA SYNAPSE program, was a unique capability, as sort of a Hebbian learning that the brain uses. So, in standard software artificial neural networks, there's some back propagation scheme that's used to determine weights based on training data. This neuromorphic plasticity, it's called spike-timing-dependent plasticity, works online automatically as training data is coming through the chip, so there's no necessity for off-line learning, or computation of the weights. The weights arise as a function of this plasticity, which can be summarized as neurons wire in correlation to firing patterns. I'm gonna skip through the competition, and get to some of our results. So, already tested some. We've been operating for about five months. We've developed some test data. Boeing's developing some more extensive subject data with a number of use context. This was primarily gain, and this was going through our 576 neuron chip, and doing a classification. So, it was setup as a liquid state machine, as a recurrent network. And it was, actually quite successful in distinguishing between individual users. So, for each time interval, a different user had the phone, and sort of the higher the classification signal, that was the prediction of the user. Now, ultimately we don't have to do like a classification. We have to do something that's a bit simpler that's an anomaly detection. I'm going to get to the questions after this slide, because we have a limited amount of time. But these are results of our early warning signal, which is looking at accelerometer data of people while walking with a phone. There are four different users corresponding to the colors, so everybody walks at a roughly the same frequency, one hertz. But, as you look at these higher harmonics, if you look in the frequency domain, you get more separation in these higher harmonics. So, this is just relative to walking with the phone in your pocket for example. We had an over 90% accuracy rate in classifying users. So, our final slide, and I'll kind of quickly go through our next steps, and our integration with the Boeing Black platform, which is an Android-based system that has a lot of layers of security and trust built on it that we want to leverage, and we have a transition plan to actually migrate the chip into a much smaller board that currently have integrated on the Boeing Black as sort of a neural processing unit that acts as the 1st stage of this anomaly detection. (audience applause) (music) 