 they're developing capabilities for open flow sdn for programmable networking so that's another reference architecture and this is some of what we do with this each color represents a different science research domain doing different kinds of experiments successfully all segmented so that the experiments don't if you interfere so there's a lot of benefits to sdn I'm not going to talk about them because by now I think that they're pretty well known you get granulated views in the network you get enhanced capabilities for controlling those views and much more so Sdn is eating the network world an issue though is that it's a single domain oriented architecture and set of protocols so motivations exist for sdx to first of all interconnect sdn Islands you also get better engineering because you get granulated views into all flows through an exchange and you get control over those however having operate in NS DX for two years we discovered something else which is that we can create a high degree of customization for individual science domains within an STX which is essentially a large-scale virtual switch so we've been developing api's into this capability we've been developing capabilities for multipath Federation controller signaling topology exchange services and much more an s DX is a large-scale recursive virtual switch within which you can create virtual switches and that's the big important thing because each of these switches can be a private exchange for a private community so one of the communities we've been dealing with to showcase this capability is a joint project with the University of Massachusetts at Amherst they're developing an application called now casting now casting unlike current radar is based on small form-factor radar so they can see over the curvature of the earth and they can see the weather in now-time versus predictive time however they generate so much data absorb so much data that you can't compute it locally analyze that locally visualize it locally store it locally so you have to send that raw data out across the nation at very high speeds on the left here you see the granulated views that they get and it's a more of a near time view it's more like six minutes versus 12 minutes versus the old form factor Doppler radar it's a very effective technology what does networking have to do with this well it uses an ongoing constantly changing topology and this is a demonstration that we did with a prototype sdx in Georgia for a gec a genie engineering conference early last year this is dynamic provisioning of topologies with the radars on genie racks simulated over three fiber-optic networks yes net the I 2 al 2 s and the Oak Ridge National Lab fiber network the constantly changing topologies or excessively signaled using Sdn capability so as weather moves you need to change the topology so this showed an exchange doing constantly millisecond by millisecond changing topologies we've also been working with amsterdam netherlands and surf net they also have a prototype sdx for last year's tarina we did interoperability demonstrations this year we also did some demonstrations advanced of this conference to report results back which we're doing this time we'll use the AAA as a data plane and we used our existing control planes we're going to continue to develop this also internationally last year we worked with Siberia and this year we're also working with them and Barton at the end of this talk will talk about this demonstration for the glyph last year the annual conference in Queenstown Australia of Queenstown New Zealand we set up a multi-country data plane to see if we could scale that Network prediction application worldwide with sites in a variety of countries again using simulated radars in Jeanne racks and this is the imaging that resulted from that there was another successful experiment with the University of Tokyo we're working on an interesting thing called a slice exchange so so far I've been talking about an STX as a communication exchange we're extending that concept to allow for software-defined networking infrastructure to also be included so that you can have other kinds of resources beyond communications extending across these exchanges this is a block diagram on this project for supercomputing last year we had the question can we also control very large scale science flows with sdn we had a showcase at supercomputing to do exactly that flows up to 98.4 gigabits per second as individual flows controlled by sdn they have to note later speaker rod here from siena helping us out with one of the nice test beds it's 100 gig testbed this is some work that we've been doing in this area with the Goddard Space Flight Center and notice in the lower right and here are servers with hundred gig Nick's so we're doing end-to-end hundred gig flows across the wide area 0 packet loss long duration controlled in part by sdn technology and this is yet another one of these this is a hundred gig SD SD X experiment we're building an international set of these capabilities or working with the number of people in a variety of countries one of the driver apps that has focused our attention recently is this one this is the core infrastructure we have been working on hybrid topology exchange capability so that these different s DX's in different countries can both segments the slice exchanges and control them with appropriate policies to showcase what these can do again with science beyond the instrumentation radar demonstration we put together this we created a custom sdx within the virtual sdx strictly for bioinformatics to show a use case for personalized medicine so it's customized medicine enabled by precision customized networking imagine this as a large-scale virtual cancer center as supposed to a physical cancer center that can serve patients around the world including those requiring data flows so the data that's required to do this application has been stored in repositories around the world not just in one country not just at one site but around the world and to do customized medicine you need to find that data integrate that data do very complex workflows that normal exchanges simply can't do they can't support that what we showed is by using this virtual exchange with sites around the world including the genomic data Commons National Institutes of Health the ontario institute for cancer research the european bioinformatics institute you can set up an effective capability for doing unique customized medicines for unique individuals this is a very different model than the current medical practice and these are some of the flows he's a very large scale file flows so thousands of small files hundreds of extremely large files in very complex scenarios we're also going to integrate this with some cloud test beds this is one called chameleon we're standing up distributed cloud testbed for computer science research and this is a bit of a shout out to our friends at es net who have a an SDN testbed that's in our facility we're going to work closely with them because they're doing really good work in this area also they've pioneered something called science DMZ there's a whole other discussion on what does a science DMZ have to do with Software Defined Networking unfortunately today we don't have time for that but i just thought i would mention it it's a very cool topic another issue is the National Science Foundation has something called the international research network connections program we've recently been awarded by the National Science Foundation funding to create an international sdx to work with other st exs around the world specifically for large-scale data intensive sciences and we'll be doing that with many members of the tarina community these are some of the participants and with that I'll say thank you and I'll turn it over to Barton to finish up and talk about your yes yeah let's see if we can we can't get it back that way so close there we go up done so thank you Joe jeez i love that example with the personalized medicine just the potential okay how's this perfect all right so I'm from sabara in Alberta Canada and a couple of years ago we were looking around for some project to do with Software Defined Networking we recognized its potential and our organization we don't have much interest in inventing new technology but we really like taking emerging technology and actually working with it and building out pilot projects so we built this software defined networking test bed it's we wanted it to be multi-vendor so we can experiment with switches from the different vendors try out their support for for open flow we work closely with the the universities across Canada and we've had this test bed more or less in place for about a year now but it's been in a state of constant flux constant constant change the sites we have a site in in Ottawa a site in two sites in Alberta at University of Alberta and university of calgary and another site out in victoria and all the sites are connected through the single layer to network on on canary the sites are connected we've got we're using MX 80 routers from juniper and pika aight switches the MX 80s are operating in hybrid mode and that was well that was why we chose the MX 80s and connected to each site you can see that we have a small openstack cloud it's a very small openstack cloud it's basically just a cloud controller and a single compute node it's enough to for someone to to get to that node and create a half dozen virtual machines or whatnot and try to do something with this something practical with this software-defined Network what else can I say about it we we have a practical focus for the work with this test bed we're trying to reach out to to network engineers more than network researchers necessarily the entire network is bookable we're looking for people who want a software-defined networking test bed they want to try software-defined networking to see what they can do with it they can contact us and arrange to have access to some part of the network or all of the network and try to do something with it as and as geo mentioned in a other slide you can see that we are we have peering with the surf net and with with I care and I I think that's about it if you have any questions about this or you're interested in in working with us and doing a project on this test bed please let me know or contact Joe and he can get to us and we can start talking yes consider this an open invitation to everyone we want a worldwide sdn fabric in this case not production but rather for because we want to test ideas with all of you worldwide as that's why we're going to have a lot of well there's a lot of ideas in this space nothing is really solid it's not quite production yet it's going to be a while before its production so start your test bed get interconnected get some fine folks to try new things including radical ideas and let's do cool things thank you thank you to you will d server some kind of price on don't go don't go that is here Joe wait one second maybe someone wants to questions shoot so any question to you so what about the end not have to do with the sauce yes oh did you- for the air for the people of is changing I have a question about this as the EAC's so is this your interface for example to other domains connecting also further tests as the enticement environments or cloud testbed environments or is this interface or a appearing appearing point that you will negotiate or exchange or sharing resources from one organization to the other one or from the private sector to the academic sector for example the answer to all those questions is yes with the possible exception of the one question about commercial domains okay we're not quite there yet the closest we got to commercial domains is that joint experiment that you saw in Queenstown at the time we were doing that experiment google had their center of SD xrd in New Zealand and worked with us on that project and for them they said look Sdn is saving us tens of millions in our data centers tens of millions are wide area but we need to get out of these islands we need to have an SD X and that was the center of their development so we had some discussions about that but we really haven't dealt with the commercial side the guys in Georgia at Georgia Tech are doing that they're trying to stand up an STX that will serve the ISPs but that's not something we're doing yet I like your other questions though it gets basically what they highlight is the fact that within its DX it's all software so it's infinitely expandable infinitely unlimited and you could do whatever you want so yes through SDI software-defined networking infrastructure you have the slice exchanges so imagine if you will a bioinformatics researcher going into an environment saying i want to see spread out before me all my data worldwide all my tools all my analytic engines almost everything right and not worry that there's even a network that exists not worry that there's an exchange there it's just one fluid environment you could do that with this sdx and that's that's what we're building toward it's not production yet but we're moving it toward production a small additional question would you also allow other connectivity than layer two weekends for example layer one for example lay a tree pre fruit or yeah yeah that's another good question because our background is one in layer 0 layer 1 layer to development as opposed to layer 3 so definitely a big yes 20 one and two is that's where NS I got started glammed exchange right we do a lot of work with with layer 2 provisioning with layer 3 the answer there is yes to accept we don't do a lot of that but we work with people that are doing a layer 3 tunneling of various types and it perfectly maps and sdn gives you a very very rich set of tools to define flow specifically into flow spaces using not just destination addresses but source addresses in you know infinite numbers of combinations you can almost say the issue here with sdn is we have too many tools and too many options because it's infinitely rich that's so for you know so this is the big revolution going from network as basically hardware with a little bit of software there to basically software with some hardware resources someplace but you're really concerned with that software it's a great revolution thank you thank you how since anyone else I have a question looking at this diagram maybe it's for you and I'm not sure who of you would be a it is about the again I made a similar question in the previous session it's about the security model when you put here the openstack cloud the collaboration among the different sites are based on on the OpenStack access control or are you using something different you can come here the short answer is that we haven't gotten there yet to to really work with that very much we are not exactly sure what the best security model for working with the OpenStack clouds particularly in virtualized applications in general with the software-defined networking so sdn gives you an opportunity for two things one is significantly more enhanced security an absolute disaster you have you have both options because you're you're creating control channels that not only our control channels for network operators super secure no lat but control channels where you're saying I'm handing this off to whoever wants it not willy-nilly it's under policy but still you're giving our way control channels to resources so it's a it's a tricky business and it's all the Rope we were good it's all the Rope you'll ever need to hang yourself but you see this sort of happening in the genie environment where genie is a distributed environment where students are creating their own national international networks using their own protocols so some are saying we don't like TCP we don't like IP so we're going to do whatever protocol want those are personal networks so they're creating personal national international network this is going to escape from the computer science community to the wider community good luck to all of us security well that's I guess the other thing that I should point out is most of the projects that we've been running in the in our OpenStack clouds they they haven't really required a high level of security so there's been nothing that's really demanded us to to to address a lot of the high security issues yeah but under you just are thinking about commercial interactions and this kind of stuff Bonnie which is not criticizing the approach is it's better to show that you are able to do and then well but dude you have to be aware that this is the kind of of task that you should well engage with the sooner the better and this is simply that and it was curious if you were running some kind of experiments already or not of this is enjoy and your agenda for the future yeah not yet i mean i think the the security is that serious concern it's just not hasn't come up to the death of our priority list so okay okay thank you thank you so much well no speaking next speaker is precisely going to talk about another key kind of application which is precisely about security sorry security common traffic engineering is a dishonest area for the University of the Basque Country so my name is Jason estava and I'm going to present the the impact framework which is the outcome of the dim pack open core project the main goal of dim pack is to provide disruptive layer to end to end connectivity services like for example the end Blues on top of a pure as the end up in flow infrastructure that is the impact allows users to request bidirectional layer to services and with a warranty bandwidth for that aimed impact implements another traffic engineering algorithm in fact do all of you know that traffic engineering is one of the most promising applications of SD ends mainly because of two reasons on the one hand having a centralized control plane allows taking routing decisions better inform having real-time knowledge about the network topology a monitoring information and on the other hand the programmability functions of SDN allows to automatically program in the network devices the routing decisions taken at the contour plane level so these novel connectivity service we provide a lot of benefits both to networks and to network administrators first of all thanks to the logically centralized control print a network monitoring will be improved as it will be possible to have real-time information about the Nagar estate and also thanks to this it will be able to to make a better use of natural resources additionally also the impact also provides resiliency against network network folders and quick response times in case that data a link goes down in case of a of a service disruption because ad impact allows to to detect network failures more easily and to react to them as already mentioned thanks to the programmability capabilities of SDN the impact also allows to save costs in operational management as services can be managed completely automatically so traffic engineering is not a novel research issue in data networks and so far quite a lot of algorithms have been proposed based in there based on the minimum cost multi commodity flow problem the main goal of this optimization problem is to compute paths between two endpoints of a data network while a meeting traffic demands minimizing network congestion and also optimizing the utilization of natural resources the basic idea behind many of the proposals or all of them is to split traffic over multiple multiple paths between a given source and destination / however although it has been extensively proven that this multiflo multipath routing allows to make a better use of bandwidth compared to the commonly used certain spot first algorithm there are in reality there are not a lot of implementations of such multipath routing algorithms the main issues common to these to these proposals is that on the one hand usually they required to split traffic arbitrarily and instantaneously at any point in the network which is not a easy to at issue in practice and on the other hand traffic or packets route over different paths usually suffer different delays and therefore reordering must be performed in the destination entity at this point it's worth mentioning one success case which is girls implementation of a centralized traffic engineering deployment in it before prevailed one with this deployment google has achieved two to increase the use or their links from I think it was about forty percent one eighty percent and to save a lot of money this way but Adele Goering they propose it's well it's very adapted to Google needs and they benefit from a priori knowledge of incoming traffic demands and full control of the network so well the impact provides is the ability to dynamically compute paths between two infants in the network and also the impact it's a very powerful tool to make an efficient use of network resources because it allows to make room when a new service is requested it was to make room for the new service either moving already established flows or even trying to disaggregate to a split ongoing services and to move the resulting so flows with being a smaller are more easily accommodated in the network the impact also provides Network resiliency and quick response times to to network failures in order to achieve certain response times the impact a uses precomputed backup paths we we compute totally disjoint paths from the primary path and it distinguishes between two types of services regular services and gold services the difference between both of them is that for all services bandwidth is reserved while for regular services no banquet is reserved for backup paths so the vaca path might be only implementable if enough resources are available in the network as I have already mentioned a thanks of the use of SDN the operational costs can be reduced as a service management can be automated and we also improve network monitoring by implementing a monitoring module we obtained real tiny information about the real of the network state with a flow level and granularity so the impact framework has been implemented using modular and flexible approach and defining standard interfaces between the models it consists of in fact that impact framework consists of six modules which are the impact graphical interface a graphic user interface the monitoring module the impact service manager the impact routes manager PC and impact our rep a handle dim pack also implements an interface to an external entity which is an entity with categorizes traffic and we have called the traffic pattern analyzer we have developed the impact based on the opendaylight network controller which is a powerful SDN controller and which provides multiple selves and interfaces among them open flow 103 and for the implementation of the impact modulus without reduce some of the functionalities or some of the modules or provided by opened island okay the Linpack service manager is the core module of of the impact as it acts as a coordinator between the rest of the impact models when a new service is requested from the graphic user interface the graphic user interface tells the impact service manager about the characteristics of the new service basically it tells which are the endpoints the day source node on port and they out out port and note and it also provided also informs about the bandwidth that should be reserved for the new service the Olympic service manager tries to accommodate the new service in the network without affecting already established flops but in some cases it might not be possible in that case that impact service manager tries to move already established services the whole the whole flows without splitting them to other locations to other alternative paths in order to make room for the new service request but maybe that is also no possible so that impacts service manager goes a step further and tries to split ongoing services into a smaller ship flows which being a smaller are more easily accommodated in the network and can be more easily moved to alternative paths all of this with the final aim of making room for the new service request the impact service manager also listens for the political changes and if it detected that a link goes down it identifies all the services that are currently being provided to that link and moves all those all those services to their precomputed backup plans the impact service manager also communicates one day with the dim pack rules manager in order to tell that impact or smaller manager with control messages should we should be sent in order to program the network devices and it also performs scheduling functionalities since different services have different durations and there won't be always the same amount of services or of the or same combination of services in the network so in order to manage the the different network estates during time we define what we what we call network as an absence a network as an upset represents a group of services which are concurrently routed through the network so in the example at the beginning with avid years service egg and service a constitutes and networks naps as an upset then another user or the same one request another service which is service be and service be stars before service a and finishes during service a so as a consequence of introducing service be in the network 38 snapshots are computed in the first one yes sis service be in the second want coexist service am be and in the last one we have just service a so when the dim park service manager has to introduce a new service in the network it has to check that there is a positive solution or that the new service can be provided in all the network as an absence that it it effects and maybe the solution might be different for Anna snapshot maybe it requires not having to do anything not having to do to move any any service and for another one it might be necessary to move some services for a third one it might be necessary to decelerate send traffic the solution doesn't have to be the same for its functionality and impact servicemen a year manit managers independently network a synopsis and services and it maintains two databases 14 as an absurd management and another one for service management in in the one related to a snapshot it stores information about the staff and time and basically about this services that are provided in that a snapshot in that would regard to service management e-stores whether its service is a gold or regular service and it also stars the different links its service is routed through or the path of its service so when the link goes down it is able to easily identify all the services that are affected by that network failure the path computation element well we have implemented our own path computation element but it could be impacts has been implemented in a very modular male manner so it could be replaced by any other algorithm in our case this element confused computers at bootup time all the possible paths between all possible ingress and egress points in the network and the dim Park Service meijer when it has to accommodate a new service in the network eat it queries the pc for all the possible paths between the source and destination points add these path computation elements implements also the traffic this aggravation algorithm this traffic disaggregation algorithm is only call when there's no possibility to accommodate the new service in the network not without doing anything and not by moving established flows yes why moving them and we understand that in operational neighbors it's better not to move traffic or the paths the wood traffic is forwarded so the this deceleration algorithm prioritizes not to have to split traffic or it twice to a split the lesser it can so it identifies which path is closer to the required bandwidth and starts trying to move or to disaggregate traffic in that path in order to make room for the new requested service the impact rules manager is the module that translate the control options computed by the dim park service manager to real open flow control messages and it is based on the OTL the flow path of amer service the impact monitoring is the module in terms of providing real-time information about the network state as the users request request services specify an a warranted band with a desired warranted banquet it is mandatory to monitor whether then the these services comply with that request our bandwidth or not so we we have a monitoring module with tracks flows flows that are far from their maximum allowed bandwidth are monitored as at a slower pace and when they get closer to the maximan allowed bandwidth they are monitor with more quickly so this monitoring model is based on the statistics messages of open flow 123 and it makes use of the statistics manager module of opendaylight then we have an arab arp handler modi we avoid having to insert unnecessary a year p related entries in the open flow switches and it replaces the air p hundred model of odl that impact graphic user interface has been introduced in odl as an extra tab to the to the OTL week and it allows to request and delayed services in order to request the service the user must specify the source no destination no then they ingress and egress port the start time and time and also the bandwidth over the information such as for example MAC addresses could also be provided but are not mandatory and that impact framework provides also information about the requested services whether they are we sir they activated they have been deleted etc so for you to have an idea of how the impact works and what it looks like I'm going to play a short video in which we saw a little demonstration of the welcome to the dynamic path computation framework demonstration welcome to the dynamic path computation framework demonstration the impact isn't end up incorporate lead by the University of the Basque Country one of the main features of the Dean Beck framework is that it provides resiliency in theme park gold services are gonna deal with a backup path in case of link failure this bucket bath is automatically installed on the network here you consider the polity that we are going to use to demonstrate how the resiliency works in the impact framework first of all we are going to check that there are no flows installing the devices this way when we request that the impact service we are going to see how it automatically programs the devices on the network in rhetoric west of the impact service we need to specify I mean and we also need to select the source and destination nodes and the ingress and I were sport we also need to specify the duration of the service the impact is going to check if they are resources available for the requested service in the entire period of time that we specify we also need to select the bandwidth that we want for our service and specify the source and destination MAC addresses that they are going to use to characterize our service in the network in addition we can also select if we want this service to be a gold or regular service as you can see the circus has been requested and when we go to the team pocket terminal we're going to see how this request has resulted in the generation of onion snapshot for this specific service called service back up now we can check how the service has been properly installed in order the basis of the network the impact selects the shortest path for the services so in this case the service has been installed in the city's 16 and for the link between suite 106 goes down didn't lock automatically reacts and installs the new service in the network now if we check we can see that there are no flaws in style in suite 6 and instead flows have been installed in switch 2 and 3 the nimpah framework supports service scheduling thanks to its time-dependent resource consumption awareness in this second demonstration we are going to show how two different snapshots are generated in the impact framework we are going to use first month for quick service requests first we are going to reserve service a definite go to the timp a terminal we can see how the snapshot has been generated here we can see that I'm missing a exist in the snapshot then you've will request so this be one we're going to see how a different a snapshot has been generated which includes service a-and day one maintaining the previous a snapshot now to buy the venture were only service a exist if we do the same with services b2 and b3 we are going to see how the three services are requested this services are using the same resources but they are doing it in different time a slots game pack is clever enough to figure this out and creates different snapshots we can see how in these near snapshots service a and B to exist and service a and B 3 exist but B 2 and B 3 never exist together finally if we waste a sunless sea of the same duration of service a we are going to see how all the effect of the snapshots are updated in order to optimize network processor utilization the team back from work implements a photo segregation algorithm for this demonstration three services have already been requested to the impact framework service a of eighty rabbits service big of a deal of it and salvation sea of CNG hobbits dim pack assigns the shortest path to the services taking into consideration the resources available in the network service a goes from switch one to search for through its shortest path settlements be goes also from switch one to switch for but from an alternative path and service see goes from switch to to switch for we can check how the flows have been programmed in the network device ince which one we can see how the flows of service 11 service to our installed we can also check how inserts to the floor entries of services B and C exist with this situation if we request asad st from switches to to switch for with nine gigabits per second we don't have enough resources in the network to allocate it unless we desire it in this cases that impact framework cause the pan competition element understudies how the services installed in the network can be disaggregated by using the information available through the traffic pattern analyzer interface in this situation the path computation element it's telling us that by disseminating service be we can make room in the network to allocate this new service now if we check how the diocese our program we can see in switch one that service be has been dissociated into three different sub services thanks to the OpenFlow tonality and now we are able to allocate this and st so that's a going back to the presentation but now that you figure out how the impact works we just wanted to serve some numbers about the performance and the framework at this point of our implementation we are not worried about performance because we are more worried about functionalities about developing a modular flexible implementation which is easy to adapt to modify and we know that that performance can be improved we are aware of some operations that can be performed in parallel etc but we just wanted to give some numbers to show that the performance even without optimizing it is acceptable or it's quite good so as a conclusion the impact provides layer to connectivity services between endpoints in a network Valentin a requested bandwidth dim pack also provides optimized nagar utilization because it is able to move already established floors or even to split these flows in order to make room for new services which otherwise couldn't be provided in the novel it implements resiliency through the computation pre-computation of backup paths totally visioned bacca bacca pads it also implements real-time monitoring with flow level granularity and it allows reducing operational cost of service management as all the life cycle of the services in the impact is manager completely automatically so thank you for listening to me do we have any questions huh Oh turn the row so now what will turn Lois I am fascinated by the way you rearranged running flow if there is a lack of resources have you tested what the impact only actual end user is when you similarly route his traffic somewhere else how long does he lose packets do how does his flow recovery if it's say a tease long TCP connection for instance do you have any data on earth do you mean when we have to move ongoing services to alternative paths they impact on in on on answer end users yes I think that well we have it we don't have numbers but in the test we have done in our network for the end user is perceivable it's sorry it's um perceivable the end user mmm doesn't realize about the disruption that seems very unlikely you're you're bound to lose some packets so you get some tcp slow down and then need to ramp up again and on a long distance link that could be fairly disastrous and we haven't tested eight formerly so we kind of perform tests to measure the delay for example that would take two since the last packet goes through a path until the next packet goes through the new path for example or the number of packets that are lost in that period of time but our impression when you in the test is that performance is quite good but I can't give numbers okay thank you we we had another one yes over there I have two questions the first one is if we wanted to do try an experiment with with this stuff is it available as open source or is there a way where we can at least use it if not develop on it yes it's a bi-level at a giant repository I can't provide you the URL right now hey I don't know if I hurt bad I can tell you of the worst okay great and my second question is for the traffic management aspect of this are you provisioning metering of flows and is that done with open flow or is it some sort of a outer band mechanism do you do multi table open flow and we are using open flow 123 in order to produce in the services yes okay and you're using the meter tables from open flow in order to control the flows and would say was have it open floor has this mechanism called meter tables no no we are not using them yeah okay thanks normal questions were doing extremely good in time so thank you yesterday in despite having lost his badge a second of glue is what reason drawn from Xena and listen to Jewish in general hygiene 84 in general sdn apps or absent drug networks according to the to the summary he's going to talk about my favorite issue in the last couple of years which is energy as well so the most unwelcome all right thank you very much so my name is rod wilson i work for sienna in our CTO research group in ottawa canada and it's my a pleasure to be with you here today um the the previous speakers spoke about STM applications and an environment that is creating great flexibility within networks my perspective working for Sienna is to describe how this is impacting some of our network and product design initiatives and and some changes that are being incurred in the behavior of sienna and the way we're developing products does anyone know what this map is have you ever seen it before it's it's actually Facebook's use map and you can see how popular Facebook is in some countries and other countries where maybe it's less encouraged and of course these are technology trends and if we wrap around a large a servant of buzzwords around this the takeaway is that there's a huge amount of change but the change is all happening around network flexibility and making networks more dynamic more responsive and this is a very different approach to traditional ways of building networks so we used to build networks you know that looked like this lots of well we use clouds you know even even decades ago you'd open a brochure and there'd be a cloud in the middle of the brochure and then various boxes and and lines connecting to the cloud and we would be defined as intercity or long haul or submarine or regional and you would have edge metro and backbone and of course a wide selection of proto products in there and these were often hierarchical so you would use edge products to connect the edge to the the metro or the regional network and then longer haul for the backbone to create intercity or intercontinental networks eighty percent of CMS business is to service providers and this has been the service provider model for for decades but networks are becoming a July and these architectures are starting to change the service provider central office is really becoming content centers and these are necessary for the flows of over-the-top services things like Netflix and so on and the expensive network functions are becoming virtualized than the previous two speakers spoke quite nicely about that the the ability to do new and dynamic provisioning and the ability to switch flows according to what the application requires so networks have to become agile because the new users and new applications and and the demands that's placing on the network and so when we look at Sdn we're using Sdn principles to actually increase flexibility within the networks so a traditional model of course had network management and OSS services that would provision a network and then monitor its performance and either manually or automatically change the the network and the network of course had this combined control plane and forwarding plane and then local regional and backbone distribution but now we see an emergence of the response to these web originated or web scale services where the control plane and the forwarding plane of log separated and so we start looking at orchestration and control and the requirement for real-time on demand control and networks that are as I say much more agile furthermore the control and orchestration techniques are outside of a particular vendor or a closed group they've become very open and this this has created a really interesting environment that we see changing behaviors changing the way people provision networks and the way networks operate the previous speaker spoke quite nicely about some new provisioning tools and an environment that allows a great flexibility from external control and in the in the hardware and vending world this is this is what we see as well so users are saying I want to move a hundred gigabytes from A to C for my application as opposed to a blanket provisioning across Ross network resources and then between the control layer in the network you see Debra's conditions they can get them employed and this is exactly what was shown on the previous presentation about defining specific flows within the network and I think if we look carefully the little Network diagram at the bottom here is almost the same network topology so that's the environment and you see industry responding that some of the developments that are happening in in the research world so one of the things that we have to respond with is a much more flexible and open hardware and open architectures to deal with this so Siena is changing and it's a very significant strategic shift we're on the process of opening the application programming interfaces for our products we're creating open api's so these are based on well defined in for interfaces but also provide powerful integration points so off board controllers can look at addressing specific specific needs and also providing tools for our for our partners for collaborators so we've created a development operation focused specifically around a laboratory environment for proving out open EP is to control our products now what might these be well if we look at DWDM applications as one example we have developed both of our own internal applications as well as an invitation for customer apps that are in development that grab on to the DA p is so so for example in our DWDM technologies rely heavily on coherent transmission and receive so there's an internal modem and it's possible to look at the internal parameters to assist the design and development of debugging of future mode of hardware this kind of thing has never been made available to two researchers or even two to end customers so for example you could look at the pre error feck rate so before it goes through the forward error corrector what is the error rate performance of the network what are what is the signal-to-noise ratio on your network what is the PMD or other chromatic dispersion impairments and so the ability to go in and look at that may be useful to some people other people may not care right so you wouldn't have that particular application on the photonic line side things like a multi-channel optical power becomes very helpful if you're looking at alien waves or other infrastructures of that type so so being able to deploy over a foreign line system require some very special measurements and if this was something that you were going to embark on these kinds of tools would would assist you and then at the application layer you see a mash-up of optical line and non-technical external derived data so for example may be using otdr to detect a cable break or locate submarine cable synchronized to GPS so the information from the cable would actually help guide the ship to where the the break has occurred so these are kind of interesting interesting applications that had all three layers of a DWDM system so one of the things that we've done is create a virtual lab to vet and prove out and the help collaborate in the development of these new applications that will create more agile networks so it's a develop environment designed to help our customers and third-party dia developers or even researchers create tests and fine-tune these custom applications now the process is actually underway to open the api's on a wide selection of siena products and you see a list of products here the first one on the list is a product called waves wave server which is a new product that was announced just last month and is designed as a data center interconnection device so on the surface it's a really boring product it has a wave logic3 optical modem inside and it has any combination of 10 40 and 100 gigabit per second ethernet on the input side and on the outside 100 200 or 400 gigabytes so it's a useful box it's it certainly had some capabilities that I sesay designed specifically for data center interconnection however what makes it an interesting extremely interesting box is the ability to use the api's and the creation of new handles and knobs to actually control ass box to do some some analytics data collection and other control mechanisms that may be necessary in your particular application so this way end users can create and test and fine-tune apps that are based on your own needs now we find this particularly exciting product when we look at research and education networks because of all the vol the people on the planet the group most likely wanting to play with open AP is and you them as a tool set to create more flexible dynamic and agile networks is probably right here in this room so a quick look at this wave server product it is capable of up to a 400 gigabit per second on the on the trunk side and it can have combination of inputs depending on what your requirements are but 40 hundred or 10 gigabit q SP FPS on the front and then there are also the ability to have a wide variety of different plug-in modules and and then obviously network management Portland control on the outside it's on my intention to talk about the the product here if you want to see it it's in our display area downstairs but the point of the discussion is really that it's I think the first departure of a vendor into the world of creating a highly flexible infrastructure based on programmable products many people speak about open networks networks that are invite a lot of different applications but often these are simply a shell in front of a proprietary system a closed system and in this way we're opening up the api's and making it an environment that will really allow this to become a programmable platform and and this has been a characteristic that we've been talking about for some time this are kind of first our first proof so we see the network actually becoming a programmable platform in the past provisioning was was rigid and prescriptive and for the path a couple of years using technologies like open flow or more generically described as as Sdn people who have shown new ways for platforms to be more flexible or more products and networks that be more flexible but we believe that this really should take the next step and become a programmable platform where network connections are fluid and can change dynamically based on application control and and connections that were once rigid are now temporary if they need to be obviously if you need to provision something for a long time and make it more static of course you can do that but the trend is certainly more towards these applications that require dynamic agile networks so in this way we can enable network specific applications network enabled applications we've done some interesting demonstrations most recently that used a multi-touch table soar like a giant iPad that to consider an configure not only the network infrastructure but to also take slices of compute power and and then graphically or through manipulations on on the table cause a network reconfiguration and a virtual machine migration at all three layers in the network so this is possible because of a programmable infrastructure and we will be undertaking work with our partners that will see that become more of an application control rather than a user on us and a touchscreen control so its network driven and reconfigurable Sdn so you know we've often heard the phrase there's an app for that we start to think that there's a network for that whatever that is we regain control real time consumed network resources the bandwidth problem are has been solved for many years but the control of that bandwidth is something that is only becoming truly addressed now cloud content centers we really have to make distance disappear at a massive scale and these kinds of technologies allow that to happen and network function virtualization is there to increase service deployment velocity and reduce complexity and with that comes reduced expense and of course higher performance for our users and so that's that's money out my talk this afternoon thank you very much for your attention Oh may seem in time grass probably will be a free to go for look for some coffee everyone anyone else and that's about any questions any comments no what wait what is the mechanism by which you switch data flows among different optical channels I mean do you do you have a something like a G 709 frame switch in those divides us in that particular device there's there's no switching capability in that particular wave server device so it should be clear that at this point it's designed primarily as a as a feeder box in the future we would be able to do switching in that but more generically the environment that we've created uses a traditional optical switching but that's based on our 6500 system and other you know line line switching equipment that's installed we have a an 8700 layer to switch installed in starlight in Chicago we have another one installed at the University of Amsterdam as well as in our own facility and so these become the flexible platforms and the switching environment that I was are referring to okay make for novice well such as much rather than the rest of our speakers and thank you for you out too well 24 be here 