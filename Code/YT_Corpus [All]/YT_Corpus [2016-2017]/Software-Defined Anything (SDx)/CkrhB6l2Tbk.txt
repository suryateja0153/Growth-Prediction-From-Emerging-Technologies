 all right good afternoon everybody welcome to sin 235 this is deploying CPA extra Doppler and new watch my name is nicko disini I'm excited to be here I'm in the net scalar product management team in the satiric service provider group and with me hello everyone my name is Joseph Larabee I'm an architect in NetScaler group at Citrix and I'm really glad to be here to share with you all the netscaler innovation that we are bringing to the world of micro services and containers I'm Technical Marketing Manager US networks and part of the partner program team focusing on container ecosystem and a ADC ecosystem okay so before we start let me yes a couple of questions so for those two what you are here which ones have you are have projects underway or planter projects around containerize apps or Microsoft which you please raise your hand two or three it's good so um start off you can keep you can keep the session it's at hashtag 235 and hashtag Citrix synergy and for legal reasons I'm obliged to present this slide as a disclaimer so there you go so let me start so my my bold statement is that for the agility scale and continuous improvement we believe that apps are transforming they really are going from large monolithic apps to containers and that process will we'll take a you know who will evolve over time by primarily using the power of one power of many from the power of 106-minute elaborate on that yeah and if we're looking at applications today in our data centers we see that they packed a lot of functionalities in few binaries and they are typically deployed on one or a few machines and that what that means is that it's very hard to make any change however small that changes to your applications and deploy it immediately to your customers or in production environments so the industry as a whole has been on a quest towards a more agile model for building and deploying applications sometimes this is called the service-oriented architecture and the idea there is to break down these monolithic applications into smaller components where each component or service wraps up a specific functionality that can be deployed on its own in its on its own servers can can be scaled up and scaled down and then you can target your changes to the specific service where you want to add a feature or fix an issue and you can deploy it without affecting the the rest of the services or the rest of the applications that are deployed now it's a it's a very good model however there is complexity that comes with it and that's why it has been eluding most businesses but the biggest ones that have the wherewithal to throw at this problem because when you break like a lot application into a lot of services you've got to manage those services you've got to manage the infrastructure needs but this new architecture imposes that is until recently with the emergence of docker and docker containers and what that allows you to do is wrap these services in one or few containers and they can share infrastructure so the insulation of those components from each other allows you to deploy a lot of them on the on the same servers and also with the tooling that that that is accompanying about the continuous integration the continuous delivery pipelines allows you to automate that complexity and and deliver on this promise of being able to deploy changes in in a faster way so what happens is that that you break these apps they become micro services and then they talk to each other the other thing that's happening is DevOps is changing a development model primarily what's happening is we're seeing in mark on a customer base is that multidisciplinary teams are coming together where the developers their ops teams their deafness teams with the goal of being more agile how can they deploy service more quickly from from weeks and months to days and how can they do this deployment more frequently so what we're seeing is that this this this movement to DevOps is portraying the use of new form factors and containers being one of them and so when I talk to our customers I find that there's a skunk works on containers or maybe it's even more than a skunk works it's more of an actual the semis sub semi mainstream project so with that if you're looking into the build your micro services or your containerize app infrastructure we'd like you to look at netscaler CPX and NetScaler mass as the foundation for the for building this infrastructure we can stitch together your micro services infrastructure and what we can do is that we can do a variety of functions right let me first talk about that scalar CTX so netscaler CPX is net scale you're familiar with in a container form factor it joins all the other net scalars we have which is the that the appliance version the multi-tenant version DSD x the the the virtual version the vp x and now the CG acts as a container form factor so netscaler CG X is packaged as a docker container it has the same bits as all the other net scalars it's managed like all the other net scalars it supports nitro API it's got the same functionality and load balancing too familiar with content switching DNS all traffic types and protocols as a seller offloading monitoring and logging so this is now NetScaler in the four factor that you can deploy in the laptop all the way through production as a docker container the other piece that we've built is NetScaler mass switches are managed with an analytic system we have a talk on the scalar mass that we're giving tomorrow so we can learn more about that but primarily a scalar mass is a way for us to control now see not just easy access but empty access and deeply access at scale so you can you might have from tens to thousands of CT access in a data center we can manage all of these from absent absent ik lifecycle management all the SSL Certificates configuration at scale or the configuration and collect orders with all the inside the visibility from from these from these net sailors and then provide from that the only pieces that we titled the service discovery framework we can type his container management systems like kubernetes and and and docker swarm have service the spark where you can you can understand what events are happening in the container environment we can capture those and use that than to to change the context on nets the others in the fleet so if we look at how now that you've breakin your application into these different services you need a way to deploy them onto your data center and deliver on that promise of agility and here we're seeing a picture of each color is representing a different service and typically you would be using one of the tools for deploying that service each service made may be made up of several instances so when you deploy an order service or customer service whatever service functionality is you might deploy several copies of that first for scale to be able to handle more load and also for resiliency in case of you know a machine fails or the rack fails or even a data center fails if you are spreading them on multiple data center and the way you deploy this is using one of the tools like what miko just tell you the true kubernetes or or mesosphere or from docker docker swarm and what these tools do they allow you to schedule your containers onto a cluster so they they kind of treat all the cluster of machines are a pool of capacity and they manage that capacity in the most efficient way so if you are deploying a new a new service or set of a set of services they will find the best place for that service and you can scale that service from these tools you can scale it up scale it down depending on your needs and you don't need to know which machine or which is you know which part of rack etc is is your service or service instance running on and so this micro services they talk to each other so I'm showing you an example of the blew the ply I'm talking to a green app and then the orange apathy think app to see FDA talking to disagree a client talking to web to web app and then do it to a customer service app and so on right so these call flows could be fuel or to be many I've seen in fact there's a diet you can see in the internet the Netflix or the Twitter golf those and it looks like a dead star with tens of thousands of golf clubs or it can be a small number of micro services with a small number of call flows we can manage there's those call flows by putting CPX in the middle and acting as a hub-and-spoke as a control point for all a traffic between containerize apps so the idea here is that if you are deploying your services what you want to do is place the CPX to front-end each of your services and what that allows you to do is be able to control the routing of requests between your services so in a sense block any requests you can see the requests that are flowing between services and it becomes your enforcement point that is in front of each service and you can kind of enforce that those flows and that communication pattern between your services and coupling that with NetScaler mass which can manage all the CP X's that are fronting all your services you have first a way to deploy your your configuration and have that visibility into what's going on so the other piece of that is also rate limiting yourself right so so so CPX can greatly but the flow of traffic to the micro services at the other end so if micro service is not performing well we can rate a limit and just send traffic to the purpose of microscopes that are performing well the other aspect of course is with below talents we can scale up and scale down in response to node so let me drill down on this right in the micro services environment the apps in the backend are very dynamic so new apps are instantiated fairly quickly it's automatic and we can learn from them from the service discovery framework about those new apps and tie these apps to do the CP arts and therefore what it does is that we can assign a VIP and just point the user to live in that vehicle then whatever happens to back-end it becomes transparent right we just hide it we just hide it from from the users so we still obscure down regardez hard to tell how dynamic the environment might be of course we monitor so we do health checks on all the micro services in the instances we have your support session persistence caching and so on as well as we have we talked about visibility and analytics we can get the lemon tree from all the CP access and from based on that identify trouble troubleshoot issues identified the call flows and and and provide additional insights what's happening again in the environment you might talk about services copies some more yeah you had you had a slide earlier on about service discovery so the the issue that comes up with service discovery in this world of micro services is the fact that it's all good that you have instances of each service scaling up and scaling down but the the problem you are going to have is that the instances of these service are changing all the time and if you have a client's trying to find out where are the instances of the service then that's that's that's an issue and usually in this world of micro services there is a service a discovery service that that needs to solve that that problem so by fronting your services with the CTX you can actually have the client talks to a stable point and then the CPX behind-the-scene together with NetScaler mass can detect all the changes that are happening in the infrastructure and updating the configuration on that VIP but that's corresponding to that service and we're going to show a demo later on that kind of shows how that automation is working including registering a DNS name for that bit so that your client can can be given a DNS name it can be resolving it against the stable IP which is the VIP IP address and then behind the VIP you can set all the instances of your service and they might be changing scaling up scaling down dynamically and the clients don't need to to care about that so in terms of securing the micro services connection say you can have the micro services in your data center or it could be in the cloud so there's a need for SSL so we support SSL TLS we can offload of course and and and provide persistent connection we can multiplex the connections to have do a back end micro service and if required you can also encrypt that back end micro service as well now it's NetScaler mass you can actually manage all your certificates from one platform and therefore you can detect things like you can put policies as to what SSL certificates to use what ciphers what trusted authorities I can look at a trusted authorities which wants to specify and then you can impose that across the whole fleet and it can determine if certain CP access are not complying to policy it will flag those right so the combination of NetScaler masses and as a cell with CP acts it's a good combination the only thing is that you can do canary testing so here really what this is all about is when you turn on a new type of a micro service you may want to as part of TDCI you may only want to test a small part of traffic to be sent to that micro service so we have a function in NetScaler that available in CTX called service a new service slow start right that's correct so what that means is that you can specify in CP access for any new service only send two percent of the traffic one-fiftieth with the weight of the traffic to this to this particular new micro service and and you can then specify policies that keep on asking for for add more overtime or or or change the current rate manually right but in any case you can send traffic to this new micro service and if it's working then you can then increase the weight so that such that most of the traffic goes to the new micro service type and if it's not working properly you can kill it and then again only a small sliver of traffic was affected by that micro service and an ethylene you want gets enabled anything else well yeah I think canary testing is very used in in deployment of micro services so you know because of that agility and because of your deploying changes all the time you want to kind of make sure that any change you are deploying is not breaking something that was working before so this idea of introducing a new a new instance of the service with the new version but just sending it a very small portion of the traffic allows you to see if it's working and as you gain confidence you can give it more loads to to work on right so so that's kind of a very very efficient way of you know deploying a change that you are not sure of and you know having that agility of deploying you know changes all the time right excellent the the other aspect of this is that you have broken down your your application or your your monolithic app into several services and you have you know architected it with CPX fronting it fronting these these different services but like initially the traffic might be coming out of your data center and at the edge of your data center you might be deploying an MPX or or or or NS DX hardware appliance that's that's managing that load so how do you unify all the traffic as it comes from outside your data center and as its traversing all the layers within your data center and having that full visibility and you know unified way of configuring that flow so with NetScaler mass and being in the picture and being able to manage both the NetScaler MPX SDX the hardware appliances as well as the new form container form factor the CPX you have a way to configure all your NetScaler appliances where the weather they are dealing with north south or whether they are dealing with east-west in a consistent manner and you can also collect all the analytics and metrics and logs and so on in a central location so you have like a full visibility of your flows as they enter your data center and traverse every service within that data center right so the other thing we built is we we built something called stylus let me talk first up before I talk bust out books when you build an app they're an app packages multiple components and with that also app configurations and now with CPX in a container form factor you can drop C text in the laptop and build that through to develop to staging and then sorts to testing and staging and in production the only thing is that we've built you also want to add the CTX configurations with that and you can now add that using Starbucks style books effectively are a declarative parameterized config definition or a template in Yama format you can build a NetScaler practitioner can build multiple types of scalped style boats it could be any kind of style book and load balancing it could be content switching it could be anything in DDoS for example you build once and use multiple times and the beauty of this is that you just give your app developer a list of parameters for configuration against that he or she needs to enter that's specific to their app so these stab look effectively abstractly NetScaler from an app developer so they can then add load balancing into their development process and and also because it fits very well with the DevOps mentality of immutable infrastructure where you don't go and tinker with existing configuration on a live system you actually have a definition of all your configuration and you deploy a new version of your configuration after it has gone through the production pipeline testing staging and end deployment so by having your NetScaler configuration in a template form that can be packaged as part of the application components and can go through that pipeline as you are deploying into production that gives you that assurance that the whole application is working together sorry well we'll go through and talk about this use case which we build for a major customer this customer want but it required was a interface where from a portal and user could enter a request for a set of services or resources for apps for the containerize apps and the request for a type of VIP and what this will do is that it will trigger automatically a service where NetScaler gets configured the apps are spun up we we add the absolute NetScaler and it's we play the VIP for that for that for that set of apps and then we we then enter a dns entry with a single a or quad-a entry for that particular app and aspiring this infrastructure the the customer wanted an overlay network they wanted each of these apps to be routable and then putting the apps into one subnet and NetScaler into another another subnet so with that they select the user new watch networks for the for the SD and overlay so let me bring in Remy who can talk about thanks because thanks yourself before going to the details of the John integration and the use case that we've developed for this major customer I will do a brief introduction of newest networks and what we deliver to our customers so a newest networks is the NCN company based in the Silicon Valley and we are an occupant jurors and we deliver a single platform the platform is called the newest networks controller services platform and it's composed of three different layers at the top you'll find the management plan has called the VSD 4 virtual services directory this part is insured of defining how the policies of your network well at mean is you're going through the VSD to be able to design your network topology apply your security rules across your data center as well as design your service chain for example if you want to serve a chain between your load balancer going through your firewall and then eating the application our VSD is also the point of integration with different CMS's we have integrated with holding my drawer CMS foreign poll we have integrated with mesosphere OpenShift VMware open second cloud stack the middle layer also called the VLC is the Sen controller in our solution it's called the virtual services controller the this part of the product is it's based on a proven service router OS that you can find in any Nokia 770 X 50 cold water that you can find in any biggest ISP networks so by leveraging the same Nokia services router who has we are able to scale to a large number of endpoints a large numbers of containers VMs and permit all servers in the data center and by using like standard protocol had the control panel although we are able to integrate your with your peer router in your data center if you have like no character of course it will work but if you do have for example a Cisco router or a Juniper router rattle that can tell kemppi bgp we are also able to integrate our solution with your gear after those policies that you have defined that we se need to be applied on to the management on to the data plane by transforming the policy internet networking construct the VSC will then push some rules and forwarding entries into the data pane which is also called the Vieira's the VRS is stands for virtual routing and switching and it's basically modified open V switch that can do disability switching this with writer Rick routing sorry and Leo to to leave for foil in this part of the product can interconnect any kind of workloads in the data center so if you have physical assets for example database which is running on your on a specific piece of hardware you can enter too like using overlay networks your VMs deploying on OpenStack or even your container deployed on the mesosphere platform now let's move on to some benefits that you have to be by running your networks in your data center the first is as I mentioned hold your we can manage container VMs and physical assets and we are also completely I provides or agnostic so you can run our VMs on for example ESXi KDM hyper-v and being able to bring all these workloads together also as we are using the service router Nokia who has we are able to give you a full tenant isolation at a large scale because we are having the same rules that we are applying into the internet backbones into your data centers you you you'll get the same scalability you can find on internet into your data center our platform is also poly Sidra I told before policy drive driven so by using REST API you'll be able to program your network by pushing rules and calls to the BSD so if you are for example a custom pota that define your topology define how you deploy application you'll be able to interact with our API to program the network another benefit is by choosing us networks for your Sdn layer we are not asking you to buy new hardware for example if you already have juniper file a fabric on the network or already invest on some citrix netscaler devices we don't ask you to reboot something we are believing that like the Citrix heels mentioned this morning in the keynote that we are better working together with a huge partner of ecosystem let's move now let's talk about specifically about neural networks in container so we have started like some years ago to develop some prototype on containers based on environment and what we believe compared to other Hessians vendors is we want to provide you a single solution to manage your network across different workloads so we don't care that your VM is running for example on OpenStack or on cloud stack or your container is running on OpenShift or with a sphere what we want to provide you in single solution to interconnect two IP addresses by applying the same the same thing that we are doing with with the VMS and the physical assets we we can provide you multi-tenancy and overlapping IP addresses for your continuous what that mean is you can run your prediction hungry-man with the same exact same topology and exact same IP plan as your dev environment or even your testing environment so you'll be sure that when you'll put your your application into production you'll be sure that it will be running as it was in the QA tenant as I mentioned earlier we have like a really scalable control plane and we have demo that a couple of times you can find it on YouTube we we did like a couple of months ago a scalability test where we launched more than 100,000 containers in five minutes able to start exchanging packets between how these containers the last piece that we bring to the container ecosystem is Pioli and currently all the dr networking lacks of security and isolation so you cannot like easily isolate for example at between each other by using us you will be able to have specific secretary rules apply on each container networking adapter today we are in the docker ecosystem are supporting native doctor integration Apache missiles and radar top and chief now let's move on to the joint integration with the NetScaler platform we have certified last year three different deployment models the first one is the outward wave model which involved MPX and STX product with our by using our hardware gateway to bridge between the physical handily and your application running in your body the second deployment model is based on the software gateway how to call the VRS G that can be which is able to connect your VPX MPX or HDX devices into the overlay and the last deployment model we have certified last year was the VP X on like any kind of hypervisor and you'll find more details about that in the next session but today what why I want to do is to announce a new deployment models by supporting the just release new form factor for the next killer platform we are going to support the CPX platform on new arch and a build platform so why choosing new ash and the scalar for your data center you have a single solution to manage any kind of workloads and any kind of a diesel devices before jumping into the meat of the demo I will explain what is the workflow behind behind the demo as we as an operator have to provide like a platform for my application operator and this is really simple because now everything needs to be automated so first things that we have to do has an operator his configure your missile slave your doctor hast to register to the missus master to be able to launch a new application then the operator will have to install some pageants in that case in our VRS on aerials to able communication between application the sort of thing that we the operator need to do is to define the policy and the topology so by using the BSD API you are able to configure automatically your topology and port set to to the to the VRS and the last thing the browser will need to do before starting to deploy the application is to launch a new job on mythos and this is the deployment of the CPX on all across all the cursor so by launching only one job if you are for example 1,000 out in your cluster you'll be able to spin out 1,000 CPX instances in your data center and those will get automatically discovered by mass so you'll be able to configure them directly from the neutrality ion mass okay so now that the infrastructure is is ready the the missus slaves are are set up the nuage Sdn networking that that allows the containers to network with each other to reach each other is in place and the NetScaler CP X's have been deployed me as an app owner can come and deploy my art so so the first thing is I'm gonna use am a sauce which is the tool I'm using here to manage my containers to deploy my app and the the other thing that's gonna happen is that as soon as I deploy that app netscaler mass is going to be listening on events that are about any app changes or any new apps coming or any apps disappearing and then behind the scenes updating the configuration about those up so what that means is that for each new service like I was showing earlier needs a VIP needs a new virtual IP address and NetScaler mass is going to talk to nosh to acquire an IP address that's going to be used as a virtual IP for that new service it also knows about all the instances of that service that have been launched and configure that VIP with those new instances so here if we walk through the flow so we have a new app netscaler mass is requesting information from nuage and then we get the IP addresses we said we also select a NetScaler CPX from the cluster it can be any any CPX that has the right load and the right location and we can deploy that VIP configuration on that CPX so in essence you know what what what the demo is gonna show is that full automation me as a user deploying and up and things are happening behind the scenes in terms of networking in terms of load balancing configuration with you know kind of anchoring all the activity around the user having actions around the app and the infrastructure caching got the infrastructure you know doing the right thing behind the scenes so yeah so let's start the the demo now let's switch to the demo screen okay so so the first thing we where we are seeing here is the initial deployment by the operator as a reaming was showing earlier of the netscaler CP access so these are NetScaler containers we have a cluster of four for meso slaves here we deployed four containers on it and and this is showing on the demo sauce marathon console that we are using to manage our applications so the next thing is now if we switch to the nuage console we can see that no ash has detected those CPX containers and allocated IP addresses for them specific subnet that's dedicated to lis netscaler containers and that's the 10:27 subnetting in this case and if we continue we also are gonna see NetScaler mass also detecting those NetScaler CP x's and starting to manage them so here you can see the 1027 IP addresses for the for CP x these are the management IP addresses of these CP x's and now they are part of the devices that that are under management by NetScaler mass so now this is all kind of operator driven so the infrastructure is ready now let's start launching some apps so the first app we are going to launch here we we are going to have an emulation of two services talking to each other so we are going to have a service called the back-end service and it's going to be made up of two instances shown here at the bottom and we're going to launch another service later on called the front-end service and the front-end service will be talking to the back-end service and each of these services is fronted by a NetScaler CPX so clients are not going to be talking directly to the service instances that are gonna go through a NetScaler CPX so as soon as we launch that back-end service we see that nuage again has detected the launch of those instances allocated IP addresses to them from a specific subnet that's dedicated to that service the 10 109 subnet and again we'll see that NetScaler Mass in a second also catching up so this is the web subnet we are gonna use for allocating VIPs the 1046 subnet and if we pause here for a second so here you can see that netscaler mas has detected the new service that has been launched it has allocated the VAP IP address to it from that 1046 subnet from nuage it also has selected the specific GPX from the cluster on which that lip is configured so that's the instance IP address in that in that column and if we play the video again we can see that the the services that are behind that lip so so we can see that the the VAP is load balancing in this case to true the true instances of that service as we saw earlier there from the ten 109 subnet okay so we do a quick traffic test here so and and also one thing I didn't mention is that there was a DNS name registered for that day so now the clients can use a DNS name which is a stable entity against whatever the IP address was was allocated so here the client is reaching that a web back-end domain name and we can see as we refresh the page it's hitting a different instance of that service okay the next thing we are going to do now is deploy another service this is the front-end services going to be talking to our back-end service so again this front-end service is made up of two instances and as soon as we launch it we can see that nuage has detected the the launch of those instances of that service and then match them with the subnet that's allocated for that service and it's the 1078 subnet again NetScaler mass also has allocated the VAP address behind the scenes on to that new front-end service coming from the 1046 subnet which is the the web subnet and it also allocated the new CPX different from the CPX that was used for the for the back-end service on which that elbe configuration is placed and we can see the two instances here the 1078 subnet and we do also a quick traffic test where the the top box is showing the front-end service and the bottom box is showing the back-end service and as we refresh this page you can see it's hitting different instance from the front end orbit or the back end service okay so good our our load balancing is is working as expected so now let's try something something else so as we also talked about these services very dynamic you scale the map you scaled them down so here is a scenario where I need to manage more more load on on the front end service so I'm going to add 10 instances to that service so my missus obliges and adds you know deploys ten new containers on the infrastructure Norwich detects the the new containers and allocates IP addresses to them from that 1078 subnet that's for that front-end service and we can see the VAP here is is updated so if we see the services behind the VIP now you can see that there are much more services than before so everything is good the scale-up has worked and that scalar mass has detected that and other new instances behind that VIP so so far we have seen like new applications new services being launched services being updated and again we do like a quick quick traffic test here and we can see more more instances so the last aspect of this kind of app lifecycle is we are going to destroy the services and we're going to see how our infrastructure reacts so we're going to destroy the the front-end and the backend services and you can see if we switch to the nuage console all the IPS have gone from that subnet if you go back to NetScaler mass all the VIPs have gone from that service because these services have been destroyed so they have automatically detected that and they have released all the resources they have been holding for those services so that was the business of the demo you should have given a no so let's switch to the slides now okay so pretty much the answer we like additional breakout sessions to attend there's a session on on VPX with new lodge and OpenStack right after this session it's in 246 there's a session on NetScaler mass tomorrow at 3:30 I'm speaking in that session so is George McGregor that's in 240 and then there's a session on next-gen ciphers and SSL sin 232 which is on Thursday at 4:30 so please attend those sessions and it can also get the consequent surveys available online and I can download expression these presentations by Monday and you can also of course rate the session now with that you can open for some Q&A there about 2 to 3 minutes really interesting thank you if I look at a Nets killer MPX you have awareness of the hardware the kernel everything happening SDX you own the hypervisor and the kernel of the VPX in a container world what's the relationship between the net scalar container and the host it's on it you know in terms of security and and the barriers that exist or don't exist between them so net scalar CPX is is meant for a world where you know you're deploying micro services and container form factors and you might be deploying an application on a developer laptop so it's like something existing that you can use and and build your your applications with so you know there's always kind of a trade-off you know what what you are using which form factor what kind of security you need so NetScaler CPX has the same you know the same characteristics like any any other containers and you know it allows you to use it in a world where you are using you know a Linux kernel you're deploying microservices you have developers you know kind of building tools and you know using their existing their existing development Tooley right but the the good thing about this it has the same API so as the netscaler MPX NetScaler SDX same configuration so you can develop on that and then deploy on an in a production environment on an MPX or or on other form factor that you decide makes the best for for you know your use case it's one more question I have to if I can be greedy yeah sure okay so one is what is the dataflow look like for service registration through to the so I if I have a new containers fooled up either in a dynamic expansion scenario or a new application deployment scenario if I'm using Bosch or kubernetes cert managing my container deployments is the data source that feeds the net scalar reconfiguration coming out of kubernetes they're coming out of Bosch or where what is the source for okay this container is now it now exists is running a listener on this port this needs to be registered with the net scalar via mozz right now how is what is the actual data flow for that look yeah so in in in every container environments like service discovery is done in it in its own way and you know we are integrating with the different container environments right so here what we showed is the maysa environment and how may source publishes events about services being started and services being changed and how NetScaler mas has that integration to that service bus so it can kind of listen on those those events okay so the same thing applies for for other container environments so in the DevOps model it would not be incumbent upon the application manifest to be incumbent upon the people running the infrastructure that deploys the application to broker that right yeah so it is gonna be part of the infrastructure so kubernetes would have standard mechanisms the operator doesn't need to do anything special you know they're gonna be broadcast and we are going to be capturing those events okay my second question which is I think a bit more binary is is the expected use case for CPX where you already have container deployment infrastructure that supports inter container communications like I noticed that everything that you did there was predicated on the idea that an application group set of containers all had open coms between them is that the is that the only use case or in cases where they're isolated and matted with the doctor port doctor port advertisements for example is that supported intended to be supported also yeah so the the networking for containers is gonna vary the pencil here what we have shown is an overlay solution with no wash and how in that in that set up a container would have an IP address that is routable across the cluster right in other deployments you might have different deployments where the container is another port in that yeah yeah exactly so in that case it will be a different mechanism for for fronting the CTX to those containers but what would be supported yes okay thank you I think we're running out of time so thank you very much for for attending 