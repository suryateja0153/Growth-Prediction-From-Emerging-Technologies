 so hi my name is Michael Bailey I'm with the University of Michigan I'm up here with Timothy battles from 80 and today we're to talk a little bit about the internet motion sensor project so I think you're all going to be terribly terribly surprised to understand that there are a bunch of really nasty things on the internet today like denial of service worms I think it'd probably be equally surprised that somebody somewhere thought that that was a good monitoring project how does IMS do is monitoring as the saying goes all the good ideas in computer science for invented before nineteen seventy that's probably not true for this one but pretty darn close we do what you guys have been doing for a while that is we use the routing infrastructure to offload packets from the network and analyze them of course when you have an OC 192 backbone the problem becomes one of trying to figure out what it is that you want to upload to analyze fortunately there's a couple situations in which we have some pretty clear indicators that something's going wrong and there's some clear indicators of what to pull off this includes attacked customer trackit traffic in the case of DNS traffic outbound to space that's not allocated and stuff inbound to parts of your network that actually don't have host in them we like to look at the inbound traffic to unused address space part of the reason we like to do that is that the traffic itself is pre-filtered because there's no host in that address space we shouldn't be seeing traffic in the traffic we do see is because somebody is scanning there's worm propagation there's misconfigurations there's backscatter so if this is starting to sound familiar it should there's been a lot of really good work by folks in this room in this area including the the work by the folks that kada as well as team coming so why should you not skip out and go to an early lunch well I think there's a couple interesting things about this particular project and they derived directly from the design goals of the system the internet motion sensor project was designed to do four things based off of some of our experience doing early monitoring of this type in particular what we wanted to do is be able to differentiate services oftentimes new exploits come up for ports which already carry a lot of traffic in this face of course not all not all the new exploits and vulnerabilities happen imports that we already know so we want to be able to capture those as well in addition to which we want to have broad representative coverage of whatever start it is that we do see and finally we want the system to be available if it's going to provide any utility during these times of new worms or threats so why don't we care about differentiating services as i pointed out earlier oftentimes we see new threats and ports that already have traffic in this particular case you see a graph of tcp 445 traffic as represented over a seven day period it observed at one of our sensors this graph was taken around the time of the sasser outbreaks and as you can tell before sasser came out there was a great deal for 45 traffic on this network well since I told you that sasser came out during this week you can probably guess where it came out if you had known that piece of information might have been harder to do it's not until you spend some time looking at what the infections are trying to do as we do in the upper left hand right hand corner excuse me that you can actually see that there's a signal within that noise why is it important for us to capture new services for those of you monitor dark IP space regularly you know there's a handful of ports that are always in the top 10 list you also probably know that the rest of the top 10 lists varies pretty widely based on what network you're in what time of day it is what the fashion of the day is in this particular case we're looking at a graph of big changes in ports from five months ago to two today one of the things i think that was interesting to look at is these two ports 2745 and 31-27 which were represented with backdoors five months ago these things did not exist or five months ago as at this graph they didn't exist and I was done they shot out of nowhere these of course our people scanning for the backdoors traded by these worms so if we didn't capture information on these ports if we didn't have a monitoring infrastructure that was capable of storing things across them we wouldn't be able to gather this information obviously a broad coverage is in great part about getting as many sensors as you can the more space that you have the broader the coverage the earlier the time to detection the better of the representation but it turns out also that different sensors see different things in this particular slide we see the average packet rate over a week as seen by 10 different sensors in the sensor network the first thing you'll notice obviously is the large difference the magnitude of that the traffic in this traffic in fact is not the result of local preference by people in the same /a in this particular case we've removed all those source IP addresses that are in the same local /a you still see these large differences finally we wonder whatever infrastructure we built to be available it doesn't do any good to be able to react and respond to a threat if the box is down during that threat this is actually a little bit more complicated problem than actually just building good software in this particular case you see a view of the witty worm is observed by three of our sensors we thought we had some pretty good diversity in these sensors they're all in three different / six teams they're all in three different organizational units there in two different / aids but it turns out they share the same upstream provider and around the time of witty a couple hours after it started the upstream provider was trying to debug a problem with one of their customer routers and inadvertently placed an apple across their entire border to block woody traffic so how do we achieve these sets of goals the IMS architecture is contains a distributed set of sensors those sensors we make an attempt to make sure that they are topologically an address space diverse we differentiate services by replying to TCP sins with TCP syn acts to elicit the first payload of a TCP connection we use payload reconstruction and md5 checksums to build signatures of those payloads and we try to respond across all services so what does the current distributed ims deployment look like right now we monitor 28 blocks at 18 different networks including a variety of academic service provider in large businesses we have a variety of spaces from very wide as a / 82 a lot of small spaces like / 24 s as I pointed out before key to what we wanted to do is to differentiate services TCP and I see I mean excuse me UDP and ICMP are easy these type of attacks contain the data payloads that we want to look at without a listening or doing anything fancy however TCP is a problem because we don't actually see what the application exploit is until we actually initiate the three-way handshake so our solution to this is to build a lightweight active responder to get the first data packet the solution is pretty simple we get a sin we sin a kit and that's generally enough to get enough of the payload to differentiate the threats so how does this look list let's look at this in the context of the blaster worm here for those of you who don't remember a blaster was TCP port 135 the buffer overflow against an RPC service for Microsoft at the top this is a this particular graph is showing a infected host in a vulnerable hosts so this is what you would see if you were TCP dumping right in front of a box it was about to get infected with blaster the top part of it is the standard three-way handshake you then see the application level RPC bine and then the actual RPC request which is the buffer overflow there's a session tear down and for those of you who remember this particular worm the payload itself in terms of what if what the word was supposed to do as well as the commands were executed over port 44 for once that session was torn down the infected host would attempt to contact the exploited host on 444 sended the payload in the a very into blaster it's a denial of service attack payload and then tell it to actually execute it and hit so what does this look like in the context of IMS well again as we mentioned earlier what we're trying to do is illicit enough of the payload to differentiate various threats in the case of blaster you can see the IMS or black hole sensor or supplying the syn ack that's enough information for us to elicit the RPC bind as well as the RPC request we can notice that the section teardown stuff is not there because we don't store state we just reply with the syn ack we're not trying to do full session reconstruction and that's part of the reason to get the scale it's also the case that with respect to blaster there's no real check to see whether or not the the exploit actually took effect so immediately following its a buffer overflow packet being sent it goes ahead and tries to connect on 444 if you respond on that port you also are able to differentiate and get a little get a hold of the payloads as well as the commands so one of the problems with this particular approach is that if you start listening more payloads you have more payloads to store and we saw a drastic increase in the amount of stuff that we were storing on disk one of the first solutions we try to this was hey let's just store new stuff and the way we did that was we took an md5 hash the payload and only store palos or to have a unique ash one of the cool things that happen as a result of looking at that was we pretty much found that if you look at the first application halo across all these different exploits worms and things you see that most of them have been seen before and in fact a very very large percentage almost ninety-five percent in this particular graph you're looking at the cache hit rate as observed by three sensors over a period of five months so you know why is this thing useful and why do we care hopefully folks here will remember the SAS earned a burr worms of earlier made this year sasser was an LSA SS vulnerable in LS a SS vulnerability it scanned for vulnerable hosts on tcp 445 once the boxes were exploited they installed a backdoor in 55 54 there are a bunch of different variants of SAS her including SAS or E which most notably changed the backdoor port to 10 23 dabber was an interesting worm in that it actually exploited a vulnerability in the back door of another worm so what dabber did was scanning on 55 54 looking for backdoors created by sasser and exploded to her ability in the ftp server of sasser and then itself installed a 98 98 back door so why do we care about those particular threats recently folks have been seen a lot of scanning activity towards these three ports and Moses getting activity looks like this large double spikes the same kind of graph is this what you would see across all these ports 1023 55 54 and 98 98 and very interestingly enough almost all the hosts and I don't mean just like the normal distribution I mean like 98 or 99 percent of the hosts are from Korea and from China so you know as you notice in the previous slides the spikes were not overlapping as seen two different sensors if we look at four different sensors over time we can see that this is in fact actually atop the bottom scan of the internet we do a couple quick calculations on time and amount of eyepiece scan we see that the they are in fact doing atop the bottom scan and they are doing it about 8 a-6 / 8 an hour which is just about enough to get through the non reserved space in a day one of the interesting things about this particular attack is it seems to be done from a very large pool of bots this particular graph shows the cumulative unique IP addresses over time I've highlighted three different regions that correspond to the three different spikes that we saw over that three-day period there's a couple things to note here that are very interesting there's only a small number of hosts they're involved each time as observed by each sensor but the size of the humps is similar each time this is a cumulative unique IP address graph so if these IP addresses were being used again for the next day scan would expect the bumps to be smaller and smaller there in fact not and it's also interesting to note although it's not relevant to this particular scan that these scanners are actually being dwarfed by the amount of background noise and other scanning activity that happens on those ports even though the spikes themselves are quite large so we saw that there wasn't a lot of reuse between IP addresses that seen an individual sensor over time as there a lot of reuse between sensors on the sensor network that is all those IP addresses skinny multiple blocks that turns out not to be the case as well what we're looking at here is the overlap or intersection between two different sensors and the number of unique IP addresses that appear in one scanning for a specific port and appear another for scanning port the region of this graph that's very interesting is the lower left-hand corner in which we see the overlap between the / 18 in the / 17 in terms of IP addresses involved in scanning specific ports you'll see that there is no overlap among the 400 IP addresses that were scanning 10 23 and only a very small handful of overlap the other IP addresses but take away from the last two graphs this one and the one before it is that the person who is doing the scanning already has a very very large pool of disposal IP addresses that they do the scanning with and they don't reuse it across scan and blocks and across days so what were they doing tcp 98 98 they were just sinning to see whether or not there was any activity or service available on that port there were two unique signatures 45 54 and 10 23 here are the md5 checksums and the hex domes representations of those two signatures but user x and d are just part of the backdoor protocol for sasser and then it's actually an application message trying to see whether or not the back door responds so hopefully you've seen a little bit of why I ms is unique in what some of the utility of the infrastructure is if you're interested in getting involved this is a publicly funded research project if you've got space that you want to donate to the project and become involved with we do have some equipment that we can set out to you we're also building a software-only version of this software so you can download it for your own private use or participation in ims if you'd like what you get when you participate of ims is very much the you show me yours I'll show you mine kind of attitude you get aggregate views across all the other participants and you get detailed views of all the information that are handed over to your blocks so I want to hand it over to Tim to talk a little bit about why this is useful in an operator context so I get the real easy part of this presentation his mind's extremely short so what's the importance alright so what's the importance I mean most most importantly we have we have early detection for the worms and viruses second we can provide the source addresses that are trying to hit these at these these dark address spaces we can provide these lists to our abuse groups for cleanup pretty much anything that's hitting dark address space is going to be some type of malicious variant or scanning or it's not supposed to be there it provides bass lines on footprint measurements one of the things we do is there's a lot of complaints about the white noise that's going around on the internet so we have customers that have a / 16 or have a /a or have it or some rather large blocks and we can cut a baseline what we receive on our are dark address space and we can go to the customer we can say well you know one hundred percent of your bandwidth out of that you know five percent of this is being allocated to just just internet noise you know let's do a footprint reduction so that you can you can recoup some of that cost so why do we need payload one it enables the detection of new variants if we're not looking at the payload if we're not looking at the signatures if you're just relying on something hitting port 80 or something hitting port 98 98 how are you ever going to know if there's a new variant are you know the typical dark address space it isn't going to pick up a whole lot of a whole lot of trend unless you can pick up on some type of payload and we can be found murdered by an entirely new variant not even knowing it can be used to create IDF signatures if if a new variant does get released it's a really quick method that we can take that signature and we can rapidly deploy to our IDs sensors as well as our firewalls and block it enables variant tracking an impediment associate important once again it kind of goes into wire you know what's the purpose of just looking at a fort if you're not looking at if you're not looking at something that's um you know a new variant that's going towards the port the using that payload it doesn't make any sense source address distributions so you can set a priority because we're collecting source AAS distributions we can say where's the thread our most of these sources are they coming from Asia pack are they coming from north america are they coming from South America or they come from our European a SS allows us to prioritize in the case of an emergency that you know something breaks out a new virus a new variant breaks out we know where to start placing our access list we know where to start our mitigation and we know how to finish our navigation it's real time so you really do we really know how do we really need to answer this question if our data is a day old our data is 12 hours old it does is absolutely it does us no good unless something to say but why did this happen but if we're going to prevent outages from operational standpoint we need to have real-time data and so bringing it all together this is kind of a more of an eye chart I don't know if you guys can see it entirely but essentially you can operationalize this if you're monitoring something from ims you can determine whether or not you have a new variant if no you still have the tracking capability of the variant of the old variant see if it's increasing see what source is is it's coming from sudden the sourcils is up to the abuse to us for cleanup if it is an invariant we can go into mitigation and from that mitigation we can determine what's the severity of it is this is this a little eyes just to my ISP or is this global is this hitting all these other blocks I ims has coverage part if it's local or regardless of if its global you can notify the proper people we can do firewall updates we can do ids updates update perimeter filters activate Tar Pits based on that vendor updates contact a vendor because we have the payload we can immediately send that off to the vendor see if they already have a nun patch and patch it sit thank you thank you you guys can't sit down because there's a question so yeah if there are any questions please stand up quickly so that I can get a good count because I'm hungry and I want to leave for lunch have I been counted yet no you are invisible here on any cast instance of the bill protocol so you once i'm gonna one you guys can take this sitting down though a question about the ims project is there any reason why we would need to dedicate a whole subnet to it or is just seeing all of the if instead of black holing a cover route for our announced prefixes if we just send them all to one place so anything we don't have a more specific for we send past your box is that good enough yeah yeah 