 maxwellian is a research chair machine learning at the University of Amsterdam a VP of technologies are called come Netherlands and a senior fellow at the Canadian Institute for Advanced Research he received his PhD in quantum physics under the supervision of Nobel laureate juror Toft at the all trekked university professor Welling has published over 250 peer-reviewed articles in machine learning computer vision statistics and physics we're here with professor max whelming from the university of amsterdam at nur it's 2019 and professor six papers that you advise got accepted by noir it's the series there any paper that you would like to highlight to us well first I want to say that it's like having six children and asking which of your children is your favorite one so I so with that caveat maybe I can say there's two papers which are somewhat on a similar topic one of them won a competition which was the fast MRI competition where you want to sort of predict a high-resolution MRI image but from many fewer observations and this can be used for instance for making the lengths that you stay in an MRI machine a lot shorter which would cut cost but even maybe more exciting there's now also MRI machines which can do real-time imaging and it that's that's the goal at least and then at the same time do radiation therapy USA for cancer and if you are moving in that machine that is doing the radiation therapy then clearly you want to have sort of a system that moves with the movement that's a the breathing of the patient because then you'll hit the right tissue that you want to hit and not hitting exactly very bad because you'll hit healthy tissue and not the tissue that you should be killing so with that in mind we participated in that competition and we were going to sort of accelerate the MRI the reconstruction speed by eight times [Music] and so yeah so the paper that we present here at nerves to achieve that is called an invertible recurrent inference machine that does that reconstruction using deep learning technology right before that people used mostly compressed sensing which is a different technique that doesn't you learn from other data and so we use that technology and very successfully so the paper is now presented here at nurbs at the same time we have another paper which is related to it which also sort of implements this idea that in order to you know do a task there is a lot of sort of classical engineering solutions out there which work I mean really well but not as well as one might want it because the human imagination is always a bit limited I guess you know it's if the complexities of the real world are always bigger than then what then then what you can put in a model but the data does contain that information and so what we do is the philosophy is to say well let's not throw away those models which are being built by humans but use them and just use deep learning to make correct the errors in them so that's that's the sort of philosophy that we're implementing and there's another paper that looks at graphical models and and figure out how to do it in that context what are some of the trends and challenges of machine learning that you've observed over the past ten years transient trends and challenges I know that's a broad timeframe but just you know high-level what have you seen over the last ten years and how machine learning has progressed during this time ah well clearly like any other field also machine learning is subject to fashion right and so it's like there is you know five to ten year cycles where people get really excited about a certain topic either because the theory is very beautiful or it just works really well and so we have seen I mean I've experienced and independent component analysis was you know the talk of the day and support vector machines and nuttin and visiting nonparametric methods and then you know came sort of Bayesian methods and nonparametric Bayesian methods and now it's all about deep learning so what you see is that the field is subject to these of fashion's and i think it's fine because you know we zoom in on a new very promising pool and we work it out and you get the most out of it and then somebody else has to come up with a really smart idea to sort of move the ship again a little bit um your previous startup cipher was acquired by Kyle come yeah at Qualcomm in 2017 edge computing of course is you know it's a big topic what's your opinion of why this is such a big topic like what can we achieve with edge computing yeah so what we see is that a lot of the data is collected you know in a very distributed sense but we have sensors in our bodies in our cars in our homes on the streets so so that so the the data is collected very distributivity and we may not always want to share that data with you know big corporations for them to build their services that then we use and so one thing that you can do with this it's called federated learning or distributed learning or edge computing is to keep that data away from the from the cloud but keep it sort of on your device or in your home or in your factory or something like that so you don't have to share it and then you but you you train a model in a distributed way but every time I have to share something maybe I do want to send some summary to the cloud or to some other device I annoys it up or I do something so that it becomes privacy safe so for privacy reasons it's good to do a lot of computation close by and not not do everything in the cloud there's also reasons like latency because if I'm driving a car and there's an immediate I need to respond immediately to something that's happening in on the road let's say a kid walks on the road then I don't want you know I don't want to be relying on a bad connection or on a connection that could be bad so that you know the cloud computes from me this is a kid you should use your brake right so that that computation just for safety reasons and to minimize the latency you want to do it on the device itself so you know those are two important reasons I think where you want to do a lot of the computation and storage of your data closeby the reliability the latency and the privacy what do you see in terms of the cost of doing this I think it will probably scale well I'm I'm more worried about the cost of running very large neural networks into cloud because they're you know they getting bit there's this funny phenomenon that bigger is better isn't real network so the more compute we throw at it the bigger we make our models somehow the better they perform and we don't know precisely what it is but we do know that they will use use increasingly more energy to do the computations for us and at some point that's just not a viable economic model anymore so I already hear companies say well you know we we might sort of saturate there so we might just not be able to you know to use more complex models because the revenue we were getting is less than the investment in energy that we have to make so there's a big sort of move towards making everything you know energy more energy efficient you're shrinking the models and quantizing them and running them at low precision etc etc so that they can run on your device and and actually cheaply because I have this commune my own anyways and I hope it in you know the outlet at night so it's doing nothing there it's just sitting there and why not actually do a nice computation and warm your room while you're at it right you're just turning in the attorney electricity and heat and at the same time doing a useful computation so I think you know there's there's very interesting synergies that you can think of I think what if we build a bunch of GPUs and you hang them in your home and then you know if you if you want to do a computation you're part of a network and you you turn a knob and you say okay I want my home heated to this you know level of this temperature and you just allow computations to happen on that device and you just nicely heat your room which you need to do anyway but at the same time you're participating in a large computation so I think that's a much more scalable model yeah I mean many leaders we talked to do talk about the impact of machinery and on climate change yeah and I know that there's gonna be some workshops on that later this week as well here at North's so you've served on the board of numerous since since 2015 on the foundation and how have you seen it evolved in the last four years well first of all there's of course is exceptional growth but there's something else that was very interesting which happened which basically happened last year which is a very strong move to be more inclusive and more diverse so this happened last year that we had a name change so we said that the name was nips and it wasn't felt to be appropriate anymore and we turn it into Europe's and if you see the number of things that we have done this year in order to make the conference more inclusive including you know lots of sort of minority groups which are having their own sort of sub conference like black and I and women in AI and and let an X in AI and queer in AI and you know it's like did they all have their own sort of sub conference going what you think is really good and you know new we have right here we have a sort of a childcare and all these things so I think we have evolved a lot over the last year to make inclusion a really important theme for nerves and of course new ribs represents the best AI research in the world where do you see the gap between research and commercialization right now so if the first thing is that the gap is closing in some interest in interesting ways so I also worked for Qualcomm so half of my time I spend at Qualcomm and of course there I can observe firsthand how papers which are developed in academia within a day you through archive end up at the desk of researchers and a company and they implement it and they run with it if it works right so there's an extremely efficient mechanism that takes results from academia and and moves them into into wheat into a corporate research and but the opposite direction is also happening which is that the companies are actually hiring a lot of the talent in the and they're building their own research labs and contributing to the to the ecosystem so they're contributing papers and results and open-source software like tensor flow and pipe arch but they also giving back in terms of organizing conferences like I think many of their program chairs and and board members they all serve on companies and so in some sense they also donating time that way and you know you've you have completed AI research in both Europe and North America and can you share some of the differences and similarities that you've experienced between both these regions yeah it's interesting so so there's an anglo-saxon model I think and then there is a sort of continental Europe model so I think the UK is much more on the anglo-saxon model the anglo-saxon model what happens is that as a assistant professor you you start your job and you you start your own research group so you're basically completely independent and you grow you're on your own and you grow that room yeah also have took of course get your own funding in and so there's this I think there's a really good model because it gives freedom to the new researchers that are coming in continental Europe you often see still a hierarchical model which is very large groups with you know a full professor and then associate professors and assistant professors in some kind of pyramidal structure where you know the advantage of that in principle is that you can be more coherent together so you can tackle a really large problem together the downside is I think that it it diminishes the freedom of the sort of the new researchers and it's I think as a senior researcher is really important to listen to the young researchers because they bring the new ideas and the fresh to the directions and if they get forced to work on the topic that the full professor likes to work on and I think that process is inhibited so I think I I mostly like the anglo-saxon model in that respect the final question for you at professor Welling what do you expect to see the next major trends in AI and deep learning in 2020 yeah one obvious one is I guess reinforcement learning we see a lot and you just have to look at the numbers and you see that reinforcement learning is on the rise as a topic but I think what is perhaps less obvious is the fact that people trying to build reinforcement learning algorithms so it happens that interact with the world that also generalized well if you move them into a new orientation and so or in a new situation in the context and that's what we think of when we say artificial general AI which music not just something you train on one specific topic and then you ask it to do that and it does it very well but if you didn't move it into a new context it just completely fails that's narrow AI so humans very clearly much more flexible if we learned something in one context and then we get put into a new context that we've never seen before seven we can still do very well and so we want our our agents or artificial agents also to have this property and you know one very you know clear direction that I see but I think it's not very much on the radio as if causality is being used the research in causality is being used to achieve that so try to figure out what the true physics of the world is what causes what and if you have this causal structure of the world you understand much more about the actual world and then if you move it to new context you can generalize a lot better in this new context but I see there's a lot of movement in that domain I think we also will see a continuation in making deep learning and and machine learning more energy-efficient that trend will continue a thing that will be very important because Moore's law is sort of hitting a ceiling and somehow we have to innovate in order to keep the growth going and so we're building chips which are you know extremely specialized to one particular task and then of course all these chips that are specialized need to work together and so there's a whole interesting set of challenges that has to be tackled and a lot to look forward to yes absolutely work is not finished professor Welling thank you so much for joining us today thank you you 