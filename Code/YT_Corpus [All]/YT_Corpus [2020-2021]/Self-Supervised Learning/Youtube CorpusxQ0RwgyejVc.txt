 the perceptron is the basic unit powering water study known as deep learning so multi-layer perceptron is a perceptron that teams up with additional perceptrons stag din several layers to solve complex problems understanding the importance of this we have come up with this tutorial on ealier perceptrons [Music] now before we go ahead with the session I like to inform you guys that we have launched a completely free platform called as Greek Learning Academy they have access to free courses such as a iCloud and digital marketing you can check out the details in the description below now let's have a glance at the agenda we'll start off with an introduction to perceptron and neural networks then we learn about activation functions after that we'll understand the concept of forward propagation and back propagation and finally we'll have a demo on neural networks we'll start with some problems first of all why you need neural networks the problems with we will say machine learning so let's try to list out let us say some three to four or five problems that you people feel machine learning will not be able to any medium so it's always good to know the problem and then go on to why are we doing that so any idea what machine learning is lacking or when there's a large data has one thing okay so you are saying data size is an issue yeah all right fine we'll see how to put this as a problem anybody else and then we have non numeric data okay so I will say non-numeric data perfect where we don't have enough features all right featuring issues anything else Corrections do people see that do we have I think we have only two algorithms in available in machine learning who are actually capable enough to correct themselves correct what are those algorithms we have SVM and boosting do people remember these two here they have a capacity to learn yeah so this is one issue our ml is you know as one of them which we have to train and then we can use it it does not have Auto hearing or auto correction system kind right and fifth one I will see is somebody already featured non-numeric data so I will say what if you want to process a sequential data so like I was looking at one of the codes sent by Ashish so Ashish of you've used LST M's there so are you sequel to Dallas team of them I use him like I work on that a lot of a what a lot of videos and so you have an idea Felicity right yeah yeah so this is one of the purpose so guys what is LS what are these things if you see our machine and stuff I cannot say this is a sequential data sequence in the sense we I showed you people Arriva for example timeseriesforecasting that was a sequential stuff sequence means what happened some 10 years back there is chances that it the same month or same time the same thing which might happen the seasonality part of it what if I want to take care of something like this on to machine learning sometimes it is not possible to do it and there are hundreds of very more reasons so I will say for our course the best reason could be non numeric data what do you mean by non numeric data say pictures say text say voice we cannot process it was up to some point we can process using machine learning after that we have a limitation here all right so now what we are going to do is let's try to build some algorithm into machine learning see also one more thing is even though in our course we say machine learning is over but actually machine learning as the whole box under which you have two parts or three parts here which we call it supervised learning unsupervised learning reinforcement learning after that we have something called artificial intelligence and then I will say some mixed bag of yeah so still it's a part of a melody but from now what we are going to do is say I have a box I will not say what it is we have some empty box here and I am giving some input to that box yeah so let us say my input is defined like this now when I give an input to this I am expecting a certain output so before I get an output I have some expectations let us say my expectations are exp I am getting an output here I'll say expected out whether we get confused now what we are going to do is we are going to analyze this output is it as per our expectation or not so how do we analyze let us say the analyzed using a function I use a function basically to operate on our output versus expected output all right now if this function is of certain value let us say the two values can be good another one value could be bad let us say if the function isn't bad value what are we going to do we are going to go back and make some corrections to this box now what made this output bad can I say this particular box made it bad because of this box we are getting some unwanted junk over here agreed everybody yes so what is our duty back go back and try to fix it you keep doing this in we come to the phase which we said good so we will come to this what are these things but till we find that this and this is matching he believes this is what is an example of a neural network a very simplistic approach all right any fusion to this no no okay now there are two two paths that you people observe this one path was called forward path forward path walls where I gave my inputs and this box amplified it or D amplified if you don't know if the box made some changes on it and give us an output this is called forward propagation now since we found out that this function is of not a good value we went back and we corrected our box this is called back propagation as simple as this all right so these are the most important parts within your neural network to understand that we will give some input will get some output and will keep training it till we are satisfied that yes we are getting expected output out of it okay one more example I usually use this very silly examples let us say this is the kid for example okay and you are teaching some tables to the kid say you have got five team so I'm given input that kid is learning yeah so you made you did something such a way the kid knows the people now you asked her the gate five five Zach for example the kid says five five thirty - so what do we do immediately we go and cut we keep doing it till the kid comes and says Phi Phi is at 25 this is also another example of neural network forward prop and a backward prop to correct it and keep doing it till you are happy with that okay now let's talk about that box that we were talking about now what exactly is this box so this is give me a moment I will open up my PPT one question here yesterday when we go that B go for the backward direction in that case it is assumed that we know the input as well as the output and ZF for putting into the box and very find out whether the box is giving me the output but in the case of prediction we really do not know basically the future prediction we really do not know the output so how does this really work okay so for any machine learning whatever box I showed you know whatever we did supervised unsupervised AI reinforce whatever we saw the very first phase of any machine learned technique is machine learning PC so for that we need a set of independent data and a set of target data no matter what you are doing if you are doing text processing if you are doing voice processing image processing no matter what the input matrix remains C alright so what do you have you have got some input for training that is we call it an independent data then you have got some tags if you remember I said Y actual right this is what will be our reference point and whatever we get output we will have we will call it as Y pred see we are going to compare always vibrate with y actuals all the ways no matter what algorithm you're doing and then if you are asking your future predictions one our machine is learned once the difference between both of them is reduced to our satisfied level and the machine is learned you have to disconnect this you have to disconnect our input and you give only your futuristic output which will be only your independent data so that you will get Y all right because that's more of a learning phase what you exactly yep so this is a common stuff for all the machine learning no matter what it is the first thing we have to make it learn now there are some algorithms like LS TM and all that I was just talking about yes you know those things we can predict some something without learning much of it but will come down and so when we come to NLP we will look at let me not confuse you there is right ok for now this is what is the architecture we are going to look like now there are some questions let me see ok all right ok so now let's go to this PB how to interpret your network so let's keep let's take the inspiration this is this particular topic is being picked up from biology ok and neither of us are expert on to that so we will make our own version of new let us say your brain neurons the neurons that are there and please remember there is no neuron in your brain which is not connected to other one some other other way it can reach from here to let us say to some other you know yeah so that is the first part of it which is called fully connected neural networks this is the basic of all the neural networks and that means each neuron is connected to all other neurons in the network alright now let us say you divide this into four parts this is part number 1 2 3 & 4 now when this brain was newly formed that means when this was a baby at that point of time all these 4 web of almost similar these zones were not differentiate now what are these zones you may ask me let us say this is my happy zone for example this is my sad zone ok we will not compare it with real biology because if we do it we are going to fail on to this so I'm just showing you certain neurons belong to happy certains on sardines want to say relax part of it or sleepy part of it and certain zone to the anxious part of it for example okay let us say when the baby is newly born they have not seen much out of the world so what they do is they mix up all the emotions sometimes they keep crying sometimes they are happy they don't get it now when when lot of events happen day to day life and the person who grows up to some level there are certain learnings that the person does and the person tries to store those learnings in each of these knots depending on the zones so let us say after let us say at the age of 30 if a kid passes with a very good score definitely the neurons over here will be active alright so please remember a neuron can be activated and a neuron can be deactivated that means in the happy phase all of these will be deactivated all right they don't continuously keep running the electrical signal is sent from one to another one only in certain triggers situations all right so this is what is the theory behind why we use neural network so from here now we will try to put this whatever I said onto the machine part of it so let's see so what basically you will learn at the end of this particular session as intro to neural networks working of a neural network forward propagation backward propagation and types of neural networks so we will see do this on a very detail because now whatever for five months you have from your course we will try to explore almost every type of neural network available in the market right now next one what exactly so I explain you what is a neural network why do we use neural networks so please remember it's a very simple neural network can adapt to changing input so the network generates the best possible result without needing to redesign the output criteria what do I mean now let us say for example we take linear regression yeah in linear regression if we have baselined of our equation people remember this equation right I think we started our interaction from this session itself yeah now is it possible for me to change the inputs if I change the inputs will this work we are not sure if the inputs are very close to what we trained it on yes it worked if they are not it will not work this model will crash what if I tell you that there is a possibility of making a machine learning model no matter what you are going to give me I will relearn myself always and I will deliver it output what if I have what a self learning kind of stuff yeah so I will say this is more robust to changes this is more adaptable and this is forth quicker in the terms of learning yeah so this is where you are going to need your neural network so the box that I just draw on the whiteboard that was nothing but your usual guys do stop me if you find it difficult to understand yeah now next one what is the application of it so basically I hail from deep learning background this is what I do on my daily basis in my job now you can use deep learning for anything whatever you have done so far classification regression you can do the same thing on your network so the first thing I would say is decision making that is your prediction and decision second thing is if you want to go a little more complex you can talk about image processing so what do you what do I mean by image processor so let me quickly show you then then do you think you know the DL is much better than ml yes definitely okay then why why the people use ml then yeah I'll tell you why why do we do that just give me a mint okay data science contains deep learning yeah so now let me take you guys through a very simple application of neural network it is not simple to code but yes down the line we are making it more and more simpler in a minute I have too much actually over here the main image recognition and image let us say I have a screenshot from a particular movie alright so this is a screen shot for me now I want to automate certain things over here so I will give you an example if you people are on Netflix or Amazon if you click on the star cast the particular scene which is going on they will give you the they will match it up who is there in the particular scene and they will give you the description of the star cast every guys observed that if you stop the screen immediately and check for the stars especially on that's one prime you will get the names of only those people live who are there in the scene have you seen that no nope just is in prime you get to some correct how do they do it very simple what do we do this when you click onto that star cast button the Amazon Prime uses its own image recognition system and tries to create a boundary can it mean use a different color tries to locate a face in the picture you would have also seen these kind of stuff nowadays flying around on YouTube if you are talking about a I know they will see people who are walking and they would have made one box around the people who is walking and they would have said this is a person who's walking it's become a trend now to post all these things on YouTube and LinkedIn just to show that I work on a I part of it yeah but it's not rocket science we are going to learn down the line now this is what I want to do so how to do this very simple first of all you need a big corpus corpus means a back-end data saying that we don't we don't know whether we'll get image of this lady or not we don't know whether is there in corpus but yes we will get lot of images of men in women and if it is a men the tag attached to it so if I say the independent variable is men the target variable attached to that will be men that is the image is men the target variable attack - it is men so this is how I tell my neural network that I am giving you an image as an input you have to adjust your whatever is inside such a way that you have to give me so whenever I give you this image you are supposed to tell me it's a men you know so this is how we do it so let me now show you how do we do it so this is an untagged image let me try to copy the name of image and now we will try to push some kind of brackets on - yeah let's see so all I need to do is this is my version of image processing okay so just hold on for a minute a kernel is dead just give me a minute guys why am i showing you this is so that you get to know why are we learning deep learning otherwise if I would have start with neurons and all it will be the same as our video yes and here I will paste our image yeah so saying yes it is showing me there are two faces that he has detected did you see that and later on if I you go and see here this is my output image it is very simple it is showing me and we have detected two faces here the next version of this could be find out who the celebrity is so what we have to do we have to give an input corpus of all the cell and we have to retrain a network saying that if you get this particular image whoever this actor is all right so this is how Amazon and IMDB and all these people do it if you want to take one more example let us say we take a complex example look at this image it's pretty huge right so what I will do is Liu push it across through a neural network so just let me copy the name of the image will input it so this is a pre trained neural network I am not real if you observe there is no neural network running here why because my neural network is currently lying into this particular format you don't have to keep running your neural network every time you can store it pickle it and whenever you want it you can put it on in this case I have an XML file which does my job now if you take some time because there are a lot of faces there and it will show me how many faces are detected if you observe these saying we have 29 face is detected let's go and see the output this is how the output looks like yeah and you will observe some of the faces are not detected in your in you spot those faces 1 2 3 4 what is common between all these faces can I say they are tilted yes yeah so there is no box around it that means the corpus that I have used to train this particular neural network needs me to have a straight face or full face for this particular person the full face is missing all right so this is how you this is the end application of a new little I will say clear we will go deep into it down the line in computer vision session anyway so this is how we do image processing using neural networks ok speech processing so I can talk something in from the corpus the network can pick up and it can tell me what I spoke about ok not sure you have seen this earlier but [Music] yeah so this is my speech-to-text converter so just observe I will talk something and after a once I talk it will populate here and it will tell me what I spoke about alright so hello everyone hello everyone vir hi everyone yeah so you observe it said hi everyone if I say some of your names say Raju are sheesh mohit Raju Ashish Mohit yeah did you see that so how does it take it it what are we doing is basically we are running some kind of Google audio in the backend so it is not only understanding what I'm saying but he's also trying to translate it and move so basically this particular board what it does is it's a payment bot so if I say I paid 300 or finally rupees it identifies what I'm saying and then tries to pull out the money oh yeah so this is one more application where you can use your neural network for voice mod takes part of it so text is not in our certification context but I will show you guys down the line how you can use this for text also yeah again gaming I will say it's very big industry when it's out of my scope also it's very complicated and on the futuristic next five to ten years you can expect something like this to grow up so I'll give you one example there is a startup who is working on an eyewear for visually impaired people so that particular eyewear will recognize what is going around the world so well let us say the person is sitting in a park see if he wears those glasses the glasses will analyze is what is going around the park and those analysis will be sent via voice to blind post saying that there is a dog who's white colored he's running there are three kids were playing a football looks like it is going to rain if the person is walking it will question the person I am able to see there is a car coming please hold on you know so whatever challenges he has because of no vision they can overcome this so probably next four to five years you can expect this to be very common so computer vision and AI is working towards this so this is where you are going to use this I'm not sure how many of you are going to actually work on this industry but yes we're very good no place to work in to our next fight Romania now coming on to the real part of it now what exactly is a neural network we saw the applications very good now this is how a simple neural network looks like this is an example of fully connected neural network F CNN because if you observe each neuron is connected to all the neurons in the next layer it each neuron is connected to all the neurons in the next layer so you're not leaving anything we are fully connecting it now what actually happens let me show you so what we do is we give an input now each neuron or sorry each line that you see over here has got a weight some random number you can say which gets multiplied to my input and goes to the next neuron the whole game over here so if I ask you now let us say we talk about some of this machine learnt algorithm let us say we talk about SVM can somebody tell what exactly we learn in SVM we give some input right we train the model till it learns and then we say okay of the model is trained so what is those things that we are learning in his field if somebody can highlight that in the pattern in the input perfect but turn theories whatever which can define the whole bottom data so let me show you a small clipping and after that we will go into an excel file where we will simulate on your okay so just observe this clipping for now and then we will see what happens okay so you will observe there is one number seven which if you observe this number seven we have divided this seven into some kind of pixels or a numbers those pixels and numbers are going in the first layer as an input okay and if you observe some of these are on some of these are off so if I rewind it yeah so this is my some layers in the box and this is my output so if I give a number two you will observe this particular neuron will come as an output saying that I have identified that the image belongs to number two now the image will belong to number one so this one will be highlighted so this is a very simple example of classification do people agree this is what we do in machine learning also right yeah we classic the only change here you guys will feel something newest how do I fragment this number seven into the inputs how I give it to them what happens here and how the output is it that is what is the today's challenge I will explain you guys how it happens another way of understanding a neural network classification could be as simple as this if you observe there is one image of a dog which gets penetrated into some of the environment and finally I say it's a dog this is how we do object detection you give any object if the neural network is trained on that it will be able to identify no matter what breed what angle we have taken the photo whatever it is you will be able to detect that it is a animal which is a dog okay so now there are three layers which are most important here one is called the input layer one is called the hidden layer and one is called the output now let me shift you guys to that people file and we will simulate something so we'll start from scratch yeah how does a neural network work as I said we have three layers input Haden and output so please remember as we are talking about neural networks the complete operation whatever it is it should be in the form of numbers no matter if we are dealing an image or we are doing voice or we are dealing text whatever it is image number goes in number comes out yeah so let's see how it does so the first thing is your input layer so represents the dimensions of the input vector now let us say I have a data set which looks like this it has around one two and three columns independent data and this is my target data yeah so if I have three columns that means I am supposed to have three inputs to this that means each neuron in input represents one dimension all right good and each neuron in the output represents my target column so let us say in target I if I have zero and one so this neuron is supposed to detect zero this neuron is supposed to detect one that means if I give a combination let us say the combination of 0 0 0 that means when all three of them are 0 it is going to highlight that this is your classified outside okay so this is input and output this is how we decide input an output now comes the hidden part of it now what exactly is a hidden layer hidden layer is randomly I will not say randomly but it is our choice that how many neurons you want here how many lists some some of them have 10 layers some of them have 2 layers for lists whatever these are nothing but the same neurons but the only thing they are connected in some other other different way all right so if you've got three less input/output in hidden any shoes on to this simple don't worry about the calculations we'll see but so far so good all three layers are ok ok how we yeah now we'll talk about something called activation function now what is an activation function if you observe this PPT carefully you will observe that not always all the neurons are on did you see that some of the neurons are off correct and in output other neurons are off only one neurons on so you might be wondering okay how this happens this is the job of activation function activation function acts like a switch now let me define one activation function right up let us say we will design a function which says if my number is greater than one then I will activate that I will say pass the number to the next neuron if the number is less than one I will say switch it off now in my input if I give a number of one point to what's going to happen this is your function you will choose this one and you will say that that current neuron is active pass the number to the next neuron allow the number to pass through these are called activation functions this is a simple one I've shown you okay let us dive deep into this activation function theory so there are so many functions available like this we'll go one by one before that let me show you what happens in the neural neuron so imagine this is one neuron this one and this neuron I have represented here for example any of the neurons all of the neurons have same kind of look what am i doing and giving some input to anyone this is my input X is zero there is a weight and if you ask me what is this weight I will sell randomly chosen number okay during your forward propagation when your your network is built we randomly assign some number say our andn and we put some number yeah that random number gets multiplied with your input to become W 0 X 0 that W 0 X 0 from the other neurons we get W 1 x 1 W 2 X 2 so these are inputs from other neurons all right all three of them are coming and converging here so if you want to see an example just have a look here so if I say we are talking about say this particular neuron how many inputs are coming one two and three so this is my X 0 X 1 X 2 alright so you can imagine that way now inside this cell inside this neuron what do we have we have an activation function we call this as an activation function here F and also there is one random number called bias which we have to add it with our addition of all 3 of them so if you observe here what is this w 0 X 0 plus W 1 X 1 plus W 2 X 2 plus some random number called biasing factor all right now if this particular operation is greater than certain value the L it is allowed to pass if it is if it does not satisfy my function it is not allowed to pass ok now let me see let me show you what are these functions so if you observe here what looks like very complicated activation functions but actually they are very easy we'll start with the easy function this one have a look at this unless and until your output is greater than 0 it will be or else it is 0 this is called step function second one is sigmoidal function have we done this earlier in any of the algorithms can you reconnect this have you done in sigmoid in anywhere else regression regression logistic regression allow this correct log R and one more kernels oh yeah SVM kernels you remember one of the kernels tangential sigmoidal curve yes what does it mean if your input is between say this phase and this phase it will continuously increase if your input is less than this the value will be zero and if your input is more than this it will be a static value of one if you expand this a little bit more okay and one more thing this is not real loop I don't know why I wear it already over here this is wrong this is sigmoid and if you expand this little more on the depth part of it but you have to cross through zero that becomes a tangential function alright third part is called rail okay so what is rail you basically rectified linear unit so if it is less than zero it is permanently zero if it is more than zero it is a linearly increasing curve this is one of the most popular activation function we have used we are using actually so depending on what type of inputs you are having you can use one of these so down the line when I train when I will show you guys how to write case studies and how to decide your networks at the time you will try to choose all this stuff as per our data yeah and there is one more important activation function called softmax whenever you have a categorical output now we just saw that there are two type of possibilities over here the output could be categorical and output could be regressive correct same thing we have done in machine learning also if your output is categorical the default function activation function you will use only on output layer is called softmax it is a categorical activation function if in case you have no categories you have regressed outputs regression as an output in that case you can use any of these are we clear all of you true yeah so how what are these functions and all we will see when I the stuff but for now I'll be clear we have sigmoid and relu and threshold these are some of the most important ones and why do we need it just to manipulate our number and let it pass for me that's it all right now moving on Duke so this is how overall on a very high level neural network works now let's try to simulate one so I have simulated a neural network in excel file now let me show you what it is now please we cannot do this on a higher level but on a very simple neural network you can't train it now observe my network so as an input what do I have I have got some alphabets from A to Z now please remember computer does not understand what is a what is it what we do is we do somewhat cheating at the back end we tell the computer that if this is the number it should be displayed as this figure if I get this as a number it should be displayed at this figure everybody agrees to that yeah binary logic and all if you have studied in the computer science and this is what it is same thing applies in neural networks also so say for our sake what I have done is I have taken A to Z and I have divided numbers between 0 and 1 in 26 equal distances all right what is my job now is my job is to train a network such a way that when I give when I say that WH Y okay in English spelling it should also give me the same numbers as a know but in the form of numbers and then we will map it up in the form of digits oh sorry in the form of letters all right now let me show you what exactly are these calculations and what we have done so before that how many inputs do I need so if you remember I say total number of independent columns is equal to our inputs in this in this case can I say I just have one independent column which is a agreed so I will need only one input how many outputs do I need it is ok first of all what is it is it a rigorous or on a classifier it is a third classic mmm look at the numbers okay one way you are right because we are passing ABC but in this case we do not have softmax in Excel files so what I have done is I've made a regresar and then later on we'll we will try to classify but perfect runs so it's a classifier with one output so this is one input one output all right and then you may ask me okay what are these other things these are my Fidan layers you will see down the line what are these and how I designed this all right now let's try to pull one number say I pulled out W what is W equal to 0.847 two that is what my actual value is this is my actual Y all right now what I am doing is I have to choose some random weights new people remember we talked about weights randomly chosen data now let me randomly choose some bits so I will make it say 0.8 4 5 4 245 say 80 67 some random number whatever we like alright so I have chosen some number as my weights now what are my weights way do my weights like my weights will lie on each of this line so this particular weight 0.7 that you are seeing is a weight given to this line so when my input 0.847 2 goes to this particular neuron it gets multiplied with this weight are we clear on to that everybody what are these weights this is my biasing factor and these are match you'll beach okay nice do let me know have you okay with this any any issues there poetic or when the concept is fine but just from just one thing I don't understand how this random number comes because when we say that the output is dependent on the input as well as the weight which is coming up so the weight the number which we are choosing for the way it is something which will influence output also exactly perfect so what is our job then to back propagate and adjust the ways such a way that my actuals and my prediction should match okay so basically that's part of learning in this case so cooperate the brain with it okay exactly the whole game here is to adjust this weight such a way that the output that we get here matches my input all right do you see now output input matching not at all right look at the loss function that I put our MSE that is around 5,000 plus or something agree so whatever made so sorry what is what is the problem that we are taking here the actual and the MSE yeah okay so the first thing what I did was I multiplied my this with my current weight and activation function I have used sigmoid onto that now you have you may ask me from where I got sigmoid it very simple we wrote a logic here or a macro over here to simulate sigmoid now what is sigmoid on a very simple scale sigmoid is defined by 1 upon 1 plus E power of minus X what is my X X is one of my inputs given to the sigmoid function that's it so what I've done is I have my own sigmoid function where what I am doing if you observe the formula bar be 5 into this one okay correct yep mine my this one what do you say bias factor and I sigmoid it up that means I whatever manipulation I am doing down the line I am putting a sigmoid onto that and when I put a sigmoid onto that the value that I get is 0.01 to which I have perfectly spoiled it up because my original value is 84 and the value which I do after multiplication is little weird okay then so this is my n1h one same way I take this up multiply it with next weight put a sigmoid onto that and get this okay third one is n 1 H 2 so this one so if you remember if you see here now now we are getting inputs from two of them we are getting an input out of n 2 H 1 and also W 3 same thing whatever goes out gets multiplied with the new weight 3 will put a sigmoid onto that as an activation and will throw it out alright so our data is propagating from here to here so when my this particular data propagates from here to the output it becomes minus 42 and if you ask me why it is all because of junk weights that we have put agreed everybody agrees to that the weights are causing this issue right so what what we should do now if weight is responsible for making this issue we are supposed to go back and change the waves now how do we do this in neural networks we call it back propagation I will explain you with formula now but for now in excel file what do we have is me and site data we have something called solver I don't know if you people have used it my intention here is to reduce my rmse now everybody knows what is our MSE right root mean square error it's a loss function what do you mean by loss function difference between my output at predicted output and actual output that is what we call is loss function everybody is okay with this our MSE all right now what is my intention here is to focus on my are MSE here and my intention is to reduce my animus II agreed yes or no yes yeah yes we'll go to the formulas now after this we'll I'll show you in derivative way how to do that next what is my intention here what I need to change such a way that my RMS it should reduce can I say all of these junk weights I have given those weights over here now let me click on solve it will take some time but you observe the way it's changed and the weights when the weights are changing now can you look at my rmse from 5,000 odd it has come down to almost zero you agree three point 2 into 10 power of minus 6 is almost zero yep and look at my output now and look at my input now can I say they are almost in sync yes or no so can I say I have designed a network here such a way that tomorrow if I give this particular value it is going to identify that it is W or at least if I give this value it is going to identify it is are you able to visualize that enough let test it let's try to test it so for example I have given a value s here s is what what is the value of S is 0.6931 okay so when I give the value automatically all the calculations are done and the output that I get is zero point six nine zero four zero seven five how I got this using these weights and the error that I currently get is zero point zero zero three negligible amount so this is your forward propagation and what we did here using solver was your backward propagation one forward plus one backward represents one epoch in a neural network so neural network continuously goes front and back front and back front and back till I find my loss function to be minimal till my weights are adjusted to the very best values this is the high level overview orphan unit so on the solver whatever it did right so it's this is very very easy and good to understand the solo was just trying to adjust the weights and keep keep iterating is it probably it will done whatever rate to ten epochs to get the right value current okay how does it I just adjust is there any way yes there is a way to adjust that so let me show you using formula but before that I'll be clear with two processes forward and backward now if I say fall forward prop and backward prob you will be able to visualize what I'm talking about forward prop is your activation functions backward prop is adjusting your weights alright yes we'll come to that we will come to that one by okay don't worry about how do we put it and how to choose this and all will go deep this is not possible in Excel files they have a limitation of only using sigmoid so if I use relu so if you look at my rail ooh if you look at the rail you any value which is a negative will be switched off agreed yes on us we will will this rail you allow us to pass any negative value I will see this is vital information and one more clarification can you just go back to that picture yeah say like from input to this NH one this w one is getting passed right is the activation function work here or from image in one h1 to win will it's only the activation function will work division here activation function resides here and one h1 the multiplication happens here and then it goes to activation function is okay so from input the activation function will not work one lemon it goes away 1 x2 the activation function we get yes yes perfect perfect good now let's come to some heavy maths so now you might you people might feel getting little heavier so what do we do so let me explain you forward propagation in a more complex way now so now when I talk about weight slayers activation function now you will be very clear ok so now will not repeat what is activation function now let us say I have got a weight or input X X gets multiplied with w1 weight of that line and I get alpha one which goes inside an activation function I get alpha which gets multiplied with my next weight and gets alpha 3 alpha 3 or a 3 goes into new activation function it becomes a 4 a 4 gets multiplied with some weight and I get my output this is your forward propagation okay now the same thing you can see over here this is my input this is my weight 1 and if you remember I said there there there could be a biasing factor it is again a random number we use it so this into this Plus this becomes this then I pass this through a sigmoid function so when I pass point eight one through sigmoid I get 0.693 that is your alpha two this one same process happens till you reach your output so if you now observe our input actually wall 0.84 and because of this whatever we did in middle we got some loss of 0.8 three numbers what random numbers random numbers if I change it if I this it will change did you observe its changed anything actually float is better integers there is a function which will allow us to put only integers but then there are some problems with that I will show you why all right okay so this is what is your forward propagation now any questions on to this how this value became this value any questions perfectly here so you imagine if there is a bigger network like this say you have a bigger network like this now if I ask you guys you know what goes in and what comes out are you clear with that forward prop yeah yep good now let's talk about what happens in the backward prop and how those weights are learnt now so before moving on to backward prop I will ask you there is a very simple question what will type of loss functions you people know so far what are loss functions we know let us say at least three of them will talk about what do you mean by loss function why pred when compared with why actual that's your loss function how do you compare it subtraction with distance F are there agreed MSE and si are MSE yes these are some of the loss functions that we know about right now let's come to the complex part of it now how actually we learn the weights now it was very easy for me to use solver and show you very easy because you have a ready-made function it worked but what happens in the neural network how network and the stretches so see this is your output okay so this is what you are supposed to get and so this is what you got and you are to get why as an author this is your actual this is your predicted so if I have a function which will take care of overseas why I will define this L as my loss function okay and what we need to adjust you put the things which are in scope so my current for my back propagation only the highlighted part in red is in scope that means we need to alter one of them or all of them or combination of them such a way that my loss function is decreased all right now which mathematical function helps us to do that my intention is by how much my loss function will change if I alter these what kind of function we can use here from our full days you can recall some functions we have done this you people know it but me we don't know the real application of differentiation perfect of quickly identified we will say it by how much my loss function will change if I alter same wave number five everybody who is okay with this differentiations yes it's a step function so how by how much I should change so that this will reduce very simple now if I want to develop a chain rule here okay now how do we do that so now you may ask me fine we got a differentiation but how do you say which way to change and how do you derive the equation so for derivation of equation we will put here so it's not needed but it's just for your understanding of backdrops I will say by how much my loss will change with respect to my actual output that I've got sorry a predicted output that effort that will be my first differentiation multiplied by how much my output will change with respect to my rate number five agreed multiplied by let's write the chain rule how much my wait five should change with respect to my alpha for how much my alpha 4 will change with respect to my alpha 3 how much my alpha 3 should change with respect to my weight number 3 how much my weight number 3 should change with respect to my alpha 2 agreed as you're getting it how much my alpha 2 will change with respect to my alpha 1 and how much my alpha 1 will change with respect to my weight 1 in P go anywhere further no right because wait and X is not dependent on each other in any way I did now just think about it if you want to just focus on how much you should change this wait what we should do cancel this and this what I will left with and I say we are left with dough off l / do off w5 agreed yes now keep canceling what if I cancel this this descenders gone descenders gone now what are we left with can I say doe off l / though off wait number three yes correct again keep changing it keep canceling canceling what are we left with doe of L with respect to do off wait number one simple so now can I say I have got a method to find out how to control my loss with respect to all three of my weights same way you imagine a larger network where there are so many weights the same rule happens and the weights up optimized in the backpropagation all right simple huh so you know we are changing the layer 1 wait you can fix whatever you want so if you say you want to change all of your weights you can change all of them if you say I want to freeze this weight and change these two you can do that as per the chain rule form right okay well you're understanding the first week you can assume that yes all of the weights are getting changed in one first backpropagation with automatic calculation do be absolute specifies I'll go it automatically one time and what it says automatically in Python we have something called optimizers they take care of one line will take care of complete optimization the way we did it in solve are no in itself same way we have it in white yep once one line that's it okay so today I will show you a neural network which can be designed in three levels that's very funny your network classifier very simple you don't need to go very complex models you can even do it a very 3 to 4 line that's okay now any issues with back prop good alright so last one just from my side I know we have done this softmax function in somebody tell me what was soft max again one more thing this all the calculations everything in them into fights and fight and you don't have to do anything so whatever mats I showed you know it is why you're on this in Python within seconds you will be able to train your network right ok final one no more theory now we'll go to practice what is soft max you people remember what was soft max okay soft max is an activation function please remember don't forget this here soft Max is an activation function to be used only when you have an output which is a classifier if you have an output which is regressor you can use any of these alright and you don't even have to worry about the formulas you just have to remember the name that's it one name in Python is enough to do all of your calculation good so now can I say at least 30 40 percent you guys are clear on what our usual Network star like like softmax is mainly used for multiple categories right for Helsinki for Cindy classifier can be used sigmoid will that we find next yes you can do it for a single classifier even you can use a step function here okay Oh zero yes yes zero or zero or one that's it even you don't want to use the classifier no problem with build a filter of our own so we take the output and we'll say if it is this answer is this or it answer it is anything but yes you for two classifications maybe you have two class defines you can use any of these not at all click on one question it is from the the video classes so in that video he told me that he told us that because the function as a constant value so we would not be able to calculate the flow and hence the grading method would not work yep my question is why do I'll be using rail you and it has become more popular because half of the real you is also a flat like that do not be able to pursue the gradient ascent or better no see if you look at this rail ooh is continuously increasing value is not reaching or radio is not parallel to x axis did you see that negative value it's flat correct correct perfectly right if you ask me yes yeah if a value zone we've not be able to create the gradient decide and I'm not be able to correct position no in that case I will say me let me correct your let me your approach here a little bit please remember we are talking about a fully connected Network so if I go back do you think this is fully connected yes each neuron is it connected to the next layer so even if one of the one of the function is clipped out there is another function which will help to pass it through you getting my point let us say this is a negative value yeah this is a positive value and let us say this was a real ooh in that case you are perfectly right if only negative value is going inside it will be clipped off but also along with that we are adding one more wire which will allow us to go forward correct since they are having two inputs there are chances that one of them is positive and it'll allow us to go forward that's it yes yeah once we move in the same concept would apply into the step function as well isn't it he so he's in the step function as well one value is positive one man is negative when if one man is negative so we it would allow us to we go through the next next iteration but the way it was taught in the class it was from the point of view of the gradient descent so trying to minimize lost and you know in order to minimize the loss we need to know the slope of a or the gradient ascent of the location where we are in the plane and that is positive or negative that would depend of they will need to go in the real function and half of the times you will not be able to calculate if they we are mean this see in the proponent of a gradient descent I will not give all the model correct perfectly so now yeah yes possibly something no you are perfectly right Andre Lu and you perfectly your analog is perfectly right and created but I will try to reshape your gradient decent understanding once more so then you will be able to fit really one yeah but here's you are perfectly right if in case the enter a negative zone definitely you are not going to get anything out of okay so let's now try to get a very very detailed or I'll say a sneak peak on do gradient descent so what as for you guys is gradient descent what exactly you mean by that in somebody quickly let me know what is your understanding on gradient descent basically calculating the slope of a V a V I in a particular plane and trying to minimize say trying to move into the right direction I love you go into negative right additional to the positive you know to minimize the loss or any function that we're trying to okay perfect now let me reframe that let us say let's not use technical too much technical term like slopes and orders when we do that people get confused so let us say these are my weights alright and this is my loss function there is one particular place where the loss function for this particular weight will be zero agreed every weight has one point where the loss is zero at least let us try to draw a diagram let us say we have a gradient descent diagram like this for example okay and also we'll drop a line over there saying that this is the line of optimal weight now there are chances that you might be here when you chose a random weight you might be here so when you are here your loss is pretty high really or else there are chances you chose a very high weight we are not sure about it at the time for your loss is pretty high in both the cases as well as you were saying is you have to either reduce the rate or increase the way direction of the gradient listen in this case my direction is towards right in this case my direction will be towards left all right depending on the slope and on whatever C was say let us say there is one number or there is one factor called loading rate I tell my back propagator yeah whatever I am going to use in back propagation I tell him that every time you make a mistake every time you get a loss you reduce or you move by some number X so every time I have a backpropagation my rate value goals by X values down or in this case by X values in this side these this keeps happening till I reach a spot where the losses in control or I have reached an actual position of zero so this is on what I kept now the lines that I kept here these are called sweet zone sometimes it is not possible to reach here now I'll tell you why let us say you have chosen a value of 0.1 and let us say when you kept doing back propagation one time you have reached here now if you add point one to this you are going to end up here and if you end up here what happens in next back propagation you subtract when you can subtract the learning rate you are going to end up here so this is what we call the oscillation zone there are certain time because of learning rate we will not be able to reach in that case we can say that we will put a boundary saying that yes we are ok with this set of gates this is what is my take on gradient descent are you are in sync now I think you people also have the same idea right the only challenge here is to understand how to choose this and how many I box on an average will take me to reach over here how many back propagations will happen to each of them all right yeah so Roger one thing is you are perfectly right Andre loop so you're gonna clip the negative part of it but also remember we are not using only relu in the network one layer could be using rayleigh another layer could be using a sigmoid also one layer could be using soft mixels since it is a combination of highly connected lengths it is sometimes okay to ignore certain neurons even if they are creating a mistake it is okay we can ignore them and they will not create much nuisance in backpropagation because of this this gradient is will fall I hope you got you got my point already yeah I just wanted to you know that a they've something other than available - yeah I just wanted to clarify that there's nothing much I cannot do that I might have missed yes so it is very good I am very happy these you guys was my other batches we're not very focused on activation functions but it's very good to know this because if you have a good idea what is activation functions and when you use your neural network designing becomes very easy because you have to and make this yeah so you have to choose activation function there yep all right perfect good so now let's try to design one of them so we are not done yet there are some more concepts which I will show you one by one so I think week 2 also have covered almost using this so I think your next week's video the week two videos will be very simple for you guys now before moving on I would like you to introduce to some of the libraries within networks there are many actually and now there is a big boom every company is putting their own library yeah so the most important library for learning is tensorflow the latest version of tensorflow now it is just released it is 2.0 I am currently working on 1.0 I am yet to migrate to 2.0 it is like you learned Python 2 and suddenly Python 3 was launched ok so it is very critical for us to transfer this because some of our codes are very hid and since this is new I am also waiting for it to be stabilized and I am also waiting for all the solutions available online after that I will migrate the codes will change so this is tensorflow what is the use of tensorflow tensorflow is an end-to-end neural net library which is owned by Google for now it is free not sure later but it is owned by Google and what it does it gives me the statistical power so whatever back forward prob back prop activation function weights whatever you saw could be managed by tensor flow the calculations could be managed by tensors good and also if you observe there a certain hardware that we need we need some virtual neurons who can hold the values locations right even tensor flow can do that we have something called PF lon which can do that but to avoid it what do we have we have a better version we have got Charis Charis is a high level API which sits on the top of tensorflow and simulates a neural network for us good are we clear Enza flow versus chaos you can build a whole network here also without chaos why do I use chaos it's easy to define impact alright we have one more called PI torch hello people heard about pythons any time yes yes I saw some very powerful library very powerful only issue it PI pouch is it's a low-level programming language this is a high-level programming language like somebody just asked me that while doing back propagation do we need to do this manually I said no why because I have a simple command which will help me to do it whereas in PI toss you have to hand build everything not now now PI torch is evolving yeah so pi thoughts is again a very popular library for academicians and researchers so maximum majority of the science when you look at a AI based paper especially from a university or a research company they will be using white or short one why because they can handmade things they don't have to depend on this I am a big fan of tensor flow so whenever this upgrades happen now I will be bound by this I have to upgrade it whereas in this and handmade distance but it's a low level one means you have everything beautiful from scratch okay so this is Phi dot apart from PI touch there are so many libraries I mean like if I if I show you guys a library called say Swift for example so whenever you want to deploy your AI on to iOS or Android this is one of the most popular libraries sonnet sonnet belongs to one company called mind learn if I'm not wrong and these company makes or publishes lot of AI based papers you can use their codes to learn the only issue is they do it using their own library called sonnet they do not use stencils no colossal so we have triple nothing like that there's so many of them away alright so the most popular ones if you see now as for your starting purpose these two are very good please learn them thoroughly and after you master that you can go on to PI taught you so you have a complete explosion of all the libraries good so these are the libraries especially you should know the difference between those two so I'll give you one example recently I was taking an interview was one of the candidates and when I asked him he said me I am from a back and this is the harsh reality of our field everybody says yeah I know artificial intelligence so I very simply asked him okay what are libraries you have you are aware about so he told me tensorflow and caris yeah so I asked him that can I use tensorflow independent without using cos he said no this is where people will pick you up saying that you have no idea about here so out of ten interviews that I take on AI nine of them I reject it because of these reasons so people would have seen the codes they would have done it but if we don't know the basic difference way to use what then it is very difficult to build a networking ta because it's not a straightforward method to be very front so guys please be careful with these two and try to learn documentation part of it so they have both of them host online some recommendations please keep it handy yep and keep in habit of refreshing your knowledge on both of them every three to four because they keep updating it they do lot of updates one question here as you said in this lab we'll keep on updating so I was working on one library that they're compatible little Python 3.5 so I'm able to run the template code on gu4 lab but I'm not able to run on my Python but the library so what is the solution out of that how do we take care of this kind of problem yes so what you can do is let us say this is the code that you are you have put your pythons a 3 for 3.5 for example and it has got everything underlined what we can do is we can pickle this you convert this whole thing as a function if possible and we will pick a letter that means we'll store this function and we will use it as a how do you say API get my point so we will define some inputs and outputs of the function so say you are given like how do you say input file is linked so we have to name the file here and that file has to be worked on yeah so there is a function called pickling that is down the line that is the worst thing you can do but if you can see if it is understand under its Python 3 I don't think so there should be a big problem did you check it up is it because of python version or anything else is initially are you sure it's finally come for you here so I was watching a few videos on this in this particular library so most of the those videos were on 3.5 Python of it before hey that Python so they were clearly saying that it should be working on it by some 3.5 or 3.3 like that and that's obvious calling it so I have Python 2.7 when I am Kryon is running it so it is showing that it is not a in addition to showing a lot of conflicts so I would easily I forgot the library name I shared the name with me I have another machine with me which I use it only for R&D let me down grade myself to Python 3.4 and then try and not even 3.5 I will go beyond that and let me try loading that let's yeah yeah oh yes there are sometimes possibilities like this sent you an example the child bought that I made no so I got one request from running saying that we want to use only TF infer flowed to build a chat pod we don't want to use Cal so what I did is to use tensorflow end to end without Kerris we have to use something called TF lon okay TF LAN is not compatible with latest version of tensorflow because they have changed this library here yeah so what I had to do is I had to downgrade myself let us say from tensorflow terms of float to to say tensorflow one point something and it is exactly like what actually said as it is not working below certain levels so i had to actually come down to one level below that and then this thing fired up so what i did was i pickled it up because in a sense i know this is going to be a problem so I converted this to it into a runnable function onto any of this worse it was not that easy because the the files the stuff has it is a function commands like input TF learn but if I'm using the current version of TF in my Python definitely it's gonna give me an error even this solution might not work that get yeah so yes since we are using something free this will happen and it has happened many times in my career where this is not working and you have deployed something so what we have to do is you to find a fix for that all right yeah one more question related to this so how is it be possible to downgrade the Python version or time salvation without losing the previous data that we have worked on yeah yeah you see if I downgrade I just need to know if I downgrade is it going to overwrite my if I have a control of where Python is going in copying the file if you know what I'm saying your C Drive it is going to create one folder if it is going to overwrite my current folder then yes you will lose it if it is not overwriting if you have a control over that to create another folder you don't worry about it it's it's going to be as it is it's all about a folder that's so if I save my file into another folder and then try to download it then it would not have anything yeah I should not be wrong genius should not be a problem I mean it would I find a simple code usually kind of corner or fee if they do I have to uninstall Python and then install it again ID you need to uninstall Python and then you need to install the specific version or if just look it out just check out on Stack Overflow or geeks for geeks any of these websites is there is there a place to run two of them because I am using Mac right so in Mac I have an option okay the original Python that I'm running is two but I have an option to upgrade it to seven so I can run both of them okay in Mac it is possible so what you can do is you can have a Linux VM or if you can have virtual machine I don't know whether you have done it earlier but if you have a VM you can do it easy you don't have to worry about any of this but if you are doing in Windows life I will say store your Python as you say and then uninstall it and then reinstall the new version this is what I know okay but try to check on Stack Overflow if there is a command to have both of these versions and to choose which version to run I'm not sure about it how much storage you have in your back Krishna this is simple to see 128 this is five year old Mac so it is 128 30 okay you and I among the same thing so we just thought what it need to upgrade or not okay no no it is working it is working good okay but yes down the line if you if you talk about working on computer vision and all then either you have to work on collab or you have to get a lot which is GPU in it otherwise you put is going to die and in hours to just train your network but collab is now because of : lot of people are very happy we don't have to spend money on GPU now but I don't but if I go to aw so you need to pay high right aw yes now Amazon Azure that is Microsoft and Google they hate to head on this in anybody wants to conquer this space basically as the reason Google is giving it for free right now so that they will get you addicted first of all for the cheese's we are giving edu which is 32 GB imagine and there is no Python dependency there so you can go and install any version anything there you don't have to worry about what you install your machine just no sink with it like but the only issue is tensorflow and will have both of them belong to Google so I'm not sure how long it is going to be sleep to be very frank and now as you is also picking up I don't know whether you guys have heard about it as you is making an end-to-end analytics platform within their own cloud so it's going to it's going to be a big rival for our hey WS okay yep so if you guys can work III had a conversation somebody the Google itself so the idea of Google collab similar to Gmail so they want to move this free yes as long as poppies and calendar that they have a good year thank you good that's good for us actually you know to spend on a GPU machine right yes because one of my learner's from the other batch bought our machine specifically with GPU you costed him a lot actually but then this collab came in but that I feel there are some issues with collab also that it's running in middle if it stops or your net fluctuates it restarts rather than restarting from where it was stopped there are some issues but yeah there this is a Vida version right so they will upgrade it ok alright so let's come back here let me show you one simple example of how to build a network and then we'll look close down there is effect prediction yeah ok see I have a very simple problem where I have got two columns one is some say number of days a person is working or a test tester is working for example and I have another one where I can say these many number of test cases the person is testing in this many number of days yeah and out of that the outcome the target column is defect prediction so this many of defects he is getting all of it yeah now what is my business problem here is what if I can make a predictor here saying that in future if I give these two values I should get an output like this okay let's try to build a model onto that so what I've done first of all as I have used all of our machine learning techniques as usual just to show you guys the power of machine learning versus here so first we are using decision tree and since I have done pruning all not getting any overfitting issue and everything's good as of such random forest is coming a little lower which is 88 boosting is 84 and the gradient is around 90 and bagging is 88 so if you compare all of this I feel bagging is sorry boosting is doing pretty good so we'll choose one of them so we have made an ml prediction predictor with accuracy of say 90 percent for example so this is a very simple way of doing an ml so now somebody asked me write that this AI or a deep deep learning is pretty good then why are we learning M in these these are the things using which on a very simplistic level you can implement it you don't have to you know go ahead and do back propagation for propagation and all that but some of the applications or I will say right now at least for next three years that is what is my prediction if you guys get on a real-time data science project also in your company the first two to three years you will be deploying only these kind of things to be very fun because if the company is new if the project is new and if the space is new the company does not take a big risk of implementing the high cost products when I say high cost it includes GPA it includes deep learning it includes training time lot of things are there which we have a really called as KP is for high risk products so what we do first we penetrate into clients trust by using these kind of simple micro services and once they are confident enough then we take them to deep yeah so this is one example you can say that yes this is where ml has an edge over DF simple levels I don't expect you know to do image processing on all using em as not possible yep now to counter this up what I have done is I have made a very simple neural network which starts from here so you can forget whatever we did about no problem we know that our part next what I am doing is from Charis and implementing a sequential a library what does it mean if you observe our excel file the simulation I'm sorry not this one the simulation that we did don't you think this is sequential kind of stuff this depends on this this depends on this and this it's like a sequence so the the first part to understand encoding is we have to tell Karass that our model is sequential one alright next is what layers you want under kill us so if I yeah what do you want under care us so to add a layer to keep adding those hidden layers no you have to use the command Holton's next thing if you want to drop out and if you do want to do normalization even it's possible under cannot so we'll do it after that we don't want SQL on and one one library has optimizer so this is used for back propagation or gradient descent or to adjust your weights anything you can call about all right now let's go further so as usual we'll import the data no change in that we will do we'll define x and y no change in that the only thing you have to be very careful is even if the output is in the form of how do you say classes yet you have to do a categorical out of it category in the sense you have to convert this into category because if in case this looks like a category and it is not category neural network is going to fail so please be careful the output the Y of each and every data in your data set should be categorical no matter it is test or trying whatever it is so either you do it before split or you do it after speed after split the only issue is what I made a mistake here is they have to write two different lines what if I would have done earlier itself one line was enough to categorize all right after that coming on to the inputs now can somebody tell me if I want to design a neural network here yeah what should be my number of inputs so I have to have some inputs right so sorry Oh perfect two inputs and what will be my number of outputs one okay I did not show you there are actually three zero one and one - okay perfect so I'll have three outputs now if I have three outputs what activation function I should use softmax please remember that no more relu anything so this is the input and output we design now let's try to focus on the interior part so before that please remember till you are confident enough to visualize all this always print the shape of your test and drain so this will help you to design input this will help you to design output all right three outputs to induce the first thing you have to fire up is you have to tell Python that this is a sequential model and the name of the model you are defining is model itself and every time you make a change now you see model dot add what I need to add I need to add a dense layer what is the dense layer so first of all this is your first input layer now in input layer what we are doing is we are considering input layer itself as a neuron so you can say that yes we are having a neuron here and we are giving input to it so you can consider directly this as an input some of some sometimes we don't take it off sometimes we start in new activation functions from it is this yeah in this case what I have done is I am saying I want an input layer of dimension 2 that means I need two neurons and I eat 64 rings now if you ask me why because my next layer is having 64 neurons if you remember each neuron is supposed to be connected to other one so like that if I have 64 inside I should have 64 lines of weights also agreed so this and this should be in sync next is I am saying the activation function I am going to use Israeli forma now coming to ok so please ignore drop out because this is the this is a topic from thirdly robot means it switches off some of your new ones it's a it's a type of hyper parameterization of feature engineering in in Iran so please ignore for now these two next is I am saying is I will add another layer that is my hidden layer such a way that it will have 64 neurons and activation again is real and the third one is your output 1 output is I'm saying is I will add 3 layers sorry I will add 3 neurons as an output activation by default is sophomores what if I have user a Lu here I will get a regressed output if I use soft mix I get a classified output that's it all right so this is your neural network on a very simplistic level 1 layer 2 layer 3 layer it is capable enough to deliver the same what ML gave us about next so we have done we have created a hardware so I can say we have created an empty Network now we are supposed to populate it now how do I populate it before populating it we have to design backdrop so I can say this is forward prop this is your back propagation back propagation is nothing but optimizes so there are so many optimizers available so if you want to see the list of optimizer you can just go to Google Kara's optimizers ok this is the documentation which will help you to understand all the optimizers available within Kara's I will show you each one in each case string ok rmsprop ad a delta ad a grad atom SGD all of them I'll show you one by one so for now let's talk about a very simple optimizer which is atom now if you ask me what is optimizer very simple remember doel by duo of weights the formula or the person who does this is this particular person called all right instead of atom you can have SGD rmsprop ad a grad lot of things we have depends on the application what we are choosing in this case it's a very simple numeric application Adam works the best it is something like a rail loop a generic you can trust him for all the backdrops and so you have an option to define a non injury so that is the I keep it usually in two decimals 0.0 if you want to be written slow if you want to be very dynamic you can put large but if you have a large activation function please remember we just discussed it is going to oscillate it will not come to a rest point but yes your neural network training will be faster also in the larger learning rate so this is your atom now you are saying this is my model please attach this optimizer which is called atom the loss the way he is going to calculate loss function is nothing but it is a categorical data and we are going to use cross-entropy guys what is cross entropy we know entropy right what do you mean by cross entropy have you heard or I told you I think I have not discussed all right you know entropy all right so I'll do one thing in next session I will give you some mathematic behind it and we'll try to see why not do a Python examples there are so many lost functions available in neural nets one is called cross entropy if the data is categorical categorical cross entropy if your data is fast what do you mean by sparse there are lot of zeroes as an in the output in that case you can say that yes it has sparse underscore category underscore inter cross entropy you have multiple of them available for now whenever you see category use this one this is the best one who's that what is what should be your checkpoint so I am saying accuracy will be my checkpoint do we know any other checkpoints we know precision we know recall we know support we know f1 score right so this is what you can use always I will say use accuracy accuracy is a very reliable factor so far next what I do is so my back prop is ready my forward prop is ready both of them are ready so you fire it up as usual from your machine learning fitting so just take the model fit it fit on to what your training data okay that size now this is something new that size means if your RAM is capable enough to fetch the input at a time I would like to fetch input for next 80 readings you know so if you have a good ramp even you can put 800 so if you are doing a computer vision image processing and all that we usually keep bad sizes very bit so that the fetching is faster in this case you can choose any random value like it's something like our seed if you remember random seed but here it is about fetched executions next comes your epochs now what is epoch please remember one epoch is equal to one forward prop plus one backward Rock that's it now you may ask me fine how do we choose the Sun so what I would say is first of all you choose single-digit epochs a five six seven like that and once you do that look at the first five epochs so let us say these are my first fight epoch still here look at the loss function yeah can I say it is having a huge amount of change you observe there is a considerable amount of change a change a difference of two is huge enough so if you find in first five or 10 he parks that the changes are very huge then you say ok let's use fifty hundred two hundred like that or else you can check the accuracy if you find the accuracy is continuously increasing by a good number then you say that yes if I have more deep ox more accuracy I'm going to get that means more number of he parks more back prompt more backprop better the weights better the weights nearer your accuracy is near at 100 riyals so in this case when I ran for 100 times I got an accuracy of 84 it is not as good as ml because in ml we got 90 but this is a very dynamic model what does it mean tomorrow when my inputs change let us say it takes no time for me to retrain this I know even our ml takes no time but in ml you could hyper parameters and all those things feature engineering and we take a lot of pain to again redo in this case it will auto take the changes and auto adjust the weights at the end it will try to show us results of many rules there are certain weird cases where you might find ml has an edge over this yes but more or less deep learning should be good all right now what do we do let me show you what is soft max so if you remember the output was soft max how many three of them so look at this this is the predicted output that we have got now what are these these are nothing but your probabilities soft max will become so all three of them will get a probability so let us say if I have given an input and ends up I am expecting an answer as three that means one two and three so soft max will give me a probability what is the probability that the answer is three let us say the probability is 0.9 this is point seven this is point three the softmax will pick up the neuron which has having highest probability so just to show you guys this is the probability that we have got and if you see the highest probability belongs to this particular question so the answer is zero so my classes are zero one and two all right you don't have to do this just for your showing purpose or softmax that's it and finally you do your testing part of it so you take your model and run it or you value it on your test data so when you do it I get an accuracy of around 88 so which is a little more than 84 I know so what we would have made a mistake here is why I shoot it up high is because of bad size or number of epochs or learning rate so you can go back and just adjust it somehow so I can say that yes this works good on my testing data I got an accuracy say of 88 was perfectly good so this is how you can train a very simple neural network so I will again request all of us pick up some of your machine learning or data and try to build a model like this and see how you are getting and then try playing around with more or less so now if you want to add one more layer what to do very simple copy this put it now when you put it you can keep the same number what a problem now you may ask how did you get 64 there is no logic for that so what I do is say I start with some number say I would have started with 100 if I have hundredweights my next layer should have 100 neurons to take it if I want my numbers to diminish I will say my next layer will have 50 neurons you can have one more hidden layer here saying that my next layer will have 25 neurons if you want one more you can say my next layer will have say 50 neurons you can even double it up not a problem and from 50 it will converge to thei yarosh alright so some of my other batches is also asking if I can give some mathematics behind it how to design this I will again say there is no proven math that how to choose this numbers optimally but yes I have got some links to some blogs where they have done some equations but that is specific only to date it so you can just take some learnings and more or less this is the way you identify clear if you try this up on your old data and let me know how comfortable you guys are on forward and back alright so I am done so I think we have covered for one and half week now because forward back and all where part of our next week but good I feel if I show you something you should also understand so I don't want you to miss out anything yeah so I think we are going good we will almost complete everything by next week or by third week starting so we will have some extra wanna and try to show you some deep learning more networks wonders yeah image classification takes classification will not good see down the line we do some social media analytics and all those things using deep learning got any questions for me already Christian unless and until we find out the correct number of hidden layers do you think the ml is going to advantage over a plan correct correct so what one of my learner did was he is very ambitious enough to find the answer for this what he did he did grid search on this he said he searched he put lot of layers so let us say in grid search he said okay I won number of it unless could be 10 it could be 20 it could be 40 like that he started and he ended up spending two or three days for the neural network just to run and complete the grid search that if we are confused about or if we have we have already obtained of mix matching this stuff up yes ml has an edge on to this but ml cannot work or I will say supervised learning cannot work on to computer vision and NLP so by default only backbone for image processing and expose okay okay yes so anyway people come back to this but yes if we don't have time to and patience to basically do this you have ml has an edge on that I agree with you perfectly and I am clearly saying here in this case study I still feel boosting is having a big edge over the other one because it's a very simple algorithm in four to five steps it is giving you everything whereas in ml we had to do a little bit of neck stencils perfect but or the long run this is far better I feel because it auto corrects auto launch itself auto corrects his own rates also yeah okay okay so again to summarize very quickly the whole game of neural network is to adjust their weights that's it how do we get this weights we will do in v3 what a different type of weights for now please remember weights are random but also we have a provision where you can control your weights we will see down the line in your third week when you do hyper parameters all right and second thing is there is two type of propagations happening forward prop backward prop forward promise to spoil your output backward prop is to adjust your own or adjust your loss function good next is you have three layers input layer which should be in sync with number of columns or features available output layer should be in sync with total number of categories you have on your output column good and the hidden layer again is a big mint I will say start with a with a number like 100 120 went through and then keep reducing it Hafford divided by 3 you are divided by 4 orderly but yes it's a cumbersome process in one short see I got this but not always we can get of 84 percent accuracy in a short to be very slim and still I stopped at 100 you know if I don't want further I would have get got at least 90 plus accuracy yes so this is the overall summary for noodle it looks good so now can I say the the the concept is little that the border is gone written less on the understanding part now I think if you go back watch the videos noting the theory what professor is excluding computer computer everything is going to go on a different level we may need to use glasses to correct that visible exactly yes next 5 to 10 years the the r4d so often yes where for machine Nonnie now they arise come for deep flux because you remember I showed you by Auto ml do you remember that code which will ought to take our inputs I don't know some of you were there with me what why - so you can easily there's a machine learning data scientist who knows only machine learning with that piece of code if you want me to show it again I will show you guys again that thing so only do my work and some of the codes that I do here for my newer batches I already use Auto a mine under that now I don't need anymore I will use what I am meant to get my predictions and it is becoming very common now even Google has come out with something like an auto ml which is similar to as your already has it so now if you want edge yes deep learning is a next one because we do not have auto dealers of such it will take some time to come okay so take it in a slow manner we don't have to rush that's the reason we have this design this particular module so that you get adjusted to noodles and we will go or we will run basically from computer next one all right so please understand each and every factor here don't miss any my new detail so any issues anything drop no post on your group I will try to answer that yeah and what I showed you today was very simple next session will scale it up we will try to design more complex models okay I'll show you something want to text an image processing also right away in next session so that you get a good feel of not only categories and regressions but also other two but I'm not sure how many of you use this for iteration and categorization who's already you have a mint for that so the edge comes in something onto image detection phase detection expression detection sentiment analysis but anyway if you do not use neural networks for this detection right you use convolution only right Chris no no no no I will show you so your first project for neural network know you equ KN for image processing for image detection okay oh yes and you are perfectly right and volution is the default one but we will make you use neural network to detect an image and opposite to that we will make you also do tienen to detect the image and then the reason we do it just to show the difference between ml nd you can use VM to detect the images or to I can say not detect I will say classify images so if I give you a number seven let us say you have an image screen shot right in that image has something like this I can use SVM to identify what it is and display this this image represents number setting you can do yes okay but convolution is a better way to do it so we will see in next model why it is better what makes convolution better than views and even we have better version and convolution we call it our CNN regional convolution neural network we have more better version this than that we call it yellow and ssp and it's still evolving we are not happy with that also it still you know evolving now we are going to complete it week session or eight week module onto computer vision it's a very long model will spend two months on to that alright okay effect so I think since let's move on to I shall take you to your code and I have a very similar code to that I can help you to give that it also does the stock prediction only predict the next ten days the model is basically predicting values for the range of data I provided I want to predict the future values okay so you are using LST mg/l right I saw you use it so is there any issue here it you as such so if you go to the bottom of the food it is a chart that I have made it if you go to the bottom of the road yeah is it art so basically what is what is happening if I see the chart itself what is happening is this is even that happens in the market and the SKU is reacting to that even in a delay format so for example let's say on a day four or five the blue line if you see it Peaks out and after that the red line also Peaks out with it happening in Adelaide format so just doing repeating it is just beginning what has actually happened not predicting the future correct correct correct got your point called your point okay then I need to analyze the whole code step by step why it is happening so I'll be missing any values here or the network is a shoe we need to check this it was a ok code because I just you borrow it for my display see then you try to put it together okay we'll do one thing Ashish I have a solution for this meanwhile I work on this correcting this code I will give you one more code of mine so just between us sorry you can just modify it and then use it yes [Music] learning lsdm see yes so I have something like this which predict stock markets yeah it's a little customized code so it is almost similar to what you've done except what do I have here is I have got a huge amount of corpus knife and look if I show you the corpus that I have might put exactly same as yours but you can use it one minute deep learning LSD and time series talks so this is what I have okay and this is the way each companies talks are there okay right so what I will do is I will shape its code with you it is a self explainatory code if you know LS TMS then I don't think so it'll be an issue for you what I am getting is a I'm getting yes next 18 or 20 days of prediction I am getting it so this is my prediction busy yeah so try it out if you are able to fix take some contents and fix it parallely I will work on line by line of this because I need to understand the whole flow first of all this sort of simple you know task again thing I need to plate this up because usually what listicles do is lsdm has two parts I don't know if you know this a little or two parts you can use this plug-in pull and then people I know if you just used it for encoding part of it or a we have we put a decoding layer I think it is just an encoder basically we let me remind you and then let me analyze why that n days or whatever gap you are seeing is happening yeah one more thing I want to include in this code that me but that I think would be really helpful is to incorporate other features by gamma - yes other features would be able to help us be better so if we can include it because most of the LSE encoder that I saw on the website they only inflicted on one value either on the closing value opening price so if we can include other features that would be able to that would be that would help us to be at the okay perfect let me check it out okay so I'll do one thing Ashish first let me solve this problem because it looks like to be a complex and not say very complex code but yes when LS came in I'm sorry when Ellis teams are involved it is little complex so first I need to understand the design of the network first of all why it's 50 60 70 what is it making this way and probably once I get hold of it I don't think so it should be big trouble editing this okay good Merilee I will share this with you my code of lsdm predictions check it out okay yeah all right perfect Ashish one more thing I just a reminder there is one guy called Ganesh who is just joined our bastard he is he may he has what you say this is a little difficult way to do time series was tomorrow something changes now you have to play in your network and I don't know how much time it took for you I think the epochs are not heavy you know it actually took me it took me around you one ought to train this code correct now this imagine tomorrow is that condemned back in content increases no the training time is also increase so first option what I would request you is if you are deploying this somewhere or if you are doing for your own our knowledge perfectly good this this is very good but if you are doing it just then is to deploy it eventually if it eventually so just check the cost of it cost in the sense because whenever you have you I have to retrain your model no you have to retire your initial knowledge first then you to pull it back and then you have to retrain it and then push it back so that non operational phase you have to calculate the cost for so if you are ok with it no issues first option should be ARIMA second option should be electives to be very very well he said i certain I trained it or not daily data is that because I it would not involve too much cost in exhibition because I didn't think the manual this is an office it particularly weather so my intention was actually to do it on a live data on a pick up buy ticket on a second-by-second data so that would be I'm not sure because if it takes someone to run the code if not impossible to do a trade on that kind of data on live data so that's what I was thinking so II is the is the deployment is different from see what we are doing so is first we are trying to create a code a once we are notified with the course how the deployment takes place all the way you want to deploy this when you would like to acquire you and deploy it on my phone so using them when when okay I will show you right away it's a way right yeah yeah yeah let me show ya let me show you right away this is not our L STM's but yes this is one one minute we use flasks basically a fish to do this and I will give you this code also so you can deploy it immediately and this is my tap so the overall architecture if I show you just give me a minute so the overall architecture is that my intention is here to make HTML web which I have done it okay so this is my HTML and this is my CSS some styling I've done to create an interface which looks like this okay okay and this particular thing is very simple you will just put a URL here this URL being given is an input to me in my code so I use flask to convert whatever I am talking in Python with respect to what HTML and CSS understands very simple so I am taking a link from a user why a flask I am in putting it into my model which is pre-drilled on some kind of data it's a neural net model okay and after that I am saying I am replying back to the HTML using slash saying that it is a real news or it's a fake that's what we are doing all right now how do we do it let me show you the code the code is very simple let us say if I can't run this before that yeah so this is the flask app so there should be one application which you have to make it after you are confident with your model what you have to do it you should pick tell it if you see this this is called pickling pickling is like converging your model and storing all the supporting files on to a location which can be called from anywhere so this is my pickled package which is nothing but my name Bayes model that I've designed above okay any model that you design could be pickled like this so this is the the two liner code which you can use to pickle and once you run it you get a pickle file like this now your job is to import this pickle file in your reel so this is my real application and also parallely I have deployed a webpage so this is the link to my web and is the CSS which I have written on that basically some styler so whoever is handling your application will be having access to both of these blue very near yours website is hosted there you have to go and drop this pickle file basically okay okay along with this the file is a cool so this is what we call it as flask now what does flash do is flash allows me to create an app inside that app it allows me to load my model if I have one this is my model a technically remember next is it allows me to connect my HTML page link here if you have an IP or if you have any other thing you just put it across here next is what you want to do with it so if this is the HTML page what do you want to do it so my HTML page what I want to do is let me run it if it is not ok it's not active so let me run the code and actually it'll take some time it's not that fast but yeah you just have to run it once once it generates an IP IP is ready look at this this is a fake news predictor all I need to do is I just need to go and for example let me say I will pull some junk out of it I have to just get the link go to my web publish the link here and say predict it might take some time the news is real so this is how I am Stelling I am telling my app that first of all this the model that you are supposed to use from Python this is the HTML page and inside HTML page what you are supposed to do you are supposed to get my text this is called web scrapping if you have heard about the Scourge read scrapping is like converting the data on the web onto an understandable which could be passed to a Python model something like a data set input data set or database this is happening whenever really you want to do with your inside your HTML you to define so in your case what you have to do in your case you to publish a graph or do some numbers that logic should come here so no actually in my case what I want to do is a it's a given order is for example a model is predicting to that the price would go up so it to send that order to the broker town that is to buy the share and he also send us a simultaneous order giving you a stop loss or a target price order so that a some execution can take this and then II when the model says yeah it's time to get out of the market then it exited loader and it fits the market perfect so in that case as usual you will need a help of a web developer basically to write this interface okay if we can do it in Python as in Python should output then no problem we will say whatever is the Python output will display it here in this junk but if engage lot of interactions are needed internally no you need a web developer to take you through those interactions because I'm not show a little boudoir I am not that good at HTML or I'm not sure even you are but the person is designed the weapon should be good enough to put interface this brings us to the end of this tutorial on multi-layer perceptron now before you guys sign off I like to inform you guys that we have launched a completely free platform called as create Learning Academy but you have access to free courses such as a iCloud and dead still marketing you can check out the details in the description below so guys thank you very much for attending the session and have a great learning ahead you 