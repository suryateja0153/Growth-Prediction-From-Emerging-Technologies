  Hello, my name is Maggie Du. I'm a machine learning developer at SAS, and I work on deep learning and computer vision APIs. In this video, I introduce a new feature in SAS Viya 3.5: deep clustering, which is a completely unsupervised deep learning approach to clustering high-dimensional data. Let me first briefly explain the idea of clustering. Clustering is the essential task of grouping a set of data points into several clusters based on their inherent similarities. Unlike classification, where you give a label to each data point and train the model according to the labels, there's no label information needed for clustering. In the example shown here, we can put the objects into three groups by considering only their shapes and colors. Some well-known clustering methods are k-means clustering, hierarchical clustering, and density-based clustering. They'll work well for low-dimensional data, but they are not suitable for high-dimensional data, especially images and texts. The reason is that they suffer from the curse of dimensionality. Take k-means clustering as an example. This approach minimizes within-cluster distances--that is, the points that are close enough together are assigned to the same group. This idea can't be extended to high-dimensional space, because all points would become sparse, and it's impossible to consider their "closeness"--just like the stars in the galaxy. When we look at the stars we feel as if they're close, when in fact they're several light-years away. This phenomenon is more obvious when we deal with images. For example, the simple MNIST data set contains gray-scale handwritten digits of 28 28 pixels--a total of 784 features. The color images in the CIFAR-10 data set are 32 32 pixels. Because they're all color images, this results in more than 3,000 features--too many for traditional clustering methods to give you an accurate estimate. Two possible remedies are given here. The first remedy is a two-step approach: we perform dimension reduction using principal component analysis or autoencoder to extract the important features, and we use k-means to cluster the low-dimensional features. The second remedy is to use an end-to-end pipeline that can extract feature representations and assign labels simultaneously. This pipeline can be used in many industries to help with defect detection, autoclassification, and image preparation. We use a portion of the Fashion-MNIST data set to compare these two approaches. The data set contains 28 28 gray-scale images from five different classes: bags, tops, ankle boots, trousers, and coats. Here is what the model looks like. We train an autoencoder model for feature extraction. The bottleneck layer contains 10 neurons, which can then be put into k-means clusters. This is the idea of the first approach: dimension reduction traditional clustering. For deep clustering, we add a clustering layer after the bottleneck layer to make the entire model a multitask model. Then, during training, the results in the clustering layer help improve the features so they are more representative, which in turn increases the clustering accuracy. Finally, let's look at the clustering accuracies from both methods. The first two-step method correctly assigned 60.6% of the images, and the accuracy of deep clustering is 88.5%. In the tables we find that deep clustering outperforms the other methods in all five classes, giving us a more reasonable clustering outcome. In this video we introduced the new deep clustering method supported by SAS and compared its results with other methods. You can find more information on the SAS home page. Thanks for watching! 