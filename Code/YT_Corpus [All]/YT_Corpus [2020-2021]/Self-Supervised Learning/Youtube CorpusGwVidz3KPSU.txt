  KEVIN LEE: Hello, everyone. Welcome to Machine Learning Pre-conference seminar at SAS Global 2020. My name is Kevin Lee and I'll be teaching today's Machine Learning courses for SAS programmers. We were going to start with intellectual and earnings And then, we're going to discuss about this main concept, such as hypothesis function, cost functions, gradient descent, and learning rate. And then, we will talk about the process and workflow of the machine learning. And then, we will also discuss the type of machine learning, such as supervised machine learning and also unsupervised machine learning. And then, we're going to discuss the algorithms so for the commission can use neighbor dysentery random forest, XGBoost, logisitic regressions, linear regressions, K-means clusterings. And then, we also explain about how to validate or verify the trained model. And then, we would talk about how to make voting in better with hyperparameter tunings. And then, we would discuss about artificial networks, which is a game changer of machine learning and its main concepts such as activation functions, loss functions and also optimizers. And then, we will talk about the deep neural network, which is actually make machine learning much more powerful and efficient. And then we're going to talk about how to improve the performance of deep neural networks with bias and variance and also regularizations. And then, we also talk about the practical deep neural network implementation, such as convolutional neural networks and recurrent neural networks and transfer learnings. And then finally, we're going to talk about how motoring AI is impacting our lives and how it's going to be impacting our futures at home and also at our careers. So let me introduce machine learning. About two years ago, my wife asked me honey, do you know about machine learning? Do you remember the case or situation that somebody ask you, but expect you to know? And that's the reason that my wife ask. She knows that I'm doing programming, statistics, and most importantly working with data all the time. If you look at these three things, it is kind of like our job descriptions. We use SAS to all those programs. And then, we use statistic to predict and build the models. And then most importantly, we work with the data all the time. I'm sure that some of you already got asked that whether you know about the machine learning or not. So let's talk about what is a machine learning. The meaning of machine learning is applications of artificial intelligence that provide the system or machine to automatically learn and improve from experiences without being explicitly programmed. The key here is that improve from experiences without being explicitly programmed. So what is a difference between explicit programs and machine learnings? Explicit program pretty much provide rule based programmings. For example, when you like to catergorize age groups, we define what age groups is going to apply to what age. As you see this example, if age is less than 65, we put that age or patient into age group what? If it's between 65 to 69, we put that into age group 2. And so on. In the machine learning, you don't apply rule. We just reading data and then algorithm to decide what age going into certain age groups. So there is no rule based programming in machine learning. So how does machine learn? Let me ask you questions. Can you tell me about this picture? Yes, it is a cat. Then, how do we know that it is a cat? We actually seen this before. Humans learn from our experiences. We learned by seeing it, taste it, here it, feel it, and so on. What about machine? Can machines see this one? Can machine fee this? Or can machine taste it? Or hear it? Machine actually learn from the data and an algorithm. Just like we see cat pictures for thousands time and we figure out what is a cat. So when we actually train machine, we look at images and then algorithms. Eventually, when machines review data, they could tell when these are cats or not. So key here thing is that machine will learn from data and algorithms. It is their experiences, just like human learn from our experiences. In the algorithm, there are actually three key functions. Hypothesis functions, such as y equal x plus b. It also minimize functions. Cost function to minimize and also gradient descent, which is optimizers. So we actually put the input data with the output, such as x0, x1, x2, xn and y, which is answer. And we actually train our algorithms with this data and the machine can learn from their experiences. So what is the main concept? We're going to talk about three concepts which is vital about machine learning. If you understand about how this three concept of function work together, then you actually understand how a machine learns. We're going into this hypothesis functions, cost functions, and gradient descent. Hypothesis function is measuring arguments and model that we will train with the data. There are a couple types which we're going to discuss later in our courses. Linear regressions, logistic regression, support vector machine, decision tree, and artificial neural networks. And then, it's main function and formula is theta 0 x0 theta 1 times x1 theta 2 times x2 and so on. This is one of the example of hypothesis functions. And then we try to find about the parameters of these hypothesis function. That is the ultimate goal of the machine learning algorithm and trainings. Cost function, otherwise a loss function, is the measurement of how well our hypothesis function fit into the data. So basically, there is a difference between actual data point and hypothesized or predicting data point. For example, for a linear model, square I mean error is the cost functions. Gradient descent is an otherwise optimizer. It is engine that minimize cost functions. By doing this, we are able to find the proper parameters or optimize parameters. So let's talk about how the machine learning get trained and also workflow. This probably going to give you about a high level of how a machine is going to work. Let's imagine that we are teaching young children about the cat pictures which they never seen before. First step we're going to do is show the full set of the pictures which may contain cat and dog and other pictures. And then, tell the kid that some are the cat pictures and some not cat pictures, maybe dogs. And then, you could explain why they are pictures, they are cat pictures, and why they're not cat pictures. And then we again, show the next set of the pictures. We actually redo this process. Showing the pictures and also explain why some are pictures, some are cat pictures, some are not cat pictures. We repeat this about couple of times until children understand which are cat pictures in general. So some kid probably figure it out about maybe 100 pictures and some kid probably 120, 150. It depends on kids. But eventually, if we showing the pictures thousands of pictures, then kids will eventually figure it out. Machine learning is not so much different about teaching kids about the cat pictures. Our first step is about the machine learning training process is we select data and hypothesis functions. And then, start with the random parameters of hypothesis functions such as data. And then, process first set of data in hypothesis functions, such as we are showing first set of cat pictures. And then, we find the predictive value from hypothesis functions. Which can mean that a kid will tell us which are cat and which are not cat. In machine learning process, we are going to calculate the cost function pretty much by actual-- the difference between actual and predictive values. And then, we minimize cost function using gradient descent. What that mean is that we actually tell the kid which cat, which are not cat. The next function, which learning is update the parameters of hypothesis function based on cost function minimization. You can see more detailed information when we show by step by step with some example. I will repeat step 3 to 7 with a new set of data until cost function becomes 0 or at the lowest point. Let's look at the example. First step of machine learning is select the data and hypothesis function. Let's imagine that we have this data point with a x and y. You can see that this x point. You got y point. On X point, you can add the y point. And then we select the hypothesis function as a linear regression. Y theta times x. The next step we start with the random parameters of hypothesis function. Remember we have a theta x. So now, let's imagine that's kind of set that we're going to set the theta equal for. and then let's process first set of data in hypothesis functions with the initial parameters, and predicted value from hypothesis function. We actually set our initial parameter as 4. So if you plot this number, this first set of x data-- 1, 2, 3-- and then our y hypothesis function becomes 4, 8, 12. And then next step a machine does is you calculate cost function, which means pretty much the difference between actual and predicted value. 3D model cost function is square mean areas. We're going to talk more detail later on, but that's a cost function that we're going to use for linear model. So the difference between the cost function of actual value and predicted value becomes 9.33 if you plot all these numbers together. 2 minus 4, 8 minus 4, and 12 minus 6. If you actually plot this number, it goes something like this. Right there. So cost function versus parameters. If you plot this cost function versus in different parameter, that is a shape you're going to see. When the hyperparameter. And then parameters equal 4, then the cost function is going to 9.33. When it's going to be 3, it's at 2.33. And then when hyperparameter is going to be 2, then it's going to be 0. So our goal is to find-- to this 2 using the data, and then [INAUDIBLE].. So here comes the gradient descent. The definition of gradient descent is engine that minimize cost functions. So it is actually the process of getting to the lowest error value, which is the cost functions in the machine learning algorithms. It is kind of walking down the mountain to find a goal located in the valley. So gradient descent actually helps the cost function become less and less up to the optimal cost function point. So what machine learning does is it tries to minimize cost function using gradient descent. It is more about [INAUDIBLE] right now, but it takes the derivative of that cost function since it will give a direction to the moving forward. And then it will step down so that it's going to be minimized cost functions. And then learning rate is another concept about the cost function, and it will actually show how much it will change based on the gradient descent and also cost function. So as you see, the point that if the parameter is on the right side of the optimal point, it's going to be negative. And then if it's on the left side, then it's going to be positive. So that where your parameter is going to be y, it's going to go into the lowest point of the cost functions. So it will help that cost function become lower and lower based on the parameters. And learning rate determines how fast it will learn. That's why it's called learning rate. For example, let's say the parameter is just 4, but the learning rate is 0.1. Then it will decrease to 3.8. However, if it's 0.5 as the learning rate, then it's going to decrease 1 point, so it's going to go down to 3. So it will determine how fast the machine will learn based on the parameters perspectives. So the next step is the machine learning will update the parameter of the hypothesis functions based on the cost function using gradient descent. So initial hypothesis function, you studying-- so 4x equals-- theta is set to 4 initially. And then cost function become-- because there's a difference between actual point, which is 1, 2, 4, 6. So it calculates cost function-- it becomes 9.33. And then using gradient descent, our parameter which is theta gonna be changed from 4 to 3.8. And then our modified hypothesis function using the first set of data becomes 3.8. And then next step is going to be 3.6, and 3.4, and so on. So we repeat 3 to 7-- training with a new set of data. Calculate all the cost functions. At the second iteration, the cost will become 7.56, and the gradient descent is going to be 3.8 to 3.6. And then for after a second iteration of the data, the train data that we get on the hypothesis function is 3.6x. So these iterations from step 3 to 7 will go on until the cost function gets to 0, like 0 data equals 0, or if there is no longer a decrease, or no more data. So basically, the cost function and gradient descent to find the best model by going through iterations. From starting this point, next point, next point, next point, next point, next points. And then our hypothesis function changes each time-- each iteration until it hits to the 2x just like this data. So in the grand perspective, the model training machine learning starting the hypothesis functions, going through a new set of iteration of data, and then calculate the cost functions, and apply gradient descent, and update the parameter of hypothesis functions. It goes on until the cost functions get to 0, or the lowest point, or the specified set of iteration. You actually set this iteration about a certain time-- maybe 100 iterations-- or your cost function becomes 0 or an optimal point. So that you can actually get the best model that can provide the best predicted value. So in this best model, then if your x this point, and it also provides the y values using the best models. What's interesting is that with the same model and same hypothesis functions, using more data provides a better model and better predictions. However, if you get different data and it provides different model, which is different slopes or data, and it provides different predictions. So one good thing about machine learning is that when your data changes, your model also change automatically. Because sometimes, market trends or some data you're going to get is changed, that you don't need to program all over again. Using the current model, just train with different data. Then it will work just like machine learning by itself. However, if you get bad data, it will provide a bad model, and it will give bad predictions. So data is most important thing in machine learning-- one of the most important things in machine learning. We call that garbage in and garbage out. So there could be bad example. We're not sure if it's a cat or humans. So now let's talk about machine learning and also these algorithms. Let's say we do have different problems. Construction, airlines, electrical engineering, hospital, or farms. Different job usually means different professions and different problems. So for each problem that we have, such as construction, flying airplanes, fixing electronics, carrying the patients, raising farms, we need to have a different professional, which means find the right person for some specific jobs and problems. Machine learning is very similar. We have to find the right algorithms for some specific problems. So our algorithms based on what kind of problem that we're going to have, and also what kind of data we're going to have. And you find the right algorithms, and then we actually change those algorithms. There are two types of the machine learning data. One is supervised machine learning. What we mean is that it has input data, has a label, which means it has a correct answer. In this case, it's the y result. It's usually for some specific purpose. And then there are mainly two types. The classifications for the distinct output values, and regressions for the continuous output value. Other type is unsupervised machine learning, which means input data are not labeled, which means there are no correct answers. It is popular for exploratory analysis. And then it's main type is that clustering analysis , using k-means clustering. In supervised machine learning, there is a classification. Classification is pretty much about the categorical target, either binary or multiple classifications. If at that point you said is the output either a yes or no, or 0 to 9, or sometime mild, moderate, and severe. And it's main algorithm is logistic regression, support vector machine, k nearest neighbors, Naive Bayes, decision tree, random forest. XGBoost is kind of popular algorithm in machine learning classification type. So let's talk about the classification algorithms. Support vector machine is one of the most popular classification models, both binary and multiplication classifications. And especially for the complex, but small and mid-sized data set. It works best for the binary classification, which means yes or no, or class 1 and class 2 as you see in this graph. And it is actually easy to train. And then what it tries to find in machine learning is lines or hyper-plane that divides two or three classifications-- 2 classes. This hyperparameter is a corner-- either linear or polynomials, and also gamma and the margin, which is how far is it different. And usually, it tries to find about the function that determines the separation between two or three classes. And just see this graph-- in the two dimensions, it's going to be a linear line or something polynomial. If it's three dimensions which is three data points, then it could be three-dimensional or plane. So once the model is trained, if data point is find on this-- let's say was something the machine finds and then trains-- so it actually finds out about this hyper-plane functions. If theta point is going to be fine on this area, which is left side of this hyper-plane, then it belongs to this class. If it's right side, then it belongs to this class-- maybe class 2 and class 1. So something about the support vector machine is they really work well with a clear margin of separations, and then also very high dimensional species. High dimensional space means that there is a lot of data points-- x1 to maybe x100, or things like that. And this can mean also about support vector machine is that it works well even though number of dimensions is greater than number of the sample, which is not always the case in most other machine learning algorithms. It's weakness is that it actually requires a lot of computational power, so it doesn't work well with large data. So big data applications, SVM is not the ideal machine learning algorithm. And then it doesn't perform well when data has a lot of noise, which means unclean data. It doesn't work well with unclean data. Actually, SAS also has machine learning package, such as SAS Visual, data mining, and machine learning. It provides data learning pre-processing, and supervised and also supervised machine learning, and also post-processing. It's kind of easy to use, and click, and click machine learning algorithms interface. Such as there is a data mining process-- either anomaly detections or clustering, feature extractions and filtering, imputations. So within programming, you could kind of provide how to prepare some of the input data so that you could apply it to the machine learning. And then machine learning has Bayesian networks, and decision tree, the forest, gradient boosting, linear regressions, logistic regressions, artificial neural network, and support vector machine. So here's a couple of the machine learning algorithms that we can actually apply into our model. So here's the support vector machine. And then once you collect this-- once you actually prepare your data, and then you can click the support vector machine, and then it will open little box, and the data coming in. And you can set up some of the hyper-parameter, such as we talk about the kernels We can make linears, or polynomials, and so on. And then once you've got any-- there's this run button that it will run this model, and it provides the result of this model. K nearest neighbor is one of actually very useful machine learning algorithms. It is very simple and easy to implement. Then you could also apply to the classification and regression problems, which means that you could apply to distinct output, and also continuous output. We actually call this the lazy algorithm. I think it's kind of funny that we call this lazy. But what happens is that we don't really train knn machine learning, because knn remembers the trained data point, and then it will calculate and memorize that data point, and it will apply the data point with our test data. Let me give you an example. In this example, let's say you do have about-- we have a training data. And then we actually run this training data into knn algorithms, and then knn remembers each data point. So when new test data comes in, such as this area, then it finds the nearest neighbors. We setup k as 3, so we find about 3 nearest neighbors. So one from this side, 2 from this side. So I just see that for this data point, here's a one-- group one. And here's a 2-- group 2-- group b. So based on the result that we got from the nearest neighbor, this test data is going to be class b. However, what's interesting is that we have a situation that when k equals 3, provide more class b, but larger k, which is k equals 7, provides more class a. So it is very important for knn to determine what is optimal. Test optimal k so that you could provide the best predictions. The benefit of knn is it could train really, really fast. It is very simple and easy to implement, as you see this. And that it is very useful for a lot of linear data. However, here's the weakness. It could be slower and costly for the time and memory in predictions. And then it might be ideal for large data, because it has to memorize all the training data points, and then it has to calculate in the predictions. Usually, all other algorithms do calculations in the training data, so test data doesn't need a lot of calculation. But knn requires a lot of calculations in the prediction phase. So it doesn't work well if you need to have a quick and fast prediction or time requirement. Decision tree is one of the most popular machine learning algorithms, because it provides visual representations, and is easy to explain to other people. So it could be applied for both classifications and regression, even though it is much more popular in classifications. If we can little bit discuss about its architectures. And here's a root node. And then internal node, and then branches such as here warm and cold, and yes or no. And also a splitting based on is conditions and then leaf node is such as decisions, which is non-mammal, mammal. That is a leaf node which is making decisions. Before we actually provide that the one decision tree, we could assess some of the hyper-parameters such as what is the maximum number of features, such as variable, when you use, and also the depth of the branches. How many branches? Here in this case, 3, but you could go to 4, 5, and 6. And also criteria-- the measure of quality of the split, which is gini or entropy. The algorithm that decision tree uses is pretty much gini and also entropy. Gini is the measurement of the impurity, and entropy is the measurement of disorder. So the whole point is that you try to minimize gini impurity and also entropy. So it kinda use cases. So for example, let's say that a problem we'd like to solve is what is the conditions of the patient who survive? And then we actually input a feature-- it's going to be sex, age, and whether they're treated or not. And also the label is whether patients die or not. So in this example-- it's just hypothetical example, but if the patient is a male-- if the patient is not male, then everybody is alive. And if it's yes, and some is die. So you look at the next feature which is age, where the age is greater than 65, and then the patients die. And if it's no, then patients still alive. But whether they're treated or not-- if you treat it, then patients are alive. But if not, then patients die. So as you see, it gives a clear conditional cases about each feature. How each feature impacts the output. So decision tree is very useful to find about how some of the results were impacted from the input variables. And then also the SAS Visual data mining and machine learning interface or package provides decision tree. You state decision tree with the data, and then you could actually set some of the hyper-parameters. And then you could run this in your programs. And that will actually provide the result. As you see, it will actually provide the result. How many branches it has, and what was the condition of each branches, and what's the output of a condition, and how it's going to impact the result, or the ultimate output of the data coming in. Random forest is another popular machine learning algorithm. It is a so-called ensemble decision tree, which is basically using the multiple decision tree. What happens is that-- lets say you have thousands of patients. And then we're actually splitting the 1,000 patients into maybe about 300 patients-- about 20 samples. So that those 20 times, we have 20 decision trees. And then it actually provides the result about the class a, and class b, and class c. And it will actually take the majority vote the output. So random forest is more about the aggregation or average of a decision tree. And it actually provides more general or better generalizations of performance of-- and it is less subject to overfitting. So random forest is a very popular machine learning algorithm that is used for a lot of implementations. SAS Visual data mining and machine learning package also have these options. So you actually click the random forest in your interface, and then it will provide the hyperparameters option. You could actually select the option, and you could run this, and it will provide the result about random forest. Another popular machine learning algorithm from the decision tree is XGBoost. Rather than prior machine learning of the random forest, it just go into boosting, more of a sequential trainings. In the random forest, we notice as the output, we actually take the average or the most vote of the output. However, in the XGBoost, you actually train from output again-- with another output that we actually train from the output again. So it actually usually provides better performance compared to random forest. So it is another advanced ensemble decision tree that provides better performance in terms of machine learning perspectives. And then it's actually extremely fast compared to parallel computations, and very efficient. It is very versatile. Actually, you can use to extract the variable importance, and does not require feature engineering. And it also has a regularization to prevent overfittings. However, it only works with numeric features, and doesn't work well with outliers. And it is difficult to set up because it is dependency of the previous trainings. But you're probably going to see a lot of XGBoost machine learning implementations in recent and more advanced machine learning algorithms. And also SAS Visual data mining and machine learning package also has this gradient boosting as one of the options. Now we'll talk about logistic regressions. Logistic regression is probably the most popular machine learning classification, which is binary output algorithms. Because it can take continuous and categorical variable as input features into variables, and then it works really well in a lot of situations. For example, when you try to predict if a tumor is malignant or not based on tumor size, at a certain point of size, it becomes highly likely the tumor wouldn't be benign. So basically, logistic regression is a combination of two functions-- logistic plus regressions. Regressions such as theta x plus b. And then logistic is pretty much a sigmoid function. If you look at these architectures, we get input variable times it's slope, or parameters, like x1 times theta 1, 1x times theta 2, and x3 times theta 3, and so on. Xn times theta 1 summation, plus biases, which is in a mathmatics we're just going to go theta 0 times x0. So we actually adding all these together. After that, we actually apply this into sigmoid. So basically, apply the value to that e to the minus z. And then our output is going to be from 0 to 1. Let's say, for example, if I have a slope as 2, 1, 5, 6, 0.5. And if you plot this number, and z we got all the summation. After all this calculation, we've got 13.5 as z. And we're going to plot that information into sigmoid, and then we've got 0.99998. So it's close to 1. Also the SAS Visual data mining and machine learning platform also has logistic regressions as a part of the machine learning package. Regression-- yeah, I think we kind of all know what regression is. Regression is pretty much about the continuous output. So we actually predict the continuous output. It could be any number from minus infinity to infinity. An example is you could predict the house prices per square foot, and so on. And it has linear regressions, like this graph, or polynomial regressions. And decision tree or random forest also provides regression, even though they are more fit into classifications. So in many cases, in the regressions problem, we usually using about linear regressions or polynomial regression models. And it's hypothesis function is very simple, like theta times x, plus weight. So like y equals 10 plus 2x is a simple linear regression model. And then it's cost function usually useful for the accuracy of regression model. Such as square errors, mean square errors, and root mean square errors, and absolute error, and things like that. SAS Visual data mining and also machine learning package also has regression as an option. We actually talk about supervised machine learning so far. And now there is unsupervised machine learning, which means that non-label input data, which means no y-- no correct answers. Usually, it is done for exploratory analysis. And then basically, the clustering is the most popular one, which means assign the set of observations into subset which is cluster. So that the data in the same cluster are more similar to each other than those from different clusters. So basically, we find these three clusters from this data point. Most popular one is the k-means cluster. And it is quite popular in industry nowadays because not all the data has the answers, or labels. So this is the one that we're using for a lot of big data which we do not have an answer for, such as grouping of documentations, or grouping of music, or grouping of movies, or finding customers that share similar interests based on common purchase behaviors. So basically, about the documentation segmentation, or customer clustering segmentation, image segmentation, and then recommendation engines are the popular uses for k-means clustering. So k-means clustering is one of the most popular in unsupervised machine learning. It's the simplest and probably the most popular unsupervised machine learning algorithm. As we discussed before, it groups similar data points together, and discovers underlying patterns. So we kind of find what is k using this data. So basically, the k-means clustering algorithms identify k number of a centroids, and then allocate every data point to nearest clusters while keeping centroids as small as possible. So in this example, we try to find two clusterings. And then the clustering algorithms try to calculate every data point, and then try to find the optimal k using and also tries to find the-- the k is the centroid of these k values. However, sometimes, you have to kind of find optimal point. And a lot of times, machine learning is the combination between programming and also statistics or model. So if you require a lot of programming, it is recommended-- not use too much computing power. So we try to find optimal data point using the cost functions and also k-means clusters. And SAS Visual data mining, and we saw machine learning package has this option as well. So you could pick the clusterings, and then you set some of the hyperparameters, and then run this one. Then it will find about clustering analysis. So now once you actually train your model, one of the most important things is how to validate or verify the training model, which means how accurate it is. I've been working with stat programmers. So many times, if you actually develop some of the report and also the data set, there also needs to be second programming to verify whether what I produce is correct or not. Kind of the same thing. Once you train your model with the training data, you also need to verify the trained model with the test data. So in many cases, a lot of you probably know about the SDLC-- System Develop Lifecycle. And part of the validation process is actually we do-- in SDLC, we actually do validate the output such as based on your requirements or based on functional requirements. Machine learning also probably similar way. For example, let's say you do X-ray diagnosis. You build the model that looks at the X-ray, and it predicts whether the patient has cancer or not. And then let's say you have your model performing about 90%, and then using another data point, you have to validate whether this model performed 90% or not. So in this machine learning algorithms, when you prepare data, you prepare data into training data and test data. The training data is one that we're going to train our machine learning models. And then we're actually using the test data to model evaluations. So we actually set the sum of the threshold for the model evaluation, such as accuracy is going to be 80%. So one person-- let's say-- look at it this way-- one person actually trains your model. Another person uses that test data to evaluate the model. So this test data never changes. We keep it as it is, and then this person can now see this test data. Once you build the model, train the model. We pass onto the evaluators, and then they evaluate it. And it should go over 80%, otherwise, it's going to keep training and training. And then if evaluation doesn't pass, then a lot of times, the trainers use different algorithms, or use more data, or they change some of the hyperparameters. So in many cases, we measure the accuracy, precision, or recall for the classification metrics. But sometimes, for the regression, we use MSE or MAE. Or ranking metrics and statistic metrics correlations, and computer vision, and also NLP metrics that we're going to talk about a little bit later in our courses. And one of the most popular classification metric is the confusion metrics. We talk about-- you actually evaluate accuracy of the model, and precision of the model, recall of the model, F1 score of the model. A lot of times, that F1 score is one of the most popular classification metric evaluation. And some cases, we're also using the ROC as a-- AUC sensitivity and specificity as a part of the metrics evaluations. We also could setup the model comparisons or evaluation using the F score here in the SAS global data mining machine learning package result. And it actually shows some of the output that we have. Hyperparameter tuning is one of the important parts when you actually try to make your model perform better. Hyperparameter is a setting of the algorithm that could be adjusted to optimize the performance. So a lot of times, the hyperparameters are not really easy to determine. So usually, we tune after the model is trained, and we actually continue to train the model using hyperparameter tunings as well. Artificial neural networks, otherwise ANN. It is the most powerful machine learning algorithm, and it is a game changer. The interesting thing is it works very similar to human brain-- human neural networks. And the main type is deep neural networks, convolutional neural network, recurrent neural networks. And its architecture has artificial neurons like this, input layers, hidden layers, and then output layers. So let's compare between human neural networks versus artificial neural networks. As you see with human neural networks, it has-- or you see neurotransmitter from other networks. And then you get multiple signals from other neural networks, and then it's processed, and also it's sent out to the next human neural network. And then it has about 100 billion human neural networks. Artificial neural networks work very similar to human neural networks. It receives the data and input, and then it processes it. And it also going to other process, and then it sends it out to the next artificial neural network. Something like this. It receives it, processes it, and sends it to the next artificial neurons. So if you look at its architectures, the formula of artificial neurons works something like this. It has an input variable from x1, x2, x3, to xn. It is a numeric value that goes into artificial neural model. And then it can be multiplied by weight-- actually, corresponding weight. y1 for x1, y2 for x2, y3 for x3, and so on up to yn to x1. And then it also has a bias. So if you do multiplications and then summations-- so it works something like this. The z1 from here is summation of the multiplications of an input variable and its parameters, such as x1 times y1, plus x2 times y2, x3 times y3, and go on-- times x1, times y1, plus biases. Once we do summations of these input variables to the z1 output, and it also goes into another function, such as activation functions. And then we get output as a1. We're going to talk in more detail about this activation functions, and it works something like this. Let's look at the example. Let's say our weight is going to be something like this. We have four input variables, and then four weights, and one bias. And if you actually plot all this information, such as input variables 255, 231, up to 122, times weight, plus biases, we get 0.98371. And we plot this number into activation function, which is in k sigmoid. Then we get 0.727844 as output. I think we've seen this one in previous algorithms. It is very similar to logistic regression. So let us ask a question-- what the artificial neuron in this case is? As we discussed before, the ultimate goal of machine learning training is to find or learn optimal parameters. In this case, w1, w2, w3, w4, and biases. So the reason that we do all those calculations and training is we try to find about y1, the weight variables, and then bias variable, which is parameters. So the way artificial learns is exactly the same as we actually talked about before in machine learning training. It calculates the cost function, which is difference between actual output and predicted values. And then reusing the cost functions and grouping descent to find about the parameters such as weight and biases. So let's look at the artificial neural network architecture. As you see in this example, we have input layers, and we have two hidden layers, and we have one output layers. And input layers, we have three features, which means x1, x2, x3. First hidden layer, we have four artificial neurons. One, two, three, four. And second, we have two neurons-- one, two in second hidden layer. And then output layer, we have two outputs. So in terms of weight wise, for hidden areas, we have 12 weight. Let's calculate. For this hidden layer, artificial neuron, hidden layer one is that we have three input, which means there's three weight. And then second, neuron in hidden layer two is we also have a three. So if you times 3 times 4, then we have a 12 weight in hidden layer one. What about hidden layer two? You have two neurons, and each neuron receives 1, 2, 3, 4, which means that we have 4 weight. So 2 times 4 is going to be 8. And then in output layers, we've got two neurons, and it receives two inputs, so it's going to be 2 weight, so it's going to be 4. And then biases for hidden layer one is that one, two, three, four. So all together, the parameter that we have to find-- this example about 32 parameters we have to find, or 32 parameters we will train. We briefly talked about activation functions in previous artificial neural network. So there are a couple examples about activation functions. So activation function is pretty much a node that's added to the output of neural networks. Sometimes, it could be added between two neural networks too. And its purpose is to provide the boundary of output. There are a couple activation functions, and the first one is linear functions, which means that it provides exactly the same thing as comes in. And the sigmoid or logistic function is that it limits from 0 to 1. So if the data comes in, all the summations of those data comes in as 2, then it's going to be about 0.8. And if you go by 7, then it pretty much goes into 1-- same as the other way. Hyperbolic tangent function is going to range from minus 1 to 1. So it is mainly used for the classifications of two classes. ReLU is probably one of the most popular activation functions, and it is pretty much going to be everything below 0 is going to be 0. And then other thing, it's going to be straightforward. So it is used between the neural networks, and it is very popular for CNN and DNN. And its main purpose is to speed up the calculations. Softmax is another function that's really popular that will turn numbers into probabilities that sum to 1. Let's say that we have four outputs such as very happy, unhappy, happy, and very happy. And you see that soft function provides the probability. Saying that the data provides 10% very unhappy, 20% unhappy, and 55% happy, and 0.15 very happy. So activation-- this softmax activation function will provide output such as happy as a final output. And it's a very popular activation function for multiple classifications for neural networks, recurrent neural networks, and then NLP-- Natural Language Processing. So let's look at how it's going to be turned out into activation functions. We assume that all those inputs, such as x1, x2, x3, x4, and weight, and bias are the same. And then we use different activation functions. Let's say z equals 13.5. If linear function is activation function, then we've got 13.5. In sigmoid, we got 0.9999. And tangent, we've got almost 1. And then ReLU, we've got 13.5. However, if z is minus 0.4, our linear function is going to be 0.04, and then sigmoid, we've got 0.4. The tangent, we've got minus 0.37, and ReLU, we've got 0. So as you see, however input that we're going to have, activation function determines the boundary of the output, and also changed the output as it fit the purpose of the machine learning algorithms. We actually talk about-- one of the most the concept such as hypothesis functions, cost function, and gradient descent. Let's go into more detail about it in the next three or four sections. First, loss function. Loss function is pretty much the same as cost function. It is a method that evaluates how well your algorithms fit your data set. If your predictions of the model is off a lot, the loss function will provide higher numbers. If the prediction of model is good, then loss function perform or provides lower numbers. There's two types of loss functions. It is pretty much based on the output or label of your data. One is regressive loss functions, and another is classification loss functions. Regressive loss function is one for continuous target variable. And then usually, activation function is going to be regression that we talk about, or provide the first example. And usually, it provides two types-- or three types actually-- the mean square errors, and mean absolute errors, and smooth absolute errors. And it's determined by the data of the uses of your output. The classification loss function is for the classification target variable. Usually, there are two types. One is for the binary, and another is a multi-classifications. Binary is pretty much about whether it's going to be 1 or 0, or yes or no. And then popular one is sigmoid. Also binary cross entropy loss function is one of the most popular ones. For multi-classification, it is basically for the multi-target, such as 0 to 9-- happy, unhappy, very happy, very unhappy, things like that. And then multi-cross entropy loss function is one of the most popular ones. So when you're looking about the] loss function-- when you determine loss function for your algorithms, then usually for binary cross entropy loss function for binary classifications, and multi-cross entropy loss function for multi-target. Optimizer in machine learning is similar to gradient descent. It's goal is to minimize cost or loss functions. It will calculate the change the weight or parameter of the model so that error for the cost function will get lower and lower at each iteration of new data set. It's kind of like walking down the mountain to find the goal-- locating the value. And it's main parameter is learning rate. How much you're going to walk down for each step, or how much machine will learn each iteration. So this is an overview of optimizers that you could actually looking about the batch. Gradient descent, or stochastic gradient descent, and adaptive learning rate, and Adams. Usually, Adam is most popular because it is adaptive-- it provides adaptive learning rate. What I mean is that when initial-- the first set of iterations, learning rate is going to be high. However, it's going to go near the optimal cost function-- then it will become less. So your learning rate kind of adjusts based on your cost functions. So these are the really good machine learning algorithms that we could probably use a lot in our machine learning implementations. It is called deep neural networks. Another one is called deep learning. So deep neural network is pretty much about aggregate of individual artificial neurons. It is a type of the artificial neural network, and that we consider it a deep when hidden layers go more than two. So as you talk about artificial network, it's basic architecture is input layers, hidden layers, and output layers. And each layer is made up of a set of neurons such as the 4 neurons in the first layers. And then each neuron is fully connected to all the neurons in the layer before, and sometimes after. So an example of deep neural network is detect whether the patient will have cancer or not. So input variables are going to be age, sex, race, weight, height, family history, and outcome is going to be yes or no. And we can also detect number from 0 to 9 from images. Kinda input variable is going to be image data, such as 28 by 20 pixel images. The output is going to be 0, 1, 2, 3, 4, 5, 6, 8, 9. And also for pharmaceutical industry, you can also detect AE events from text messages. So input variable is going to be the text, comment from social media, or report from the site or hospital, and the outcome is going to be whether those texts or messages are going to be every event related or not. And also you can detect sensitivity from text message, such as we could have an input variable as a blog, comment from social media-- the outcome is that you'll be very happy, unhappy, happy, very happy. SAS also provides the neural network package in Visual data mining and much learning package. And you see that there is an option for neural networks. You actually click it and drag into the data after that preparations. And you could actually connect this one. You could setup the layer, such as you setup to three hidden layers. And then the number of neurons per layer is going to be setup to 10. And also activation function Tahn and things like that. So you could have an option to set up the hyperparameters, and also the architecture of the deep neural network using SAS Visual data mining and machine learning package. This is another hyperparameter you could set up-- all this area. You see that SGD is a Stochastic Gradient Descent, which is the optimizers. And the iterations-- how many times you're going to try. And so you could actually setup all those options which is hyperparameters using that SAS Visual data mining and machine learning. One of the good things about this package is that it is very easy to use and also very intuitive. And with some of the things that you could already setup as a default. And you could also see what is a hyperparameter you can use for these machine learning algorithms. So let's also talk about how we could improve deep neural networks based on the biases and also variance and regulations. Once you train your model, there is a situation you kind of notice-- is it could be underfitting, or it could be overfitting. Underfitting is more about your model doesn't really represent you well. Remember sometimes, you actually wear clothes that it's not really about you-- it doesn't really tell about yourself. It's kind of like that. And overfitting is that it looks really good at the moment, but not really all the time. It only fits into certain situations. For machine learning is only for certain data points. For example, after you model your data and you train your model, underfitting is that-- as you see that your data point represents something like this, but you actually get the model in a straight line. And it is probably not really good performance in terms of accuracy, and also it doesn't represent your data properly. And overfitting is that it fits too much like this one. So what you really want when you build deep neural networks or machine learning algorithms, you want to have a some kind of balance. You don't want to have a underfit-- you don't want your model underfit compared to your data. And you don't want it to overfit. You want to have something just right. How can you do that? Now the reason is that you want to have an underfit/overfit is that a lot of times, if you have-- for example, there's a high bias-- means underfit. And then overfit means it's high variances. And then if you have high variance, then it also provides a lot of errors. If you have a high biases, it also provides a lot of errors. So you don't have something just in the middle. So that is kind of why you have machine learning algorithms. And then when you have overfitting, one of the ways that you could actually minimize overfitting is called a regularization. There is two types of regularizations-- L1 and L2. And its main goal is discourage some of the more complex or flexible model so that you could avoid the risk of overfitting. So pretty much, it will minimize the learning rate. So also general procedures-- a way to remove high variance underfitting-- [LAUGHS] I mean high bias on the fitting, or high variance is overfitting. High bias means that your model is underperforming, which means accuracy is not up to the threshold. The way that you could actually improve your model is that you either have more features with more input variables, or maybe you could train longer. Like rather than doing one-time training, maybe you could do about 10 trainings. And also you could use a more advanced model. If you have a high variance, it means that your model is OK with the trained data. But in the test data, your model doesn't perform well, which means that your model fits too much on the training data. In the cases, you have to use more data or apply regularizations and maybe try less features. So machine learning training is kind of art in science. Using the science such as machine learning, but at the same time, you have to find the right fit-- art. So let's talk about convolutional neural networks. There are actually two, I would say, really big advancements in machine learning. One is image recognition. Second is natural language processing. That really helps or actually make all the things-- it's really, really advanced. There isn't a whole lot of difference between machine learning and statistics up to when we talk about image recognition and natural language processing. For image recognition, convolutional neural network is the best way for image recognition problems. So CNN uses recorded image-specific artificial neural networks, such as image search recognition, face recognition, or face verification, self-driving car, and more. And the concept is coming from brain visual context where many neurons have a small region of visual field. We talk about features in neurons in our presentations, so you'll see more detail. The name of a CNN actually comes from convolutions, one of the most important operations and calculations in CNN. We also show in our training data slide. The first CNN network is LeNet-5, which can classify digits from hand-written numbers. We will see more about transfer learning-- is probably the most effective way to apply CNN. The advantage of CNN compared to DNN is that CNN could read the data as two or three-dimensional. Compared to DNN-- it's only one dimension. So for image recognition, it becomes much more powerful because we see the image as two dimensions or three dimensions. And then it will provide less parameters, which means much less computing power to train image data. So let's talk about image data. Let's say when the computer sees this image, actually, it sees the picture value. This PNG data, if you actually import that data into computing numbers, it equals something like this. And you see that you can kind of see the same shape, and 0 is probably blank. And then high numbers, such as 255, are dark. And then low numbers such as 6, or like something dot 7, it becomes very small numbers. So now this picture is represented by 28 by 28 pixels. So this is not really a good quality picture. However, if you have a good quality picture, then this pixel becomes a lot bigger. It goes up to like a couple thousand. But the key here is that your image data-- any kind of picture could change into the numbers. And you see that if you create this picture, and then go to Property in your screen, you could kind of see that 1,300 by 1,300, which means that it has 1,300 x and 1,300 y pixels. It's a huge data point. When you process image data on deep neural networks, what happens is that-- or any other model in machine learning-- you actually change this two dimension to the one dimension. Such as 20 by 20 pixel data goes into one dimension, which means 784 input data points. And imagine how much weight you have to carry in. So if you do image data training with a DNN or other machine algorithms besides CNN, it requires a lot of computational power. When you actually stay as two dimensions, it becomes a lot easier to train. That is the reason CNN has became very popular. For example, this data-- this picture has about-- like 2,356 and 2,304. And then this 3 means that-- when you see that image data, you could see either two dimensions or three dimensions. Two dimensions is actually black and white, and three dimensions is RGB color. So usually, you've got three dimensions. So if you actually convert this data into one dimension, and then it becomes 30 million features going into DNN. This is going to take almost forever to train the image data. So what CNN does is that it actually looks at data in either two dimensions or three dimensions. If you look at the architecture of CNN-- and we go one by one as a more information-- here's input layers, which is about four dimensions with a three-- 28 by 20 times 103, where the 1 is color, One is black and white, and 3 is actually on colors. And then we actually-- or rather, the first one is going to be the number of the picture that's going to go into training. So input layers, convolution layers, and pooling layers, and another convolution and pooling, and then flatten layer, and then fully connected layer, such as deep neural networks, and then reaches optimizer. Compared to DNN which is input layers, and hidden layers, and output layers, CNN has more complicated architecture. So input layers. Usually about that-- so three dimensions. If there is a one to the end. And the first and second is going to be the pixel size. And then one is going to be-- if it's a 1, it's [INAUDIBLE] dimension, which means black. If it's 3, it means color. And if you actually process about 60,000 images, and it's going to be four dimensions. So CNN, the input data set-- feature is going to be always four dimensions. DNN is going to be always one dimension-- two dimensions. So convolution-- pretty much a mathematical combination of the two functions to produce the third function. CNN has features. We're going to talk in more detail about these features as we actually multiply this feature into these 3 by 3 matrix, and we got the value. So 1 by-- 1 times 3, 1 times 1, 2 times 1, and 0 times 0, 0 times 5, 0 times 7, minus 1 times 1, minus 1 times 8, minus 72 , then you've got a minus 5 value. And you go on. So this is image data, and this is a feature of a CNN-- 3 by 3 features. So you've got all these numbers. And you see that minus 5 is coming from there. And then you've got the oldest number, and then you notice that 8 is the largest one, which means that this area represents these things well. So feature could be many different format, but also filter is representing image feature identifier. If you actually change this into the image, it's going to be straight line. This is going to be-- is a horizontal straight line. The vertical shape-- then it's going to be kind of shape. So when you've got a high number in certain feature, such as this case, which means image in this area are more likely into straight line. So convolution kind of works this way. The filter goes into each area, and then finds what it will represent. So it finds about slope-- in this kind of slope in these features. And this kind of slope in these features. And this kind of slope in these features. So convolution is kind of filter-- finding best filter in image perspectives. And then pooling is just to making sure that you could reduce some spatial size so that you could actually compute faster. So there is a max pooling, then there's average pooling. Max pooling is more popular than average pooling. What it does is that if you are pooling with a filter 2 by 2, it means that it goes by 2 by 2, and then finds the highest number. In this case, minus 2 from this 2 by 2. In this case, 8 from this 2 by 2. And it's going to be 0 for these 2 by 2. And it's going to be minus 3, and 2 by 2. Flatten layer is that it is actually converting all those kind of 4 or 5-- well, actually, 4 dimensional pooling layers into one dimension so you can actually process things much faster. And then fully connected layer is kind of deep neural networks basically. Here's the flatten layers, and then couple of the hidden layers, such as fully connected layers, and then you connect to the output. So the fully connected layer is working like neurons in fully connected layer to detect a certain feature of images, like nose, and mouth, and eyes. So in this case, this neuron represents maybe nose, this neuron represents certain types-- nose 1, nose 2, nose 3. And it could represent eye 1, eye 2, eye 3. So in this output, it probably gets more value for nose type 2. And in this case, it could be more value from eye type 2, and things like that. So output layer is pretty much output representations. So if you get a 10 output, which means there's about 10 output. Whether it's going to 0 to-- probably 0 to 9, it could be [INAUDIBLE] 10 output. And then the interesting about this output layer is that the resulting vector for digit classification programs, such as-- let's say it's going to be 0 up to there-- then as you see that it represents 0, 1, 2, 3, 4, 5, 6, 7, 8, 9. Then that means that the 10% probability, that is going to be 1. And 10% probability is going to be 1, and then 2. And then 75% probability, that image is going to be 5-- 0, 1, 2, 3, 4, 5-- so that you actually are looking about-- the 5 is the most popular answer. Machine learning most of the time is about the probability. If there's about 10 output classifications, and then you pick the one which has the most probability. And the softmax function provides that information. So as you see, for CNN model, input dimension is going to be 4 dimension such as 20,000 images. And each image represents by 1,400 times 1,400 pictures, and the colors. And then output is 2, which means about 20,000 dimensions to 20,000 and then 10 output. So this 20,000 is going to be number of the records, which is output. And then second dimension is the number of the classification. Such as 0 to 9, it could be car, and truck, and van, and bicycle, and things like that. Actually, every year, there is a competition about image recognition. And then one of the most popular ones is the LeNet developed about 1998 to 2000's. And then the one that's really the most popular one is the AlexNet, which is developed about 2012, because it uses CNN, and then it actually beat other competitions more than half. It's about 85% accuracy for the image recognition. And then the thing is this gets better and better when we apply more CNN algorithms. The ResNet which is competition winner in 2015 is less than 4% error rate, which is amazing. We're going to talk more detail about this one later on in transfer learning, because we will use some of the pre-trained models to any other machine learning implementations. CNN implementation is one of the most popular deep neural networks, and it is pretty much go-to model for all those image related problems, such as image classifications, X-ray diagnosis, face recognition, and face verification, and object recognition, and autonomous vehicles. I'm actually very exciting about our next topic-- recurrent neural network and natural language processing. Actually, this is the one that I'm working on at this moment in my current positions. Recurrent neural network is the model that uses sequential information. The reason that the recurrent neural network became popular is that it is very useful when our input are dependent. When you actually talk about other machine learning algorithms, all those input data-- input features are pretty much independent of each other. However, in the same-- or in the situation that the data becomes very much dependent, such as sequential data in RNN-- recurrent neural network-- has the most effective machine learning algorithm for those kinds of data, because this RNN has a memory feature that captures previous information about what has been calculated so far. Now let's look at an example. The basic RNN structures and algorithms are shown below. As you see, there's an input such as x1 goes into the model. And it gets process, and it provides the output model. And when x2 was input into the model, what happened is that these RNN neurons also have information from previous input, such as x1. And x3 in the same situation also received the information from x1, x2. So now when you talk about this y3 as an output, it has information from x1, x2, x3, and so on. The basic structures of our RNN model has two units. Gated recurrent unit, LSTM, or Long Short-Term Memory. The gated recurrent unit is a gating mechanism in recurrent neural network. And it has been shown to exhibit better performance on smaller data sets. And then GRU actually has fewer parameters than LSTM so it can actually train faster. However, LSTM which is Long Short-Term Memory unit, becomes more effective when you talk about RNN and also natural language processing implementations. It has 4 gates, such as input, forget, gate, and output. LSTM-- remember, the values over arbitrary times intervals, and 3 gates regulate the flow of information into and also out of LSTM unit. The basic popular implementation is that-- such as text notation or filling in the missing output. So actually same number of inputs and also same number of outputs. When you see the situation when there is a missing word or vocabulary in a sentence, then this one is able to fill in that missing information. Another implementation is a sentimental analysis, such as PV signal. When you read some of the text, and then you could actually analyze whether this text means or represents some information. Whether this text is about AE event or other information. Or when you read this text, you could see that, oh, it sounds happy, or this sounds positive, or negative. And then another implementation is kind of picture descriptions. When the picture is read, then output is going to be the information about the pictures. And also machine learning translations. Input is going to be English, and output is going to be French or Spanish. Or in chatbot development, or any other things. RNN is actually a very useful implementation for natural language processing. The natural language processing is pretty much in the area of artificial intelligence, of a human language interactions, and implementations. So basically, the computer reads some of the language, and also it provides descriptions and analysis about those language text information. So our input data will be some text language, and output data is going to be descriptions or other text in the language. Let's look at some of the sentimental analysis. So input data is-- we actually implement the embedding process, which means represent each word to the vectors or numbers. [Going by actually read the input data as a language-- some of the vocabulary-- and we convert that vocabulary into numbers. For example, if we go into words such as "I am happy." Here's a completely, and it's converting to the embedding process, and then it becomes e1852 , which is about 50 vectors of that information. And the output data could be representation of the softmax output, such as 0.07, 0.13, 0.1, and 0.70, which represent very unhappy, unhappy, very, and very unhappy. So using that as output, NLP could predict the output of this texts is going to be very happy because it has highest probability of 70%. And you see this one. So if you go into more detail about this information-- for example, this input data is "I am smiling." So now, in NLP process, this "I"-- the vocabulary is going to be converting to some other numbers, and then it will go into LSTM process. And then "am" is also going to change into number using the embedding process-- it goes into the LSTM. And then "smiling" also goes into the embedding process, and converts to the vectors-- numbers-- and then it goes into LSTM. So this part has a memory from "I am." Also a combination of smiling. And using this process in natural language process, it also provides the output. In this case, very happy. Recurrent neural network is applied a lot in many industries, and it is one of the most popular implementations for machine learning. And there will be more implementations you can see in the future, such as speech recognition, music generation, sentiment classifications, motion translations, video activity recognition, and name entity recognition, DNA sequence analysis, and also chatbots. I'm also very excited about our next topic-- about transfer learning. It is one that I'm currently working on. But at the same time, it is actually making machine learning implementations and training much easier than before. Let me tell a story. Let's say we try to train SAS programming people. You have two options. One is experienced programmers. The other option is novice programmer which has never programmed before. So in general, you can ask the question, who will learn faster, and who will be much more effective or cheaper to train? Yes, usually, the experienced programmer who knows about Java or Python are non-SAS-- program much faster than people who never programmed before. Exactly the same way. Transfer learning is that we already trained our model with some information, and then we actually convert-- or using that already pre-trained model with other implementations. So in a way, the machine learning method where a pre-trained model is used as a starting point of the model development for another or a similar task. So you might wonder how it could be applied. If we go in that direction, let's talk a little bit about some of the characteristics of the machine learning model. For, let's say, image recognition model-- and we actually train the model-- in all the layers cannot detect about edge detections. And when you go into middle layers, it starts shaping. Each neuron represents some shape of the images. And then when you go to later layers, and then each neuron represents more high level feature detections. So as the model progresses, the layer or neurons from the layer model-- later layers actually represent more high level features. So let's kind of think about con pre-trained models, such as VGG. VGG model is the most popular one-- it is also free, available in the public. And here's the two architectures. It's either 16 layers or 19 layers. And it is a CNN model for image data, and then it only trained with 14,000 images with 10,000 class objects. And it has the parameters, such as weight and bias, almost 140 million parameters. And then if you want to train again, it will take about a week. And it costs a lot of money. You need a GPU to process and train this model. However, all those parameters in this pre-trained model VGG are available in public. So let's see how we could actually implement transfer learning in our new problems. First, we select the pre-trained model. Let's say you select the VGG. And then we import pre-trained model into our programs. So this is VGG is already trained with 14 million images-- about thousands classifications. So you import this already pre-trained model into our programs, and then we could actually determine which layer we're going to train again, or which layer we're not going to train. Right now, let's say you have about 6 layers here, but you could then decide to train maybe last 2 probably don't train more. And then we decide more layers of the imported pre-trained model. Right now, there is only 1 layer in our side and I replaced with our new layers here. And then we define the output differently. Let's say you're going to have a 2 on the output. And then we actually prepare new data. Right now, there is about all the images we trained with, but right now, we're going to focus on certain images, such as X-rays. And then we determine what output is going to be of these layers. And we compile this, and then train against. In terms of VGG, we need about 14 million images. But in a pre-trained model, setting about the proper output layers, we might need about a couple thousand. So it is actually saving a lot of money and saving time. So you wonder why transfer learning? We actually talk about it-- we could train models much faster, so it becomes cost effective. In many cases-- sometimes, you don't have a choice. Because finding the right data is sometimes very hard and very difficult. So lack of data decides that we're going to go with pre-trained model in other cases. As we mentioned, there are a lot of pre-trained models. For image data, there is Xception, Inception model, ImageNet, ResNet, VGG model, and also ResNet model, and things like that. For language data, there is Google word2vec, and GloVe as the embedding process. And then UMLFit or BERT. ELMo is one of the most popular language models out there. So when you do some of the high end implementations, in many cases, we start with a pre-trained model, and then we prepare data accordingly. And we actually set up some of the model so that we could actually apply it to other problems. So let's talk about how machine learning AI is impacting our lives. First, it's probably the most prevalent in our implementation-- voice recognition. I have young children, and from time to time, I notice that they're actually talking to Siri. So such as Alexa-- Siri is one of the most popular NLP implementations. So it is the voice recognition. And then Amazon, and Netflix, or Spotify using machine learning for their recommendation systems. The chatbot is probably one of the most popular ones in terms of customer services. So when you open some of the websites, they actually pop up a small window saying, how can I help you? Most of the time, those kinds of pop up windows are actually the chatbot, and you are initially talking to the machine, not a human. A good thing is that is chatbot-- once you setup this chatbot, it will provide quick and easy communication between customer, and it will work 24/7. I think about last year, Google introduced AI Assistant. It's a system that's accomplishing real world tasks over the phone. It's amazing what you could do in the future. And also imagine-- introduce the Amazon Go cashierless grocery store. What happens is that you actually scan your phone when you walk in, and then you actually pick up your items into your bag. And what happens is they monitor you using the CNN image recognition. And then when they grab it, they notice. When you return it, they also notice too. So they charge based on what you actually selected. The funny thing is there's no line-- cashier-- but there is a line outside waiting to get in. It happened about a couple years ago, and IBM built AlphaGO to beat the best Go player in the world. We think that Go is so complex, so machines will probably never beat humans, but AlphaGO actually beat the best Go players with a short time of training. Whenever I talk about machine learning, when I say about Terminator, then people always got it. There is a debate about how much machine learning should be applied or implemented in certain areas, such as military. There's a lot of people actually against it-- about this part-- something that we should regulate, and some of the machine implementation in certain area. But when you talk about AI machine learning, then if you kind of hint about Terminator, then people usually get it about the machine learning implementation. So how the machine learning implementation in industry? Let's talk about some tools. There's some machine learning programs such as SAS, and R, and Python. And then SAS also has a great interface tool, such as SAS Visual data mining and machine learning interface. And you could actually do a lot of visual and easy to use machine learning implementations. And also if you look about the SAS Viya, it also has some of the machine learning procedures that you can use. And R and Python are probably the popular machine learning implementations, and it's also available on the website, and also there are a lot of good machine learning packages too. And then there's also very interactive, easy to use tools such as SAS Visual data mining and machine learning package, or IBM Watson, and Microsoft Azure, and Google Cloud, in H2O. So let's talk about why AI machine learning is so popular. And it is actually very innovative. It actually helps to solve problems that we weren't able to solve before. And it actually provides new business revenue and also developments. And it is actually cost effective. It could automate a lot of tasks and work, and it might have a chance to replace or enhance some human resources. Andrew Ng is one of the most popular AI implementation-- he's a co-founder of Coursera, and he was leading Google Brain, and was Alibaba for the last couple of years. Right now, he's actually doing some AI machine learning based on the future-- I think the investment funds. But he kind of says that pretty much anything that a person could do or think in less than second, we could now automate with AI. So there will be a lot of implementation in terms of innovations and cost effective purposes. So there will be more-- and a lot of AI implementations in the future. And in some cases-- not all, but it could be more accurate than general humans in some of applications such X-ray, or diagnosing, things like. A lot of people actually ask me about how they could start with machine learning. Whether we like it or not, machine learning is going to change a lot of different things. So the first step is we have to admit that machine learning is there, and it will change many things. And then I recommend that reading or learning machine learning either take courses. There is a lot of online courses, free videos, and schools. And then as a programmer, I love to do hands-on programming. So the best way to learn is hands-on programming. So do exercises. You could participate can have competitions with others. And then start following other people. There are a lot of good machine earning materials and also machine learning teachers-- even there's a lot them are free. So try to follow them, and try to keep up with them. And then start implementing in your organization even if it is very small and simple. That way that you could actually start learning about it, but at the same time, you can actually evangelize machine learning for your department and your organization's. The hardest part is any innovation in any new technology or new idea is actually starting. And I applaud you starting machine learning, and also taking these courses. So let's kind of keep it up. And then if you have any questions, and if you have any comments, then please let me know. You could find me-- you can send an email to my personal email address. And also you could actually send any information or requests to LinkedIn. I'm very active on LinkedIn-- social media. So you could actually contact me through that area. And please let me know how you're doing, and also let me know if you have any questions. Once again, thank you all for attending machine learning pre-seminar conference at SAS Global 2020. And I look forward to seeing you all for next SAS Global conference. Thank you. Please let me know if you have any questions. Thanks. Bye. 