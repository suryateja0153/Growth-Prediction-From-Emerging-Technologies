  SHAWN COLE: Welcome to J-PAL's IDEA Handbook Webinar Series. I'm Shawn Cole, Professor at Harvard Business School, and co-chair of J-PAL's IDEA Initiative. These webinars accompany the release of our new Handbook on Using Administrative Data for Research and Evidence-based Policy, which is funded by the Alfred P. Sloan Foundation. The handbook provides a series of technical guides and case studies on how to make administrative data more accessible for research and policy. Today it's my pleasure to introduce Arianna Legovini. Arianna is the Head of the Development Impact Evaluation department, or DIME, at the World Bank. She established the group in 2009 based on a model of collaboration between research and operations to optimize project design, secure higher returns to development investments, and empower governments to generate contextually relevant evidence to guide their policymaking processes. She now presides over a team of 186 people, conducting research in 60 countries across all sectors, working with 200 agencies, and shaping a $20 billion development finance agenda. Arianna will discuss how DIME generates demand from government agencies and supplies them with research services that augment their data, program management, and policy functions. DIME's work ranges from developing a pilot administrative data system, to digitizing paper-based administrative data, leveraging existing cross-sector-specific data sets across multiple countries. She will describe how DIME combines an evaluative and capacity-building approach to secure access to existing administrative data, and fuses it and integrates it with other existing or newly-collected data to make administrative data analysis ready provide an added value to country clients. With that, I would like to invite you to listen to Arianna's talk. Following the talk, we will have a live question and answer session. ARIANNA LEGOVINI: Hello. My name is Arianna Legovini, and I'm the founder and Head of Development Impact Evaluation department at the World Bank. I'll be presenting, today, the use of administrative data in World Bank research, specifically the case of DIME. And this is a chapter I co-authored with Maria Jones, who's the head of our DIME Analytics team. The work is based on much of the research from some of our colleagues, including Lupe Bedoya, Daniel Chen, Sveta Milusheva, Florence Kondylis, and Vicenzo Di Maro. And I'm going to discuss a little bit about the DIME model, and our concept behind the use of administrative data. The idea behind DIME was really to shift development practice from expert advice to implementing tested solutions, and empowering governments to really discover how to solve their own problems, and then gather support around their own solutions. And so the idea was to focus a lot of our attention in building capacities-- capacities of government to understand the problems they are facing, a much greater level of detail to the capacity to ask the most important questions, the capacities to monitor their processes and their programs and their policies, and then to understand and operationalize the evidence that we could generate with them and take action-- and action that would then affect the developmental effectiveness of their policies and programs. So when we think about access to data, we kind of step back and really install a paradigm, or think of a paradigm of creating an improved capacity for generating and using administrative data. The DIME model for adoption of data-and-evidence-informed policy is based on the idea that we should be releasing constraints, and all the constraints the government face in adopting a more evidenced-based policy-making model. What are some of those constraints? Of course, there are technical constraints and financial constraints, but there are also motivational, reputational, and aspirational. And so what we do is to subsidize local research with the idea that we can generate local knowledge but also contribute to the global knowledge agenda, and supplement skills, and teach by doing our government counterparts how to develop better data systems and better evaluative models that then would feed into their policy cycles. We use group dynamics to secure the interest in adoption, but also to allow them to learn more across programmatic approach to research that puts them in contact with many other policymakers from other countries and start learning more through the experience, and data, and evidence of others than they would in isolation. One of the characteristic features of what we sell as a model is to see the light at the end of the tunnel for governments who get a lot of support during the whole cycle of implementation of policies and programs through a very collaborative effort and approach that then would allow them to aspire to greater results, that would inspire them to solve problems and not just manage the problems they face. And finally, in terms of reputations, we document the results and successes of these processes to allow them to then negotiate both the political and resource base for continuing their programs or expanding them further. As a result of this interactions with governments, we face huge demands. And in fact, more demand than we can possibly address through our own capacities and through the size of our research group that has grown quite a bit in the last few years. Specifically, in the last six years of programming, we have developed a global research program of about $200 million that has been able to shape and contribute to the delivery of about $20 billion in development finance. This program is present in all the sectors that the World Bank is supporting and collaborating in about 22-- sorry, 62 countries with more than 200 long term iterative research programs. As a result, DIME has become a global leader in adaptive development research, focusing specifically on three areas. The first is to innovate in measurement and build the data capabilities that allow us, together with our clients, to understand the problems that we are trying to solve. The second is to analyze these data and provide or find opportunities for targeting and prioritizing policy actions, where we think that there is a greater return to the effort. And then conduct randomized controlled trials to improve outcomes to understand what the modalities function better or to estimate parameters of interest, and so forth, and so on, kind of iteratively learn how to select better ways of doing things that would then contribute to the effectiveness of those policies and programs. So back to administrative data, we feel that research, in general, and impact evaluation specifically, is a good organizing framework for developing data sets that are of high quality. And generally, administrative data are designed to monitor processes and analysis writing. And so what we do is combine the kind of evaluative and capacity building approach to access existing administrative data, but then integrate it with other existing type of data or collecting new data that allows us to create high value data sets that are ready for analysis. And this process is done collaboratively with governments and even kind of develop prototypes of data systems and dashboards that then can make very explicit to agencies that are collaborating with us with the value of their own data is and how they can extract information that is actionable and useful. So over the last few years, the use of administrative data has increased substantially in our research project from about 10% to 15% of research projects using administrative data to more than 1/3 recently doing so. And I expect this proportion to increase quite substantially. In fact, even in the last year, for which I don't have data yet, I would imagine this proportion having gone up quite significantly due to the COVID crisis and the intensified use of administrative data, especially data coming from e-government systems as we have tried to provide a response in different countries on a real time basis. And so we've started using more and more high frequency transactional level data to inform the response to the crisis. What I would like to do next is provide four examples of the use of administrative data or the development of administrative data when data is actually not available. So our first case is piloting a new administrative data systems, the case of patient safety in Kenya, a work which is led by Lupe Bedoya and colleague Jishnu Das, now at Georgetown University. Patient safety is an issue that is taxing our health systems, as the recent crisis has demonstrated, but one where the team found very little groundwork to base their research on. And so there was a huge investment in understanding the very concept of patient safety and what it means for a patient to be safe in a health facility. There was no systematic data available on compliance with patient safety standards in health facility. There was a regulatory framework, but there was no consistent inspection of facilities or standardized inspection of facilities. So the team developed, really almost every tool from scratch, from manuals, to training of inspectors, to a system or a framework for measuring patient safety with an e-checklist, et cetera. Now, this was done in close collaboration with the health system and all the different actors in that system, both from the private and public side, which culminated in a mock trial that demonstrated an inspection regime with clear rules, monitoring enforcement can be quite effective in improving patient safety in public and private health facilities. We started from a baseline of only 3% of those facilities being minimally compliant with patient safety standards to a large increase in patient safety due to the new inspection regime. This was a proof of concept of the value of supporting government in developing data system to evaluate sector-wide reforms. And the prototype system is now being scaled up at the national level with the support of the World Bank investment project. The second example I'd like to discuss is the case of digitizing administrative data that exists but is in paper form, and therefore not usable. That is the case, for example, of the Kenya road safety, where with my colleagues, Lupe Bedoya, Rob Marty, and Sveta Milusheva from DIME, and Sarah Williams from MIT, we started thinking about how a government would address the sustainable development goal number three to have mortality on the roads in their own countries without having any data on which to base the prioritization of their investments or even any data to understand the main factors behind unsafe roads in Kenya. And so we received the permission from the National Police Service to digitize their police reports, paper reports in all 15 wards in Nairobi. And we digitized about 10,000 reports, including characteristics, and location of crashes, and geolocating those crashes on a map. The result of that work allowed us, for example, to see that about 200 locations in Nairobi were responsible to more than 50% of injuries and crashes-- injuries and deaths, sorry. And 71% of those deaths where pedestrians, 41% of which died between the hours of 7:00 PM and 12:00 PM. And as we continue investigating, we could start identifying the factors behind those death, including lighting, speeding, law enforcement, et cetera. And we kind of started developing through discussions with governments and understanding of what package of interventions could be tested in these different locations with the idea that targeting a reduction in half of mortality across 200 locations representing less than 1% of the road network of Nairobi would be a more manageable problem than trying to fix road safety across the whole network. In addition to that, we invested in publicly available data, transforming Twitter reports into geolocated crashes, but innovating algorithms to geolocate in real time, and then verify the location of those crashes, and creating a life map of crashes across Nairobi. This is also a way to understand the quality of administrative data systems and start to work in improving police recording of crashes across the city. The third case I'd like to discuss is the work led by Florence Kondylis, which is leveraging country investments in administrative data in Rwanda. Rwanda is a country has invested quite substantially in administrative data systems of high quality. And we have worked with them since 2012 to leverage those administrative data systems and create, again, a national data set that is able to answer questions of larger economic import. Specifically, the work was initially motivated by large investments in infrastructures to improve the productivity of the rural sector and improve the supply chains of agricultural production. And the question as it was clearly stated, what is the impact of these investments on market functioning and household welfare? And so we use existing administrative data combined with high-frequency market price data in an event study to start identifying those impacts. Now, I think what has been extremely interesting about developing a national research program with a national low to high frequency data system is, for example, that we are able to monitor dispersion of prices across multiple markets, across the national geography, understanding arbitrage opportunities, the constraints faced by farmers in taking advantage of those arbitrage opportunities because of lack of roads or inadequate connections, looked at constraints from the labor market side, land markets through land registry data. During COVID the data has been extremely fruitful in understanding, for example, the impact of urban lockdowns on different sectors of economy across different geographies and being able to inform policy response during the crisis and hopefully during the recovery stage as well. The last case I'd like to discuss is led by our colleague Daniel Chen is on leveraging investments in administrative data systems. The case of data and evidence in justice reform or DE JURE. This is a program that is currently active in multiple countries across the world, which is taking advantage of the investments in electronic case management systems and of innovations in artificial intelligence to extract from unstructured text data that then can be used for the purpose of analysis. And what we do with this program is run law and development, randomized controlled trials to understand how to improve the efficiency and quality of judicial process, but also to understand the economic impacts of a judicial system on individuals and firms. The program was kind of took shape after our first successful interaction with the justice systems in Senegal, where we actually digitized the information from the commercial courts and starting informing the regulatory reform processes, by identifying real stumbling block within those processes that then led to a 30% reduction in pre-trial delays and increased the interest of the judiciary in working with us on using data to really inform the process of improvement in court functions. Now, the DE JURE program, for example, interacts with justices, in the case of Kenya, by presenting them a view of their own performance and recommends actions for them to improve their performance on the ground. In other cases, such as Chile, we use information related to the justices' previous judgments and decisions to inform their understanding and potentially reducing biases in decision making in subsequent cases. We can see, for example, that in Kenya, providing justices with actionable information is quite effective in decreasing the number of abjurements justices use and therefore avoiding unnecessary delays. I'd like to conclude by talking a little about our DIME Analytics team. DIME Analytics, I established DIME Analytics within DIME to take advantage of our skill, and experience, and start developing a series of public goods or institutional solutions for high-quality data and research along at least four elements. One is capacity building, which I discussed briefly at the beginning of my presentations, including trainings. I discuss capacity building for governments. But we are developing also a lot of tools for capacity building of researchers and improving the quality of development research more generally. Second, we focused on reproducible research and especially developing the protocols for our research teams that would then ensure the reproducibility of the research. And we have also made those tools available more widely. We have a number of open source research tools and high-quality data acquisition element. Now, I'd like to briefly mention the computational reproducibility, as we have implemented these protocols in 2018. At that time, only about 50% of our outputs, our papers do not require significant revisions. But a year later, more than 90% did not require significant revision. So a huge jump in computational reproducibility by simply ensuring that all projects follow basic protocols. So this is something, I think, that it's quite exportable from our experience to other research groups and certainly something that we would be happy to share with all interested parties. The way this is organized is the DIME Analytics test every single paper for computational reproducibility doing all the code's checks, and making sure that everything replicates exactly from the code provided before each publication. When computational reproducibility is not perfect for the teams, we see feedback, and they are required to make the necessary changes to ensure that that code is up to par. On the public goods for high-quality research, I'd like to mention six items. The first is the DIME Analytics data handbook called Development Research and Practice. The second one is the DIME Wiki, which we consider a one-stop-shop for impact of additional resources and of course, count on the participation as in any wiki of all practitioners to help us improve the quality of the DIME Wiki. Two visual libraries, one based on Stata code, and one on R code. And two toolkits, one for data collection, i.e. field kit, and one for data analysis, i.e. toolkit. And just to give you an idea of the outreach of one of these tools, the DIME Wiki, you can see in the map on the left, the whole world, almost every country on the map has been accessing the Wiki. And the most active cities among the top 10, you see a large majority of cities in developing countries being active users of the DIME Wiki, with the top user being Nairobi, which makes me, of course, very proud, as I lived in Nairobi for four years. And also, a lot of my research is based there. So without further ado, let me thank the organizers, and I hope to have enough time for discussion. Thank you. 