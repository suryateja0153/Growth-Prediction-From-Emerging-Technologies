 welcome everyone to what's new in bigquery session I'm Sudhir has day I'm the director of product for smart analytics platform at Google cloud and I'm Tina thrush go on a product manager on Google bigquery at Google cloud in the smart analytics team our vision is to give you or provide you with an enterprise class potatoe platform with proven dependability and Google we believe in building these large-scale services that can meet all your security and Trust needs so so we basically have been focused on that in addition to that we are also about being open and flexible providing you with choice and finally and most important we want to embed intelligence across the whole platform so that's our primary vision in the smart analytics team let's Rumble bigquery first Google bigquery it's now 10 years old in June we celebrated the 10th anniversary of bigquery query has customers from a you know few terabytes to hundreds of petabytes it's a completely serverless technology what do I mean by that oh it means you don't have to worry about any infrastructure pieces just bring your data and start analyzing it start writing queries on it there's no monitoring there is no administration there is no machines there is no nodes there are no servers that you need to worry about so most of that is managed by by Google we take care of all of that for you the second thing we are highly differentiated we provide you the ability to ingest tens of millions of events in real time into bigquery and lot of organizations like our like King which is a gaming company they have in-game events that happen and they want to stream that in real time so they can analyze what what users are doing on their platform so it's possible and menu ingest large scale events it does not impact your query performance on top of top of the data because we completely distribute or decouple of compute and storage layer in addition to that we have embedded machine learning capability where you can write sequel commands to create machine learning models and get get advanced predictions and finally we don't want insights to be limited to few in the organization we want insights for every one of you made a lot of investment in the space where bigquery is being used by organizations like AirAsia but they were able to reduce their operational cost airline by five to ten percent by making those insights available to everybody in front lines that they can make better decisions so so those are those are the key capabilities that we provide one thing that bigquery is great at is scale we are really powering some of the largest of the workloads in analytic space our largest customer has more than 350 petabytes of data in the data warehouse one of the largest queries that was run was roughly 100 trillion rows that were queried in a single query and we have seen up to 10,000 concurrent users being you like no use by our customers so so concurrency at a very high scale is also supported let's talk about HSBC it's a it's a systemic bank it's highly regulated it just BC uses bigquery to run large-scale analytics or lot of regulatory reporting and all one of the key things that we were able to do by working with HSBC is provide a lot of security capabilities in bigquery like CMAC the festival manager encryption keys virtual private connect so all of these VP CSC all these capabilities we built with with HSBC they are proven they're they're used by some of the largest banks in the world in HSBC's case they bring data from 40-plus countries all transaction data they put it into into their data link / data warehouse will be query they analyze all of this data and at the end of the day they have to report to regulators about the viability of the all the data and all of this is running in few minutes which used to tape like I think 30 hours on on-premise systems and stuff like that and you have to do this every day so in 30 hours you cannot go ahead and report every day so so on on bigquery we can do it in a few minutes and it's allowing them to scale scale their business so the core is much more than a data warehouse because we have so much advanced capabilities but one strength of bigquery is the fact that it is a part of a tightly integrated broad smart emmalin's platform that includes services like data prog data fusion and even looker and actually the vast majority of the query customers are using a number of these services together with the query and sky UK is one of them of course sky is a broadcaster and they provide these enhanced set-top boxes that communicate that directly to pops up beautiful and the query for real-time analysis what that enables Scott to do is to really understand the customer deeply they're able to understand what customers are doing what they're watching their preferences they're able to tailor customized content and advertisements on so forth and they even can do research on customers by doing a/b testing and if you look at the growth of bigquery like we've seen tremendous growth in last last year or so we have customers across every industry vertical across every region in the world we have large customers like Home Depot to ups in in in United States we have HSBC we have sky we have King we have know various different customers Metro picado in amia because of customers and JPAC region like fast retailing group in seed bank and go check and aeration also so we have we have seen adoption across the globe bye-bye different customers different kinds of use cases and and synonyms so for today's roadmap session what we did was if you've taken some of the key highlights in the roadmap and we are going to share them with you and we're going to do this across the three value pillars that we have being open and flexible intelligent and and proven in dependability let's start with proving dependability HSBC and sky of course multinational corporations they'll put their trust into the query to drive their business forward so we really need to take care of our customers in this area and so what we think about it is we enhance dependability in four areas availability and uptime administration and control performance and just quarry execution and finally trust security and governance today we're announcing the fact that we are enhancing our SLA by an additional nine so now there's four nines availability that we guarantee right we're doing this free of charge to all of our customers there's no special rates that you have to pay the reason we're able to do is is because we have service architecture it's very advanced radically unique architecture that does guarantee against downtime and specific circumstances so there's four nines of availability is really only about four minutes of downtime per month or less than an hour per day and you note that it is actually industry-leading when it comes to cloud data warehouses all other plans that are warehouses only offer three nines of availability and of course we care about performance and our customers care about performance so we started running this query in the last few years to demonstrate the power of the court this is a query that is a simple point lookup but it is a query on an entire petabytes worth of that so in 2016 when we first ran this query we had executed about six minutes and scan the whole petabyte in 2018 a couple years later we executed this query in just two minutes and it actually scanned about 400 men of megabytes today if you run the score in bigquery you will notice that it takes about force that's wrong and the best part of all is that you didn't need to do anything special you didn't need to pay anything extra to start getting this better performance we just upgraded your service for you seamlessly without any downtime and you just got better performance in fact just in 2020 alone from the beginning of the year with me major improvements to all the typical industry standard benchmarks this is a TBC D s benchmark and we're looking at an geo mean of performance so both for want eternity and ability scales we improve performance aimer from 20 to 30% and again you just get this performance as part of using the query you don't have to do anything and it just happens so we have a number of customers in all kinds of areas and of course sports leagues and sports teams are taken advantage of recorded a major league baseball being the newest one there's a breakdown da 204 that talks about the journey that MLB took to kind of read platform onto the court well the first thing they notice when they start using bigquery is the fact that they're able to give this information to give analytics to all the key stakeholders when they made you look baseball and the teams that are part of the league and they're able to do some real-time right they don't have these bottlenecks anymore at the same time they're getting performance that's significantly better than the previous the previous platform and finally it's very very easy for them to manage this right because the queries serverless there's really not a lot of things for them to worry about and they really like that so we talked about how bigquery serverless it doesn't require administration that said the more customers we have that are multinational that are complicated they have lots of business units the more they're asking for better control better predictability better visibility right so we've made significant investments here just in 2020 alone we've launched a number of improvements to the query the first one being reservations reservations is an enterprise-grade workload management platform that allows you to achieve predictable pricing to make sure that all your workloads are executing under the proper oscillates and it's super efficient because it's using auto capacity the next enhancement is flex loss flex slots allow you to purchase capacity just for a few seconds at a time and you can cancel them anytime you essentially get instant capacity to make your workload demands and for the classic database administrators out there we've made a number of enhancements as well one is information schema these are just tables that contain matter that are relevant to your service we've made him handsome for data types and we've made improvements to sequel that as well I'm really delighted about this feature it's coming in the next few months the query slot auto-scaling so this kind of combines the best of both worlds right you're getting the price predictability of slots based pricing and you get like the low management overhead on this associate with our on-demand model because slots auto-scaling allows you to configure your scaling limits and your spend limits and bigquery takes care of the rest we simply scale up and down your workloads depending on what you throw out the court so some of the things that are really relevant about this is the fact that the supports to Auto powers and our start mode so we can go from zero to full scale and back to zero if you'd like that because we are not powered by the an so you get a lot of additional advancement so for example we don't have this pre warm period when you're not getting optimal performance the second you get your capacity performance is at 100% also if you have queries in flight or is they're being executed you can add capacity and those queries would immediately start taking advantage of that right so you can accelerate queries in flight or using the quiz slots Auto scale because we don't have yes we're not powered by we're not powered by local disk right so we don't have those local disk bottlenecks if you start running out of local disk you start getting performance clips that are unpredictable they're hard to monitor for and hard to document we don't have such problems right we always have hot data for you and finally we kind of already talked about the submit SLA slides but we can provide a high level of reliability because we're immune to individual no time no downtime in fact a huge portion of the data center can come down and you're not even going to notice that the next feature we're launching administration next two months is admin panel you are now we have stock drive Florida which is incredibly powerful but our customers want us to also have the query native monitoring capability so admin panel will provide you with the ability to monitor your queries your slosh your resources your spent your workloads in your users right in the quarry from the query this will have a real time component with so you can see what's happening right the second and you can go back in time several weeks and months so how are you gonna use that mint panel well you're going to be able to figure out how your organization's using the query in general who are your top users what are the types of queries don't run and you're also going to be able to perform real-time root cause analysis whenever things are wrong maybe there's a for loop that went awry so you want to catch that in your figure out what's going on and move on customers always ask us you have all these price capabilities but how do I choose which model to use which one is the right one for me and you know how much capacity show are purchased so we're launching bigquery slot recommender big choice lock recommender we're going to run this intelligence and we're going to send you inside automatically that will actually recommend whether you should be on the on-demand model or whether you should get on a slot mom and of course we're going to do this too without sacrificing your performance so we're gonna tell you that there's a recommendation out there it's going to recommend you to save money without extra sacrificing performance so we talked about availability we talked about administration we talked about performance but probably the most important aspect of the query is is security right our customers trust us with their data and their workloads and we can't fail them so we have a kind of a three prong strategy here the first one is the quarry is a part of Google and Google employs thousands of the best security engineers in the world there they're working on security on custom hardware networking penetration so on and so forth and bigquery gets to benefit from all of this innovation that's the beauty of the quarry and that's the first builder so you just get a high level of security automatically when the quarry the second pillar is the fact that we're giving you a number of controls and configurations and services that enable you to customize how much security you want in your environment things like pseudo mention customer management corruption keys virtual private networking but the key to this component is data catalog data catalog is a metadata management and discovery service that we launched recently so imagine your data coming into Google Cloud data catalog can automatically index that data then the data passes through data loss prevention API removes and tokenize sspi information and private and secure information and then you can apply tags and policies to this data and and grant access to the right levels of data to the right users inside of your organization so it's a super flexible super powerful platform for data management that allows you to really control how how your dad is exposed internally and externally and the third pillar that's critical to our success here is the fact that we're working with all the relevant agencies to achieve these artists and certifications right so if you're storing medical data inside of the query you know you can trust us because we have HIPAA certification if you're storing financial data inside of the query you know you can trust us because we have PCI certification if you're doing business in Germany or Singapore we have proper credentials as well and with FedRAMP we can do business with government or with that now now we talked about proven dependability let's switch gears talk about the intelligence one of our key capabilities in Google cloud is of course our capabilities around machine learning in AI and we people talk more about how we have and embedded machine learning capabilities that we are providing with the query we'll also talk about some real-time analytics improvements that we have done but before that let's talk about democratizing insights one of our key value pillars in Google flower is we want insights for everyone we want to make sure every individual person in an organization can get access to the insights that a moment so in this realm the first thing that we are doing is refreshed to bigquery UI and all of our customers have been asking for capabilities in in bigquery UI like multi-tab editing we are adding that so so it's now available for everyone to use it's a really great experience where you can write multiple different queries compare them but more importantly it not only write sequel for for bigquery you can also write dataflow sequel and create streaming pipelines with observe and dataflow and combination with bigquery so so it does allow you that that integrated experience it's a faster IDE and one of the other features I like is this autocomplete for for me so it can recommend or suggest what are the table or fields that I should be using and stuff like that so a lot of innovation and investment going in that space and the second thing I'm super excited about this feature which is connected sheets connected sheets is literally think about Google sheet in front of bigquery you can have petabyte scale data sets in bigquery you can use sheets to go ahead and create pivot tables charts are functions and custom calculations on top of the sheet and then all of that actually runs on half of Bitcoin so it's it's best of both worlds the great experience with great analytical engine I personally use this everyday I have a 29 plus billion row table I analyze data from that every day about a product usage what's working what's not working and also so really this makes data at scale accessible to all analysts who can use spreadsheets within your organization so really powerful tooling but with that we don't want to stop at analysts and and just a few folks in the organization you want to extend insights to everyone else in the organization with that we are announcing availability of data Q&A or data Q&A is natural language interface or bigquery you literally go ahead and ask a question get an answer it's as simple as that there is no setup required on top of bigquery for leveraging it you just enable an API and pick the table that we want the good and asked questions on and we just make it possible for you so you can just start leveraging it we also believe that no one interface is the right interface for for technology like this right I think now organizations want to build custom workflows and custom experiences on top of such technology so we do have the whole API available for for documentation where organizations can literally build their own experiences but from Google site we will be integrating it in Google sheets with connected sheets plus data Q&A now you have a very powerful experience we will be providing chat pod experience you will be working with a dialog flow and various other experiences that we can provide or directly including bigquery UI we'll have have a version of this all of this is actually built on on internal Google technology analyzer is a great paper that you can read more about it on but fundamentally this the same technology that powers Coogler assistant and various other services and products that we internally use analyzer gives us the ability to go ahead and do question parsing intent identification entity matching all of that comes because of Google's investment in this space of of natural language conversational understanding and we're just leveraging parts of that now we are on bigquery side making sure that that works really well with your custom data sets and and it can make it easy to go ahead and get started without doing that much of preparation and setup on your data sets let me switch gears talk about embedded machine learning one of the key values that we have in bigquery team is we want to bring computation to data not the other way round we don't like moving data copying data that's not the best way of running lots in analytics and so in the same realm 80% of time data scientists we are spending in data preparation according to some studies now we want to avoid that with with bigquery what you can do is just use two lines of sequel to create machine learning models you literally say create model model name of time X regression matrix factorization whatever you want and then give the input dataset and we will do everything for you on that we do internal hyper parameter tuning bkb take care of the whole whole system on the back when we launched couple of years back we only had regression and logistical and linear regression models from there we have come far far ahead we now support of k-means clustering matrix factorization in the I've seen lot of organizations use this in combination they do customer segmentation use in k-means clustering they do matrix factorization to find products that we should recommend to those segments and they basically done email campaigns and ad campaigns on it so very common pattern you can you can use use this or in addition we've also launched time series forecasting this is great for inventory optimizations and stuff like that so we see a lot of interest in in this model but in addition to that we have enabled bigquery ml to be the sequel interface for a lot of our capabilities in Floria so DN n classifiers energy boost and auto ml tables all are using cloudy I platform services in behind the scenes and and you still get the same consistent experience that you have but most importantly lot of our customers said to us hey all these models creating them easily and running batch workloads great but I would love to use these models in real time predictions how do we enable that and so we enable you to go ahead and export these models directly into tensor flow model and so you can export it a sense of remodel then hosted in any of the serving platform that supports transit which will be a mail engine queue flow there are various platforms available with that we recovered the democratizing insights especially data Q&A and connected sheets embedded machine learning the third area of innovation that we have spent significant amount of time is in real-time analytics as I already mentioned we have customers putting in like tens of millions of events per second if then bickering and just this year we rewrote our whole storage engine from like a batch first more to streaming mode so it's a streaming first storage system now and you can scale to any of your needs tens of millions of events per second is without any any problem the more important is none of your queries will get any have any impact on performance because of that ingestion rate so we can do tens of millions of events and give you the same query performance in the real time and that's coming the second thing is materialized views we know when you have lot of these data changes happening batch or in-stream you want to materialize your data set and views so that you can easily power the dashboards and reports that you may have all of this is automated and once you create a materialized view as the underlying data changes we persisted in the materialized view for you what that means is you don't have to worry about scheduling these you don't want to have to not have to worry about when was the last update me into the base table but nothing like that we will always keep it consistent and most important is query will be routing what that means is if you fire the query to bigquery and you created a materialized views later and you have this historical query we will automatically take that query our query parsing engine will realize that you have a new materialized view which can make the query run faster and we would automatically leverage that so that's there it's available in beta for you to use now a bi engine is another third investment in always fast on this fresh theme for us a bi engine we launched the BI engine nasty working within a studio so that we had an integrated experience you want to test the technology make sure it can scale to global means and all of that so I think that is there a provides your sub second latency query capability it automatically choose your queries as they come in and all but more importantly in this year we are going to extend that capability of BI engine which is our in-memory caching engine to all the queries in between so when the query comes in it will be able to leverage bigquery even from a standard bigquery interface in addition to that on your JDBC ODBC driver still supported and also all of our BI partners like tableau Nucor theissens Domo power bi all of them will be able to leverage the BI engine capability that we have you just pick what your size of cache prism everything will automatically work and then and also one of the other things will support a star schemas so that all your BI workers are taken care of extending that if you really think from a staff perspective you as customers today now have a choice you can decide whether you want low latency or you're okay with relatively higher latency and you can decide how much you want to use on the very hard data with caching with with bi engine or you just want to create materialized view which we will keep fresh all the time or you want to just use partition tables or just for the storage layer directly so all of this is a choice that you have but you write the query we will automatically first try it bi engine not their go-to but you realize you've not there for a partitioning and buffering if not go to the core storage however the data is stored so so that's the key thing that we have been working on you will always get the best performance and the best price so you can even pick and choose how what you care about with that we covered intelligence and and proven dependability let's switch gears and talk about open and flexible this is another big theme for us we'll cover like bigquery everywhere flexible pricing as well as data platform interoperability in this let's talk about bigquery bigquery everywhere we are introducing bigquery Omni what is the query on me as I earlier said we have this theory vision in in bigquery where we like to bring compute to data and not for customers have data not in GCP not with him have data in AWS s3 and maybe other other customers have in Asscher so with bigquery Omni available for AWS we will allow you to write queries and execute and do analysis on top of the data that's stored in s3 what does this mean we will literally run our compute engine of computation engine of bigquery in AWS closer to your data and what that means is you don't have to worry about paying for this egress charges or anything so you may have tens of to hundreds of petabytes of data in s3 you can start writing queries with the same interface in bigquery it was the same sequel dialect that we support as well as like you know and run it on AWS so so you'll be able to do do computation in that and and then get access to the results there are there are two or three different kinds of use cases that are becoming really prevalent in this a lot of our customers I do have split mode lot of our customers use bigquery and GCP as well as they have data in SP and AWS this is going to allow you have a single interface to analyze data across counts and as I said we will be bringing out the bigquery Omni for for Azure in coming quarters so so that will extend it to that platform too so so that's that's one the second use case that is becoming pretty prevalent is I have been talking to large customers who have tens to hundreds of petabytes in in s3 they don't use GCP today but they're intrigued with our capability is like the bigquery ml embedded machine learning capability and they want to use it and so in this case what we can do is we can enable those organizations to do data preparation summarizing the data identifying the key data sets that are there and then just move the data that you have to run a machine learning on to GCP on in bigquery and then those machine learning models do advanced analytics with it so so so those are the different kinds of you cases fear we have seen in the early adoption that we have seen we have learning as we go and we would love for you to the request access get access to this technology and and go innovate with you in the space with that let's talk about pricing so we talked about how big Cory has some of the largest use cases in the world but what's interesting is the query you probably also has some of the smallest use cases in the world and its really because we built our system to be scale-invariant and we build the right pricing options to support that kind of great end of scenarios so no matter where you are in terms of scale capability and requirements we're going to have the right pricing options for you so we do have a perpetual free tier where you get 10 gigabytes of storage for free and a whole terabyte of execution query execution query processing for free no strings attached and we have pay-as-you-go pressing which is service pricing incredibly efficient you don't have to think about anything but as you kind of graduate and and become bigger and bigger you start caring about additional capacity you start caring about price predictability so we have flex slots there and early season launched and then all the way out of the largest use cases you really care about efficiency you care about price predictability and you're working on these types of annual budgets we have flat rate pricing for you so wherever you are the queries gonna have the right pricing options for you and of course you're not just using bigquery typically our customers are running spark or close down a panda's data frame other types of execution engines and at the same time they keep their data in other places are Linda query storage right so whether it's my sequel Postgres cloud sequel it could be a potentially a big table it could be Google Drive and it could be open data lakes that Park and org so we provide interoperability with all of these layers so bigquery storage API and its ecosystem of open source connectors allow you to run spark pandas MapReduce and other open source workloads directly on top of the query storage at high levels of through and parallelism so it's as if you running these workloads directly on open storage directly on HDFS without sacrificing performance it's very unique differentiated capability of recording now if you want to leverage bigquery sequel and is but your data lives outside of the query we provide that capability right so cloud sequel Federation allows you to in real time access data in your relational databases from the query execution engine using you're familiar with equity sequel and of course we support a part a and org Federation which means that you can run bigquery right on top of your data links and finally your data may be living in these other service providers like stripe Marketo maybe have Google internal data sets to live within Adwords within YouTube and so on and so forth how do you get that data into data warehouse you can enrich it and you can join against your other relevant business data we provide we provide hundreds of connectors that are very very easy to configure very easy to set up and we take care of the rest like once your connection is set up we simply move that data into bigquery on your behalf and now you can do it advanced analytics on it and and this is just a subset or summary of all the different different capabilities that we're announcing you know there's not enough time in 30 minutes or 35 minutes for us to cover everything there is a lot of other sessions there are 30-plus sessions that are happening so that you should be able to get deep dives into all of these different topics as well as hear more about different aspects of the of the roadmap I do want to highlight one of the ESG studies bigquery is providing the lowest total cost of ownership for our customers across the globe I highly recommend looking at the study and then try and get query out and then finally we are the leaders in in all the different magic quadrants from Gartner as well as Forrester waves over last couple of years this one example but one of the things that I want to close today by telling you is when Cove in 19 hit I know the whole globe everybody's is s fighting the the new pandemic a lot of organizations came to us they wanted to get access to data and we were able to go ahead and make 20-plus datasets available globally accessible shareable in bigquery we were able to go ahead and make all the computation on top of that free until I think later part of the year the key thing is bigquery does provide us this platform that we can share data share insights with the globe not just within organizations and then that's really really a great great feeling from from the team's perspective are we want to thank you today for joining us and hearing what's new and bigquery thank you 