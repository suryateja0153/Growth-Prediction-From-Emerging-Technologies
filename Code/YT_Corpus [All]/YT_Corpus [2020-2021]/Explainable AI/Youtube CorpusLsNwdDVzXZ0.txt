 [MUSIC]  At EY, we fundamentally try to make the world a better working place, through trying to put AI and cloud at the forefront of digital transformations.  Our Trusted AI Platform is something that we've been building to help our clients really understand where the risks of AI are manifesting from.  Now, in the last couple of years, there's been a tremendous desire to use machine learning. [MUSIC]  Machine learning models are created by humans and also exposed to unfairness as a result. That can take the form of unfair treatment of individuals that are part of the protected groups, such as gender, race, income, age, etc.  We use Azure Machine Learning and the Fairlearn open source toolkit to support our efforts  on our Trusted AI Platform. And it's basically designed on different interrogations that we do of our clients' AI systems to better understand their risk profile and to manage those risks.  Fairlearn is a very, very cutting edge approach towards fairness, which actually ensures our approach and using it going forward for all our different projects where we talk about fairness.  Because it's open source, we are seeing the latest in a fairness algorithms and metrics within the tool. When we put Fairlearn to the test with real mortgage adjudication data, it improved the fairness of loan decisions. Before mitigation, the models had a disparity of seven percent between men and women. After mitigation, the disparity was less than 0.5 percent. Our data scientists and IT teams use MLOps to help accelerate their work while maintaining fairness levels. We monitored every step of the process using the MLOps capabilities and Azure Machine Learning.  Microsoft has been a real leader in recognizing the need for ethics and responsibility in regards to how we think about responsibility AI.  This is filling a real need of our clients. They're seeing more successful AI deployments, which is translated to greater trust in their AI systems and ultimately an acceleration in achieving their desired business outcomes. [MUSIC] 