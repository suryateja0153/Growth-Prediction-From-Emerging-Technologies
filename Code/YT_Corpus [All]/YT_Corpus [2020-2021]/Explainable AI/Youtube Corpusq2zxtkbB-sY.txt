 [Music] hello thanks for joining us for another insight tech talk i'm ken sear national practice lead for data aid insight i'm joined today by christina hines ai center of excellence lead and dr michael griffin lead data scientist with the growing impact of artificial intelligence on our everyday lives it is increasingly important that we use ai responsibly but defining what responsible ai use is and ensuring deployed ai remain responsible is the challenging task for many organizations christina can you talk a little bit about what responsible ai is sure um so if we think about ai as a mechanism for decision support it's a little bit easier for me to talk about it we all know that decisions have consequences so that means responsible ai is really about mitigating the risks of negative consequences in the decisions that we make at the highest level you know that means not intentionally using ai in a way that isn't in support of positive human outcomes most people don't fall into that category we all intend to do no harm so it's really about ensuring that we take care not to accidentally or unknowingly do that that can come in the form of privacy and security risks different types of data being leaked understanding how we're using the data what decisions are being made and why they're being made as well as really being sure not to have bias making sure that our models are diverse it's a really long checklist but at the end of it it's really just about ensuring that we know why we're making the decisions that we are and that those decisions the best of our ability aren't causing negative consequences we hear a lot about bias in artificial intelligence in the news mike could you tell us a little bit about how bias gets into a model and what kind of steps we might be able to take to remove bias from a model well i think it's important to understand that all ai models are biased because the data that's used to train ai is biased and there's just no getting around it i think what first it's important to acknowledge that and second it's important to understand where those biases are and in fact i think it's okay to have bias in your models because your your models serve a community and your community might be all white like me or it might be brown or it might be high income low income male female all kinds of different communities are served so you want your models to be biased toward the communities they serve right and what is the human impact of responsible ai so um i'll take the first shot mike and then you can have your turn um you know if we think about the severe impacts right the things like self-driving cars where we really want to understand the decisions the calculations that go into the decision to slow down or to stop right because because it matters it matters a great deal but even in lower risk scenarios there are still consequences for people deciding whether or not to grant someone credit is very consequential to them so we do need to understand what went into that decision and make sure that it's fair make sure that it's well thought out that it's reasoned um and you know having a human component to those decisions around the ai really helps to facilitate that yeah and i i think there the consequences of irresponsible ai are going to become bigger and bigger with time right now every one of us consumes ai to some extent we all have one of these in our pockets and those things are ai powered and um all of our web applications that we use are ai powered or for the most part they are and that and it's already everywhere and it will become even more everywhere right it'll be uh and it'll be also be more and more invisible to us we won't know when ai is impacting our lives so it's going to be largely a burden of the the developers and the distributors of ai not the consumers necessarily uh to develop responsible and deliver responsible ai and and and you can imagine you can imagine if it's used irresponsibly a lot of there could be a lot of negative social consequences sorry no that's okay i was just going to add to that you know there are more and more regulations these days about the right to know you know the right to know how your data is used and that plays a big role in responsible ais and going back to the explainability you know how is my information being used to make decisions that impact my life um so in addition to having a responsibility just ethically you know there are regulatory responsibilities that need to be factored in and i think that that's good many major organizations are right now lobbying for responsible ai and that includes explainable ai can you talk a little bit mike about why explainable ai is important right now well there are many reasons but i'll give you a real good example i work a lot in the health and life sciences space and we deliver clinical decision support to doctors and care providers and uh it will not ai will not be used in the clinical setting if it's not understood and for for very good reason right a doctor they go to school they have training they have many years of work behind them to understand how they make decisions and if they if they're presented with a possible decision they want to know from from an ai application they want to know why that ai application made that call why why they why this ai application predicts that this patient will get developed sepsis in the next 24 hours so they can do something about they're not just you know flying blind so we've talked a lot about what responsible ai is and its impact we know that it involves mediating or understanding the bias in your models in making sure that that model performs responsibly and safely in securing that model and the information that it generates in explaining how that model came to its conclusion can you talk about how you can help an organization go from beginning their ai journey to enabling consistent responsible ai uh yeah so you know there are more and more tools available to help with this problem thankfully right everything from evaluations of fairness and bias within models to um to to the explainability i think that starting with a policy that prioritizes responsibility and really defining what your values are as an organization is something that's really important you know and something that that we can definitely help with um and then putting some policies and processes around those values and that could be the implementation of a variety of tools and the decision to really understand not just what your models are deciding and when and why but also why are we using our models to begin with so starting with a good intent um starting with a good policy and then making sure that we're diligent and tracking over time not just when we implement but afterward what those decisions are are doing in the real world i think that's a good start and i think another thing that we can do and that we are doing with some of our clients is uh helping them to sort of automate responsible ai so ai applications don't make decisions for you they just provide you with some evidence that something might happen and you the subject matter expert has to make a decision based on that prediction and you and you might have to make hundreds or thousands of predictions a day and certainly a week or a year and what we can do is is provide a layer on top of that an optimization layer that allows you to set a goal a goal say i want to implement responsible ai i want to serve the my community as best as possible in a most beneficial way or i want to make the most amount of money or i want to you know provide the safest possible services i can all those things can be quantified and all of the decisions that you make can be uh optimized in such a way that they lead you to to achieve those goals and that's that i think is probably the the single most valuable thing we can do is because so many decisions need to be made and it's so easy to go wrong a little bit here a little bit there that real optimization can help you meet your goals in a responsible way over the over the long haul great thank you both for your insights today christina and michael you can find more information and insights for the future of our business in our digital magazine the tech journal read and subscribe at insight.com tech journal 