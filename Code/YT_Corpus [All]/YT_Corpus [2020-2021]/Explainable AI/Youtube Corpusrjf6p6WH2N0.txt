 Explainable AI is a series of techniques that are used to build trust in artificial intelligence products. Machine learning teaches algorithms how to learn without needing to program them for specific tasks. The problem is that many algorithms are known as black boxes, which means that their consumers and creators don't know which data points are interacting with each other when these algorithms learn and teach themselves new skills. And that's how AI products that are built on machine learning can produce biased results like denying someone a home loan based on their skin color. Explainable AI help prevent bias. It applies open source packages and toolkits to help people see how algorithms make decisions. So if businesses want to use machine learning for mortgage approvals, claims decisions, in other use cases involving their customers then black boxes aren't enough. They'll need to start building Explainable AI to help users see that their products are as fair, accurate and transparent as possible. 