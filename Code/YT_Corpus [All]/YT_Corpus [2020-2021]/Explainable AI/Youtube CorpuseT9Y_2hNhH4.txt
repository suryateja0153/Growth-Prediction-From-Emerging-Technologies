 How to do research at the MIT AI Lab.  Step 1, read this paper. Step 2,   see step 1. In all seriousness, I  found this paper on Twitter about a   month ago and I thought it was really  interesting. It was written by a   bunch of MIT grad students in 1988  and it was supposed to serve as a   guide for people who are new to both  the AI Lab as well as the larger   field for how to get into research  in AI, and how to catch up to the   field. It's something that I honestly  wish that I had access to when I   start getting into AI research,  because it has a lot of good advice.   So for those who don't know, my  PhD isn't actually in AI, it's in   medical engineering through a joint  Harvard MIT program. In fact, the   MIT AI Lab doesn't exist anymore.  It's now the Computer Science and   Artificial Intelligence Lab, or  CSAIL, as well as the MIT-IBM Watson   AI Lab. Having said that, I've been  programming since I was in high   school, and I started getting into  AI when I had the opportunity to do   research in machine learning for  radiology at Stanford during the   summer after my junior year. Since  then, I continue to use applied   machine learning for neural signal  processing and imaging throughout   my graduate work. This is all to  say that when compared to the field   as a whole, I would say that I'm  actually still pretty new to AI   research, especially since a  lot of my initial education was   self-taught. I've spent a lot of  my graduate studies focusing on   filling in the gaps in the material  that I never learned. I'm hoping   that makes my perspective more  valuable to you, because a lot of   people are now coming into the  field from a similar self-taught   background with not a ton of  guidance on how to get involved in   research. Also, if you're new to  this channel, hi I'm Jordan. I'm   fascinated by the ways that we  interact with AI and algorithms on   day-to-day basis. You can subscribe  to my channel to stay up-to-date   on all the interesting things that  are happening, and you can click   the "Like" button to let me know  that you enjoyed this video. So the   first half of this paper focuses  on practical skills that you might   want to develop, starting with reading  papers. Honestly, I wish I had   done more of this when I started  doing AI research, because I jumped   straight into tutorials to teach me  how to make the models, and didn't   actually read up on how the models  work. I think it's really important   to understand how and why models  are constructed, as well as how you   choose the right model, how you  choose the right optimizer, loss   function, etc. The only thing that  I would add to this section is that   I would personally recommend starting  with peer-reviewed research.   When this guide was published, sites  like arXiv, which are preprint   servers that publish articles  before they've been peer reviewed,   didn't exist. However in 2020, it's  basically assumed that all papers   in AI will go through arXiv before  they are formally published in a   journal or in a conference. That's  really good for both sharing   knowledge and getting feedback from  the larger community, but it could   also make it really difficult for  anyone who's newer to the field to   identify which papers are good, and  which papers are not so good. The   sheer number of papers uploaded  everyday is daunting, to say the   least. In fact, there's a funny line  on the second page of the guide   that says, "Since AI is still  a small field, you can read a   substantial fraction of the significant  papers in a couple of years."   Which was probably true in 1988.  Luckily, many people have cultivated   reading lists on peer-reviewed papers  for their field or subfield, so   you don't have to dive in with no  guidance. The next section focuses   on networking, including infiltrating  secret paper passing networks   where unpublished drafts are  circulated to others in the community,   which I think at this point is just  arXiv. The author also recommends   sending papers of interest to peers  in the field, whether it be people   in your lab or people that you met  at conferences. I definitely think   that this is a great idea, and also  applies to field outside of AI. I   know for my labs we often share  papers in Slack. In fact, we have   dedicated "Papers" channels where  you can just post papers that you   thought were interesting. Personally,  doing this helps me learn about   fields that are tangentially related  to my work that may have some   interesting insights or methods  that I can use, and that I wouldn't   otherwise encounter given the narrow  focus of my work. Of course, they   recommended attending conferences  and meet-up groups if you can, which   I absolutely recommend. However,  this has become increasingly   difficult for some of the big  conferences as attending can be   expensive, and many are placing  caps on the number of people that   they'll allow in. I was really  impressed that this guide also had a   section on diversifying your  research interests to include the   humanities, social sciences, philosophy,  and neuroscience in order to   get alternate perspectives on your  work, and I absolutely agree with   that. They don't discuss AI ethics  mostly because that wasn't a field   at the time, but obviously that  would be added to the list now in   2020. As someone who came from a  different scientific background, it's   definitely interesting to see how  my background informs the ways that   I design models. For example,  something that I think about a lot is   clinical use, and more broadly, use  by people who aren't me. There are   times when there's a trade-off  between making a model that performs   slightly better and making a model  that's more explainable, or that   performs better in clinical settings,  or that uses less resources than   I might have available to me so  that others with less resources can   use it too. Writing is definitely  an important skill, and it's   something that I'm still working on  when it comes to machine learning.   In fact, I had to submit a report  on a project that I did recently.   The hardest part of writing that  report was describing my data so that   other people who weren't familiar  with my work could understand what I   was doing. In particular, writing  so that another scientist can   understand and implement the work  that you did is something that we   can always stand to practice, as a  large part of the reproducibility   crisis in science isn't due to people  falsifying studies, it's due to   poor communication. Plus, writing  things down helps you keep track of   the list of things that you tried  to do, whether or not they worked,   and how you might've improved on  them over time. Next up is talks.   Talks are a combination of networking,  diversifying your interest, and   reading papers. In fact, I usually  try to go to one to two talks   outside of my field per week, just  to see what other people are doing   that might be interesting to me.  Plus, unlike when you read a paper at   a talk, your questions can be  answered in somewhat real time.   Interestingly, the last practical  skill development section is on   programming. A lot of this section  is a bit out of date. At the time   they used different programming  languages that aren't commonly used   now, and the entry level skills or  projects that you might try have   changed a bit. However, it does  still offer some good tips including   reading and understanding people's  code. At some point, you will have   to parse somebody else's code and  it will suck to varying levels,   depending on how well their code is  written. But it will help you get   better at reading other people's  code, and it will also help you write   better code yourself because you'll  see the places where you had   trouble understanding people. Be  sure not to do that when you publish   your own. Now this doesn't mean that  when you're initially developing   a model it needs to be pretty, mine  certainly are not. However, once   you're getting to the point of making  it available to the public, it   should be organized and written  in a way that other people can   reasonably understand. So the second  half of this guide is much more   focused on how to do research,  especially as a grad student. So a lot   of it wouldn't be useful to anyone  who isn't doing graduate studies.   If you're a grad student or a new  researcher, you might want to read   these sections more in depth. But in  the interest of hitting on points   that are more applicable to the  broader public, I'm going to breeze   through these sections a little  more quickly. The sections focus on   picking an advisor, writing a  thesis, doing research, and the   emotional labor of research. The  last section in particular is   interesting to me, because it can  be really hard to understand how   much of an emotional roller coaster  research can be without having   done it yourself. There's a comic  that often circulates through   academic circles that describes  what doing a PhD is like. But in   short, you're trying to make a  small dent in the vast expanse of   things that human beings don't  know, and that's really hard.   Experiments often don't work or  don't provide the results you   expected. You might spend months  working on an experiment, only to   realize that you were asking the  wrong question. In fact as an   undergrad, I spent three years working  on a project that consistently   failed for the first two years.  So as the authors mention in this   section, setting short and long-term  goals on the progress that you'd   like to make is important for both  maintaining your sanity, but also   documenting how far you've come.  I'm coming to the end of my second   year of my PhD right now. Initially,  I felt like I hadn't gotten   anything done. But as I looked over  my lab notebook and looked over my   code, I've realized that I've  done a lot more than I initially   realized. Plus, just as neuroscience  is a new field for me, AI might   be a new field for you so just catching  up to where the field is, is a   great accomplishment. That's how  you do your research at the MIT Al   Lab. Hopefully this was interesting  to you. These tips probably   translate to other fields outside  of machine learning, but obviously   also aren't the end-all be-all of  doing research. So if you have any   questions, let me know and I'll do  my best to answer them. Otherwise,   you can check out my video on my  journey through AI up here. You can   subscribe to my channel and let me  know that you like this video by   smashing the "Like" button down  here. If you'd like to learn more   about my PhD life, you can follow  me on Twitter and Instagram. Thanks   again to all of my patrons and I  will see you guys next Friday. Bye. 