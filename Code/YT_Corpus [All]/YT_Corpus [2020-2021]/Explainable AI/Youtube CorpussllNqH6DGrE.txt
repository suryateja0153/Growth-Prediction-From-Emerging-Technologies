 I'd like to especially thank the speakers both Pierre and Aaron and they came before me because I think they did some heavy lifting I hope that sitting through the that hour or so of content most of you are convinced that there's at least some role of AI and machine learning in doing this type of work so certainly I'll cover a little bit of that but more so what I want to focus on is sort of the practical nuts and bolts so if you have an idea and you see that in the literature it seems like it's something that can be solved what's the next step right how do I actually go and in start a project and build some of these tools right is it is it true that I need you know tens of millions of dollars with the hardware is it is it hopeless for me if I don't have all the infrastructure built and so I want to try to offer some of our experiences now let's see your clicker here perfect okay so I want to just start here now I'll go over some of the practical aspects throughout this talk but if you remember nothing else I would say the answer to that problem of how to get started can be remembered very succinctly with the fact that we do have a new Center here at UCI and with a vision essentially to provide the infrastructure and tools for all researchers on campus to actually get started in deep learning machine learning type of projects now if you haven't heard of us that's not entirely a surprise we've only been around for six months so we're brand new but that's part of the reason I'm here is to is to really give you guys a little bit of vision and a little bit of background as to what we can offer and I will say that this extends not just within the UCI family here certainly we have many projects with collaborators here but outside of the Irvine healthcare system across California and across the country we have dozens of collaborators so this invitation really extends to anyone out here in this room now in terms of the way that we've sort of developed and built this Center one of the key foundational principle Society of collaboration right so the bottom line is that there's almost an unlimited number of problems that can be solved with deep learning machine learning applications and certainly while we have some of those problems and a good understanding especially me as a radiologist I certainly don't have the domain expertise of the rest of you in this room who are vision experts were you know ophthalmologists and so the way that we're able to turn around and build 20 or 30 different 40 applications is by relying on you guys to come up with the questions right and and to come up with the data sets and to help us annotate and help us inject some of that domain expertise into the algorithm building process it's actually a part of the development process that I am I personally feel is extraordinarily important this idea of black boxes and you know machine learning algorithms that are completely trained without any human supervision right there's certainly some value there but I'll touch upon this again at the end I think it's absolutely critical that we build some that domain expertise into the algorithms and really kind of blend the the two types of approaches effectively now again I'm a radiologist so many of these tools that I will show our radiology based but the same principles as you've heard throughout the morning apply broadly to many different types of applications including ophthalmology and and the types of diagnostic tools you use all right so thank you very much just before I continue I want to highlight again this idea of translation right so our vision really is not only to build tools but to actually try to use the tools in the hospital here's an application that actually sends every head CT in the ER to an inference engine to look for brain bleeds in real-time you'll see that a new patient that scan in the emergency room is immediately interrogated by our AI system and in the case of a positive hemorrhage that notification is available to me as a user right away through the same interface I can actually open up the the raw images and scroll through the stack and indeed there is a bleed in the brain stem and similarly with a another click you can actually have the AI system identify the location of the hemorrhage and tell you the volume so again I know the theme today is is essentially bet bench-to-bedside so this is a very important part of what we do we don't want to just show a proof-of-concept tool and publish we we actually want to try to use these tools clinically all right so how do we get to somewhere like that well I think the first thing that you might take away from the talks earlier this morning is that if I have a data set in a project idea I should just hire a programmer and voila I've got an algorithm that that works right it sounds very very simple but in fact what happens is that if you set off on performing your first experiment in designing your first project you will encounter a number of infrastructure related problems that you don't necessarily anticipate starting out so unlike traditional types of projects where you might look at 20 or 30 patients in a small cohort we're looking at data sets now that are thousands if not tens of thousands of patients and the very simple task of storing that data or keeping it safe or annotating the data becomes exponentially more challenging so these are the different steps and we'll kind of talk about them but the other point I want to emphasize here is that although building this infrastructure is extraordinarily challenging and and takes a lot of time once it's built properly it can be shared by everybody right so if we have clean pipelines to get data to anonymize data and to create platforms for algorithm training the rest of it is just sort of reusable in every downstream steps so that's sort of what our Center provides this is what we want to to build and make available to the community here and and so let's go ahead and and go forward so the first thing of course as you'll see when you design one of these projects is that you need a lot of data now peer mention of course importantly that there are a lot of techniques to limit the amount of data that you and often times you can get by with smaller data sets but the reality is that most state-of-the-art algorithms are still extraordinarily data hungry all right these are a few of the internal data sets we've curated already in the past few months a lot of radiology data in fact we have a clean pipeline now to extract and use any data in our PACs archive and anything that's been digitized in the past decade so over half a petabyte worth of imaging data and similar systems are being built for our EMR so any patient that's in the epic system or any of the legacy systems prior to epoch and and then a lot of imaging data warehouse is outside of radiology so pathology we've worked very closely with I think ophthalmology is certainly a key player here and something we're very interested in actively building towards of course if you don't have a data set available internally there are a lot of public data sets that have been released these are some of the radiology ones but there are actually in fact a few very large ophthalmology data sets in diabetic retinopathy and some OCT imaging that you can use to get started just to get comfortable with the techniques and to explore some potential ideas that you have the next step after you've identified a problem and you've picked out the right data set and found your patients right is to actually go through and annotate this data in some way now again because of the scale of the problem because you may have 10,000 or 50,000 images to imitate you do have to be creative with the way you do this right if you have a unlimited army of medical students maybe if you get by with just manually annotating everything that you see but on a practical level we have to sometimes be a little more creative what we oftentimes do is use a combination of both weakly labeled data as well as a few strongly labeled examples as needed in other words we can take ground truth reports and apply a natural language processing to give an approximate ground truth and answer that is used to essentially train the first round of our algorithms it's actually okay if there error in that initial annotation process it turns out that deep flirting and machine learning tools are extraordinarily good at cutting through noise so as long as the general trend of the annotations is towards the underlying ground truth the AI are wooden will typically be able to pick out that pattern from there you actually assume that the the AI trade system may be more accurate than your annotation so you look for the discrepancies between the the reports the NLP generated annotations and the AI system and that's where we spend the the costly time of having humans and experts look at those images and in this sort of iterative bootstrap fashion you can quickly annotate very very large data sets now of course for a lot of problems it's useful not to just have global labels but to pick out the abnormality to either draw boxes or to highlight encircle the abnormality as we've seen in many examples today and for that system as well we've developed another in-house tool so a web-based application that's connected to our back-end so it's connected to every single one of the images that we have throughout all our databases and through one system multiple users across the campus across the United States really could login securely and help us annotate the data efficiently and so this iterative annotation part again is just highlighting the the need for the annotation and the machine learning specialists the kind of work hand-in-hand trying to come up with creative solutions to get the data annotated now when it comes to building the actual architecture you do need some specialized hardware I will take a slightly alternative perspective of Aaron in the sense that having 10 million dollars worth of machines is nice I absolutely would not argue against it in any way if you have those resources but the reality is you can actually get started with a relatively modest budget so if you understand what parts of the machine need to be upgraded and just focus all your your resources on those important key components things like GPU cards and network bandwidth you can actually put together a very reasonable and cost friendly solution our Center just starting out we have 20 GPUs all sort of this prosumer level card which you know it essentially maximizes the amount of return for a dollar and again we we put it together and hand build the system for you know just over fifty thousand dollars I will say that certainly when you're starting out and you want to build tools and you want to work together this system is available completely to any of our collaborators we set up web-based accounts get you into our system and if you're comfortable using Jupiter notebooks or other sort of web interfaces to do your development in the cloud we can set those up and provide those for you and then the last component here is is the portion where we actually try to build the tools and put them in clinical practice a couple of the key things here without going into too much technical detail is the fact that you typically need to build a separate parallel infrastructure behind the hospital firewall so our research servers essentially are a little bit less secure we assume that everything by the time it comes to us has been anonymized and cleaned and we take care of that but when you're dealing with patient data and you're using a tool that will potentially host patient sensitive information that typically needs to be built behind a separate system that we do have that system has specialized hardware to run these type of machine learning algorithms in real time and you know again without going to technical detail we essentially have a big environment where multiple algorithms all sort of live and once a study comes in that has the appropriate prerequisites you know it's this type of study of this organ system with this modality that will automatically trigger a particular AI system to come to life and run and provide those results back to the physician from the output side we have mostly web-based tools but certainly text messages pages even a mobile app that we have in development those are all options to put out any of the tools that are built and essentially developed through collaborations and then finally I would be of course remiss if I were to sort of highlight the things that our Center offers and of course ignore people so people are our most important valuable resource I would say that that we have the team that we put together certainly finding deep learning machine learning experts and putting them under one roof can be a very costly endeavor so we actually took mostly entry-level software engineers people with passion and and desire to work in medicine but maybe not a lot of AI background and I simply worked with them for for many months to sort of bring them up to speed in addition to nine full-time staff we have many visiting scholars graduate student researchers and undergrad as well as resident fellows which essentially really are the heart and soul of what we do and and allow us to execute on the many projects I would say another very important part of our mission is education broadly so not only outreach to undergrad in sort of grad school level students where this type of education is popular but actually into the medical school and into the residency programs this is a part of the curriculum that really doesn't exist yet currently but we feel strongly will be a very valuable asset even if you don't do ml or AI research we find that there's probably some basic level of confidence that everyone coming through the medical system should be able to at least appreciate what's there they should be able to look at a new paper that's published and sort of critically evaluate and understand what was done again even if they're not the ones that are are building these tools themselves so we have a curriculum that I teach to the medical students and then we try to host as many workshops and hackathons and things like that to really encourage discussion between computer scientists between physicians and experts to work together and do some of this work all right so that was a big overview again it highlights some of the things that you can think about whether it is whether you're actually coming in and working with us where if you want to build a similar type of system at your own home institution those are probably the important parts to consider now the speakers before me already did a fantastic job of highlighting what AI can do so I won't belabor this part of it too long but certainly I'll show some examples in radiology that might serve as sort of inspiration as you come up with your own ideas so what kind of things can we do in radiology well I would say one of the most popular and easy things to tackle is trying to find some abnormality to do simple detection and localization of an abnormality and bring that pathology to the attention of a radiologist this here is a tool to look for a clot in patients with stroke this particular type of clot in a very specific distribution can be treated immediately with surgery so rapid identification here is very valuable similarly you can detect cancers of the multiple types either on regular x-ray imaging or MRI and hemorrhage so that hemorrhage tool that you saw initially typically these are not findings that are very subtle or difficult for a trained expert to identify but clinically provide value because by automating that process you're introducing new paradigms that would really otherwise be very difficult to manage for example if I come in on a weekend in the ER I may have 30 or 40 patients waiting to have their images read a finding like this is not hard for me to see but still might take me one or two hours by the time I I come to that patient on a tool that immediately identifies positive findings and alerts me to read that image first again has a lot of clinical value in addition to identifying and detecting abnormalities the the fact that we can quantify an abnormality is very valuable as we saw in multiple examples again previously here we're quantifying the amounts of hemorrhage the same can be said to quantify and estimate the the volume of various tumors across the body here's an example with kidney cancer an addition to quantifying volume another thing that the AI systems are very adept at doing is essentially quantifying or objectively trying to evaluate some finding on a continuum this is an example in prostate cancer where humans try to assess the prostate cancer along several dimensions and assign a specific PI rat score based on the amount of darkness or the blurriness of edges this is something that AI systems can do very well it's a very objective problem I just simply need to put it along a continuum and we've shown that not only does the algorithm perform well it actually does so in a much more reproducible reliable fashion of course these examples extend far beyond just radiology images here's an example of looking at manometry tracing so pressure tracings along the course of the esophagus over time the the images are slightly different the problem is slightly different but fundamentally we have some sort of diagnostic data whether it's time series whether it's image and we're trying to map that particular data to a to a diagnosis the same has been done of course and also shown a few times a day in in pathology so in this particular example two examples one we have a tool that goes through and identifies various alzheimer of plaque morphologies another tool here on the left with the pink HD images is a tool for counting cells again not a particularly challenging task for a trained pathologist but the fact that you automate it means that I can now run this analysis over an entire digitized slide all right so not only look at high power few fields and tell us what they see but project that finding and across an entire sample and now we have a type of data a type of output that would otherwise a previously impossible and potentially yield other interesting diagnostic data and finally of course as we've seen many times today the use of optical coherence tomography and and other tools where you're essentially scanning through a very small structure you have at the output a very very large data set that may be tedious or difficult for a human to go through in in high detail this is certainly something that various AI algorithms and architectures can solve very very effectively all right and this is my last example so again I think Pierre flashed the slide earlier as well but this last category of tools now falls into the question of whether AI or machine learning tools can teach us as humans something so typically it's it's humans coming up with a label and saying hey I system please learn this mapping that I've told you but can the reverse also happen and in fact it's it can so this is a tool where in the first phase we trained an algorithm to go through brain MRIs and identify brain tumors as well as their underlying molecular mutation so just based on imaging predict what mutations that the tumors and so that's a classic machine learning problem very simple to solve but after we trained the algorithm we asked is there a way for the algorithm to tell us what it learned when you tell me it's idh wild-type or a 1p 19q Co deletion what is it that triggered that you know that diagnosis and in fact this we did the algorithm can't tell talk to us in English I can't you know communicate but it can show me prototypical examples so we went back reverse engineered the features and said what are the most common or the most prototypical examples of each of these mutations and on its own the algorithms able to generate what turns out to be an atlas of common findings and what was interesting here was that if you look through the literature you'll see case examples of a single or two experts coming up and saying after my 30 years of reading brain tumors I suspect that this is probably a pattern that's come up in the past right but typically these are just one-off patterns here and there if you go back and accumulate all of that literature and do a thorough review you'll find that it essentially comes out to these patterns at the AI system recognized so in fact something that's very powerful and interesting so with that I I do want to open the floor of questions before I do I think the the comments and questions that came up in the past two sessions one thing I noticed was this idea of explainable AI black boxes and when these tools will be ready for primetime clinical use and I'll give you my answer there I think that AI tools will be ready once we're confident that they can essentially replicate what humans do and importantly never make an error that humans would make so in other words with the way a lot of black box systems are designed even though it predicts with 98 99 percent accuracy it is possible that a single adversarial sticker or some little part of the the image that's noise can completely drive the algorithm to make a very unexpected prediction all right and so what that might mean is that a patient with a very large hemorrhage or a very large stroke randomly gets misclassified as the wrong thing I would argue that that's a unforgivable mistake something that if you ask 10 radiologists all ten would agree is egregious right by contrast if you inject a little bit of domain knowledge and expertise into your algorithms I think the idea of encapsulation that pierre brought up is absolutely on point so dividing the task up in creating endpoints that i as a human can now interact with and understand then the algorithm will only make mistakes that humans would also probably realistically make so maybe it looks at an area of artifact and high density caused by hardware and says I think there might be a small hemorrhage there and and I'm an expert and I look at it and say yeah you know what I think it's it's fine but I see I understand why you made that mistake you know it was it was high density that's kind of what blood looks like if you can ensure and in design a system to map to those type of findings to tell you what it sees and and think the way a human things then I think the the tools will be much more ready for primetime I think currently the fact that you can very easily trick it algorithm and you can occasionally find mistakes that don't make any sense I think that's what we need to avoid before these tools can be used so with that I like to thank you guys for your attention in open you I would say where we're discussing a lot of projects but right now I think the missing part is the infrastructure so I know at University of Washington what Aaron just showed I think that's a that's an amazing kind of infrastructure and system to have built I would say in many ways we should move towards building something similar I know there's a lot of the ophthalmology image and databases are built in a similar way to our PAC system so there's I pack sand things like that there's no reason that we can't be building parallel structures here in the Department of Ophthalmology so I would say you know this is my contact information and please reach out and let's let's try to build some of these types of things again right so I would say that that is that is a byproduct of the fact that the low-hanging fruit tend to come from images and things like that but that's not inherent limitation to the technology at all in any way so number one I would say one of the one of the biggest opportunities right now is trying to combine imaging data which is readily accessible and integrate it with non imaging demographic sort of background data it turns out that for machine learning tools it could be tricky but deep learning specifically makes it very easy so we can integrate patient treatment histories backgrounds and things like that as for prediction I would say again there's there's nothing inherently challenging about that prediction problem if you have the right data in radiology we had a big landmark paper recently where on PET imaging we were able to show that deep learning systems can predict the onset of Alzheimer's disease up to seven years before the patient showed symptoms that happened again to come from imaging but that's not you know that's not a limitation it's something that's very feasible if there's a signal if there's something there that essentially will lead to a downstream diagnosis if that pattern exists it's something that we can we can uncover so actually bill is I believe the next speaker and he will actually do some really nice demos similar to parotid we're inference from an AI system can happen so fast that it can be performed real time with with video frames right so again when you train a network it's very extraordinarily time-consuming and when you're building the network that initial architecture may be very large but when it comes to inference there's many creative things we can do to speed up the process right one is that you can compress models most of the weights that your model learns from it has been proven to not really add that much incremental benefit so you can just prune the neurons away and leave a very lightweight model to be to be used and again the actual hardware to drive it compared to trading where you might need many GPUs and lots of compute power the inference is very fast and very efficient so on in real time prediction you may need a GPU but oftentimes for something like cameras you don't even need a GPU you could you could run it on a CPU and and and have really no significant degradation in performance you 