 live from Las Vegas it's the cube covering AWS reinvent 2019 brought to you by Amazon Web Services and in care along with its ecosystem partners welcome back to the Sands Convention Center in Las Vegas everybody you walk to the cube the leader in live tech coverage my name is Steve Allante I'm here with my co-host Justin Warren this is day one of our coverage of AWS reinvent 2019 Naveen Rao is here he's the corporate vice president and general manager of artificial intelligence the out of a I products group that Intel good to see you again thanks for coming the cube really thanks for having me you're very welcome so what's going on with Intel and AI give us the big picture yeah I mean actually the very big picture is I think the world of computing is really shifting the the purpose of what a computer is made for is actually shifting and I think from his very conception you know from Alan Turing the machine was really meant to be something that recapitulated intelligence and we took sort of a divergent paths where we we built applications for productivity but now we're actually coming back to that original intent and I think that hits everything that Intel does because we're a computing company we supply computing to the world so everything we do is actually impacted by AI and will be in service of building better AI platforms for intelligence at the edge intelligence in the cloud and everything in between that's really come full circle I mean I mean when I first started this industry AI was the big hot topic and really Intel's ascendancy was around personal productivity but now we're seeing machines replacing cognitive functions new is that has implications to society but there's a whole new set of workloads that are emerging and that's driving presumably different requirements so what do you see is the sort of infrastructure requirements for those new workloads what's Intel's point of view on that well so let's focus that on the cloud first any kind of machine learning algorithm typically has two phases to it one is called training or learning where we're really iterating over large data sets to fit fit model parameters then once that's been done to a satisfaction of whatever performance metrics are that relevant to your application its rolled out and deployed that that phase is called inference and so these two are actually quite different in their requirements and that inference is all about the best performance for once how how much processing can I shove into a particular time and power budget on the training side it's much more about what kind of flexibility do I have for exploring different types of models and training them very very fast because when this field kind of started taking off in 2014 2013 - typically training a model back then would take a month or so those models now take minutes to Train and the models have grown substantially in size so we've still kind of gone back to a couple of weeks of training time so anything we can do to reduce that is very important and why the compression is that because it's just so much data and you're it's data and I act on it and yes it's data the sheer amount of data the complexity of data and the complexity of the models so a very broad or a rough categorization of the complexity can be the number of parameters in a model so back in 2013 there were Paola 10 million 20 million parameters which was very large for a machine learning model now they're in the billions one or two billion is sort of the state of the art to give you a bearings on that the human brain is about three to five hundred trillion models so we're still pretty far away from that so we got a long way to go so one of the things about these models is that once you've trained them that then they do things understanding how they work these are incredibly complex mathematical models so hey are we at a point where we're we just don't understand how these machines actually work or do we have a pretty good idea if no no when when this model is trying to do this thing this is how it behaves well it really depends on what you mean by how how much understanding we have so I'll say it one extreme we trust humans to do certain things and we don't really understand what's happening in their brain we trust that there's a process in place that you know but that has tested them enough like the neurosurgeons cutting into your head you say like you know what there's a system where that neurosurgeon probably had to go through a ton of training be tested over and over again and now we trust that he or she is doing the right thing I think the same thing is happening in na I some aspects we can we can bound and say I have analytical methods on how I can measure performance in other ways other places it's actually not so easy to measure the performance analytically we have to actually do it empirically which means we have datasets that we say does it stand up to all the different tests one area we're seeing that it is autonomous driving autonomous driving it's a bit of a black box and the amount of situations one can occur and incur on the road are almost limitless and so what we say is like for a 16 year old we say go out and drive and eventually you sort of learn it same thing is happening now for autonomous systems we have these training data sets where we say do you do the right thing in these scenarios and we say okay we trust that you'll probably do the right thing in the real world we know that the intial is partnered with AWS Iran autonomous driving with their deep racer project and I don't think it's on Thursday is the is the grand final it's been running for it let me I think it was announced on the cube last year and there's been a whole bunch of competitions running all year basically training models that run on this Intel chip inside a little model car that drives around a racetrack so you're speaking of empirical testing of whether or not it works like lap times gives you a pretty good good idea so what what have you learned from that experience of having all of these people go out and and learn how to use these these aoi models on a real live racecar and race around a track I think there's several things I mean one thing is when you turn loose and of developers on a competitive thing you you get really interesting results or people find creative ways to use the tools to try to win so I always love that process I think competition is how you how you push technology forward on the tool side it's actually more interesting to me is that you know we had to come up with something that was adequately simple so that a large number of people could get going on it quickly you can't have somebody who spends a year just getting the basic infrastructure to work so we had to put that in place and really I think that's still an iterative process we're still learning what what we can expose as knobs what what kind of areas of innovation we allow the user to explore and where we sort of lock it down to make it easy to use so I think that's the biggest learning we get from this is how I can deploy AI in the real world and what's really needed from a toolchain standpoint you talk more specifically about what you guys each bring to the table with your collaboration with AWS yeah AWS has been a great partner obviously AWS has a huge ecosystem of developers all kinds of different developers I mean web developers are once or developer database developers or another AI developers or yet another and we're kind of partnering together to to empower that AI base what we bring from a technological standpoint of course are the hardware my CPUs are AI ready now with a lot of software that we've been putting out in the open source and then other tools like open vino which make it very easy to start using AI models on our hardware and so we tie that in to the infrastructure that AWS is building for something like deep racer and then help build a community around an ecosystem around it of developers I'm gonna go back to the point you're making about the black box hey I mean people are concerned about that the concern about explain ability do you feel like that's a function of just the newness that that will eventually get over and I mean I could think of so many examples in my life where I can't really explain how I know something but I know it and I trust it do you feel like it's sort of you know a tempest in a teapot yeah I think there's depends of what you're talking about if you're talking about a you know the traceability of a financial transaction we kind of need that maybe for legal reasons so even for humans we do that you got to write down everything you did why did you do this why'd you do that so we actually want traceability for humans even in other places I think it is really about the newness I really trust this thing I don't know what it's doing trust comes with use after a while it becomes pretty straightforward I mean I think that's probably true for a cell phone I remember the first smart phones coming out in the early 2000s like I didn't trust how they worked I would never do a credit card transaction on them these kind of things now it's like take it for granted I've done it a million times and I never had any problems right yes it's the opposite of social media darlings analogy from from MIT louver which is we already have AI we're quite used to them they're called dogs we don't fully understand how a dog makes a decision and yet we use them every day that's all right you know in a collaboration with human so the dogs sort of replace a particular dog but then again they don't I don't particularly want to go and sniff things all day long so having having AI systems that can actually replace some of those jobs actually that's kind of great exactly and think about it like this which we can build systems that are tireless and we can you know basically give them more power and they keep going it's a big win for us and actually the dog analogy is great because I think at least my eventual goal as an AI researcher is to make the interface for intelligent agents be like a dog to train it like a dog reinforce it for the behaviors you want and you know keep pushing it new directions that way as opposed to having to write code that's kind of esoteric you talk about ganz what is ganz what's it stand for what does it mean general at a generative adversarial networks okay what this means is that you kind of think of it as two competing sides of solving a problem so if I'm trying to make a fake picture of you that I don't know makes you look like you have no hair or like like me you know you can see a Photoshop job and you can kind of tell all that's that's not so great so one side is trying to make the picture and the other side is trying to guess whether it's fake or not if you have two neural networks they're kind of working against each other once generating stuff the other ones saying is it fake or not and then eventually you keep improving each other this one tells that one no I can tell this one goes and tries something else this one says no I can still tell the one that's trying to do with a discerning network once it can't tell anymore you've kind of built something that's really good that's that's that's sort of the general principle here so we basically two things kind of fighting each other to get better and better at a particular task like deep fakes I use that because it is irrelevant it is race and that's kind of where it came from is from Ganz okay and so Wow obviously relevant with twenty20 coming up I want to ask you how far do you think we can take a two-part question how far can we take a I and near the midterm you don't start in our lifetimes and then how far should we take it some of those thoughts how far can we take it well I think you know we we often have the sci-fi narrative out there of you know building killer machines and this and that I don't know that that's actually going to happen anytime soon for several reasons one is we build machines for a purpose they don't come from an embattled evolutionary past like we do so their their motivations are a little bit different say so that that's one piece you know they're really Purpose Driven also building something that's as general as a human or a dog is very hard and we're not anywhere close to that when I talked about the trillions of parameters that a human brain has like we might be able to get close to that from a from an engineering standpoint but we're not really close to making those trillions of parameters work together in such a coherent way that a human brain does and efficient human brain does that in 20 Watts to do it today would be multiple megawatts so it's not really something that's easily found just laying around now how far should we take it I think I look at AI as a way to push humanity to the next level let me explain what that means a little bit simple equation I always sort of write down as like people are like Oh radiologists aren't gonna have a job no no what it means is one radiologist plus AI equals a hundred radiologists I can take that person's capabilities and scale it almost freely to millions of other people it basically increases accessibility of expertise we can scale expertise that's a good thing it makes solves problems like we have in healthcare today all right that's where we should be going well good example would be you know when and probably part of the answers today when will will machines make better diagnosis than than doctors I mean in some cases it probably exists today but not broadly but that's a good example right it is it's a tool though so I look at as more giving a human doctor more data to make a better decision on so what AI really does for us is it doesn't limit the amount of data on which we can make decisions as a human all I can do is read so much or hear so much or touch so much that's that's my limit of input if I have an AI system out there listening to billions of observations and actually presenting data in a form that I can make better decisions on that's a win it allows us to actually move science forward to move accessibility of technologies for so keeping the context of that time frame I said somebody in our lifetimes however you wanted to find it what do you think that that or do you think that driving your own car will become obsolete I don't know they don't ever be obsolete and I'm a little bit biased on this so I actually race cars it's like you and I drive a stick so professionally so it's like I don't want that to go away but it's the same thing like we don't need to drive ride horses anymore but we still do for fun so I don't think I'll completely go away now what I think what will happen is that commutes will be will be changed we will now use autonomous systems for that and I think you know five seven years from now we will have we will be using autonomy much more on prescribed routes it won't be that it completely replaces a human driver even in that timeframe because it's a very hard problem to solve in a completely general sense so it's going to be a kind of gentle evolution over the next twenty to thirty years do you think that that AI will change the Manufacturing pendulum and perhaps some of that would swing back to sort of in this country anyway onshore manufacturing yeah perhaps I mean I was in Taiwan a couple of months ago and you're actually seeing that already you're seeing things that you know maybe we're much more labor-intensive before because of economic constraints are becoming more mechanized using AI AI as inspection did this machine install this thing right so you have an inspector tool and you have an AI machine building it's a holder like again you can think of it right there so this is happening already and I think that's how that's that's one of the good parts of AI is that it takes away those sort of like you know harsh conditions that humans had to be in before to build devices do you think AI will eventually make large you know retail stores go away well I think as long as there are humans who who want immediate satisfaction some humans enjoy shopping about some people like browse depends how fast you need to give it and then my last AI you know question do you think banks well traditional banks will lose control of the payment systems as a result of things like machine intelligence yeah I do think there gonna be some significant shifts there we're already seeing you know many payment companies out there automate several aspects of this and reducing the friction of moving money moving money between people moving money between different types of assets like stocks and bitcoins and things like that and you know I think AI is it's a critical component that people don't see because it actually allows you to make sure that first your your doing a transaction that makes sense like when I move from this this currency to that one I have some sense of what's a real number it's much harder to defraud and that's a critical element to making these technologies work so you need AI to actually make that happen right all right we'll give you the last word just maybe you want to talk a little bit about what we can expect ai futures or anything else you'd like to share I think it's we're at we're at a really critical inflection point where we have something that works basically and we're gonna scale at scale at scale it to do to bring on new capabilities it's gonna be really expensive for the next few years but we're gonna then throw more engineering at it and start bringing it down so I start seeing this look a lot more like a Rane something where we can start having intelligence everywhere at you know various levels very low-power ubiquitous compute and in very high power computing in the cloud but bringing these intelligent capabilities everywhere these great gifts well thanks so much for coming on the qaq thank you for having me they're really welcome all right birthday everybody we'll be back with our next guest Dave Volante for Justin Warren you're watching the cube live from AWS reinvent 2019 be right back 