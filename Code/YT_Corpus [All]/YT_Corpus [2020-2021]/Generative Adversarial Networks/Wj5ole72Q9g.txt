 data science is one of the most popular domain but why it's getting the popularity and why all the companies are trying to use the data science consoles let me give you the example because all the companies are trying to use their data and getting the insights from them so they wants to use the data science technique to keep that in our mind we came up with the tutorial that is data science in 60 minutes before start that tutorial let me introduce that great learning has come up with a brilliant idea that is great learning academy where you will get almost 80 plus free courses and after complete your course you can claim your certificate as well and if you want to do this courses in your mobile application that is also possible using great learning apps [Music] okay get started my name is karthik i work for a company called latent view analytics my background has been on a lot on the data management side of things data warehousing business intelligence for many years i moved to kind of analytics i mean to latent view a year and a half back but i've been on analytics for probably three four years now right doing some hardcore advanced analytics machine learning kind of stuff um so what i would like to do today right i'm sure you guys would have heard a lot of thing i heard there was a logistic regression thing which happened in the time series forecasting i'm sure you're getting a lot of different inputs in in multiple ways right um and so in some sense that's really the i would say the problem with data science and machine learning and advanced analytics is that there are just a lot of moving parts a lot of different things that are happening right so what i'm going to talk to you today is more like a it's like a personal journey of sorts in terms of when you start getting a lot of this information right how do you really segregate it in some way so that you can navigate through this space right and i say a personal journey because i was terribly confused right you learn some stuff you learn specific algorithms and things like that but how do you kind of slot it in some way so that you can you can basically say okay i know this right and you also have a feel in terms of what you don't know right in terms of you know what you don't know right that's extremely important as you kind of move through the space because as i said it's fascinating in its own way because there are a lot of different applications a lot of different ways you can use it but unless you slot it in some way and i'm talking about the just the math part of the whole thing so we the focus of this discussion is going to be on the the techniques right the quantitative techniques we'll just touch upon all the other aspects of business and things like that a little bit but the core focus is going to be on the math and the algorithm part of it don't worry if you hear terms which you don't understand because jargons is part of life in almost every discipline and data science is no different right you heard a lot of jargons lot of different algorithm names and stuff like that but the real essence the takeaway that i want want you guys to take away from this session is essentially that you need to develop a personal map right in your own way as you go through this course and even beyond this course of saying these are all the different aspects of data science and machine learning advanced analytics whatever you want to call it and for certain types of problems certain things are applicable and what are some of the things that probably you need to gain more information on right that's essentially the the bottom line and what i'm going to discuss today is my own way of organizing the different areas within within this space right i'm going to divide it i've divided into kind of 10 plus one categories which i will discuss specifically on what those categories are but of course there is jargon there is there are things that you probably might not have heard heard about it earlier but don't worry about it that's really not the uh not the essence of the whole thing okay let's get started so the topic is navigating the data science world just a little bit preamble on why it is so fascinating interesting and why it makes sense for you to invest the time and energy to do to learn about different aspects of data science which in some sense is preaching to the choir because you guys have already as part of a course you have invested extra time and i mean you had the motivation to come and listen to somebody speaker in some sense you guys are already interested in this area but the bottom line is it is a fascinating area because the amount of data is increasing and that's an inevitable truth right and why is it increasing it's basically because the number of transactions are exponentially growing the lot of interactions that are happening the social media the reviews on e-commerce websites and all the lot of interactions and the other big chunk is observations right sensors kind of giving out a whole lot of data on almost every single machine that is being replaced is instrumented with a sensor which collects a lot of information right and we are seeing all this in our daily lives in terms of how there is really data sloshing all over the place within enterprises and outside of enterprises and somebody has to make sense of all this data for you to drive business decisions or society related decisions as such right governmental decisions and stuff so it is accelerating a digital shift which we all experiencing in our own way and ultimately there is a data dilution there are different types of data and i am not talking just structured data we are talking unstructured data semi-structured data all different types of data that's basically uh are out there but interestingly what's happening is of course there is it's unlocking a whole lot of newer use cases so this is again from the vantage point of a latent view right we see a lot of different companies using data in many different ways an automobile company trying to use sensor data to detect driving patterns right once you detect driving patterns you can have better warranty claims right there are companies out there which are trying to use social data to identify trends in the marketplace right cpg companies fashion trends because there's so much of information that is out there in the social space there are companies trying to use uh they've been using uh structured data like say uh movie companies trying to do box office forecasting right they've been doing it for quite a while but now with extra data coming in from social space they can back they can do better forecasting right so there are multiple use cases happening across the space customer intelligence uh marketing intelligence sales intentions supply chain supply chain is a classic case of uh people instrumenting their assembly lines getting all that data and trying to figure out can i predict something in the assembly line right can i predict when a failure could happen can i predict whether this assembly line throughput will reduce right so that i can take decisions accordingly and that's for real so i can assure you that these are things you might have again seen it in your own work life but if you haven't take it from me that these are these are problems solved by organizations and they're only scratching the surface at this point in time right and the interesting thing i am coming to is the fact that yes there are always a need for using data to solve business problems and all that but now there is an increase in technology power which is actually making it possible right you guys might have heard of this whole neural networks thing which started in 90s kind of it just trailed off right because there's not enough computing power or artificial intelligence if you take if you if you want to look at uh some of this is fascinating right so stochastic optimization which is the basis for many of these machine learning algorithms is a 1953 paper it's an eight page paper which everybody goes back and refers they want to really look at optimization so it's not these ideas are not new it is just that now you have the ability to implement it in a practical context why because of the cloud because of big data because of the whole sophistication of algorithms and the tech power that is coming in so new use cases the tech power all coming together helping to solve different kinds of business problems and the digital shift and the data deluge is a fundamental change right so it is worth investing the time to learn all this because it's a journey right every each one of you are trying to invest time and moving in this direction i think it's well worth it right that's the idea of this slide right so what does it take to provide actionable analytics the way we see it at a very high level is about bringing these four elements together every single problem that you will try and solve in analytics essentially is a combination of four things at the end of the day right the sophistication might be higher lower proportions might vary but it is all about bringing business data math and technology together right just i'll just repeat this the business part is about understanding what is the business impact right of doing something with data of of kind of running this algorithm or trying to implement a certain statistical technique there's a data part of it structured unstructured semi-structured data how do i understand it right how do i make sense out of it how do i explore it visualize it right then there's a math part of it in terms of what are the quantitative techniques that are applicable for a certain problem does it make sense to apply that technique because at the end of the day there's no business impact nobody wants to develop a big complex neural network right why should you do that or for that matter implement a logistic regression if it's not going to yield the business benefits but the fact of the matter is there is a lot of cases where applying such techniques is going to give you much better results right so bring in the math part of it and of course there is a technology angle in the sense at the end of the day all this has to get delivered through a to a technology platform right be it a web interface mobile application right embedded in in classical erp type of applications right so all these but technology plays a big role in terms of getting all this to the end user right and we also again have experienced this in multiple ways when you order from swiggy right there is an analytic thing that's going behind the scenes but it all gets delivered in a very nice seamless way on your mobile device you look at a recommendation system on a flipkart or an amazon that's same thing that's happening there's a very complex recommended system that's running but at the end of the day it presents you a very nice way of saying if you bought this you might be interested in buying this also so technology is also fairly critical at the end of the day if you bring all these things together in the proper way the appropriate manner you're going to deliver good actionable insights for organizations right so that's the bottom line i will not go into the details here but a quick look at if you look at the business part of it use case formulation becomes very important right what kind of use cases are there in terms of for data driven decision making you're talking about now yes you have run an algorithm you've got an output how do you really interpret it in a business context right it's not the business is really not interested in your auc metric or an r squared metric at the end of the day they are saying with this metric what are you helping me lower cost increase revenue increase customer satisfaction right so how do you interpret the output of your data science pipeline into a business decision making pipeline right so that's what the whole interpretability aspect of it is all about and of course domain expertise in specific cases uh data data acquisition how do you acquire the data right data exploration visualization right and data pre-processing math and the quant part of it is understand algorithms at an intuitive level what does it do right select the right techniques for the right kind of problems and evaluating the output of algorithms right by now you must have realized running the algorithm is no big deal right it's just one line of code in a python or r and in many cases it's a gui interface also but really understanding what the output of that particular algorithm is and trying to compare right using cross validation and different other other different techniques it what what makes the algorithm powerful so evaluating is extremely important the tech part of it is about understanding the ide ecosystem uh data engineering and architecture how do you create data is somewhere there algorithm is here how do you kind of bring these two together in a more seamless way because something will require real time processing something is batch oriented uh thing is is fine right some something will require so much of data that you need a big data infrastructure right you need to scale on the cloud so there are many different aspects to building the data pipeline right and of course software engineering is dlc and i see a lot of people from the i.t world so that way you will understand the software engineering principles there's dlc how do you run a project how do you test verify validate all those are very important things even from even from an analytic standpoint right so with that so this is a mind map that i have created right so it is available free on the web you can take a look at it at your convenience but this will give you a complete perspective of what are all the different areas within when people say analytics right there's a business aspect to it there's a complete data so i i do cover data management reporting etcetera because i've kind of lived that world for a long time but the focus of this talk and one which makes the whole data science very interesting is the quantitative techniques what kind of math related techniques are going to apply on data and why right that is that is the most that's a secret source in some sense and that's extremely interesting so we'll focus on that so that is also covered so for and where this kind of a map helps you is to fit it into a context so if you know okay there is this deep learning somebody is talking about as convolutional neural network you might not know the underlying techniques behind it but if you can search for this in the map at least it will you will know where it kind of fits in it fits into this space this area and this is what it's going to be used for that is where you start and then depending on whether you get that opportunity your work life or your own interest you can start delving into the details right so i'll leave that thought with you but this is a resource that's available on the web uh it's it's just a mind map right you can keep clicking and then figuring out you can also search for specific terms and things like that okay we'll come back to this i'll probably show you this towards the end okay so what's the real problem okay it's great that there's a digital shift a lot of problems getting solved and things like that you guys are learning some of these techniques so what's the real problem with the quantitative side of data science the real problem to me is this there are just too many things right there are just so many different techniques and every day some new things keep coming up right and it's not just structured data is unstructured data semi-structured so i mean how do you make sense of all this world because you still have to navigate through this at the end of the day when you're in you're in the when you're in a position where you'll have to apply an analytical technique right you would probably be given a problem statement right uh you'll have probably tons of data correct now how do you go from there to really say for this problem these are some of the options that you have in terms of applying that these are some five techniques that are possible here and then how do you go from that really say this technique is what makes sense and not only that once you apply the technique you need to interpret the output in a business context so it's not a trivial job right if you really take that whole pipeline it's not a trivial job to really go from just a problems maintenance statement and data all the way up to a business impact kind of a situation so how do you navigate through this space is what the focus is going to be and the way i found out to be the easiest way to do it is to just divide into categories right so in my mind there are 10 plus 1 i say 10 plus 1 for a certain reason right so so i said okay how do i how do i make sense of this right and there is a certain flow that i kind of thought about it this is again my own personal way of thinking about it some of it could resonate with you it might be applicable from your context also but i'll just explain how what the flow is at the end of the day every slide is going to have these two parts on the left side is the navigation right what are all the decision variables at the end of the and at the end of that is basically that category okay and we'll try and debate a little bit on that category on the right side are some of the details around it so that's where the jargon will probably come in about the different techniques and stuff like that again don't worry too much about it but it's good to know right okay so and the navigation if you understand one it it's very similar in the other things also so i'll spend a little bit more time on the first slide and i'll kind of rush through the other slides right or go a little faster so the first question right which is important to ask yourself when you're faced with a data science problem is is the focus on the process or on the data right this is a question that many people skip and what i mean by that is in a classical machine learning sense what happens if you're handed a data set correct and said here is the data forget about the data generation process it doesn't matter to you in some sense here is the data kind of go ahead and do all the things with data correct so the focus on such an analysis is really on the data correct but there are many different problems where the focus is on the process which means what is that process that generated that data correct now as part of this talk i will not spend too much time on the process part of it i have one slide towards the end that talks about process mining and stuff like that but i feel it's very important to ask this question because for example if the whole problem is about understanding the bottlenecks in a process right machine learning can't answer it for you correct if the question is about what is the golden path in the process how are people deviating from the norm or or from the actual process which has to get implemented there is no way machine learn logistic regression neural networks can't answer that question so if the focus is on the process you need a different kind of technique right but we will start with the focus is on data okay the focus is on data which is what bulk of the slides will be again there are a whole range of techniques that are there then the second question that you ask yourself is what is the type of data right and the good thing there is there are only three fundamental types of data right and i'm saying type of data from a from a more structure rather than from all the ratio ordinal data interval data which you guys might have might have learned this is about is a structured data is it semi-structured data is it unstructured data correct structured data is very easy for all of us to understand because many of us have dealt with tables right in databases and things like that rows columns clear data types you know by looking at that column you know what data type it is you know the type of data everything is wonderfully organized you have metadata for those columns so you you kind of by looking at it you understand what the data actually means at some level what is what is that so that's structured data it is what bulk of those it systems have have uh have really accumulated and stored correct now unstructured is also easy for us to understand though we haven't dealt with it in a probably an organizational context right some of you might have if you worked in content management systems and all that but most of you might not and so unstructured data is also fairly easy to understand it's about images text where there's no structure to data you really can't put it into a schema and things like that and clearly define what this is unless other than saying that this is a mass of it's a wall of text right or it's a bunch of images or it is audio file speech files it does not have structure to it at the start at the start of course you need to translate it to some structure over a period of time but when you're getting that data it's all unstructured correct semi-structured is a little confusing can anybody tell me what semi-structured data is and in your experience if you come across some semi-structured data even an excel sheet in some sense is i would say semi-structured data right because you still have to infer the column by looking at the column names right i mean there is no you'll have to understand what the data type is by looking at those column names and figuring out what the whole thing is so semi-structured data is something like you have the ability to get to that structure but it's not straightforward right there is some clue as to the structure of the data but you still need to put some kind of a thought to understand what the data type is can i interpret it as a date or an integer or a float right so it's not strictly defined right and why it becomes semi-structured data is becoming a lot more interesting is because of all the all the iot stuff that's coming in right any sensor data that is coming to you is in some sense semi-structured right it will have a decent structure to it but then you still have to discern that structure by looking at for example there was a project that we did for our automobile company the car said the sensor data that's coming in from the cars right uh so essentially the the sensor captures everything about how the car was driven right the pedal position acceleration engine temperature oil temperature ignition when was it on all kinds of stuff it's all present there right it's so it's a there's a series of vectors there is there is a scalar variable and all that but we're just looking at the data you won't know what it is you don't know what the first column is how is pedal position what are those 10 numbers right up front nobody knows you need to have certain level of expertise here in this case you talk to a domain expert to say okay how does it really capture right and the moment somebody gives you that clue you say okay the first 10 numbers mean the pedal position the second five numbers mean the engine temperature right you can get to the structure but it needs a certain level of processing right and iot devices everything emits on semi-structured data so you need to have a figure a way out figure a way in terms of figure out a way in terms of getting to that structure right okay so i spent quite a bit of time and so okay next what is the volume of data i think volume of data plays a big role right so for now i'm saying at least for the purpose of this slide just for our understanding we are saying it's not web scale data right we are not talking about a google or a facebook we are talking about probably the gigabytes terabytes range right so i am not talking really web scale data okay i'll again i have a category which talks about web scale so your focus is on data we're talking about structured data in this particular case it is not web scale data then you ask a question it's a time series data right i i guess you guys have done a time series forecasting uh class right and why i'm saying time series not time series because the kind of techniques that you apply is again quite different creating a data set if it is a time series as a non-time series and trying to apply it will just give you garbage right as simple as randomizing right you can't randomize your data set because there is a there is a pattern there is a time component or a temporal component to it correct so assuming that it is not time series so the answer that question is no it's not time series data then the next question you ask yourself does it have a label or a dependent variable right the moment you say yes it has a dependent variable then you're coming to the first category which is probably the most simplest and in fact a lot of applications of this category i say simplest not in the not in the sense of belittling it there's still a lot of applications but this is this is one area which is fairly well understood right which is machine learning supervised machine learning on structured data all of you understand this the supervised machine learning on the structured data part of it which is and the moment the next question that you ask yourself is is the dependent variable continuous or categorical correct if it is continuous you are talking regression if it is categorical you are talking logistic regression classification logistic regression being an implementation of it correct so i'll just quickly go through this once fairly simple thing but if you keep this in mind i think it makes a lot of things easier when you get to the other categories so the focus is on data then you ask yourself a question what type of data you're saying it's structured data then you're coming down to saying okay is it web scale probably not web scale at this point in time is a time series the answer to that is no so it's not a time series data then you ask yourself the question is it does it have a label or a dependent variable the answer is an s and then you ask yourself is that dependent variable a categorical or a continuous variable if it's continuous you go the path of regression techniques if it's categorical you go through the path of the classification techniques correct so this is category one for you category one might appear straightforward but still there is a lot of different nuances towards how do you address this problem again some of some of this you might have already come come across and all that so how do you do exploratory data analysis that is an area by itself right how do you look at the data how do you organize your data and the whole thing about data pre-processing outlier identification how do you treat missing data because one of the biggest thing with all these different techniques is it is it is a situation where you put garbage in you will get some fantastic you are probably better off not implementing data science and machine learning in some cases right because your gut decision probably might be much better but if you feed in the right kind of the right kind of data and the algorithms can actually get the signals in that data you can get some fantastic results so data pre-processing talks about outliers missing data variable transformations right then there's a whole aspect of feature selection dimensionality reduction okay so essentially i'll give you a quick thing obviously people will talk to you about more in detail so the whole idea behind ensembles is that you are not just getting so if you look at a logistic regression right and what is called as a parametric algorithm right logistic regression has a linear thing to it right and then you basically the whole idea of logistic regression is to estimate the parameters by looking at the observed data you basically estimate your different coefficients or the different weights right to the individual features correct and so the mathematical equation is set correct uh you don't you're not really uh you don't have the liberty of looking at the whole hypothesis phase but your equation is kind of set up easier example would be a linear regression right y equals your whatever b 0 v 1 x 1 b 2 x 2 and then all you are doing as part of the whole thing is figuring out what does b 0 b 1 b 2s are correct so that's linear regression logistic regression is similar and so you have some of these parametric algorithms ensembles is about bringing multiple things together so you have a decision tree which is an individual algorithm you kind of build multiple trees to estimate the output right and that is basically becomes a random forest right of course i am talking at a very high level there are nuances to it on how you really combine the trees what you look for and things like that but the whole idea of ensembles is you take multiple weak learners you combine them together it makes for a very strong learner okay so backing up about combining multiple algorithms boosting there is a different technique but the essence is very similar right take multiple things together each one predicts something and then you kind of combine all that together give your final predictions okay those are the ensembles uh parametric non-parametric i just spoke about algorithms can be linear non-linear type of algorithms right cross validation right is extremely important in terms of evaluating the output then hyper parameter tuning do you guys know what hyper parameter tuning is so every algorithm right has parameters associated with it correct so it will be the number of trees in a decision tree that's one parameter right how do you know how many trees to build right is it 10 trees 25 trees 50 trees 100 trees right and similarly if you look at some of the random forest there'll be like 25 different knobs that you can actually adjust right to get you great performance so hyper parameter tuning is is a way by which you can actually get to the best parameters for that particular problem right so what people do is they do a search and say okay i will take the different parameters put them in a grid and then try and solve the problem and see whether i get better results right and once it gives the best result is the parameter that i want to go with right so there is a there are ways by which you can actually get to the actual parameter that will give you the best performance right that's what is called as hyper parameter tuning and of course at the end of the day you predict on the test set you have a model that is built right on your training data correct you cross validated you have looked at either ensemble standalone all that you have done at the end of the day you have to predict this on use this to predict on test data right so have you guys done something in terms of training a model predicting it on a test data set and all that okay so there are some interesting things there i mean it might look a little simple but as simple as let's say you there is a there's missing data in a column right and you apply the mean to basically on the training data set to say okay i'm basically for all the missing data i'm going to fill it with the mean or the median you guys must have done it correct now if you have to apply this model on the on the test data you can't again do a mean computation on the test data correct you will have to take this mean which is done on the training data and apply that correct mean is a very simple example but if you use one hot encoding and more complex things on your training data you need to do the same thing on your test data you cannot do it afresh on the test data these are nuances which are extremely important again the moment you do it on the test data separately you're not going to get the right results right category 2 is the focus is still on data the type of data is structured it's not not web scale not time series it does not have a dependent variable so you guys know what the category is sorry unsupervised machine learning on structured data right with its own set of specific techniques right clustering is something that you would have heard you have probably even done it k means clustering hierarchical clustering but it will be interesting for you to know there are probably another 25 different ways you can cluster data right fairly sophisticated ways of doing clustering and identifying patterns in your data right but the bottom line is your dev you're creating so you're not predicting anything you're just understanding the structure in your data correct anomaly detection that's one of the uh i mean we get a lot of things around especially with respect to sensor data and all that coming in detect anomalies right so the techniques by which you can actually take all the data have algorithms like isolation forest and things like that which will help you to detect anomalies in data right a recommended recommendation systems i mean that's an area on its own but again track on in our daily life we have come across many recommended systems and there are many different techniques right item collaborative filtering so probably it makes sense for you to quickly look at some outside resources because it's a fascinating area in terms of how do you do recommendations right how do you look at user user similarity how do you look at item item similarity right and then how do you kind of correlate one over the other and give appropriate recommendations to people and it's a great area by itself right we spoke about the dimensionality reduction like pca pca you must have all heard have you heard of t-sne p-sne is again a very nice way of reducing dimensionality and you can get it in a very visual context very high dimensional data you can get it into a into a more interpretable visual context right that's decent uh so this is unsupervised machine learning on structured data so explorative analysis is still important you need to understand the structure within your data a clustering key means hierarchical many others anomaly detection is isolation forest loft what the expansion is recommenders content based collaborative filtering uh hybrids uh there is another thing called self organizing map songs right which is basically a little more advanced way of doing clustering right and also identifying outliers right okay so let's move to the third category right by now you must have guessed the whole logic right focuses on data type of data structured not web scale yes it is a time series right the moment you come to time series your classical things might not work right or it will not work in the same way as you used to do for a uh used to do for a linear regression or logistic regression even for an ensemble scenario right and typically time series has a label associated with it right you're predicting something more often than not it's a continuous variable and why time series is extremely uh interesting important from a from a business context is that's probably the first problem which will be posed by any company can i forecast demand right can i forecast sales because once i forecast things better and forecasting is not new forecasting has been done by people for many years right so when we work with companies what happens typically is they say we already are having forecast okay we've been doing it 25 years some models has been running for a long time typically it's developed in sas mostly but they are not getting accurate forecasts they are not getting granular forecast right because the techniques have changed drastically from what used to happen whatever 15 20 10 years back right so there's always a requirement for companies to do better forecasting in multiple different things if you really look at it forecasting is something that it's very wide right sales forecasting is one part of it you can do employee related forecasting you can do infrastructure forecasting right so the thing that we do for facebook right is basically about i.t infrastructure forecasting right they need to know how many laptops they need how many servers they need right for them to plan the whole thing appropriately that's a classic forecasting and it's a fairly complex problem you're looking at demand you're looking at supply you are matching the two right so so there are specific techniques and good that you guys have gone through a time series forecasting thing but personally to me i find time series forecasting to be the most difficult in some sense right because it might appear to be very straightforward but at the end of the day you never get good forecast for some reason it's probably just me but so and there are specific fundamentals so to say of understanding a time series before you can start modeling on top of it so in your course again you must have heard about stationary and non-stationary time series you guys have gone through that right so that took quite a while for me to understand right um how do you stationarize a time series why is it important and things like that what are the techniques by which you could do that right how do you decompose a time series look at your trend look at your levels right look at the noise what is called as white noise and things like that and how do you do auto correlation plots acf pacf how do you detect the differencing all that are very interesting techniques which you will not find in a typical supervised machine learning problem correct uh of course feature engineering is also it's very interesting in a time series scenario on how much of moving averages and lags that you want to calculate right in order to get better forecast right and building time series forecasting models the classical way of doing it is arima or hold winters and things like that but more recently there are a lot of deep learning techniques that are coming in right so for example something called recurrent neural networks right now gives you probably the best results when it comes to time series forecasting it's a deep learning model it has a it has it is used for sequence prediction problems typically and time series is nothing but a sequence prediction problem right you have a sequence you're trying to predict the next sequence right it might be for 12 months or the most immediate data point whatever that might be but you are still predicting a sequence yeah so that's basically so what i also have i'll finally i'll probably show it towards the end is for each of these categories i have some sample illustrative code of course it's written in python because that's what i'm comfortable with it's it's part of my github repository right not probably the best possible code but it'll give you an idea if you want to get started in an area right how do you really get started there could be some template code which i will show you towards the end okay so and that code which i'm going to which is there in my github basically uses arima based time series forecasting right category four is focuses on data but now the data is unstructured right and i'm kind of bucketing semi-structured i mean semi-structured under the structured thing so i don't have a separate category for it because there's one extra step to make it structured but the real big difference is unstructured data the moment you say unstructured data you're talking text and things like that volume of data probably not web scale at this point in time has label dependent variables now if the answer is yes then you are talking about supervised machine learning on unstructured data right the most simplest classical use case is spam detection right how do you detect spam in emails right there is text so you need to you need to understand the text structure the text right but the end of the day you are still predicting whether that email is as a spam or a ham correct that's the easiest example but something like sentiment analysis image classification all that falls into the whole supervised machine learning on the unstructured data space right ah type of unstructured data it gets very interesting here because depending on the type of unstructured data there are different techniques again right different type or category of technique so if it is text it's all about natural language processing right have you guys done anything on text analytics natural language processing you've done it okay you do it as part of your daily job is it as part of your work okay i mean you would appreciate the the amount of uh one it's extremely interesting and right now we're just catching the surface of the whole thing correct we probably use a bag of birds model you take the terms vectorize it and you basically use it for models but there are very sophisticated techniques that are out there correct we'll talk about that a little bit again it might appear as jargon if you haven't done text analytics nlp but it's it's good to know if you're talking about images now you're talking a bunch of images if you if you look at kaggle and things like that a lot of competitions now is about image classification correct i think there's a recent one where that was actually a sound thing using the sound that is emitted can you detect a whale or not right that was i think one of the recent things but there have been many can you from the pictures can you detect cats and dogs is a classic learning problem in kaggle but images is becoming very very big nowadays right even in a business context because nobody's even touched those images but now people are starting to think if i can actually get interesting insights from images now the world is anyway i mean we keep clicking so many photographs so many things and there are so many pictures on your mobile phone just imagine for an organization there are just so many images that are there one problem that we are working on just to kind of motivate you in this direction is so we walk up pepsi and the assembly line the sensor basically takes a lot of photographs right and then what they really want to do is using the photographs can you detect defects right bunch of photographs and they actually have have labels associated with says defects not defects and then once you train your cnn or your convolutional neural network for the new images coming can you detect an image or not can you detect a defect or not right now you can expand it in multiple different ways in your own uh in your own customer situation in your own whatever you're working on i think it'll be good to figure out whether there is text that is involved can i do things better or can i can i get some insights out of text images if you're dealing in some way with images and stuff like that probably there is a there's a wealth of information out there right uh and and if it's so in terms of types of unstructured data we spoke about text and images in a kind of a standalone manner but speech is text having a temporal nature right or there's a there is a sequence associated with it right audio speech videos for example videos is nothing but images in a sequence correct and for that there are different techniques and the the state of the art is something called record and neural networks are r and ns right which is useful for sequence prediction so this category is all about uh this category is all about you're still doing supervised machine learning so all those other techniques still apply but you need to figure out a way to take all this unstructured data convert it in some way to a structural form and then start applying the different techniques on top of it right uh so nlp is probably the most interesting because there is text people have already started doing quite a bit with text and now you can do a lot of things with it fairly sophisticated things with text so there is that is where the maximum activity has been in terms of using text for our predictions and classifications uh convolutional neural networks and rnns is used in a big way in specific industries as of now but this is also going to become mainstream because images and all the this is not been touched at all by organizations till now so there's a lot of opportunities out there right um have you guys done neural networks artificial neural networks or we started doing it okay which is good so a n is the basis for many of these different things right but there are very sophisticated architectures right that make a cnn different from a classic a n and also from recurrent neural networks have a memory associated with it makes it different right okay so that is okay this is a brief data uh let me anyway go through it so why is text so interesting for people is basically because of this right uh one there's a lot of unstructured text what they say is eighty percent of the organization's unstructured data people haven't really tapped into it so every organization wants to do something with it right if somebody use some some of you is from the content management side you would have seen when organizations implement cms they throw in a whole lot of documents into it but all the best they will do is probably search through it keyword search there is really nothing that they get or get out of cms other than probably search right which is which is important its own way but now with this kind of techniques available you can actually extract a lot more insights from text and text typically packs a lot of information within a short window right so if you look at this particular piece of text it captures issues product urgency organization customer there's typically a lot of information available within text right and text analytics is the foundation for any higher level if you talk about artificial intelligence and all that unless you can process text speech audio and things like that you really can't build intelligent agents right because that's a very important part of how we live our daily lives right text is important we listen to words make sense out of it get the context from these words sentences and things like that again this this slide i'll rush through but just for especially for a person who has already been in nlp to know uh there are a whole lot of techniques and fairly sophisticated ones extremely interesting in terms of the power of these techniques so at the end of the day what you want to do with the text corpus is basically four things one you want to convert text to some numerical output so that you can use standard machine learning algorithms right which is where count vectorizers and you can you can vectorize text and give a number to that word right what is called as a bag of words model and then you can use it for any kind of a machine learning prediction so that's one thing that you typically do you can extract content from individual documents in the corpus so you give a corpus and say tell me whether the names of organizations which is there in this corpus correct or names of people right all this parts of speech tagging entity extraction right all that is also you can do with uh you will try and do with text then dimensionality reduction right you want to reduce the dimensionality because if every word becomes a dimension there are just millions of dimensions which is very untractable and then extract relationships between words and documents in the corpus so you have again a whole lot of techniques obviously the most famous one if people have heard probably you would have heard of it is word to wick right so word to vect is how google runs its search right now okay what two vectors convert word to individual vectors right this is a topic on its own but good to know that there are i mean i will be good to know that these are the different techniques state of the art in terms of handling text right and this is a portion by itself but if anybody is interested this is a great area to be in because i think i would say the next five years is there's going to be a lot of text based analysis in multiple forms and shapes we're already seeing the seeing organization start delving into it a lot more right but suffice for you to understand given a body of text there are ways by which you can make it structured there are ways by which you can extract meaning out of it right you can extract insights out of it you can understand the semantic equivalence right which means what is this word equivalent to right um so the most classic example people say is given a corpus of text if you use word to work right which is basically what is called as word algebra is that then you can actually have algebraic statements saying king minus man plus women right women gives you queen right you can actually start doing those kind of exercise what is called as world word algebra with text itself and why is that possible because everything is codified as a vector there is a way by which you can convert each piece of word into a vector and the moment it's a vector you can do all sorts of mathematical manipulations on top of it right if not anything else just go and look at word algebra try and look at some videos you will find it extremely fascinating on how you can actually do this with words right okay so let me just quickly move on i think i have another twin okay category five so we have another five top five categories to cover um so focus is still on data it is unstructured data not web scale no label right which means you are doing unsupervised machine learning on unstructured data right which is again you use the same type of techniques in some sense but here you know do not have any different variable dependent variable you're just trying to understand the structure within text or you're trying to understand the structure within the images or you're trying to understand the structure within your whatever audio and things like that right and i've put a question mark there because i don't know whether cnns and rns are still applicable in this area i haven't done much investigation into that space but i know for a fact there's a lot of nlp that is used for just unsupervised machine learning right so some of the topic modeling and things like that actually falls into that category right you have a bunch of text can you divide it into specific topics right full range of nlp can be utilized what you saw on the previous slide right a part of speech tagging topic models word embeddings and things like that there is a there is something called gans right which is this is all generative networks there are also neural networks that generate new things uh neural networks write movie scripts in fact that movie script there's a famous example of a movie script written by a neural network that won some whatever the fifth prize or sixth prize in a uh in a particular film festival right there are things that create new art there are neural networks that create new music so this is one area where neural networks are becoming generative right by training the neural network with a bunch of let's say picasso paintings it can actually generate new types of paintings that can be that is very similar to the previous ones that it has seen right there are fairly advanced i haven't seen this in a more business context but these are some interesting developments that are happening which will come mainstream probably over a period of time yeah gns is generative models right so it's okay generative adversarial networks is so examples are something like so the moment you're generating stuff which means uh generating new art generating new music and the most classic example is generating movie script so what these guys did was they fed a bunch of hollywood scripts to her neural network it looked at all the patterns and things like that it actually the output of the neural network was a new piece of movie script right on which they actually got an actors to act on that script and that run some award and stuff it's a movie called sunshine right and so there are new networks that are coming in which are not only just discerning patterns to kind of predict whatever the test data is but it is actually generating new types of uh content that's the whole and it's called adverse serial because there are two neural networks that work together to make these things happen right one new one neural network generates it the other neural network verifies that whatever is generated is is good enough right and so you have two neural networks working in conjunction okay i'm quickly moving on so category six uh category six is essentially it's what is called as reinforcement learning if you look at machine learning machine learning is divided into three categories right supervised machine learning unsupervised machine learning which is what we saw earlier and there is this whole area called reinforcement learning right ah so what happens here is it is structured unstructured data typically reinforcement learning of the involve both but it can also work in uh work with structure on structured data but really the difference here is the feedback from the environment right and the simplest way to understand this something like a game right and so lot of work in reinforcement learning happens on game environments right so when you play a game right a pacman or even complicated games like doom and stuff like that you take an action but there is also action coming in from in this con in this case a particular game but then think of it like an environment right so the environment gives you certain kind of a response and at the end of the day you get some delayed feedback right either you win the game lose the game you score so many points all that is possible correct so how do you really do machine learning or how do you make an agent learn in that context where agent takes an action there is feedback coming from the environment right and this feedback is not the ultimate objective the ultimate objective is winning the game which will happen probably after three levels five levels 10 levels whatever that might be right how do you take that feedback and take the next best action right so if you really correlate it that is what artificial intelligence is right if you want to have a robot right move this move around this place it basically has to figure out should i take the right or the left right now am i hitting an obstacle if i'm hitting an obstacle how do i take back and how do i move forward so this is all something you have to take an action relate to the feedback and take a next best action right and at the end of the day you probably achieve your goal of probably if it's a robot it has to probably cross this and then reach to the other end right but it can be fairly sophisticated for many other different types of situations so that's the whole area called reinforcement learning more than a business context i think this is where artificial intelligence kind of comes in right how do you how do you develop intelligent agents that can take actions right not with so when i say delayed feedback right just to clarify that a little bit if you look at supervised machine learning you're getting immediate feedback right you have you have a label so you do prediction you have a label which tells you this prediction is so far away from the actual one correct so you get immediate feedback on your single row of data correct whereas in the case of reinforcement learning you are not getting that immediate feedback you are going to get delayed feedback take any game chess for example you play a move open and play the move at the end of the day the the feedback is about winning or losing the game which comes much much later right so how do how does an agent evaluate the position at every single point in time and take the next best action is what the whole reinforcement learning area is all about right the good news is there are algorithms there are fair i mean again if you're a python guy or guy you have you can implement it on your laptop once you go back to your rooms or homes right it'd probably take three hours to implement a reinforcement learning algorithm so that is not that's not the limitation anymore right there there is code available in fact in my github by uh reinforcement probably i haven't put in a piece of code but it's readily available right i'll add that soon but and there are all these autonomous cars where there's a lot of talk that's all about reinforcement learning and artificial intelligence right think of it that's the other end of the spectrum a car has to kind of drive itself and it's getting feedback from the environment in many different ways there is wind rain right obstacles pedestrians signals right just imagine the complexity out there and it's actually it's like it's happening right it's just a matter of time before it kind of spreads all over the world right uh again i've just given some terms in terms so i'll leave the presentation with you so at least some of these terms you can take a look at it and see what are some of the techniques that are out there and and these are all not static these areas keep moving these are rapidly evolving areas so a month down the line there will be some new algorithms and new implementations that have come in correct um okay alphago platforms okay that's basically what the reinforcement learning is i'm not going to spend too much time but i just want to introduce this topic called bayesian machine learning because this is again not something which is very i would say thought about but if you look at machine learning the biggest problem with the machine learning output in a business context is you give a prediction right you give the what is called as a most likelihood estimate right you say here is a bunch of training data and i am predicting a single variable for you or a single prediction for you now in certain context that is okay but in certain other contexts that's not acceptable because you don't know the uncertainty around those predictions correct so just to give you an example let's say this is about a detecting something in a patient right for to to verify whether you will have to uh have a surgery on the patient or not right let's say that is what your machine learning models are used for right just imagine from a doctor's standpoint you're giving a logistic regression kind of a prediction and saying there is a probability of point eight right which so whether the particular disease is uh there or not right you really can't take a the doctor cannot take a decision just with that point estimate right what you need is a level of uncertainty in the estimate right level of uncertainty comes from the fact that you give a prediction and say yes this is the most likelihood prediction but all the other types of things are also possible in a in a range correct that is what bayesian machine learning helps you to do bayesian machine learning is all about giving not only the predictions it also gives you the uncertainty around the predictions and it is not a new area in the sense that you have done linear regression there is bayesian linear regression you have done logistic regression there is bayesian logistic regression right so it's not a completely new area by itself but the thought process is different right i just leave that with you guys because from a business standpoint uncertainty is extremely important for a business guy to take a decision and tell a stakeholder you know what i am taking this decision but this is how uncertain it is correct rather than giving one particular estimate so personally i feel there's a great area to explore because at the end of the day if you really have really want your business to take a decision you need to provide them a level of uncertainty in your estimate otherwise they are not going to trust you okay so again there are multiple packages multiple ways of doing this uh again if you have the time please do check on some simple thing around okay you know what a linear regression is see how bayesian linear regression is different and what output does it provide so that you are comfortable about the fact that okay now this this is something over and above a classic uh machine learning kind of a situation right so that i put it as category 7 and i do have a notebook in my github which where you can quickly take a look at it in terms of what that is all about all right uh category eight is okay now we have done supervised unsupervised uh machine learning and reinforcement we have looked at it we looked at text images all that but what if the data is web scale correct you can do certain things on your laptop or with probably with enough memory enough codes on your machine but what if you are talking really web scale data terabytes of information correct how do you scale machine learning so scalable machine learning is an area by itself right where you are talking about things like spark right big data cloud all those things come together when you're talking about scalable machine learning the moment you say yes i can do things on one machine for a certain volume of data but as it scales up and you're looking at web scale data the same thing will not hold good right so how do you scale how do you use a spark in in a kind of a so so bottom line is again there is there is recently came across this thing called h2o right that's also built ground up for scalable machine learning right and this is an area which will again expand rapidly because every organization now wants to for most of the work that we do again cloud is a de facto thing we don't do anything on premise right now because just the volume of data is just so huge right and just the the car sensor data i was talking about you're talking about every single car in 158 countries and the volume of data is just so huge you can't really put it on anything so you put it on we used a platform called data bricks which is essentially spark on the cloud right and use tons of machines to process all that data right and the good part is it is not it's not costly you're going to use it for a certain period of time yes you're going to use that power for a short period but it's very i mean compared to the benefits that you can get out of it the cost is not prohibitive at all right so big data cloud is going to play a big role because now it's all about scalable machine learning how do you scale across computers and the good part is in order to learn how this works you don't need a cluster of computers you can still do it on your laptop right so you can write a piece of spark code spark again linear regression logistic regression decision trees whatever that might be run it on your machine okay see what how it works etcetera the same code essentially works for thousands of machines in a cluster you don't have to even change a single line of code because there is something called a spark session context which abstracts the the distributed nature of spark you don't have to know anything other than knowing how to work with spark in a machine learning context correct okay there is also this fascinating area called a search if you come across elastic search solar and things like that there's a lot of activity that is happening in terms of you throw in a bunch of data into a search platform right and it indexes everything and on top of it you can run machine learning you really don't need i mean at least people like me used to spend a lot of time creating data warehouses right ods data mods on top of it you run certain types of reports and stuff like that some of these search techniques is very simple you just have to index it into elastic search and top of it you can run reports you can you can run machine learning you can run it straight away you don't need to really invest time in developing schema right do all that kind of stuff right not that it is as simple as what i say but potentially right you don't have to spend real time in building all those different uh platforms right and each layer of the platform adds to latency adds to complexity and things like that right so this is again a fascinating area in terms of enterprise search okay so that's scalable machine learning that's category eight i'm not going to talk about this slide i'll leave it with you on how do you make sense out of big data again if you look at any big data if you look at the big data 2017 picture the landscape it has some 200 odd technologies platforms techniques you get like totally overwhelmed with it but the way to make sense is to divide again into some area saying okay distributed storage distributed processing sql access machine learning right some categories and learn certain techniques around it so that again over a period of time if it's really required you can get into the details of each of those technologies right but big data is there it is therefore especially from analytical context it is going to be big it is already kind of getting into almost every single aspect of machine learning right okay so that's big data um category nine is okay category nine is optimization right it's one thing to have predictions right you can give out predictions but if you put that in a business context the business has constraints right it's one thing to say uh there is a demand for your product is going to be whatever so many units 100 000 units right but the business will have constraints in terms of okay how much can i really produce right at what cost right so there is a lot of constraints around how much how much of this prediction can i actually fulfill right so at the end of the day every analytics pro i wouldn't say in every many analytics problems have to end with an optimization thing because if you are putting it in a business context the business is going to say predictions are fine but these are the kind of constraints that i have right the most classy case of optimization that we do is like what is called as media mix modeling right if somebody has done that you know the marketing manager basically has this problem of how much money should i allocate to different channels correct so you could have some regression and all predicting saying this is the kind of money that you have to invest to get the the maximum output right or there's the money you can invest but there are going to be constraints that they cannot take all the money out of let's say a tv ad right they still have to spend something on tv ads because they can't really move away from that medium completely right so there are going to be constraints in that problem so you finally will have to solve an optimization problem there right minimum maximum we heard of optimization you guys have heard of it so i am sure you understand the language that i'm speaking at the end of the day right you have to put in those decision variables the constraints and solve either to maximize or minimize as the case might be and the good thing here is if you combine machine learning with optimization it makes for a very strong output right because predictions are the output of your good machine learning algorithms that have already developed evaluated and you're also kind of putting it into a business context right and so and it need not be in a business context so again i have a piece of code which basically talks about using optimization in your daily life right so the example that i have which i submitted a blog on is in terms of okay if you have to really optimize on how many ted videos you've got to watch right you have certain amount of time right the tech videos are all available which runs for a certain period every ted video runs for a certain number of minutes or whatever right if you want to say how many ted videos should i watch for the next six months one year i have so much time and i don't want to be overloaded with stuff can i use linear optimization to solve the problem if you want to go on vacation you have a certain number of days available right you have a certain budget that you are you have you have what vacation should you take you can use it for all kinds of problems and of course it's very powerful in a business setting also right so very relevant in a business context many optimization methods are available and optimization is again a very well researched topic but the good thing is it is all available again on our python and things like that so python use a package called pulp which is basically a package to linear programming i am sure r also has got a package but essentially again going back to my earlier thing if you know what you don't know there are going to be opportunities for you to do all those things on your laptop right but the key thing is to know what you don't know right to figure out okay this is one area which is interesting word to work as long as you know that bird to back exists and that is used for this kind of purpose you don't need to know what word to make today correct you can learn it as and when an opportunity comes but if you don't know that tomorrow when somebody's asking a question you can't even figure out what to answer that person or how do you have an intelligent conversation that is why the breadth and understanding is important the depth go into it as per your requirement and the need because going into depth across all these areas is just not humanly possible right the last one except the last penultimate one is machine learning in production right which is about yes you can do all this fantastic stuff but how do you really get it to the end users there's a lot of questions that you have to answer to really push machine learning to production right so you need to understand the technology web technology probably you need to understand some kind of a more so you need to understand the i.t ecosystem answer a bunch of questions right saying okay how frequently are you going to run the model how are you going to get the feedback right to feed it into the model for you to recalibrate it from many aspects to running machine learning and production right and at the end of the day all of us want to do that right it's not we are not just learning machine learning for fun or data science for fun we really want to implement it in a business context and the business or anybody has to kind of take an action on it right so there are multiple things in terms of getting machine learning into production the last one i've said ten plus one because this is where we are starting to think if the focus is on the process not on the data right so all along we have only seen cases of your given data or you have extracted data and you're working with data in multiple different ways what if the whole thing is about the process right and typically the process data is all structured and what i mean by process in a typical sense is purchase order right known application process right everything has a series of steps associated with it and the question is basically okay what are the bottlenecks in my process right where are the deviations in my process right can i discover the process what is called as process discovery using using all this data and there is area called process mining again nobody talks about it in a very big way but if you are a person who is interested more on the process side especially if you are on the supply chain and areas like that right process mining is probably more important than data mining or your machine learning because uh with machine learning at least as far as i know you can't answer us questions like this right you need to and this is also a fairly well researched mathematically strong area you have bunch of algorithms which will tell you how to identify bottlenecks how do you identify performance metrics right all types of very interesting stuff if you are a process person yeah i'll just complete this if you're a process person check out processmining.org that's a ocean by itself you can just make your carrier just looking at process mining as a as a discipline so but i just want to talk about three key skills that you need to acquire to be successful in the analytic space again this is just my personal views one business connect every problem unless you are able to define it in a business context analytics is immaterial that's one key learning that i have so if you are especially a hardcore technology person which in some sense i was earlier the biggest roadblock or the biggest thing that you have to cross is about looking everything from a business standpoint and asking the question of so what so what if you implement this algorithm so what if you get this kind of metrics right at the end of the day how is the business going to get impacted is extremely critical in this space probably the whole narrative has to change in terms of people talking about oh this was a problem that is being tried to solve that is being tried and so this data driven decision making is important so i would want to bring that up front uh again some categories and things like that but the key thing is there might be programmers out here who are very comfortable doing r python and things like that so no problem you can pick up your uh two uh programming language of choice and go with it but there could also be non-programmers right and they i've seen at least people coming to me and saying i feel left out in this whole thing right we will talk about a lot of algorithms but i'm not able to do it because i don't want to really sit and learn python for now i'm a i'm a domain expert having invested so much time doing this the good thing is then i would say please look at some of these gui based tools right if you look at microsoft azure machine learning if you guys have looked at it it is basically a way to assemble things together it's all gui based you don't even have to write a line of code right h2o is another very classic platform big big ml right these are all platforms which are completely gui driven right and even if you are a programming expert i think it will be good to know some of these platforms recording because you can do things much faster right especially sorry prototype things and quickly get some predictions and stuff like that it's amazingly easy to do it on as your machine learning platform and as your machine learning is free by the way for i think up to around 10 gb of data i think right you can pretty much do all your practice uh even for fairly large data sets using azure machine learning right so try out azure machine learning try out h2o.i right fairly sophisticated algorithms gui based there's something called flow that it has then of course big ml is another platform which is very interesting so and i think there are quite a few others also name and things like that so i the slides basically says non-programmers may not be left out you can develop an intuition for all these different algorithms by using a gui based models also i think technology landscape is another thing don't don't get too focused on just the data science machine learning part because at the end of the day this has to get implemented within an environment so think technology landscape again expertise is not the key thing here if you already have expertise great but at least a feel in terms of okay how is it going to get implemented what questions should you ask or need to answer right cloud mobility web technologies embedded analytics legacy systems just have get a feel for it cloud probably is probably the most important i in if you ask me right now in another three years i don't think there'll be any analytics without the cloud everything will be on the cloud because that's that's the power of the cloud especially when it comes to scalable machine learning you can prototype stuff but in a real production setting it's going to be there on the cloud most of the time right because that's a volume of data that you're dealing with so that's basically what i had right thank you very much for your patient hearing in this tutorial we have learned what is data science and what are the topics and what are the concepts comes under if you like the content then please do let us know in the comment section and also if you want to learn more about these concepts then please go to great learning academy where you will get almost 80 plus free courses and after completing your course you can clean your certificate as well and if you want to do this courses in your mobile application that is also possible using great learning app thank you so much you 