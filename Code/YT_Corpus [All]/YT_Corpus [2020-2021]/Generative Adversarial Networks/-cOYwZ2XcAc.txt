 Dear Fellow Scholars, this is Two Minute Papers with Károly Zsolnai-Fehér. Before we start, I will tell you right away to hold on to your papers. When I’ve first seen the results I didn’t do that and almost fell out of the chair. Scientists at NVIDIA published an amazing work not so long ago that was able to dream up high-resolution images of imaginary celebrities. It was a progressive technique, which means that it started out with a low-fidelity image and kept refining it, and over time, we found ourselves with high-quality images of people that don’t exist. We also discussed in the previous episode that the algorithm is able to learn the properties and features of a human face and come up with truly novel human beings. There is true learning happening here, not just copying the training set for these neural networks. This is an absolutely stellar research work, and, for a moment, let’s imagine that we are the art directors of a movie or a computer game and we require that the algorithm synthesizes more human faces for us. Whenever I worked with artists in the industry, I’ve learned that what artists often look for beyond realism, is ... control. Artists seek to conjure up new worlds, and those new worlds require consistency and artistic direction to suspend our disbelief. So here’s a new piece of work from NVIDIA with some killer new features to address this. Killer feature number one. It can combine different aspects of these images. Let’s have a look at an example over here. The images above are the inputs, and we can lock in several aspects of these images, for instance, like gender, age, pose and more. Then, we take a different image, this will be the other source image, and the output is these two images fused together. Almost like style transfer or feature transfer for human faces. As a result, we are able to generate high-fidelity images of human faces that are incredibly lifelike, and, of course, none of these faces are real. How cool is that? Absolutely amazing. Killer feature number two. We can also vary these parameters one by one, and this way, we have a more fine-grained artistic control over the outputs. Killer feature number three: It can also perform interpolation, which means that we have desirable images A and B, and this would create intermediate images between them. As always, with this, the holy grail problem is that each of the intermediate images have to make sense and be realistic. And just look at this. It can morph one gender into the other, blend hairstyles, colors, and in the meantime, the facial features remain crisp and realistic. I am out of words, this is absolutely incredible. It kind of works on other datasets, for instance, cars, bedrooms, and of course, you guessed it right, … cats. Now, interestingly, it also varies the background behind the characters, which is a hallmark of latent-space based techniques. I wonder if and how this will be solved over time. We also published a paper not so long ago that was about using learning algorithms to synthesize, not human faces, but photorealistic materials. We introduced a neural renderer that was able to perform a specialized version of a light transport simulation in real time as well. However, in the paper, we noted that the resolution of the output images is limited by the on-board video memory on the graphics card that is being used and should improve over time as new graphics cards are developed with more memory. And get this, a few days ago, folks at NVIDIA reached out and said that they just released an amazing new graphics card, the TITAN RTX which has a ton of onboard memory, and would be happy to send over one of those. Now we can improve our work further. A huge thank you for them for being so thoughtful, and therefore, this episode has been been kindly sponsored by NVIDIA. Thanks for watching and for your generous support, and I'll see you next time! 