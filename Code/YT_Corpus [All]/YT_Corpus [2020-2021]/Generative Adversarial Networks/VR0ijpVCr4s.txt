 Hello we are team number one. Our term project title is Virtual Try-On, VITON. Our members are Wonjung, Soonchan and yujin,  and we are going to present by this order. The basic idea of Virtual Try-On is following It has input with model and cloth. And VITON system synthesize the output model wearing the target cloth. Basically it is by supervised learning aiming for a natural Virtual Try-On retains model's properties such as pose face and other clothes, and so on. Our replication model is CP-VTON, the title is Toward Characteristic-Preserving Image-based Virtual Try-On Network by Bochao Wang et al., published it on ECCV 2018 It consists of two steps of network.  The first network is GMM. The input of GMM is models information with head, pose, body and cloth. It makes the output-warped cloth which fits to model's pose. This work cloth is used in second network - TOM. TOM's input is models information including head pose and body and wrapped clothes. And finally it synthesizes the final output model wearing the target clothes like this We use data so called Zalando data set it consists of 16.3 k pairs of cloth and model we use the 14,221 number of train set and 2,032 number of validation set. Basically it consists of front view cloth and model. And its clothes and models are matched with the same index so, You can see this model wearing the cloth of the same index. Our replication method is based on official open source of CP-VTON. The link is here, And the site looks like this right figure. It has the source files with data processing And gmm training, which is the first network And tom training which is the second network And result visualization with Tensorboard. During replication we had several problems firstly environment setting Source code had outdated libraries with torch 0.4.0 So we needed to cope with the recent version with this specification And during version upgrade we did code modification to resolve bugs. Also, it had non-refined data. Thus, we removed non-refined data manually 5.5% of 16.3K dataset. It included wrong cloth data, which is not plain clothes image And tilted cloth viewpoint, although we need frontal view clothes And finally wrong cloth model pairs, which means same index but wearing different clothes. Next presenters will explain our replication results and plan for improvements of term project Images are result from the paper and our application result. When you compare Try-On images from the paper and our application, We can confirm that the performance of replicated code is comparable to the original paper We defined three problems to be solved from our observation and related work First issue is on excessive distortion of cloth images. As it is shown in the figure, some warping results are too much exaggerated. The second issue is occlusions on closed region In the figure in the middle the network performs improper warping on closed image because they do not consider the region occluded by the human's hair. The third issue is performance of GAN itself The generated images from gen has artifact when we investigate those images It is not difficult for us to distinguish generated images and real images By referring existing works we attempt to solve the aforementioned problem We will apply new laws Namely grid interval consistency laws to restrict unnecessary warping in clothes. We also apply human passing data in order to consider the regions of clothes occluded by the other body part Lastly we try to improve general performance of generated images from GAN Specifically we implement the refinement layers and attach discriminator after GAN generally enhances the performance of GAN. Okay now we'll talk about the plans for our improvement Our team members will do ablation study on each section Dividing each section and then testing separately with a baseline Wonjung will apply the grid interval consistency and occlusion handling concept Soonchan will implement the gmm tom's discriminator along with SNGAN. Youjin will implement the refinement layers on tom and evaluation metrics Now you could see the schedule for the future plans First the implementation on each part will be done on the following week Then on week 2 ablation study on each section will be done Third all tasks will be integrated into one and final evaluation will be done with the original paper Then with the results, Documentation on the experiments and implementation will be written Now both qualitative and quantitative evaluation will be done on this project The comparison of original results and ours as you can see from the figure These will be done as quantitative evaluation And for the quantitative evaluation, we'll use methods like Inceptive Score and Fretchet Inceptive Distance Which are widely used metrics to measure the synthesizing performance of GAN, which is used in our network It is to determine whether the synthesized image data set is statistically similar to the real data set Today we've shown you our progress on Virtual Try-On And if you have any questions or further idea, feel free to leave your comments here on youtube Thank you for your attention 