 [Music] and now the entire summary of this whole deep generative stuff that we have done right so here's the summary so we had these four algorithms that we were interested in so we had our beams variation auto-encoders auto regressive models in which we did need and made will not talk about pixel ordinance and gangs okay so these are the four things that we did and there were several things that we kept asking about this model can you do abstraction can it do generation and so on so abstraction how many of these models were able to do except for in Ganz do you have any abstraction no in fact you start from some normal random distribution and come to the image so there is given an image there is no set right you don't have Z given X in a gap okay so it cannot do abstraction whereas our beams and bas can do that what about generation all of them can do it okay what about P of X if I want to compute P of X the options that you have is tractable interactable not applicable if I want to compute P of X in the case of our beams tractable interactable not applicable interactable right because to compute P of X you have to sum out the edges right remember that so it's interactive for variation in auto-encoders so remember always you had this bad expectation and then you approximated it by something in the case of our BMC approximated it by sampling in the case of variation auto-encoders by using variational inference right so you did not optimize the actual objective you optimized the lower bound so there is a difference that means it was interactive what about auto regressive models tractable but slow all about Gans not applicable Gans do not even compute a P of X what about generating samples or sampling from this distribution in the case of our beams how will you do it how will you generate samples once you have learned the distribution you will do get sampling for variation auto-encoders you can just pass a Z I mean for variation or ten good as it was simple and you take a Zed and you just generate the image from there right the decoder will do it for ER models you can do it but it's very slow because you do it one pixel at a time from left to right and for Ganz it's very fast because you just pass it through your convolutional neural network or the transpose convolutional neural network and you'll get it okay what about the type of the graphical model the options are directed undirected undirected directed directed directly you take a Z and then give X right it's also directed okay what about the loss function okay this since you have not done the math part so it's KL divergence for the first three and something known as Jensen's Shannon divergence for the last one which is again a sum of two KL divergence okay so why is it KL divergence we were always looking at cross interpolate then why am I writing KL divergence because the KL divergence is the same as cause entropy which we are trying to remember that you have proved this earlier because one term depends only on the true distribution and the other term depends on the true and the predicted distribution so the first term does not matter and the second term is the same as the cross until everyone remembers that you have derived this at some point if not you can go back and check it what were the assumptions made by these different models for our beams X's are independent given the z4v A's no V ace we did make an assumption it was implicit sitting somewhere in the corner we assume that the covariance matrix was that means the X is are independent given the z4 autoregressive models we do not make any assumptions for gans not applicable because you don't really find P of X right okay and okay this last part is so the generated sample so what's the current state of the art so you have these four different ways of generating now right and doing all these applications which I said given an image and it another image and so on so what's the state of the art right now so our beams are pretty bad at it we azar okay the images are a blade flurry they're not very sharp a our models are good and Gans are considerably the best among these four options that's what you hear a lot about gaps okay so this is one way of analyzing all these models and like finding the relative differences from each other the other is we could actually and okay so before I move on so there's a recent lot of newer works which look at a combination of these things so you take the auto encoder idea you take the adversarial idea from ganz and try to come up with a net do a serial or variation auto encoder right or you take the pixel are in an idea you take the variation auto encoder idea and try to come up with a pixel variation auto-encoders right so these are lot of combinations of these things are now happening why because all of them have their own relative advantages and disadvantages so if you combine them hopefully the disadvantages should disappear and the advantages should multiply right so that's the hope okay so the lot of recent work happening around that and finally if you look at the overall take sonamoo of these approaches so remember this maximum likelihood this nothing this is nothing but the recipe which I told you right whenever you want to learn a joint distribution what you do you have a P of X and you want to maximize log of P of X so all the models that we do have the same recipe they want to maximize some log of P of X right but some models have an explicit representation for P of X some have an implicit representation for P of X so the explicit representation ones are Ghats that's the most important one so the implicit representation it does not compute P of X it just gives you samples from the distribution so that's guys for the explicit once you have two parts one is tractable models and the other is intractable models so the tractable models are made made and pixel RNN because you can actually compute P of X as the default factorization okay and the interactable ones are the ones whose uses approximate density are variation auto-encoders and boltzmann machines or restricted Boltzmann machines so this is the overall taxonomy of all the algorithm that we have seen and these three right ganz pixel Iranian and variation auto-encoders are the most popular ones that you'll see nowadays okay so okay so with that I officially end the course and I hope you enjoyed it I really enjoyed teaching it I hope you also enjoyed learning from it and picked up a few things along the way now I would like to do an important thing I would like to call all my tears on stage and really thank them for all their support and effort throughout the course and they've done a very very fantastic job it's not very easy to make these slides I and I can really be a pain in the neck when it comes to these things replaced Nick by any other word that you want and so it's very very hard because I make this storyboard and I am very particular about that this image has to come at this pixel location and not anywhere else and so on and the equations have to be in a certain point and so on so they've lived up to all that and survived through it so they really deserve a big hand of applause so please join [Applause] [Music] [Music] 