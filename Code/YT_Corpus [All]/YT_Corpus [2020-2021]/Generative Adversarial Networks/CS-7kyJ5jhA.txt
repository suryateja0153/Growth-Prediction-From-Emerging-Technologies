 Hello. My name is Mark Turner. And I'll be taking you through this talk on learning control decisions in gas networks. I'm currently a researcher at TU Berlin, working in corporation with Zuse Institute Berlin. This is just to put a face to the voice. And hopefully you'll see me on the other side of this talk. Please enjoy. So as a gentle reminder if you weren't aware already then here's the mandatory warning. This is the final lecture from a larger series of talks on gas networks. I'll try to make this talk mostly self-contained. So there'll be minimal references to the other talks. There's two points that are especially handy, that you really should listen to before this talk. So firstly, the descriptions of individual guest network elements. This information is mainly in Felix's talk. But essentially, it would be repetitive for me to go over the definitions twice of everything. Secondly, the background of how we actually derive this problem. This is given in Kai's talk and gives well-needed structure on kind of how we derive to the definitive problem statement. So on to the problem setting for learned exact control decisions in a gas network, we focus on network stations. Network stations are commonly located at the intersection of large pipelines. And they contain all heavy machinery in the entire network. They also contain the majority of controllable elements, so things which the operator can actually control. There are some natural exceptions to this for instance. There could be an emergency valve in the middle of large pipelines in case of an emergency obviously and these lie outside the scope of our problem. On the right hand side of this slide you can see a typical example of a network station. It's located at the intersection of two major pipelines. You can see one going east to west one going south to north. And zoomed in, in this expanded mirror is the exact network topology of what actually happens inside of there. Simply put our problem aim is to find all control decisions for all elements inside of these network stations. We specifically want control decisions over an entire future time horizon. So this means specifically, that we have a discretized future time horizon. For instance it's noted there as time step 0 to absolute value T which represents the set of time steps. And we have a priority that these control decisions are as stable as possible and a requirement that these control decisions are safe obviously. I'll present two approaches in this talk for calculating control decisions in a network station. The first is a model driven approach that uses a series of simpler MIP formulations and a rolling horizon method at its end. The second is a data-driven approach that uses a dual neural network design. If you're especially interested in the first approach, that's the model-driven approach then i've added the link to a much larger technical report on it. If you're also after more information in general about gas networks, then I've added a link to a rather thorough literature review that covers stuff. Well outside of the scope of this course. I'll quickly run through the problem input and output for learning exact control decisions in the network station. The first piece of input to consider is the network topology. That is complete individual element descriptions. For instance take a pipe. We need to know the length of the pipe, the diameter, the roughness factor, the pressure limits. All of these types of values. We also need to know the connectedness which is just the underlying graph structure for instance, which pipe is connected to which pipe. Next, we need an initial state. This gives us starting values for all variables in our problem at the very beginning. For instance, it gives us the pressure at all points in the network the flow of gas at all points in the network. How fast does that gas move in, which valves are open, which are closed. All of this information. Finally we take the prognosis as input this comes from our previous models. See Kai's talk specifically for this information. This prognosis prescribes values to the outside world and tells us what the pressure levels and flow values. We need to have for all elements at the edge of our network that connect to this outside world. This outside world is irrelevant in a large part to us as it could be other gas networks. It could be factories. It could be gas burners. You name it, but essentially we have a desired pressure output and a desired flow output. We would like to meet in this area. Onto the output, so the output for our model is actually multiple sets of decisions for the same elements. We need this as we need decisions for all future time points as we mentioned earlier. This time horizon is flexible, so for instance, we may require for every 15 minutes a set of decisions over the next 12 hours. These decisions are as follows, so for valves we have the states open and closed, for compressor states, we have active bypass enclosed, in the case of active, we also need the exact operating point of the compressor station. We'll go into detail what this is exactly later. For regulators, we also have the modes active open and closed. We would also like to know the pressure and flow values throughout the network. These aren't decisions but rather show the consequences of the decisions we make. And when they're used to show how our decisions affect the gas network. Here's some nice tidbits from finding control decisions that addresses the difficulties uncertainties of the problem. And we'll go through these before getting into the exact problem solutions that we use. First of all organizing priorities working with the project partner. There's going to be a lot of priorities and there aren't such priorities isn't always clear. An example of such a priority would be making sure that supply and demand is met that is specifically respecting our prognosis perfectly. Due to inconsistencies in data or a limitation of our model. However, we may not be able to meet these exactly. In such a situation, should you return nothing or should you incorporate slack into your model? On the right hand side, you can see how slack can be simply put into such a constraint. In such a case, you would also then naturally penalize this slack term in your objective. Another priority is making sure the control decisions are safe. This should obviously naturally be a constraint in most cases see the example of pressure bounds. But there's other definitions of safety given in projects like these that are not always so clear. As an example, the sentence: Don't stress the network. This can sometimes only be expressed as sentiment and not have any well-defined constraints This sentiment can be quantified in part but then it gets very hard in how you would penalize this. Another priority in the case of gas networks is stability. The gas network does not want to constantly be turning m.achines on and off if it can help it For example, if we take an active compressor station with fixed configuration. It would be best, if our active operating point in the compressor station does not move too much over time. In other words: We don't want our active operating point to hop from corner of the polytope to corner of the polytope from extreme vertex to extreme vertex. Here's an example of an active operating point in a compressor polytope. If you look at the right hand side of the slide, you'll see a compressor polytope and inside the active operating point. Note here, that a stable control decision doesn't mean that this active operating point stays at the exact same location, but that it just doesn't move manically. I'll now flash through some different active operating points for the same polytope that are linked together by one time step. So a simple question would be how do these get added. Could they be added as a weighted objective or would they be a multi-level model or would they all be listed as constraints? This can be answered by whether or not there's a strict hierarchy or whether or not there is flexibility with them. The questions you would need to ask yourself before you look into things like multilevel models would be: Can you afford the additional model complexity? In our approach we used a weighted objective. So a linear objective with customized weights. And these weights were given to us by our project partner after much internal discussion. Another difficulty of our problem and many other problems is the time it takes the model to run. In our situation, it is entirely unacceptable if a model returns no solution in the required amount of time. Our model will be used in reality and it needs to return decisions quickly. Unreliability is not acceptable in a gas transport context. For instance, if they do a run with the expectation of a solution within 15 minutes within 15 minutes. There must be a viable solution. Another problem difficulty is model exactness. The first example we give is for the pipe discretization. In this problem, what assumptions do I make before discretizing or do I even discretize to begin with? If I discretize, what discretization techniques do I use? Once I arrive at my end result do I leave the result as is do I convexify? Or linearize my end result? In our case, you should see Kai Hoppmann's talk for more information, because he goes quite deep into the pipe linearization. But as a summary: We linearize by using a neat trick with the velocity. Another source of model exactness in our problem was compressor polytopes. As a heads up, they'll play a major part in luvs workshop. As a summary of what a compressor polytope is i'll first give a summary on compressor stations. So simply put a compressor station is a network element that increases gas pressure in the forward direction. The compressor station is made up of multiple individual compressor machines. It then has a set of configurations which decide how the machines inside of the compressor station are used. Each configuration with its unique layout of the individual machines i.e the arrangement and how they're connected. Then has its own specific polytope that describes how it can increase pressure with respect to flow. After deciding on which configuration to use, the polytope is selected and the model must then choose a point within that polytope that describes the active operating point of the compressor station. This concept can be formulated using a disjunctive formulation. I've added a link which is sadly behind a paywall for the source of this model and more information on disjunctive formulation and by extension disjunctive programming. So the exact use case of this concept is that we can efficiently model each compressor configuration's polytope such that we retrieve the active configuration and the active operating point inside of the polytope and the specific formulation mentioned by the reference binder paywall has the benefit that its LP. Relaxation is the same as the integer hull. Here on the right hand side of the slide, there's a formulation of a simplified version of our problem note that there is no closed or bypass mode for the compressor station only active. Please feel free to pause the video and look through it. We've got binary variables described in the configurations denoted by mc. And the pressure and flow variables indexed by configurations. Our constraints force exactly one configuration to be active. And all pressure and flow variables associated with the other configurations to be 0. HPlanes here is just a short dirty notation for hyperplanes, which create the half spaces of which the polytope is the union of. Here's the end result of such a set of constraints and what it actually describes. The first picture, the top one, shows the possible choices of configuration each having its own polytope. You can see by the different color the different ways they're rearranged. Blue in this context is parallel. So you can have multiple machines side by side and thereby have much more flow. Orange is a single machine and brown is multiple machines in serial. So, one machine leading into the other and by this you're restricted in flow to that of the single weakest machine. But you can get massive pressure increases by increasing one machine followed by the second folded by the third etc. The next picture the bottom one represents what the choice of an active operation point means given that we've already decided on a configuration. So, you can see that we've picked a configuration, so only one polytope exists and we're now required to find a point within this polytope that describes the exact pressure in pressure out and flow relation. Here's an example constraint set for network stations which revolve around a binary variable set called the operation modes. In network stations each controllable element cannot choose its mode independent of the other elements. We rather have a set of operation modes as we call them these operation modes determine the modes and configurations of all valves and compressors. This can be thought of as a binary variable that decides all the other binary variables attached to valves and compressor stations. Below there's a more complete definition which I encourage you to pause and read. This set of operation modes is very restrictive in its size, if all elements were independent, then the number of ways of a range in the network station would be at least 2 to the power of the number of valves, multiplied by the product of all compressor configurations. This is not true and rather we are given a restricted set of valid combinations. This is in the ballpark of size 50 to 2000 depending on the station. The size of this set is drastically reduced for many reasons. Here's some examples of why: For instance some valves cannot be opened at the same time as other valves. Another obvious scenario would be that a compressor station that is active cannot be surrounded by all closed valves. On the right hand side of these slides you'll see different examples of operation modes. As a more concrete example of what these operation modes specifically do we'll use the variables introduced in the previous slide. So assume in a fixed operation mode, then that fixed operation mode may force the selection of a certain configuration for a compressor station. In this case the model is still free to decide on which operating point inside of the associated polytopic can use, but its choice of polytope is now fixed. You can notice this below, where the binary variable for c1 and c3 are forced to 0 and c2 is forced to be 1, ak active and then the flow pressure in, pressure out variables 4 c1 and c3 are all forced to 0. But note that then the flow pressure and pressure out variables for the active configuration c2. Still are not fixed to anything but rather now are forced to satisfy the polytope constraints. Each operation mode also has a set of allowed flow directions. For example: In none of the operation modes shown was the gas allowed to flow from east to north. So what is our model driven approach and why do we simply not solve a single large MIP? We can't simply solve one large MIP, because the solvent time is too unreliable. The quality of solution with the given time frame for a single MIP formulation can vary wildly. And with a 15-minute time limit, it would be useless in the vast majority of cases. Our idea to tackle this intractable mixing program is to break it up into smaller parts. Despite narrowing our focus down to network stations which are already a small topology within the larger network. The topologies can still be quite large. Not large in the sense of gas volume, but large in the sense that there are a lot of pipes and the network is cycle and element heavy. Keeping in mind that the majority of controllable elements and all heavy machinery are in these network stations. We thus reduce our problem into a series of stationary problems and ignore the transient nature of gas flow temporarily. Please keep in mind that our end result requires a transient solution as we need control decisions for many different points in time. Breaking our problem into stationary components allows us to create a greedy heuristic, which can determine binary decision variables for the larger model, specifically the operation modes mentioned earlier. See the image at the bottom and imagine that now each image represents a problem and we need to solve the series of problems as opposed to a single large problem. Our algorithm introduces a penalty for change in operation modes in between time steps and it is this which links our solution per time step in the middle of the algorithm. Making sure that each individual time step is not independent. After obtaining the operation modes or if you want to think about them as the binary decision variables. We then see if we can recombine different sets of operation modes that lead to a better objective value spread over the individual time steps. This is done by combining operation mode sequences and creating small sets of operation modes that are most likely to improve the first solution. This can substantially improve the overall objective summed over the individual time steps because the greedy heuristic. Only considers the present and only considers a penalty parameter that goes back one time step. We then finally smooth our solution by fixing the binary variables in the larger model and solving the larger model with a rolling horizon approach. This enables us to get good primal solutions to what was originally a completely intractable mixed integer program. So the smoothing procedure is a necessary task after our greedy algorithm. We need to do this as the algorithm largely ignores the continuous variable interaction between time steps and thus these values are largely independent. This continuous variable independence comes with some rewards though and the upside is that our greedy approach is very fast and scales linearly with respect to the number of time steps. The effect of this continuous variable independence is that it can lead to spikes in variable values over time. That would not be feasible in the original mixed initiative program that contain constraints linking to adjacent time steps. A roll in horizon creates a time horizon where it solves a time step with limited look ahead and then moves on to the next time step. In doing so we respect the pipe equations that link two adjacent time steps and respect more complicated binary variable interactions, which were addressed in the greedy heuristic where they were computationally much less expensive to include. Below you see an example of why smoothing in is needed. The upper graph shows the pressure of an element over time directly after the greedy solution is returned. Note that it jumps at a certain time step. After fixing the binary variables in the rolling horizon approach. However, this jump can often be removed with no effect to the objective. An example is the graph below which shows the flattened line of the above graph. Our approach with the smoothening procedure has a nice property that guarantees feasibility to the original mix initiative program. It also like the greedy algorithm scales linearly with respect to the number of time steps provided you keep a fixed window size. So now onto a data driven approach where first I'll go through some steps that should be checked before approaching a task of this size. Firstly, the mandatory question if do I have enough data. There really is a lot of data needed for complex tasks and sadly. I'm not sure, if there exists a perfect way to approximate when the enough threshold is hit. This problem does also exist in part for the model driven approach. For instance our role in horizon mixed into the program could not have been tested unless at least one complete data point existed. As a warning to those starting a new project the plan to do a data-driven approach. Then just a warning that there's a never-ending amount of new features and interfaces. They may in fact never stop. Certain features simply required time or the project partner did not have the ability to record them before the suggestion was made. And naturally new suggestions will always happen through the course of research. Another warning is do not make a design that cannot incorporate new information. A large part of projects like ours in the beginning is simply ensuring that your partner can deliver the data and as mentioned this data is never ending in terms of the new features being added. Secondly: Ask yourself: What technique is best for your purpose? More complex techniques aren't always better. So there's a quite well known result the free lunch theorem that states there is no universal method. For some tasks certain techniques simply empirically work better. So for your task, make sure you choose the technique that best fits instead of forstner technique that you want. This can be done both experimentally and theoretically. Also: In the case of data-driven approaches, ask yourself, if a simple heuristic will suffice. Simple heuristics are often surprisingly effective for practical problems. In addition how important is an optimality guarantee for your specific purpose. For instance, for our problem: We did not begin our data-driven approach until a rolling horizon approach was complete. And in both cases an optimality guarantee is simply not on the table. Model in your input this ties quite heavily with your choice of technique as they will have a natural representation of your data. This is simply a reminder that the way you feed in your input often can affect the end result of your output. Despite using the same technique and design. So here's an overview of our dual neural network design, but first I should address the inspiration behind the design. And some relevant material that would help understand it. Firstly, generative adversarial networks or GANs. Here's a link to some nice workshop slides that cover what again is. Essentially they've recently become popular for tasks which involve creating content. Secondly actor critic methods. Here's a link to a paper which summarizes what these methods are. Essentially, this is just a branch of reinforcement learning Both these approaches helped us come up with our design, which we believe was necessary due to some assumptions, which can't be made for gas networks. For those who know both these methods and are interested in a comparison of the two. I've added a link to another paper, which briefly describes, how both work and in what ways they are similar. Now to briefly explain our design. We feed in the traditional input that is our network topology initial state information and the prognosis. This goes into a generator. The generator then outputs the operation modes. The discriminator then takes its input. The original input as well as the generated operation modes. With these as input, the discriminator then outputs a prediction of the optimal objective function value of the large scale mixture program, if these operation mode values were fixed. So some properties of our design that may make it easier to understand. We use a generator and discriminator design firstly. Secondly the generator produces binary decision variables specifically the values for operation modes. The discriminator predicts the induced optimal objective value of a problem with these variables fixed. When we say fixed, we mean that they are fixed to the values output by the generator rounded to 0 and 1. Our MIP or our LP solver is the environment in this case and our discriminator and generator are trained at different times never simultaneously. Here are some Pros and Cons of agile neural network design and its implementation. Many of the Cons are in its relation to the model driven approach. The first Pro is that we can generate our own data. We can do this as we learn from our MIP formulation itself and thus data generation is much simpler. The downside of this however is that our MIP must represent reality. This may become a problem in extreme scenarios due to simplification such as our linearization. Remember that for our pipe equations. We assume constant velocity. Normally, this is quite effective but in some extreme scenarios it isn't. Our approach learns on the gradient of objective values, because remember our discriminator predicts the optimal induced objective value by a choice of operation. Mode this means that our non-optimal decisions are much more likely to be near optimal. This was a large part of our design choice. We needed to generate decisions and did not want to use the general GAN discriminator which accepts or ejects. The downside of this however is that the project partner may wish to change their objective function. And this would require retrain in the network heavily. There is also no bound guarantee at all with our solution. We can move a substantial amount of training offline, specifically the discriminator's early training. Our approach does not use everything offline however. And the generator requires some form of online training to ensure that the discriminator continues to return results that faithfully mimic the induced optimal objective values. Our data-driven approach is used as a primal heuristic for the large intractable mixinship program. It drastically reduces problem complexity by having a substantial amount of binary variables a.k.a. the operation modes fixed. It is not a complete primal heuristic, however, and requires a MIP or LP solver to find the optimal continuous variable values associated with your choice in binary variable values. Cheers for making it through and hopefully this lecture series has given you some stuff to think about. If you've got any questions, then remember, that there's a Q&A-Session, two of them in fact. And feel free to ask whatever you wish there. Have a good one. 