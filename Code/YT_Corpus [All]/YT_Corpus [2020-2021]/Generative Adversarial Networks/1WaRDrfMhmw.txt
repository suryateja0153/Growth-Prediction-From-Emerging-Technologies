 [Music] hello welcome back to the NPTEL online certification course on deep learning so for last few classes we are discussing about the generative Network where what we have discussed is that if you feed in latent vector or latent variable to the generative Network then the generative Network will give you an output data or reconstructed image or the reconstructed object and the kind of generative network that we are discussing so far is what is known as adversarial auto-encoder so we have started our discussion on adversarial autoencoder we have discussed about what is variational inference today what we are going to discuss about how do you practically realize the variational autoencoder then we we will briefly discuss about another generative model which is known as generative adversarial Network and we we shall conclude our lecture or conclude this course with the applications of generative adversarial Network so this is what we have discussed in the previous lectures that our initial objective was to minimize the KL divergence qz x pz X and we have seen earlier that this is same as maximizing the qz X log of P exit qz given X log of P X said what P XJ is the Joint Distribution upon Q of Z given X and we have seen that this is what is known as a variational lower bound and the concept of variational lower bound that came because we have seen that P of X computation of P of X was intractable so what we try to find out and we have seen that this particular expression the variational lower bound gives a lower bound of P of X so in order to maximize of X it is equivalent to maximization of the variation or lower bound because when we are when we know that this variational lower bound is always less than P of X so if I can maximize this variational lower bound P of X is also going to be maximized so this is an indirect way of increasing the probability distribution P of X so our aim was was now to maximize this variational lower bound and this variation a lower bound can be rewritten as sum of P of Z given X log of P of x given Zed into P upside upon Q of Z given X so this expression can be rewritten as sum of cubes each given X log of P of x given Zed plus sum of Q of Z given X log of P Z upon Q of Z given X so here you find that the second term that is sum of you said given X log of P Z upon Q Z given X this is again another KL divergence KL divergence between P of Q Z KL divergence between Q offset given X and P offset so this can be simply written as the first term is now expectation value of log of X P X Givens it and you find that this log of px given Z is nothing but log likelihood and when you try to maximize this basically the first term maximization of this means you are going for maximum likelihood estimation and the second term which is the minor scale divergence of Q's that given X P said max maximization of this term effectively means that you want to minimize the KL divergence between Q offset given X and P of set X and P upset so then we have seen that how we can translate this loss function or maximization of the loss function into an auto n Kedar architecture so for that again we have gone back to our graphical model that given your latent variable or latent vector Zed and the data which is to be reason which is to be reconstructed X so there is a probability involved probability density distribution involved that P of x given set that is given said I want to maximize what is the likelihood P of X given Z and similarly to get your latent variables or latent vectors from the training data I have another probability distribution involved what is which is Q of Z given X so in terms of network realization you realize both P and Q with the neural networks and the network model that we'll get is something like this that Q of Z given X is your encoder Network P of X given Z is the decoder or the generator network and P of Z given Q of Z given X actually gives you the latent variable which is said so here comes the difference between the traditional auto encoder and the variational auto encoder in case of traditional auto encoder the latent vector Z was deterministic but with this variational auto encoder because we have a term P of said that is the probability distribution of the latent variable said so instead of getting a deterministic latent variable as in case of auto encoder it over here what we expect is the encoder part will give us a probability distribution or the parameters of the probability distribution of P upset so it is therefore expected that Z codes does it let in variable that we get that should match with the distribution of P of Z and we assume a normal distribution a normal a prior of normal distribution for P of Z for this normal distribution is zero mean and unit variance so that will be a prior for P upset so as you have seen that here instead of getting a fixed latent variable said what you are getting is a distribution or the parameters of the distribution and this is the network realization that we have the encoder network on the left and the decoder Network on the right in between what you have is as the encoder is giving you the distribution of said I can sample a set from that distribution and feed it to the decoder or the general Network and the decoder of the generator will give me the generated or the reconstructed data that is X and then we have discussed about the problem in always in this sampling which makes it difficult for the back propagation learning because gradient cannot flow through the sampling process so in order to avoid this problem we have made use of the T parameterization trick so this is what we have discussed in details in our previous lecture so now the problem is that we are trying to maximize the expectation value of log p of x given said minus KL divergence between Q of Z given X and P Z so maximization of this expression means we are trying to maximize expectation value of log of P X given set and we want to minimize the KL divergence Q z given x preset so we have both this maximization and minimization involved and for this maximization you find that the maximization of expectation value of P of x given Z is nothing but a maximum likelihood estimation which we have encountered a number of times in our discriminative Network so this can be solved using any of the classifier or the input is said and the output is X then you optimize the objective function by using different techniques for example log loss or regression loss and all that whereas for minimization of the other part that is the KL divergence as we said that we assume a prior distribution of pubes which is normal distribution with zero mean and unit variance for all the attributes of the vector said so by when we try to minimize the scale divergence that effectively means that we are pushing the parameters of Q's they'd given X towards that normal distribution of zero mean and unit variance so by using this prior this normal prior it is advantageous in two ways firstly it becomes very easy to sample it ain't lettin vectors from this normal distribution and secondly assuming that Q of Z given X to be Gaussian distribution with parameters mean and the covariance matrix Sigma it allows this KL distribution to be in a closed form and that becomes easy for optimization so this cause form representation is something like this that the scale distribution can now be represented as 0.5 into trace of the covariance matrix Sigma plus the vector mu transpose mu minus ki minus log of determinant determinant of the covariance matrix where this K is actually the dimensionality of the latent code or the latent vector set and this can be further simplified as all of this I will go come to the final expression so this finally comes down to 0.5 into sum over K the Sigma XK plus mu XK square plus 1 plus log of Sigma XK so this is the final closed form expression for that loss function that we get or the KL divergence form that we get and this is the advantage of assuming normal distribution prior for Q of Z given X but in practice we predict log of Sigma X instead of Sigma X since it is numerically better to exponentiate a value during runtime rather than taking a log operation so your final expression that it becomes the KL divergence of Q of X depends ed and the normal distribution 0 1 that is equal to 0.5 into so instead of Sigma X K now it becomes exponential of Sigma X there plus mu X square plus 1 plus log of sum of X K you find that this log of sum of X K has come from the product term which is basically determinant of the covariance matrix Sigma right so this is log not sum of X but log of the different components of the covariance matrix in my XD right so now let us see that what are different kind of output that we can you we can have using this variational auto encoder so this gives the reconstructed output from the variational auto encoder for given inputs you have the different reconstructions and this second set of results is showing that if I sample a vector from a normal distribution 0 mean unit variance then the generator network generates or reconstructs the signal as given in the last one in the last row so you find that in many cases this generator sample the generator examples are the generated data that closely resemble the amnesty database the characters which are available in the industry database this is again another set of output again reconstructed from this generative model from the variational local encoder which is trained on Salib a database with variational auto encoder we can have another trick following the vector arithmetic approach that is if we take a set of face images with classes the corresponding latent code we say is c1 then Tana take another set of face images which are without glasses the corresponding latent code is C 2 then C 3 the vector C 3 which is C 1 minus C 2 that gives you the code for the glasses now if we have a face image without glass we can impose this glass onto that fasteners so you take a new face image without glass and it's corresponding latent code is less v4 then you generate a latent code which is C 3 plus C 4 so you find that C 3 was the latent code for that glass and C 4 is the latent code of a face without glass so when we are making C 3 plus C 4 effectively I am generating a latent code for a face with a glass so this transition is possible because the latent space is continuous instead of clusters of points that you get in case of traditional Atlantic so a set of results on this so it says that we had a set of images with glass and we also have a set of images of man without glass you subject these two you get the latent code of the glass then you have set up images of women which are without glasses then you add the latent code of the glass with latent code of women and then you feed this latent code the latent vector to the generative Network and the generator network outputs faces of women with a with glasses so this is a nice trick where we can play with the latent codes in the latent space and I can generate the output data in various combinations so that was your our variational auto encoder now briefly I am going to discuss about what is generative adversarial network so generative at first their network is another form of generative model for reconstruction of the data from the latent code so unlike in case of variational auto-encoder where the distribution the probability distribution of the latent code was quite explicit in case of generative model this implicitly defines the probability distribution so a sample code vector said from a sample your sample code vector said from a simple and fixed distribution which may be say normal or uniform distribution feed it to the generator network which is trained as a differentiable network and this generator network then map a to your data Maps this latent variable said to the data point X so effectively what you have is you have the data from a true data distribution and the generator model what it does is it takes a sample from some distribution may be say you need caution distribution and this then it generates another distribution of data which is the P hat X then while cleaning this genetic model what we want to do is we want to minimize the KL divergence between P hat of X and P of X P of X was the true distribution of the data and P hat X is the distribution of the generated data so we want to minimize the scale divergence and while minimization of that you try to update the parameters of the generative model so that effectively or eventually your P hat X becomes similar to P of X so as we have shown that the blue reagent in the previous diagram that was your probability distribution of the real image what is the black dots that was actual images from the true distribution actual images samples from the true distribution P of X generative model for which the parameters are theta this gives you our distribution which is P of X P hat of X then this was generated by taking points from sampling points from and unique from say a Gaussian distribution and then theta is optimized by minimizing KL divergence between px and P hat X and eventually the green distribution initially that starts randomly and then gradually it aligns for the blue distribution as was shown over here so the green distribution is the distribution of the generated data and the blue distribution is the distribution of the real data so initially green distribution starts at random and while the training goes on this green distribution eventually becomes similar to the blue distribution so this is how the generative model works so in generative adversarial Network which is popularly known as Gann the main idea is to have two neural networks and they will compete with each other in so effectively it's again a game theoretic approach one of the neural network is a generator that samples jet vector from the latent space and tries to produce a realist example and the discriminator Network which is a competitor of the generator Network or adversary to the United Network that is why it is adversarial Network so there this the discriminant network it tries to distinguish between the fake samples which are actually coming from the generator and the real samples which are fed to the discriminator to decimate between the real samples and the generated samples now called as fake samples which are generated by the generator so while this contest goes on eventually both the generator and the discriminator both of them learns the distribution and this is implicit it is not explicit unlike in case of variational automatic order so this is what is our network in fact let us assume that D X represents the probability of belonging to real class for a given sample X so the discriminator will try to decrease DX for real samples will try to increase the X for examples because it wants to distance between the real samples and the fake samples or the generated samples so X being input to the discriminant network if this X comes from a real sample the discriminator will try to increase T of X that is its probability distribution whereas if this X is a fake sample which comes from the generator Network then the discriminator will try to reduce D of X in turn generator will try to increase G of X for its own generated samples and that is how they are locked in a game so by doing this now there are two training components one of the training component is training of the discriminator and the other training component is telling of the generator so for training we need the cost function so for training of the discriminator as we said that decimator wants to maximize the probability for the real data and it minimizes the probability for the generated data or effectively it maximizes the probability or log likelihood of 1 minus D of GZ what GZ is the data generated by the generator Network from the latent variable which is said so while training the discriminator it is an maximization operation where it is maximization over the log likelihood log of DX plus the value of estimation value of log of 1 minus D of Z said so maximization of this will train the discriminator on the other hand the second component which is training of the generator obviously the generator wants to maximize the probability of its own data which is generated by the generator itself so it tries to maximize log of D GZ or expectation value of log of DZ set so you find that these two are in opposite direction the discriminator tries to minimize dzz probability of the probability distribution of the generated data on the other hand that generator tries to maximize log of DZ set so they are actually working in the opposite direction in effect what is done is the generator is trying to fool the discriminator so that disk Lemaitre cannot discriminate between which is the real image and which is the fakeness and while doing so both of them learns the distributions so this is just what is shown as the algorithm how the generator and the disk mental networks are trained so given a set of noise samples or the latent variables dead the generator network generates a number of data samples using these data samples that discriminator tries to maximize the same cost function which is log of DX plus log of 1 minus D G of Z and once the discriminator is learnt it stabilizes then you come to the training of the generator wherein you try to maximize D of G Z G said okay so these two training operations disco training operations occur one after another effectively making both of the generator and that discriminator quite strong so this gain has been applied in many application domains there was a paper in a cellar in 2018 where this generative adversarial network was used for synthesis of high resolution images so this particular slide shows two images which are synthesized and you find that though the images are synthesized but they are really looking like real images right so that shows what is the power of generative adversarial Network it has also been used for image to image translation so this is a semi peer paper in 2017 so you find that given the semantic segmentation of a scene using the generative adversarial network it is possible to generate or possible to synthesize real looking images similarly from the input levels you can also generate real Duke images given black and white images or grayscale images you can generate color images so all these are possible using this generative adversarial Network this shows another one that if we have a sequence of input frames which are basically semantic segmentation of different frames then it is possible to generate a real looking video in different style again for that we have to train the generated generate a network and the adversarial network in a proper way this is a piece of work which is for image in painting him as in painting si is a problem where if you have an input image where there are a large areas where the information is not available or the image is damaged so we can try to fill up those damaged regions using the information of the overall image so this generative adversarial network has become very effective in that area also so for that what you do is you use a generated network which is pre trained over the domain of images which for which we want this in painting operation to be active and then use this generator network to generate a real looking image and then our aim is that when we compute the cost function the cost function will have two components one is the perceptual component where the discriminator tries to discriminate between this generated image or the fake image and the real image that means how realistic this generated images so that gives you our perceptual loss and another loss component which is contextual loss the contextual loss says that okay there may be some portions in the image for which the information was not available or it was damaged but the image which has been generated of the reconstructed by the generator in that if I take that portion of this generated image which is matching with the undamaged part of your input damaged emails this undamaged part of the input damaged image and the corresponding portion in the generated image they should match and that is what gives you the contextual loss and what you do is you try to minimize both of these losses the perceptual loss and the context were lost and while trying to minimize this in go on updating the input vector or the latent vector and given a latent vector you are getting the generated output we had done some piece of work on this where we have done some improvement of the previous work where what we have done is we have added we have used two type of loss one is the data loss which is similar to the loss function which has been used by this previous authors a at all or they have published this work presented this work in cvpr 2017 this is a recent work that we have presented in ic 2019 in Taipei where in addition to data loss we have also introduced another loss component which is the structure loss and in order to improve the computational complexity what we have done is we have taken random samples obtained samples from your latent space and for each of these 10 samples we have generated 10 images using the generated Network and out of these images you have taken we have taken that one which is closest to the damaged one the damaged input image and the corresponding latent vector now as it was our initial vector and we updated on this so using both of this we have found that computationally our method has become much more efficient and at the same time that reconstruction because we have introduced a second loss which the structure loss that is in the gradient stress so introduction of the structure loss also has improved the quality of our in painted images so this shows the output you find that the images in the leftmost column these are the damaged images which are frayed to the generative and versatil Network the three images in the middle middle column these are the outputs in generated as reported by a at all in their Civic year 2017 paper and the rightmost column is the output that we have obtained and this has been as we have said that this particular work has been presented at International Conference on him as processing 2019 at type II the same concept we have extended for video and painting so in case of video in painting because as you know that video is nothing but a sequence of frames played at a particular frame right so what we have done is we have grouped those frames into something or called group of friends and we have tried to do the in painting for every group of RAM so for that we had the first group of the frame first frame of every group was in painted using the same concept as we have applied in case of images and that particulars eight vector that you get that is applied to four in painting of all the frames in the same group and if I take say a frame Z T minus 1 an initial vector say t minus 1 4 of em t minus 1 finally whatever the final vector we get at convergence that becomes the initial vector for the next time and using this also we have observed that our computations is much more efficient than if we use frame by frame as proposed by a at all of course a it all did not propose it for the video they proposed it proposed their technique for the images so what we have done is we have used to their technique for different frames in the video and this particular set of video sequence tells you what are the computations that we have obtained so on the left most one the video samples these are the damaged video sequence in the middle as we said that what is obtained using the approach of a at all and the right two columns the right two video sequences are what we obtained using our technique and you find that apparently the output that has been given by our approach using this Gann based approach for unsupervised semantic imprinting this appears to give better result and what you get using a at all so with this we come to the end of today's lecture and in fact to the end of this particular course on deep learning I hope you have enjoyed the course and you have been able to learn the different methods of deep learning their applications their optimization techniques of course we have started our course with the conventional machine learning techniques where the feature extraction is manual and then you use the machine learning techniques for feature classification or the data classification there and then we have moved on to deep learning or even the feature extraction part has been made part of your machine learning approach and we have talked about different types of networks that deep neural networks for deep learning applications for machine learning applications and this variational auto encoder or the generative and versatile network which are used for generation of the data or reconstruction of the data or synthesis of the data this is these approaches are actually the recent trends in a declining domain so I hope you have enjoyed this course and the course was really useful for you thank you 