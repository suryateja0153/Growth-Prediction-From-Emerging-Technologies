 thank you for coming out on a Monday night it's actually quite like I think it's more people than we expected which is pretty good we'd like to thank the Science Gallery for for hosting this and to Accenture The Dock for sponsoring this talk and I think this has been a long time coming I think there's been a meetup group that's been around for a couple years I just moved here from Toronto and I was like Connor we got to get this started and so this is the first inaugural designing human AI interaction meetup talk and the first of what we hope is many and we're gonna be doing a series that we're calling designed intelligence these are talks that explore tools methods technologies and ideologies that are shaping human AI collaboration and interaction and and on that note I'm just gonna I'm just gonna get right to it I'm gonna invite Connor Upton up here and Connor is the group design director at fewer Dublin it's situated when within Accenture global innovation hub The Dock who sponsored this talk as group design director he's responsible for design craft across the organization leading the evolution of design practices to embrace data algorithms and systems thinking Conor applies human centric approaches to the design of complex work environments and has published and spoken widely on this topic his projects cover multiple domains including Public Safety manufacturing sustainability and he's interested in how interactive visualizations can support collaboration between humans and AI so welcome Connor the stage oh yeah so thanks again for coming out as Rob said we're based down in the dock which is a centers global innovation hub looks like this it's an interesting place to work as a designer we are a team of about 45 designers that sit alongside similarly sized teams of data scientists software engineers and we operate underneath the banner of pioneering conscientious innovation so looking not just at the technical aspects but also what are the human and societal impacts of some of the innovations that are happening so we're a place where we work a lot on projects pretty much all of our projects touch on artificial intelligence to some degree or another but we're also a venue for clients to come in and bring in some of their strategic problems and to see how design innovation and technology can help them tackle them so we're kind of a venue for clients to come in and over the last year - we've had a lot of clients who've come in who are curious about AI who are sometimes concerned about AI but more often than not they're actually very confused about what a is and it's not surprising that they're confused because the term nowadays is kind of synonymous with with technology which it's it's kind of everywhere the hype cycle is really big and it leads to confusing things like this flower dog which James one of our designers was playing around with I think was gain breed or use it's a it's a nice nice piece what's confusing about AI well part of what's confusing is it's in our lives already I mean it's everywhere this isn't robot citizens and Terminator we're all interacting with AI every day it's on our phones categorizing our friends it's allowing us navigate the world even were unfamiliar with it most of us are experiencing it because it's telling us what we should watch for what we should listen to and while there is AI in all of these it's deeply embedded in products and services so deeply embedded that that most people don't even think that it's AI and this was predicted by john mccarthy one of the pioneers of AI he said soon as it works no one calls it AI anymore and I think in this case he's right but that's confusing for people you know it's just an app the other thing that's confusing is artificial intelligence you know it's early uses were in the areas of categorization of big data or prediction of future trends based on large volumes of past performance data but AI itself is evolving all the time and it keeps evolving I don't know if people have seen this this is a tool from Autodesk who makes computer aided design tools it's called dream catcher and this is what they call a parametric design product I'm hoping this is gonna play yeah so in this case what designers who are making a product do is they set the parameters of the thing they want to design you know the strength the amount of material they want to use and then different forms of the product are generated by the AI automatically in this case it's the chassis of a motorbike and you can see they can look at see all of these different versions of what the thing may look like and then they can play around with the vectors to choose what's the best solution so this is this is confusing because this is this is you know relative to the other things pretty pretty far out there and they are it's also confusing because more and more we're starting to see its unintended consequences when we see AI apply to web-scale platforms and AI deployed at speed at scale we're starting to see some issues and this includes things like gender bias I mean there are have been a litany of examples of that most recently the Apple pay card that gives higher credit ratings to men and women we've seen it with racial biases in a range of different examples again most recently in terms of healthcare access in the u.s. we've seen other issues things like complacency where people become over dependent on AI and there's a long history of this in critical systems domains but most recently again we've probably seen it in the rise of autonomous vehicle crashes where the human thinks the AI is just going to look after everything and then and then stuff happens and we're starting to see it on some really really strange weird places places I think we didn't think it would go which leads to the things like this so that's very strange what you're looking at here has anyone got kids in the audience yeah okay I have a four-year-old who I've given in like many parents and let him watch a bit of YouTube when he's freaking out watching YouTube but I've stopped us basically because I've read an article but James bridled who's a researcher an artist who was he brought an article called there's something wrong with the internet and he identified how bot generated content and comments we're targeting the ad revenue around kids YouTube and kids nursery rhymes so they use common nursery rhyme tropes and famous characters to try and game the recommender engine so this would come up in the auto feed and this is just weird there's loads of thousands of versions of these these have started to be called now but actually a lot of it had very you know unsavory content violent sexual references stuff that you wouldn't want to show to children so this is confusing you know I think having Kelly summed it up well in this book the inevitable he was talking more broadly about technology but he says said in it we're morphing so fast that our ability to invent new things at paces the rate we can civilize them and I think this kind of triggers a lot of the concerns that we see today about AI and where is this bringing us it's bringing us to the strange place where organizations who largely are building and in control of artificial intelligence are are diverging their views from from the general population from people in general so organizations are accelerating their use and adoption of AI but at the same time the general public workers consumers are starting to grow weary of its potential effects on their lives and they're certainly becoming a lot more aware so this is an interesting point in time and you know we've been doing some research into this and reflecting on it we've we've seen that when you design for artificial intelligence it actually also means designing for human intelligence designing for the intelligence that builds and controls it designs for the and that has to use it day in day out and designing for the intelligence that gets affected by it and that sounds like a lofty goal within the program we're trying to look at how we can unlock the full potential of both human and artificial intelligence in a way that's more symbiotic in a way that they can collaborate together this is a broad program of work we're looking across different areas like in forming strategy like in informing how systems operate and also looking at how we can enhance the human experience by giving people capabilities that they didn't have otherwise and we have a range of different tools and activities we do around this but in this talk I just want to step into one which is called we're calling it the AI creative matrix can I just get a show of hands who here would identify as a designer of some description okay yeah and as a technologist okay all right so yeah largely a 50/50 split I think so let's dive into this so we've already said how AR is quite confusing in the midst of all this confusion how should we even start to think about it how should we come up with solutions that can use it in a way that that is more resilient more flexible this is a challenge we face a lot as designers when we're told to look at tech problems but also for clients who come in and the difficulty is the barrier to entry around the term AI is actually quite high like I said we sit with a lot of data scientists with a lot of experts I think typically when you ask a deep expert what is artificial intelligence more often not they kind of go you're using that AI term when they want to get into the details of it they probably give you some of the technical terms around it so quite soon you hear about neural net to hear about random forests you hear about all of these accurate descriptions of the models that drive AI but certainly for a lot of our clients and for most people who aren't experts it's very difficult to associate those with the lived experience or the problems that you're trying to solve around so what we've been doing and when we found helpful Iced actually reframed the technology in more human relatable terms so we don't talk about computer vision we talk about seeing we don't talk about natural language processing we talk about reading we talked about hearing Torche recommendation creation and by reframing the technology in these terms you actually democratize the ability to id8 around us people can start to see how these terms could be brought in to support some of the some of the activities that they're facing and we've built an exercise with this that we run with client workshops where we essentially use Design Thinking methods to get them down to what is the core problem they're trying to solve so I have my twe statement then we quickly bring them through micro lectures around what these technologies are industry examples we give them like three minutes to id8 how this technology could help solve their problem and very quickly you can get everybody from my CEO level down to somebody who's working at the coalface to actually promote put ideas in the context of the other work they're doing so I'm gonna use this as a way of explaining how we use it but also to show you some of the work we're doing at the dock so let's jump right in I'm sorry at the dock and broader across the fiord network and the essential network so when we talk about seeing computer vision is probably one of the most you know widely known forms of AI that's out there and computer vision has gotten incredibly powerful um a number of years ago fueled published a trend where we talked about taking things off the thinking list so how technology can help us in our already very busy lives and when you think about it we're already carrying around these extra eyes in our pockets so the cameras that are sitting on our phones were all around us so our studio in Austin was looking at how we could use this to improve a consumer experience working with a large retailer in the u.s. I'm just going to play a short video here so this is computer vision with augmented reality with recommendation engines all interweaved into a product that can make the consumer experience better so it's interesting in consumer experience but when you look towards more expert systems I think this is where I can get really interesting because they are I can allow us not just make our lives easier but also go beyond our own capabilities seeing things that are imperceptible this is actually some research that came from MIT a couple of years ago that I just think is really amazing this this baby here in the picture I don't know you probably can't see it but that baby's breathing it's hard to actually see that at the moment what what the researchers did was they found a way to detect very slight variation within that video feed and then feed that back to Rhian Hance the video so they can be detected with the human eye so that's pretty impressive there's another example of it here where they did the same with heartbeat and while this allows you as a human to observe these types of you know these types of signals of the body it also provides another way to gain those signals so if you think of an immuno compromised individual like this allows you to you know start to move away from body worn sensors into and the impact that that might have for those patients or even the patient experience I think is pretty a pretty impressive so if we go beyond to another sense then what about reading so it's as humans we read to learn about the world to get the opinions of others to try and understand or the people's views and that's great but there's limitations to our capacity to read it's a it's a it's a serious serial process you can only read one book at a time what if we had to understand a huge amount of text or vast opinions from many many different people you're probably all familiar with NLP and how it's been used for things like sentiment analysis and social media we've actually been using it within our design practice to help us augment our user research there's a project we did recently with a large insurance company who wanted to understand their customers behavior the customers lives because they wanted to move beyond classic insurance products which is essentially a premium that you renew once a year into more digital health services so how can we support people aging their health particularly things like chronic care now it was interesting is there a data-driven company their insurance agency they have loads of data but most of their data describes customers in terms of risk the risk that they carry not in terms of their pain points their lived experience so they asked us to do some research but they wanted us to cover a lot of people and in a relatively short period of time so I want to just play another video here that shows an example so again this the idea here is not to automate the user research process but using technologies to allow us enhance the scale of which we can carry it out so what about hearing again this is another sense and probably one that people don't really think about when they think about AI but more and more we've got conversational agents within our lives within our homes when we pick up the phone and ask for a service and again we think about this a lot in customer care services but what if we had to push this out into its extremes we worked with a large policing organization to what's probably not coming up super clear there to look at how we could augment our emergency dispatch so emergency dispatchers and is a challenging is it's challenging work you have a lot of agents who you know people dial 911 999 and they're talking to someone about a stressful situation but at the same time those people who pick up the phone many of them are not touch typists they could be police or offbeat they could be you know citizen police officers or support staff but they have to fill in a very complex form very very quickly speed is really essential you want to get the services out as quickly as possible but you also have a job of keeping the person calm keeping them on online keeping them safe so they asked us how we might be able to help solve for that and we again I'll just play this video so again what you see here is the ability to use the technology to accelerate a process to augment process to improve the data quality but not to replace the work because you're never going to do that you need to have that human to human relation in that stressful environment so moving on to another sense what about touch a lot of the time when people hear AI they think about robots robots are not AI but AI is changing the nature of robotics over the last couple years we've seen a whole new generation of robots these cobots that have been used in factory settings in other settings as well robots have been used in heavy industry for years but typically it's used to do highly dangerous tasks like spray-painting cars or lifting up chasis but the robots themselves are dangerous people were traditionally kept away from them new rage of cobots Loretto are flexible there you don't you can actually train them through physical manipulation so moving the arm around getting them to do something and then say do that repairs and times it can go and do it and that flexibility then makes them a lot more adaptable you could do a lot more different tasks with them we've been playing around with robots at the dock this is something we did for for a large innovation show where we were racing individuals against individuals paired with a robot where they had to build a robot it was a little bit yeah inception but um and it was yeah I mean it was a really fun experience for people where we could actually outsource somewhat the precision manual tasks to the person while still having them deal with the cognitive tasks and recommend so again as people we love to recommend we love to predict we like to think we know people and we can see what their habits are and give them good advice and a lot of us will have encountered recommendation engines again through media platforms things like Netflix things like Spotify but IOT and the ability to put sensors everywhere opens up the space for where we can recommend and how we recommend there's another project we've been running under the codename the last mile and what we've been looking at here is it's actually the challenge is that Postal Service's face so the purse Postal Service model is is kind of if it's in a serious state of decline when you think about a postal service it was built in the Victorian era around the idea of putting a letter through the letterbox of your permanent abode once a day but that loses relevance in a world where people expect fast flexible parcel delivery to wherever they are but these services typically semi state or state Ron comb with you know they have a lot of work force already in there they have big infrastructure investments how can we how can we help them to to pivot to to kind try and deal with challenges that are emerging from saying day delivery services so we looked at things like demand prediction like how wicked optimized routes around the city to try and allow them move from a that static model to a continuous collection and delivery model and some of the interfaces you're seeing here these are really really critical these are the interfaces in this case for some for the for the dispatcher in the command center but we also have interfaces mobile interfaces for the delivery agents because these are people with years of experience and they have access to data that the optimization engine doesn't so if they hit a scenario in the world how does that information get back so we've provided the ability for them to set these dynamic constraints out in the field based on their lived experience out in the field and get the AI to do the heavy lifting and this is really important by keeping it collaborative we can help help ensure its adoption by existing workforces and finally create we talked about dreamcatcher earlier on and we have we're so lucky to have Jean here tonight who's really kind of you know in terms of computational creativity and generative art he's he's really at the forefront of this many of you will probably have heard about generative adversarial networks or you know they're using deep fakes but it goes way beyond this this is a project for Microsoft Research this bird over here doesn't exist in the real world this bird was drawn by an AI based on the command for draw me a yellow bird with a black black wings and a short beak and this is what I produced which you know I think if you're not an ornithologist this is this is pretty good it's better than I would draw anyway so gene will show a lot more work in this type of space we've been playing around with it in other areas we have clients in food production and one of them came in looking to see how can we actually use AI to help us come up with new products new flavors new flavor combinations so the team at in technology labs or essential labs came up with a knowledge graph that allowed them to recommend these unusual yet delightful combinations of flavor and then we set up a little test kitchen and started to try and build out some of this stuff so it's combining the computational power of the algorithm with some of the creativity of the people that we work with including some of the folks in the kitchen who produced these very nice AI inspired tapas which we then fed to clients as part of a workshop on on artificial intelligence the more in the middle there is a bitter chocolate pool on a Parmesan crisp so it's kind of like a chocolate taco and you'll have to take my word for it but it was pretty good so like I said we use this framing to try and democratize the process of how we think about artificial intelligence how we can actually allow everybody to say okay well I have an opinion on this and I know the problem space so I should be able to give my opinion and actually start to see how we can solve problems and we think this is really important because when you show clients the power of the technology a lot of people move straight to this idea of oh well I have human eyes who look at this thing but now technology can do it so I can cut down my workforce and this is fine there's this big jump around automation that people instantly go to but the reality is AI machine learning tends to automate tasks not jobs jobs by and large are messy they're a lot more complex than people usually say they are and this idea of being able to swap out an AI for an entire workforce I think has been challenged and certainly as we look at it over a longer period of time so we're looking to try and move people from this automation mindset that focuses on workforce replacement to designing work more as a living system so thinking about ok this work exists to do a certain process or a certain task but actually there's feedback loops in there we've got points where people interact with the data or the product we got points where we might be able to put in AI or machine learning or robotics but we have to understand what happens when we put that technology in what does it do to the rest of the system what kind of knock-on effects can it have and this is where we've really been focusing in on systems design as a new capability that we're developing so like I said this is one module within a much broader set of work that we're doing and as part of the the series that we want to run on this that we're running on this will touch into some of these other points things like how we design collaborative AI how we take a systems thinking approach to designing solutions in this space if you're still interested and you want to find out more on this there's a the good news is that the barrier to entry for exploring AI in a more creative way has dropped really significantly over the last decade so there's a range of websites resources feel free to grab a pic about if you want it elements of AI is a really good onboarding algorithm design phenomenal to see how the design industry is being changed Google runs a lot of experiments and I like that some of these are absolutely mind-blowing distill that pub with great articles in there and building blocks a few words we published under medium under a channel called design voices and also the dark actually has a medium channel as well when we publish all of our work and also gene has his website and gene we've been fortunate have Dean with us for the day doing works up with us I strongly recommend you explore and some of the work he's been doing here it's really really great stuff so yeah we feel this is important for designers and for technologists to start to talk about these issues together again just to leave you with a final Kevin Kelly quote in his book he states this isn't a race against the machines this is a race with the machines and I think it requires multiple disciplines to come together and hopefully we can build amazing stuff like this guy who built a robot that feeds him tomatoes while he's running I don't know what he did us but um but he's kind of a hero of mine so that's it thank you so we'll do a Q&A session at the end but I'm delighted to be able to introduce Jean to you so Jean is an artist a teacher a programmer he explores autonomous systems collective intelligence to narrative art and computer science science so it's interested in advancing scientific literacy through creativity in play and building educational spaces which are open and accessible as possible and again Gina point you to some of the stuff he's published on his work alright so hi everybody thanks for having me and these guys earlier at the workshop this is my first time here in Dublin in 11 years and I was just here once back so I'm gonna just kind of dive into my work is it gonna try to make this a short talk and I have like way more slides than I really need to and so I'm just gonna blast you with stuff so let's see how it goes I'll tell you really quickly about myself I had this fantastic ok great ok I have this I have a background in music and machine learning so that's kind of how I got my start I originally was working with a sort of mad scientist friend of mine who was developing musical instruments and trying to create systems for these musical instruments they don't make any sound it's just the controller that has a bunch of sensors on it and then we try to create digital in digital synthesis instruments and virtual instruments and then control them with this you know this sort of flute looking flute looking thing and the only way to really do that properly sort of mapping sensor parameters to the general synthesizers to use a machine learning you let it you let a musician kind of train the instrument to play in the in the way that they wanted to be played so you know the the trainer is holding it in a certain way and if it's held this way and they wanted to make this sound and if it's hell that way they wanted to make that sound and then machine learning is used to kind of fill in the gap between all of this relationship between the inputs and the outputs and then you get working synthesizer and so this kind of got me on the path towards creative AI because it's a sort of dry academic question you know sort of how to create mappings from sensors to digital instruments but of course it has this sort of creative element to it and that got me interested more and more in the creative sides of of machine learning and lots of people were asking questions like can we use this for real-time music production can we use it for you know creating interesting digital tools you know Ableton Live isn't it for those of you who are musicians you might know Ableton Live uses a lot of this kind of you know scientific libraries to automatically figure out how many beats per minute your audio is or figure out how what the chords are and things like that that help you as a musician let's get that so I so this kind of guy I started working a little bit more in a visual domain and one of the things that I became interested in is this technique in in deep learning which is kind of the ascendant form of machine learning today which visual which tries to visualize what's going on inside of neural networks and neural networks are these machine learning algorithms which detect patterns in data and they detect patterns in this sort of compositional almost hierarchical way so patterns on top of patterns on top of patterns and the question is what patterns are they are they visualizing because they do so much of it autumn automatically and so there's research into this that goes back 10 years trying to synthesize images which maximally activate a particular part of a neural network so let's say you have a neural network that is optimised to detect bell peppers well then the question is what is the perfect image for this neural network so as to make the bell pepper neuron go crazy and so it's something like this right and of course originally this this work was purely academic in nature because it was just interested in creating tools for for scientists to visualize data but but years a few years later it started to look prettier so this is kind of going back to 2015 a the release of a package called deep dream or Inception ISM which was a technique for doing this exact same kind of visualization process but in such a way that produced much more interesting pictures so this is what a the optimal banana looks like in the optimal starfish and the researchers went even farther with this they they started making art because the idea is that this is a process that optimizes the pixels of an image towards some objective and the objective in the case of the bell pepper was to maximize the bell pepper new neuron right but then what if you instead turn the process around and say okay instead of telling it what objective I wanted to have instead I'll put in a real image and then look at all of the activations of the neural network and then make them all go higher try to make the neural network go crazy for everything that it thinks it sees so it's literally hallucinating making the neural network hallucinate and you can feed in images of pure noise and it'll find something it'll find some pattern in the noise and then keep on enhancing that pattern until you get these kinds of vivid vivid looking images so this is the original researchers work Alex Morgan's have Mike tyka doing all kinds of crazy stuff I got really interested in this technique I'm gonna show you some work I've done in the space so I started making these kind of so like as an artist I'm really interested in getting more levers of artistic control because you know machine learning kind of takes them away from you ai is kind of doing everything by itself right and so how can we get back some of those controls you know compass for doing composition right and the idea here is that you can maximize multiple objectives at the same time and combine them with masks so these masks are kind of sort of telling the neural network I want to enhance this pattern over here and I want to enhance that pattern over there and then the what the most interesting aspect of this is that in places where you're kind of blending them are transitioning them you see that the network hallucinates these patterns that kind of maximize both neurons at the same time and so you get these transitional patterns that you see at the middle here and using this approach you can create images like this so this is two neurons again kind of linearly interpolating between the both of them and you see in the middle there's you know it looks a little bit like both like there's this kind of gets the extremes of both pattern into a sort of mellow transitional zone let's call it and then you can come you can arrange the masks in circles as you see here or you can do all sorts of interesting things you can create videos and so because there's always an input image to this process and so if you want to make video you just make one image and then you use that as the input to the next image and use that output as the input to the next image and you do this in a sort of feedback approach and maybe you even distort the canvas as you do it maybe rotating it or zooming in or something like that and you get all sorts of you know interesting looking shapes so these are just some highlights of it here's using masks from actual images so this is an eye and then you know you just kind of segment the eye and then use each of the regions as masks and for different neurons and they they tend to blend really nicely and so I really enjoy that approach so a little while ago I was angry at Twitter you know as we all tend to be because but I was angry for different reasons most people are angry for some some current events or something and I was like I don't like this 15 megabyte rule for for videos I want my videos to look longer and so I figured out a way to actually create infinite loops of these deep dream rotations so here if you're if you've noticed you probably have noticed but this is there's actually a six second long video and it just loops these are actually it's actually three seconds long I think the videos six seconds long but the loops are three seconds long and so it looks like it's it looks like it's expanding outward but it's actually never going anywhere it's kind of like a Shepard tone a little bit if anyone's familiar with this auditory illusion called a Shepard tone really interesting thing don't want to go in too much to tell about that but yeah infinite loops saves the day so more infinite loops this is so these are texture synthesis this texture synthesis and approach to taking some random image and synthesizing it synthesizing images that look like you know look like the texture of that image so this is using the Great Wave off Kanagawa as the as the source texture famous painting from Japan and taking Kandinsky again this is three seconds long it's just going in from loop and then this right here is google maps and you know it's kind of like if you ever have a dream and you're looking at your phone and you're zooming into google maps and it just never never terminates this is what that would look like I think more of these loops so you can you can compose with them in various ways right you said the point is that with these approaches you know there's less magic now you know it's not just neural network make me a crazy image it's that I can actually kind of control it a little bit I can say okay I want these patterns to go in this direction I want these patterns to distort in this way and so on and also using masks of other images so I'm sure you recognize the the person on the left maybe not the person on the right though I'll give I'll give I'll give five dollars to anyone who knows what that is I I was I was gonna say like a hundred bucks and then and then I realized like no this is a bad bet okay so style transfers same thing as texture synthesis except you have sort of you apply it to a particular content image and so this is the Mona Lisa and a style of Van Gogh hokusai and Google Maps my favorite source texture of all time and you see that it's it's remarkably accurate you know you really see the the patterns in great detail and so you see all those little google markers everywhere yeah so this is an information I made called cubist mirror and it's exactly what it sounds like or at least it was the first version of this was just a mirror that would turn you into a cubist painting now it's actually not just cubist paintings it's it's all these other styles but basically you get in front of the mirror and you see yourself in this iconic painting style kids really love it and so I'm available for weddings and bar mitzvahs and and events so please let me know and okay let's talk about generative models so this is where things get really trippy generative models are probably one of the most exciting areas in the world of deep learning it's the kind of thing we weren't really able to do in this in this way up until maybe three years ago and it's just getting crazy so we can make hyper realistic looking I mean maybe these aren't super realistic but but you know pretty impressive looking images that look like they came from you know datasets of cats or cars or you know TV screens and things like that and these are these are increasingly becoming realistic and so even a few years ago you wouldn't have been able to do anything like this and I've been really interested in generative models as person interested in generative art generative models of course being you know probably the most powerful generative algorithms that we have and so there's kind of two categories of them this is my workshop mode coming out my teacher mode coming out I'm not going to labor the auto-encoders and Dan's but if anyone's been keeping track of the field generative adversarial networks and guns they kind of take all the press all the all the sort of exciting press but there's actually a lot more to it and ganzar pretty really really amazing and interesting and yeah we don't have time to get into details but I'll just show you some cool things that I've done with him the original authors I always love to credit the people who made this stuff work because they don't know they don't show up in the press anymore you know everyone's like I made an AI do this this and that and it's like these no these guys did so this paper first showed the application of of Gans to making images that looked super realistic like face is and actually this doesn't even impress people anymore does it in 2015 we thought this was mind-blowing you know but but now it's actually kind of small and weird-looking and now it's gotten a lot better the state of the art but in 2015 this was crazy and they showed that you could do arithmetic on the features so you could basically do this kind of cutting and copying and editing different features that will so you could be like okay I want I want to take the smile off this person you know so I find the smile factor and I subtract a smile vector and then I produce you know an image of a person without a smile or here I I find a gender vector so I subtract man plus woman and then I bake this man with glasses - man plus woman equals woman with glasses you could do this kind of neat arithmetic tricks on the generative space and my first project with this I was it was shortly after the first software business came out I was working with this data set of handwritten Chinese characters and I basically applied a DC gam to these and generating fictitious kind of well fake versions of real characters let's say and this was a project called a book from the sky a named after the work of a Chinese artist named Xu Bing who had been fabricating actually fake like fictitious characters out of wood blocks for a long time he actually lives in New York City and and so this kind of shows you the latent space of Chinese handwriting and you know people have just like just like with us we kind of write in different ways and you know there you can see that some people have blocky letters and some people have you know write their loops differently and so this kind of lets you visualize that process you can do even do interpolations between different characters and so this is kind of interpolations between sets of related characters and with nice transitions between them and my in my sort of half-baked imagination the way I think of this is Chinese writing is pictograph pictographic so you know you have assigned four different characters right or four different words or different concepts right and you can think for me like you know why isn't there a word between people in culture you know maybe there's like a concept between people and culture and no one ever bothered to us the character to it you know so this is we have this whole sort of continuous fabric of possible words and then the points that we actually have characters for you know those are those are there but then this is kind of lets you model that whole space so that you can anyhow same thing but but this is actually holding the so Chinese characters are divided into two hundred fourteen radicals and radicals are these sort of base root characters which in the characters that belong to a particular radical they all have this related history and so you can actually hold in some of these interpolations the rat the radical is preserved it doesn't break up even though it changes form in different characters over the centuries it's kind of lost its shape in various ways doesn't always work but I cherry picked some examples to do and then this one is kind of a joke because we have this you know the whole arithmetic on features thing so you is in the the one that we always use in word vectors is this kind of like if you if you do Kane - male plus female you should get Queen now this is not the character for Queen doesn't it doesn't actually make any sense but but it's kind of a this is a joke that only scientists would laugh at so I should really do okay so these Gans they have gone from literally being 32 pixels and five years ago to life-sized you know like there's a thousand twenty-four pixels this is not a real person it's totally fake face and all of these faces are fake so it's it's just crazy where we're going with this and I think by 2020 I think we're just gonna have like totally giant-sized Ganz all over the place and they're becoming more and more realistic so this is some work from deep mind making fake dogs and mushroom this is one model that produces all of these so it's really it's really really like incredibly you know yeah incredibly realistic and and trained on many things not just faces but train them many things artists love guns you know there's lots and lots of different artists who are exploring these many of them are actually all of these are my friends now which is really great we've kind of found each other through the internet and there's been just like lots of yeah lots of actually not this person because I don't know who it is this is anonymous someone made some generative ramen on reddit so but the other people are good friends of mine okay so here's another again on trained on one hundred thousand paintings from wiki art so this is I downloaded 100,000 paintings from wiki art this is kind of the last big one that I trained and it makes fake paintings they look like you know historical sort of paintings abstracts and landscapes and you know all of the all of these different kind of features that you might expect to see in lens in in classical paintings and yeah everything else just kind of gets gets to be more and more like like my talk is gonna become more and more sort of nonsensical as we go this is a this is so I showed the hyper-realistic dogs and everything that was a big that's a again called big gun and began was trained by deep mind and they released it online so you could do all sorts of things with it so I thought I would have some fun with it and one thing you can do is to try to mix different classes together so you go okay I want to generate a dog or I want to generate an owl well maybe I want to generate both a dog and an L at the same time and so that's what this looks like this is basically the owl dog this is another L dog it looks like a character from Harry Potter right like this should be in Harry Potter it's just like the wise owl I think something like that this is cool because it's an owl plus a cat and it looks like a Snow Leopard it's kind of a Snow Leopard looking thing this is a mop dog of some kind a crown this is a now it's just yeah it doesn't make any sense it's basically an owl plus a crown or a throne yeah this is a dog plus the felines really adorable so I just kind of thought about in there this is my favorite so this isn't yeah so this is an orca like a whale and a tram and it looks like a ferry right when you combine them makes total sense Oh what's this missing oh yeah so this okay so here's the what's going on here so I downloaded a video from Planet Earth you know the show planet Earth and so this is some sequence from Planet Earth and from every frame I did a prediction of what the image has like the you could do you could classify an image into into a probability over all the different things that's in the data set then you take that probability and you feed that to big-gun so you basically get the began to try to regenerate the movie and so whenever it's these birds it generates birds whenever it sees penguins it generates penguins and so on and so I had limited success with this but it kind of worked really well with animals so the planet Earth was was the kind of one experiment that worked really nicely at this now this is there's a category of generative models that translate one image to another so you can generate you can train for example a neural network to take an image of a place in the daytime and convert it into the same place at night right and this doesn't look that good but this is kind of actually a few years old it's gotten a lot better this is just the original paper for doing this she trained it to do edges to the two photographs train black and white images to color and so on and so one of my first projects in this it's actually the first project in the space I think was a collaborative project during the workshop of mine actually back with students where we basically downloaded map tiles from different cities and then and then trained these models to convert the map into the satellite image of the same place so then so so then you could do this kind of city style transfer you can take the map tile of one city and run it through the generative model of another city and the end result of that is what we could take a satellite image of Milan and change it into a satellite image of Los Angeles you know so this is kind of Milan in the style of Los Angeles or Milan in the style of Venice and you can see that all of the all of the roads have become like canals in Venice it was kind of the most fine the state of the art of this has also improved a lot so this is actually these are some highlights from Nvidia who released this report this work last year that shows again converting these these sort of label maps into realistic looking for like photographs basically and so it was really kind of really interesting work and also doing things like synthesizing dancers oh just you know really really crazy worker nvidia and using this technique i actually made an installation which is up running now in berlin so if anybody happens to find themselves in berlin some anytime in the next two years you can go to a museum a really new museum awesome new museum called food to diem the future museum it's it's like in central berlin and it's free admission so if anyone's there anytime go check it out you'll see this this is basically an installation that lets you draw landscape photographs so you know you put some rocks over here some mountains over here some trees some clouds and so on and you get sort of realistic looking you know landscape photography it's very similar to some work by nvidia i basically recreated it and but but kind of for the masses let's say and rule number one you put a cute baby in the photograph and everyone loves it yeah so this is this is some highlights of another installation in the same place you this is a playpen where you have these plastic pieces which represent buildings parks and water and as you move them around the playpen there's a camera tracking them and doing kind of the same thing as you should as I showed in the invisible cities project generating landscape photography sorry generating satellite imagery of looks like Berlin so this is kind of a generative model trained in Berlin this is a work that I did with a colleague of mine andreas ruffs card where we oh here I do have so much for God maybe I should skip this if I don't have sound I'll just tell you about it maybe you'll be able to hear it actually from my laptop when let's just give it a shot oh okay all right all right so basically the idea here is you draw musical you draw instruments on paper and it creates music depending on the instruments that you draw so let's let's give it a shot okay little piano put a saxophone some drums in there yeah okay so yeah like I said this talk is just evolving from here so so when when this picks the pick stuff started happening you realized we could we could impersonate Matt we could create masks of people right so you could you could do you could extract the landmarks of a face and then generate a generative model that will convert the landmarks into a particular face and so I did this for the president our president in 2016 and and you know this was kind of like and and this is 2016 this is my hacky version of this in 2016 2017 still a little hacky but starting to look better 2018 here's NVIDIA generating synthetic faces obviously not of the President and and you can see that the state of the art of this just keeps on improving and I'd like to think that my job as an artist sometimes is to warn people about the future because you know this stuff is just gonna be all over the place so this is this is a my favorite model that basically lets me do sort of operations on you could project unreal image into the generative model then do operations on it so here this is me and then this is me with blonde hair glasses and heavy heavy makeup yeah it looked like a 1980s hair rock sort of popstar this is me yeah just like doing all of these operations kind of having fun I like to make myself to joke the butt of my own jokes and this is me being turned into a certain Canadian pop star know so that is this one I'm not gonna make a bet on definitely not a good idea this is me being turned into various heads of state yeah and then this is this is also a practical joke so how many people know face app you seen face up yeah so face app like you know makes you old and young and then it puts a smile on your face this is not my smile this is like definitely not what my smile looks like and so the the the I thought it would be funny or interesting let's say to try to run face app like over and over and over so basically like you put a smile on your face and then and then you take this picture and then you ask face app to put a smile on this face and then you take that picture and then ask it for it to put a smile on that face and you just do this over and over and over so if anyone's interested in knowing what that looks like I'll save you the trouble so and at that point it actually stops and then can't because it can't recognize the face anymore and so you can't do it anymore yeah yeah so there's this repository called deep painterly harmonization which lets you sort of like superimpose one image into another it's kind of like style transfer and so I just started like throwing myself into various you know paintings like hanging out like hey this is super creepy right okay now describe a new project of mine that it's like my my life stream this is this is my ten year sort of this one's gonna take a long time because it's not really practical right now so this I have this idea to make an autonomous artificial artist so what I mean by that is it's so so over the last few decades many artists have tried to create agents that they call AI artists you know so so like one notable one is Harold Cohen who made an art who made a project called Erin and he basically made this this this sort of robot that draws paintings and he and and he would always encode all of his own he would program Erin to make art kind of like him so and many people have made these things that they call this is an AI that's making art but I've always found them a little bit unsatisfying because it felt to me like Erin was really just Harold Cohen and it was Harold Cohen programming a robot so I thought like is there some way I can create a true autonomous artist an artist that's not me an artist that is separate and independent and sovereign and has its own creativity and so on and so and and I and and I think we can do this now and it's combining multiple kind of layers of technology that and and also multiple layers of collaboration to actually achieve this and I don't have enough time to really explain in great detail but but I'll tell you a little bit about my sort of crackpot idea to make this work so the idea to make an autonomous artist would involve creating a generative art program which is a separate agent whose behavior is controlled by a network a decentralized network of collaborators and the artist would have to make unique and original art it has to be original in the sense that it doesn't it doesn't copy from any of us it doesn't copy from any of the people who make it and it's unique in the sense that nobody nobody actually has control of the artist it's kind of like a shared secret a shared secret is this cryptographic term for something that all of us have together but none of us have individually so basically like we all have like a piece of I don't know like a Da Vinci Code secret type thing we all have like a piece of the secret and your piece by itself is useless but all together we we we have this artist and I associate this with autonomy because it's basically it's its autonomy emerges from the collective right and and we get into the philosophy of this but I don't have enough time but basically that's the that's the general idea and so how do we actually achieve this and I kind of looked at a nature for inspiration right I think we see examples of autonomy emerging in nature so for example that the best not not doing students is a different analogy the best example is hives right so we have this term a hive mind right and what is a hive mind it's the apparent mind or presence of a collection of bees or you know if applied to some other kind of collection which apparently emerges from the collective but doesn't apparently exist anywhere right it's kind of this abstraction on top of all of these unique individual minds and so I think that that this is sort of that collective intelligence is a separate intelligence well it's kind of a unique autonomous intelligence and so I'm a and so this is kind of how I think we could build it I think it works really well with deep learning because in with machine learning you have a neural which is which is very very large and homogeneous and can be easily split up and we actually already split up near electrics we when we split them up into different GPUs into different graphics cards and all the processing recombines and so I have this idea to basically make a a peer-to-peer network which splits a huge neural network whose job is to make art and each of the pieces of the network hold a peach of the like participants hold a piece of the neural network and then the neural network produces art and so someone if someone wants to get a piece of art from this network they send a query to the network and then the whole signal this would make more sense if you knew how to work some artwork a little bit which which so in my workshop that makes more sense but the whole signal propagates through this network and then output outputs an image which goes back to the collector and so because this graph is sort of decentralized no one has enough to reconstruct the entire image it has to actually pass through the entire network and so you can enforce sort of like arbitrary scarcity on it you can enforce all sorts of decentralization constraints on it so maybe all of the training data has to come from multiple people and so basically the whole thing becomes irreproducible so the this only this graph can produce this artwork only this network can produce this artwork and there's no other way to do it and so from this I associated with with autonomy like a like an autonomous spirit that's making its own art and I would I know it's really have you know crackpot half-baked idea if I had more time I would elaborate and I actually have a talk online that that talks about this for like a whole hour and a half and so I encourage you to like that if you're interested but the project is called Abraham a little bit of no Maj to Aaron and some other and some other things but there's an article online that I've written you'd go to Abraham that AI you'll see more info about it the idea is it's sort of a grand synthesis of four different fields I think so computer art and AI artificial intelligence philosophy like the philosophy of mind like what is it it means to be a creative autonomous spirit and encrypt and cryptography basically crypto economics the center Asian technology putting all these things together and there's various things that are already at the intersections of all these fields and then there's autonomous artificial artists is smack right in the middle of them and so the problem of course with the idea is that it doesn't it doesn't it's totally impractical right now they're realizing that a bunch of experimental technologies which aren't mature at all do not scale but but there's a lot of good reasons to believe that in the next five to ten years the technologies that it relies on are going to be are going to be much more mature and they're becoming more mature because people demand them so their overlaps a lot with for example decentralized AI privacy-preserving AI secured a and things like that and so yeah well kind of see how that turns out in a few years and it has a whole bunch of like intellectual building blocks are super experimental computer science a lot of a lot of kind of very meaty space and a lot of stuff that I I know barely anything about myself and so I'm at the beginning of a long process of learning this stuff and trying to kind of trying to convince people to join me in this in this sort of process and so yeah that's all my work and I want to mention a few things I run a lot of workshops over here kind of running one we're running a workshop at fjord which has been great this is the first day we'll have another day tomorrow I've done something like 100 workshops in last three years it's been really really awesome really basically almost like a full-time job for me and I put all of my materials for machine learning for artists online on this website ml for a Thai github better i/o and so these are some of the resources basically a lot of applications a lot of demos real-time demos a lot of sort of instructional guides and so on and and the guides are over here you can see that we have something like 30 guides that do various things and and and I also record a lot of my lectures and I put them online I teach at NYU and so the last class that I did where I did a full a whole basically recording of 12 weeks of lectures is online on ml free and so that's basically like 30 hours of this so if you if you want to if you if you want to hear that yeah over there and another thing is I'm an adviser to a new company called runway runway is a basically trying to bring creative AI to the masses it's basically like the Photoshop of creative AI so trying to create an application that you download and you can run all of these open-source algorithms that you can find on github for doing interesting things in the machine learning you can run them locally and so that's all thanks for thanks for having me I went a little over I'm sorry about that but thanks a lot 