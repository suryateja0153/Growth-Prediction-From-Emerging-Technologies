 Hi, I'm Albert Cheu. In our work, we expose an inherent vulnerability: the output of any locally private protocol can be manipulated by corrupt users. The error grows with privacy level and the domain size. The core example is distribution estimation: if we get data from a distribution and we want to estimate it in L1, we need error scaling with square root d over epsilon. Here’s a diagram of local privacy. N Users run a differentially private mechanism on their data and an aggregator computes on the messages. In our threat model, the goal of an adversary is to skew the aggregator’s output. The adversary controls a gamma fraction of the users who report arbitrary messages. The rest of the users are honest and the aggregator computes on all messages. Our work shows only a small gamma is necessary to control the aggregator’s output. 