 when it rolls out from the descent government and they enable policy makers businesses analysts researchers and many more uh to to assess and measure trends about who we are and where we're going as a society and supporting all of these diverse uses of census data requires us to publish an enormous amount of statistics and data tables often at very fine levels of detail or granularity and unfortunately we know that every time you're going to publish or release any statistic that's calculated from a confidential data source you are going to reveal or leak a tiny bit of private information in the process back in 2003 and what later became known as the database reconstruction theorem academics demonstrated mathematically that if you release too many statistics at too high a degree of accuracy then eventually you're going to real reveal the entire underlying confidential data source from which those statistics were calculated and this challenge is even greater when you consider these new and emerging privacy threats that we're facing today it's long been said that nothing on the internet ever goes away and the same is definitely true for for data to get published or that are available externally over the last 20 to 30 years we've seen an incredible proliferation in third-party data sources that could be used to re-identify individuals in publicly released official statistics data about us are are collected all the time by the the companies and businesses we interact with by data brokers through social media and so on um and these data often include very rich information about each and every one of us and they could be used in attempt to pick out specific individuals in published official statistics meanwhile computer technology and machine learning algorithms have improved substantially computers can now easily perform the kind of complex matching algorithms that would be necessary to leverage that external data in order to re-identify individuals or to attempt to re-identify individuals in published statistics and these parallel trends aren't just abstract concerns they represent real concrete threats to protecting confidentiality that need to be addressed over the past century the census bureau has been a world leader in the design and implementation of statistical methods to safeguard privacy in our public data releases and as new privacy threats have been identified over the years the census bureau has worked diligently to improve and and strengthen the statistical safeguards that we use to mitigate those threats our adoption of formal privacy or differential privacy for the 2020 census uh is merely the latest in a long history of this innovation and continuous improvement to our privacy protections and it's a necessary one to counter the 21st century privacy threats that i just mentioned so there's a common misperception that aggregating data publishing data as aggregate data tables is is sufficient to protect privacy and while that may have once been the case and may still be true for some limited or smaller data releases it's not sufficient to protect privacy in large-scale statistical data products in fact aggregate tabular data can often be thought of like a giant game of sudoku for those of you who play sugoku with sudoku if you have enough numbers pre-populated into the grid of the puzzle then eventually there's one and only one solution to that puzzle well the same is is true or can be thought of as true for data tables when you publish enough data tables that aggregate and disaggregate the the data by various characteristics well eventually there's going to be one and only one set of individual level records that could have produced all of those aggregate tabular data and while it may have seemed unthinkable a decade ago for computers to do this uh these these machine learning algorithms and optimization algorithms can now perform these reconstructions of individual level data from aggregate data tables uh relatively easily so let's look at a simple example here imagine that you collected some basic demographic information about seven people who lived on a particular census block you then publish some aggregate descriptive statistics about those seven individuals how many were female how many were black what's the median age of married individuals and so on well with those basic tabular statistics uh it's a trivial matter to solve for the only set of individual level records that could have yielded those results uh and i i really mean trivial in this context it took a 2013 macbook pro all of 0.2 seconds to solve for those individual level records from those aggregate tabular data and now our would-be attacker would have individual level records for everyone on that block just missing name the question is can this attacker actually re-identify any of them well it turns out that this is also a relatively trivial exercise while the reconstructed individual level records didn't have names attached to them they did have a number of pseudo-identifiers that could be used to link to an outside data source that does have names in this particular example the attacker could use age and sex to match the reconstructed individual level records to third-party data say for example voter registration lists for that block now it's easy to attach names to the records and you've just learned jane joe and john's race and relationship status and those are two variables that are included on the census that most third-party commercial data don't have so with the risks of of reconstruction and re-identification attacks these examples i just showed in mind and the knowledge that these types of attacks are getting easier and easier to perform the census bureau decided to do some research to see how vulnerable the privacy protection methods that we've used for previous sentences would be to to these types of attacks so remember i mentioned a few minutes ago that uh that database reconstruction theorem tells us that anytime you release any calculation or tabulation that's derived from a confidential data source you're going to reveal or leak a tiny amount of private information in the process well the 2010 census collected a handful of attributes for the at the time approximately 309 million people in the united states that gave us about 1.9 billion confidential data points that we had to protect but from those 1.9 billion confidential data points the 2010 census data products released over 150 billion aggregate statistics that were derived from those data so with the knowledge that each time you release one of those statistics calculated from a confidential data source you're going to leak a little bit of information we wanted to see what were those 150 billion statistics enough to allow an attacker to reconstruct and re-identify individuals from the 2010 census well unfortunately the results were were an emphatic yes they were in fact using only a small portion of the publicly released 2010 data uh census bureau researchers were able to accurately reconstruct individual level records for all the inhabitants of all six million inhabited blocks in the united states moreover we were able to reconstruct detailed individual level information including sex age plus or minus one year race and ethnicity for 71 of the entire u.s population and then linking those reconstructed individual level records to commercially available data from the 2010 period we were able to confirm that we had accurately re-identified those individuals on all variables for 52 million people so it should go without saying that the results of these internal experiments were a real eye opener for us and and recognizing the growing threat posed by the these uh incredibly powerful machine learning algorithms and this proliferation of external data we realized that our traditional approaches to protecting privacy in our public data products were increasingly insufficient to meet these new threats so to meet our continuing obligations to safeguard responded information the census bureau has committed to modernizing our approaches to privacy protection and we've decided to adopt differential privacy for the 2020 census so what is differential privacy differential privacy is is a framework for quantifying the amount of privacy risk for each calculation data table or or data product that you want to release no matter what third-party data is available to use in a re-identification attack now or at any point in the future said slightly differently differential privacy as an approach allows you to precisely measure and then mitigate that leakage of private information in your published statistics and by quantifying by measuring that risk it allows you to then inject precisely calibrated amounts of statistically neutral noise or uncertainty into those statistics that you're going to release to make sure that you've decreased that privacy risk to an acceptable range acceptable threshold but what constitutes an acceptable level of privacy risk that's the key question well the only way that you could absolutely eliminate all risk of re-identification in data products that you want to publish would be to never publish any usable data at all and clearly as our mission is to be the leading provider of quality statistics releasing no usable data would not be a viable option for us so instead policy makers have to find this optimal balance wherein we're providing data that are sufficiently accurate to meet our data users needs while also being sufficiently noisy to meet our legal and ethical obligations to safeguard those data and and finding this balance is a difficult decision but it's ultimately a policy choice not a technical one that said once you've identified that point on the spectrum between perfect privacy and no useful data on the one side or perfect ac perfectly accurate data with no privacy protections on the other once you find that sweet spot in between those two extremes that point becomes known as your privacy loss budget and you'll often see this represented by the greek letter epsilon and much like a monetary budget the lower your privacy loss budget the less privacy you're willing to give up uh so an epsilon of zero would be the world of perfect privacy with completely useless data and an epsilon of infinity would be the world of perfect data with no privacy protections at all now there are a lot of folks who particularly when we first announced our adoption of formal privacy for the 2020 census they said oh differential privacy will destroy the usability of of census data compared to the traditional privacy protection techniques that we've used for past censuses but i want to be very clear that when comparing differential privacy with traditional disclosure avoidance techniques neither approach is inherently any better than the other from the perspective of data accuracy it's all going to depend on how you implement those methods and and the parameters that you use in that implementation i've seen some implementations of differential privacy that result in highly accurate data when they're well designed and when they have sufficiently high privacy lost budgets and i've seen some actually quite a few implementations of traditional disclosure avoidance techniques that have resulted in terrible data quality when they were poorly designed or when they had particularly high record swapping rates or cell suppression thresholds for example where differential privacy and traditional privacy protection techniques do substantially differ is on the privacy front um traditional disclosure avoidance techniques were often ad hoc in nature and had little if any ability to quantify just how strong those protections were formal privacy provides you that framework for precisely quantifying privacy risk and that quantification is future proof you don't have to make assumptions about what third-party data attackers might have one year two years five years from now or how much computer algorithms will improve over that time so what does all this mean for the 2020 census well i want to be clear that the census bureau's adoption of formal privacy for the 2020 census does not alter our constitutional mandate to apportion seats for the u.s house of representatives using the actual enumeration of state populations for the 2020 census data products we will be holding state population totals as invariant meaning there will be no noise added to those numbers the remaining data products however including the the pl 94 171 redistricting data will have privacy protections applied to them as they have in prior synthesis only this time the noise will come from differential privacy rather than from the record swapping mechanisms that we used in the past now our switch to differential privacy does require us to reevaluate the quantity of statistics and data tables that we're going to be releasing as each additional statistic or table uses up a fraction of the overall privacy loss budget for the 2020 census consequently our proposed suite of 2020 census data products will look somewhat different than in past decades and if you want to learn more about these differences there'll be a link at the end of my presentation today or you can just search 2020 census data products on the census.gov website so i mentioned before that the decision about where on that spectrum from perfect privacy to perfect accuracy you find that sweet spot that's a policy decision and that decision is going to be made by the census bureau's data stewardship executive policy committee or dsep and they're going to have to decide not just what the overall privacy loss budget for the 2020 census will be but they'll also have to decide how to allocate the shares of that privacy loss budget uh to the various data products that we'll be producing and this includes um the various components of what we call the group one data products the the pl 94 171 redistricting data and the demographic and housing characteristics files it also includes the group 2 data products that include tabulations on detailed race detailed ethnicity and detailed tribal data as well as detailed household characteristics and then all of the the out year and additional data products that are generated from the the decennial census so they'll have to give shares of that overall privacy loss budget to each of these data products in turn and again i said that's a policy decision but then even within those data products there's also going to be an allocation of that privacy loss budget to the various tabulations that comprise each of those data products and then here is just a a sample allocation that allocates shares of the privacy loss budget uh to queries by geographic level from the nation all the way down to the block and by the query set so essentially the different variables and cross tabulations that are being calculated so each of those gets a share of the privacy loss budget attached to that data product and each of those data products shares some to the global privacy loss budget for the 2020 census now these decisions have not yet been made and they'll be made by dsep in the coming months but they will be factoring in uh input from you our data users in terms of what is the relative priority of for example tabulations at the county level versus those at the tracked or block level what is the relative priority of information on voting age by hispanic origin and race versus detailed crosstabulations that would support age bisex pyramids for example now um i'm sure many of you know um the census bureau's operational schedule has been in some some flux recently and particularly with uh the ongoing litigation that is occurring um we have had to compress our production schedules to meet our statutory deadlines currently we're focusing all of our attention on identifying the activities and schedules that are needed to produce accurate and complete redistricting data by the the march 31st 2021 deadline the statutory deadline there um as such uh our recent planning and das development work uh has been focused on getting to done for that pl statutory deadline uh and so we've had to postpone work on the remaining data products and support for those remaining data products for the time being we will however restart the the planning and production planning for production release of those other 2020 data products once we've completed uh the data planning and scheduling activities for the apportionment and redistricting products so what have we been working on recently what have our our recent priorities been well for starters uh as we're moving closer and closer to production uh we are hardening the system for uh integration testing into the the larger 2020 census it uh infrastructure as well as preparing the system to be able to run in established time frames for production more importantly for for your interests i have a feeling um we have also been focusing a lot of our attention on improving the algorithm improving the the performance of the algorithm to bring the resulting data accuracy of the data products under the direct control of the privacy loss budget for those of you who analyzed the 2010 demonstration products that we released last october or the the files that we released from the maydas run or or the most recent september das run you'll have seen that even with the same privacy loss budget being expended different mechanisms of the algorithm can can produce changes in the resulting accuracy we use the same privacy loss budget across all three of those files but you will see widely different impacts on accuracy one of the things we've been focusing on have been to bring the performance of the algorithm under the control of the privacy loss budget so that as you tune that privacy loss budget as you increase it for example that you will increase accuracy in direct proportion to how much you've increased the privacy loss budget assigned so that's been a major focus of the das development work recently and as those of you who have analyzed the the september privacy protected micro data file and resulting tabulations that were released a couple weeks ago you'll notice that we've significantly increased accuracy for those data even using the same privacy loss budget we've also been uh focusing uh substantially on improving accuracy for population data for legal and political entities particularly for american indian and alaska native tribal areas uh and populations for legal and political entities that are in what we call off-spine geographies those that don't follow the standard kind of county to um sorry state to county to tract to block group to block so we've done a number of improvements we've implemented a number of improvements to the algorithm to to better target enhanced accuracy for those off-spine geographies as well and then on the kind of i.t security front a major focus of ours has been um ensuring the security of our random number generator in order to inject the noise into the data we have to pull trillions of random numbers from a distribution of noise values those the the security of that noise injection depends on the security of the random number generator used and we want to ensure that nobody could essentially undo our protections by undoing the security of those random numbers so that's going to focus as well so as i mentioned a moment ago we recently released new demonstration data it was the demonstration privacy protected microdata files uh of september 17th as well as detailed summary metrics uh calculating various measures of accuracy across the data that were produced in that file now consistent with our our retooling of the schedule to focus on preparation of the redistricting data by the statutory deadlines uh those new demonstration data products are limited to just the data necessary to support the release of the redistricting file that would be tables p1 through ph and h1 uh in addition to the the files and metrics that we released uh ippums has also tabulated those data for data users that want to go in and look at tabulations of those for their particular data use cases again as i mentioned across all of the releases of our demonstration data products we've been so far keeping the privacy loss budget consistent across those releases so that our data users can assess improvements to the algorithm itself not changes in the privacy loss budget again if you increase the privacy loss budget you'll get greater accuracy if you decrease it you'll get more noise we wanted to show improvements to the performance of the algorithm and and accuracy improvements that come essentially without any cost they don't affect the privacy guarantee they're improvements just in how the algorithm performs and so we used uh privacy loss budget as we have for the prior releases of an epsilon 4 for the ppmf person file and an epsilon of 0.5 for the ppmf unit run again that is limited to just the h1 table so the epsilon of 0.5 would be consistent with how much was spent in the prior demonstration data on the broader ppmf unit tabulations that had been scaled back for this particular run with the focus just on the pl data so what are some of the major changes to the disclosure avoidance system that are included and represented in this new ppmf release these new demonstration data well for starters we brought american indian alaska native tribal areas directly onto the processing geographic hierarchy onto the spine we also included a new state level american indian and alaska native tribal area population invariant so essentially uh the total population for all aion tribal areas within each state is held exactly as enumerated and no noise is injected to that much as we do for the state level population totals as well we made some substantial improvements to uh the the rounder algorithm that's used within the system and that's helped to decrease the post-processing errors that we noticed in prior versions of the demonstration data again improving accuracy as a result we changed the noise distribution that we're viewing that we're using for the noise injection from the previously used geometric distribution to a new discrete gaussian distribution uh that has an impact of better clustering the noise values closer to zero uh reducing the likelihood that uh noise values would be pulled from the tail ends of the distribution on either side and finally we made a number of stability and reliability enhancements to the algorithm to prepare us for for production once we go into production mode so how did the how did the new demonstration data stack up to to the prior demonstration data products that we've released well so i mentioned earlier that one of our top priorities had been to improve the accuracy of population counts for legal and political entities so these graphs here show the mean absolute error for counties across the entire country broken down by county size so for comparison you can see the average error for the october 2019 demonstration data as well as the average error for the may 27th privacy protected micro data file that we released dark blue is the october 2019 data light blue is the the may 2020 data and the burgundy is the new september 7th file that we just released and as you can see across counties of all different sizes the average error was 82 people in the october 2019 data by may we had improved that so that average error was reduced down to only 16 people and with the new ppmf that error has been further reduced to just 6.7 people on average across all counties that's a total of about a 92 percent decrease in average error for population counts at the county level since last year's demonstration data and again that's holding the overall privacy loss budget for the data product constant also important to note here is that is the average error across counties of different sizes the october 2019 data had large disparities in average error across counties of different sizes now those error rates are quite uniform across the different size categories but counties are entities directly on the geographic spine so how did we do for off-spine geographies here is the mean absolute error for total population of incorporated places again the dark blue is the october 2019 data light blue is the may 2020 data and burgundy is the september 2020 across all incorporated places average error was 85 people last october which was improved to 55 people in may and with the new ppmf we've further reduced that to an average error of just 23 people across all incorporated places now given that these uh incorporated places are off of the post-processing geographic spine you'll see a little bit more dispersion and error rates across size categories with the smallest error roughly 17 people um in the smallest places those with a population of under 500 people and slightly larger error around 60 people for the largest places those incorporated places with a population of over a hundred thousand uh but still compared to earlier versions of the algorithm we've substantially addressed the distortion that we have noticed in those earlier runs lastly one of our other priorities as i mentioned was to improve accuracy for american indian and alaska native geographies so here is the mean absolute error for total population of federal american indian reservations and off reservation trust lands again the light blue is the may data and the burgundy is the recently released september run now there's no comparison from the october demonstration data because those geographies were not included in that first set of metrics that we produced but in the may data the average error for american indian reservations was 32 and a half people bringing the aiam tribal areas onto the processing spine along with our other algorithmic improvements we've reduced that from 32 and a half people down to six and a half people in the new demonstration data and again average error is pretty consistent across size categories with even the biggest reservations only having only having an average error of about 10 and a quarter individuals now these are just a few of the metrics of interest i encourage you to review the full suite of our demonstration our detailed summary metrics uh and and look at those use cases and the error measures for those use cases that are most uh relevant for your particular uses of census data and also to check out the tabulations that have been produced by iphones um let us know your reactions and tell us what you think are your sorry excuse me tell us what you think our priorities should be uh for future improvements to the algorithm because we want to make sure that we're we're addressing fitness for use concerns of our data users to the maximum extent that we can so here is a rough schedule and as i mentioned at the beginning of my talk our schedule is somewhat in flux and i know that even since i put these slides together last week i've been out on vacation for a week i know these dates have now changed um it is likely that the decision uh the d set decision-making meetings uh both for setting the final list of invariants and system architecture as well as the decision meeting for setting the privacy loss budget uh for the 2020 data products those are likely being delayed as a result of changes to our operational schedule um we will be announcing more information on when those meetings will happen once the schedule has solidified more but roughly speaking there will be a deset decision meeting setting the invariants um we do intend to release additional demonstration data uh to support our users and to allow our users to inform uh the decision making that dsep is gonna make about setting the privacy loss budget and particularly about allocating that privacy loss budget across tabulations that support various use cases um and then as i also mentioned once that schedule is more firm we'll be able to provide a more detailed schedule and the decision making points uh that relate to the data products beyond the redistricting data file so here um a couple useful links um we post regular updates on the work to the disclosure avoidance system on our website at this link here we also have a dedicated email box for our 2020 census data products that's reviewed by our subject matter experts for the data products as well as by our disclosure avoidance system team so if as you're looking through our demonstration data you have uh feedback for us if you have concerns if you have suggestions for relative prioritization of accuracy for various use cases or suggestions for thresholds of minimum fitness for use standards for tabulations at various levels of geography or various combinations of variables please submit that to us that will be enormously helpful to our our policy makers when they are making those those decisions about the privacy loss budget uh you can send those to the 2020 das at census.gov email address here for those of you who want to stay uh informed on all the latest updates uh we also have a uh uh das newsletter that we send out uh information through um we won't spam you i promise we we release information as it becomes available uh then we we target having uh new newsletter uh updates to our data users roughly every two weeks or so so with that i know we have some time left i'm happy to answer any questions that you might have so michael we haven't uh received any in chat yet so if anybody has a question please go ahead and submit those um you just mentioned the newsletter how does one sign up for the newsletter so i provided uh barb le flair the the direct link to sign up for the newsletter as long as uh as well as a link to where all of the archived issues of our newsletter are and i believe she's going to be sending those out to everyone okay great yeah i know that came up on the washington meeting yesterday all right so nothing coming in on chat yet so if anybody does have any questions for michael while we've got him please go ahead and submit those and then as michael said uh barb will work with charles to get that information to how to sign up for the newsletter in case you're interested and i'd like to thank michael for his presentation once again uh good to know that the uh the algorithm is being tweaked and that that we're gonna hopefully uh get better data than what we what we thought a year ago so uh of course we are looking forward to getting data next year and uh wondering uh if anybody knows uh is there any you know that the census debt collection period is going through october 30 first but uh are we still is this census bureau still subject to the the public law deadlines of december 31st and and march 31st nothing has changed in that regard has it so as i said i've been on vacation for a week and i know these are subject to ongoing litigation so uh i am probably not the most informed of what uh the current status of that litigation is um so i i can't comment on the current schedule for for collection and the the statutory deadlines but i'm sure as that gets clarified it will be announced okay yeah charles this is barbara that's what where i've been at too is that we're waiting for clarification we're still you know running underneath the guises that we have been so there has been no um i'm gonna say etched in stone answer come down yet right well if anybody on on the on the call here it's curious about what we're talking about the public law that the census bureau has been adhering to for the last several uh decades requires the total population of each state to be submitted to the president by december 31st of the census year that's when we know how many seats in congress each state will get and then the block flow data is released by the end of march again according to to the u.s code by march 31st and although it sometimes comes as early as february state by state in the past so that's the data that states can use to hit the ground running for redistricting and the sense at one point there was a recommendation to extend those deadlines and that was included in a bill that the house passed but the senate and white house have not uh passed that bill have not proved the extension of the vines so that's that's the litigation that we're we're waiting for and requires a change in the us code and we've got we're scheduled to commence the final session today which is a oregon update hearing from our investments program manager and myself and our 