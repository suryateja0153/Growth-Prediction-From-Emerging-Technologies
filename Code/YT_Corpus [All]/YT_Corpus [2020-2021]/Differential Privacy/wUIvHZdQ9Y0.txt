 you [Music] thanks everyone for coming today's speaker is Huan Yu Jiang Huan you is a graduate student in Cornell and this summer he interned in our group he worked on some cool projects and differential privacy but today is going to talk about some of his other work on privacy-preserving statistical learning and testing Vanya okay hello everyone so thanks Jenna so today I'm vertical I talking about Hall here and my topic is on privacy-preserving statistical learning and high stakes okay so first I will talk about some introduction the motivation why we need the statistical Travis that his role learning and testing and in the second section and the third texture is many is Manhattan apart so the the first problem is on a differentially provided in he testing and the second the problem is not materially private property estimation and at last I will also measure some future works okay so let's start with the introduction and the motivation so there are some old and the classical statistical learning and hyeseon problems the first problem and most of and maybe most famous ones distribution learning for example you have some you have some whole and you also estimate the pass of a coil okay just a learning problem and another famous problem is some hypothesis testing problem problem for example you have a coil you just want to theis the wide and all coins are fair fair or not here Ferguson means it will show up tail and hide away the same half probability and the last there are also some problem name the property estimation suppose you are given some I these samples from some unknown distribution you want to estimate the property of this distribution for example you want to estimate the Shannon entropy of it okay so these are old and also well started problems but the problem in us they mainly focus the previous studies mainly focus on the small domain setting here the small domain setting means it has a very small arthur by size and you have many more samples compared with a number of the other by size for example in the example of alcohol the ARA Pacis is only true but for now we want you to look at some other settings as everyone knows right in the year of big data so we have the loss or loss loss of many data and by self data generally every day and the beauty that has brought huge success for marshal oniel statistics but also some new challenges so what is the new challenges so now we are not even focusing on the small domain side here but we want to focus on some large domains that you feel are domain setting the reason that so because we will need you estimate or test a lot of distributions over large domains or high dimensions for example if we want you t always some dream mutations which is has a really huge support sighs okay and also another reason is that we want you the data is quite expensive so we want you see use as small number of data data as possible so today we will focus more of the focus more on the final sample setting which means we will mainly focus on the sample complexity which is defined as the minimum number of samples we need to do some tasks okay and also we also need to consider some constraint of privacy so and the the reason it should be obvious because the samples may contain sensitive information we just want to do the same testing or learning problem but we also want to preserve the privacy for the for the individuals who contribute data to us okay and also some more examples on why we want you on the private data data may contain some information for example the medical studies because freedom but if we want to learn the behavior of genetic mutations which contains House reports of disease history or fitness is why example not data contains native information and also in some other application like a lot navigation because the navigation who suggested rules based on aggregated positions of individuals because the position information can contain a lot of information and Neha indicates user residence for example if Google Maps and me always either Microsoft maybe he will find me I'm just actually a staff of Microsoft right so which means that here the data is kind of significant incentive informations okay so what we want to do it to do some private in universe okay so what do we want to do is we won't just want to do the old problem also always a constraint of the privacy and the furthermore we want to explore the privacy sample complexity trade-off in these problems and neroli and which will be a fan later so the sample complexity of these problems can be divided into two parts the first part it has a sample complexity of non-private algorithm and the second part is just additional cost due to privacy and then a natural problem an interesting problem in that is privacy cause a lot of very small or even free so why it's important because when the privacy because it's very small we can just you incur the constraint of privacy with very small comments very small cost okay so now so we first win you some notation of the privacy here the notation for privacy we use these a differential privacy which should be the most famous one notation for the privacy and I think I realized should be well familiar with it but I just want to briefly go over it the definition is that will you change one sample in a data set the output distribution won't change a lot if we look at the plot the graph here so you will have two data sets t 1 and teach you they only differ at 1 petition for example I'm sorry so I just change X Y into X 1 Prime so they only T for either one positions and I've had it some randomized algorithm which you need to design by yourself so the different of privacy just require not the distribution of the F height on the condition of the first data set and the distribution of a I've had any condition of this set of data cells should be close here close if some multiplicity ratio can be bounded by some Erie's to after and which I found that will absolutely large you will have a very weak privacy constraint for example if you take abs on to be infinity you have no constraint of it and even when you tell us them to be 0 you will have a very stringent engines revs the constraint which means that you need the distribution to be almost the same okay so TP is widely used by the industry for example Microsoft and I know Google okay so so what was this random distribution function okay so not the randomness comes from your algorithm so now I've had is your algorithm so no data the data yes what is the distribution here is it a fixed rancher or this would be depend on your data center right well your data said these are figures that you the others are either fixed and you you also have some distributions because our algorithm is random Oh in that sense nothing yeah particularly the inputs can be the input X or whatever is biggest like you see anyone just check yes where's Kate privacy yes and the you can find that you must use some randomized algorithm right if you do Salma if you don't use randomized algorithm you cannot high above this Karen keep you have the teacher you can be a bit handle fixed okay so now okay I just want to talk about one framework you change non-private algorithm to private algorithm okay and we reserve last mechanism which is the most famous one so I need you define sensitivity at the first so the sensitivity of a non-profit estimator F is defined nice when you change one dataset when you change one point in a dataset the possible chin in the maximum possible change for the output this is a fully nonprofit estimator because I'm talking about changing a non-profit estimator to some private estimator and you are imagine that if since it sensitivity is large which means that free nonprofit active estimator when you're changing point either will change a lot in the output okay so now what is a famous a bloodless mechanism you can be divided into two steps the first step is that you design a nonprofit estimator with low sensitivity and the second side we just your proud this estimator by just adding some blah blahs noise and you can see here is a lot less noise with standard deviation of this an annuity / absol and you can find that we will Nixon TV is very large which means that you are non profit nonprofit estimator is quite bad you need to add a lot of noise to make it even really private okay and the epsilon just the privacy parameter epsilon is more you have a higher requirement for the privacy you so you need to add some more notice of it hmm okay so now we miss talk with your content follow jung-hyun works now first work is on P printer D private high steam and then he intestine and the colonias testing and the wit is done by by myself and Chad which is meadow up with my adviser to the home with my lab mate and also another work is done the the visually private Iestyn made some some property estimation problem and this is trying to work with close-up okay so okay so any problem here now so I just want you to start at hiding it apart okay so now first one should be the differential D private I didn't hear you testing okay there is a one motivate motivating example for the for the for the I didn't he testing so which is a famous and is a true story is a handle isn't is a Polish Lottery name the multi logic okay so and inside not this lottery is fire by choosing uniformly and random these thing 20 numbers out of one to 80 okay so now the problem we concern that in the lottery fair or not fear fairness means every number comes out with the same probability okay so and the answer for this problem is not there is no so but also if you draw the histogram of the 300 yes the three 300 drawings of this polish multi logic it will find that the number 50 to 60 is very small so you will with high probability you can see that this work should not be a uniform distribution right mm-hmm so this is the because the machine is the best much there is something wrong with emotions okay so the more the idea in that we got to want you see why there is some distribution is same with our known distribution or not now we just formalize it by this problem formulation so this problem is very famous name dyes I didn't he testing also cooling ease of feet some well so namely as one sample test income so we will see a few sample tends to test in later so we only have we only care about the discrete distribution we see the support size to be k k just 0 1 into K minus -1 and we suppose Q to be somewhat knowing distribution okay some known t3 distribution over K now what is that task that has tree is that evil acts indifferent you need independent samples from unknown P x1 into axon we want to answer the following question whether P hijos cure or not okay so what is the definition of our tester our tight search should be Casa function from the random samples into 0 & 1 which should studies find the following things with high probability our ties the truth output what if P equals Q okay you can see the high status kind of a classifier you just need to justify wider P and Q are C or they are are far away in total variation theatres maybe you will ask me what will happen if if neither of the Keynesian will satisfy so the answer is we don't have so you can let your tester to as true output either 1 or 0 with no guarantee in the problem clear okay so and we mainly concern about the sample complexity of this problem within the smallest and number of samples we are such a high star uses and you can find that the sample complexity should depend on the should depend on list should on this queue unknown distribution right suppose you have some ones for the moon distribution you can see it should be independent of the support sighs okay so here the several capacities defined as a worst case here the worst case it means that worst among all than all the cues although cute here is the some no distribution on the suppose that's okay any problem for the problem definition okay so okay so there is some there are some previously results so for the nonprofit problems so the known sample capacity for this problem is to quite low K divided by RS square which is really strong by penske this is tight okay so we mean you don't need a linear number of the Union linear number of samples here linear means the linear support on the are bite-size you only need some square root K dependency of it and I can give you some lower bound intuition really just a birthday paradox okay so because we don't have enough people here so I don't think I can make a real experiment but the birthday paradox is that yes suppose you have a uniform distribution under suppose sighs okay so I'm you just IIT draw some samples from this distribution okay so and only if when you have some square root K number of samples you can see some clear the clear means you will see every you will see I said few samples which belong to the same seems the same symbols something like this one and for this problems we can just show a very easy argument you prove a square okay divided by alpha square okay lower bound for this problem by this birthday paradox you can just assume you have two distributions the first distribution is the uniform on K okay and the second distribution is you have you have uniform on hey / - but you don't know which what is the support of this k / - okay so now you just want you these pin which between these two okay so what you can do you just randomly draw some samples and if you some samples which is less than square root K McClay mean that four-eyed furnished few cases you will see the samples are almost the same because you can even now see the clear raspy howl you will see ok every sample appears with every symbol we only have at most one sample so from these few cases it will the samples look is that any the same so you cannot distinguish between these two so will gives you a lower point of square root 8 something okay so underneath it for the non-private case and for the absalom different really private algorithms in the paper of high and the cost of customs paper so they show an upper bound of square root k divided by alpha square plus square root K log K divided by s MC and you can stand on this one class is just a cost of the nonprofit estimator right and this term it should be the cost because of the new incurring the constraint of differential privacy okay so what is the problem for this estimator because this this estimate is based on hi squirt highest which has a very high selectivity okay so what do we what did we do we just show that from this problem we have a height pump of square located by r square plus the maximum of these three items and we show is tight feared hadiza for all the parameter ranges of K alpha and epsilon okay good luck oh I see there is this locked gate down here they're gorgeous and even if you can run the heater there's still like where is the exponent solution on later Bret Hart part of the bottom three halves but alphasphere dominates no depends on the value I'm not always we are concerning the Loctite acres so we will have a my refuge the IRA buys us a teddy bear laughs okay yeah so what do we show in that behind us no more so when I have so long to be infinite I am science Kravis the Alpha is some accurate reliable so our part Arfa is defined here yeah yeah yeah yeah and Absalon is yes for the different your privacy parameter okay so what do we show you that will have some close to infinity which means you have no constraint on the privacy right you will see these three items will be zero so you will only have the first item which we used to wear okay divided by alpha square which is the cost of for the non profit estimators okay and also one case large what we have is a square root K divided by alpha square a square root epsilon which is strictly better than the previous result okay just when epsilon is privacy saying at some times P infinity seems a weird statement proving but I get what you're what you want to say I just want to say this one can be happy well once you I mean is just saying that like if you don't have a privacy thing straight then why should I use this algorithm like even the previous algorithm will also first where we correct the trivial one yes yeah I mean it's fine I practically it's fine but it just seems weird when you say epsilon you make it infinity after studying a privacy problem that's okay okay so mm what is our contribution so we have new algorithms for achieving better ones and we also have new methodology to prove lower bounds for this kind of problems I need to point out the more interesting parts will be the lower bound to how to prove this is Ultimo so for all the parameter ranges and okay so in the first argument I want to make peace with it I just want to talk about some reduction from identity ties into uniform defense team so what does it mean you just mean that if you have some okay lets me define uniform in hesitant first so the island it has been won't cure is a uniform distribution over okay so we got the known distributed as a uniform distribution over our bioscience okay so my claim is that if you can solve the uniform it has two of its null my claim is the previous works in the non-private case up to constant factors if you don't care about constant factors if you can solve the uniform it has been problem you can also solve the identity transient problems you will only without cost of some constant factors and also we know uniform it has being should be should belong to that and it has them right because uniform distribution just that's one specialty square distribution on the support side okay so because we only care about the worst case guarantee so we will we can argue that the sample complexity for this view will be the same I have two constant factors okay and what will show you that this one is all is also true for the private case so anyone interested in how to do the reduction okay so suppose now okay what is the reduction you suppose you have some uniformly testing algorithm you want to solve it the salsa I don't hit hyeseon problem right okay no reduction is something like you had found out my pin from from the known distribution to the uniform distribution and you can also made the samples in some ways and even show that if you have Q which is a known distribution somewhere far away from here you will also have some uniform distribution and somewhat Sikhs are far away from uniform distribution something like this one yes enemy dimensional rest so if you want you had also point out a special case because if you wanted a flat has not lot has life distribution which means that everyone every every must can be seen eyes so I would like to see so for year for an eye she I you know something like something like a I multiplied she she is um just a mess so you can see the eyes um so with mr. ivory forever distribution you can't be seen as the my integer times the myself here you guys have something here so what should be the what should be the right my team you can just map this one to be also to be the same on the uniform distribution this is the two times of it you just map it by something like you in the large domain size and this one is to ryoga's maybe into some three some things and we need to increase the balloon size yes yes of course you can show that so this one yes you will you will you increase the domain size from trying to exchange some constant number of yes but this one is uh okay so this is only in the special case of the allotted lot highest but they also show the the general my team from so we know the year like this okay yes Kassar intuitions of the Alliance okay so now what I want you to see okay so now it would be sufficient only to consider you when you complete I see right because we show the sample complexity does say I'm to a constant number of factors okay so now we just come to you the algorithms so some we just see the binary taste first okay now here a binary case is that is that we only have our bass aside to beat you with it as a binary distribution okay so we just want to distinguish beat you but only half and the Bernoulli beam and we just want to tie stop wiser be 0.5 or alpha away from each other would usually do for the nonprofit space so you can't just randomly drawing samples and in let I'm going to be a number of ones in the samples and you can imagine that if you draw just from Bernoulli half the number and I'm one should be roughly other work you something that right and we if you draw something is are far away from 0.5 you will have something like all over Q plus and plus R for learn something right so so what should be the red algorithm for it you can just have some hard threshold algorithm so for example and this this is a PDF and this is a number of ones so if he is a beast exactly from Bernoulli half you should be a binomial distribution with the expectation is actually 1 over 3 multiply something right and if it's not from the Bernoulli half it should it should be another binomial distribution just from 1 over 2 plus alpha multiplied something right and you had imagine that were is getting larger and larger because of the housing tree changing people of the concentration this one post needs to you will have a smaller variance when he's bigger and the so when the standard deviation is smaller than a citation cut at the UN distinguish between these two this is a rough idea for in on private race so what should it be you are algorithm your algorithm should be something like for here you just output if the number of one's is smaller than something like 1 over 2 plus alpha over 2 you just output here is a ok there should be the probability to output different so I just want you this is the probability you are so suppose you have some randomized algorithm ok so and this wife's it's just a prop in his output and they are different ok so what should be your algorithm you just have 0 here and and before this threshold you have zero probability to output they are different and here you just have a jump in here you have one and one is larger than some 1 over 2 plus alpha over 2 you will just output ok this pew and notice it this is the case for the this is the case for the non private case so and know I know Lisa's is very simple it just will earn is large enough the standard deviation will be smaller than the expectation curve and which will give you a pound oh well this is a non private ok so what will happen in the private so the cost of the ok because of the different your privacy what does it mean it means none when you change one sample you can note that your outputs probably he'll change you a lot so you cannot have some some hard search hold algorithm like this one ok so what should you do you should just that you just want to smooth it by some sigmoid functions so it just kind of like some idea filter and some real filters so in a non-profit case you will have some idea of filters you just have a huge jump and you'll lose nothing but you need stiffly premises because you require you don't you are not allowed to have a huge jump in the output of the distribution so what you do is that it has to use a sigmoid function to smooth it a new pressure here so the algorithm is named some soft thresholds what you've got something like okay these the difference between I'm one man and a difference because I'm one over two so we just also see something similar here and so beforehand we don't have something more the function we just hide okay if this one is smaller than zero something we just output the same I also we all put different but now we just smooth the probability by some sigmoid function okay so right okay so and this is the analysis of it but it's not quite important so we need to prove it by into eyes files the first aspect is some privacy okay the privacy guarantee is not hard just by the property of sigmoid function because we know that sin and he with he for the I'm one just of what right so when you change one sample now I'm one will write the most exchange Q strange some concepts okay so so what will what will happen this one will change I the most Q so the come up here is something like a few apps around so you will have here is to minus epsilon and between you is to manage eternally used to epsilon we adjust the requirement for the differential privacy and also for the utility and analysis it's also not hard so you don't need to read this one it's all kind of messy so the intuition is that suppose we consider the real distribution is Bernoulli have okay in that case I am 1x Almaty the number of ones in the samples should be roughly other word to natural suppose a number suppose number of sample is large enough so the things in the persons is roughly miners all miners are fun right so what do we need is that we need the Absalon multiplier for to be some concept because we need to have some huge concern for the sigmoid function so we will have some current here like our four other epsilon to be one so on to be how about of our overalls are five so something and problems you know so this privacy is insane to one you know several diversity is our central model quality but there are also for the same problem there are some obvious that the algorithm without differential privacy is not already DP yes I think so why because you can't just so is not a randomized even though the run not a randomized algorithm right so in terms of hand but hopefully hopefully non-randomized so suppose you face that it is the result of the algorithm is fixed right and we just argue that the non-id randomized algorithm cannot be differential Travis yeah but usually feels like if they are also doing very collaboratively it shouldn't change much yes so what do we yes well what do we do it as a boat your child what is a low sensitivity non privatize numerator and we just do this handles even more the tree but you may feel friend like okay so I thought what we are next and see mark just doing exponential function you don't even do a lot of last year you don't even do a lot less noise but he doesn't see the motor function so it seems a more fancy but you're not using Oblast now you have lots of mechanism here and they use that in verse 8 the other sanity is very small for the arm works and it doesn't want okay so now we come to the general case so the idea is just we just want to prioritize the statistic used by the previous papers so like I am at speed and number of samples so they see the non-private estimator they use we just the empirical I all won total we're not Iowa empirical total total total distance between the empirical distribution and under the uniform distribution so this one has the following few properties the first one in the sample Optima in the non private case and the second property the the statistic also has a very small Sin City which so what we do is and and they also have another some property on the exploitation crab and the small sensitivity so they show in their paper that a citation cut off today's well can be bounded by the following of three terms and also unison we also have some street firms so which match the bungs Union for our results the three different items in our and also it's very easy proof to prove they had a very small annuity only in the minimum of 1 + 1 / K we're only the number of samples and okay there are biases depending on what is the value of okay okay so what do we do is you have this algorithm is very the idea is very simple so what we do is that we do the almost the same handoffs trick in the with the Bernoulli case okay we have something with just miners - some time here and we smooth it we are using some sigmoid function and using usually the same analysis we can kind of pound corresponding to does our main theorems ok so you can see that different you just need something like this one x multiplier I'm strong to be smaller than some concept something like this and you will kinda pop okay so any problems you now for the upper bounds I have a question I don't know problem but so if this is this actually the right way to like add noise you guys show that this is also sort of think of people yeah we show this much is the lower bounds for for these problems okay so now comes to the now comes to a lower bound other words ok MIT is I think it's more interesting so the we have the following lima suppose there is a coupling between P and Q over X so anyway I just want to point out as a no necessarily iid so such that the Hamming distance between Alice and one is very small you can be bounded by T I know we show that I knew epsilon TP algorithm which can distinguish between s 2 can be bounded that I will study if I I was going to be Omega 1 over T something so what does the mean is the mass either if you want to prove some lower bound you need to find some coupling between P and Q which has a very small and I use parity in visas okay so for example if you have the 90-pound 40 it should be infinity right so in that case you bill how absurd is greater you hold and zero it is nonsense so you just want to find something some funds find some distribution which is more happier you study the Hamming distance as possible just rough idea okay so lower bound we have also first we see a lower bound for the binary case okay so for any distribution P 1 and P 2 over X with total variation alpha so if we draw a lotta samples there must exist coupling with inside a the Hamming distance are really the most famous maximal happening argument right we hold over a region okay for iid case if you look at the one sample the total variation is the probability they need Nate you are different and now you have Alan so you will have some mean value how many turns of an alpha something like this one right and just by the unjust by this arguments if we take P to be an alpha will get n to be greater than 1 over R 5 so something like this is the most naive lower bound for this problem so if we take P 1 to be Bernoulli 1/2 and P do to be Bernoulli 1/2 plus alpha so we will kinda use that lower bound for bandages right so and now the problem is that this point doesn't have any dependency on K so we need to find some PI soccer player for this problem to incur the dependency on K ok so what is what did we do we just use some league hands two point method we construct two hypotheses and not happening between them with very small sided Hammond teasers ok so what is the so what did we do we just design the following hypothesis - problem the first hypothesis these charts are these samples from uniform distribution and the other one is not only one distribution is a mixture of a lot of distributions and you see the distribution you have seen as a small perturbation every position of the uniform distribution you have some plans to have some manners something here but you everyone is are far away from the uniform distribution and here you can't use a mixture of it so and we have found a common distance of uni uniform mixture to be something like this one so because of the because of the mist Lima we just take P to be something by this one we will get a lower bound of the of our main theorems and I will skip this okay and I will also mention another problem we have a little bit look at in this paper is a cloning sighting problem also named that you see what has in the I think it has been problem we have won only one distribution known and what unknown distributor well here what we have in have we have two unknown distributions and what what is the problem setting is that we just draw a dissembles from here and also from here so given these two examples we just want to classify whether P and Q are the same on they are far away from each other okay this is a problem of closeness testing so this is the people in the way the Allen hit has seen not we don't know any of the distributors so he has a strictly harder problem than though and he testing so in the literature the pound for the non profit face is Noah is the analyst height it should be very 2 to 3 over 3 plus 4 okay depending on the which wise visually is large depending on the number of the parameter and depending on the parameter ranges so if K is quite large the first one will dominate okay similarly spending process like problems is there any relation I don't know I don't know a lot about those things down not all of it oh no no but for what do you think we got found yeah I don't know this is so decent it's in 24p nice ladies huh getting the right answer for it yeah yeah no problem of yours look there was I think that an original paper which had like a to the two-thirds from some time ago this might even be was the original budget all papers but I think actually getting this trade-off between these two terms it's fairly recent yeah nice the fastest paper for the 1980 as far as I know we read the paper not this problem of terms first yeah but the bond is not short okay so on the way show we can also prioritize some now probably estimator to have the following bonds we have that you item it should be the maximum of the following two so and also okay we skip this one because Jenna things is very it's very weird so let's say one case I think yeah that's kidding so I'm just saying we don't care about the the prior with privacy with your hand exactly the same boundaries with a non private place okay and also it's supposed to encase large maybe a higher height bond for this problem when this is tight because this is just up on the second her means upon from and eat healthy right and we know this problem is strictly harder than the other the enticing problem so this should also be a lower bound for this problem so when K is large labia or guys are tied a lower bound one for this problem okay so conclusion for this first work so what do we do is that we establish a general happy matter to prove lower bounds we also have the optimal sample complexity we also give some some capacity of closes testing okay I will go over the second work quickly okay so in this work we also consider the differential privacy setting but we consider another problem is between the property estimation fear the property is some property of some distribution suppose we have some P on which reason only square distribution so and we want us I'm here which is some property of these tributaries ample entropy you should be the property of the distribution itself okay an RV is a multi reliable now you input is some iodine poles rolling from P and the one we want to do is that we want to output some estimator I've had such that with the high probability now sorry yeah the isolator should be closed with the real value with the accuracy level are always high probability something like so and we also want to know the sample home velocity for this problem which is the least number of samples to estimate a speed I mean the problem clear so and transferring is your high probability question you know it will you video tricks but it's not clear in the predator ah even then it's not clear but anyway yes I think since we are running late I just want to just go back once by any standard so in our FB is just sound property of this okay okay so now what we okay we also consider the people ready private property I see major problem so we require our estimator to satisfy the first is accuracy the same accuracy as the previous slide and the second as user privacy we also in our estimator must study if i I've sound definitely privacy it's also global differential privacy mode okay so we consider the following three properties the first one in the shadow entropy the second one is a support coverage which is the healthy number of these things symbols if we draw am sample from P okay so what I want to explain more about it suppose we have some unknown distribution and we draw am samples of it okay and the you will see and uh okay let asked to be the random variable which indicates the number of the different symbols which will appear among the samples you should be a random variable right but here we consider it's healthy number of it so we should be a fixed value I will explain more for this ones and I'm nice wise I run your example last which means our support size which is a number of symbols with nonzero probability which is easier to understand okay this is a I example the underlying assumption I don't mention that we assume everyone has probability 1 over K so yes yes oh because if you have something which appears very small probability you need to say that with a very large size of samples right yeah it really is impossible if you don't have anything in number of samples ok I don't have time for this motivating examples so yes ok so it's just a second electrons what you're saying is just like generalization of coupon collector kind of problem oh yes yes so when you draw some III mean coupon collector is kind of like the opposite direction how many times until you definitely see it everything and that takes sort of like a log cake right so me I am then how many will see okay yeah and there's the other way in the sense that you'll be able to save a log k but maybe a boiling question what Signum of is a simple application of inequality sorry there might be so his initiative that means the sharing of power argument that because s is Lipschitz right I guess the real bonus so what what you want to say follows directly from I think Mac the are miracles because this is a vicious function on a what am i up yet okay so if you have a subset of M examples and you change one of them they stop so define the function there example M examples and I look at the trend listing writings right so this is my function this relationship okay but the problem this one only works when you have okay it only works with M is very small so okay so okay let me put it in this way suppose you have some suppose has okay these were only words when you have a lot of samples larger than say but if you have only required somewhere is small sample compared with them this one does yeah well but this is true when you have us it meant much more samples Helen your comments I guess like what you're saying is exactly correct if you had more than app draws from P it group it up into the sets of size M into C with the value that this will concentrate but the surprising thing that he'll show it you can do this with far fewer than AB draws from P right oh yes okay slice example so our main results are the host of privacy in probably the property estimation is also negligible okay so now same for all these three problems I will only talk about the supposed hard problems this is our upper bound so in this upper bound you can see the first one is tight for the nonprofit case it's optimal and the second one is upon for the for the cost of privacy and we can show that the privacy is free analyzed I have said on to be very very very small so because what suppose I've come to be something like 1 over something like for some constant you will see this will have almost no cost of your privacy any problem and we all right maybe I need to stress this bound only works when the I'm is very large I am is greater than 1 over R 5 or something so maybe you're curious why this to one is why it's strictly larger than this one is because we have some assumption that we are in the M is very large size okay so yes so we just shown that the privacy house it's very small here's what all what we do each other a lot less the mechanism which are our already hard work so I found one the bottom without your own privacy is likely beer so you're saying that we estimate the expected number of like the support coverage you may actually need mor log M Sam yes you don't need more than samples because you are only interested in an open this was hired for any parameter so doughnut you still use IBM samples right you help me you that is they I'm samples or comes in number of is okay so what do we do is just a Laplace the mechanism we follow the following nonprofit estimator from honestly so where some lost Nativity so what do we do is that we found those Nativity of this one and we can i some loveless noise and we show the bounds in the onion our main theorems and also we use happening lima so we could be already used in that hyeseon problem so two to three lower bound for this problem the kid on this one is really harder than that above this heightened problem right if you want to use for example if you have the UN is uniform over this one and YouTube is distributed over n plus one so we will have one huge mass of about alpha divided by 1 plus alpha and I remind the same win this one so you and when I showed that the support heritability for by alpha AB and if you guys remain this one either Italy you can also distinguish between its two okay I say so with so we got to use a poem from the habit of testing and show a lower bond knock people over half absol mm-hm and we also do some experiments so we just show the real prodigy meters and the number of estimators doesn't differ a lot on the agility okay so also are some real data sites so conclusions or upon show that some privacy is also negligible and with you have some lower bound for these problems and also we show it that you felt hearing is of it you buy some synthetic on the real do that samples okay I think this is for for today so yes I don't have an tongue power it any problems with my your questions so I have one good so like here this one sample seems like I'm more interested in seeing that since the privacy almost comes for free right like how many samples I need to change before I actually like have any background or switch problem and he has to any of these settings like so in your now the or applying strict differential privacy definition where you change only one sample but suppose I allowed the epsilon fraction of the samples do you think many of these things will like when will they break recommend what is the sensitivity goes out so like because oftentimes people already have this like there are because this one sample it seems to Strix like oftentimes there is a good fraction of the samples coming from this name user and this may be the set of problems were actually I mean differential privacy once you quantify this right like you know if you do like changing two things you have a two epsilon guarantee yeah but that's what I'm saying right yeah but here when really break ripening like but I also like here could be able to show some amplification kind of thing so it's not like I think you can get better is that yes I don't think my competition is the right answer for this yes so I'm thinking so for example if we only look at the example of the Bernoulli the polluter Bernoulli case we have some whole line of this water right so when you so will you change suppose n is very large all your chains up comes a fraction already the will not create the apartment exactly actually see like whether you can show bonds which are like which we can buy Co bypass one strong opposition I said yeah I mean yeah the crew but my statistics it should be pretty easy to analyze because often the privacy it just done by sort of a gap into not only not very sure dollar they do for citizens yes your house yeah ghosts of all you are here what actually need to change a lot of almost around Omaha half of it yeah that's what make it a breakdown but on the other hand if I simply walk strong competition then if we're going to give you this strong character sure I think there is some work but I'm not quite familiar great but oh you're saying there is some works my visor Kostas desk life work some on this and other other people at but like I can link you to some a furious understudying differential photos yeah yeah I do differential privacy cool Oh give no questions 