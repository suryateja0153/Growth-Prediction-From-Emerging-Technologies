 Hello, and welcome to this short video on the formal definition of differential privacy as proposed by Cynthia Dwork. Let's walk through the definition. A randomized algorithm M with domain as a certain set of natural numbers is epsilon-delta differentially private, if for all S in the range of M and for all x and y in Nx, such that ||x - y||1 is less than or equal to 1 satisfies the following constraint. M is a randomized algorithm which adds some sort of noise to the input or output of the query. Depending on when noise is added, it could be a locally or globally differentially private randomized algorithm. S is one of all the potential outputs of M. x and y are databases which differ by only one record. If x is the original database then y will have one less record than x. So, for all pairs of dataset x and y that differ by one record, and every possible output event S, the probability that we will see S when the dataset is x is e to the power epsilon times the probability that we see S when the dataset is y. e to the power epsilon constrains how different the two distributions are. If epsilon was zero, then the two distributions are identical and we have perfect privacy. Delta is the probability that you will accidentally leak more information than epsilon claims you will leak. Some algorithms do not use delta. There you go. 