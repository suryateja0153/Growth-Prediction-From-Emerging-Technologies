 [Music] so today i will talk about more uh quantum algorithms for systems of linear equations um after being almost 18 years in this field i'm still positive that when the computers will when they be able to solve problems and applications that are beyond reach of classical computers and um and quantum algorithm design appears to be the main reason why there are so many investments in these technologies but anyone that's been in this field knows that building new quantum algorithms improving upon the existing ones and even finding applications for them is really hard really hard so here we are looking for needles in haystacks basically and uh and today i will talk uh in particular for quantum algorithms for linear algebra problems so some of the ideas that i present been discussed before but it will go into more detail a couple of relevant works uh my job will be these two papers in 2017 and 2019 and let me introduce to you the linear system problem this is a problem that is ubiquitous in science and uh engineering technologies um we are given a matrix a specified in some way this matrix uh is of dimension n you may think of this began as being really large okay exponentially large maybe in some problem size we're given some vector b uh again specifying some way and explain that more uh later and the linear system problem is basically uh finding a vector x that solves the equation ax equal to b right so classical algorithms for this problem um typically take time which is a polynomial in the dimension of the matrix and one of the best non-general purpose classical algorithms conjugate gradient scaling goes with linearly in n and nearly in kappa which is known as the condition number of the matrix which basically is a way of to quantify how far images is from being invariable so the quantum linear system problem is some tricks that we've done to the previous linear system problem so this becomes now amenable to quantum computers so the idea is that given the previous system of linear equations now our goal is not really solving the system but preparing one a quantum state that encodes information about the solution of the system so this quantum state x is proportional to the solution vector of the equation ax equal to b so in more detail i mean the problem is defined such that we want to prepare a quantum state that is epsilon close to the exact state x okay so this epsilon quantifies the error uh this distance is known as a trace distance basically if i were to to prepare rows of x on a quantum computer then i wouldn't be able to distinguish it with probability larger than epsilon from the true state that i wanted to prepare so all known results on this problem that's been discussed today kind of reduced to this form so why is this interesting at all right so okay well on one side linear systems appear everywhere um on the other we know that quantum computers are known to provide exponential quantum speed ups for many problems so this is natural to us understand what they can do in indiana problems such as these and um beyond linear systems i could say that uh studying new problems like this one sometimes result in new algorithmic primitives that are using quantum other quantum algorithms and this has been indeed the case for the linear system problem so this quantum version of the problem however is only useful for computing for example expectation values on the solution of the system but not for obtaining the vector because that will require complexities at least linear in n and we want to avoid any complexity that scales with the dimension of the matrix so to understand quantum algorithms um we need to understand the complexity so many times uh we resort to what we call a query complexity in which we assume for example that we have access to procedures that uh provide information about for example in this case the matrix a or the vector b this is the way that we can specify the uh the problem the instance of the problem so in this case a query for a for example would compute the matrix element of a a query for b would prepare an initial state that is proportional to the vector b so this kind of like set the rules of the game the type of algorithms that we'll build will be based upon these two procedures for simplicity i will assume that this process can be implemented in constant time like with a constant number of two gibbet gates and i will not um discuss in detail what are the inner workings of this procedure so um by setting this query bundle then i'm setting the rules of the game of the type of algorithms that will build for this particular problem so what are the known results about the quantum linear system problem um well we know of the former hhl algorithm uh its scale in asymptotic scaling this order notation has constants which may be important in applications but it was basically quadratic in the condition number and logarithmic in the dimension of the matrix which is what made the algorithm um excited been a later improvement by mbinis he introduced the notion of variable time amplitude amplification and was able to reduce the complexity to something that was almost linear in the condition number and this can be proven optimal uh in the query model more recently my paper with child security we were able to reduce the scale in terms of precision to something that was polylogarimic so this was an exponential improvement and we'll discuss this into more detail to this end we have to introduce the notion of linear combination of unitaries which basically replace the phase estimation step in the hhl algorithm and there's been a couple of other algorithms based on adiabatic evolutions this paper in 2018 is again inspired by algebraic evolution it's a randomized algorithm we were able again to obtain a linear scaling in the condition numbers almost optimal there and other improvements by anne and lean where they basically randomize the algorithm that we present i should point out that there's been other algorithms uh we heard today about other approaches those approaches are similar their core ideas are similar to this idea of linear combination of unitaries in which they aim and approximating the inverse function for example so why are these results important at all well so on one side it's nice to know that we were able to uh obtain optimal algorithms for the quantum linear system problem we knew about the lower bound but we didn't know whether we could achieve it these improvements allow us to provide some other true quantum speed ups and explain those a little bit more later and uh for example the approach based on linear combination of injuries or related approach on quantum signal processing this allows us to reduce complexity in terms of precision which is very important if we need to perform high precision calculations at the end instead that we prepare and on the other side this algebraic inspired algorithm because it was so simple it had a record at least until last year i think being the biggest implementation uh to solve the linear system on the quantum computer uh just as a 8x8 system but um it opened the possibility of dealing with with larger problems all right so as i mentioned right i mean on one side we're claiming there is an exponential speed up because the complexities are only polar logarithmic in the dimension of the matrix but in reality these algorithms do not output the full vector okay so when looking for applications this becomes challenging people have looked at this here i mentioned a few examples we know that for example uh we can use these algorithms for computing the resistance of a network the speed up there is not exponential it's polynomial there's another uh application for example uh computing the hidden time of a markov chain again the polynomial the speed up that we saw there was polynomial not exponential and there's been applications in machine learning and solving certain linear differential equations where the speed ups are truly unknown okay it will depend on type of instance what type of speed that we can have so finding applications i mean it's kind of finding applications it's hard um we kind of like have the hammer but we need to find for more nails all right so i'll give you a quick review of the hhl algorithm and then i show how to improve all right so let's assume that we have a matrix a there is a spectrum composition there are eigenvectors of the matrix it can values lambda j all right and i will assume that kappa is my condition number so the balance range all the way from one over capa to one all right so if cap is very large then the slower second value will be very small and the matrix will be harder to invert so the h algorithm starts by preparing the initial step b that encodes the vector b in the linear system okay we know loss of generality is a spectral composition of it it uses what the so-called phase estimation algorithm to perform a map in which now i have a register of qubits that give me some eigenvalue estimates okay then i apply a one cubit conditional rotation to perform the map in which i rotate one qubit depending what the eigenvalue was all right and do the phase estimation step and at the end basically i have something a quantum state that has two branches one branch noted by zero here which really implemented something that was proportional or approximate to the uh the inverse of the matrix the c that we want and something that i call the bald part of the state that is labeled by ancillar cubic being one we can use a well-known technique called amplitude amplification that's using robust algorithm to basically get rid of the bar part of the state with one and boost the probability of getting the right part of the state uh towards one the complexity of this education algorithm is mainly given by how many rounds of amplitude amplification i need and what is the complexity of the phase estimation step a detailed analysis gives the scaling that i gave at the beginning which is almost quadratic in the condition number and poly logarithmic in the dimension of that matrix so how can we improve such an algorithm okay so the first idea that came by um unbiased in 2012 was based on this technique of variable time amplitude amplification so rather than doing amplitude amplification in one step as the hhl algorithm does okay what variable time amplitude amplification does is place the state into branches depending what the gain values are larger and lower again values and thus variable does amplitude amplification to each of the branches sequentially okay so this allows you to go from a quadratic scaling the condition number to something that is linear and certainly i don't have time to discuss more details about this another idea which is in our 2017 paper in order to improve upon the precision scaling uh was to approximate the inverse operator by something else okay instead of doing phase estimation for example we can use a fourier transformation okay that approximates the inverse of a as a linear combination of unitaries so this unitaries here would correspond for example the evolution standard matrix a for some time and one can show that by using this fourier approach that time is at most logarithmic in the inverse of the precision parameter and this is what it allows basically to prove an exponential improvement in terms of precision so other approximations can be used here as polynomial approximations that we saw before uh i picked the the fourier tran uh transform as one of them because it gives us you know the the interesting results but um that paper also contains approximations based for example in chebyshev polynomials so how so once we do have this linear combination of unitaries how is that we are going to implement them so there is this nice uh quantum primitive that we developed for hamiltonian simulation methods basically what it do is they map a step psi to a linear combination to a linear combination okay of two unitaries v1 and mu2 by using this uh quantum primitive that we have here so the the operation b basically what it does it rotates an ancillary such that the state after that rotation calls the coefficients alpha and beta and we have to do such an operation at the end when we look at the state at the end we have two components okay two branches and one of the branches is the state that we want to so we may use again amplitude amplification to boost that amplitude all right so um while we prove that this linear combination of unitary's approach has optimal synthetic complexity it still requires many ancillary qubits this can be further improved by for example using the techniques of quantum signal processing but in this case it still would require many ancillars so we resolve this issue of having many ancillars by providing a new quantum algorithm inspired by alabama evolutions and then go through it fairly quickly so this algorithm is based on a randomization method that we developed with boise neon in a 2009 paper the idea is similar to the idea of adiabatic evolutions there is a hamiltonian path an interpolating path such that the eagan state of the first of the first hamiltonian can be mapped along the evolution to take a state of the final hamiltonian and we chose those hamiltonians such that the egg institute of the final one is the desired state that solves the quantum linear system problem rather than doing these evolutions in continuously in time this randomization method basically what it does is it picks hamiltonians along the path and evolves with them for a random time this simulates measurements okay and these measurements basically due to the scene aspect uh will map will transform one quantum state to the other against it with high probability so by picking the discrete decision in the path right then we can assure that we have probability we will evolve towards the state that we want to to prepare here so we could show that the hamiltonians that we chose the minimum spectral gap goes with the inverse of the condition number that the agencies of these hamiltonians in fact correspond to linear systems of increasing complexity so the beginning i'm solving a very simple system at the end i'm solving the system that i want to and in fact the agency of the final hamiltonian is the solution of the quantum linear system problem when you look at the scaling of this algorithm it almost scales linearly with the condition number again polylogalimic in the dimension and with the inverse of the precision parameter and this technique as i said before can be randomized by a purely adiabatic approach that was provided by anne and lean in the 2018 paper and was discussed before all right so um the next thing is that the asymptotic complexity of this alibi inspired approach is almost optimal if we are looking at constant precision the algorithm is built upon simple hamiltonian evolutions i didn't discuss the hamiltonians but those scandinavians are fairly simple and they don't need techniques complicated techniques such as variable time amplitude amplification that require many ancillary units in fact in here only one additional and serial equivalent was needed and while the complexity was linear in the inverse of the precision it can also be made logarithmic in this quantity by using one of the many known methods for example foreign quantum state filtering as we heard in the previous talk so um so the there's been other proposals for this quantum linear system problem okay many of those purposes were based on variational and related quantum algorithms to this problem and some of the claims is that these approaches may be useful for noisy quantum mechanologies for example nist devices may solve for example the quantum linear system problem may not need a quantum metal correction and so on but when you look at it you give a closer look to such proposals when um it becomes evident that on one side they require a costly optimization loop remember this variation approaches aim at minimizing some cost function all right so we have to have some sort of feedback in which the information that we got from computing some expectation value has to be fed into the initial step preparation and repeating this many times at the same time related to this is that these cost functions have to be computed at very high precision and that precision has to depend on property on parameters such as the condition number of the matrix all right so when you put everything together and you look at random instances of this problem you can see that this has some unknown or even poor performance and the performance could be even worse than that from the algorithms that i described today in fact i would say that these two reasons are um two of the main reasons that basically will kill many of the proposals for using this devices um in many problems in linear algebra and these are two of the things that we will have to really look into when we design um um quantum malga and star amino alternates device all right so i'm rubbing up and um so so what i want to say basically is conclude is that quantum computing is promising that we know that there's problems uh quantum mechanics for some problems in linear algebra uh i describe some quantum algorithms for sovereign problems related to linear systems with number of improvements in terms of precision condition number and so on the complexity is logarithmic in the dimension all right but the technique the techniques that i developed can also be used in our algorithms and problems for example in hamiltonian simulations uh as it was the case for for for these techniques that we developed here i also presented a few applications for this including machine learning okay uh but it would be really nice to have many more and again as i said before i think we do have the hammer but it would be nice to have more nails for this problem all right thank you very much 