 all right let's see who's coming in today hi everyone we have another teen science cafe today i'm going to share my screen for those of you who have been with us before you know the drill and for those of you that are new give me one moment and i'm going to tell you what we do i just want to open up a couple of documents so that is not what i wanted to do would help if my mouse worked today all right i see some of our usual suspects are back today hi simon and jack hi emily hello mariah and adrian from the fluffy dreamland nice hi desmond so for those of you who don't know me i'm lauren traister i am the 4-h teen and leadership program coordinator here at uvm extension i also coordinate these science cafes which i love and i love that we get to meet every week to learn something new about science so for those of you who are new here um please find your chat box and we like to do introductions and as you can see they've already started we have summited scout from maine and catherine's from vermont we have sage also from maine so just go ahead put your name in the chat let us know where you're from i am also going to put in the chat right now if you need the live captioning today that is the link where you can access the live captioning hello fiona from vermont so as we are waiting for everyone to join in i'm going to go over our protocols for when we are gathering together here in zoom hi eric from vermont so all of you are muted today you we can't see you you're only going to be able to see myself and our presenter and you don't have the ability to unmute yourself um the way you are going to communicate today is through the chat box and through the q a box and we use those two things very differently we use the chat box for you to share your thoughts and your comments if the presenter asks you a question you're going to answer in the chat box to create a back and forth communication the chat box is not to be used for off topic so we stay on topic in the chat box to keep things moving along so we don't create any distractions if you have questions for our presenter those go in the q a box and those will get answered but they may not get answered immediately so when you ask your question try to be as clear and specific as possible so that we know what you're referring to because it may be several slides later or maybe 10 minutes later before your question gets answered but again all questions do get answered that is the beautiful thing about our science cafes the questions you have our scientists will answer them for you so remember to be courteous and respectful to everyone today um and again just don't create any distractions the only way that happens in this format is with the chat box if i do see that the chat box is being used inappropriately i will private message you and tell you to stop um but you all have been so good over these last many many weeks that i don't expect that to be a problem so i always appreciate how engaged you all are so that's the last thing to stay engaged participate fully that is why you are here today to learn something um so let's do that so i just want to remind you um i always like to share other opportunities with you we still have the speak up contest that the deadline is november 30th so there's five more days for that that actually if you win in your age category you could win a 50 gift certificate so i encourage you all to check that out um and we have after today we have three more science cafes before our holiday break for the new year and i am happy to tell you all i am putting together the schedule for january through june we have some amazing topics that have um come up so i'll be announcing that schedule soon so jack the gift certificate yes for the speak up contest if you enter the speak up contest and submit a video video by november 30th um there's three age categories that we're gonna pick a winner simon okay thank you um and if you win in your age category you'll win a 50 gift card so i would encourage you all to check that out it is you know talking about something that you feel passionate about something you want to see in your community change so it might be of interest and then of course there's that added bonus of getting some spending money right okay so i always let you guys know our friends at vermont brandy are still meeting every week um if neuroscience is your thing or you want to learn more about the brain i would encourage you to check out what they're doing at vermontbraidb.com and maybe participate in their weekly sessions we also have our friends at the lake champlain secret they have one more zuma scientist session on december 4th and then our friends in maine have their teen science cafes and they've added some new dates and topics which you can see here i'm going to put these links in the chat as soon as i am done talking so you'll all have these links so you can go check them out so today we are talking about privacy on the internet why does it matter and how do we get it in our presenter today is professor joe near and i just want to give you a little bit of information about joe he is an assistant professor of computer science at the university of vermont and a member of uvm center for computer security and privacy his research interests include data privacy computer security and programming languages joseph received his bs in computer science from indiana university and his master's and phd in computer science from mit so let's all welcome joe to our teen science cafe and joe it is all yours now thank you for being with us today thank you uh all right is my is my screen visible i hope yes all right um let me move my mouse over here i wonder if these little videos in the side can everybody else see that or do only i see that the little videos um those are you and i okay right i was just curious if everybody can see that or yes yes all the participants can see that um so my name is joe i'm an assistant professor at the university of vermont in the computer science department uh and i do research on privacy on the internet um and privacy in general privacy especially in uh kind of how we analyze data so i'm gonna talk a lot about privacy today i'm going to talk about some other issues that show up on the internet and in kind of some of the modern ways that we deal with data and a lot of the problems i'm going to talk about today actually are kind of issues that come up when [Music] new ways of using data surprise us okay so this is almost a technology talk in a society talk as much as it is a science talk um all right so i guess there's a picture of me i wanted to get that on there just in case you couldn't see me but i think you can all see me um so you've all seen this uh that plaid symbol there that's uh the research lab that i'm part of at the university of vermont um so i'm part of this center for security and privacy at the university of vermont and our kind of research arm is called the plaid lab and we do research in security and privacy and algorithmic fairness which i'm going to talk a little bit about today as well so i've been at the university of vermont since 2018 um that's when i moved here so i'm a relatively recent transplant to vermont before that i lived in california i was a postdoctoral researcher at the university of california at berkeley and before that i was getting my phd at mit so you know the first thing that that everybody from vermont asked me is uh how can you possibly move here from california right you must hate it here because we actually have winter and i'm like no it's okay i lived in boston before that i know what winter is like and i grew up in indiana that's the symbol for indiana university that's where i did my undergrad uh and so we had winter there also um but i kind of started out i grew up in a small town so in indiana universities in bloomington indiana and there's about 30 000 students at indiana university and there's about 60 000 people in bloomington so the university is like half the town and i'm very pleased to be back in a small town again a reasonably small town i i really enjoy living in vermont um so before i start talking about i'm going to talk a little bit more about me um but logistics wise i am the reason there's two of me i don't know if everybody can see that but i'm logged in twice uh i've logged in on another computer right here so i can see the chat at the same time and the q a and uh i would like to encourage everybody to ask questions as we go along and i will do my very best to answer them as we go and so i'm going to start doing that now i see actually in the q a there's a question already what's my favorite coding language what do i use the most and i actually don't have a huge preference on this right uh i would say the one that i use the most is python i'm going to show you some examples of python today and the reason that i use it the most is just because everybody else uses it it's it's becoming uh kind of the language for coding that the vast majority of people know a lot of software is written in python and so we tend to use that just because that's what everybody else uses i like programming in some kind of less well-known languages like haskell uh which is a functional programming language um there's some other kind of related functional programming languages like scheme and racket that i find a lot of fun but i don't get the chance to program in those very often because if i write code in those languages nobody else can use it it kind of tends to be the case um okay so what gets me excited so we're gonna talk about privacy today um that's the first thing here and there's a netflix envelope there we'll talk more about that in just a minute uh so this is gonna be our topic for today another thing that i'm really into is bikes and bike racing uh so that's me after a race in the rain back when i raced for mit and when you when you race bikes in the rain you know you're all kind of in a big pack you're following somebody close uh in front of you and their bike kicks up a bunch of water and mud into your face and so you look like this afterwards so i've been racing bikes for a long time and and this is another reason i love living in vermont it's an awesome place to ride bikes the other thing that i mention often is that i really like going to arcades um i have two kids i have an eight-year-old and a four-year-old and they love going to arcades and i love it too and so uh we go to our kids any chance we have there was one called pizza putt here in burlington and it closed last year so that was very sad we used to go there like every weekend uh we were regulars there and we don't get to go there anymore um when they closed down we actually bought one of the arcade games they had there there's a picture of it it's called spider stomping so this is i have my own little arcade in the basement got one game in it um i see r.i.p pizza putt in the in the chat indeed uh it was a real like it was actually a very sad day for my family when the pizza pie closed okay so here's what i'm going to talk about today um i'm going to start by kind of talking a little bit about you know in if i was giving a technical talk right i would say this is the motivation section right the mess we're in um and i want to try to relate this to kind of some problems you've probably heard of and so i'm going to talk a little bit about kind of what are the problems in society that we see when we don't handle some of these privacy and fairness problems that i'm going to talk about and then i'm going to talk about two of the areas that i actually do research in so privacy and fairness and how those problems kind of show up in the way that we're seeing issues uh pop up in society today and and how we can solve some of those issues and i'm going to end by talking about you know what are some of the pieces that we still need to solve that we don't have uh good answers for um oh i i missed a question have i won the spyder game so it's one of these games where uh you get a score and you can get a perfect score so so the way that you play the game is you start the game and then these things that you stomp on they light up uh and when it lights up you're supposed to stomp on it and that's supposed to kind of simulate the fact that you're stomping on a spider that's why it's called spider stomping and when one of these things lights up you stomp on it and then it makes this this sound like a spider being crushed right like like a screaming sound right the spider goes ah and uh so if you stomp on all the spiders perfectly then you can get a perfect score like 100 and i've done that before uh but you can never win like the best you can do is get 100 and then move on to the next game um okay what would i say is the best privacy thing that blocks things trying to spy uh i'm gonna say more about this as we go forward the truth is there is nothing that can block things that are trying to spy right you will be spied on if you use the internet uh and that's kind of the sad truth um so i will say more about this as we go along there are things you can do you can do things like uh there are browser extensions you can install like there's one called ghostery there's do not track modes that you can turn on your web browser sometimes you can not use social media you can not use certain websites but in general if you use the internet if you use a cell phone you kind of will be tracked right um so i'll say more about this as we go along okay so why are we in a mess right i'm gonna say there's two reasons right and one of them is that we know a lot more now than we used to know right so if i have a whole bunch of data how can i learn things about individuals that i can use to violate their privacy it used to be that we had data in like books right people would actually write stuff down so before we had computers at all for example and so if i want to attack somebody's privacy and i have a book full of say census data or something like that it's time consuming and challenging for me to do that i have to like look through the book physically uh and so it was not really considered a big a big problem before we had computers so now we have computers we have i'm going to show you some examples of ai systems for example that can look through data very fast right huge amounts of data and so the fact that we now have bigger computers and we know more about uh honestly we know more about math right uh means we're able to track people better to attack their privacy better we're able to learn things about people that in some cases they don't know about themselves uh you know these are things that we just couldn't do before because we weren't good at math and we didn't have big computers right so that's been one big driver of this the other one is that we now carry around these cell phones all the time so you know i i have this i have a an apple iphone and uh honestly the reason that i have this instead of like a flip phone is because uh you know my wife gets worried when i go out on bike rides she wants to be able to track my location and know that i haven't been hit by a car or something but basically everybody has one of these right and you kind of have to have a smartphone now to participate in society and one of the real challenges of this is that first of all it's a surveillance device right so your cell phone is always on it's always tracking your location uh anytime you use it to do anything the vendor of the app that you're using to do that gets to see what you're doing so it's a way for people other other people to see what you are doing it's also a way for them to affect your behavior so um on your cell phone if you use uh any app basically but especially social media apps you're gonna see ads right and the cell phone is kind of like a direct link from those companies to your face to show you ads to get you to do what they want you to do right and and we've never really had that before you know on the tv for example right they've got to show everybody the same ad i'll talk more about this in a couple of minutes but you know the cell phone really has changed things because it's it's two directional and the two directions are are like fundamentally different than things we had before okay um do okay so here's a question in the q a uh do they try to make privacy policies confusing uh i assume this is referring to companies in general so um i assume you mean those privacy policies where when you sign up for some service there's like here's our privacy policy you must click agree or you can't sign up for the service right and these privacy policies generally are so long that you have no chance of reading the thing even if you want to and even if you do read it you're not going to understand it generally speaking and i think the answer is like yes absolutely they do make those things confusing they do make those things confusing on purpose they want you not to read them because if you actually do read them you know basically those privacy policies say you have no rights we have we the company have all the rights and we reserve the right to do whatever we want and you can't sue us for it and that is like yes absolutely i mean there have been lawsuits about this where it's very clear that the company has intentionally constructed the privacy policy to mislead people and to you know put themselves in a position where they can do bad things on privacy and um we're going to get to this but i think maybe one of the only ways to really solve that problem is to introduce regulations on companies to just like force them not to do that um ah okay so there's a couple questions now in the q a about cookies um so the first one is what does i accept the cookie policy mean right so this is increasingly common you go to a website you'll see at the bottom a little banner that says we use cookies just like every other website don't worry it's not a big deal please click i accept to accept our cookie policy um what is a cookie right so your web browser normally you go to a website and your web browser's job is just to show you that website right but it turns out that it is useful for certain websites to be able to store some information on your computer so that when you come back to their website they recognize you and they know who you are so you have a shopping cart for example on amazon when you go back to your shopping cart the same items appear there that were there before and so the way that that on the web you can store this kind of information in somebody's browser is with this thing called cookies and this was the way that cookies were supposed to be used they were invented for this to do things like uh i i the website developer i'm gonna store a cookie in your browser that stores all the items in your cart so that when you come back to your cart you see the same items again okay and that was what cookies were invented for very quickly web developers realized they could store cookies on your web browser that would track you and they could track those cookies that were stored in your web browser across different websites to get a history of all the websites you have visited over a period of time okay and so they started doing this and so in europe they invented this rule called the gdpr or the general data protection regulation that says companies you can't do this you can't store cookies on people's devices without at least telling them why you're doing it and what you're doing it for and so that's why you see those banners is because now when a website wants to store one of these cookies on your device they are required by law in europe to tell you about it so when you accept that cooking policy it means that they are going to store cookies on your device probably for the purposes of tracking you and they're kind of getting around the rules that are imposed by europe by telling you that they're going to do this the banner always implies don't worry about it it's not a big deal just click accept that's what everybody does right and that is intentionally misleading you into thinking it's okay to click accept if you don't click accept they will track you anyway so it kind of doesn't matter it can never hurt your computer to click accept it just means they're going to store these cookies on your computer um you're not going to get a virus or anything like that so honestly it probably doesn't matter that much whether you click accept or not but it's another one of these places where um you know these sites on the web are kind of intentionally misleading you about their privacy policy they're implying that nothing bad will happen if you click that accept button because they want to be able to track you um when a website tells you it uses cookies is it bad could it be used for tracking and stuff like that yes absolutely it could be used for stuff that actually improves your web browsing experience like on amazon they use them to retain the information in your cart stuff like that when you log into a website when you log into google next time you go back to gmail you're still logged in they use cookies to remember that kind of information as well to keep you logged into websites but it also gets used for tracking all the time what happens if you don't accept so if you don't accept usually some functionality in the website will break uh sometimes nothing will change at all right because the only thing they were using cookies for was tracking you and if you click i don't accept then they will stop tracking you or they will stop a certain mode of tracking you and because they didn't use the cookies for anything functional on the website the website will look the same to you so you know one experiment to try is just always click don't accept right and see what happens uh usually nothing bad will happen um but like i said they have other ways of tracking you so it probably is not going to help you not be tracked even if you click i don't accept um if you don't click anything at all yes they can still track you sadly uh why are they named cookies so that's a really good question i don't know the full story of this um i i think i knew at one time i want to say this may be completely wrong i'm going to take a guess here and i might be totally wrong about this that the idea is that um so cookies were basically invented to allow websites to remember things that happened in the past so if i added some item into my cart in the past the website wants to be able to remember that so next time i come back to my cart the item is still there right and so there's this you know in the there's a long history in all kinds of kind of uh folklore things where um folklore is the wrong word here but like uh you know stories where people leave crumbs for example breadcrumbs behind them in order to remember where they have been and i think it may be the case that the reason they're called cookies is because the idea is that you're kind of leaving crumbs behind to know where you were this could be just totally something i made up uh and i i can't remember for sure if this is the kind of legacy behind the name cookies um and i'm going to look this up afterwards because i'm really really curious now not sure if that's the right answer if a website does not give the option to say no to cookies you can turn off cookies in your web browser so you can you can change the settings of your web browser to disallow all cookies there are websites that will break if you do this right so like amazon won't show you items in your cart if you do this so they don't give you you the option you can still turn them off entirely but a lot of websites will break um i don't see an option to not accept there's only a box for except you have to go into the site to not accept so i'm not sure if the rules say they have to give you the option or not so some websites make it very hard to say i don't accept you can always just say nothing i'm going to try to get the camera here to focus better the focus is okay it's getting dark outside and there's not quite enough light for the camera so you can always do nothing and just leave that banner there at the bottom and then you haven't accepted right um [Music] i don't know what the rules say i believe that the law says in europe at least and most companies just kind of apply that law to everybody that um if you haven't clicked anything then that means they better not send you any cookies i'm not sure about that um so i will say before i move on this tracking issue that there are tracking approaches that work regardless of whether there's cookies or not right so even if you turn all cookies off in your web browser you can still be tracked and one of the ways that you can still be tracked is uh there are there are mechanisms specifically designed for tracking you across the internet facebook has one google has one uh google's is called google analytics and the the kind of hook that they use to get you is if you're a website developer you can get for free this google analytics product that tells you statistics about the people who visit your website and that information is useful to a lot of web developers and so they install this thing on their website and guess what what this thing actually does is it runs some javascript code in your browser that tells google who you are and so you can be tracked by stuff like that even if uh you have turned all cookies off you can turn off all javascript in your browser but at this point basically the whole web will break if you turn off javascript so there's basically no surefire way to stop yourself from being tracked on the internet um is it bad to remove cookies with a remover because it won't remember your cart it usually will hurt you only a time like nothing severely bad can happen if you remove cookies they are intended to be temporary and so websites will always have a way to recover if you remove cookies maybe your items will go away from your cart just add them again i mean never it's never the case that something catastrophic will happen if you remove cookies uh they have tracking built in yes absolutely tracking is basically built into everything now um okay so who's seen this social dilemma right i imagine a lot of you have seen this you're asking really good questions so i bet a lot of you have seen this if you haven't seen this you should go see it right this is a documentary it's on netflix and uh it's all about kind of what social media companies are doing to or what they are doing right they have a lot of reasons for doing it they have several reasons for doing it they have some really important reasons the major one is they want to make more money and the way these companies make money is they show you ads and the more time you spend looking at your phone on facebook or on instagram or whatever the more ads you're going to look at so the more money they're going to make right and so there's this kind of built-in incentive in this business model to make the product more addictive and this document is really all about this right it's really um they interview a whole bunch of people that used to work at some of these companies and these people talk about like yes we go to work every day and we make the products more addictive right and they say it indirectly right and in fact facebook has you know written a whole bunch of things to try to persuade you that this is not true all of these companies are trying to persuade you that this is not true um you know here are some selected quotes from facebook's response to the the social dilemma uh documentary they say facebook builds his products to create value not to be addictive i'm not even sure what that means what does create value mean uh and it's related i think to the second point you are not the product um so one of the the points that people make about products like facebook or about systems like facebook is you know the the person who is paying facebook is the advertiser right you are not paying facebook as a user of facebook and so you are not really the customer right you're not paying facebook so why should they care about you they care what the advertisers think they don't care what you think and so facebook says oh facebook is funded by advertising so it remains free for people this seems to me completely contradictory to the part in bold right if you are not the product then facebook should be funded by you right when you go buy a car you're the customer because you are paying for the car um so i'm not convinced by this but facebook has written a lot of stuff about this to say you know we promise we're not trying to make the product more addictive we're trying to make it more useful right but i think there's a lot of evidence that in fact there's this implicit incentive that facebook and these other companies have to make the product more addictive the more addictive their product is the uh you know the more money they're going to make because the more ads they get to show you and you know my personal opinion is that in 20 years we're going to look back and be like well duh of course right it's kind of like the way we look at cigarette companies now in in the 90s it wasn't even that long ago there were these lawsuits against cigarette companies where you know in court they said to the cigarette company ceos do you think cigarettes are addictive and they stood there and they said no right and we look back and we say duh right uh and i think probably that'll be the case in 20 years so i encourage you to go see that documentary it's on netflix it's easy to watch and i i don't want to rehash the whole thing but it's really informative um i want to get some questions um would there be a problem using facebook without an account not saying i use it of course so i so first of all i don't want to tell you to delete your social media accounts right because facebook really has us in a tough position here it's basically impossible to be a functioning member of society now without using these products right they are essentially utilities it's like telling you oh yeah you should delete your electricity account you should just stop using electricity because the electric company is going to track you it's like not a choice right you can't throw away your cell phone you can't delete your facebook account people can't function in society that way anymore right it's kind of a false choice i don't have a facebook account i'm in a a position of real privilege to be able to say i'm going to kind of put my money where my mouth is and not use it but for a lot of people it's just not an option to do that okay so i'm not going to tell you to delete your account because i don't think that's a realistic option for a lot of people but here's the bottom line they're going to track you no matter what they have these things called shadow profiles and you know there there are former employees of facebook that have talked about this this was a real thing that has happened and i bet it's ongoing where even if you don't have a facebook account in their servers they have records about and they track you wherever you go on the internet those websites that have the little tracker embedded in them the facebook tracker they track you whether or not you have a facebook account and so they have an account for me they have all kinds of information about me they collect contact details from facebook members and so if somebody else has my phone number in their phone book on their iphone or something then when that person joins facebook facebook gets to learn my phone number so that account that that shadow account about me has a lot of information about me that i never gave to facebook and you know they keep track of that and they keep that in their servers i'm sure they know a whole lot about me um well more than i would like them to know even though i don't have an account so deleting your account doesn't really solve the problem anyway um am i evil for putting cookies in my coding projects no absolutely not i would say if you are a web developer and you really want to be proactive about this don't use tracking products don't use google analytics don't use the facebook analytics products um it's fine to use cookies cookies are not inherently bad if you need cookies to store state on somebody's browser like um you know storing the items in their cart so that you can remember those when they come back to your site that is a perfect use for cookies cookies are not inherently bad javascript code is not inherently bad even though these are used for really bad things in a lot of cases now they're not inherently bad and i'm not going to say don't use them if you're not trying to track anybody then there's no problem with it right so absolutely i think that's fine okay why do people want to track us and could it be dangerous they want to track you to make money okay so it all comes back to this if they can figure out how to make you spend more time looking at ads then they can send you more ads and they can make more money so they don't really you know there's not like some secret plan at facebook to say we're going to track all these people and that's going to like allow us to take over the world right that's not the deal they just want to make more money and i i think it's pretty simple i think that's kind of the bottom line but what they figured out i'm going to talk more about this in a minute is that the more they know about you the better job they can do making you look at ads for longer okay and so they want to know as much about you as they can possibly learn okay so they win no matter what no they don't win no matter what right they don't win if we design laws that limit what they can do okay and i'm gonna get to this in a minute also but i think that's kind of the only way to prevent them from winning okay um kind of obvious about facebook it's literally a book of faces that's a good point um okay so i want to talk about something i call tech washing i didn't invent this term but um this term has been used in other ways and so i want to define what i mean by it when i say tech washing so tech washing in the way that i'm going to use it today is the process of using technology or using math or using science to basically convince you that something is neutral or something is inherently good or okay or that you should kind of assume that it's not going to have a bad effect on society right and ai and machine learning are good examples of this right so how does facebook work the social dilemma i think does a really good job of kind of uh anthropomorphizing this almost right they have these scenes where there are actors pretending to be artificial intelligence agents right trying to figure out how to send a particular person a particular ad to make them do something and this is what actually happens at places like facebook they do machine learning or ai and they they generate these machine learning algorithms where the input to the machine learning algorithm is everything they know about you plus some goal right and the goal is something like maximize ad revenue and then the machine learning algorithm does something and nobody really knows what it does right like literally nobody knows what it does and what comes out is something right some you know they ask the machine learning algorithm what ad should we show you next on facebook and the machine learning algorithm says i think this ad for a car would be really good and they show you the ad right and they say we're not trying to make the product addictive right the we just have these machine learning uh algorithms that are really good at what they do they make the products useful they add value by increasing ad revenue uh you know they they kind of use this language to um almost kind of pull the wool over our eyes about what the goal really is right in a sense this process of tech washing is outsourcing the blame to a technological artifact in this case that machine learning model that thing in blue it's intended to be like a kind of icon that looks a little bit like a brain but kind of like a computer brain um and you know this is this happens over and over and over again right there are these technology products that people say the product is neutral or the tool is neutral it's just a tool right and facebook says this is just a tool for connecting people but the goals that they feed into this machine learning algorithm are things like maximize ad revenue and then they say okay now anything that happens next is not our problem because it's just math in there right and then the machine learning algorithm figures out oh actually in order to maximize ad revenue what i should do is i should make the product more addictive right they've outsourced these very negative things to this technology product so that they can wash their hands of it right and and that's what i call tech washing and we're going to see some other examples of this it's pervasive right whenever somebody tells you a tool is neutral or they're just building the tools and how people use it is is up to them like be skeptical okay that's that's my opinion be skeptical uh because this might be happening they might be kind of outsourcing the bad stuff to math or technology um yeah so when in the chat somebody says i would have inflicted laws on facebook a long time ago i think i would have too so so here's a question how many how much time you spend using your phone every day i think that i my computer is doing an interesting thing here because of uh this let me okay so i've launched the poll and and everybody started to take it so hopefully you all see the poll and put your answer in it for some reason you don't see it just put your answer in the chat box but it looks like most of you um have gone in i know a couple of you are doubled up on one computer so hopefully you all like jack and simon hopefully you guys can agree on what your answer is same with scout and summit ah so this is a good question actually in the chat uh i don't have a phone does a computer account right i'm impressed uh you know there's not a lot of people who don't have phones anymore i i wish i didn't have one to be honest um i was thinking just phones honestly because that's kind of the most pervasive setting i will admit that i have lots of problems getting distracted on the computer i have locked down my phone so it doesn't even have a web browser on it because i just can't keep myself from wasting time looking at websites i'm impressed that you all are saying less than an hour i am i am bad i i uh i'm on facebook but i use it um i read the news so i use facebook because i'm on like various news organizations and that's how i read the paper i started getting my news from podcasts only because then at least it's like in a defined period of time and i can't uh you know products like facebook but also if you just go to like a newspaper website now the websites are designed to keep you clicking on the next thing and uh just my personality i can't i can't help myself i just always click on the next thing you know part of the reason that i i take kind of in some ways extremist positions to say like it is not your fault it is the product that is addictive and partly that's me selfishly reacting to the way that i use these products or failed to um i get sucked into these real easily but it's not just me right uh the average according to this there's an article there's a link down here um the average is about 3 hours and 30 minutes per day so i am actually really impressed that uh you know people use their phones less than an hour that's really impressive i struggled to keep it below that and i've deleted all the apps from my phone like literally all i can do is text people and look at google maps um what program are you using to combine you and your screen so i um the program that you're seeing that has me in it is like a webcam viewer so it's just a program that displays what your webcam is seeing and i'm screen sharing and just showing you what that program is outputting and then this window right here is just a web browser window showing my google slides um okay so here's what i'm going to claim is the solution here's what i think is the solution this is me speculating okay so i don't have any great evidence for this but um you know i don't know that there's a lot of evidence in another direction either so i'm going to claim this is as good a solution as any i think that the first thing we need to do is we need to figure out the world we want to live in right so i would claim that what we've got now is not that world but we need to figure out what that world looks like and this is to a large extent what my research is about right so this is you know i there's a lot of science as well right there's a lot of math specifically to define exactly what i mean when i say we should want this in the world uh but at the end of the day this is what we're trying to do is we're trying to define you know exactly what should we want out of a better world um the second piece of this though is regulation i think right and so the question was asked earlier you know how do you make facebook fix themselves i don't think you do i don't i don't think that the market can figure this out right um you know that it is one of these things where any company even if there were competition for facebook and there's not really but even if there were many facebooks they would all be incentivized to do the same thing because all of them would make more money if they do that right and so i don't think there's any market force that can fix this i think you need the government you know like they do for safety regulations like they do for you know to make sure that the power company can't charge you too much right uh we need regulations like that on companies like facebook so i'll come back to this at the end of the talk um but i think this is kind of the two-step process we need how many people have sued facebook in the questions i don't know actually um it's probably quite a few but the truth is our laws right now don't prevent them from doing a lot of these things that they're doing and so actual substantive lawsuits on privacy issues i think have been pretty rare i mean most of the stuff they're doing is legal i think it's bad but it's legal okay so let's talk about the privacy problem so when i talk about data privacy um in terms of defining my research right i define it this way i say take for granted we're going to collect a lot of data about people how do we make use of that data right how do we actually get something useful out of it while still protecting people's privacy okay and so in kind of intuitive terms what i mean by that is you know we should be able to learn something from this data right if i collect say a whole bunch of health records i should be able to analyze the health records and figure out you know does this drug work or not right that's useful information it doesn't violate anybody's privacy because it's a property of the population it's a property of everybody right uh i want to be able to learn stuff like that right the world is a better place if i can use data to learn things like that okay so how do we enable uses of data that look like that while still preventing the ones that are that kind of zero in on one person to learn something about that person um i want to give an example of where this kind of thing can fail so um probably most of you have not heard of the netflix prize when i talked about this say five years ago a lot of people had heard about it uh but this was kind of a long time ago now so netflix released a whole bunch of movie ratings data um and now on netflix all you can do is give it thumbs up or thumbs down but you used to be able to give it a number of stars and they released a bunch of anonymized movie rating data and they were hoping that machine learning researchers would help them figure out how to do recommendations better right so they released these anonymized data um and what do you think happened right so here's a poll how likely do you think you are to be uniquely identified by your movie ratings right so clearly netflix was making the assumption that they could release these movie ratings and people would not be uniquely identified so what do you think all right so i just launched the poll let us know what you think so these movie in the chat somebody says i thought you said anonymous so the movie ratings were just the ratings there were no names attached okay it was literally just like you know for the matrix they gave it five stars right for lord of the rings they gave it five stars uh there were no people names attached so i don't rate movies either on netflix actually not anymore because uh a few years after this they changed their recommendation algorithm uh and what i've heard is that they don't even try to recommend movies you're gonna like anymore they recommend movies that are cheap for netflix to show you so they have all these like titles that they paid for the ones that have the netflix logo on them and those are cheap if you watch that movie it doesn't cost netflix anything and so they recommend those to you they don't say what they do anymore so it's not clear uh so it looks like most people said somewhat likely right so there were some researchers arvind and the ryan and vitali schmadikov who are still doing a lot of really great work in this area what they did is they uh they correlated movie ratings with similar ratings that were on a website called the internet movie database and they found that in fact you can figure out who gave the ratings just by looking at the rating itself they were able to re-identify i think about 18 of netflix customers just using the internet movie database data and this is called a linking attack and this is really common if you have some data that's been anonymized so somebody took all the names out then you can re-identify people in that data by taking data from somewhere else that you often call auxiliary data and you link them together right so if i'm moving ratings from netflix and i also have similar ratings from internet movie database but the internet movie database ratings have names attached i can figure out the names for the netflix customers right um and so this is super common the kind of uh all right i'll say this really quickly uh you can't solve this using a security approach either right so you know netflix intended to release this data nobody hacked them they released this data on purpose they thought they had anonymized it but in fact that anonymity guarantee was not very strong not as strong as uh they thought it was i want to give one more example of this new york city releases taxi data this is an example that is not maybe as popular or as well known but it is one of my favorites this guy named anthony takar he took uh he went to celebrity gossip websites and he found pictures like the ones on the side there of celebrities getting into taxis and he was able to figure out which taxi trips in the taxi data were the ones that the celebrities had taken and so he was able to figure out where those celebrities went to and if i'm the person who's who works at the new york city taxi agency or whatever it is and i'm trying to anonymize this data i'm never in a million years gonna consider oh what if somebody goes to a celebrity gossip website and gets photos right like that's not a thing i'm gonna think about and so these linking attacks against anonymized data are often really easy to do and really hard to defend against i want to skip this poll so i don't run out of time so here's the bottom line anonymization doesn't work okay this is a picture in the top right of latonya sweeney who did a lot of the uh early work on this and i like to think of her as kind of the original privacy mythbuster because for decades there was this myth that if you just remove the names from data then it's okay it's anonymized and you can't learn anything about individuals from it and this is just like not true at all and back in like 2001 massachusetts started releasing anonymized medical records and they were like ah this is gonna you know medical studies will advance by decades because this data is available and latonya sweeney actually went through there and found the medical records of the governor of massachusetts and sent them to him in the mail like in the mail this was 2001 and you know the governor very quickly stopped the program right uh and at the time people thought this was a good approach and latonya sweeney has shown over and over and over again that it is not a good approach anonymizing data just doesn't work in fact the general result that she found is that if somebody knows your zip code your gender and your date of birth for 87 of people who live in the united states that is enough to figure out to uniquely identify right so that combination of three values for 87 of the people in the united states nobody else shares those values okay so this kind of auxiliary data attack where somebody can figure out information about you by having some other source of information about you sadly this is almost always possible when you're dealing with anonymized data so this is a picture of a website uh here's a link at the bottom here it's called aboutmyinfo.org you can actually put in your zip code gender date of birth and it will tell you how many people share them for me it's nobody i'm the only one so i'm in the 87 percent so differential privacy is where i do a lot of my research and i'm going to go through this quickly but if you've heard of differential privacy it's maybe from this talk or a similar one like it um differential privacy actually is used in the iphone to collect statistics about the way people use phones and it's also used on mac computers uh and you know apple uses in several places differential privacy is a way to define what privacy means in math okay and it's robust against these kind of auxiliary data attacks so you can't do the thing against differential privacy that you could do against anonymization um can you put the info link in the chat um let's see that's kind of challenging for me to do let's i don't have a great way to do it i will put in the chat after i'm done a link to the slides themselves so you can get all the links from there um it is uh and i'll also try to put those links in the chat also um what does anonymization mean so anonymization is a really kind of poorly defined term usually it means removing people's names from the data sometimes it means removing what they call personally identifiable information so that's like names and phone numbers and email addresses and social security numbers and the question then is like what is personally identifiable and the answer is basically everything right so movie reviews are personally identifiable because you can use them to identify people we saw an example of that so anonymization is usually usually it means removing personally identifiable information the reason it doesn't work is because in reality all information is identifying information um okay so differential privacy is like math for privacy right um how do you get differential privacy so say i have an analyst who wants to answer some question using data they're going to ask this question of the database they're going to get back some query results and we're going to add some random noise to it okay and if we add random noise to it we get a differentially private result and so the math of differential privacy tells you how much noise you have to add in order to satisfy this mathematical definition of privacy okay so you add noise you have to add just the right amount of random noise uh to get a differentially private result okay so the study of differential privacy is basically all about figuring out how much noise to add and when do you add okay so as an example if i'm asking a question like how many people live in vermont i may get the answer you know 600 something thousand right and then i'm going to add a small amount of random noise like maybe i ask my computer for a random number between 1 and 10 right and it gives me back like 5.632 and i add that 5.632 to the real answer to my question and that's my differentially private answer and it's that randomness that gives me privacy okay random noise meaning uh generally speaking random numbers okay so you ask your computer generate me a random number the more noise you add to your results the more privacy you get there is this thing called the privacy parameter or the privacy budget it's often written with the greek letter epsilon that's that thing there so if you've heard of the privacy budget that's what they're talking about um if you have more data you're so what you're doing when you're adding random noise to stuff is you're giving out the wrong answer right so if i had a random number to my answer then that means my answer is going to be wrong so if i have more data i'm going to get closer to the right answer while maintaining privacy so there's this trade-off in differential privacy you have to give the wrong answer that's how you get privacy but if you have a lot of data then you can get quite close to the real answer while still protecting privacy okay um does zoom use all of this stuff zoom uses end-to-end encryption sometimes zoom has done some stuff that's a little bit shady so it's not 100 clear what they do they don't use differential privacy that i'm aware of but they also don't collect statistics that i'm aware of so it's not like they have data that they need to be using differential privacy on i hope that is true i hope they're not collecting statistics about us okay um i'm gonna skip this averaging attack so who's using differential privacy so apple i mentioned google has been using differential privacy to collect browser statistics for a while so if you use chrome on your on your computer they're collecting information about how you use your browser with differential privacy these are good uses of differential privacy right it means that they can collect statistics that help them make decisions about how to make the product better but they can never find out specific information about you this differentially private information can never be used to target ads that you use specifically and this is exactly what i think we should want from privacy right we should want data that that is useful right that allows us to learn things but at the same time that data should be not useful to do things specifically targeted at one person another user of differential privacy that i want to mention is the us census bureau so census is right now working on their 2020 count of everybody in the united states when they release that data it's going to be protected using differential privacy they actually did an internal audit over the past few years that showed that their previous privacy practices were terrible for exactly the reasons i showed you just like the netflix prize just like this new york city taxi data you could re-identify people in the u.s census data and so they're going to be using differential privacy in the future to protect that information which is really cool i'm really excited about this do you know anything about the dar wed uh maybe that means the dark web uh i think i think probably the question is about the dark web so the dark web is this really vaguely defined nebulous thing right um and i don't know too much about it because this is not related to my research really but basically the dark web is you know websites that are hard to find using a regular web browser and a regular internet connection and there's a system called tor for browsing the internet anonymously it's spelled t-o-r and a lot of these kind of dark web websites you have to use tor to get to them and i it's not really clear to me what you can do on the dark web these days right there's all these rumors about like oh you can go on there and you can get like information that russian hackers have stolen from people i don't know maybe that's true i don't really know one thing i do know is it used to be that you could go on the dark the dark web uh this vaguely defined idea you could get you could go through tour and you could go to a website called the silk road where people would buy drugs and stuff and that website is no longer there so that's a very popular example of a dark web website and it's no longer available um what about the deep web i'm actually not sure what the deep web is maybe it's some subset of the dark web uh i think i've heard that term but i don't know what it means um so here's some of the research that that is actually going on at uvm in the plaid lab um that's a picture of a phd student in the lab named abua and he's been working on a system that can help programmers write programs that satisfy this differential privacy idea okay one of the big challenges in differential privacy and one of the reasons that there aren't more users of it that this slide doesn't have more logos on it is that it's really hard to implement differentially private programs it's easy to get it wrong if you write the if you write a program that adds the wrong amount of noise then the program will look like it's running correctly but it will not satisfy this privacy requirement that you have so what chica's been working on is a system called duet that actually checks that a program you wrote does satisfy the property okay and the goal here is to enable more people to write programs that satisfy differential privacy um and and that's kind of where chica is going with this work um all right so i want to talk a little bit about deep learning and ai uh so here's a picture of a deep learning system that can turn zebras into horses and horses into zebras so that first row of pictures this one right here uh there's a picture of a zebra that's a real picture of real zebras and then they ask the system turn this picture into a picture of horses and the picture on the right hand side is the horses that come out and on the bottom row it's doing the reverse it's turning a horse into a zebra so there's all kinds of cool pictures you can find on the internet of these kinds of systems and so uh here's fake people right so this is these are pictures of people who are not real people right they were invented by a deep learning system so they look like real pictures they're not real people so do you think that deep learning automatically preserves privacy um so there's a poll for this yeah i'm gonna get that up and i just launched it so go ahead and respond to the poll um this may be too easy at this point right because every single time i've asked you a question do you think that privacy will be preserved in this instance right and the answer every time so far has been surprisingly despite what your intuition might tell you the answer is no it won't be so once again the answer is no um this is this is a pictorial example i don't know if i should be able to see the responses um but oh i'm sorry i had um can you see the results now oh there you go i see them now yes most people have gotten the message here uh that uh in fact you know every time i ask this question probably the answer is going to be no so here's a picture of what's called a model inversion attack and the picture on the right hand side where it says training example this is a picture of a person that was used to train an ai system okay so this is one of the pictures that was used to kind of tell the machine learning system what to do and the picture on the left is extracted from the trained model and so what this means is that if i participate in training some machine learning system then that means anything that i put into the system as part of that training somebody else can come along later and extract okay and so if there's pictures of me that go into this image recognition system or something like that then potentially somebody could come along later and pull those pictures of me out and hopefully those pictures weren't you know pictures i wanted to be kept private right so why should we care about this well facebook has all your pictures right they're using those pictures to train image recognition systems that are based on this kind of ai technology those systems don't protect your privacy so this is another student in our lab his name is tim stevens and he's a phd student and he's working on developing differentially private systems for training these kinds of ai systems and so you take one of these deep learning models say for image recognition you put it into a system that he's working on called the immediate sensitivity checker and it tells you how to add noise to that system to satisfy this definition of differential privacy and the results so far that tim has been working on suggest that you can actually add just enough noise to these ai systems so that this kind of attack becomes impossible but the system can still recognize images like this picture has a cap in it right or this picture has a dog in it and so this is this is another piece of research that's going on in our lab this is the thing that tim is working on where we're trying to get to a point where we can build these ai based systems without violating people's privacy so this is another instance of tech washing right we have these machine learning systems they produce more addictive products if we have differential privacy here then this is a more ideal world right it means that they can't use these personalized models to make the product more addictive all right so i want to go really really quickly through this fairness issue um i do want to get to the end but i don't want to go over time okay so i'm gonna go fairly quickly here um i want to make sure i can see okay cool so i don't see any open questions right now um so i want to talk about predictive policing right this is one of the most visible issues in what i would call algorithmic fairness which is another area that i do research in this is an example of a person who was wrongfully arrested because an ai based system said that this person is the person that there was a warrant for right it was a facial recognition system that said yeah this is the person we're looking for it was not the same person right they arrested the wrong person because an ai system got the spatial recognition problem wrong okay so sure facial recognition problems could systems could be wrong sometimes but it is wrong in very bad ways okay and these systems that do kind of police oriented tasks are wrong in very uh ways that should make you extremely nervous overwhelming okay so this is an example of an article from propublica a while back where they looked at a system called compass that predicts how likely somebody who's been arrested is to commit another offense later on and this system is an ai-based system it's not clear exactly how it works but this system predicts that people will re-offend much that are much more likely to reoffend if they are black right and just overwhelmingly so right the system is just incredibly biased against black people and why is this you know the people who make this product would claim well we just put data in right you know we didn't do this on purpose this happens over and over and over again even if people aren't doing it on purpose okay especially when you use these ai based systems so i want to go through this quickly but uh you know here's another poll that that i intended to show but i'm going to give you the answer right it's all the above right machine learning systems do all of these things if i give out some data and there's bias in the data it's going to learn how to be biased right if i give my machine learning system data about previous outcomes in criminal trials right it's going to figure out that our criminal justice system as it exists today is biased right and the machine learning system is going to replicate that bias it's going to in some cases amplify that bias right uh and this happens just over and over and over again and it's another form of tech washing right we have companies that are building products and they're saying ah it's just math right it's just machine learning it tells it does what the data tells it to do and you shouldn't accept that as an answer because we know that this is a major problem okay there are some people doing really really good work in this area that you know kind of were really pioneers in calling out this kind of behavior and here are two of them joy bullam weenie i'm really bad at the same i apologize for that uh and timmy gabriel did some of the the early work in this where they said these facial recognition products like the one that made that false arrest that i showed you earlier these are biased against black people they are just not very good at recognizing black these peop are not confident about identifying black women in particular right so they are really bad at uh correctly identifying people in particular when they are black women right and we know this and since this paper came out a lot of companies including amazon and i think ibm pulled their facial recognition products off the market because it was very clear that they were incredibly biased uh they've since proposed some of the same authors timid was involved in this work they've since proposed that like we know how to check for this right let's just check for it before we release the products and this is an approach called model cards that's intended to do this and i think this is a really interesting piece of work um ah so okay there's a question is dominion the male encounter thing a biased system as far as i know this dominion thing i don't know much about it as far as i know that thing doesn't have any ai in it right it's just people putting in boats and then it adds up the votes right there's lots of bias in our voting system tons of it all over the place voter id laws are a good example of this right voter id laws you know i i guess you could debate this but i don't think it's there's a lot of evidence against it you know i think it's pretty clear that those kinds of laws are racist and you know that's the kind of place that i think we need to be looking for bias in our voting systems uh the primary way that these algorithmic fairness issues come up is when you introduce ai into a system and then blame the ai for some of these problems um so this is some work that's going on in our lab we have an awesome phd student named crystal mom who's doing this work and what we're working on is a way of detecting unfairness as predictions are being made by these systems so this is a graph from a paper that we wrote together recently where the orange predictions are the unfair ones and the blue ones are the fair ones and because you see that spike that's a little bit farther over to the right what that indicates is that our system is able to detect when the machine learning system is making biased predictions so what we hope is that we can turn this into something that can kind of monitor these systems that are you know showing you ads or recognizing people's faces or things like that we can monitor those in real time and when they start making biased predictions we can raise an alarm we can say hey you need to look at this so this is another example of tech washing the goal is identify this face we get biased predictions out if we had mitigations for this kind of fairness problem hopefully we wouldn't end up with these biased models okay so i want to wrap up real quick um i want to come back to this right so we're working on this first part what do we want and i showed you a couple of examples of this with differential privacy we're trying to say here's the privacy we want it would make the world a better place if we required companies to use this on the fairness side of things i went through that kind of quickly but what i was trying to show you is that we need to enforce that when companies use the ai systems they put mitigations in place to make sure that those ai systems aren't negatively affecting people in the real world in a biased way so we're trying to move towards defining exactly what it means to say here's what a better world looks like but i think how do we actually enforce those things is going to require regulation and there's some really good people working on this too so this is raditabe she's starting as an assistant professor at uc berkeley next year and she's working on problems that involve humans and technology right and so a lot of her research is about how do we put humans into the loop to help them uh kind of embed with the technology so that we get uh at the very least we know when these systems are doing bad biased things okay so how do we get it well i think we need to kind of raise awareness that these things are happening i think that's starting to happen right so documentaries like the social dilemma are already doing this i think a lot of people already are way more aware of these issues than they were even a year ago um delete your social media i think this is too hard for a lot of people right this is not a you problem this is a facebook prom it's their fault it's not your fault and so should you be made to suffer for this i don't think so so if you're in a privileged position like i am and deleting facebook is not going to mess up your life then yeah sure do it i think it can help facebook to realize that they need to change but i don't think they're really going to change in the end unless there are laws that force them to change okay and so i think the real answer is we need regulation on these companies we need to force them to move towards this kind of more ideal world uh that in our research some of us are trying to uh to kind of map out okay um so i'm gonna stop there uh i thank you so much for all these awesome questions i'm happy to stick around and answer more questions yeah i'm gonna jump in for a second i'm gonna throw up one last poll for you all to just give some feedback on today and if you have any final questions get them into the q a we know we're we're right on time but we'll we'll run over if you have questions just first do the poll that i just launched and then if you do have any uh final questions for joe just put them into the q a box and we will get them answered you guys have been so great today with your questions always impressed so i'm gonna just like a few more of you to answer the poll let's give it another 10 20 seconds and then we'll see if any questions come in anyone else gonna take the poll and i'll leave it up for a sec i don't see any final questions um so let's all thank joe for all of this fantastic information and um for giving us his time today i know joe you said you were going to throw up the link to the slides um if you want you can i oh i have them i can email them out because i know some people have already well actually if you want the link don't log out yet because we'll he'll pop it up into the chat um and then hopefully we will see you all next week we have three more cafes um in december and then we'll have a break over the uh holiday time and we'll start back up again then in mid january but we have three good ones coming up so hopefully we'll else we'll see you all there and i hope that everybody has a wonderful thanksgiving holiday uh eat some turkey relax with your family uh you know be grateful for what you have and uh just yeah find gratitude in the day 