 thanks everyone for coming today what an incredibly impressive group I hope you and your families are all well and I hope that the science fiction movie we all seem to be stuck in is not treating you too badly and that the next episode is better than this one but mainly we're all thrilled that you're here and interested in bringing the idea of open DP to reality so what is open DP our vision of open DP include includes four parts it includes open source software that's owned by all publicly validated and trustworthy it involves a community that works on deciding what validated and trustworthy means in this in this case it involves a set of institutions to support the software building and the community so far we have Harvard's privacy tools a project at the at the Harvard engineering school that Salil leads we have Harvard's Institute for quantitative social science that I lead the sloan Foundation has provided very generous financial support we've had a great collaboration with Microsoft at this early stage which has provided some terrific people in great use cases and loss of energy and most importantly we have everyone here today those are the first three the fourth one is a proposed new intellectual direction for the field traditionally scholars tend to pick one thin slice on the continuum from abstract mathematical theory to practical application we instead propose that scholars engage or at least understand the whole continuum theorists can develop new directions from the novel needs they see in applications those with applications can learn from theorists that they have options they didn't even know about if more of us engage that entire continuum from theory to practice we think that with open DP we will see rapid and widespread usage in real applications across academia and Industry and government and together we will all create enormous public good so let me tell you about one application that brought us to propose the open DP project in the first place are our first discussions so I'm a social scientist and goal of the social sciences is to understand and solve the problems that affect human society we do to do this we need data data on the subject of our study people and their groups and organizations and companies and societies well we have more data than ever before and that's created spectacular progress but although the social sciences have more data than ever before we have a smaller percentage of the data in the world about the subject that we study than ever before because most of it is actually locked up inside private companies and inside governments so the question is how to get that out in fact one of the key issues is that in in preventing the data from coming out is customer privacy the privacy of the people that we're trying to study that often prevents data sharing what happens now is that people talk about when they're negotiating they talk about balance the balance of the needs of customers and and citizens and the business with the needs of researchers and the public good that balancing doesn't always come out in our favor we want to use differential privacy to avoid the balancing act I want to use it as a technological solution to the political problem of data sharing so no balancing is necessary so to give you a feel for this I want to give you another example outside of deep being outside of differential privacy of a technological solution to a political problem just to give you a feel for what one good application and it's how we convince Facebook to make data available to researchers so I'm just gonna tell you the story so here's how it worked I was visiting Facebook as I had many times to try to persuade the company to make data available one of one of many visits they they said they think about it you know that's usually where I got and I'd been there lots of times so fine I started going home I went to my hotel room and I mean literally in my hotel room packing and I get an email from my friends at Facebook and it says what do we do about this and this was Cambridge analytical so that means that basically I had the worst time to lobby event pretty much in the history of the world so I went home fortunately three days later they called me and they said hey Gary could you do a study of the 2016 election and show everybody that we didn't change the outcome or maybe if we did something wrong tell us what it is and we'll fix it really fast you know losing a hundred billion dollars in market cap sort of focuses the mind and they really wanted to do the right thing so I thought about it and I said oh I'd love to do this study of the 2016 election but I need two things and you're only going to give me one so the two things are complete access to the people and the processes and the data like all the employees get right the employees get access to all the data that they need to do that work but they need a second thing I need no pre-publication approval of what I write because if you get to veto what results if you don't like them then nothing I actually am allowed to publish would have any scientific value at all so we need I need those two things and so I was talking to Facebook to some orc actually and he said well you're right I'm not gonna give you those two things and I said well okay that's fine I'm not gonna do the study so he said no no I really want you to do the study I said well okay give me those two things I said he said no I can't give you those two things I said well so we went back and forth like that a number of times until finally I realized wait a second there's a solution to this it's a it's a technological solution to a political problem but the technology here was a constitutional solution I'm a political scientist so we think about these things so instead of giving me act data access and no pre-publication approval we'll create two groups of people and we'll give each one of them one of those things so one of them was outside academics who proposed to study very specific things they asked to study specific things just like if you get data from governments you have to say what is your gonna study if approved by a process I'll describe in a second for the first time ever they would have no company veto no so there would no be no pre-publication approval as long as they studied what it is that they were proposing to study so who decides not the company actually a trusted third party a commission of senior distinguished academics at an organization we set up called social science one you can see it on the web social science thoughtful any and we served an institution directly for that for that purpose is now part of IQ SS that organization on or the people in the Commission at that organization sign NDA's agree not to publish on the basis of the data so they sort of take one for the team they choose the datasets that are appropriate they they stand up for the academic community and say those are legitimate datasets they stand up for Facebook and if if there was a lawsuit that was not public and and it was about a subject that was meritorious we would not approve research into that because the roof's the researchers would be to post for the next two months and that that clearly wouldn't work for Facebook either so so that actually solved the problem we solved the problem without balancing the same way differential privacy is going to solve the problem for us they were agreements announcements funding more than 30 people were assigned from Facebook to the problem it was really great it was just one issue it turned out that Facebook's implementation plan for how to actually do this was according to regulators well illegal so we had a new problem and that is how do we share data without it actually leaving Facebook that's what we had to figure out how do we do that so we we then worked on solving that problem and it turned out differential privacy was the technological solution to this to this political problem it avoids balancing and it convinced the regulators that that it was okay for us to study certainly these data we get both sides what they wanted we've now shared a differentially private data set with researchers on the effects of social media on elections and democracy we process an exabyte of data a quintillion bytes and released a data set to social science researchers and others with 10 trillion selves al use it's probably the largest social science data set ever made available to social scientists ever so maybe it's the largest differentially private dataset I don't know um in any event I'm solving problems is hard slogging but with differential privacy technology you all create things that make it possible for us to stuff that were previously impossible so finally I want to I want to illustrate these points with the next step in the story so differential privacy solves the political problem and that's great but gosh you all create privacy protections by censoring or what you call clamping results and then adding noise from a statistical point of view we recall that that selection bias and measurement error and because we're making inferences beyond the private database to a population and censoring noise induce huge statistical biases well known actually so we absolutely cannot use the results you give us as is utility as measured in in large parts of the differential privacy literature has actually no utility for us of course once we understand what you're doing and so we communicate with you once you've communicate with us we can fix the problem right from a statistical point of view a scientific statement is not one that is necessarily correct it is one with known inferential properties like unbiasness and consistency and accurate estimates of uncertainty um so if we can if we can fix these problems once we know once we know the importance of these properties for applications for this particular application at that end of the continuum we can find ways of adding statistical fluids differential privacy and we can make it useful for us and give the theorists something different to focus on as well in other applications there are other things needed that none of us would never have thought those were not necessarily have thought of ahead of time so we call on the theorists here to get to know some of the applications in detail and some of the folks doing the applications and we call on those interested in applications to get to know a theorist or two so you can see the options you would you wouldn't have known about previously and we call on everyone to join this open DP community to help us build trustworthy open-source software available to everyone so thanks again very much for coming let me now give you one of the clearest and most insightful thinkers I know in this field which is Salil valance he is the Vicki Joseph professor of computer science and applied mathematics that's a pretty cool title but he was also recently appointed harvard college professor and his co facts the director of me i was opened EP soiled thank you Gary and I said I'm Sol vidonne faculty member here at Harvard and co-director of open DP together with Gary and let me start by echoing Gary's thanks to all of you for joining us in spite of the circumstances of the pandemic and also wishing you and those dear to you continued health and safety in my remarks I'd like to give you an overview of the motivation for open DP it's elements that we'll be discussing in more detail in the rest of this workshop the timeline for the effort and how you can engage we have a number of attendees who are from outside DP community for example representing use cases in the open source software community so let me begin with a very quick review of the motivation for differential privacy in the appendix of the open DP white paper that was posted on a website a couple of days ago you can find a pointer to a longer primer on differential privacy differential privacy seeks to enable statistical analysis of data while providing privacy protections for individual level data so what do we mean by statistical analysis this includes things like publications of statistical tables training machine learning models generating synthetic datasets that reflect statistical properties of the original data those familiar with differential privacy will notice that here in this slide depiction and indeed in the nerd near term for open DP we are focused on the centralized model where there's a curator that is trusted to hold all the sensitive data and perform releases such a curator may also field queries from external analysts allowing them to perform custom not previously anticipated analyses like running a regression on a variable on variables of their choice statistical query systems are already in use by both government agencies and in industry as a means for allowing the public to study sensitive data in the bottom right you'll see a Google Trends query on the terms differential privacy and I'll proudly note that Massachusetts comes out on top of US states for this query so that's the kind of utility we aim to provide why do we need differential privacy the reason is that traditional methods for protecting privacy are now understood to be inadequate and are vulnerable to worrisome attacks starting with this work of Sweeney there are now numerous examples showing that removing so-called personally identifying information often leaves data sets still vulnerable to re identification where an adversary can use auxilary data sources to still determine who is who even more surprisingly releases of what appear to be simply aggregate statistics can be subject to severe database tree construction attacks where an adversary reconstructed almost all the sensitive data from the released numbers or membership inference attacks where an adversary can determine with high statistical confidence whether someone is in a sensitive data set or a subset of it these attacks don't tell us that all hope is lost only that we need to be very careful even with allowing only statistical analysis and we need a theory to guide us in understanding what is safe and what is not that is what differential privacy promises to offer it gives a way of being sure that individual level information cannot leak when releasing statistical information and is increasingly accepted as a very strong gold standard for privacy protection the way it achieves this is by carefully injecting small amounts of random noise into statistical computations to hide the effect of each individual data subject while still allowing signal about the population or larger groups to come through so it does come with a cost and accuracy but there is now a huge literature showing the differential privacy is compatible with almost all forms of statistical analysis at least in theory or asymptotically here's a partial list that I made six years ago and the literature is only exploded in size since then in addition to lots of advances in the science of differential privacy we have seen a number of exciting deployments starting with the US Census Bureau back in 2006 which recently also made the landmark decision to use differential privacy for all its public use products from the current decennial census there are also several products and tools using differential privacy from large tech companies like Google Apple and Microsoft these are all well resourced organizations with lots of technical expertise to build specialized differential privacy systems for their own use cases unfortunately is currently still difficult for smaller organizations to build differential privacy solutions on their own and wider adoption has been slowed from the research community there have also been many wonderful advances in differential privacy tools but these often stop it being research prototypes that are built by one group don't integrate with tools built from other research groups and don't often don't make the transition to ever being trustworthy production code so with open DP we want to initiate a community effort a community effort to build a trustworthy and open-source suite of differential privacy tools that can be easily adopted by custodians of sensitive data to make it available for research and exploration in the public interest why well what excited me most about open VP is the idea of bringing this community together to channel all of the advances we are making on the science and practice of differential privacy by working together we can build software that is more trustworthy provides greater utility and has larger impact we can foster greater adoption of differential privacy to address compelling use cases and we can provide an advanced starting point for custom differential privacy solutions where they are needed in the other direction as Gary discussed I believe this effort effort will uncover many important and fundamental new research questions for our field we envision the open DP software to be divided into an open DP commons and a number of different open DP systems the commons will be the community governed portion of open DP containing the core library of differentially private algorithms as well as other general purpose tools and packages the open DP systems will consist of end to end differentially private systems that will usually be built in a partnership to address a particular set of use cases and govern more independently the system we've been building in partnership with Microsoft what you'll hear more about later is an example of such a system by definition the open DP systems will make use of components from the open DB Commons once it exists and conversely we expect that that the efforts to building systems will result in you and improve general-purpose components to be contributed back to the Commons subject community vetting the key elements we see for open DP are the following for use cases we are focused on opening otherwise siloed and sequestered sensitive data to support scientifically oriented research and exploration in the public interest including data shared from companies from government agencies and research data repositories the goals of our governance model include ensuring that the software is trustworthy in particular as correct and secure implementations of differential privacy that the software continues to develop rapidly and serve the overall mission and that all important stakeholders are heard the programming framework for the core library of differentiate private algorithms in the open DP Commons should enable the library to expand with the rapidly advancing science of differential privacy while still ensuring the trustworthiness of code contributions and enabling the design of efficient high utility open DP systems the open DP software must provide statistical functionality that is useful for the researchers who will analyze it in particular and related to what Gary's one of Gary's points is crucial that the library of differentially private algorithms exposes measures of utility and uncertainty it will help researchers avoid drawing incorrect conclusions due to the noise introduced for privacy the open DP software must integrate seamlessly with the storage and compute infrastructures arising in use cases in order for the deployed systems to provide secure efficient and usable realizations of differential privacy an open DP must develop fruitful collaborations with other groups in academia industry and government that can contribute to software design and development apply open DP tools to important use cases and provide personnel and financial resources to support open DP and last but certainly not least open DP must build a diverse inclusive and vibrant community who will be motivated to carry its mission far into the future this meeting is the start of our building this community the other six elements are the topics of our plenary talks today the breakout sessions in the sections of the open DP white paper that's available on the project website so the time left left let me tell you where we are in this project last spring I first pitched this idea of open DP to the differential privacy research during a semester on data privacy at the Simons Institute in Berkeley and got a very positive reception so we went ahead and submitted a proposal to the sloan Foundation which generously granted us funding and a few months later our collaboration with Microsoft on building a differentially private system got started in the fall we convened an ad hoc design committee bringing in external experts Marko Gilardi Michael a hey Alexandre karlova and Ilya miranov several of whom you'll hear from today to help us plan open DP we also started working on hiring our initial staff like program director Annie woo who you just met and our Software Architect Mike Phelan and continue to make progress on the on development with Microsoft this spring we fleshed out the details of the programming framework for the open DP Commons and the other elements I mentioned earlier we are near to completing the first version of a differential privacy system with Microsoft and a fantastic and really diverse group of thought leaders have agreed to serve on the open DP advisory board that brings us to today and this community meeting going forward we are going to take all the feedback we get from this workshop and afterwards I absorb a bit and adjust our plans accordingly and get to work on building the open DP Commons we'll also need to get a security review of the code in the Commons will be looking to work with some folks who might be excited to join the team as application leaders driving effort to bring open DP to applications such as contributing to the battle against kovat 19 or other pandemics we also will establish our model for partnerships and start more collaborations and we need to do some fundraising as we are already projected to be short of what we need for sustaining our core team come fall we plan to launch the open DP Commons with a working code base for the core library of differentially private algorithms and establish the editorial board encode committers to review contributions we also plan to have the minimal a minimal Viable Product of a deployable differentially private system coming out of the collaboration with Microsoft this MVP will make use of the open DP Commons and will be integrated with the data averse data repository which you'll hear about next along with all of these launches we plan to have this and open DP community meeting looking beyond we hope for continual growth in the functionality and applications of the software through community contributions increased community governance through a steering committee and sustainability through a community commitment to the project how can you engage well you'll hear more about our plans during the workshop and can read many more details in the white paper on the website hopefully most of you signed up for our mailing list when you registered which will allow you to stay posted or in our progress but the main reason we are here and having this meeting is for communication in the other direction to hear your feedback and suggestions this will partly occur in the breakout discussions but this is a large meeting with over a hundred people registered for each breakout so we may not be able to hear from all of you so please do send additional email be input by email afterwards and anytime in the future and as I just discussed more ways to contribute including eventually code and other forms of collaboration are on their way we look forward to starting to get to know all of you during the next few days at least as far as this online format allows and hope you enjoy the workshop 