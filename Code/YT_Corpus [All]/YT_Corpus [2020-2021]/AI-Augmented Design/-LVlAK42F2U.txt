 I hope that you find this session interesting. Well, if I can help you with something about these topic, well just let me know. My name is Luis Beltran. I am Mexican Microsoft MVP in developer technologies and also in artificial intelligence. For the last 4.5 years, I have been pursuing my PhD in Artificial Intelligence in Czech Republic. Well, here we are in order to share some of my experience working with the Bot Framework. Thank you to all our sponsors for bringing this event, and well, without them, it wouldn't be possible or it would be harder to handle this event. Also, thank you to you for attending this session. All right. So well, maybe we have seen this kind of animation or we have been involved in a project regarding this type of mobile application in which we have user interaction. A person ask a question, then there is someone behind or attending these queries. Maybe the user is asking for some product information, and there is an employee answering these questions. Well, since few years ago, there has been a new technology which is called chatbots, which kind of automate these activities, so the companies can focus their human resources in other areas. Mostly, these queries or these user interaction is repetitive. The user asks a question and there is always the same answer for every user that comes to the application or to their website. Like, "Okay, how can I log in? How can I pay?" Well, they are simple questions but of course, there can be also complex scenarios. So the basic idea is that we can create bot or conversational bot that assist in these scenarios. As you can see, the user ask a question, then there is a reply. Sometimes the bot can suggest something for the user and well, there is flow in these communication. Basically or in summary, a bot performs an action. The bot reacts to messages or responds to these messages. Normally, the bot use the text, the user's intent by using natural language. It means that the user's words, types of words in English, Spanish, and so many language, and about has the task of detecting what they user mean. He wants to pay for something. He wants to book a hotel or a flight. What is the intention of this user? Also, since this is an application, it's software, it can be available 24/7, 365, and it can run in any platform or anywhere. Well, that's the idea. Of course, there is a lot of artificial intelligence behind this in order to improve the user experience, and also keep the human efforts to a minimum. I will talk a bit about it in the next slides. Just something which I found interesting about bots. Normally, we have tools for developing these bots like Bot Framework, but how to develop effective bots or how to improve this user interaction? Well, we need to detect what kind of bot we to develop. For instance, there are some KB bots, knowledge based bots, which basically means that the user wants to do something such as want to find a house. It is the task of this bot to generate some queries from these natural language to guide the user in some conversation. Like okay, the user wants these filters but normally, the user doesn't start the conversation by typing all this information. They start by, "Okay, I want to find a house." Then the bot or the application may respond, "Okay, what kind of house, or what is your budget, or in which side do you wants to live?" And so on. So we can guide the user step-by-step in order to filter the results or improve this conversation. Also, there is support in fuzzy search. Fuzzy search means that sometimes, the user types information that is not exactly as written in our database. Like in our database, we have house but maybe they user says home, or uses some synonym, or even some typos. Maybe he wrote house without u, I don't know. So the bot can also detect this. Fuzzy search is something inside the artificial intelligence, that gives us the most probable result about a word or some item. So the knowledge base bots in short are query in database for instance, in order to retrieve results according to some filters. Normally, well, we mentioned two slides ago that we want to minimize the human effort interaction. This means that normally, when we have our customer service in a company, the customer calls and there is data collection at the beginning; what is your name? What is your location? And so on. Normally, these data collection is repetitive, so it can be automated. But there might be some complex cases that needs some human interaction or some escalation. So since these simple questions or some questions are repetitive, they can be coded. They can be included in the bot part like for instance, the user calls and, "Okay, my computer is not working." Maybe we can launch a wizard. "Have you tried this? Is it a power on for instance?" Yes, no. "No, it is not." Then that's probably the solution for your problem or, "Okay. Yes, it is power on." "Do you have Windows? Do you have Linux?" So we can again, guide the user through some steps. But these are repetitive. Sometimes, the user tried everything. So there is no solution that the bot can give. So we can escalate it to a human, to someone behind a support. Like, "Okay, this is John. I understand your computer won't power on. Let's take a look at some service option." But after the bot tried some solutions, the user could not get an effective answer. Then there is a human interaction, but the bot doesn't go. He can be behind the curtain and still suggest something to the main user, to the administrator. Like, "Okay, maybe you can recommend to the user to buy some hardware, to type a specific question, and so on." But after the user tries several repetitive steps or some questions, then the customer support might come in. Okay. So now, everything that I mentioned is agnostic to any technology. It means and you can use any technology for these patterns. But now if we talk specifically about what framework. Okay. My first question would be how many of you have tried bot framework? For demo, for commercial application, or less, half of the group. Okay. What is bot framework? Bot framework is a set of tools which allows developers to create in matter of seconds or minutes an application which runs some code that can interact to the user, it can ask questions, it can use natural language, and we can also publish it to Azure for instance or to our server, because in the end, it is a web application, ASP.net Core in the latest version. So it can run anywhere, we can host it anywhere. Also one of the main advantages of bot framework is that we can use several channels. We can use Facebook Messenger, Skype, Bing, and other popular channels. So our bot can be present in or cover several scenarios. That's quite good, because for instance we can use web chat and also direct line to integrate it to other applications such as mobile applications, like Xamarin. Well, bot framework encompasses all of these that I just mentioned. The bot code goes in the web service or in the web application. There is an SDK bot builder SDK. The latest version is Node base four. There was version three, but towards me or if you have worked with it, it was a complete change. So well, even the documentation states this. Also for publishing to Azure, it is a complete different new process. Since this is a web application, we can connect it to other APIs, we can integrate it with NuGet packages, we can use or call any service that we want. We can even make queries to a database that's included in the demo. As I mentioned, we can use several channels. In this case, we do that through the Bot Connector that's the name of the service, Bot Connector service. Yeah. Well, there are several channels such as the Slack, but well, if you have read the news, you'll know that Microsoft recommended not to use Slack because of some security issues, but okay. That's something different. There is Twilio, there is Telegram. There are several other channels. Have you worked with Telegram? It is quite an interesting one, because in Telegram, there is something called the bot father. It's again a bot for creating bots. We simply need the key. Well, an API key that we integrate in the channel. I can show it to you in the demo. Okay. All the communication between the web application or the bot and the channels are through or in JSON format. There is a conversation ID, there is a content type because we can include images or attachments in our conversation; audio media files and also a specific data such as SMS or some address, even language. But basically, the communication between the channels are in JSON format, which is quite nice. Normally, to work from the beginning to the end with bot framework or in the process of creating a bot, we will work with some of these elements. Okay. We have the SDK template. I will go through that in the next slide. We had the bot code, I will show it in the demo. There is Luis service, thank you Microsoft for this name. We can publish to Azure or to any other server. We can connect it to users through the channels, and we can also add the dialogue of smarts or adaptive cards, which is something interesting. So first of all, the bot builder SDK template is a free extension that we have to download in Visual Studio 2017-2019. Well, most of us are, you've seen now the latest version. We just download it, install it on our favorite IDE. Then when we create a new project, we can just type or filter by bot and then several type of projects will be shown such as the Microsoft bot builder before SDK and three templates; the Empty Bot, Echo Bot, and Core Bot. The Empty Bot is for the expert, once because it means that it is as I said completely empty. So you call the bot from scratch. But the other two are for beginners, especially the Echo Bot because you are presented with all the code that you need to type a message to the bots, and then the bot will repeat what you just said. But it already includes the code for the communication, for detecting the message, and so on. The Core Bot is the same, but it is an intermediate, let's say template because it also includes communication with the Luis service. Okay. What is a Luis service? Okay. The Luis service is basically natural language processing. It means that we can train service yes or a model through examples or also called utterances. We establish intents or intentions. Okay. The user wants to login. This is an intention, user login. How many different ways has these user for that intention. Okay. Maybe they user can type, "I went through into this my credentials," or, "I just want to log in, this is my username," there are several ways. So we add these examples. We can also include some important information. These are called entities such as a name, city, date, and so on. Of course, these are like our variables, that different users can say different things, but they are important because we want to detect those intents. We can use this intents to filter out some results, to make some queries to our database, or to pass these data through an API. We can use it for several intentions. I will show these. Again, these service also uses JSON format. The user might say, "I want to find news about flight delays," and then we have our Luis model train. So it detects some intention. Okay. The intention is find news, but maybe in our model, we have other intents such as known, read news, share news. You can see that every intent has probability. Yeah. All of them add up to one. So this is the most probable one because we train with some examples. Also, the topic is flight delays. Again, flight delays is the entity. Yes and well, of type topic. Publishing to Azure is easier. Now we just basically create a web app bot, we fill in that data, and then we obtain Microsoft app ID, a password that we add in our project from Visual Studio, and then we can publish, and that's pretty much the steps. It's quite easy. Okay. Connecting to users in different channels is also a simple task, because in the bottom management section, we have the channels, and we can add several channels such as Facebook, Skype, Bing, Web Chat, direct line. All of them uses a keys. For instance, in Facebook Messenger, we actually need to go to the Facebook Developer website, then we create an application, we obtain I think there are two or three keys, and then we add them here into Azure. Then our bot can interact in Facebook Messenger, of course, we also need to polish our application in Facebook, and it has to be accepted by the Facebook Team. Finally, the Dialog Smart with Adaptive Cards. This while you have seen notifications in Windows 10, or in other Operating System, they add some buttons for interaction with the user or some messages, we can also add a media information. Well, there is some good news and also bad ones. The good news is that well this adaptive cards appear in different channels, there are adaptive cards for Facebook, for Skype, for Microsoft Teams, even for Android, SDK, and iOS, but suddenly, there are no adaptive cards for Xamarin Forms, while especially if you work with it. But well, we can role on our own User Interface. Actually, I will show it at the end of this presentation. I went to open-source it. So if you went to collaborate, we can talk about it and feel free to assist. I think it can be a nice project, but I will show it to you, right. So it's demo time, but before that I would like to ask you if there are any questions about this. So let's go to them demo part. Where shall we start? Okay, I think we can start from the Mobile Application, and I will show what is behind because well there are several projects in Bot. This is like of course the results, this is the mobile application. Hopefully, it doesn't take too much. So I will show the first one, Adventure Works Bot. I can ask these bolt. Okay. I want to login. I am presented a message there, I want to login. Please add your e-mail to your login message. Okay, it detected this one. It is searching for specific information about these user. Welcome, you are presented with this card, and show me some query about the top sold products, and I am presented with this information. All right, so this is PC, I am cheating a bit because I am using a web view and an integrated element from Web chat, but I will explain a bit about it. So this is very simple, but of course, it can be really useful for companies for users. Now, what's behind the curtain? First of all, there is a Web API which is displit. These web API is simple project which communicates with an Azure SQL Database. That is products controller, customers controller. These products controller has several methods. This method gets product has a code for searching the top products. You saw the top five, this one basically. Also, there is customers controller for searching a specific information about an e-mail correct. You saw the results in the demo. This Web API is called by these Bot project. This template was built by the echo bot template. As you can see this is a web based project because there is www.root, there is Start up, there is App Settings and so on. But you can see that there are several classes such as the Botservices, Botfile, Accessors, and some other important elements which are part of the Bot framework. I also have these Web API service, which is the communication that I established with my Web API that is polish into Azure, this one. All right. In here, I have these Luis class, which detects the intention and also the entities such as the e-mail, such that when you want information about products, and so on. Question? Yes, I will also show this part. Okay. Here, yeah. You saw that welcome message at the beginning, and here the Luis intents are detected. Yeah, which is the top one, the top intent with the highest value. If the intent is login, then there is a code which requests the e-mail if the user did not introduce the e-mail because I can even say that. I can ask, I want to log in. Most probably it will say is that the user does not exist, but it has to detect the e-mail. Yeah, you can see that in this case, it is not requesting for the e-mail because it was detected in the message. But this is not like parsing. This is not C-sharp parsing. These intents and entities are detected by the model that was trained, of course I will show that part. Okay. Yes. If there is no e-mail, please add your e-mail, but it is sending this message. But if the intention was product info, like show me this information about a specific product, okay, our top five products are, and then some results are present, right? In this case, you have to quote what you want to do for every intent, int. These intents and entities are part of a LUIS application. Started with LUIS is quite easy. You just create an application. Type the name. Select a culture and a language, English, Chinese, German, Spanish, and so on. When you start your application, you can add your Intents. I want to add to the cart. That's another intent. I did not show. That is Login. So in "Login", there are the utterances, like I want to access the system or I use one to access credentials info, my username. But as you saw here, I did not type this exact message. I want to login with. There is no specific utterance for that. But it was trained, in this case, maybe with enough examples for this scenario. But probably, if I write something different, it will not detect it. We can retrain. We can improve our model every time with new examples. We can even use this new information to retrain the model with the LUIS SDK. So this is one intent. That is PlaceOrder. That is ProductInfo that I mentioned in the call. Product, in this case, is an entity. It's an entity of type list. I use this one for like synonyms, like the user, instead of product, can say item or use plural. But also, there are some prebuilt entities such as number. I can say show me the top five products. It's the same. It will retrieve the same because you can write it. But the language is important because I set this one in English. If I use cinco in Spanish, it will also detect it, if the LUIS model was trained in Spanish language. Of course, there are keys that I use in this LUIS project. Sorry, in the Bot project. Okay, here. Sorry, in the App settings. That are used for the communication. Finally, for the mobile application, in the mobile application, I am using the Web Chat. Before that, sorry. Before that, I have the Azure Portal. I have the Bot. It's this one. It's the same break that you saw here. I can do same. I will be presented with the same messages. There is the Channel's part. In this case, I am using two, Web Chat and Direct Line. If you want to simply add Web Chat, which is this user interface, actually is the same one that you saw in the mobile application, you can add it even in a Web project, any language, because it gives you HTML code, this one. So you can embed it in Web project. But for, let's say, a mobile applications, we can just extract this URL and then we need the secret. The secret is here. But also, in the documentation, it states that you need to request a token for communication with this Web Chat, but that's really easy because, give me a second, we just request this one to this specific URL. We enclose our secret. We get this token that we sent to the web view, which is here. That is WebView. We set up the source and we are presented with this interface. It's already integrated. That's the easy part. As I told you, maybe we want to use our own user interface. We want to handle complex scenarios. So I am starting a project in which we can use some adaptive cards such as, let's say, here, and we are presented with this interface which includes images. A title, some buttons and the buttons work. Let's say we see a website and I have that one working here, this one is not using Web Chat, it is using DirectLine. This is the Audio card or Adaptive card, this is the Hero one that you just saw. But I am in the Xamarin.Forms application, I am building or writing the code, you can see it's a couple of images, labels for the titles of title buttons, it's very simple UI but we can of course extend it or do whatever we want with them. I also have the video one but the video one is not implemented in Xamarin.Forms yet, but there are several types of Adaptive cards. We have receipt like for tickets, this is again a Bot project, this is a different one and it's a bit simpler. This one does not use LUIS, it's just the message activity and it's the technology, what's the text? But I can't use contents, hero, receipt animation, and let's say this one, thumbnail, this is the Bot project. There are Adaptive cards already included in the SDK, in the Bot Framework SDK, this is the web application. So you just put the information and you are presented with these nice user interface, but if you want to extend it to a Xamarin.Forms application, first you need to add the DirectLine channel because you get one key. Here there's one, and we are almost on time and here I use it for communication here. MobileView, this MobileView, the page in our project, this one has just these Entry button and ScrollViewer, that's it here but I think dynamic code in this StackLayout, then you can see it here. If I want to create let's say, all this code is DirectLine communication, you can see they're DirectLineClient, ChannelAccount and so on. In this part I am detecting what is the content type that the Bot is retrieving to the user? There is Hero and Audio, they are the ones that I just included in this project, if I type thumbnail, nothing will happen because I have not created the code for that one. The Audio one is also here, just a second because the service is slow, but, yeah. Sorry? Yeah, the Audio one for some reason the sound is not playing but this is the Audio card and the code for this one is here, CreateHeroCard for instance and StackLayout, Label for images, it's just the image and I just add it to this container. So it's very simple because let's say that the difficult part is to cut these content type and some cards are not detected such as the Audio card, there is no Audio card in the DirectLine NuGet Package. So in this case I have to just create a class from the JSON content because as I said, it's a JSON content. Then I just add the relevant elements such as again a StackLayout, several Labels, and there is a player for detecting the URL of these media elements. As I said, I will just publish this one, maybe we can create a Nuget Package for it, I don't know, but I think it can be a nice project. Well, basically that's it from me, you know there are several Bot scenarios for Q&A, Helpdesk, Product selection, booking a hotel reservation and so on. Well, I think this is the most important links that you can get for documentation for the several services that we just talked about in the session, and basically that's it from me. Thank you very much for your time, and if there are any questions, we maybe have one, two minutes or we can just chat. Yes?  Does the Bot Framework or the Bot Screening with the Bot Framework be hosted internally like let's say behind a company's firewall?  Yes. Actually in the built event with another MDP [inaudible] , we demonstrated how to work with the Bot running under a container for local scenarios. That's one thing that you can do, also you can publish this to your IIS server in your local environment. I don't know which scenario you wanted to cover, but yes you can use containers or you can instead of publishing these to Azure, publish it to your servers.  That's only for the Bot, why not for LUIS?  Okay. Yes, there is also local container for LUIS.  Okay.  That's one of the greatest things about the latest additions for Azure, everything is being containerized, some Cognitive Services but at least LUIS is there. For Vision, they have the text detection, if you want we can talk about it, if it's possible. Any other question? Thank you very much,and enjoy the event. 