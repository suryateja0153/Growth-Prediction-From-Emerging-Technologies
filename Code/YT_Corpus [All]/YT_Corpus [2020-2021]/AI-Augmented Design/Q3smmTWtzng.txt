   [MUSIC]   Hello and welcome to 'Creating Mobile AR Applications: Seven Things to Consider". My name is Dan Miller, and I'm a Senior Developer Advocate focused on XR here at Unity. You can follow me on Twitter for more AR and VR updates. First, let's go over the agenda. We'll break down specific questions and things to consider when developing for AR. Starting with: is AR critical? Followed by some considerations and things to think about with user interactions and interfaces, how to set your expectations and guide your users, sharing your creation, specific platform features, keeping performance in mind, and finally, things to consider when planning your development workflow. The first question you should always ask yourself: Is AR critical? Can this app or experience work without augmented reality? When thinking about this question, really think about the value that AR adds. Here, we can see a visualization of an engineering model. In this case, a building. Here in 3D, we're able to navigate around and see different parts of the building. This is using Unity Reflect. Now, in 3D, it's nice to be able to move around, and understand the space from a higher perspective. When thinking about AR, we can place this in the real world, and then we can actually adjust the size of the model and ourself and be able to naturally move around and walk around the experience. Here, we can actually make the experience life-sized. And AR enables us to easily and naturally walk around and explore the space with a window into the environment. Here, AR makes sense by providing an easier space to move around in, and a natural experience. Rather than having to learn or navigate around with different keyboard or controllers, you can just walk around. Next, let's talk about user interfaces and interactions. With any AR experience, the content in the real world should always be the main focus. Consider showing and hiding UI so that the user can interact with the augmented reality content more. You also see some examples where UI is at the edges of the screen. The main focus is the augmented content, and looking at that view into the real world. When thinking about interactions, think about common interactions on mobile phones, such as taps, swipes, or two-handed gestures, like pinches and rotates. All of these should work naturally with the content that you spawned in the world. Here's an example of placing some content in AR. And then selecting it by tapping on it. Moving it around by swiping around on the device. And using two fingers to pinch to scale it up. And then, pinch to scale it back down. Here we see an application that allows us to place different augmented content depending on the surface we're looking at. Notice that the UI by default starts fairly minimal, and adds different UI elements depending on what you're looking at. You can see that the UI is limited to the edges of the screen. And the main content in the real world is front and center, allowing the user to nicely visualize what they're looking at, as well as the models that they've placed. Next, let's talk about setting expectations and guiding your users. For AR to work well, certain real world conditions need to be met. Things like lighting, as well as different textures and things in the environment so that the content can work, and the object can be tracked. For many platforms, there's things  called tracking reasons, which allow you to link into an API and instruct the user on why the AR content might not be working or tracking. There's also different types of augmented reality content that can be localized by things like images or bodies. And you should consider  guiding your user on how to place this content, and what to look for when using your application. Also think about things like fallbacks. If the user hasn't found an image or hasn't found what they're looking for, how can you provide an alternate content or additional instructions to guide the user? Here, we can see the different tracking reasons that we've exposed here. When augmented reality first starts up, you'll need to wait a moment for it to initialize. If the tracking has been lost, it could be because there's not enough textures or details in the area for the computer vision algorithms to work and begin tracking. If the application has been paused or closed and then reinitialized, you'll need to reinitialize the augmented reality as it begins tracking again and understanding the environment. These are just a few of the reasons available that you can show to your users to help them better understand what's going on in your application. Here, we're seeing some UI that tells the user to move their device slowly. As you move your device around, the device will pick up different feature points as well as detect planes on surfaces. Next, we're guiding the user to tap to place. This helps them understand that they can tap one of the surfaces and place some content. Here's an example of guiding the user on finding a body with a body-tracking application. Similarly, guiding the user to find an image. Once they've found that image, you can see that the UI fades out, and the augmented reality content is front and center. Next, something to consider is sharing your creation. With augmented reality content, it's important to think about how to capture and share the content that you've created on different social platforms. Sharing augmented reality content can be helpful for remembering or referencing things, like furniture visualization, as well as just capturing fun moments. Still images work well, but videos can show  more of the story and provide a more interesting engagement. Here you can see me standing in the park, and we're using a visualization to show a dinosaur. This is Ludia's  Jurassic World Alive app that allows you to show the different dinosaurs and capture videos and pictures of them to share with your friends. Here, we also have another app that allows you to put different content on your face. Instead of just capturing a picture, we can capture a full video. This app also includes native sharing. We can link in to the native OS here, in this case, iOS, and save that captured video to our device, send it as a message, an email, or more. Next, think about platform features. Understanding all the unique features offered by each platform is important when deciding on which platform to initially target or build for. Unique features can also help your application stand out. Think about taking advantage of some of these unique features to create all new types of applications. Here we see an example of a body-tracking application. Body-tracking is available on the ARKit platform. Here's a small app that allows you to record the different body-tracking movements and move around throughout the space. This type of application is only available on the ARKit platform. Next, keep performance in mind. When thinking about building augmented reality content, make sure to keep in mind that AR functionality is computationally expensive. It can be taxing on the CPU as well as the GPU of the device, and impact battery life. Consider disabling AR when you're not using it, such as navigating through different menus, or things like that. And also make sure you test early on the lowest end  supported devices. This can be great for understanding the different restrictions, as well as the performance considerations when building and adding different augmented reality content. I recommend checking out these other Unite Now talks for Optimization Tips and Maximum Performance Part 1 and Part 2 . As well as an Introduction to Profiling , which goes over the profiler and allows you to understand more information about what's happening in your game or application. Last but not least, plan your development workflow. Consider the team makeup, and what tools or workflows make the most sense. With tools like Unity MARS, you can quickly speed up the iteration and time  when developing applications, and it also makes creating more accessible to non-developers in your AR experience. Depending on what you're building, this may be a great  thing to consider when planning your development workflow. Unity MARS offers an in-Editor Simulation view, which allows you to build and author content visually. You can quickly test in different environments, set up different interactions, animations, all within the Unity Editor. Here we can see a small planet visualization, set up, and visualized here in a classroom. By leveraging Unity MARS, we're able to create this application more quickly. To wrap up, make sure that augmented reality makes sense and adds value to your content. Think about sharing your content from the beginning. Building in a capture mode or what the sharing might look like. Keep in mind the different platforms and understand their unique features. Lastly, I want to call out  some sample repositories, as well as the Unity MARS product page. The "arfoundation-samples"  repository contains all the different unique features of AR Foundation. The "arfoundation-demos" repository contains higher published demos, many of which were shown here in this presentation. And lastly, the Unity MARS product page is where you can find out more information about Unity MARS, some of the unique features, as well as how to get started. Thank you for attending this Unite Now session about seven tips to consider when creating augmented reality applications. I hope you've learned a lot, and it helps build your Unity skills and advance your projects. Feel free to provide feedback. And finally, be sure to check out our Unite Now page for other sessions that are sure to inform  and inspire you.   [MUSIC]   