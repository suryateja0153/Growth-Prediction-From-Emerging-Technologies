 good morning and good afternoon wherever you are this is to welcome our presenters today for our biodata webinar um which is looking into graph databases so our first speaker of the day is rick van bruggen and he's going to be discussing a short intro into graph databases and why contract tracing is a graph database problem and also how companies may benefit from the implementation of graph technologies uh to tackle these business challenges so without further ado i'm just going to put you through to uh to rick super thank you so much hello everyone i can't see you but i'm hoping you can see me uh great to be here and thank you for the invitation of biodata to uh to host this webinar um my name is rick rick van bruggen i work for a company called neo4j i don't know if you've uh you've come across us before uh we're originally a swedish company now we're kind of all over the world i would say with lots of really cool implementations of graph technology in the pharmaceutical industry and and beyond i would say and we consider ourselves pioneers in graph technology in general right right because we really think that there's a there's a lot of stuff going on there there's all really interesting evolutions happening um you know the rise of connections in data as we sometimes call it meaning that you know more and more use cases more and more companies are trying to make sense of their data create new insights create new competitive advantage with their data by looking not just at know the elements the data elements the isolated data elements but also uh looking at the connections between the elements right so i think there's a there's a growing understanding that you know a data element in itself a transaction or a or a an asset or a whatever it may be a molecule whatever it may be the data in itself obviously has a lot of value and is very meaningful but but if you can see how that piece of data connects to other pieces of data it actually brings you a lot of additional insights right and so we see that this this actually plays really well into lots of you know mega trends as we might call it you know where companies are really trying to innovate and and uh you know make sense of of their already existing data silos uh by connecting them right by making making sure that they can for example apply artificial intelligence on top of it or by integrating the data or by doing some fancy algorithms running fancy algorithms on top of it that's how they create this new business value with you know existing data sets that they that they just really need to interconnect right and i guess that's where where the the interest of graphs and graph databases as well is coming in as it allows you to do that in a really really easy way and you know we're kind of seeing a lot of interest in this you know there's a lot of really big organizations that are starting to make use of it and um you know from you know retail organizations travel organizations logistical organizations pharmaceutical organizations and they're trying they're starting to apply a lot more innovative you know discovery processes on top of this right so we see a lot of improvements to be made in analytics in machine learning you know using using these new techniques to uh to deliver value right when you look at neo4j um as you can probably tell from just the name uh it's actually something that's been around for quite some time we've been hacking away at this problem for for for more than uh 15 years now neo4j was originally started as an open source project in malmo sweden um back in the early 2000s 2001 around that time free and it really became you know commercial technology a little bit later on 2009-2010 i joined the company in 2012 um and i've been uh been working with it ever since and the core of the technology is really what we call this native graph uh infrastructure native graph technology nitty graph databases and tools right what we mean with that is that you know it's it's graph so it's all about networks about these connected structures that we're trying to manipulate with our data infrastructure but we do it in a native way so that it really becomes a lot easier to do so right it becomes more easier more powerful more more more quick and also to uh to manipulate these graph structures i mean you can represent a graph in an excel file if you wanted to right it's not that difficult to represent graphs in in any database structure but if you do it natively if you build the infrastructure from the ground up to represent this type of data then all of a sudden all of these things become so much easier and and i guess that's where what we're going to uh going to uh going to talk about a little bit here because at the end of the day it's really about making this graph technology which really literally has been around for centuries um we're trying to make it more accessible more more applicable and insightful for for uh organizations big and small right so native graph technology is what it's all about and at the end of the day where it's based on a very simple but powerful paradigm right this is all about representing data in a different data structure right so we're not working with table structures anymore like we've you know all been educated to do so and in the past 40 years i would say right but we're going to work with this very simple data structure that you see here which is essentially a node connected to another node right a node you can kind of compare it to the structure that you would also represent in a relational database system as a record right so it's a it's an instance of an entity right it could be an employee it could be a city it could be a company could be a you know a book could be all kinds of things you know an instance of an entity right so a row in a table is essentially what you're representing there and all of these things have properties right so names keys and keys and values right so names dates whatever they are right but the cool thing about is that they are explicitly connected to one another right in a normal you know traditional relational database system you would have a table for employees and a table for companies and you would have to do a join to see which employee works for which company right that join is you know the heart of the problem that we're trying to solve here because by representing that join no longer as something that you do at query time but by representing it as a relationship as these little arrows that you see here in this data little data model and storing it explicitly in the data model in the database at right time all of a sudden those join operations become way way simpler at query time right this is the the heart of what we're doing here it's it's literally you know avoiding joys at joins not joys uh we're avoiding joins at query time and doing them basically connecting things up at right time right by by basically saying you know company employee they're already connected to one another at right time all i need to do is follow that little arrow you know because the joint has already been done right that's the labeled property graph that is exactly what this is all about we're representing data in a new way where we're using the the property graph to store the data in a database management system and that means that we will be able to do uh different operations on top of it right traditional databases we are really good at storing and retrieving data you know big data technologies you know aggregate stores like document stores or key value stores or column family stores are really good at aggregating and filtering data right but graph databases are all about these connections but you know deriving insights from these correct connections about making these connections first-class citizens you know we really want to leverage those connections to to do something new so essentially what i'm talking about here is two things you know you're talking about two kinds of benefits that you can get from graphs um in pharmaceuticals or in by biotechnology the first one is that it becomes way more uh simple and and and and manageable to represent complex data models as a as a network right because in a traditional data model you know relational data model you would have all these join tables sitting in the middle right you would have employees and companies and a joint table in the middle and it basically blows up the size of the data model because you you know you have you have these uh relationships uh those joint tables in the middle right here you're dealing with a much simpler data model to represent these densely connected domains right which gives you a lot of you know ease of maintenance ease of flexibility flexibility um ease of implementation as well um and an ease of understanding i would say you know it makes it way easier for people to understand the data that is being stored here right so this is kind of like a longer term benefit that we're getting from working with these property graphs but i would also argue that you know the short term benefit that we're going to see here is that because these join operations have already been pre-calculated have already been stored persisted inside the data model that kind of means that at read time and remember most people read their data a lot more than they write it right so at read time we have to do a lot less work right and that means more performance it's going to be quicker right so there's a lot of things that all of a sudden become possible because you have already done them once at right time and at read time it just flies through it right yeah i mean if you if you would talk to your your dbas you would know you would know the answer when they when you try to ask them for a system that can do more than you know a handful of join operations right because joins are compute intensitive if you can avoid joins your dbas will be happy right so essentially that's what it is and uh you know i guess that you know this system the uh the graph database system or the graph database platform i would say it really allows you to do these things um much more efficiently so in highly connected domains in you know highly connected query patterns as well you're just going to see a dramatic boost in performance and a lot of things that become possible that weren't possible before right so what are we talking about here you know what kinds of um use cases are we looking at here um and i'll you know you'll hear about two of them in a little bit more detail today right so we're going to talk about contact racing and we're going to talk about knowledge graphs a little bit later on as well but effectively you know there's quite a few areas where you can apply this where you can apply um this new data model and this new type of querying uh to to to real business applications you know i've just highlighted a few of these here but like for example recommendation systems is a great use case for all detection systems it's a great use case network operations you know anything related to networks right if you can store the network as a network it kind of helps you know if when it's an electricity network or a rail network or a bus network or a logistical network or whatever it is you know storing networks as networks is is interesting because you can you can optimize a lot of things there but there's a lot of interest also in in in like more um you know data governance oriented domains like master data management or identity and access management there's quite a few things there that we can do to optimize how people store their data with uh with graphs and it's all because you know first of all the modeling becomes so much more easier and secondly some of these query patterns they just just become a lot more efficient right so that's like that's essentially what we're what we're uh what we're trying to do here with uh with graphs and it's also why um we wanted to highlight a couple of uh use cases to you uh that are related or are relevant to the the biotechnology and pharmaceutical industries because obviously the uh the pandemic that hit us earlier this year has kind of brought to life a couple of really really interesting problems data problems right and um and i'm going to talk about one of them and and kirsten is going to talk about another one a little bit later on um let's see here oh what do we what do we uh what are we going to talk about you know i will leave the part about the knowledge graphs to to kirsten right so uh it's probably the the more impactful or more interesting part and i'm going to talk about uh what what i kind of explored with and what i've worked with customers on in the past couple of months which is really using graphs for contact tracing right then and i i you know just to frame this a little bit what do we mean here at the end of the day you know we've all seen this happen you know as citizens as employees as as uh as you know biotech industry members i would say uh what we're trying to avoid here is that you know in the next wave which you know i live in belgium it's kind of hitting us right at this very moment uh um this next wave you know people want to avoid that we have to lock down the healthy people right that's really what we want to avoid we want to lock down the sick people sure right people that have that have contact have contracted the virus yes sure we we need to con lock these people down and quarantine them right but the healthy people we should try to keep them healthy and let them let them go about their daily lives as much as possible right so there's been a lot of debate and i'm sure it's been the same in in your countries about how to do this you know and contact tracing is an essential tool for this understanding who has been contaminated who has high risk of contracting the disease or spreading the disease it's an essential tool for us to you know allow the the society to basically continue to work without having to go through these lockdowns again right so i it's kind of like a big deal i mean i i feel quite uh strongly about it uh uh having been locked in this room for such a long time i i i don't want this to continue until you know i'm even greater than i am already you know it's uh it's uh it's it's kind of important to make sure that we that we understand who is at risk here who might be spreading the disease um and obviously there's there's lots of different ways that you can do this there's lots of ways that you can organize this uh but essentially uh there's two types of systems that have been uh proposed right it's a centralized system or a decentralized system right centralized system where you kind of keep track of all of the all of the information in a centralized repository the decentralized system where you know maybe your phone would know about your uh exposure but no one else would right and obviously there's pros and cons to that both approaches right they're not uh you know an absolute blessing in in one or the other direction right so i guess the the summary from what i can tell at least is that the centralized system is a lot more privacy sensitive and you know we want to be very careful with that uh especially in uh in in today's polarized political climates um it's kind of important that we don't uh centralize too much data or expose that to too many people uh when it's not required right but you know it kind of also allows us to see bigger patterns and bigger anomalies um in a much more predictive fashion we can see things a little bit more clearly when we look at the bigger picture right so that allows us to look at population-wide patterns for example right which is kind of a big deal it's kind of important right the decentralized approach is all about stopping the chains right it's all about stopping the the contamination chains and um making sure that the population can limit the spreading of the disease by just you know cutting it at one point right so i guess both approaches have have their merits um and the application of graph theory to this domain is is not new at all it's uh it's been pioneered by lots of different different uh people academics uh industry specialists uh pharmaceutical companies alike you know it's it's uh it's been described in many books it's not like this is a uh um you know rocket science or anything um so what when when the pandemic hit us and you know everyone's social life basically got decimated i quite did quite a bit of work to try and illustrate that we could apply this beautiful new graph technology uh that uh neo4j and other people have been pioneering um that it could really prove its merits here right and and and contribute to uh to a broader solution and that's where you know neo4j at least uh you know ever since you know guys for years already you know we did the panama papers a couple of years ago we did a lot of other research in the meanwhile uh and we we do believe in you know in a greater good and graphs for good uh initiative so we we we tried to help out and and illustrate that the technology could help and i personally did that by writing a number of blog posts um where i very simply illustrated that you know in a synthetic data set right it's a very simple synthetic data set that you could very easily apply very interesting uh pathfinding algorithms and community detection algorithms and predictive algorithms to understand how the disease was spreading inside our communities right so i started with this synthetic data set where a person visits a place right and and therefore if two people visit the same place at the same time that means that they meet each other right so there's a person meets person relationship there and based on this uh data model you can write a number of queries right and and some of those queries are really really interesting but i would really encourage you to take a look at this yourself and i actually just spun this up this afternoon myself if you go to sandbox.neo4j.com right you can actually choose a new project right and you can actually spin up a contact tracing database yourself like the sample compact database yourself obviously and you can just take it for a spin and see what it what it does right so if i open this over here in my neo4j browser i'm hoping this didn't expire of course it did give it a second or two but it actually opens up a neo4j browser right which is the tool that people use to interact with graph databases and it allows you to run through you know a sample data set here right and run a couple of queries right so we've got the data model that i just showed you right with people visiting places and people meeting people right and then you can just run through a couple of queries here let me just find an interesting one uh like for example here for example this one here allows you to look at which people have visited the same place at the same time right so and if of course these people are sick have been diagnosed tested as sick then we could actually infer that that they might be at a at a higher risk level right there's also some queries here that allows you to um just flicking through this here because i'm assuming that most of you will will take take this uh for a spin later on um we can also apply some graph algorithms here some some of these graph algorithms are super fascinating i'm i know that you've used graph algorithms today right right because if you if you've used google search then you've used an algorithm called pagerank pagerank is an algorithm that ranks the search results not because of you know who pays the most for the advertising but because uh uh you know it actually looks at how things are connected to one another right i'm old enough to remember web search before google and how shitty it was and uh uh you know google actually innovated the web search industry by looking at the graph of connected pages and looking at you know the pages that are most connected are more likely to be you know relevant to your search right and you can apply the same thing to contact racing right the person that is most connected to other people and to other places is more likely to be of significant influence on the spread of the pandemic right that's the logic here right so you can actually run uh queries here uh that allows you to this is a pagerank query right it writes the pagerank property it calculates the score and it writes the pagerank property on top of my nodes here meaning that i can very easily see i just need to run this you know that tishon ayala is probably because of her connectivity to the rest of the graph more interesting for the spreading of the disease inside this community right just because she's been connecting too much right she's been connecting to places and other people too much and therefore there's a higher risk associated and actually if you look at some of these other algorithms here there's some really interesting ones uh something called betweenness centrality right this is actually a very predictive um scoring methodology why why because it tells you something about how things that are sticking together right so there's a community of of people here and there's a community people of people there in the middle there's a couple of people that are connected to both communities guess what they have a very high betweenness right these are the people that might cause the pandemic to jump from this community to the other community so we want to know who these people are you want to know the people that are have a high betweenness centrality for example right there's also other algorithms here like community detection i'm not going to go into that i just recommend that you go to sandbox.neo4j.com take it for a spin and if you have any questions about it i'd love to talk about it and and see uh and see if it would be relevant for you right so there's quite a bit of experiments that you can take here um a lot of uh tools that you can look at here i also want to illustrate a little bit of the the visualization possibilities that you have here right so yeah it's obviously it's disconnected i'll have to do that some other time uh but there's some visualization possibilities that you can take into account here not just looking at the structure and the and the raw properties but also coloring the the graph in certain ways putting icons on it making it more usable for business oriented people um that that's actually a real big part of what we do right so i'll i'll wrap up uh there um i've covered quite a bit and i know i'm conscious of our timing constraints here um so um with that i think uh i'd like to hand it back over to you uh bruce to uh to guide us to the next part of this this webinar thank you very much rick excellent presentation we just had uh a question from hans lasse um he was wondering if there were any tools for converting a graph into relational database and vice versa oh yeah yeah there's there's there's quite a bit of tooling i mean uh i i skimmed through this obviously but and what we say here in in in the the the graph technology platforms kind of is that neo4j has some capabilities that allow you to introspect a relational database read the data model from the system tables and then suggest a mapped uh graph data model uh that that's derived from the relational system right that's one way of doing it but essentially there's like a number of data integration tools that allow you to do this and to do it bi-directionally right so you can you can pump data from a relational system into a neo4j system and the other way around um there's some really easy to use tools for that i would recommend that you take a look at the neo4j etl tools another question that we have um from simon tilly is how to represent the the temporary of the edges how to represent what sorry how to represent the temporality of the edges okay that's a that's a great question um well i mean obviously you can you can put time stamps on everything right so neo4j you know back in the old days when i first started at neo4j we didn't have a temporal data type so it was a lot more complicated to do this these days you just have temporal data types and you can just put diamond date properties and you can you can you can calculate uh very uh you know like uh how to say that periods of time and then those types of things super easy to do these days the question that the person is hinting at i think is you know how do i how do i run through different versions of my graph you know and see how it evolves right that's a different question and it's a much more complicated question and we do have solutions for that and there are tools for that but the bottom line is that it it really needs to be built into your data model uh right so in your data model you need to separate the the structure of your graph from the state of your graph right and if you do that if you if you basically represent the structure like this and and then say okay this structure has a number of instances right and they those instances follow each other right so they get versions right that allows you to travel back and forth into time and to look at the structure at different points in time right it needs to be built into the model we have tools for that it's it's not it's not rocket science it's not that complicated but please talk to us and we will help you out with that because you know the first time you look at it it might be a little bit daunting thank you rick we have um one more question which is um from a colleague martin romaker he's using rft triple store domain um he's looking to move to neo4j and he's asking if he could elaborate on the migration and conversion pathway from rdf to neo4j oh yeah great great question um that i would um i would definitely uh um the name escapes me right now but there's a tool there's a tool for this uh what you will find if you start working with with neo4j is that it's very much a swiss army knife with a lot of tools that it can be bolted on top of it there's an extension um name escapes me right now too neo4j it's actually an open source project that allows you to point to a triple store endpoint uh like for example we've done it a bunch of times with wikipedia or or other uh you know dbpedia other other uh notable uh triple star endpoints and then you can basically suck it out of those stores with sparkle query and then convert that into neo4j data structures uh if that would be you know a good way of doing things note that you know while uh triple stores are graph databases right so they they they are not they are a particular kind of graph databases using a subset of the neo4j data model right so the the neo4j data model is actually a richer data model the labeled property graph and so when you go from one to the other there's a high probability that you want to go through some modeling or remodeling of your data model so i would i would recommend that you take a look at the tools i will put it in the chat as soon as i remember after this talk what the name of the tool is but then also please do make sure that you go through some some some thorough assessment of the data model so rick we have a comment from one of the uh one of the individuals uh on the on the presentation now wolfgang nugent have mentioned that the tool that they're using is neo-semantics that's the one that's the one sorry yeah i uh all that belgian beer sorry so one one question we have here is what are the advantages of neo4j tools over existing pacquiao packages such as uh networks in python oh i i you know like i said during my presentation you can represent uh graphs in excel files if you wanted to but what you can do with it greatly varies uh depending on um how do i say that you know the the applicability or the nativeness of the tool i would say that you know if network x it will probably work really well uh for smaller data sets and you know kudos right great great great choice uh but i i will bet you my right arm that uh for larger data sets or for more performance you know query speeds you will need something else so it's it's uh neo4j is just going to be a lot more scalable a lot faster probably more flexible um but you know for smaller data sets it doesn't really matter right it's you can do that with whatever for larger data sets or more intense applications i think you will find that a native tool set is going to give you a lot of advantages okay wonderful thank you very much rick that was fantastic um in the matter of time we should cross to uh to kirsten langendorff who's representing uh s cubed and she's gonna be speaking on the benefits of removing data silos uh for the pharma industry and also a bit of an example of covert.codegraph.org so passing across to uh to kirsten okay now i'm unmuted can you hear us custom yeah can you hear me perfect you're online okay and you can see my site slides up and running good thank you um yeah hello i'm kirsten you mentioned and thank you for providing the opportunity to present here today um i will be presenting and unfortunately my colleague dave iverson host is not able to present today so you have to to live with me i'm not as experienced as rick is i'm a newcomer to the to the graph technology so bear with me um with what i'm about to show i'm new to this but um today i will focus on the stuff that i've done in connection with copycraft um and uh i mainly done that in my spare time but but i've uh it's okay it's of course in the within brand of sq because i work for sq um i will also show you a little bit of how we use neo4j in in what we do on our daily life before i switch into the work that i done with the neo4j or neo4j with kobe graph and uh i think it might better become a little nerdier towards the end because i'm i'm gonna show you some of my uh scissor queries and some of the challenges that i faced while doing the profit 19 graph stuff um but um just so you start by talking about who we are it's cute very briefly we are a consultancy company we are based in denmark in copenhagen and also in the uk and what we do is that we are providing consultants to the pharmaceutical industry within statistical the area and data management and we also have a part of our businesses doing data analytics using click and doing different vi reporting we also have a part of the organization that deals with regulatory affairs and then the part that i'm part of is the bottom right half which is the what we call clinical standards management and we are building a tool based on graph technology which we call a3 suite and it's a it's a graph based platform or a tool that allows the pharmaceutical industry to work with standards and so we have a what we call an mdr where people manage the different standards for clinical studies and then we have another tool that we call study workbench which is a tool that will allow the users to set up studies and we also provide services or helping people in pharmaceutical industry adopting graph technology and then we provide training in cdisk which is a data standard used within the pharmaceutical industry our so-called study world is very much connected as this is just a a abstract world or for the picture of how a study actually looks we do when we start the study you do a lot of planning you write a protocol you specify what you need to collect during a study and actually behind the scenes a lot of things that are linked together even though you don't really see it then there's a lot of things being defined and set up how to collect the different information for the for the studies or the patients that we're going they're going to ask for information they are setting up edc system electronic data capture systems and all kinds of other tools that collect data then the study runs and data is coming back and you organize the data you put them into this standard which is the seeded standard so there's a certain structure that the pharmaceutical companies need to adhere to so this data needs then to be to be created and from those data sets you do analysis and eventually you end up with a result whether a certain drug is better than the other one or how safe it is and along the way there's a lot of things linked together and then within this space there's a lot of talk about this end-to-end optimization internet traceability and we believe with the tool that we are building that graph technology is a good way to ensure that you you have an easy way of maintaining this traceability and the traceability is also something that the the authorities would like to see in a certain document um so they would like to see okay given an analysis where did i what page did i collect this piece of information and what happened to it uh from from that result to how it was collected so backwards compatibility so that's a lot of challenges in there and and and making sure that you have all all the information needed to to make this traceability a little bit about what we use neo4j for we as i said we have this mdr and the study weapons these two tools that we are building the first one is is not based on neo4j but the other one is um so the study workbench is is says is it setting up a study we make what we call an annotated case report from crf and we also study they also make a what they call a define.xml document which is a data definition document a certain standard needs to be applied and when you set up that study that's actually a lot of it it's just metadata and our tool is then helping people working in a in a the way that they know and not need to deal with all the underlying technical details um so that's our goal that you don't need to know a lot about graphs or connectivity you just do what you normally do working with studies and then you get the connectivity behind the scenes we have also we have also um made an a prototype oh my god dave has made a prototype where we would like when we see the data coming back into the graph so we have both the metadata and the data connected and then you kind of have say a warehouse or a whole cloud of both the metadata and data together and that's basically our goal with what we're building at the moment so obviously uh we're improvising here a little bit uh ladies and gentlemen uh i i but i do want to make sure that you get the most out of this uh session and if kirsten takes a little bit more time to get back um then uh maybe i can just still uh give you a little bit of a pointer here because i know that what s cubed and what kirsten has been working on in the past couple of months as a neo4j partner as well is very much related to this initiative it's an initiative called covet graph it's a fascinating uh initiative and i i can't explain it as well as as kirsten could because she's much more involved but enough to get you uh get you updated here i think is what these people are doing and who these people are it's it's it's really a consortium of a lot of different um graph experts i would say right and uh you know there's people from s cubed involved there's people from the curious involved but you can see that there's a number of other um uh people involved here it actually started with these two guys here kaiser and poison which is a small integrator in germany and the german center for diabetes research who is a long time neo4j user and customer in germany who basically realized that you know what they were doing in diabetes research right which was essentially putting together all kinds of data and trying to make sense of it and trying for that to advance diabetes research they could apply the same techniques to covet research and i see that kirsten is already back so i don't want to uh intrude on her time either but that's where while you're getting ready kirsten i'll uh uh i'll uh i'll just point people to this website covidgrav.org right where you can find a number of these um tools that they are building right tools that are building uh which are very illustrative of how people could use graph technology to make sense of data right so um some really interesting applications for querying it um yeah so so i was talking about covid graph as an example of how lots of different pieces of data are being brought together and you know it's really quite elaborate what they've done here is it's a you know lots of different medical databases research databases test result databases there's an amazing wealth of information that they've brought together here um and you know you can see it here the the different um ideas that they've brought together here right and so this is really targeted uh not so much at uh you know my me or anyone else it's really targeted at at medical researches right medical researchers that could that could um hopefully and potentially uh learn from past research and leverage that past research to figure out a way to create a cure or a vaccine or or or a you know some kind of uh instrument to treat the disease more quickly one of the one of the first results that they found was um um yeah you can tell that i'm not an expert here uh but they found that there was like this general virus treatment drug that was actually proving to be similar to other virus treatment drugs and that they could actually suggest that as a as a as an early treatment possibility obviously not what we want and what we need yet but apparently that was one of the first possible avenues at least for accelerated research into this new pandemic i really recommend that you take a look at it knowledge graphs or this is for me this is an example of a knowledge graph right then a knowledge graph is applied in many many different cases right um we've we've got examples of nasa for example using knowledge graphs to enable and unlock their their past experiences right lessons learned database they call it and apparently this was actually one of the one of the one of the key things that they found out when they were developing a new um launch platform for astronauts to go into space and to come back from space they needed a new landing uh platform a new landing capsule uh the prototype that they had built here on earth was uh tipping over all the time which was exact exactly what happened in the 60s and 70s when the first moon uh uh missions were actually happening and so by unlocking the lessons database in a graph they were able to say okay we can you know go back to that engineering design and that doesn't change then and we can leverage that to save time in the development effort of the of the new landing capsule so knowledge graphs are very much a generic thing that you can apply to lots of different things and hopefully also to the kofi 19 um use case i just keep talking uh internet connection so i don't know we normally have a high-speed internet at home but it just dropped off yeah i don't know if i should continue from the corridor for um yeah i gave a quick introduction to what the project is and what what what they've been doing and what knowledge graphs are you know you you are much more knowledgeable about this so i'm going to leave it to you now yeah okay but very quickly uh right through um you know so we started uh in march the danish denmark was locked down and uh also this copy 19 and our health minister and topia told us you know we need to make sure that we don't over um you know swarmed the hospitals with the cases and everything that we had seen in italy and then we started working at home which is the next picture and i thought um you know we got this letter from the authorities oh i got that they view our health care educated then please join the um the emergency team and i thought oh i couldn't help so i was a little nerd from the lego film so i thought i can't help so how can we help with the math and computer science background so i got this email from neo4j and they talked about this copy graph knowledgecraft and it caught my eye and that was really interesting so i looked up their homepage and looked at what their their purpose was and that was to bring information together from various sources so that researchers can gain more knowledge about this new disease from patents papers and they also wanted the clinical trials so this is can you say my contribution to to the cover growth so i joined the team i signed up and i said that i have been working in the pharmaceutical for 20 years i know a little bit about clinical studies and i've uh recently you know working with uh neo4j and um so they said yeah please help us and so we started with the source data there's a there's a mandatory this requirement to publish all the studies uh on this website in the us called clinicaltrans.gov and they have this api even though this is beta but you can access this one and you can you can make some sort of search criterias i went into the documentation and looked for for the different kinds of syntax there and then i started to look for the studies and in this version here you can only pull down a thousand records station records at a time but i could see from when i looked at the there was this limit and so i looked up in over here you can see there for these interventional studies there are actually more studies i need 2 000 studies um so how to go about that so i use this um every every record has a rank this is you can see here the minimum rank and the maximum rank so i used that to to make a loop query and so i did a loop looping through the uh for the different records and like this now it's going really quickly because it lasts a lot of time and then i actually called the another query using this lower range and operands that i did in the first to get all the different records in there so i learned a little bit of cyber doing that so i wanted to share my what i did here with the render community so i did this paper and choreographed that some of you might read then a little bit about the the modeling uh so you know now you have access to all of this information this is just a picture of the description that you can access on the page as well describing all the different fields and i had a little chat with alexander and from the cover graph about he's the one of the uh one of the researchers and he we went through this and then discussed with what kind of information that they wanted i basically ended up with wanting most of it um so some of the fields are mandatory like indicated here with a red asterisk so i try to model this this graph or this trial as best as i could from the knowledge that i have first i did a lot of properties but then putting it into the ecosystem of the code graph we realized that we had to have some more nodes so we could connect to different nodes um and um so yeah so how did we model i had a comment from my colleagues and said how did you actually do the model and it was just using my experience and i think as you also mentioned rick it's uh it's very intuitive and then you you want to describe actually what's how how is it represented and you can do that while the uh the relationships and naming the relationships in a sensible way so i think it's very intuitive and well yeah that's this is one model that might be uh you know room for improvements then i had a little other challenge there like this we had this was the different locations and the cities and states and countries i skipped the state in this case um and as you can see here in the days and there's a lot of data redundancy um obviously there were these six records and i need to join them together pairwise so i did a little uh loop down here in the bottom illustrated here that i did a for each for each record in here i will then join the things together um also i had an another issue that i encountered maybe you can help me ricky i don't know i found out that if i had missing values for some of the things here then uh for some reason uh this part didn't come from so i did a lot a huge query here and because this was missing this didn't come through in my in my graph here um so but if i split it in two then i got the graph that i wanted um so it might be some querying that i don't know of um so uh yeah time is getting uh uh for quests so a little bit of learning uh as i said i'm new to this to this uh neo4j so i took this certification in 19 and they have used it within our organization for making a traceability matrix in respect to validation but with this task i got an opportunity to learn a lot more about sci-fi and graph in general certainly the model can be improved i think so and it's always have a good chat with the colleagues about how the model can be improved perhaps also next step could be to try to use some machine learning to because the data is not that uh standardized in auditor in all the fields that we get through uh back from the json so uh pairing data and cleaning data using machine learning could be done we need to be aware of this missing value that i saw and uh and the next step will then be to add the trial results because right now there are a few studies that has results which can also be interesting to have as part of the code curve uh yeah and so i realized that i was able to help even though i'm a techy nerd so with that uh and very short presentations please petey uh thank you ray i think it will be useful to have a couple of uh of uh of questions i do see two more that are open in the in the in the in the uh question box uh or actually one more the other one i've already answered i think you know it's a very interesting you know what are the main indicators influencing query time in a graph in a relational database as you mentioned the poison is joins what is it with graphs uh well uh that's a that's probably my favorite question in the whole world so um um so this is kind of counterintuitive right but in a graph database the data set size is not that material right it's not that big of a deal to give you any indication on um on on what the performance of a query would be like and that's because what when you're querying a a graph system you're always going to try to make it quite local you're going to try and reduce the scope of the query to you know a particular thing molecule person place whatever it is and everything that surrounds it right so so the the the sweet spot query of a graph database is a very local query right because you you wouldn't have to explore the entire graph and you wouldn't have to explore the entire data set you could just work with the starting point and the things connected to it so the poison in a graph system is a global query right it's it's when you have to look at everything right and some algorithms require you to do that right there's no there's no getting around it you you kind of have to if you want to control if you want to understand centrality if you want to understand communities you know all of those types of things you need to look at the entire data set and then you have to come up with smart ways of doing that so that you know you don't run into you know memory problems or whatever right so uh we we've done a lot of work on this but i can tell you right now that you know if you write a query that sucks in too much data right and that looks at a too big of a portion of the graph you will very quickly find that your machine is starting to uh to run on all the fans and and uh and and screaming for help um that's just because it's a combinatory explosion you everything is you know it's a connected structure so if you if you suck in too much data it goes it just comes bigger and bigger and bigger and that's that's poisonous as you as you said yourself so hence that i hope that answers your question hans laser i think that's uh that's probably what you want to take a good look at trying to keep the queries local and if you don't if you can't keep it local then you have to come up with ways to chop it up or or or do it in a smarter way i hope that answers your question yes there's another question from hans laza do i need green data analytics or what are the experiences needed to develop a graph i would say it's always good to have a little bit of domain knowledge but i don't think you need a degree [Music] um i think the the especially when using your everyday it's very intuitive um you kind of it's very oral in some sense you you can if you explain your your domain or the problem that you're trying to solve then it's fairly straightforward to to make a model of course you need a little bit of ability to to abstract the things you're talking about but otherwise i think it's it's fairly fairly similar and the good thing is that you can it's very easy to change the model without it you know interrupting a lot of things and that's also what we're doing in the development our tool we can add on stuff and so we don't have to have the full model in place from the beginning we can add to the model as we go along i don't know if you have any comments on that like your experience no i could i couldn't agree more i think you know we we're you know it it sometimes it feels a little bit difficult to work with a graph because you kind of have to unlearn things a little bit you know yeah i know for i know for a fact that you know i would never ever ever have gotten my my university degree if i didn't know my rdbms modeling you know what i mean and it was just mandatory and and i was drilled to do it that way and and if you actually if you if you think about it graph modeling is like you were saying kirsten it's actually all more natural and and intuitive but i kind of have to unlearn my relation relational database modeling skills a little bit and that creates a little bit of a hump to get across you know it's um i find i find that you know it's actually easier to model in a graph database but it's different from what i was forced to do in university and i kind of have to unlearn that a little bit in order to be a good uh graph database modeler if that makes any sense yeah the things that we're seeing in in this data standards that we're working with is sometimes um you you make because you have so much knowledge from the domain that you're working you kind of make implicit relationships in your head just because two columns are next to each other but it's not always um uh obvious that that's the case and you really haven't described the relationship it's just um it's just because it's uh in people's heads in some ways because the the columns are next to each other so with a graph you have more much more explicit relationships also that you can query um and that can be a little more difficult when and if you have in the top interview yeah it's a it's a you can have a long philosophical debate about it i i actually really think that it's it's more intuitive because that's how our brain works you know we think associatively and uh and you know that's just how we are wired literally and as a consequence it's it's a more natural way for us to think about data you know if you explain a bit if you ask a business user to explain their problem to you before you know it they start drawing things with arrows between them you know that's what they do because that's how they think and before you know it they're drawing graphs for you and yeah i think it's a it's it's really uh a more natural way of modeling and yeah i think it enables a lot a lot of um new things that way by the way you know the original uh computer system databases they were all graph databases right so i mean the the the when we had mainframes and you know back in the old days they were all network oriented databases that's how people started out the problem was that you know you needed more resources and those resources weren't available right and so as a consequence people people people went backwards a little bit but the original database systems were network database systems you know when i first told my dad that i was going to work for neo4j and i explained it to him and he was like oh i used to do the same thing in the 70s you know that that's literally what he told me and it's it's just the way it is uh we've got a final question um from hans he says thank you very much that what are the next steps in developing graphs what's your opinion on the future and what's going on what's it going to look like next steps in their features i i would love to see some one of the things that i've been wondering about was um some ways of because the graph can be really really big as we saw also on rick's slides and it could be really great if you can make some nice visualizations of the graph um i have a i think i have a i have a book i can't recall the author but it's something about uh graph is beautiful or something infographics it's beautiful it's about having another a very visual way of displaying all the data in a in a smart way um that could be really fantastic if you could um it can make some sort of a visualization on top of grass that would be my wish we've made a lot of progress on that actually you know if you look at the older visualization technologies they were all based on you know older browser technologies now we have we actually have uh you know graphic processors in most laptops and tablets and phones these days and modern browsers are able to exploit those i mean yeah so so it becomes possible to have bigger graphs uh uh represented on on a on of individual way having said that you know as soon as you're looking at stuff that is like a little bit you know like a couple of million things it just becomes a big higher ball you know it's it's like it's not it's not possible you know you again again you kind of have to you have to you have to make it more local you have to uh look at a part of the graph to make any sense out of it but if you can aggregate it in some sense i don't know if it's possible with ai and whatnot um then that could be really cool having some some tools on top of that um i don't know yeah well we're we're we're starting to look at these things right so in in the last uh version of the graph data science library you've got these um graph patterns that you can um that you can pull out or represent as a subset of the graph and and then and then start reasoning over subsets uh which is you know kind of like an aggregate for uh for uh for a graph structure um so there's there's a lot of stuff that's starting to happen there but you know yeah there's a little bit more more work that that needs to be done from my from my perspective i'd love to see more intuitive ways of of of um of reasoning over graphs you know of inferring knowledge you know define finding new patterns um i think you know there's a lot there's a lot of uh interesting work that needs to needs to happen there um i think influencing which is kind of natural to to the people in the in the triple store world um and when we start applying that to property graphs it's actually super interesting as well yeah some of the things if you log on if you go to the covetgraph.org and try to you know see the graph and then you can browse the graph and look for different things there's a visualization on top of it and they have used different icons for different for instance the clinical trials have a certain icon and that's also what we're trying to to use in our in our tool so for instance concepts that i talked about earlier if you heard that it has an icon and something so so it's um it can be easier to you know separate one note from another one visually that's just a small tiny step and i'm getting a better overview of what what you have cool i think we're already over our time so i'm wondering thank you very much um for your time with the presentations today rick and kirsten it's been great having you with us um thank you with our audience and um yes uh thank you very much for being with us today and being part of the buy data series thank you pleasure have a nice day everyone bye-bye 