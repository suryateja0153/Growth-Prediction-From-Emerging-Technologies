 - I'd like to thank Todd Constable for coming up from Yale to give a talk, the talk today. Todd is Canadian and you grew up in Winnipeg, right? - Yeah. - Grew up in Winnipeg. - Winterpeg. - And so, I grew up in Minneapolis and Winnipeg is like Minneapolis, but worse. (audience laughing) So I feel a certain kinship because of that kind of Midwestern, North American, the cold part of Midwestern North America. Todd is not a psychologist. His degree is in medical biophysics. So he started off in physics and then he got his PhD from the university of Toronto in Medical Biophysics and he is now the director of MRI research and co-director of the Magnetic Resonance Research Center at Yale. So he brings a really fresh perspective to functional neuroimaging because of his background. I think that what he's going to present today is kind of radical, actually. At least, you know, I happen to agree with it, but I think that you've hit some resistance with this perspective. And I have great respect because he's gone back and really looked at the assumptions that underlie a lot of what we think is ground truth, what some of us might think is ground truth in functional brain organization and going back to the original literature to see what the real foundations are and why we should be questioning that. And I'm going to let him tell us the full story. - [Todd] Great. Thanks a lot. Great to be up here. Thanks for having me. I've always heard a lot about Dartmouth, but I've never, I've driven by I think, but I've never actually stopped here, so it's great to be here. Yeah, hopefully what I'm going to say is not only radical, but right. I don't actually know that though, but I think it seems to make sense. And actually I've already given this talk to most of the people in the room here in our one on one conversations today. So, I'm not sure how much new you'll find here. What I'm going to talk about today is fMRI and some of the assumptions of fMRI. And we'll talk about resting state BOLD signals and then maybe the not-so-resting state. So when we apply a task to functional MR, and hopefully I'll give you a little bit of insight into what I think we can learn about functional organization from functional connectivity. And then I'm going to get into node definitions and atlases and the connectome and that's going to lead us into: What are the goals of human brain mapping? And a lot of you already heard some of this in our discussions today. And by the way, thanks for all the discussions today. It was really great. I really enjoyed all my conversations and it's cool to get feedback and insights and to see what your responses are to some of these things. So I assume everybody here knows what functional connectivity is, but I have one slide here to talk about that. We're really looking at resting state BOLD signals that are correlated in time. And this indicates that things are functionally connected. Actually, even though this is and so the first paper on this was Biswal in 1995. So Biswal published this paper in 95 and basically from 1995 to 2005 people were all focused on physiologic artifacts and saying, this isn't real. This is, there's a coherent activity because the cardiac pulsation and things like that. And that's why it's symmetric in the brain. But what Biswal did was he did a finger tapping experiment and that's what's shown on A there. And then they took a seed region and one of the motor cortices on the right, let's say. And they said, "What's this connected to "in the whole brain?", just by correlating that seed region with the rest of the brain, lo and behold, they pulled out the motor network. And so that kind of started us on this whole road of functional connectivity. The reason I put this up and I want to emphasize that I'm talking about functional connectivity is that I'm going to talk about the flexibility of the brain and the flexible organization. In submitting several papers on this, where I've hit a lot of resistance from people that feel like the brain is structurally defined and that, what are you talking about when things are flexibly connected and stuff like that. I want to emphasize its functional connection. Neurons aren't jumping around from location to location, which is what one reviewer suggested we were suggesting. And this is just, things are synchronized or not. If you're that reviewer, oh forget it. (laughing) This is different. This is distinct from task-based fMRI, in task based, you might have an external stimulus and you look for a response that looks like that blue line and that is your activation. You're looking at typically a few regions that are synchronized with that onset of the stimulus and connectivity there. It doesn't have to be a stimulus, there can be a stimulus, but in connectivity we're just measuring BOLD signal. This blood oxygenation level dependent contrast. We're measuring that over time and regions that tend to oscillate together, this is low frequency, like 0.1 Hertz or less, regions that oscillate together tend to be functionally connected. And so that red and a green area, we might say are functionally connected if they're highly correlated. The cool thing about this is that you can extend this to measure the correlations if you have an atlas, like what's shown here, you can look at all combinations of connections between all combinations of pairs of nodes and come up with a connectome, the functional connectome. And so in the original Biswal paper, it was kind of a seed region to the whole brain. But now what I'm mostly going to focus on is looking at the connections between regions or nodes and building up the connectomes. So this is the functional connectome and there was a whole project called the Human Connectome Project, which was out of Wash U and they basically, imaged 1200 people and they were trying to get these connectivity matrices, which are formed by numbering the nodes, let's say one to 268. This is one of our 268 node atlases. And you look at all combinations of node number one with all 267 other nodes and you can fill in then, the correlation value and that represents how well connected those nodes are. There's a couple of interesting features here. One is that this matrix is symmetric and that's because we don't have any directional information. So one to five is the same as five to one. If we had directional information that matrix wouldn't necessarily be symmetric, but for now we just assume everything's symmetric because we don't have directional information. There's really two ingredients we need here to do this. We need an atlas and we need the time courses and then we can get the connectome. This is your functional connectome. I think the functional connectome is fascinating. This is actually what it looks like for 268 node atlas. That's a 268 by 268 element matrix. So in that there's 35,000 connections. And I was asked today what I think is cool and what I think is cool is that there's a ton of information in there. And what I'm focused on these days is how to extract that information. So yeah, by the way, it's 35,000 nodes or connections, edges for that 268 note atlas for something like the Glasser atlas, that's 360 nodes, there's 70,000 unique edges there, or connections between nodes. There's potentially a lot of information there. We're only looking at the bottom half, but when I say 70,000, that's in the bottom half. There's been a lot of work already. With Emily Finn, who's coming here as faculty next year, we did the functional connectome. That's her little fingerprint picture up there, where we showed that this was unique to an individual so we could identify you by this matrix. And that was, we didn't set out to look for that. We were actually looking at grouping, we were looking at trying to cluster people by brain state. And, in fact, in the HCP data, they had all these different tasks and we were going to see the working memory task all clustered together. But instead, an individual would cluster together across all tasks. And so it turned out that you could actually identify individuals with this. Yes. - [Student] Is this already, have you, gotten rid of the hemodynamic response? - This is just that correlation over time and you replace-- - [Student] You can get just correlation from the blood, right? - Well, it is a blood signal. You're looking at changes in blood. The BOLD signal is the change in local tissue oxygenation, which causes a T2 star change, which is a complex function of flow volume, oxygen consumption and oxygen demand. So that leads to this BOLD signal. We look at two regions and how their BOLD signals are correlated. And we replace that with one number, which is a cell in this matrix. So whether we get rid of blood flow not, you know-- - [Student] (mumbles) - It's an intrinsic signal. There's various pre-processing you can do in terms of global signal regression and stuff like that. And I'm going to ignore all the pre processing steps, but there's that. That's what the first 10 years of connectivity was from 1995 to 2005, but I think these are real signals and we can get real results from that, that are encouraging. So Emily showed that this was unique to the individual and then as part of that paper, she showed that you could build a model from this data to predict fluid intelligence. Xilin Shen, in 2017, published additions to that model and we have a nature protocols paper there. But then there's been other work on, predicting fluid intelligence from the connectome. There has been work by Monica Rosenberg and Marvin Chun at Yale, in terms of looking at attention networks. Autism symptoms is a paper I had using the abide data and predicting social responsiveness scores or ADOS scores. And then there's some personality work also from the Yale psychology group. And then reading recall, which Emily's on this paper or no Monica's on this paper , on could you predict reading recall from the matrix that you obtain when somebody's reading a passage. I think there's a lot of information in here, and one of the things I'm interested in is building models to get that information. And so how do we do that? In summary of that part, the functional organization seems to be unique to the individual and it seems to be relevant in the sense that, so we can identify people and these functional phenotypes seem to tell us something about the person. One of the things I'm particularly interested in is can we categorize patients with this? Instead of using DSM-5 criteria for schizophrenia, can we look at a functional phenotype and maybe group patients into treatment groups and maybe have more success in treating people if they're in the right, if get the right treatment at the right time. This is where I'd like to see this go clinically. We can build these connectome-based predictive models, we call it, to allow predictions of scores or behavior. And I think actually, even though I only show one matrix here, and all of these papers tended to use different data in different models, I think from an individual connectome, you should be able to get all of this information once you have these models. So for an individual you could get their connectivity matrix and from that, potentially get a complete profile if you had models for all these different constructs that you were interested in. Part of the work right now is trying to build these models and learn how best to do that. So how do we do the most simplest form of this connectome base? The CPM is to look at what edges vary as a function of behavior across subjects and then build a model based on that and bring in a new subject and apply the model and see how well we do at predicting their score. The simplest way to do that is to stack people up like this. We get a matrix from you. You have your subjects one to N minus one, let's say. You have a connectivity matrix for each subject. And then in this case, we have a behavioral measure. Let's say it's d prime, so a d prime score from an attention task and you have a score for each individual and you're basically going to correlate these scores with the matrix and you're going to then pull out the edges that either very positively or negatively in that correlation as a function of d prime. And so you're using this as a feature extraction step to isolate the feature, the edges that are relevant for this behavior. And this could be behavior, a trait, a symptom, anything like that. And so you get an, you get a mask then essentially, which is like this and you could then look at the positive tail of that, the negative tail, and you could sum those edges and you could get a score for each individual that gives their network strength, if you call the sum of those edges network strength. And because we defined it this way, the network strength increases with higher d prime scores. Then you can fit a line to that data, and that line becomes your model, such that you can apply this mask to a new individual and calculate their network strength. And then you should be able to, from this model, once you have their network strength, you should be able to predict their d prime score. If we go through and leave one out and cycle through and do that, here's the first subject. Can you see that dot? No. With the first subject, there's a dot. And that's their, we calculated their network score and we can then look at how well we did in terms of predicting their d prime from the network score using this linear model. And then you can cycle through a whole bunch of subjects and do this and get some sense of performance of the model, which is really how well did we do in predicting the scores versus the observed scores? You can do that for the positive edges and you can do that for the negatively correlated edges and you can combine these in a general linear model. And that general linear model gives us similar results, in terms of performance. It turns out it doesn't seem to make much difference whether you use the positive model, the negative model or the combination of the models, the performance is pretty similar across these. Now one of the limitations of this, is that that summary statistic there, is probably a weak way to build these models because we're losing a lot of information. And if you can keep some of the information separate, you might ultimately do better. And so we're looking at other models that do that. The other thing is that I've been talking about having a resting state scan, we've shown recently that actually resting state is probably the worst condition in which to collect these connectivity matrices in, but if you have task data, you can actually build much better, or models that perform much better in terms of prediction. We can do that and our cross validation has gone from now leave one out to split half. So if you have 800, when Emily first did this, it was the first release of the HCP and we were like 118 subjects or something. Now there's like 1200 subjects and 800 of which are good, but you can do, train on 400 and test on the other 400. And it works pretty well. We had two basic papers on this. The first one by Emily on the functional fingerprinting, let's say. And then Xilin, and this model is available. You can get our atlas and you can get the code for this from our GitHub there. So that's kind of the basics of that. And as I said, there's lots of behaviors that people are working on, and there's lots of prediction. There's two reviews that are coming out, one by Steve Smith's group and the other by Mike Mellum and some others, whose name I'm blanking on. Gayle Viroqua, who looked at a million different atlases and modeling strategies and their predictive abilities. It's those two papers, if you can find them. I think one is published one is on BI Archives, and I've given them them to some people here, but Jim knows them. But I can look those up at the different techniques for doing this. And they're making progress. The bottom line is that there's a lot of information in this matrix and it's cool to be able to extract that information and learn what information is in here. I think we're just at the tip of the iceberg when there's 70,000 connections there, that's a lot of data and we need to learn how to read that data. I want to go back to the beginning. Which is, the ingredients for this was an atlas for no definitions and an fMRI time course data. I'm going to focus actually for the next a little bit on this atlas. The motivation when we started on this was could we, is there a better atlas, how many nodes is the correct number of nodes? And when I actually originally worked on this, I wanted there to be a functional Atlas that was kind of equivalent to the cytoarchitecture atlas, Brodmann areas, or there's been other anatomic atlases, like the AAL Atlas out of Montreal. And now there's lots of these functional base atlases based on fMRI data. There's a ton of interest in this atlasing work. What's the ideal way to parcellate the data and divide the brain up into these functional atlases? You can see there's lots of papers and lots of interest in this, and there's tons of citations, so you can actually do, it's funny, you can do an H index on topics, so the H index there 163 peaked. But when I started on this, when I started on this I had a postdoc, Xilin Shen, who I said, there's the Broadmann Atlas and then there's going to be the Shen Atlas and the Shen Atlas is going to be the functional atlas, the equivalent to Broadmann areas. This was back in 2010 we did our first one and actually lots of other people had done atlases by then too. We weren't the first at this, but I always kind of psyched about this using functional connectivity to define an atlas. This is based on the same concept of resting state fMRI, and if adjacent voxels are oscillating together, then they're probably part of the same node, that's the basic assumption there. And so if they have high synchrony, we'll cluster them together and then we'll divide that into various subunits and try to divide up the brain in that way. We've had a couple of papers on this and the 2013 atlas is the 268 node atlas, which is the one that's pictured there. That's available from NITRIC, the NIH website. And we actually have a 368 node atlas. Those seem like odd numbers, well, even numbers, but strange numbers. We actually put in that we wanted 300 nodes, but we got 268 and then later we put in we wanted 400 nodes and we've got 368. So that's where those numbers come from. But anyways, so you can get these atlases and there are lots of other atlases out there, in fact, here's some of them. So Cameron Craddock has an Atlas of, actually Cameron Craddick has a bunch of atlases. There's one that's about 400 nodes. Thomas Yeo has an atlas. He's got a few atlases out. The Matt Glasser one is a high profile because that was in nature, I think. And that's a multimodal Atlas. I forget how many nodes the Power atlas is. How many nodes are in the Power atlas? Does anybody know? - [Student] 264 - Two? - [Student] 64 - 64. And the Gordon Atlas, which is 333. So you can use any of these atlases. And, in fact, it turns out that in these predictive models, because of that collapsing the data into a network score, it's not super sensitive to the atlas, but I think that's actually a problem with the data reduction strategy of the modeling. And if you handled the data better, that might be a little more sensitive to the actual atlas. These are not random atlases. These atlases are a little more meaningful than random. Although that's hard to evaluate. It's also interesting to note the number of nodes. There isn't a right answer on how many nodes there should be. That's typical. 400 is a factor of four almost, greater than the Brodmann areas. And people seem to be comfortable with that. I'll leave it at that and we'll come back to that point a little bit later. You can think of this as either these are meaningful subunits and we should talk about what they mean, or you can think of this as a data reduction strategy. If you think of it as a data reduction strategy, it doesn't matter which atlas you use. I'm going to talk about these as meaningful subunits. So all of these atlases are based on resting state data. Glasser's Atlas is resting state plus some other stuff Actually, they have tasks, they treat everything together and kind of collapsed resting state and task data from the HCP project into this atlas. But most of these are not multi modality. Most of them are resting state. At the beginning of this I had said to Xilin Shen, we're going to have the Shen Atlas and it'd be really cool. You'll be famous. And it turns out now though that I've, completely given up on that. And I'm going to tell you that there isn't a fixed functional atlas and that there is no such thing as a functional atlas. The brain is very flexible in its organization and these node definitions are brain state dependent. Okay? So, if you see this Atlas under different conditions, it's going to look different. And that's what I'm going to show you data on now. And I'll show you data on now. I'll give you my editorial comments later. So, consider parcellation in different brain states. If we're going to look at parcellation, one of the things that kept me from doing this for a while was that we, most of these algorithms don't have a way of keeping track of node correspondence. And so you need, if you're going to compare atlases across brain states, you need to have the same number of nodes, for one thing, otherwise you end up with a node correspondence problem and you don't know, if things are rearranging, you don't know which node rearranged to what, or it's a very difficult problem to solve. We have an exemplar-based parcellation approach, which maintains node correspondence. So if we start, and basically we start with something like a 268 node atlas, or anything. And from there we develop exemplars and then we grow those exemplars to fill the space, basically. We can do that under different conditions, and we have a way then, to compare nodes across those different conditions. We need an algorithm that and, I don't think any of the, as part of the review process for this parcellation paper, they were like, "Well, why don't you compare? "Why don't you do this with some "of these other algorithms as well?" But you can't because those algorithms don't have a way to keep track of which nodes goes with which node, and so the comparison becomes problematic. So you need that. We start with a group atlas. We actually started with several group atlases and I'll show you results where we did this from 200, 400, 1,000 and then 5,000 nodes. And the result holds across all those different scales. But basically, you start with some random group atlas, and then from there you can look at how that atlas deforms to an individual and then how that individual atlas deforms with brain state changes. We apply this to data collected under different conditions. We had six continuous performance tasks and two rest runs. So we had eight different runs basically, and we could run this atlas on each of those individually. They were each about six minute runs. And we had a TR, I think, of about a second, so 360 volumes per per condition. And then what we did was we imaged me 30 times over about nine months. And so we have a single subject now imaged 30 times, and there's no anatomic variation here. So we're not introducing any, and hopefully my brain wasn't changing anatomically a lot, but, presumably that not a lot of degeneration over nine months. But we imaged me 30 times over nine months. And this data, I think we've loaded it on OpenNeuro now. And so this data is available and there's also in magnet performance data for the tasks and things like that, which I'm a little embarrassed to say I really suck at the end back task. But so, 30 times over nine months. So what we could hypothesize, then, was that the parcellation should be consistent from day to day or session to session, within a condition. And we wanted to see is it going to vary by conditions or by task. This should be a pretty clean set up. These were the tasks. So we had an end back and two back tasks, and the emotional I's task, which is the same as in the HCP. We had a reward task, which was kind of like a card guessing task. We had a response in inhibition, like a go-no-go task. I watched movies, so everybody's been asking me this, Princess Bride, Up and Away and Inside Out, little two minute clips of each of those. And so those are the movies. This is Monica Rosenberg's attention task, the grad CPT tasks. So you see city scenes coming on very quickly and you keep pushing as long as there's a city scene. And then when there's a mountain scene, you withhold your button press. So it's actually a little bit of a response inhibition task as well as an attention to ask. And it's trivial for the first few seconds, but it drags on. At about the fifth minute or something, that gets a little boring. So there's attention task. And then we did rest at the beginning, a rest at the end. And to be honest, we haven't really directly compared the time effect of those rests. The rest runs are pretty similar to each other. So all of these are continuous performance tasks. They are not blocks In the HCP data, the task data there is blocked design, so there's rest and then there's blocks of activation and then rest. These are completely, so if you're doing two back end back, you're doing to back end back for the whole six minutes. So we think of that as a brain state manipulation. It's a well controlled way to have the person doing something. And if you parcellate all these brains and you arrange them in one of these tenser modes based on similarity the movies condition is in the upper left there, and it was actually the most distinct in terms of, the node definitions were very different in the movie task compared to some of the others. But there's some things that makes well, and that makes sense. And there's some other things that make sense, which is that like the grad CPT task and the end back task are a little bit similar, and the two rest tasks are there next to the movie conditions and they are somewhat similar. And so that's kind of the bottom line. We do, fundamentally the answer is going to be yes, we get different parcellation for each condition, and these are super reliable across days, within a condition, and they're super different across conditions. And we can look at this a bunch of different ways. One way is, well, there's two ways here that are on this slide. This is looking at parcellation similarity, on the left is measured with hamming distance. It looks like I cut off. I'm sorry, I cut off the label there. That's hamming distance. So basically how similar, how many voxels overlap in parcels and the other is node size similarity. So remember we have correspondence between nodes and so we know we have a node size vector, let's say that's 268 points long. If there's 268 nodes and we can measure the size of each of those nodes and we can correlate those vectors. And you can see, for example, one of the interesting things is that the movie condition is very different from all the other conditions. So on the diagonal, you have within condition similarity, and that's high. And that's what this histogram is. So this is within condition similarity scores for either correlation of the node size vector or for hamming, one minus the hamming distance. And you can see, for example, that the differences between conditions, the movie condition is very different from these other conditions. And that maybe the stop signal task and the card guessing task are somewhat similar right there. - [Student] Wait were you able to estimate the number of functional nodes that exist for each task to see? - [Todd] No. So we're starting with a fixed number of nodes. So we did this at, we started with a sample atlas at 200, in this case, 268 nodes, and we're not allowing the number of nodes to change. We're only allowing their shape to change. - [Student] You were saying earlier that if two nodes are fairly similar in their activity in their activity and their (mumbles), they're clumped together as like a single thing? - Well we grow-- - [Student] (crosstalk covers speaking) estimate the number of functional (crosstalk covers speaking) - Yeah, we've tried that. And the answer is basically no. That curve is very, very flat. We've tried to look at this and other people, I think Thomas Yeo has looked at this too, is there a happy number that seems to be the right number of nodes? And that's a super smooth curve anywhere from 200 to 5,000 and there isn't a good way to draw that line. - [Student] Because different tasks actually require a different number of functional nodes. - Yeah. That may well be, and we didn't allow that here. So all we're allowing here is a change in the shape of the nodes. But yeah, it could well be the case that, maybe there should be 300 nodes for task A and 250 nodes for task B, and we didn't allow that option. But that could, that's another yet another level of flexibility that we didn't consider. Yeah. - [Student] The scan sessions, from all the tasks, I'm assuming you're watching the movies that (mumbles) but other tasks? - The movie, yeah, the movies never changed. It was Princess Bride first. But the the order of the tasks did change, so we always started with rest, then the order of the tasks was randomized and then we always finished with rest. - Within a task, was the sequence of the trials the same? - [Todd] Yeah, no, no. They're randomized too. You couldn't, I didn't learn the pattern for the attention task anything like that though. There were always randomized. That's a good question. But you can see from these distributions, they are very different within versus between, and that's the main point here, and this is for the 268 node atlas. And we could, as I mentioned, we could convert that 268 node parcellation to a vector representing node size, and it turns out that that node size vector could, is actually informative in terms of we could predict which condition we are in based on the node size vector. So in other words, the node size vector is like a signature for that condition. So, we could do classification here based on, we can basically tell with 70-80% accuracy, except for maybe in the stop signal task, wasn't so good, but we could tell with pretty good accuracy which condition we're in just based on the node size vector alone. That is suggesting that it's reproducible and it's unique to that condition. We took this a step further, and some of these tasks actually had behavioral data in them. So the end back had some behavioral data, the grad CPT had a d prime, a stop signal card. All these had behavioral measures in them and with across sessions, then we actually tried to predict performance. And we could do that with some accuracy, suggesting that the more your, the more my atlas looked like it should, the better I was doing in that task or something like that. That's basically what that's saying. And so again, that suggests that these node sizes have some useful or meaningful information in them So then you could ask, well, is it just my brain is weird? The answer is no. There's midnight scan club data available. There were actually 10 subjects scanned 10 times, but two of the subjects didn't have all the data, and/or they were, there was quite a bit of motion. So we used eight subjects scanned 10 times and that kind of replicated the same finding. They have these, there's three groups here and these are really, they have two semantic coherence tasks. They have these memory tasks and then they have motor tasks. And I think that's what these three groups are on the histogram here. And the data's a little noisier, so they were only scanned 10 times. Mine was 30 times, and I think they have less data per run. And some of these runs are pretty short, but there's still the overall effect of there's more within task similarity than between task similarity, and that these tended to group by task categories, so these semantic tasks grouped together. That would suggest it's not just me. But this is still within subjects, so this was, even though there's eight subjects here, we did the analysis within subjects. So you're looking within a subject at their parcellation similarity across the conditions. But we're not looking across subjects here. We're just summing the data across subjects. But then we went to the HCP data and you could say, well, now we're going to introduce anatomic variations and we're going to go across this is 514 subjects, only scanned once. But the bottom line is does the atlas look more similar in a condition across subjects than it does in between conditions kind of thing. And this also strongly, the histograms are pretty well defined here with 500 subjects. There's a strong within-subject parcellations similarity, and between conditions it's not as strong. This would say that even when you introduce anatomic variations, we still get a better functional parcellation that looks more similar within a condition than between conditions. I would say it's not unique to my brain. And actually, in both the midnight scan club data and in the HCP data, we could predict which condition, with some accuracy, which condition you're in based on a node size vector. So we can do prediction in there as well, meaning that these node size vectors are unique to those conditions. And so that's kind of interesting. So then you could say, well is this variation really, there was a question about are the nodes, could you combine nodes or split them? And you could say, well, maybe what's happening here is that some, that the nodes are conglomerates of multiple nodes and maybe you're just splitting them in different ways because the resolution is too crude. So we cranked it up. We did 1,000 and we did 5,000. And, ultimately, if you get to the level of the voxels, there's no further divisions, right? And so it would plateau at the level of the voxels. But we went up to 5,000 nodes, and even at 5,000 nodes, we see this reproducible rearrangement. And so that's shown here. This is back to my data now, looking at a parcellation with five, an atlas of 5,000 nodes here. So to do this, we actually evenly randomized 5,000 seed points over the cortex and subcortical structures. And then we just grew those, and the same starting seed points for all conditions. But clearly, the parcellation is more similar within a condition. And so even at 5,000 nodes, the nodes are rearranging their size. So maybe at 10,000 nodes, this would stabilize and not change. But that's getting pretty high. So what does all this mean? I think what this means is that state dependent node definitions should be considered, in most work to date, people use fixed atlases and they do look at connectivity matrices under different conditions. So you might consider the fact that those atlases aren't correct for all those different conditions. Now you might also, it might also be the case that it's not critical to much of that analysis, but you should know that they're changing. We are now moving to doing individualized atlases and also state dependent atlases. So that's individualized on two levels. I'm currently investigating into what extent this influences the results. But the bottom line is that there is no functional, there isn't a fixed functional atlas that's analogous to the Broadmann areas or to the Broadmann Atlas. And so I've given up on having Xilin Shen define the ultimate functional atlas, although most of my colleagues in the parcellation field haven't, they're still working on that problem. But this also has, when you start to think about what this means and why this is happening, it does have implications for brain mapping and the problem of brain mapping. I'm just going to spend, then, a little bit more time on brain mapping. What's the goal of brain mapping? And I've already talked about this with a bunch of the people in here, but the goal of brain mapping is to take a region and to assign a function to that region, right? We want to know: What does this region of the brain do? And that's fundamentally what brain mapping is. Can we assign function to a brain region? But there's an implicit assumption there. Maybe it's explicit, I don't know. There's kind of an implicit assumption about a 1-1 mapping. Well also, as an aside, I think we talked about this a little bit, some people. We want to know what each region of the brain does that comes from task-based fMRI and from lesion studies and things like that. It turns out that when we do these CPM analyses and MVPA and stuff like that, you see that actually the whole brain is kind of involved in tasks and we get these complex connections that are not usually observed with task-based fMRI, but they appear to be meaningful and they do help these predictive models. And so maybe the brain, as an aside here, maybe the brain is a little more complicated than a single region activating under a certain task. But that's kind of an aside. That's a whole other talk that I have. What if there's no such thing as a fixed brain region? This is where I'm going to go. I think there actually isn't a fixed brain region, but the field of brain mapping is, and you could maybe convince me that I'm wrong on this, although I think this is true, the field of brain mapping is looking for 1-1 correspondence between a region and a function. They want to assign a region a function. And I'm going to make that argument here now that that's not actually true. It's probably much more complicated than this 1-1 thing. We know from the brain map, our neurosynth databases, that if you look at various behavioral domains, and this is our 268 node atlas, and we could go through and look at what behavioral domains are associated with each node in the atlas. And you can see that almost every node has associated with it a ton of different behavioral domains. So one of the arguments is, well, the behavioral domains aren't defined properly, and if you have the right behavioral domain property, you would have the right, there'd be a 1-1 relationship between node and behavioral domain. But I'm going to argue that's not the case either. This is just blowing up that bottom axis so you can see what those domains are. But let's go and look at this a little bit deeper. We'll do some math here, some rough math. So let's say there's 16 billion neurons in the cortex. I got that from Wikipedia. The Broadmann Atlas has about a hundred nodes. The functional Atlas, let's say, 400 nodes. So if we do the math, 16 billion divided by 100 is like 116 million neurons per Brodmann area, and 16 billion by 400 nodes. There's about 40 million neurons per node. So when you're using a 400 node atlas, you're lumping together 40 million neurons, let's say, okay? And if we're assuming that we're going to assign a single function to that, we're saying that 40 million neurons are all doing the same thing. And I don't think, I think most of you would agree that that's probably not the case. At 4,000 nodes, there's still 4 million neurons per node. So that's a lot of neurons in there. And the fundamental question is, do these 40 million neurons all do the same thing? Because to assume that there's a fixed node or the fixed function is to assume that that's the case. In our 268 node atlas, there's about 60 million neurons per node. So I do think that this is kind of the basic assumption of human brain mapping, although maybe we're not brain mapping at the level of a 400 node atlas, maybe you're looking at smaller regions and things like that. There's still this fundamental assumption that whatever that is, if it's bigger than a voxel, a voxel, actually I have this on another slide, a voxel, a two millimeter cube voxel has about 85,000 neurons in it. And so even at a two, if you're only mapping a two millimeters single voxel, you're still assuming that those 85,000 neurons all do the same thing. And I would say that's not true. But you see this time and again in meta-analyses with brain map neurosynth and the work on ontology. So coming up with new labels, there's still trying to find, assign, a new label of function to a single region. And we see this in the parcellation, where people are still trying to come up with the ideal parcelization. So if we look at an example of a 6x6 voxel node, so this would be equivalent to a 2,360 node atlas with a maximum of four neurons per voxel, let's say. I could have those neurons tuned to different things like you could have some of the neurons, these are all, let's say, pyramidal excitatory neurons, they could be tuned to some yellow task component or green or red or black. And depending on the inputs and the outputs, there is just going to be this slight different tuning. And if I group things, if I do a parcellation analysis, and I grouped the neurons under these different conditions, I'm going to get different regions defined here. So I'll get the yellow region, the red region, the green, the gray, maybe the only region that overlaps, or is the intersection of those, is that little blue region. But probably if I had more tasks, conditions and different inputs and outputs that would get smaller and smaller. This is incredibly flexible with only four neurons per voxel. And I'm not saying that these neurons have completely different roles. I'm saying that they're slightly different tuning. And we see this in the visual cortex. So one hemisphere, v1 has something like 140 million neurons in it. And we know v1 has ocular dominance columns there's retina topic maps, there's all sorts of different organization levels within v1. And that's what I'm saying here is in the cortex, some sort of organizational level that may be tuned. You know, maybe you got the red area, if there's no outside stimuli and the person's well rested, maybe get the yellow area if they have an itch simultaneously while they're doing the task. And if they all of a sudden think about what they're doing in the magnet or have to do outside the magnet while they're doing the task, you get D or something like that. So these are slight differences on the inputs, outputs, brain state changes that influence the subgroup of neurons that's tuned. This is only four neurons per voxel and I can get this sort of complexity. And, in general, we have 85,000 neurons per voxel, and I'm sure they're not all doing the same thing. So to me this seems to make a lot of sense. But what we have to incorporate then in our models, when we're trying to assign function to a region, is we have to have flexible function and we have to have flexible region definitions. And we have to allow that those regions can overlap and be very, maybe there's an infinite number of combinations of these regions and tuning and function. The brain is complicated and I think we've been looking at this in a much oversimplified way. For reference, up there in the upper right, there's a, that's when an atlas with 1,041 nodes looks like. And you can see those are getting fairly small, although they're still pretty big. And, and the example I'm giving here of a 6x6 voxel node would be for a 2,360 node atlas. So each of the nodes would be half the size of what you're seeing up there in the upper right. Although you can see those aren't evenly distributed in terms of size. So this is like the, I started off, I wanted to find the ideal parcellation. I find that the parcellation changes with tasks and when I think about it, this is kind of what I come up with as an explanation of why it changes with tasks, and it seems to me to make sense. There's evidence for this in the visual cortex, there's evidence for this in the motor cortex, there's evidence for this in the literature and the macaque, there's face regions and there's regions that are sensitive to different aspects of face processing. And there's all kinds of evidence for suborganization, subspecialization within regions, and there's no reason to think that we can't be sensitive to that with functional conductivity data under these different conditions. And so I think that's potentially why we're getting these changes in the node definitions as a function of brain state. So the neuroanatomists don't like this. And, it's really a difference in emphasis. So some of the neuroanatomists would argue that, well, the yes, there's functional specialization, but we don't want to break that up, and because it's potentially complicated and yes, I would agree that it's potentially complicated, but I also think that it's potentially interesting, and for us to make advances in this brain mapping problem, we've got to get away from the assumption of 1-1 mapping between a region and a function. And I think if we incorporate, allow flexibility in terms of the region definitions and the function definitions, it gets a lot more complicated. But it's probably a lot more a realistic than just assuming if we stick at the level of cytoarchitecture, let's say, and we stick at the level of v1, we know V1 does vision, and the question is do we want to get any further than knowing that it does vision. And I think to get further we have to allow for organization at different levels. And so that's my argument there. So the supporting evidence in MVPA, we know that there's lots of a suborganization, we can do hyper alignment based on that suborganization. But even there, there's 85,000 neurons in a voxel. Maybe MVPA or hyperalignment would be different under different brain state conditions. And I think you guys should look at that. I would predict it is. It would all be useful, it's just you would have a different hyperalignment as a function of whatever you were tweaking in terms of changing the brain state. I already mentioned the visual cortex. It's organized in all sorts of different ways. And we're doing some experiments now. We have, from Brain Initiative, we have some funding to do this mouse imaging experiments. You can do two photon single cell calcium imaging and you can look at individual cells. So this is following an individual cell here and looking at its fluorescence over time. These are each individual cells. Here is their plots of delta f over that. That's the flourescent calcium signal over time. And you can look with mesoscopic calcium imaging done at the same time, you can look at the cortex and you can see these motifs that are in synchrony with the different cell types. And so you can actually relate these kind of macroscopic patterns of activity to single cell imaging. We also have experiments underway where we can do this kind of mesoscopic calcium imaging, simultaneous with fMRI BOLD in a mouse at nine or 11.7 Tesla. And so we're starting to get some data on that too. But with that, I hope to be able to link individual cell results to macroscopic activity. The other thing about this, and I'm not sure if this example really shows it, but basically these cells are in this tiny chunk of cortex here. These are almost adjacent cells and they can have very different projections at the cortical surface. So again, showing that they're not all doing the exact same thing and there is tuning and that would be supportive of this sort of model that I'm proposing. And also just from the literature, in the macaque, there's regions that respond to face, to color, disparity, body. And so there's subspecialization in lots of cortical regions in both humans and animals. And then there was a paper, there's this cool paper by Thomas Yeo in cerebral cortex 2015 where they were looking at association cortex. And they did a meta analysis on a bunch of brain map data. I think they took a thousand studies or something like that. And they were developing this new ontology to look at mapping these new functions onto the brain, and they actually showed these overlapping regions from this new ontology. So they would get isolated functional regions that were associated with different cognitive domains, but these were overlapping regions. And so they went on to say that that's all related to the underlying connectivity, but they didn't take it that next step to say that, well, maybe we need functional, flexible definitions in terms of brain regions and things. And so I think that's important. What I haven't done here, so the point was brought up about, did we consider letting the atlas change the number of nodes? We didn't. We also, in this theory here, I'm not even discussing different cell types, okay. There's tons of different cell types within a brain region. I would suspect that we can measure with calcium imaging, for example, we can measure excitation profiles of those different cell types, and I wouldn't be surprised if we actually get different atlases for different cell types and they wouldn't necessarily overlap in the same sort of way. So there's a cell type of fact. So functional MR is independent of cell type. It's really responding to metabolic demand. And so MR is some complex integration of glial activity and excitatory activity and things like that. Whatever consumes oxygen leads to an MR signal. There's probably some overlapping cell type information there. And you saw from, or maybe you saw Emily Finn has a paper out on layers and you can look at inputs and outputs. There's probably some organization that differs across layers, too, and we haven't considered that at all. I think the bottom line is that it's probably, we're working maybe in a little bit of an over-simplified realm and that we have to consider some of these factors in looking at the brain flexibility. So I want to say I'll just wrap up with the, I think the brain is pretty complicated. There isn't a single functional parcellation. The state dependent parcellations reveal flexible organization of nodes. And I think that flexibility is fascinating but unfortunately most neuroimaging studies ignore this complexity and flexibility. But as we make more and more progress in terms of linking brain organization to behavior, I think we may need to take some of these things into consideration. And I'm not saying that the infrastructure is changing in any sort of way, you can have a fixed infrastructure and still have functional flexibility within that. And so this doesn't discredit or discount any of the structural work that's gone before us, this is within a fixed infrastructure, the brain can have flexible functional architecture. And so with that, I'd like to wrap up and thank, there's a bunch of people. That's a pretty old picture now of Emily and Monica and Marvin Chun and the gang at Yale. And in fact that's an old trio, I think, 3T Trio in the background, but no, in fact that's a 1.5T Sonata in the background. But there's a big group of people doing this at multiple levels and I actually do very little of this myself, this is kind of a everybody in the lab contribution. So thank you. I'd be happy to answer any questions. (applause) Yep. - Now I see that I should have not just tried to sell you on or something or promise, but you should've talked about researching. (laughing) Wouldn't you agree more, although that's more (mumbles), wouldn't you agree more with Ross Auldrich, who states that we are just using the wrong terms, to describe what we are actually studying, right? Because all the ontology-- - Yeah, that's the ontology thing is that we're using the wrong terms, but he has an ontology paper. I interrupted you while you, finish what you're saying. (laughing) - Those are in terms go actually through that's why in your talk, I was like I am siding with him and then I go with the verse, but these were from diverse deciding. Let's say thank you for using parcellation instead of saying atlas, right, because atlas, usually when I open atlas, there was objective information presented in that atlas. Now our case, we're dealing with nothing objective because we have no clue what you're studying, right? You're presented random blobs, right? Which we parsellate according to some algorithmic rate you're in, so even if there are regions you might not even be able to tell, right? So I would say their maps like if you draw a map, you have them draw a map because he doesn't have objective, right? So even the term atlas is incorrect term to use to describe what you're doing. Functional connectivity, as (mumbles) says, there is nothing functional and nothing about connectivity in that kind of statement, right? You are talking about correlations of secondary order measure which acquired from the brain, right? So all these as (mumbles), like can we say that there is no atlas, single atlas, with objectively defined regions. We know that there was to be one clear borders, right? Can we site a function and then you say yes, we can vision, early vision, right? Yes, we can. Right. How to keep it apart? How do we prescribe that, oh, within this region we can do more or more specialized in the description that goes about the oncology. Again, using the correct terms to describe sound objective matter. It's just my opinion that we just kind of happen to describe higher order functions of those regions we don't even know, right? So it's not a matter of not having such a thing, but as I'm able and capable to actually describe it. (laughing) - [Todd] Yes. (laughing) So that's great. So lots of things there. First of all yeah, there are lots of people that say there's like none of these atlases are right, right? They're all wrong. And maybe it's a data reduction strategy, although I would say they're also somewhat better than random. I mean they do have some, you may argue. Are you nodding yeah? - [Student] They're arbitrary. You use that word again, correct word, but it was about the (mumbles) arbitrary. Separate, but arbitrary. - And nobody knows what scale we should be at. I do think that, I mean, like functional connectivity, I do think that things that are oscillating together are probably somehow in this meta, whatever, doing something jointly. And there's lots of evidence that suggests that, yeah, that's a meaningful measure. Like Bob Cox may make fun of it, but he's totally in the field too. - [Student] The truth is somewhere in the middle. - Yeah, the truth is somewhere in the middle. But yeah, there are lots of caveats and I would accept that. Gail Viroqua is somebody who says all these atlases are wrong and I agree. It's a data reduction strategy. Fine, you know? But I do think too, that there is, when you get to the ontology thing, so Russ Pauldrack's view is that yeah, our labels like memory, or attention or whatever are wrong, and that if we just had the right labels that maybe we could get in a data driven way. If we just had those right labels, then we could assign a reasonable function to a region. But that still makes that assumption of a 1-1 mapping. And I've come around to thinking that that's a wrong assumption. There is not one region of the brain with 40 million neurons is not just doing one thing. - [Student] (mumbling) - Well that, yeah, but if you want to say, if you're happy with vision as a description of function, we're almost done brain mapping, right? We know, we know Brocha's we know Wernicke's, we know the motor cortex. I mean this, this chunk over here does motor, you know, we know that. So are we done? No, I don't think we're done mapping. We need to look, we're interested in looking at more detail, right? And so that's when we break it down into these subregions. I don't think it's on, the question is, do you buy functional conductivity as a measure? You know, like I kind of do and I-- - [Student] There's nothing wrong with correlation, of functional signals, right? - Yeah. - [Student] But that's a term, right? - Well, it a-- - [Student] My functional connectivity might be different from your functional connectivity. I think I would use the Goldens, I would use some other metric. - Oh, sure. But, I don't think it's not necessarily pertinent to how you measure correlation or what that measure is right? You're making some, what did you say? - [Student] Directionality. I mean like how-- - [Todd] We don't have any, in BOLD information, we don't have any directional information. - You can compute directed information, cross entropy. You have data that's long enough that you have probability distributions over (mumbles) sub-regions, right? Then you can correlate. - [Todd] Yeah. You can get that, but it could be erroneous, because in BOLD, you're dependent on plumbing and things like that. So directional information isn't reliable in BOLD. I mean, we're looking at really slow fluctuations here. They're a complex mix of all those things I mentioned before in addition to the local vasculature and plumbing and stuff. And so to compare A to B and see which one went on first, that's really difficult to do, and I wouldn't put too much effort into doing that because of the plumbing Callum found, you know? But yeah, certainly-- - [Student] You have information that's passing from one region to another region during some sort of a test, right? So wouldn't it be nice to be able to quantify, like how many bits of information are actually being sent from one region to another region? How much processing is actually going on? What are the thermodynamic costs of all of that process? - [Todd] It would be nice to have that, but we don't have that, right? I mean yeah, it'd be great to have that. I agree. - Can I ask a different question? - [Todd] Sure - Which is, I think in a way there's, there are two competing explanations for the kind of observation you have that the membership changes, right? So, voxels, certain sensitive voxels with changes, temporal profile of its response as you change the task, and that will change its grouping with other voxels and then the parcel definition. And one explanation is that there's a fixed architecture, but there are these overlapping neural populations, that you showed really nicely. And so one task you activate this subpopulation another test this other subpopulation, so that all makes a lot of sense. But in a way, you could think of the architecture as still fixed. So if you could measure every single neuron in the brain and that was your atlas, every single neuro in Todd's brain, then (coughing drowns out speaker) Because orientation, diagonal to neurons, always going to be that great or something. The other alternative is that there's actually a change in the dynamic organization. So that, so the function of the same test population of neurons is actually changing based on its connections and inner correlations. And do you have a strong feeling about that? - [Todd] No, but yeah, I could agree that that could be another explanation for it too, right? Is that they, it's the same neurons, but they're getting different inputs or outputs or different inputs, let's say, from other neurons. That's kind of the second argument, right? (student speaking) Which is consistent with your positive versus negative response of, or was it you who were telling me about in, no, who was telling me they had who had a nice, positive Nager caravan? But yeah, you can you change the function of something depending on the state and/or the input and nothing else has to change. Like nothing. Again, here, nothing's changing here. It's just which neurons are firing, right, and in which order. And I guess in my case, I'm saying that something is driving different subpopulations, whereas in your case, you're always driving the same population, but in different ways. And both are equally fine, although, yeah, both are equally fine. But I do think that there's some sub-organization that we need to consider and I don't think we're considering that. Yeah. - [Student] I came up with good analogy, we can discuss it in the evening. (laughing) - Can (mumbles) slide? The one thing I, when you were talking about functional (mumbles), I kept thinking about can we, over some tasks time or the resting state, you're just taking the correlations fluctuations over time. You know, what, what are the signals that would come out, what if things are changing really fast and genes are changing in the slow time scales or if they're fluctuating back and forth, and could it be that the functional content measure itself is obscuring, and the reason why you're getting similarities or how much of that drives it? When you look at the calcium (mumbling), if you correlated all of those, some of them are going to correlate really strongly (mumbling), There's going to be a gradation rate from like zero correlation to some correlation. What's interesting, if you look at a time you're saying it was like binary at exceed some threshold. Are they active? There's time points when all three of those four, you know, three of those four neurons are active, sometimes there's four or two, but those might be discrete states. But if you're, if you're taking continuity over time, we get completely different measurement of (mumbles). - Yeah, so the the dynamics problem is really difficult. And I, I showed this in terms of state, but that's only because that's the easiest way to show it. I'm sure this happens at the dynamic level, but it's really difficult to prove that, right? It's pretty easy to say you're in a brain state A or brain state B. I'm sure we're going between all those states over time. - [Student] So I guess like, did you see any variation in your, when you look across, because I know you showed that like the ability of the node size of the parcellation respondence, but is there a consistent variation across the nodes or edges or particular (mumbles) classified states? Did it mean that or something about that as giving you some extra information? - [Todd] Are you asking, is there a set of nodes that defines a state transition or defined? - Well, the state as you're talking, and I agree I think especially from (mumbles) it's hard to do that, but at least you have like your task dates from your data scanned over and over again. And I think there's a couple of things. One is like basically common core if you're smaller, which like they becomes much more reliable (mumbles) rested step states, which is interesting. But then couldn't it be that some edges or combinations of edges while you discriminate between different states really well, basically? - [Todd] Yeah, I mean there would be, so we haven't looked explicitly at that, but I'm sure there'd be a subset of edges that help that maximally define that state are mostly characteristic of that state. - [Student] And so did you see some structure variation across different task states between certain edges? Does that give you information of what that region is doing or how it's-- - Whenever we've looked at that in other studies that hasn't been very informative. You get that mass of connections everywhere and it's not like just one network or one system or something. - [Student] Well last week this was just kind of the same thing, just another way, which is where do your third orders, you have another edge that's modifying another edge. So it's like dynamics affecting each other. I know it's uncommon exposing them more. - Yeah. Well I don't think we could discriminate that, right? I don't think we could tell, again, we can't tell what's driving what. - [Student] But if you have like two nodes that are fluctuating together but then when those and they just fluctuate and they just might affect another edge. So it's like the interaction to things versus the interaction of two things, the reaction of two other things coupling. - [Todd] Yeah. We haven't looked at that. - [Student] So does that suggest that calculating the three point correlation functions instead of the two points like-- - (mumbling) So one could be, like you have three nodes interaction and the other one could be actually how one state affects the state of another coupling of another at a different point in time. - Different points in time. - [Todd] Yeah, I think the whole moving window and all that temporal dynamics, I'm very interested in that and I had a really hard time getting reproducible results in that and knowing it's hard to know what state you're really in. - I think we should thank the speaker. There's some snacks out there, if you'd like to stick around and ask Todd some questions. - Alright, thank you. (applause) 