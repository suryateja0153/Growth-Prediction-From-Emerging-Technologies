  Good morning, everyone. Thanks for joining us today for the NCI data science seminar series. I'm Tony Kerlavage, the director of CBIIT. I want to remind everybody that today's presentation is being recorded, and will be made available on the datascience.cancer.gov website. You can find information about future speakers on that site, and also by following us on Twitter. Our Twitter handle is @NCIDataSci, S-C-I. Today I'm very happy to welcome Doctors Tim Griffin and Pratik Jagtap from the University of Minnesota. Dr. Griffin is director and professor of the Center for Mass Spectrometry and Proteomics at the College of Biological Sciences. And Dr. Jagtap is a research assistant professor at the Department of Biochemistry, Molecular Biology, and Biophysics. The title of their presentation is Galaxy-Based Multi-Omics Hub for Cancer Researchers. And with that, I will turn it over to them.  Alright. Thank you very much. How does the audio sound? Can you hear me well?  Yes, sounds fine.  Alright, great. Well, thank you. Pleasure for both of us to be here today. So just happy to be able to give an overview of the work we've been doing, and are continuing to do. So I'm going to start it out here, and then Pratik is going to take the second half. So just as a real quick start, definitely what you're going to see here is a work that is very collaborative across a number of groups, and really across a good part of the world, but-- I'm not going to go through all of this here, but much of this is done at the University of Minnesota, along with collaborators at the Supercomputing Institute here, help us develop the software and put it into place, as well as a number of groups that are developing really high-value software that we're leveraging, and you'll hear more about that. And also, just a note that this is through the Informatics Technology for Cancer Research is one of the main support mechanisms that this work has been based on. So that is what is making this all go forward. But here's the outline. I'm going to start with just a kind of a brief overview of our ongoing ITCR project. And sort of what our philosophy is, and what we're trying to do. And then, we're really going to focus today on two multi-omic applications. One called proteogenomics, and I'll take that. Pratik will take you though what we've been doing with metaproteomics. And then, also a bit about how we are trained to make this software accessible, and some things in some future directions. So that's our outline. So this is a very brief, high-level overview of the ITCR project. So the project is titled Multi-omic Informatics Hub for Cancer Researchers. You're going to hear more about this. It's based on the Galaxy platform. And really, our goal overall here is to develop a unified environment that is accessible not only to bioinformaticians, but to bench scientists as well, where we can make high-value software available for multi-omic applications that are relative to cancer research, both basic and translational. So what do we define as mulit-omics? it kind of means something different to everybody that does it. The sort of organizing, or central part of this that's all of what we've been doing, our central type of data is mass spectrometry-based data. So I'll talk very briefly on this. We are doing some work in the metabolomics realm of mass spectrometry-based metabolomics development. But what you're going to hear today are these two applications of proteogenomics, and metaproteomics, which at the heart, utilize mass spectrometry-based proteomics data as well as integrating this type of data with other types of omics data. So those are going to be what you hear most about. But just very briefly, this is just a single slide on the metabolomics work. So part of what we're doing is really trying to develop these tools across these different omic domains. We do have, along with some collaborators, Adrian Hegeman here, at the University of Minnesota, who is a metabolomics expert, and some members of our team who've been doing this. We have also been developing tools within this Galaxy platform for doing metabolomics. And really, there's a pretty thriving community out there. Did I just see a note that there isn't any sound?  We hear you fine.  You got me? OK. I'm getting a note on my screen saying there isn't any sound, but as long as you can hear me, I'm going to keep going. So we've been doing this work, leveraging this kind of thriving community that is developing metabolomics tools within this Galaxy platform, and really taking advantage of some of the benefits that Galaxy has that I'll talk about here in a minute. And we've been contributing to that. Really trying to generate an environment where you can either locally install these tools, to really [inaudible] sort of comprehensive metabolomics, or we do have these tools available on a public instance, and that's a European instance, and you're going to see that a little more in some of the proteomics work we're doing. And we've been doing some work on some customized tools also for various types of metabolomics analysis. And trying to contribute sort of this community of metabolomics researchers. So that is a piece of what we're doing. And you can go to this public instance to see a bit more about that. But we're not going to focus more than that today on the metabolomics part. So something in the other applications here, and this is sort of the proteomics-related side of this. I'm going to start with proteogenomics, and some of you may be familiar with this, but I wanted to give just a little background, which actually will help when we get to the metaproteomics part that Pratik will present as well. So as I said, we're really at the base of this multi-omics approach is starting with tandem mass spectrometry, or MS/MS data. And so utilizing really what is the mature and sort of most prominently used pipeline for proteomics analysis, and that is taking complex mixtures of proteins from a variety of sources: cells, tissues, fluids, whatever this might be. Turning these into peptides through enzymatic digestion. Taking this through separations that then introduce these peptides into the mass spectrometer, and that's what these little colored circles are supposed to detail here, are different peptides in a mixture that are introduced into the mass spectrometer. And the mass spectrometer, one by one, isolates these charged gas-based peptides, isolates them in the instrument, breaks them down into smaller amino acid segments, and then detects the masses of these peptide fragments, or these amino acid fragments, within the mass spectrometer. So that's this tandem mass spectrometry process, where it now generates this spectrum of fragment masses that go with this peptide sequence, which is really sort of like a fingerprint to that peptide amino acid sequence. And these instruments have gotten very automated, and very fast, so that a very complex mixture of peptides that you've generated from complicated biological samples. This is a process that just goes over and over. It selects one peptide fragment, selects an MS/MS spectrum, then goes back, selects the next peptide, and tries to process as many of these peptides that it can detect as possible, and fragment them down into these fragmentation spectra. And then, what we do with those is take those MS/MS spectra, and we try to now annotate these. Match an actual peptide sequence that goes with this spectrum, so that's done by sequence database searching, and I'll get into this here in a second. But traditionally, it's taking a protein sequence database, generated either just from another reference database, from biochemical protein sequencing, or potentially predicting proteins from, say, DNA sequences. Those are then matched to these MS/MS, and you get a peptide that then goes with the fragmentation spectrum. That's used to then infer and identify a protein that was within that starting sample to start with. So you build this back up to a protein sequence. So that's kind of the routine, mature way-- that has become the mature technology for sort of automated proteomics. What we're doing in proteogenomics is a bit of a twist on this, and that really leverages and takes advantage of the fact that with next-generation sequencing that has become really so prominent and cheap and accessible to really most labs. You can now pick a sample, and not only detect the proteins, but also, say take a portion of that sample, and submit it for RNA-seq analysis. So use that to assemble a transcriptome. And what we're able to do then is take that transcriptome, and this is a very simple example, and if you had DNA sequences, you could similarly do something along these lines, but we'll focus on the RNA-seq part of this. So. Take this transcriptome, predict from that all the potential proteins that may be translated out. So basically create now a comprehensive database of hypothetical proteins. Proteins that carry mutations, splice isoforms, single amino acid changes due to changes at the RNA level that you might detect. And really what you're doing is effectively creating a sample-specific database that sort of contains all the potential proteins within a sample, which goes beyond, say, just the reference database, and would capture events within your particular sample that may not be captured, say, in a reference database. So what does this give us in the end? So when you bring all this together, now we take that same sample, and we generate protein MS/MS spectra, so we also analyze the protein component of, say, that sample, utilize this customized sequence database that we've generated, say from RNA-seq data. And match these spectra to these potential sequences that are in our sample. And now you get peptides that are present in the sample after doing this database searching process. And with some bioinformatics, you can now map these back to, say, the genome, and start to uncover new and interesting things, such as peptides that are coming from transcripts, and then being translated from sort of, unexpected regions of the genome that weren't thought to, say, code for a protein. Within those protein-coding genes, you definitely will find many, many peptides that go where they should, in terms of predicting coding genes. But also within those, we start to be able to pick up at the protein level, things like unanticipated, or unique splicing events. So that's what this figure is kind of trying to show is that peptides that are spanning, say, the boundaries of spliced exons in unique ways that give rise to then unique proteins due to splicing events. Or say, single amino acid changes short indoles that may be happening within these coding regions, that then manifest themselves at the amino acid level as changes to the actual protein itself, which potentially has that impact on structure function proteins. So this is becoming kind of really an emerging method, proteogenomic method. CPTAC which you may be familiar with at the NCI, that is, is doing a lot of proteomic analysis across different tumor types. Utilizing this sort of proteogenomic technique as well, to really get more comprehensive data there. Has a lot of possible applications. Definitely one that we're not going to talk about here today, but it fits into this is things like neoantigen discovery. So looking for unique peptides that are present in samples. And really the power here is that it goes beyond just the RNA-seq which is sort of predicting a change to proteins, and actually putting on top of that, direct confirmation that changes at the RNA-seq level are actually translated to a protein that has a change in its amino acid sequence. We're really adding a complete look at things. Well, how do we do this? And we got into this several years ago, and started being interested in these applications and what was very obvious is that, it sort of ups the ante in terms of bioinformatics and computational tools you need to do this. So it gets a bit more complicated than, say, just traditional proteomics, where we need to generate these customized databases from, say, RNA-seq data. We need to search them. And then we need to do a fair amount of filtering, trying to understand where are we finding unique and not whole amino acid sequences. As well an attempt to sort of visualize these against the genome, and interpret the nature of them. So this was a bit of a big task, as we started into this, and sort of what has led to the work that we've been doing. And so what we did is turn to Galaxy, which many of you may be familiar with. It's a good 15 years or so that Galaxy has been around. It was developed by Anton Nekrutenko and James Taylor. And really what is-- this idea was to make this web-based environment, this computing environment that was flexible, and open to bringing in different software tools, potentially across different omic domains, and fields and things. And then, integrating things together and presenting it in sort of this unified accessible environment. So we started to look at Galaxy as a solution to our issues for proteomics, and then these more multi-omic types of applications. We started sort of integrating sort of proteomics tools into Galaxy, and that was what gave rise to this Galaxy for proteomics, or Galaxy-P project, which we continued on. And now has expanded into some of these more multi-omic types of applications. And has just-- Galaxy has a lot of advantages for what we're trying to do. And already has a very thriving genomic transcriptomic sort of community that is contributing. So we're adding in the proteomics as well as some of these customized tools for doing these multi-omic applications. And really, kind of what we're trying to do from the outset, is wherever possible, leverage software that is being developed by other groups, and bring them into this environment so that we're not trying to necessarily reinvent the wheel on all sides here, but bring these together, integrate them, and customize and make tools as necessary, that are needed for these multi-omic applications. I just put this in here as another view of Galaxy and what it does. This is from Jeremy Goecks, one of the creators of Galaxy. But this idea that it brings this environment, and this workbench, to users that can take in data, can then also bring in analytical tools, and integrate these tools together. Flexible in terms of what sort of resources it can be-- or installed on, and run on, and implemented on. And then has really, is geared for, and one thing that was helpful for us, has a web interface that is really a user interface geared towards non-expert bioinformaticians, that people who are bench scientists that can learn this. Also has a programmatic API. So one can do this through the command line. And really gives a lot of flexibility. As well as a nice API, where you can communicate with other software, and communicate into Galaxy as well, and really automate a lot of things. So it's been a platform that really has been very useful for us, and has a lot of advantages. So we're going to show you a little bit of that. So getting back to proteogenomics then, as we started to work on this, a lot of what we focused on initially was generating this sort of integrated, automated workflows that are needed to take, say, input raw RNA-seq data, analyze and assemble that. Call variance, and things like that. And then, more customized tools that utilize the RNA-seq to generate, say, a protein sequence database. Now we can bring in our MS/MS proteomics data. Use that database, do the matching of peptides and things, and then get output of sequence variants. So that's been a big focus is just sort of getting that data, integrated data processing, up and running in an automated and sort of rigorous way. But a lot of what we've been focusing on is sort of that next step. And I think anybody who operates in the omics sphere with a lot of data being produced, what you can do is start to feel a bit overwhelmed by this giant list of information. What do you do with that next? So a big focus has been trying to develop, and really leverage some of the nice features in Galaxy as well of how do we develop some tools to help interpret and characterize some of this data that comes out, so that we can really put in the hands of researchers some tools that help them interpret what is most important, and most interesting from this data? So I'm going to talk about a tool that we've developed that is a visualization tool, called the multi-omics visualization platform, or MVP for short, that really allows us to take this output, and start taking a closer look at the variance, and mapping them to the genome and understanding them. So I'm going to run a very quick video here. I'm going to just kind of narrate through. This is the Galaxy user interface. Over here is sort of a completed data analysis history. So it records and keeps track of the whole entire history as it runs. And what I'm going to show you is how we have developed this MVP tool to-- once this proteogenomics work flow has run, and we have results, to in an automated way, start to try to visualize some of these results. So I'm going to hit play here. And it is what's called a plug-in tool. So we developed an output here that's sqlite output, and it's a data table with all the information that we need to view these results. That this MVP tool then recognizes. And within Galaxy can be automatically launched. So what you're seeing here is just sort of the overview of it. What you can also do is go back into that completed analysis in Galaxy, and we've filtered out those hits to peptides that are novel sequences. So that's what this is showing is, we're just pulling in novel peptide sequences identified in one of these proteogenomic workflows. And now we're going to select these, and look at them closer to understand what is the nature of these variant sequences. These variant proteins. So we're looking at one example, it's showing you a certain peptide sequence. These are pretty standard sort of proteomic data that are visualizations of looking at those MS/MS that gave rise to this peptide sequence match. And looking at some of its quality. And also we put in this ability to view the protein level. So what you're seeing here is a view of the complete protein sequence, and as this scrolls across the colored sort of orange-brown bars are peptides that were identified by this proteogenomic workflow, that map to this overall protein sequence. And what you're seeing here is the ability then to look at-- we're looking at a single amino acid variant. And launching the IGV, Integrated Genomics Viewer, which allows us to take that peptide sequence, that in this case had a single amino acid change to it, and view it against the genome to understand what was the translation frame. What's the nature of this particular amino acid change? So that's just a, you know, very quick overview here, what we're showing. So I guess it went through pretty quick, but what this is showing is highlighted right here with a serine that is a single amino acid change that went from asparagine to a serine. Based again on the RNA-seq data, but then also identifying a peptide that actually matches to that, that single amino acid change, that was actually expressed, and within a protein in the sample. So that's this MVP viewer, which gives you the ability to do some mapping and analysis in visualization of these results. We've also done some collaboration with a group. Rachel Karchin is at Johns Hopkins, who is also an ITCR group, has developed this tool called Cancer-Related Analysis of Variants Toolkit, or CRAVAT. And it is a standalone program which was developed to take in either genomic or RNA-seq data which indicates a variance that's been detected, and give you the ability to do impact analysis. So understand I have this variance been seen in other types of diseases or cancers? And some things about sort of functional implications of these at the protein level. So we've partnered with the CRAVAT team, and really what we've done is taken their tool and created sort of a Galaxy tool that brings in now, if we have proteogenomic results, that we can put on top of, say, RNA-seq results where we have actual peptides we've identified. Use that as an input to this CRAVAT tool. So we call this CRAVAT-P. And so within Galaxy, we can then again, launch this tool, and open up some visualizations. And that's all this is saying. So the output is such that automatically within the history, when you get the right type of output, to you use this CRAVAT-P tool, go to the Visualize button, and then you can open up this viewer, which automatically opens. And this is actually accessing CRAVAT in the databases that CRAVAT uses, and just a very quick overview, what this is showing is sort of this main page, where you can lift out all the variants that were, say, indicated in your RNA-seq, and also see those where we had actual peptide-level confirmation of those transcript variants being expressed at the protein level. We can then select those, and CRAVAT gives some really nice visualizations of, say, the overall protein structure. Where did our variance show up on that protein map? What other variants are known in certain types of cancers? If it's available, some 3D functional understanding of where does variance show up, and how might it affect, say, a structure function protein? And they've also brought in the index tool, which is a networked biology tool, where you can now also look at your protein of interest in terms of what are other interacting proteins, other interacting genes and things, to give you another level of interpretation. So another nice tool that gives you sort of a next step in interpreting some of these results. And then, really quickly, the last of these is one that we've worked on recently, and kind of answering the question of when people now do quantitative proteomics, and quantitative transcriptomics, where they get an understanding of, say, protein response under different conditions, and they also get an understanding of gene expression responses from the RNA. You want to do a sort of correlation and a comparison analysis of those. So this is a paper that I worked on many years ago as a post-doc, where I did this by hand, where we had mRNA abundance, and we mapped those mRNA to their corresponding proteins, and asked how does the mRNA respond compared to how the protein responds? And so what we've been working on is sort of a more automated way to do this, we call it the QuanTP tool. Where now we can run a workflow where we generate transcript abundance ratios, under two different conditions, and also have a proteomics analysis that also then we generate a protein abundance report. We map those proteins to their corresponding transcripts, and now [inaudible] and compare how the proteins and the RNA respond, and how does that compare? And I'll just very quickly take you through a quick video. What this really is, once we have that output, QuanTP applied some more sophisticated ways of visualizing the data, and understanding which of these protein and RNAs might have sort of discrepancies in terms of how they respond. So this quick video's just going to go through a little bit of what didn't get displayed, again, within Galaxy as a visualization tool. [inaudible] these results. This is a correlation map of RNA versus protein response, and tried to do some fitting of that data. And I think, most importantly, what we tried to put in here are some ways to detect those RNA and protein that seem to be the outliers. Seem to be the ones where you're seeing a big discrepancy between, say, an RNA expression level, and a protein response. And that's what this is showing. There's a measure called a Cook's Distance, which sort of shows those which had a very strong influence on the fitting of that line when we compared RNA to protein. And really, what we're trying to do is put in the hands of researcher some sort of automated ways, and hopefully intelligent ways, to give them a list of those proteins and their corresponding RNA that might be of most interest here, that are showing large discrepancies in their response, which you could then go in farther, and visualize, and look at what pathways may be post-transcriptionally regulated. So that's just a real brief overview of this as well as some visualization of clusters and things like that. So a tool that's really trying to automate this comparison of RNA to protein response. Alright. I am going to hand it over to Pratik. That is my sort of pretty brief overview at least of proteogenomics, and certainly maybe, when we have question time, I'll be happy to answer any questions. But I'm going to hand it over to Pratik to take you for the second half here.  Thank you Tim. So I'm going to switch gear and talk a little bit about metaproteomics, which is equivalent of doing microbiome analysis, using proteomics instead of using metagenomics, which is the most common metric that's used. So I'm going to give a little background on what [inaudible] and how-- what are the tools that we have available to analyze the data. Just to give a brief overview, I'm sure most of you are aware of microbiome research, but multiple studies now have shown the correlation of the microbiome. It has implications in health, disease, as well as the environment. Most of the studies for microbiome research have focused on metagenomics, and metagenomics would involve [inaudible] RNA sequencing, which gives you an idea about which organism is present in the sample, or [inaudible] genomics, which gives slightly more information about the gene potential of the microbiome that is getting studied. But in the end, metagenomics basically helps you to get an idea about the taxonomy, and not much-- I mean, you can make some predictions about the functions, but we really do not know which proteins or genes are getting expressed. And for that researchers have started using metatranscriptomics, where there is definitely a scope to understand taxonomy of the microbiome, but you do get some information about function, at least in terms of RNA expression. But we started doing metaproteomics almost 6 or 7 years ago, and our-- the reason why we got into this was, we believed that not only taxonomy, but we also get an idea about function of the microbiome. What are the functions that the microbiome expresses? And you know, [inaudible] expression obviously is the ultimate, and maybe metabolomics as well is the ultimate way that one gets analyze the function for microbiome. And the-- we also think that this will give us insights into the mechanic details in which how microbiome interacts either with the host, or environment. So instead of looking at just taxonomy, we actually believe that looking at the function, that is expressed by microbiome. It could be terms of proteins, it could be in terms of functional groups. And it's very important. But just to kind of highlight this importance, this is an unfocused data set, and this is from a biogas cellulose degradation dataset. On the left, all you see is a protein of principle component analysis plot, which has several time points shown in different colors. And you can see that if you use taxonomy as-- you know, the organisms that have been identified in the system as way to classify this, you see that it's kind of comes as a mixed-- you know, there is no good separation there. But if you use function, which means if you're looking at proteins or [inaudible] gene ontology terms that have been expressed, you can see that the point T1, which was the initial point of this dataset, is very well separated as compared to rest of the set. So we see this in a lot of [inaudible] datasets. So when we use function as a way to differentiate the samples, we see a much greater separation as compared to taxonomy. So in terms of cancer, there has been quite some research that has gone in to show that microbiomes, or microorganisms that are present in your body, especially in gut and other systems, do have an effect on cancer initiation, or progression. And so it definitely has some implications in trying to find if this could be a way to address cancer management. And on the left, as you can see, there are quite a few mechanisms by which the microorganisms interact with the host. But in order to understand the mechanism by which microbiome interact with the host, it's important not only to understand the taxonomy, but also function. And that's where using complementary methods that I mentioned earlier, like [inaudible] metaproteomics and metagenomics might actually give us a better insight than just performing metagenomics analysis. So with that in mind, we have studying working on metaproteomics. The difference between metaproteomics and proteomics, the way Tim defined earlier, the single organism proteomics, you definitely have a defined set of sequences. They're not as complex as metaproteomics, wherein metaproteomics you would actually have a larger database. And your database is comprised of multiple organisms, which have homologous proteins that kind of makes it difficult to not only to identify the sub-types, but then to fragment right protein that you would like to identify. But there are quite a few challenges in terms of [inaudible]. For example, there have been search algorithms that have been developed for this large database search issue. The identification statistics get affected, because you are adding a lot of noise to your data, and hence your identification numbers actually are [inaudible] back to single organism proteomics. And then you basically use taxonomy-- in order to find out the taxonomy used, the unique peptides that are identified in the system. And you use proteins that have been identified to understand the function. So there are multiple tools and multiple processes and steps [inaudible] and that's where we use Galaxy to kind of bring it up-- bring all these tools together, and bring the steps together. Very briefly I'll go through various steps here. So there's database generation, which means that you start with a FASTQ file, let's say from [inaudible] data, or the metagenomics data. You can convert it to protein FASTA file. You take your spectra that you have searched to your mass spectrometer, and then you assign the peptides for these. These peptides can be unique peptides, you assign them to a taxonomy, and [inaudible] you can define organisms set up within the system. You can also assign these to proteins of known function, and you can perform functional analysis either to get partway or to [inaudible] analysis and such. But there are various steps [inaudible] that one requires, you know, tools for, and we actually have bring these tools in order to [inaudible] you're not only looking at the function of the taxonomy, but you're also looking at quantitative analysis of the proteins, as well as functions that are expressed in the system. And for that, we actually use either spectral counts. So the number of spectra that identifies for a particular protein. Or intensity data. So we basically go back to the mass spectrometer, look at the intensity of the peaks, and try to identify and assign these to functions [inaudible]. So all of this was actually put together as a metaproteomics workflow in the Galaxy. And I won't go through the details of each tool here, but just to let you know that there is peptide identification set, which you just-- a few tools here. We have peptide quantification, which is performed by using [inaudible] that have been developed by our collaborators, and then we have [inaudible] Galaxy. We can assign function and taxonomy using a tool called Unipept. And then-- so for example, Unipept basically takes in a set of peptides that have been identified in your system, and then depending on whether these are unique peptides to a particular taxon, or whether they are shared by a taxon, they kind of get assigned to the taxonomy. But it also has [inaudible] to perform function, and so it basically assigns a peptide an EC number, and from the EC number it can find out which gene ontology terms are getting extracted in the system. And that can be very useful for us, too. But from quantitative analysis of the function [inaudible]. So once this is done, we basically feed this data, the peptides that identified, the quantification associated with that function as well as taxonomy into this tool called metaQuantome. And what metaQuantome tool does is, it performs statistical analysis and provides visuals so that one can interpret the data based on the input that you have provided. So for example, here is a slight more description about metaQuantome. So MetaQuantome basically can take in the quantitative information, function information, and taxonomy information, and then what it does is, helps you to not only detect the taxonomy and function, but also quantitate that. It also gives you the relationship between taxonomy and function. So answers questions like, if there is this one particularly taxon that could be in the system, what are the different functions it is expecting in a particular condition. [inaudible] can also answer a question like if there's this function, what are the different organisms that seem to-- are comfortable with this function? So basically just to highlight what we did with-- or what we can perform with metaQuantome, I'll present here a case study. So this was a case study that was published in 2015, along with the collaborative professor Joel Rudney from Minnesota. What he had was-- he was studying dental caries, and he was looking at plaque samples from children who had suffered from dental caries. And the idea was-- so he basically took 12 such samples, and each sample was taken, was grown in a biofilm reactor, in a pair. So one pair had control samples, so there was nothing added to the sample, and it was grown for 70 hours. While there was another sample in which sucrose was pulsed at two different time points. And then at 50-hour time points, samples were collected both for the control sample as well as the sucrose sample, or the sucrose-- sample. And so he had one such pairs, and this was-- this data was then searched [inaudible] using mass spectrometry [inaudible] by searching it against a Human Oral Microbiome Database. And then we performed analysis using our Galaxy [inaudible]. So I'll present a few results that came out of metaQuantome analysis. On the left, you see it blue, basically control samples. So you could see that these are the most abundant genera that were expressed in the control samples. And on the right side, you can see the most abundant genera has changed now, and you have-- in samples where you had introduced sucrose, and we have streptococcus as the most abundant genera. So you get a lot of information, quantitative information about the taxa that change. We could also see the [inaudible] changes by looking at scatter plots for both taxonomy as well as function. And for function there are two [inaudible] cellular component as well as molecular function. To look at what are the different functions that have differential [inaudible] in these 12-pair samples. We also performed PC analysis, principal component analysis, and we found, as I mentioned earlier, with taxonomy, we kind of get not as good a separation, but the new taxonomic function in this case, gene ontology terms that were used, you can see that the control samples are slightly more clustered, as compared to the samples where we introduced sucrose. The metaQuantome can also perform heatmap analysis, so you can see when you used function as a tool [inaudible] control, as well as sucrose-introduced samples. And then, you know, one of the things that [inaudible] metaQuantome has is you could also answer question about if you were to take a one-function process, for example, here we have carbohydrate metabolism as a process. What are the different organisms, or what are the different taxa that have been, that contribute to this, and as you can see here, fusobacteriaceae seems to be contributing most in the control sample, while the shifts of-- you know, you can see that streptococcaceae is the most prominent sample in carbohydrate metabolism. Then again, you can answer the question about what if you have a particular, you know, organism such as streptococcaceae, what are the different processes that it expresses in two different conditions? So this is-- this was metaproteomics metaQuantome workflow. And then we have also studied working on metatranscriptomics. And for this, we have used a workflow named ASaiM, which was developed by Berenice Batut, from-- who's now at the University of Freiburg. And while working with them we basically used multiple tools that were developed by them and were put into the workflow, but we went ahead, and actually optimized these, use the latest workflows, the latest tools, latest parameters associated with that. And what it can basically do is, it can take input as the FASTQ files from the metatranscript data, perform various processing steps, and gives a taxonomy [inaudible] functional output. And so using that, we basically use that on one of the cellulose degradation projects that we were working on. So this was basically a bioreactor wherein cellulose was used, and organisms were basically grown in an anaerobic bottle. And the idea was to see how do these organisms [inaudible] in high temperature, you know, along the time. And you can see here, there are at least four samples that were collected at different time points, and were subjected to either mass spectrometer or other [inaudible] data analysis. So with this analysis, we could actually find an time code analysis of taxonomy quantitation. You could see that there are some organisms which seem to increase and then decrease later but simple [inaudible] shows that particular trend which [inaudible]. We could also look at functional quantitation with different functions, which seem to change across time. And then, [inaudible] addressing questions like how does a particular taxonomy contribute to various functions, and other perspective, or take one function, what are the different organisms which seem to continue to that particular function. We can see they seem to be [inaudible] particular tribe. So there's some very interesting biological insights one can find using this [inaudible] analysis. Our eventual plan is to take the metatranscriptomics analysis [inaudible] and then compare them, and see whether we get actually slightly deeper insight in case-- rather than just using like a transcriptomics or metaproteomics. So that work is going on. We are working on correlating this metatranscriptomics and metaproteomics output so that you could get good biological insight. Our future plans are not only to kind of merge the metatranscriptomics and metaproteomics workflow, microbiome analysis, but also I should mention we also have workflows available for quantitative analysis of metagenomics. We have quantitative tools within Galaxy, host-transcriptomics as well, so the idea would be to take all of these quantitative analysis from the host as well as microbial side, and then try to merge them and get insights on how the microbiome is [inaudible] the host, and get slightly more ideas about the mechanistic details about how, you know, cancer [inaudible] progressive or the host system progressive. So with that, I think the last part that I have here is how do you access these workflows or tools [inaudible]. And you basically have at least two gateways. The one is proteogenomic gateway which can be accessed through this link that's been shown here. It also comes along with documentation. So step-by-step instructions and [inaudible] which tells you how to use this workflow, and hopefully to present the data. So it's pretty well-documented. We also have another one, the metaproteomics gateway, which can be accessed through this link. And it also has step-by-step instructions on how to use the database. Most of our workflows and tools that have been developed are also on the European Galaxy proteomic-- you know, the website here. The proteomics.usegalaxy.eu. Basically hosts all of the workflows and tools they are developing. So if you have colleagues in Europe, or if you want to actually access these, and use some of these workflows for your own data. We would recommend you go to this site to [inaudible] the workflow and tools. Or you could also contact us here, you know, sort of a recommendation which of these things [inaudible]. For people who are more software development-orientated, we are also available on GitHub. Most of our tools-- or almost all of our tools that are published are in the Galaxy Toolshed, which is technically a collection of tools that have been-- Galaxy tools that have been developed by researchers, so they can find out which tool could suit your need. We also have some Docker instances, especially for providing the tool that Tim mentioned earlier in the talk. And then we have quite a few training workflows available on this site called the Galaxy Training Network. So the proteogenomics workflows that Tim mentioned, the metaproteomics workflows, and some of the workflows are already available there. So if you can always go and read about it. You know, so that comes with info dataset, Galaxy system. It also comes with documentation if people want to kind of learn it on your own. Lastly, we could be reached-- I mean most of our manuscripts can be accessed by using this link. We have presentations that we have presented at various international conferences over the years, which can be accessed through website, through the site here. And then, if you would like to know more about our work, or you would like to collaborate, you can also contact us at this-- by using this link. We're also available on Twitter with the handle usegalaxyp. And with that, you know, I'd just like to acknowledge that this has been a work not only within our lab, but also with researchers at University of Minnesota and collaborators and developers all over the world. With that, I think me and Tim would like to take any questions if you have it.  Great. So thank Doctors Griffin and Jagtap for presenting this very nice work. [ Applause ] So we look forward to any questions. If you're in the room, just raise your hand. And if you're on the Webex, please indicate with the raised hand feature on the Webex dashboard, and we will [inaudible]. Question?  Yes, thank you. Thank you both for giving an excellent presentation. And just wanted to let you know Tim, that we've been using Galaxy here at NCI, and for training purposes for the exome and the RNA-seq, and we love it. You've done an amazing job. And we're happy to know now that you guys have the proteogenomics. The question that I have is, in terms of more fundamental issues with proteomic, do you think normalization of some of this MS/MS has been resolved? And more importantly, in terms of correlating-- in our hands, correlation of the proteomics and RNA-seq has not been as good as we'd have liked it. And lastly, if you don't mind, just about the using RNA to call variants. Is that reliable enough in your opinion? And with that, thank you so much. Again, great talk.  Maybe just clarification. So the first question was the normalization of mass spectrometry proteomics data. What-- could you clarify what you mean by that a little more?  Right, right. So I hear that there's a lot of noise, at least in the past that has been an issue in terms of really getting specific peptides. You know, there's been issues, at least in our hands, and again, maybe things have changed now. We were involved in some proteogenomics studies maybe about 5 years ago, and we had a lot of difficulty actually identifying some of the actual peptides. And again, that's more of a technical thing, if you don't have that information-- [ Multiple Speakers ]  Yes, more of the question of is there a reliability of like proteogenomics being able to identify, say, variants that are truly real, and not like false positives? Is that kind of the--  Right.  Yes.  Right. That's right.  Yes, maybe that was kind of [inaudible] that question and also is RNA reliable enough to predict protein variance, right?  Yes.  It definitely is. I think this area is still emerging as-- you know, it needs more work, and there's definitely a opinion and I think a realization from us as well as those who are trying to do this that there's a lot of pitfalls when you're trying to kind of-- it's sort of a needle in a haystack, you know? Where you're matching these MS/MS to these spectra-- or to these sequences. And there's a very small percent of these that are going to actually hit the variants. Most of them are hitting to the known reference sequences. So how do we ensure that those variants that we hit to are really confident, and they aren't false positives, which there are many reasons why these false positives might arise. And are you chasing ghosts basically, because data told you it's a variant, but it's not real data. So we're definitely working on that, and I know other groups are, that what we're actually doing is bringing in some new tools where you kind of do this first phase. It's kind of a discovery phase of, you know, matching these peptides to the RNA-seq indicated variants. Getting at least a decent list you're somewhat confident in, of amino acid changes and variants that you've detected, and then putting it through another round of sort of rigorous validation. So there's a tool that CPTAC, Bing Zhang, who's at Baylor developed called TechQuery that we're working with them to implement in Galaxy now, too. Which kind of is a validation tool, where if you think you've found a variant peptide sequence, you then can use this tool to sort of play devil's advocate. And take that variant sequence, and the MS/MS that match to it, and say go back to the reference database of normal proteins, and do a re-analysis to ask questions like, you know, is this hit that you think a variant, is it actually better explained by a post-translational modification to a reference sequence, that is really the real hit, and it isn't actually a variant. So we're definitely working on some ways to try to automate sort of a validation, to help make this data more confident. And really what we're trying to do is give researchers a chance to run these workflows and hopefully in the end, they get an output that is as reliable as we can possibly make it. There's still going to need to be some follow-up validation, but at least what we're giving people, we hope to try to make it as confident as we possibly can with, you know, the information at hand. Does that sort of answer that question?  Absolutely. Thank you so much, and it wasn't meant as a criticism. That's fantastic work. We're definitely going to be using it for our [inaudible].  Excellent. And yes, just the other question about the RNA to protein, the comparison, I think. The quantitative sort of response? You know, we're looking at, like, the tool we have, I think it's a good start, and it definitely gives some nice outputs and automation to doing these quantitative comparisons at the RNA and protein level. What we really want to do is go beyond that and it's more informative are things like time courses. Things where you can get more data points to really understand, you know, how well does the RNA track with the protein? And right now the way it's working is it's pretty much like a single time point that we look at, which may reason why the RNA wouldn't match very well to the protein, but I think expanding this a little hopefully will give us a better view of really what that response looks like.  OK. Was there a question online? [inaudible] go ahead.  Yes. [inaudible]. I have about [inaudible] program, which is looking [inaudible]. My question is, can this ever use gene-level data? I mean, it's the gene-level expression and the predominant reading. So can you use [inaudible] also can system handle several hundred samples?  Several hundred samples?  Yes.  Yes. Great question. [laughs] That one we haven't tried. It would probably take some work to figure out how to best do that. It is definitely the next frontier so to speak, is the issue of scale. I think where we would try to handle that, as Pratik ended with, where we're really trying to push these tools onto some infrastructure that really is built to scale better. And that would be like this usegalaxy EU site is really built to do that. And the Galaxy community is trying to make some of these resources, put them on infrastructure that can handle scale. There probably is just going to be some issues there, trying to analyze that many samples and bring all the data [inaudible] and manage it and visualize it well. So I think the answer right now is I don't know that we could handle that scale, but it's kind of where we would like to go, and truthfully it's we need some studies like that to help define the issues that are out there in terms of scaling this out. So we'd be interested in talking some more, if you're interested in working with us, and giving it a try.  [inaudible] Yes. We do have some [inaudible] data. Thank you.  I want to pick up on something you said early in your part of the presentation, Tim, which was you having a goal of bringing proteogenomics to the masses. I mean, clearly Galaxy is a terrific platform for being able to do that sort of thing, being able to leverage, as you said, all the big tasks that went into putting together the components in the pipeline, and creation of the peptide databases, and all of that. Being able to standardize the workflow for these types of analysis. And then ultimately having a very nice visualization tools in leveraging the built-ins that Galaxy to do that. My question is, are you finding-- are your colleagues either at University of Minnesota, or elsewhere, other colleagues, are you finding that they're actually using these tools more independently now, or is this still requiring people with a good deal of bioinformatics knowledge and expertise to actually run these workflows, because-- where would you say you are in terms of bringing this to the masses?  You know, that's a really good question. It's been a sort of central focus for us as well, is how can we really make these more usable, and really lower the entry bar for people? So I guess, based on our experience, you know, if people are willing to just take the step of saying I want to use Galaxy, I want to learn it, and run it, it is very much useable and accessible, and people can learn it. We've had undergraduates, and all kinds of people step in, and a little bit of training, they wanted it, and off they go. It does take, you know, it's new for people, so we also found there's just that barrier of, you know-- they're used to launching a Windows application on their own computer. [inaudible] for analysis, and now kind of stepping into this sort of enterprise-level type of software where you have to learn some new things in itself can be a barrier. But the place we're really trying to, I think, work on lowering that entry barrier, and making this more accessible is through what Pratik kind of said at the end here. The Galaxy Training Network, which is through the Galaxy Community has really been pushing this. And it's really nice, because it's an online resource, where you can go, and what we've done this and others are contributing. And really have all the documentation, as well as the actual tools and workflows, and some demonstration data. So that it is pretty step-by-step getting people just get their feet wet of how Galaxy works, and how these workflows operate. And I think that has been a big step forward to getting more people involved, as well as some of these public instances that are already set up for people, that they can just go and register, and log into, and start using these tools. I think one of the entry barriers up until now has been that to run Galaxy locally, you do need some bioinformatics expertise, in terms of how do you install it, and maintain it, and all of those things. If you don't have that, you know, we're trying to make these resources available to really make it easy to access. And you don't have to maintain your own instance, and all those things. So I think work continues to try to make these more accessible.  Great. Thank you, Tim. We're out of time, so I just wanted to say I hope you can all join us for our next presentation, which will be on Wednesday, January 29th. We're going to have a presentation on a tool that actually Tim mentioned in his presentation. Doctors Rachel Karchin and Kym Pagel from Johns Hopkins will be presenting on Open CRAVAT, an open source collaborative platform for the annotation of human genetic variation. So I want to thank everyone who's joined today both you're online, and here in the room. And once again, thank Doctors Griffin and Jagtap for this great presentation. [ Applause ] 