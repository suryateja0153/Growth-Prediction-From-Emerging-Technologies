 Su-In Lee: My favorite Allen School event is the job talk by a comp-bio faculty candidate who can help us learn about new problems, new important biomedical problems that computer scientists can address. Always really exciting to see what's out there. So today, it's my great pleasure to introduce our speaker. Sheng Wang is a postdoctoral researcher in the School of Medicine at Stanford University, and a Chan Zuckerberg BioHub scholar. Prior to that, he obtained his PhD in computer science from UIUC in 2018 and his bachelor's degree in computer science from Peking University in 2013. Sheng's research uses machine learning and natural language processing to address both fundamental questions in biology and translational sciences as well which directly is directly relevant to disease treatment. And today, he's going to talk about his recent research focus on predicting and understanding never-before-seen situations in biomedicine. So this research has resulted in not only publications in prestigious biological journals, but also noteworthy many real-world impacts in biology, medicine, and healthcare, and is used by major biomedical institutions. So before we have Sheng talk, I'd like to briefly remind you about a few things. So first please mute your microphones, which I think everyone did it and then please enable your webcams as well. And then, second, the Q&A needs to be initiated by the chat feature. So please type hand or question there and then I'm going to interrupt Sheng if it's during the talk, and then the finally, our new question asking policy which is that we welcome only quick clarification questions during the talk and the other questions that need to be asked at the end of the talk. So ok now, please join me in welcoming Dr. Sheng Wang. Sheng Wang: Okay, thank you for the introduction and please let me know if you can't hear me clearly, okay? I'm very excited to speak at Paul Allen School of Computer Science & Engineering. Today, I'm going to talk about a very important problem in modern biomedicine. The goal of modern biomedicine is essentially to adjust a computational problem, that is how to transform complicated and large-scale data sets into knowledge. Machine learning can do a very good job if we have enough training data. But what if we don't have enough training data? Or in the extreme case, where we don't have any training data? For example, predicting side-effects of a new drug or classifying patients to a new disease like Covid-19. I name this kind of problem never-before-seen biomedicine. It is a label class, like a disease or a drug, and we have never seen any training samples belonging to these classes. For example, here we have five training patient samples who are classified into two different diseases. We also have three other diseases: SARS, MERS, Covid-19. We have never seen any training samples belonging to these three diseases. They are the never-before-seen classes and they are the focus of my talk. We will see some test samples in the future and they might belong to any of these five diseases. So now the question we want to ask is; how can we classify a test sample Into a never before seen class? This problem setting is similar to generalize zero shot learning, but I'm going to talk about specific challenges in biomedicine later. Well, let's also talk about a solution later. Let's first look at what kind of biomedical problems involve never-before-seen classes. In fact, this patient disease classification problem is just a tip of the iceberg. There are many other important problems that involve never-before-seen class. For example, we still don't know the mechanism of many new diseases and rare diseases. That is because we have only seen very few patients of these diseases. Side effect of a new drug is another example. Drug side effect is the major reason why many new drugs are taken off the market. We cannot predict side effects of new drug because we have seen, we hadn't, we have never seen any patients taking these new drugs except those very few in the clinical trial. Problems caused by never-before-seen causes are pervasive, especially in big data age. We are often collecting and integrating data from different species. So when we do such a joint analyze of all these data set, we will inevitably see lots of never-before-seen classes. And if we are studying new drug, new disease, a new cohort, we also needed to consider lots of never-before-seen classes. So now you can see that there are so many problems caused by never-before-seen classes. These problems seem to be very different and they are currently tackled by different biologists, but I believe that addressing the never-before-seen challenge might be the key and a general solution to all these problems. So just like how deep learning has become a general solution for lots of problem where we have enough training samples, we want to find another general computational solution for biomedical problems with no training samples. Let's go back to this example again to see three specific computational challenges here. Because we have never seen any training samples for these never-before-seen classes, we need to have some extra information. What do we often have our class attributes? So in this patient disease classification problem, class attributes could be symptoms. Although we have never seen patients belonging to these never-before-seen diseases in this dataset, other sources or other data set might have seen such patients and have provided us with class attributes. But why don't we just simply use class attributes to classify patients? This is because these class attributes could be very noisy, especially for never-before-seen classes. If we only diagnosed based on these class attributes, we could make a very significant number of misdiagnosis. For example, at the beginning of Covid-19 outbreak in December, the first few patients are misdiagnosed as SARS. So the first challenge here, you to develop representation learning method that can obtain high quality class representation. Okay, now let's assume we have a drug test challenge and we have high quality class representation. The second problem is how to do the classification. The problem setting that we have training sample for some classes, and we have class representation for all classes. How can we use these class representation to transfer labels from seen classes to classes we have never seen before. Okay, let's assume again we have addressed this classification problem, and now we can accurately classify our test sample into a never-before-seen class. The third challenge is how to interpret our results. Interpretation is very important in biomedicine and then interpreting never-before-seen classes is even more challenging and more important because our knowledge about these classes is very limited. Do we have a good class attribution or cloud? Do we have a good good interpretation for COVID-19? We don't but we really need one. All of my previous research focused on addressing these three challenges in never-before-seen biomedicine. For example, one contribution I have made you to develop representation learning method to embed different biomedical structures into class embeddings. Using these class embedding, I have addressed important prediction problems in biomedicine such as protein function prediction and cell type prediction. Then, I developed in terms of a model to interpret these prediction. Model interpretation is one of the most important problems in biomedicine. We integrate scientific papers and biological databases to build a knowledge graph for interpretation. I know that UW has the leaders in this field, such as Professor Su-In Lee and Professor Dan Weld. They have developed many exciting methods, like Sharp, Tree Expander, Limeade. Our method is highly complementary to these approaches. They found the interpretation from the data set itself, but we found an interpretation from external knowledge graphs. So these roots, these three steps together build up a very exciting framework from no labels to new knowledge and it also provides us a general computational solution to different biomedical problems. Our method had real-world impact in biomedicine, they are building blocks for many important biomedical applications. We then collaborate with different biologists and fine-tune our method, but their tasks are curled in to the specific problem settings. This results in a very fruitful collaborations, for example our representation method help doctors at the Mayo Clinic find the mechanism of more than 400 cancer drugs. Our classification method with never-before-seen cell types help 36 biologists in Chan Zuckerberg Biohub accelerate your analysis pipeline from 3 months - 20 minutes We are also currently trying to find a rare disease genetic factors for California newborn screening program. Our interpretation method and the knowledge graph also helped hundreds of scientists at NIH understand their biological discovery. Today, I'm going to talk about all these three parts; representation, classification, and interpretation in never-before-seen biomedicine. Let's start from the first part. The reason why we need to do representation is essentially to help classification. Then why is classifying samples into never-before-seen classes difficult? Let's look at an example here. These green ones are test samples, and the remaining ones are training samples. Here is the gold standard - green and the purple are never before seen classes. So samples belonging to these classes only show up in test samples and have never been seen in training samples. If a sample belong to a never before seen class, we want to classify it to the specific class. So if our sample should be green, but we classified as purple, this prediction is still incorrect. Here is the prediction of K nearest neighbor. You can see that K nearest neighbor incorrectly predicts the classes of any samples belong to a never-before-seen class. This is not just a problem for kNN. In fact, any machine learning method cannot make correct prediction here by only using these features. Then how can we solve this problem? The solution to this problem is Zero-shot learning. Zero-shot learning can classify samples into never-before-seen classes if we have class attributes for these classes. Zero-shot learning has been used used to classify images into never-before-seen image classes. It is relatively easy to collect class attributes for image classes. This is because these image classes are often classes that we humans are familiar with like animals or fruits, so we can often find high quality class attributes somewhere. It is less likely that we are interested in classifying image even human don't know. Like maybe classifying image into alien from Mars or alien from Jupiter. But in biomedicine, the story is totally different. In most cases, we simply don't have any class attributes. So, this is a very interesting dilemma in biomedicine. Zero-shot learning has good performance when we have class attributes. But these classes are often old knowledge and less interesting. however, for new knowledge which is more interesting, zero-shot learning can not do well because we don't have any class attributes. Do we have class attributes for COVID-19? And the biomedicine is all about discovering new diseases, new drugs, and new cohorts. So how can we solve this problem? Our contribution is to use the biological class hierarchy to help us. A class hierarchy is a structured data that biologists use to talk humans their knowledge. In biology, we call them ontology. You can see that you can think of it as a 2d binary adjacency matrix. Each node is a biomedical concept, each edge connects related biomedical concepts. And even using this hierarchy is challenging. This hierarchy is high dimensional; there could be more than 20,000 nodes. It is also incomplete and noisy. The creation process could introduce many missing or incorrect edges. So we don't have class attributes and all we have are these high dimensional noisy and incomplete class hierarchies. Now the question is, how can we convert them into high quality class representations? Here is the problem definition for this question. The input is the hierarchy. The output is an embedding vector for each class in this hierarchy. So one prerequisite of our method is that these never-before-seen classes must present in the class hierarchy. The goal here is to represent each node in this class hierarchy as a low dimensional vector so that topologically similar nodes are embedded closely together in a low dimensional space. Well now the question is which two nodes are topologically similar given this hierarchy. One key observation is that this hierarchy does not follow six degree of separation. So two leaf nodes on a hierarchy could have a much larger distance than six degree. So we need to explicitly model the global structure. We use high order proximity to calculate topological similarity here. High order proximity can capture global structure. It is different from low order proximity like first order or second order proximity. They only capture the local structure. For example here, for this hierarchy, we want to know which node is similar to this red node. If we use first order proximity, then two nodes are similar that they are direct neighbors. For example, this blue edge circle, they're similar to the red node. But in this case, we only utilize very limited information on the hierarchy, that is only the direct neighbors. So, how about we use the second order proximity? Second order proximity means that two nodes are similar, that they share many neighboring nodes. For example, This blue touch circle is similar to this red node using second order proximity, because we're not their neighbors is the same. So now you can see that for each node, second order proximity utilize a bit more information on the graph, not only direct neighbors but also neighbors neighbors. Then why don't we just use that Nth order proximity? Here N is the number of nodes on the graph. In this way, We can capture the whole graph structure. Because class hierarchy could be incomplete and noisy, We want to capture the global structure to mitigate the nodes, the noise. Using the nth order proximity, any two nodes are similar if their distance to all other nodes are similar. Let's look at the mass to see how we implement high order proximity. The goal here is to calculate a similarity score between every two nodes on this hierarchy. Here, we use a diffusion model called random walk with restart to calculate the similarity score. In each iteration, we will either randomly walk to a neighbor or restart from the original node. After the diffusions converge, we will get the equilibrium distribution. Starting from each node and this equilibrium distribution models the distance from this node to all other nodes on the hierarchy. So in this way, two nodes are topologically similar if their equilibrium distribution on this graph is similar. However, these distributions are still high dimensional. We need to reduce their dimensionality. What we can do it is to join decomposed the equilibrium distribution of all nodes. We want to find an embedding vector X and the context vector U for each node, so that the observed S is close to the estimate S have. And this Xi will be the class embedding for class I. Our representation can be used in both supervised learning and unsupervised learning. I'm going to talk more about the application and supervised learning later when I finish the classification part. Here, let's look at the application of our method in the unsupervised setting. The goal here is to cast our cancer patients into different groups so that we can find them personalized cancer treatment for each group. We use our method to impact 6000 cancer patients for can't patient survival clustering. Each data point here is a cancer type. We set hundreds of real patients. So this figure shows that our method is much better than the one result using high order proximity. This figure showed that our method is much better than the one without doing dimensionality reduction and these results together show that our embeddings enable personalized cancer treatment by accurately clustering patients into different groups. We also have a field full of papers extending our method so that it can be applied broadly to different problem settings. I'm going to briefly introduce three extensions. First, if we've had multiple hierarchies, for example drug hierarchy created based on different criterion; one could be based on drug chemical structures similarity. Another one could be based on drug target similarity or based on drug side effects about it. How can we integrate them into one hierarchy? The key idea here is to decompose every hierarchy as we did before. And that is node embedding Xi we shared across different hierarchy. So Xi represents the embedding of node I by integrating different hierarchies. Now our message can be used to integrate information from accumulating and the diverse biological hierarchies. What should we do that the hierarchy has multiple motor types and multiple edge types, for example a hierarchy can have not only drugs, but also diseases and genes. How can we embed all of these nodes? We introduced additional parameters to model different edge types. Because now the hierarchy could be very large when it has multiple edge types and no types with some whole address according to the frequency of different past types. So in each iteration, we first sample a path and then we sample a specific task, according to this test type. This method enable us to incorporate the data set from other sources into biological hierarchies and then we can jointly analyze all of them. So, what should we do if we don't have any hierarchies? This time we need to build new hierarchy. We jointly mine scientific literature and biological data data sets, we first build a gene class the hierarchy for the specific problem We want to study. For example, in our major communications paper, we built a class hierarchy to model human evolution. We then mine biomedical freezes from literature and allowing each gene cluster with a freeze. So in this way, we can have a new class hierarchy for follow-up predictions. And this method enable us to update correct and build hierarchies. Our hierarchy based method can then be broadly applied to other biomedical applications. So this is the first part of my talk. We use class hierarchy to generate class embeddings for never-before-seen classes. Our representation has two key steps. First, we use equilibrium distribution to model global structure. Second, we reduce the dimensionality of these equilibrium distributions. Next I'm going to talk about the second part. How can we use these class embeddings to classify samples into our never-before-seen classes? This is the problem setting of the never-before-seen classification problem. The first input is samples. The second input is the class embeddings we got from the representation step. The goal here to classify test samples and the many of them might belong to a never before seen class like green ones and these purple ones. So in the treating stage, we want to find a transformation to project samples from the sample embedding space to the class embedding space. The optimize, the optimization goal here is to map training samples as close as possible to their class in the class embedding space. For example in this case you can see that the optimal, the optimal transformations like rotate a little bit and squeezing this dimension so that the orange samples are close to the orange classes, pink sample close to pink class, blue are now close to the blue class. During the test stage, we use the same transformation to project past samples and past sample will be classified into that closest, into the nearest class, in the class embedding space. So this one will be classified into orange. This one would be classified to pink. And the key of our method are these samples in the green region. They are classified into the green classes and we have never seen any green samples in the training data. Let's look at the implementation. So during the training stage we want to find W then minimize the cross entropy loss. And during the test stage, we use the same transformation to classify each sample into the closest class. So generalized zero, zero-shot learning could be easily overfitting and bias to same classes In the extreme case, all test samples might be classified into same classes. So we often use a linear regression, linear transformation in the training stage. We also did that calibration after the test stage to normalize prediction skull between same classes and never-before-seen classes. Our method has been applied to a few important biomedical applications such as protein function prediction, single cell prediction, and patient's disease prediction. Next I will talk about two applications. Let's start from the single cell. So what is a single [INAUDIBLE] city so our human body is consist of 20, 27 trillions of cells. A cell type is the building type, like a restaurant, a school, or grocery store. The goal here is to classify cells into cell types and the we have only seen about five percentage of cell types in the training data. This is one of the most important important problems in biomedicine. Why? Because we detect is easiest by counting different types of single cell. This is this is a complete blood count test which is often the first attack you will get if you feel sick. In this table three rows are the counts of three different cell types, white blood cells, red blood cell, and platelet cell. Five other rows are different properties of cells. So from this widely used CDC test, you can see how single cell can be used to detect diseases. In 2018, there is a very exciting technology breakthrough called a single cell technology. With single cell technology we can measure features for individual cells as these features are the gene activity score in biology. We call them gene expression. Single cell technology let us see the feature of every single cell just like here in a fruit bowl rather than seeing the averaging feature of many cells in a big organ or tissue like here your smoothie. If we don't study the cells individually, we will not be able to tell which part of the organ you're sick. We may not even know that it is sick. Because we can see every individual cells now, we will see lots of never-before-seen cell type, then predicting cell types using emerging problem. Let's look at the experimental setting of our method. There are two inputs, the first is the gene activities feature scores of 500 thousand cells. It is a 20,000 long numerical vector. The second is the hierarchy of cell types. They are two more than two thousand cell types, but only 98 of them are seen in the training data. We can now use our method to classify these cells. First let's look at the cell type prediction performance. X-axis is how many level be posting cell types are there in the test set. A larger x-axis means that there are more never before seen cell types pink one is our method. We can see that our method outperforms all the baselines, for example even when 80 percentage of the test data is from a never-before-seen class, our AUROC is still greater than 0.7. The key observation that the improvement of our method is larger. We still increase of never-before-seen classes. By embedding cell type hierarchy, our method first ever enables the classification of cells into never-before-seen classes. This kind of never-before-seen classification often cannot be achieved by human experts. We then studied a generalization ability of our method. This is very important in biomedicine when we want to integrate and a jointly analyze multiple data set. So we collect 27 data sets. Between the one dataset and then predict on these 20 the other 26 datasets. You can see that our method has a very strong generalization ability for those cell types we saw in the training data the AUROC is greater than 0.95. Even for 7 cell types we had never seen the training data. We still had an AUROC greater than 0.8 for 4 of them. Because we can accurately classify cells into cell types now, we can also do some post-processing to find theta urban class attributes. These normal data driven class attributes are exactly the knowledge that human experts don't know but they really want to know. We also observe good performance here. Our method, the red one, is comparable to expert curated attributes in classifying new cells. My research in single-cell analysis has been extensively used by major biomedical Institute's Chan Zuckerberg biohub. Biohubs are joint joint collaborative effort for more than 100 labs in Berkeley, UCF, UCSF, and Stanford founded by 600 million commitment from Chan Zuckerberg foundation. Single cell is one of the two main projects in Chan Zuckerberg biohub. They are producing some of the existing largest of single cell datasets in the world and our method is used to predict the cell types in their pipeline. We are now applying our method to rare disease detection. We are currently working with scientists who advise the California newborn screen program. So any new discovery of our method might potentially impact every newborn in California in the future and this is also the ultimate goal of my career. That is to help millions of patients and their families. Now let's look at the second application, how to predict protein functions. Human bodies consists of single cells and a single cell consists on consists of millions of proteins. If a single cell is a building, then proteins are bricks, windows, carpets in this building and the protein function will be the property of these bricks and windows such as fireproof, thunder proof, or waterproof. The goal here is to classify each protein into its functions and the challenge here is that most of the functions have very few training samples. For example, in human, about 50% of functions has less than 10 training samples. So this is a few-shot learning problem now. Why is protein important? From this CBC result, you might notice that eight of them are related to single cells and the last one is actually an indicator of protein. So we also detect diseases by monitor by monitoring proteins. Let's see the experimental setting. There are two inputs. The first input is the feature representation of proteins. The second input is the hierarchy of protein functions. We can now use our method to classify these proteins. Let me first introduce how to represent proteins from different species. To give the future embedding for each proteins, we need to group proteins from different stages. There are two types of edges; one is edges connecting protein across species based on sequence similarity. The other is edge connect protein within the same species using molecular networks. So this kind of large scale network life has an embedded proteins from different species into the same low dimension space. So later We can transfer biomedical experiment results such as drug effectiveness, drug side effects, from other prod- other species to human. This process creates a very unique heterogeneous network data set including more than 60,000 solvent nodes and more than 300 solvent labels. Here are the results of our method the x-axis represents classes in different categories based on how many training samples appear for each class. The blue one is our method, we can see a significant improvement in comparison to other approaches. Especially for those functions with very few training samples. The improvement of our method comes from using the hierarchy to classify proteins into function with very few training samples. In addition to these exciting results, our method has been used by NIH big data to knowledge Center and the Mayo Clinic. Our method in this pipeline is an important building block for cancer research conducted by doctors in Mayo Clinic. This is how we use class hierarchy to classify samples into never-before-seen classes in biomedicine. First we cannot back to apply a zero shot learning in biomedicine using class embeddings generated from class hierarchies. For biologists they can now make prediction tasks with no training samples such as new drug, new genes, new diseases. Computer scientists they can use the embedding from 227 hierarchies to investigate new zero shot learning method, new zero shot learning tasks in biomedicine. We have just finished talking about first two part, now we can classify samples into never-before-seen classes. The next question is how can we interpret these predictions? So how to interpret the prediction of a never-before-seen class. Many existing methods and an interpretable feature many existing methods find in comfortable features within this data set. For example, Glioblastoma is one of the most aggressive cancer with average survival time of only three months. From this glioblastoma patient cohort, we found that we can find that which genes are interpretable for cancer survival and we may find out that these seven genes are interpretable. But use this information now, this is information that were helpful, but we might want to know a little bit more. That is why these genes are interpretable. Can we interpret these interpretations? This kind of why question is actually the key question science. They are the new knowledge scientists want to know. Especially when interpreting something we have never seen before. So how shall we answer this question? Well, let's look at this character string, these characters can interpret my talk and they are the most representative information my of my talk. But can you understand this search stream? You may not even know how to read this string. Why? Because the structural information is missing here. There's no space, no punctuation. In biology it is a sin. Even if we found out that these seven genes are interpreted - interpretable, we still don't know why they cause glioblastoma. In fact many biologists, they must spend their whole life just studying one single gene. So it is very challenging for anyone to know why these seven genes cause glioblastoma. To understand the character string, we need to know the structure at different levels like word, clause, sentence, paragraph. We cannot understand a document by only reading a character stream. In biology, it is the same. To understand why these genes are interpretable in diseases, We need to know the information between gene and diseases and in biology we call them scales. Our biomedical work translates from nanometer scale genes to micrometer scale cells to minimeters scale tissues and finally to the disease. We observe on centimeter scale organism. Now the challenge is that we only observe gene scale information and disease scale information. How can we identify the scales between them? It is likely you are reading a book now and this book is only written in characters without any space, without any space, and any punctuation. How could you understand this book? Going back to this example, some of you might be able to understand this character string without any punctuation and space. It is actually the title of my talk, learning for never-before-seen biomedicine. In fact, If you can understand the sentence without space and the punctuation You are using the multiscale knowledge graph in your brain you infer that Learning should be a word never before seen shall be a high level phrases. It's a combined freeze, a high level structure and this whole stream should be a sentence. The same in biology. We need a such external knowledge graph to help us groups these genes into three modules, cells and tissues, but we don't have such modest scale knowledge graph in biomedicine. Our contribution is to build the first ever multi scale knowledge graph in biomedicine, it integrates millions of scientific papers and biomedical database records. There are many other knowledge graph. The main novelty of our knowledge graph is the multi scale structure. We have a very unique module called multi scale gene modules. Each gene module is a set of genes that work together in the biological system and these multiscale modules connect gene to diseases at modesty. We found 27,000 normal gene module from literature so our knowledge path can be updated all the time with new literature. By using this knowledge graph, we can know understand why these genes are interpretable. Let's review this example; the glioblastoma. Here in the terminal model tells you that these seven genes are interpretable, but you don't know why they are interpretable. We can answer this question by searching these seven genes and a glioblastoma In our knowledge graph and then extract a sub graph. We can send know that for example GCS cube tree is important because it inhibit egfr signaling pathway and then cause glioblastoma. Each edge here is linked to an external evidence. It could either be a database record or a scientific paper abstract which mentioned our two notes sharing dispatch. We evaluate the performance of using our knowledge graph on several different prediction tasks such as predicting function give a set of genes or predicting associated genes for disease. We found that integrating biological database and the scientific literature can do much better on these seven tests. They're only using scientific literature. For example in gene function prediction test, our method of 50 percentage improvement. One important principle in my research is to build web servers, not just github wrapper. So that people who has no programming experience can easily access our method and the data set. So I call myself full stack biological computer scientist. We had a web server for this project as well. User, user can parry any number of genes drugs GMO dose diseases and we will then return a multiscale evidence subgraph for user and provide evidence from either literature or biological databases. Our method has also been used by hundreds of scientists in NIH center, we are currently incorporating the system into existence so our method and knowledge path would be used by more people in the future. We have also done some found some other words in text mining to support information extraction of noisy text. For example in this on life health or impulse post these user mentions multiple drug side effects from different drugs. So side effect from different drugs are missed together Even this user doesn't know which side effect come from which drug. How can we figure out? We use a probabilistic topic model to model loss of text data jointly. And we then optimize this model using EMR wisdom to find which side effect is associated with which drug. Our method has been used by doctors to analyze 300 thousand patient records from six hospital. So this is the last part of my talk. I introduced how a multi scale knowledge graph had helped us better understand biological discovery. For biologists, they can now obtain up to date and the multiscale evidence to interpret their discovery. So computer scientists, we provide a new multiscale knowledge graph data sets for medicine identification in biomedicine Well, let's summarize my talk and my previous research. Using our representation method we can now provide personalized cancer treatment for 6000 patients. Our method has been used by Mayo Clinic and NIH KnowEng Center to identify drug mechanism. These methods are recognized by AMIA Year in Review award and a few other dream challenges award. We also introduced a new biomedical data set of machine learning researchers to study zero shot learning in biomedicine. In the classification part, we talk about two important problems protein function prediction, and cell type prediction. Our method has been used in has been used by Chan Zuckerberg bio hub to predict cell types in one of the largest data set in the world. We successfully accelerate the pipeline from three months to 20 minutes. And we are currently Applying applying our method to rare disease detection for California newborn screening program. In the interpretation part we introduced the first-ever multi-scaled knowledge graph, our knowledge graph has been used by 200 scientists in NIH NCATS, Another text mining method has been used used by doctors to analyze electronic medical records of 300,000 patients from six hospitals. These three steps together representation classification and the interpretation build up a comprehensive framework and let her study biomedicine from no labels to new knowledge and The most exciting thing that it gives a general computational solution to many different biomedical problems like cancer survival analysis, single-cell prediction, protein function prediction, drug side effects prediction and electronic medical record analysis. Next, I'm going to talk about some future works future competition biology problems in Representation classification and interpretation. Today, I'm going to talk about visuals in more broad computer science areas. The first problem is how we can do high order zero shot learning. High order prediction means predicting the effect of combinations. For example predicting synergistic effect of trial combination intensive treatment. This problem could be more challenging if we only held training data or low order single drug And we don't have any training data for high order combination like two drugs. So it is a high order zero shot learning. I see the key solution to this problem is how to represent key items jointly, how to represent one job to drug three drugs so that they are comparable in the low dimension space. The second important huge work is to do transfer learning across populations. So most of our biological datasets are collected from certain population. For example, UK Biobank is the most widely is the most widely used and loved by compiled people like us However, more than 19 percentage of patients are Europeans. So machine learning model tree now this dataset cannot be generalized well to other ethnic groups. How can we develop effective transfer learning algorithm so that we can generalize our machine learning model to understudied populations The [INAUDIBLE] eruption is a more broad one. Can we better use real people in power medicine? Right now NLP biology mostly focus on analyzing text data in biomedicine like scientific papers or clinical notes. But soon it will be more exciting to directly integrate biological data into the NLP model So one interesting example would be how can we automatically generate analogy from common sense. By allowing biotext data and adds other text data Can we infer that if human is like a city of single cells like a building then protein is like a bricks or carpets or windows. Many other CS areas are also very important in never-before-seen bad medicine. So to elaborate some of them I would like to use data collection as the example. We are a few challenges, There are few challenges in biomedical data collection. I summarized them as how to generate the data, how to collect data, and how to share the data. So to generate the data in biomedicine, we need to three bench scientists from tedious lab work, especially this common I think they can not do anything without going to the lab. Can we build a robots for them or can we use computational design to help them work more efficiently? To collect data, we need to encourage people to participate in tests. Maybe they fear negative results. They may even lie to doctor about some very sensitive information whether they are smoking or drinking alcohol. So, how can we use HCI and ubiquitous computing to encourage them participating tests and support them? Finally, to share the data. We need to have secured method and scalable data based approaches to support data sharing in biomedicine. [Audio cuts out] Thank you, this is all I want to talk today; how to represent classified and then interpret never-before-seen biomedicine and by doing these three steps, we build a general competition approach to different biomedical problems and this solution enables us to transfer from no labels to new knowledge. Finally I would like to thank all of my collaborators. I'm also looking for more computer science collaborators to help me, help us, help every patient, help average human beings advanced biomedicine. Thank you, and I'm happy to take questions. Su-In Lee: Okay (laughs) Okay, all right, so Yeah, thank you for the great talk really liked your talk, I have many questions, but I want to see what other people have in mind. I know that Magda was going to ask a question during the talk, it was somehow missed. Magda Balazinska: You know, thank you so yeah thank you for the great contest is really interesting work. I was - I just had a clarifying question for the first part of the talk. So the most important component of that first part is that you need to have a hierarchical ontology but it seems like there's an assumption that in order to get good results that ontology, that hierarchy has to be sufficiently detailed. Sheng Wang: Yeah Magda Balazinska: Right, so what like how detailed is sufficiently detailed or how do you know that the you know.. it's a good enough hierarchy and also there seems to be an assumption that there's an expert or someone who knows how to match the new entities somehow into that hierarchy. So how do you make sure that this can be done? So that's my two-part question. Sheng Wang: So the first question is the hierarchy need to be very detailed, right? The second question is how to make sure the expert hot... What's the second question? Can you say that again? Magda Balazinska: So how do you know if you have a new that's a new kind of disease like Coronavirus, that you can actually match it correctly map it in the right place in the hierarchy. Sheng Wang: So first of all, I think this I think first of all, so first of all whether we need a very detailed hierarchy depends on whether we need very detailed prediction. If we want to predict it we so those kind of hierarchy they have this kind of from general to specific structure if we just say we want to predict if this patient has coronavirus then we don't need a very detailed hierarchies, just up here and then later when human or some experts we want to classify coronavirus into alpha coronavirus and the beta coronavirus is classically split into different categories that our machine learning model can also further learn whether this specific coronavirus patient should belong to alpha or beta coronavirus. So machinery model can be updated with its hierarchy and if the expert you stop here with no with no deeper layer here. We also cannot predict for the for the remaining for the beta coronavirus and alpha coronavirus. Yeah This is the answer for the first question that we really want to do that we can use some text man, text mining method to expand the hierarchy. So for the same question, how to add a, how to add a note to the hierarchy, actually this does not require a very strong expertise. I think some maybe some very simple guess some very simple prior knowledge can be used here. We don't expect this hierarchy to be perfect Actually, this hierarchy is also very noisy and that's why we need to do embedding here. So for example coronavirus maybe the expert will just add the coronavirus, add COVID-19 here. I think this is very easy to do and then if there's some mistake that is not incorrect, COVID-19 shall be added to alpha coronavirus, we can use data you saw a machine learning model to correct it so I think it will be a syergistic effect I thought it would be a combination combination sauce from expertise human knowledge and the data. So I think they would help us synergistically address this question. Yeah. Magda Balazinska: Okay. Thank you. Su-In Lee: OK, next is Georg. Audience Member: Yeah, very a very impressive work, very nice talk. I had a question about this single cell analysis and I was just curious there. So in your example, we say you train on about 100 cell types and then you essentially annotate no 2,000 or so clusters, is the output of your annotation the actual name of a putative cell type based on the ontology and is this primarily based on similarity of gene expression patterns between something you've seen and something you've not seen yet Sheng Wang: Yeah, it's primarily based on gene expression pattern, for example here in this example. Let's say we see cell type of B cell type of D, BD here. We don't see AC here here Yeah We can still predict a cell to cell type E if the cell type with we can still classify a cell in the cell type E if that cell is very similar to cells if that cell's expression is similar to cells in cell type B. But this similar not similar to cell type B. So we still use gene expression to assess feature to measure similarity. So we have node BD We want to predict E, we will say if something is similar to B but not similar to D, it shall be here because E is closer to B but more far away from D. This is based on gene expression. Su-In Lee: Okay, so I have a question. So maybe oh, you know when I come suggestion, so you know if we know the single cell type prediction problem is currently the most important problem in biology So something like [INAUDIBLE]. Yeah, so and then well, I can see [INAUDIBLE] agree with that. So so it's a future direction. I would, you know, combine the interpretation approach you presented in the third part of the talk um with the classification method you're presenting the second part. So that you can use both of gene expression data and this knowledge graph so that you can better, you know, predict the cell type, is that something, have you thought about that? Sheng Wang: Yes, I think that sure we can do that. So what we are doing I think well I see we can do it him I think well, I see we can do it in both ways. But first we can use knowledge graph trying to find some for example knowledge part from the literature literature tell us cell type E is related to gene A is related to gene 1 gene 2 but we have never seen cell type E in your data set so we can use those knowledge graph Information as a future markers to help us cart like cell type E so we can use knowledge graph to tell us those kind of never before seen cell types, which genes are related to that. This is from one direction. And I think we can also do it all for the other direction. That is if our model tells us that so actually we design our paper after we treat our model we can find a gene markers for every cell type here, and then we can use them to supplants, to supplement human knowledge So people later they can use so this will be from model to human knowledge when we know some new markers for those things people later can use them to their classification. They don't even need to run our model. So actually this result, so this result is what we get, we found some G markers for cell types we had never seen before and the human used those genes to classify cells. They didn't even run our model. They til, they didn't even need to do zero graph learning or run our model. They just base off, which tells them that this gene is overexpressed and what we cell types what we did we tell them this information. They do the classification. So I think it's a five direction problem, not only use knowledge graph to update node but our model will also generate a lot of knowledge for human. Su-In Lee: Thank you, any more questions from the audience? Audience Member: I have a question about the single cell part, we are show the highest the cell hierarchy so if you if the seen data include cell type B, D, and E is it still possible to predict an unseen data type cell type as cell type C or others that you don't have at all like it's not even on the same branch of hierarchy, is that possible? Sheng Wang: Yeah, that will be very difficult. So for example, let me say in this way, if we know ABC, if we seen ABC but we have never seen D and E. Then our method cannot distinguish from D and E because they are identical topological situation in this hierarchy, if we know ABC when we cannot distinguish DE. Going back to your question and we know BDE, we can somehow still guess whether it's A or C because A is pretty close to BDE. Or C is very far away from BDE. There are being our low dimensional embedding, for example here, We have BDE we have BDE here. Maybe CA is quite a close to them also we haven't known we haven't see it and C is very far away so we can still somehow try to classify them, again it's also depends on the distribution of cell types on the cell cell type hierarchy. Audience Member: Thank you Su-In Lee: Okay, I don't see any more hands or questions in the chat, are you sure? Okay, great, thank you. Thank you for the talk. Thank you. Thank you everyone here. Sheng Wang: Thank you everyone 