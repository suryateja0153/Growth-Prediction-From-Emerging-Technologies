 (upbeat music) - Hello everyone. My name is Marco Pavone and today I will be discussing my work on interactional work decision-making. Before starting I would like to thank the organizers of these workshop My lab, the Autonomous Systems Lab focuses on the design or the planning and decision-making algorithms for autonomous travels. It is on the design or the techniques that allow robots to make decisions on their own. A key focus of our research is on designing techniques that allows robot to interact with the humans in a safe and efficient manner. For example, let's consider the case of autonomous driving which is a typical task that requires complex interactions with other humans. In this example, which entails vehicles merging on the road. We see that the overall goal of everyone on the road is it clear to everyone, but the outcome of the interaction is very unclear and it really depends on the complex and often aggressive negotiation. Well in general, merging into traffic and driving entails an exercise in negotiation. And the robots should be able to perform such negotiations for safe and efficient drive. Alternatively, as I like to say, robots should be able to perform a proactive decision-making. That is they should be able to proactively interact with other agents in order to infer the intents, while concurrently exploiting this information to take actions that account for agent responses. My approach to this problem is model-based whereby a probabilistic understanding of the interaction dynamics is used as a basis for policy construction. This is different from a model three approaches whereby human actions and responses and the relative likelihoods are only implicitly encoded into a policy that is learned directly from data and the rationale for this the cabin between a human intent prediction and the decision making is to achieve a level of transparency that is difficult to achieve in a model free approach. Now in the model-based approach, the first task is the task of intent prediction or must be more specifically orbit trajectory forecasting. And this will be the focus of the first part of our story. My work in the context of a trajectory forecasting is motivated by five key considerations. First of all, from the perspective of decision-making we're interested in predicting human behaviors, conditional on that is in response to possible candidate robot actions. Second, we are targeting action and reaction responses at the timescale in the order of about one second. This is different from traditional high-level decision-making that reasons in terms of multi-second on the macro actions. And this is also different from low level collision avoidance control that typically has to run at 11th Avenue mid seconds. Third at, after this timescale human behavior is typically multi model. What I mean by that is, let's consider for example the case of lane changing. So here we have a robotic vehicle depicted in a green that wants to change lane. So it's the first traffic weaving scenario. So in order to capture the intentional interraction what the robbots want to understand is whether if the robbots were accelerate, what will be the possible responses of the human driven vehicle? Well, in this case, we will see that most likely the human vehicle will decelerate, but the human vehicle might display an aggressive behavior, and it might actually accelerate And this corresponds to two different modes. That's what I refer to as multimodal behavior or alternatively, in this case if the robot were to decelerate, then again the human might display two different modes. The first one corresponding to acceleration and the second one corresponding to deceleration. The key point is that at this time scale human behavior is typically much model and the trajectory forecasting should account for such a multi modality. For consideration, We want to consider an intent prediction model that accounts for history. This is in order to uncover latent behaviors such as alertness or aggressiveness. And finally we will like to have a intense prediction model that is as interpretable as possible in order to ease the bagging. And in order to increase the level of confidence in such a technology. Now a difficult approach to intent prediction, which I refer to as ontological or theory of mind postulates some structure on the human decision making process. For example, in terms of a cost function that a human is trying to optimize. This is the typical approach for example, of inverse reinforcement learning. Now, a human in general is neither competitive nor adversarial is such a fattiness of behavior, it's difficult to reconcile with a theory of mind approach that ultimately is rooted in gateway. So in my lab, in the past couple of years we have been investigating phenomenological approaches. The idea of a phenomenological approach is to directly learn the probabilistic structure of an interaction without reasoning about the underlying motivations. That is without reasoning on how humans makes his or her own decisions. To do that, we have the leverage of techniques from generative modeling. Now there's been a lot of exciting work recently on generative models. What our work differs from the norm is that we not only want to predict the future based on the past observation, but also we want to listen contingent on what an autonomous system might do in the future. Specifically, we want to learn a probability distribution P that allow us to predict the future action of a human subscript H stands for human. We're assuming that we're at time T, so T plus one is the next time step. And we want to learn such a probability distribution condition on the history of interaction externals the relative states, for example, relative positions or relative velocities, and U denotes the past controls by the human or by the robot. And critically we also condition on a candidate future covert action. Conditioning on the past allow us to uncover latent behavior such as alertness or aggressivity. And the conditioning on the future allows us to capture the interactive aspect of an interaction. Practically in order to learn such a distribution, we use a conditioner variation out encoder model. The way we use this model is as follows. Let's consider again the previous traffic weaving scenario where we have a robotic vehicle that is trying to exchange lane with a human driven vehicle. In these plots on the X-axis I'm showing time, and on the Y axis, I'm showing the longitudinal acceleration. A solid line means something that has happened in the past, where dash means the future. Specifically here we're seeing that in the past half a second or so, the longitudinal acceleration of the robot depicted in blue and the longitudinal acceleration of the human depicted in red, is zero. Which means that both the robot and the human driven vehicle were going at the at constant speed. Now, the way that we use this model is as follows. If the robot were to enact as a candidate action sequence, an acceleration, then a costing profile, and then at deceleration. What will be the reaction from the human? And in order to answer this question, we sample that generative model that we have learned from data. So in this case, you'll see that a bunch of samples will predict that the human would decelerate while a few samples, so few particularly trajectories would imply that the human perhaps because the human is aggressive in this case would accelerate. And here also we see how these models can capture the multi modality aspect that I was referring before. So how do we use such a prediction model for the purposes of control and decision-making? In actuality considering the case of a traffic weaving, we considered about 4,000 action sequences that is motion primitives. For example, emotional primitives might say that we go straight or we make a sharp turn and so on and so forth. For each motion primitive we generated distribution of the possible responses by sampling from the generative model that we have here which again, is based on a condition of variation out and call. In actuality we sample about 100,000 human responses per computation cycle. And by leveraging technique, by leveraging a GPU's, of course this sampling procedure is highly parallelizable. We can compute decisions at about three, four Hertz which from the perspective of a high level decision-making is good enough. In particular for each motion primitive we sample a bunch of possible human responses. We score each motion primitive according to some aggregate costs function that combines task fulfillment with a penalty for collision avoidance and a few additional terms. And then we score, we record, the motion primitive that scores the best. We drive the first chunk of it, and then we re plan in a fashion. Now critically, in order to score emotional primitive we consider an expectation of the data. So basically we look at average performance, an interesting question is that since we have a distribution of information about the human responses will be, how do you account for risk? That is in order to score emotional primitive, how do we replace average performance with the sum risk measure, that accounts for what may happen in the tail of the distribution, for example, to account for particularly bad behavior that a human mind exhibits. Now, the topic on the how to account for risk in a decision making context, that is a fascinating one. And I don't have time to go into the details in this presentation but if you're interested, I will refer you to a paper that I co authored with a former postdoc in my lab Aniridia Majumdar, now a professor at Princeton. Which it can be viewed as a sort of a position paper on how we think about modern risk from a robotics perspective. [Inaudible] to show some a human the loop simulation to showcase how this controlled pipeline works. The simulation side of human in the loop in that there is a human that is driving the blue vehicle. So there's the human driven vehicle that was also depicted in the previous figure. And then the robotic vehicle the white vehicle drives by using the prediction the intent prediction algorithms and the decision-making algorithms that I have just explained. And data is collected by using the same driving simulator by having two humans driving side by side, on a variety of interactive scenarios such as traffic weaving as we discussed but also negotiating intersections and so on and so forth. So here on the left-hand side we see predictions in terms of the longitudinal velocity and the longitudinal acceleration for a specific motion primitives. As you see, you have a bunch of other possible trajectories corresponding to the many possible ways that a human might react to a candidate robot action. And in the simulation you saw there were some interesting behaviors that emerge. Like for example, the white vehicle, the robotic vehicle nudging a little bit on the other lane in order to probing the intent of the human. So the behavior is quite natural and quite efficient and safe. This is great until disaster happens. So here, I'm showing a case whereby the human the blue vehicle behaves in a way that defies the prediction of the intent prediction module and the crushes into the robotic vehicle. So this is bad, but I would argue that in some ways is unavoidable, for three main reasons. First of all, the intent prediction module that I have just presented is a probabilistic prediction approach. And probabilistic prediction sometimes might get it wrong. This is the same for humans. Of course, we make predictions about other agents around us those predictions are probabilistic, and sometimes we may get it wrong. Second, and another critical reason why sometimes we might have very undesirable behaviors is that at this level of a decision-making collision avoidance is typically included as a penalty function in an aggregate cost function that includes many other terms And this may cause a conflict in objectives. And finally, as I said before, we can plan at about three four Hertz with this methodology which ultimately is a too slow to ensure safety. So the key question is how do we integrate a probabilistic decision-making module that is targeting efficiency with a lower level control module that tries to promote safety in a way that does not unduly impact performance. So we've done quite a bit of work in order to address this question. And the key idea is to use techniques from backward disability in order to reason in terms of interaction at the lower level of the control hierarchy. Specifically the way that our full decision-making control stack works is exposed. The interaction planners so the decision-making models that produces predictions, according to our condition variation out encoder prediction model produces a desired trajectory. In parallel, we have a Reachability cache that is computed offline that captures the notion of a unsafe sets. It is sets of tentative states, that might lead to collisions despite our best efforts. For example, in this picture here, the red vehicle is a robotic vehicle and this site would present the unsafe set. We don't want the other vehicles to enter the sets because of the why's, no matter what we do there might be an action for the human driven vehicle that might lead to a collision. And then we integrate the Reachability cache, that reasons about interaction in a worst case sense with the probabilistic interaction planner, that the reasons about the interaction in probabilistic sense through trajectory tracking module that produces actions that they minimally deviate from the desired trajectory from interaction planner in order to comply with the constraints that stem from the eligibility cache. In other words, as soon as another vehicle enters the unsafe set, the tracking controller corrects the trajectory in order to take the vehicle the robotic vehicle outside of the unsafe set. The trajectory controller is a based on mobility control and it runs at about 100 Hertz. And we have tested that the full decision-making control stack on the full driving [inaudible]cars showing that actually we can seamlessly integrate higher probabilistic decision making aimed at promoting efficiency. We did low level control routine eligibility theory aimed at ensuring safety. Now in the past year we have been extending these methodologies along three main lines. First of all, so far have been talking about the pairwise interactions. That is interactions between a robotic vehicle and the human driven vehicle. We have been extending the the Montessori account for multiple agents possibly belonging to different semantic classes such as pedestrians, other vehicles, trucks and so on and so forth. A second direction, is how do we produce representations for intent prediction that our data better tolerate to downstream controller applications. And finally, we've been working on how to better integrate prediction with perception in order to account for examples for the uncertainty that stems from the perception model. Let me start with our work on generalizing our CVAE based prediction approach to multiple agents. Specifically we have been working on enlarging our model in order to condition predictions on a vast set of heterogenous data. In particular now we can produce predictions for human intent, that account for dynamical information. That is account for the fact that the dynamics of the pedestrians of course are very different from the dynamics of a car. And also all the way to accounting for map information as encoded by a map in encoder, capturing for example information such as a crosswalk or road boundaries. The overall methodology we referred to as a Trajectron plus plus, all the code is available on our data. And it does solid, actually incorporating heterogenous data in terms of a dynamical information and map information is extremely important for intent prediction . And perhaps surprisingly is oftentimes overlooked by other intent protection work. Specifically to make this point clear, I'm showing here at the bottom, experiments on using the new scene data sets in order to predict future trajectories of the number of agents on the road, for example, vehicles, pedestrians and so on and so forth. In the last panel, I show the predictions based on our base model. It is a model that only account for the external part interaction in terms of relative states and relative a control actions, but does not account for dynamical information, nor does it account for map informations, for example, capturing that geometry of the same. So here we see in the context of a predicting the future trajectory of this red car, that our prediction actually under shoots the ground-truth, depicted by the white car. In the center panel, we now consider the case where we augment the base model with whatever it was referring to before the conditioning on dynamical information. It is conditioning on the fact that actually the vehicle is a car, which is in our case model as a dynamicaly extended to this model. So here we see that in this case the intent prediction produces as outputs two different modes. One that predicts the red vehicle making a right turn and the other modes that predicts the vehicle going straight. Finally, in the right panel we augmented the base model by accounting both for dynamic information as well for my prediction. Now we see that the model further corrects the prediction which now lies almost perfectly on the ground. Second aspect, as I mentioned before, we're working on is how do we find the representations for intent prediction that are more conducive to decision-making. More specifically, typically the output of intent prediction model is represented by individual trajectories for the agents in the scene. And this is a very natural prediction pattern. But unfortunately it's quite difficult to work with from the perspective of decision-making. As we saw before, in order to compute actions, by considering a distribution of a possible future individualized trajectories from the other agents, we had to perform a fairly brute force approach whereby for each motion primitive, we produce a bunch of samples. We score them according to an aggregate cost function. It's okay, but it's very brute force. So the question here is how do we reason about prediction representation that are more cognizant or the downstream control applications. As far as I'm concerned, interesting trajectory forecasting insofar it improves decision making for the autonomous car. Having said that we have been considering system theoretic representation of future intent by modeling future trajectories through, either a linear time variant system. It is the output of the trajectory forecasting module is a set of a matrices AT, VT and CT which model the interactive structure of a scene. Specifically the trajectory forecasting model learns the off diagonal elements of the system matrices which capture agent-agent interactions, as well as the fact of one agent on the ego robot. So we learn all the green blocks, we do not learn the diagonal blocks because these diagonal blocks represent the agent dynamics which we assume are not. For example, the case of the ego vehicle will be the dynamics of the car. Just to be more specific. In this example, here is a scene with the three agents. We have the robotic vehicle and one human operated vehicle and one pedestrian. So this translates into a system matrix that is partitioned according to a three by three block. And we also account for since we're interested in control, we also model the robot action that allows the robot to reason about it's future impact on the obvious control actions on the other agents. Now, the key points here is that if we learn this representation of future trajectories, then these are this representation is much more amenable to control because it can be readily embedded in a variety of control pipelines, such as the stochastic NBC. This is work that is in preparation and we plan to publish it in a month or so. Finally, and a complimentary to what I have discussed so far is how do we integrate more tightly trajectory for casting with the perception? For example. So one we're looking at this problem through two main directions. The first direction includes reasoning about explicitly about the uncertainty that stands from the perception model. For example, here, we see that objects that are far away are much more difficult to detect and classify. And in this image, you can see that each object comes with a classification score. So we're working on how to account for such a classification score in trajectory forecasting process or in equivalent terms how we are working on how to propagate the uncertainty from the perception model all the way to the projected forecasting model. Related to this perception of course is also quite noisy. For example, in this video you'll see how the yellow vehicle has a classification that switches at a very high frequency between being a truck and being a car. So we're working on techniques to make trajectory forecasting robust, to noise, distance from a perception in particular, in terms of frequent class. To sum up, I have presented our work on generative models for a trajectory forecasting. And I will claim that in general generating models that is phenomenological models are becoming the state-of-the-art tool for trajectory prediction. And then we have a survey paper on the JV models for trajectory prediction that is coming out soon. So if you're interested, check out my webpage in a month or so But as I mentioned, integrating generative models in the autonomy's tech, it is integrating generative models with downstream decision-making logic and with upstream perception model is in general quite challenging. So right now we are working primarily on how to find principle ways to integrate generative models with the other components of the autonomy's tech in particular, in terms of reasoning about prediction representation that are cognizant of downstream control application through a system theoretic formalism. And two, maintains to tightly integrate perception and trajectory prediction in order to account for the uncertainty and noise that comes from perception. All of our code is available on my lab data. And I would like to thank my collaborators, in particular most of this work has been done by Karen Boris and my former student, and who is now at (inaudible) If you have any questions, feel free to send me an email and ensure you also have the rest of my contacts. Thank you very much for your attention. And I hope to see you all soon in person at some other hour later. Thank you. (upbeat music) 