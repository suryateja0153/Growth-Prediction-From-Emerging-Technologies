 Image inpainting, meaning to fill the missing parts of an image is a vital process in various visual editing tasks in this digital era Like the given examples we can employ it to conduct object removal, adjust image contents Traditionally, it relies on the exemplar-based method to recompose the image with similar patches from adjacent parts while it may not fit the complex requirements of rich media nowadays With the advancement in artificial intelligence and deep learning techniques our research group applies an emerging method the generative adversarial networks, into the inpainting process The basic idea of the generative adversarial networks is to train two neural nets a generator and a discriminator to compete with each other and improve their effectiveness The generator needs to convert the input conditions like partial images here to the realistic one while the discriminator is trained to distinguish whether the image is genuine from the real world or painted by the generator This competition-like training encourages the generator to produce visually-appealing images with high-realism Combining the generative adversarial networks with prior knowledge of image inpainting and other editing techniques we can achieve impressive visual manipulations Such as removal of objects, text, graffiti and raindrops and face, scene, facade editing On the other hand, we can extend the image boundary based on its semantics and even reconstruct the whole face or body from a small portion of the image With different input regions, we can picture different possible outcomes This technique can help to convert the input image into different screen ratios naturally Apart from the photo editing works some media companies have been introducing the generative adversarial networks to improve the resolution and the quality of some old videos and even create the virtual fashion models What’s more? It will be your turn to discover 