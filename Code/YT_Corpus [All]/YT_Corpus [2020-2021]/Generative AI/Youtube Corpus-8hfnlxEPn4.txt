 Good morning everybody. In most of my videos so far I've been discussing GANs which can generate images. Although generating images is really awesome GANs have applications far beyond just that. Today I'd like to talk about how GANs can be applied to the translation of images. Specifically I'll be talking about CycleGAN and how it's able to translate images of one kind to another without needing pairs of images. In some cases like the one you're seeing here images can be split up into two distinct domains. Here the domains are satellite images and map images. Let's say we wanted to make an AI which translates satellite images into map images. The simplest approach would be relatively straightforward; we could simply train an autoencoder to translate the photo, then compare the translated photo to its actual pair. The autoencoder would use some convolution blocks, down sampling the image a few times then up sampling a few times to return the image to its original size. The reason for the down sampling and up sampling is to compress features which might be far apart spatially but are related in the image. The auto encoder is a key concept in image to image translation and is used in CycleGAN as well. It is, on its own, far from the best in terms of paired translation, but is a relatively simple solution nonetheless. If you want to look more into paired image to image translation, here's some solutions you could look into which are outside of the scope of this video. Links to the papers will be below. In some other cases all we have in terms of data is two data sets which don't overlap at all. For example it would be incredibly difficult to obtain pairs of horse and zebra images, as it's very rare for the layout of these pairs to be the exact same. We'll need a solution which is somewhat more complex than just an autoencoder to train our AI. This is where a CycleGAN comes in. CycleGAN is an architecture introduced in 2017 designed specifically to perform image to image translation on unpaired sets of images. The architecture uses two generators as well as a discriminator. The two generators are often variations of autoencoders and they take an image as input and return an image as output. The discriminator however takes an image as input and outputs one single number. The CycleGAN has two objectives for its main generator, generator one. The first is to ensure the translated image looks like it is in fact a zebra. This is trained into the generator using a generative adversarial network architecture or GAN for short. Here the discriminator and generator train adversarially. The discriminators goal is to classify whether an image is a real zebra or a fake zebra made up by the generator. The generator training alongside the discriminator tries to make images which fool the discriminator into thinking they're real. Thus, the generator must learn to make convincing looking images of zebras. If we were to only use this objective however the generator would still not be useful. Nothing would be stopping the generator from disregarding the content of the original image and making the final image whatever it thought would fool the discriminator best. Thus the second objective of our CycleGAN should be to ensure that the translated image still looks like the original in some way. We can do this using the cycle consistency loss and a second generator model. The two generators work together in this loss. The first generator translates the image however it feels necessary then the second generator learns alongside to translate the image back to the original. Both generators are penalized for any differences between the original image and the image that's been through both generators. This ensures that the main generator doesn't completely disregard its input and using the second generator allows for flexibility in that translation process. So those are the main concepts behind CycleGAN. If you'd like to see it implemented in Python and TensorFlow 2.0 my implementation will be linked in the description. If you enjoyed this video I recommend liking it and checking out some of my other videos. Thanks for watching! 