 - Hey, everyone, welcome back to this interview series. I'm delighted to have with us Quoc Le, who is a researcher at Google Brain. I had the pleasure of working with him at Stanford university many years ago and Quoc Le and I were chatting just now. Fun fact Qouc was the very first intern that I had recruited into Google Brain when I was leading it back in the early days. Jiquan Ngiam was the second intern that ever recruited into Google Brain. And I think Jeff Hinton was the third intern I ever recruited. So I think Quoc was in good company. Since then, Quoc has done some of the most influential work in NLP and I'm delighted to have him here today to tell us about some of his experiences. Thanks for joining us Quoc. - Yeah. Thank you, Andrew, for having me in the interview series and it's a pleasure to be here talking to you. - So today you Quoc are known widely as one of the most influential NLP and Deep Learning researchers and your journey has been a complicated one. I think you had started off going to school in Vietnam and then went to Australia, and then Germany, and then now the United States. So tell, tell, tell us more about your journey getting into AI. - Oh yeah. So when I was a high school student, I was fascinated by AI, and I ended up reading a lot of books and even programmed some simple, you know, AI programs. And then I got a scholarship from Australia for my undergrad, in the Australian, Australian National University. And in my second year of my undergrad I got a little bit bored. And I said, you know, maybe I should do something research in AI because, it seems like the faculty there, they had some very, amazing faculties, so I contacted Alex Mola, who actually took me as an intern for a summer. And I work on coding methods with him. And that's the, I think that's, even though I did some AI you know, projects before that, that's the first time that I actually learned about machine learning and I became super fascinated about machine learning and I realized the potential of doing machine learning and learning for AI. - Wait, wait, back up a bit. I don't think I knew this story. What was the AI project you were coding up in high school that got you a scholarship to, to Australia National University? - I didn't get a scholarship to Australia because of the AI program, but I programmed it myself to learn more about AI and so on. I was building like a chatbot, you know like a rule based system to actually talk to myself, right? And, you know, try to randomize the answer and so on. Try to see how I can fool my friends. Because I'd read about the Turing test and so on, and I was fascinated about it. But I didn't win the scholarship because of that program. It was too simple for it. But I, you know, I, because when I program it I know how hard it is to write a computer program to do, to actually be intelligent. - I think it's really cool that you started out that way, because I think if there's someone listening to this interview series now, that is coding up, you know, some slightly broken chatbot that kind of works, doesn't work and finds it hard, right? They may be taking their first steps to an illustrious career in AI, much like you were once, coding like, you know, a so-so chatbot. I'm finding this finally that we all start from, you know, programs that don't quite work, as well as we wish, but that could be a wonderful start to something. - Actually, much later. And, many years, many, many years later I actually had a conversation with you in terms of, you also did something like this as well, in the past. But I was fascinated. I was always fascinated about, you know, if you ever do an AI program can I talk to it, right, can I, can I talk to the program and hear about what it thinks? But anyway, we're going back to the journey. I did my summer project with, with Alex Mola on coding methods, machine learning. And I realized the potential of using machine learning to do AI. And then, and then after that, I graduated from, you know, I kept on doing research with him for a while. And then after I graduated, he has a friend in Germany, and I went to Germany, you know, Bernhard Schölkopf, hosted me in Germany. And when I was in Germany, I was also doing machine learning research and near the machine learning research, there's like a neuroscience center that they were trying to think about, trying to understand the Brain and so on. So I became very fascinated about that as well. And then I listened to one of your talks at NeurIPS, that year that you were talking about using machine learning for AI. And I, by the way, at that point in time, most people think about machine learning as open recognition, just doing machine learning for machine learning, like trying to classify things. But when I heard about machine learning to do AI, It really resonated with me. So I applied to the Stanford PhD program to to do the PhD. And then, you know, I ended up going to Stanford and then doing the PhD program, the, initially a degree with you. So that's around 2007. And then around 2010, 2011, you, you told me that you were founding and creating a project at Google to scale up Deep Learning Research and make Deep Learning, you know, like 100 or 1,000 times bigger. When I heard about it, I say, "Oh yeah, that must be the future". Because of the neural nets I've trained. Like, no matter what I did, the only thing that make a big difference is giving it more data and more compute. So it really resonated with me. - You thought, I'm glad you thought it's the future, a lot of my friends at the time were telling me it was a terrible idea to do this. To do this crazy Google Brain thing, so, I'm so glad you thought it was reasonable. But actually I think you and I, we had the privilege at Stanford of seeing some of the early results that Adam Coates was generating. And Adam Coates had shown using small scale resources and scaling up the new networks really works. I think it made it easier. - I totally agree that figure that Adam Coates did. I think, I mean, that's basically changing a lot of the things that I did, but I think probably a lot of the things in the field did too. But really influenced me into, you know, joining the project. Of course, then I went to Google Brain and  I was an intern, like you said, I was the first intern of the project and that's around 2011 I think I remember that around April, 2011. And then I stay since with the project and, you know Brain has grown, grown from, you know, two, four or five people that you had at the beginning and now to, you know, much larger team. And now I do research, still continue to do research in Deep Learning and AI and yeah, yeah. - Google Brain was incredibly lucky to have you join. And I think one of the first home runs was that, you know, Google Cat project which you were the lead engineer and the lead author on. - Yeah, yeah, yeah, I remember that. So back when we were at Stanford, I was, you know, playing around with this method called auto-encoder, Basically giving the input image in and trying to reconstruct the image. And then if you apply some kind of sparsity, you start having some, at the low level of the neural network, you start seeing some kind of like hash filters. And hash filters is very useful for, for computer vision and then this, this influential result by Honglak Lee Lee, which is, and I think in the project he did with you, is that like if you do, if you do this in a deeper neural network, you start having more sophisticated features. And for me at that point in time, you know, learning feature representation is very, very, very interesting. And how I thought exercise, this is how but it's not me, but how i thought exercise, but, you know, you got a lot of credit in this, so I have to say it. But I thought exercise well actually, can you make this 100 or 1,000 times bigger, and learn even more sophisticated features? We don't know what they're gonna end up doing, at these networks, right? And then we set out doing this project, we scale it up from a single machine to 16,000 machines. I remember that. And we trained it on YouTube, because I feel like my question was you know, what is the biggest image data set that we have access in the world at that moment? And it turns out that YouTube images. So we trained the neural network for like a week or so. A vast auto-encoder. And, you know, with a lot of poking, we found some hidden, some neuron in the network that is very sensitive to faces and cats. The, the typical things that people expect on the internet. And yeah, and one of the most intriguing result was that it's actually face, surprisingly the network found cats on the internet. - I still remember, I think we're both in the office that day, the team was still much smaller and you grabbed me and say, "Hey, Andrew, come to my computer and take a look". And I walked through and said "Whoa!" And that was the cat thing that you had discovered from unsupervised learning. And I think, you know, and I think one, one piece of early Deep Learning history is I think almost all of us maybe overestimated the short term impact of unsupervised learning. And didn't realize that supervised learning will be where a lot of the action, you know, at least in the early days would be. Although I find it interesting that one place where unsupervised learning has really taken off and is showing wonderful commercial results is in NLP. - Yeah, yeah, so true. - And in fact still remember when, you know, there was one day in the office where we were in Google Brain, where you walked over, tapped on my shoulder and you said, "Hey, Andrew come to the computer and take a look." And walked over, and there, you know, you'd gotten this cat to, to appear on your monitor from unsupervised learning, and I think that iconic, slightly blurry Google cat wound up being one of the iconic images of unsupervised learning at that time. So, I think, team couldn't have done that without, without you. - Yeah, okay. - Shortly after, one of the other huge hits that you worked on, was the Sequence-to-Sequence Model. And I think that that was another piece of work that changed the trajectory of NLP. Tell us a bit more about that. - The first version of  Sequence-to-Sequence is actually, a lot of people did not know but there's this idea called Word-to-Word is translating words from one language to another. So, and the reason why we did this as a foreign, so back in around 2012, 2013, suddenly there's this wave of new world vector methods. And I near by a guy called Tomas Mikolov and he was developing Word2vec, right? And it trained, it trains, code vectors very quickly. And, and it shows these amazing ability of, you know if you take, you know, pink minus green, then the vector is similar to men minus woman, for example, right? And basically solving analogy. So the next question we ask is that, can we, is there any similar structure between the two languages? So for example, can you train word vectors from, in, in Spanish and then also train word vectors in English? And can you try to align them a little bit, for example, can you learn that, you know, certain words in one language aligned with another word. And we did this thing, and it turns out it works. So you can only have, let's say five words or, you know, 100 words in popular words in English. And we do know the corresponding translation in Spanish and then you learn the rotation matrix. And then you can actually map, now you can start translating words from one language to the other without knowing too much about the language. So, that, you know, this word-to-word translation gave me the feeling that, "Oh, maybe we should not do this Word-to-Word. Maybe we should do sequence sentence-to-Sentence". And then we say, "Okay, so how do we do sentence-to-sentence?" And it turns out that that's, it wasn't easy to, conceptually at the beginning for us. So we were thinking always all the ways for example, let's try to read in the input sequence, the input sentence, and then try to predict, you know, what's the first word looks like. And then trying to predict what's the second word would look like, without knowing the first of word, for example It's like predicting the first word, second word, third word, et cetera, without knowing their relation. And then I said that, "Oh, maybe that's a little bit limited because, if you predict a second word you should know the first word, because if you, and if you predict the third word, you should know the second word, et cetera, right? So it has to be some sort of dependency. So we, we thought about it. - In an English sentence, you know, it doesn't really make sense to independently predict the first and the second and the third and the fourth words. You should predict the first word and then based on that, figure out what's, what's the second word. And then based on that, after that, figure out the third word. The sentences you output just make a lot more sense when you do it one word at a time, rather than try to spew out all 10 words at the same time, that may not end up relating to each other. - Yes, yes, that's a good way to explain it. Now it turns out that so, you know, like from the point that we realized this idea to actually make it work, it took like a year and it was actually very difficult. And one, one bottleneck about this whole thing is actually training the sequence model to do this. And back at the time, when I was training this, I trained with a conventional recurrent neural network. But at that point in time, together with me, Ilya Sutskever and Oriol Vinyals, they all also have very similar ideas of doing this. So and Oriol Vinyals and Ilya Sutskever, they had, they know how to train this model, how to get this model to work with LSTM. So we met and then we decided that let's, let's try with LSTM, it turns out it gave us really good improvements. But with the first translation, it still look awful, and it can output certain words that looked like the input, but mostly wrong. So the question is, can we, should we continue? And, and, you know, I was into, you know, trying all sorts of ideas and so on, but credit to Ilya that he said maybe we should train, train this model better. We should really train this model better, and train a bigger model. Train bigger model, and train it longer, train it better. And credit to him that actually, actually that approach actually turns out to be successful. And then he, we train it. We lower the perplexity slowly, slowly over time. And then we stopped when after, you know, a couple of months we start seeing better and better translation. And you know, now it's just only one or two words, but like five words suddenly more correct. And we realized, we realized that we were onto something. - Sounds like, if I got my history right, you tried through variant ends then got better results with LSTMs. And then the last mile was just scaling, more data, bigger network, bigger LSTM network. And that wound up being the last several steps to get to that, you know, similar breakthrough that we then saw on new works. - Yeah, I will say like last time to preview from the perspective of a researcher. But I think it makes a huge difference for the project because, you know, had I tried, you know, fancy ideas and, you know, doing all sorts of crazy ideas, I think I would not get the thing to work. And we will delay the project for much longer. And it's a lot of lessons, even though the last mile seems to be trivial from the research point of view, it made a huge difference for the project. And had we invested in, you know, fancy ideas and not didn't try scale and didn't try to train the model longer or better, you know, if we invest more on ideas, we never got the model to work, and it would not, it would delay the project for much longer. - It doesn't seem trivial to me at all. And I find that when I'm building systems, when I'm, you know in basic research mode, sometimes I hold the data set fixed and change the algorithm. But when I'm in production, just build a commercial system that works more. Sometimes I hold the algorithm fixed, you know, pick an architecture that I think is good enough, and then spend all my time changing the data. So there's very, very different ways of operating. - Yes, yes, yes. - The work that you did with Ilya and Oriol on Sequence-to-Sequence Model, some of this work, really huge impact on the whole field of Deep Learning. And then, almost coming full circle. You built chatbots in high school and building on the ideas of the sequence, you also build this, well much more advanced chatbot than your high school version I imagined called Meena. And I remember reading that paper and thinking, well, some of these outputs actually look pretty cool. Talk a bit about the Meena chatbot project. - Sure, sure. One of my dreams in my high school is that the viewer chatbot that can tell you a joke. No, it can, it can tell me like a new original joke. - One of the things when we're writing The Batch, every Tuesday, because we send it out on Wednesday, is my editor in chief and I often end up sitting around brainstorming for five minutes to see what's the joke we want to tell one of the chatbots. When you made a chatbot to automate joke telling you'll make my life easier. - Same with me. You know, sometimes I wanna give a talk and I, I will always begin the talk with like some joke and it sometimes hard to make the joke as well. But yeah, when I was in high school, I was thinking, you know, can we come up with a way to create like an original joke? And it turns out, if you think about through that exercise is actually difficult, more difficult than you can, we can program. So, so after I worked on the Sequence-to-Sequence project, I realized that if you can get in sequence and as input and then produce sequences as output maybe one of the biggest application is to train a model can talk to you. Now, this idea I actually executed better. Actually the who thought about this idea at Google first, it's not me. It's actually Oriol Vinyals. So he actually trained a chatbot that actually worked really well. And we, we realized that maybe we should collaborate and then build like a chatbot, cool chatbot. And we did it in around 2016 or something like that. And it's like a paper on Arxiv (Arxiv.org) and we showed the potential of this. - I remember you had to do a lot of work, right, within Google to get permissions to use the IT support... - Exactly. - To support the chatbot, right? - So back at the time we were like we would research as I'll say, where's the data set. So one thing, what we did was that like going after that, you know, technical support internally at Google and get a data set from them and then train a model. And then we ask the question, like, "Can you debug this? I lost my passport, what should I do?" And then it start answering some, some kind of question. Although, you know, although it still feels a little bit off but you start seeing it, there's something there, right? There's something there that's really promising. And then I spent... - I just had this very clear recollection. You, me, I think Adam Coates, a bunch of us were having dinner in a restaurant in Palo Alto. And you had just gotten permission to use the data. And you were very excited over dinner that day. - Exactly, yeah, yeah. - I have a recollection of that dinner. - That was when we had sushi in, in the Palo Alto restaurant. - [Andrew] Good times, yeah. - I remember we would talk about that and how, how excited you were that, you know someone would work on a chatbot, because you also worked on a chatbot back in the days. But yeah, and then I spent... - I think I told you about my high school chatbot, which was actually more of a prank, right? I think told you I wrote a prank chatbot where I will type and no matter what I type, the chatbot will print out "What is your name?" so, I would type, you know, Q-U-O-C L-E, and as I type that the chatbot will print out, "W-H-A-T is your name" and the effect was, when I hit enter, then it will print out what I actually typed. So to the user, they see, they think I typed, "What is your name?" and then it prints Quoc Le. As so, to my friends, I was pranking them. It looked magical because I could ask you the question and it will know the answer, but what was actually happening is I was typing the answer, it just was displaying a pre-canned question. So that's impressive, no AI, just a high school kid prank. But see, go on, go on, your Meena was much more interesting. Tell us that story. - I spent one year trying to improve the bot myself and I didn't get very far. And don't sound very hard to know how to improve it after you actually, after, so if you train multi-turn conversation and after one or two turns, it becomes very difficult. Actually, for example, it can answer you the first turn but the second turn it started to forget information. It doesn't give you, you know, good answer and so on. And so it's pretty much broken. But then by the end of 2016 and 2017, I met this guy at Google, who was an engineer at Google. His name is Daniel and came and told me and said "I want to, I also had a dream to build a chatbot. So let's work together to build a chatbot". And, and when he came in back at that moment, something magical happened which is basically people have discussed, has developed this transformer architecture. And we say, okay, maybe the transformer is more promising, because it can understand long range dependency better, right? So it can see multiple turn better than the LSTM. And so we started working on using the transformer as to deal with this multi-turn conversation. And, you know, we created a bigger model again, right, longer and using more resources at Google and slowly we start to see some improvement. And one, one magical moment that in my opinion, is that I looked through the log. So we allow some people to chat to it at Google, right? And there was one magical moment is that we looked through the log and then I saw some joke the bot made and we ended up, it's actually in the paper. The joke was about, you know "If cows go to Harvard, then horses should go to Hayward." It's funny that, that joke and that joke. And then, but it's actually a multi-turned conversation. It's trying to lead the audience into it. So I saw it, and I thought, so I tried to look into the training data to see whether it's actually, does it have anything like Hayward, you know, cows go to Hayward, sorry, horses go to Hayward or not, and we couldn't find it. So, so it's truly, it's actually trying to invent, it understand the concept of jokes, it understand the concept of puns and it actually created a new joke. And I think that's, that's a very magical moment in my opinion. And I'm pretty excited about it. - I remember reading that joke when I read the Meena paper Hey, how, how do you know if it was a true understanding the concept of jokes and puns, and Harvard versus Hayward versus, you know, if you, if you enough monkeys on the typewriter or enough randomness means eventually there'll be a funny joke. - So we look into the training data very carefully and see, look for the word Hayward, right? And see whether that word mention anywhere, it mentioned once in the entire training corpus. But it is not next to, like a joke. It's mentioned in a different context. Our conclusion is it's actually trying to actually understand this concept of a joke. Because a training dataset has a lot of jokes, a training data set has a lot of jokes as well. Puns, there's a lot of puns, but this particular example is actually a marvel. We could not find anywhere in our training data. - I see, cool. So you've been at the forefront of, you know, NLP research for many years. So, and then we continued to see breakthroughs in NLP on a regular basis. So I'm curious, looking into the future, what are you most excited about, in terms of things yet to come in NLP? - Oh yeah. I think, I think I'm most, in NLP, I'm mostly mostly excited about genetic models. I think currently a lot of NLP and is basically doing traditional NLP where you can classify the sentiments of the sentence, or you can do name entity recognition on the sentence. But I'm more excited about the capability of generation. Like, can you generate a new book that, you know, consumed by humans and, you know teach people a new concept? Can we, can we get to that point or can, or maybe it, can it have like a, a director to, or screenplay writer to come up with a better movie plot, right? There's so much potential in using this technology for generation in my opinion. - No, actually since, since the breakthroughs of transformer model and several flavors of transformers, one huge vector of progress for the generative models has been scale, right? Scale of data and especially compute. Other than scale, what, what are the, what do you think are the important vectors of progress for generative models? - Okay, I think I'm, I think the, I think true understanding, I think right now we look into like, for example, text generates, there's still things that are a little bit off, right? Made up stuff, right? Like there there's some, some facts that it made up. So the question is, can we get the bot to really have common sense understanding and, and generating more factually correct output? I think that will be a big thing. I think that's what will be a big vector progress. - I wanna dig a little bit in further into that because I think a lot of researchers, including me you know, sometimes have talked about computers understanding images, or understanding language, and common sense is a concept that philosophers have debated for, I think, over 2000 years now. So when you talk about NLP understanding of common sense, are these scientific concepts that are measurable, or are these philosophical concepts that you kind of feel like it understands it. But how do you approach these questions of understanding common sense? - Okay, I think it's measurable. So in some sense, you can ask, for example, you can for example, you can create ask GDP in any language model. You can give a prompt about let's say, you know, talking about the GDP in the world, right? Like, let's talk about GDP in the world and can you look at the GDP and you compare with Wikipedia and can you say they are matching? And that's measurable or you can start talking about movies in 2020, right? And, can it understand that these are the movies, right? I think it is measurable. - Do you have a favorite set of benchmarks like this, this like the common sense QA is one data set? Do you have a favorite benchmark for measuring understanding of common sense? I though common sense is a bold name, to say "This is our measure of common sense" is a bold name for data sets. - So instead of like talking about common sense we can just talk about maybe factuality a little bit, just factual knowledge, right? Just generate some statements that are actually factually correct, right? For example, you know, how old is Barack Obama and so on, it can generate correctly. And from that perspective I think it's easy to create a data set for that. We haven't had that data set yet but I think it will be created. I think that people, people are in Allen AI that created like common sense data sets to measure the performance of generative models, right. So I, I'm not expert in this field, but I think my my feeling is that when I read a lot of these outputs, I still see things that actually factually not correct. And I think, see things a little bit off. And I think addressing that issue, can be quite important. - Also a good test set on measuring factual correctness, would be a great way to help the field for it. In your time at Google, you've mentored a lot of younger engineers. And even at your time at Stanford, you mentored a lot of the younger students. So today there are a lot of people wanting to break into AI, or they want to advance or to grow their career in AI. What advice do you have to someone wanting to build their career in AI? - Yeah, okay. So first of all, I have to say that I don't have true meta advise. I don't, I don't like the concept of meta advise for a lot of people, because I think you know, food for me is poison for other people. We are living in different world now, but I say, you know looking through my journey, I say that I started out from something very, very different, right. I came from different culture, different background. So maybe one piece of advice is that, you know like career as a whole is taking a long time to make really significant progress. I never can imagine that I make a big progress. I make a good contribution for translation, for example. So, so my, my thinking is that maybe you can start quite low but maybe, you know, with how it work and dedication that you, you know, over time, you can you know, do good work and make impact for the field. And so be patient really, right. So for me, that journey has taken me 15, 15 years also, already from the point that I started. And then until that, you know, I become a more senior researcher at Google. So be patient because it takes time to do impactful work, that's number one. And number two is that I think naivety can be good. A lot of people think that they have to read a lot and understand everything. I think naivety sometimes can be in your favor. For example, in around 2014, when I was doing this Sequence-to-Sequence at 2013, I tried to re implement phrase based neural machine translation. And I was just a bad programmer, I didn't know anything about phrase based machine translation. I was bad, I was, I spent two months implementing it. I couldn't do it. And because of that, because of that frustration, I I say, okay, maybe I should do something here. I should, I should do end to end learning instead. But imagine if I was a good programmer and I knew a lot about phrase based machine translation I would program it successfully. And then I would not develop a Sequence-to-Sequence and I would not participate in a different project like that. So maybe naivety is, sometimes it can be good. - I think what you said about patience is great advice and sometimes it does take some time, years, to become really good at AI and then it can be a long journey but extremely rewarding journey. I'm curious, what advice do you have for someone that is learning about AI learning about machine learning, growing their career and in the course of that process, how can someone know if they're making progress? And how can someone know if they're doing the right things to be advancing in the right speed? - Like we need to identify a data set, identify a task where you can see progress more quickly. And maybe sometimes you, you don't, you don't get success on that. Then try to understand why and try to talk to, you know, more, maybe contact more senior researchers and try to figure out all the senior engineers and trying to figure out what went wrong. I mean, if I were to start AI today, as in career in AI, as a researcher, let's say, that I would probably maybe just start the starting point. It would be, I would try to replicate my, my favorite AI research papers. Then try gratify, you know, look for, read the paper, try to understand it, reproduce the results, compare against the data and try to, you know to get into the habit that I can implement quickly. And, you know, my code can reproduce the result quickly. And then, you know, if I make progress in that easy phase then I can start thinking about how could I contribute? How could I get better at developing my own ideas? So that what I do, although, and then I will start. In other words, I will start with something easier first. Trying to get something that easier. Like it's like a learning to swim, you don't wanna go to the ocean to learn to swim. You wanna learn to swim in a pool first and then, you know, do something quite easy that you get happy doing it, and then move slowly, move yourself towards more and more difficult tasks. And to the, for example, creating your new idea, writing your own paper, that's difficult, but I think reproducing a line of existing paper and getting a result on MNIST or CIFAR. That's easy enough to do so maybe start with that first. So start with something simple. - Good advice. Kind of like, you know, we use curriculum learning in training neural networks as well. Thanks Quoc, this has been great. Before we wrap up, do you have any final words or any final thoughts for the viewers watching this? - Oh, I can say some final words. I say, you know, I, I accept the interview because I want to see Andrew and I wanna thank you know, Andrew was a spectacular educator, I have to say. So I remember in 2017, I came to, you know, I was already a researcher, I wrote papers and so on. I came to Stanford, I started my PhD. I came to a lecture hall by you, the CS229 lecture. And I literally had goosebumps because your lecture was so good. It was, it was like another level. And I learned, I learned a lot. I think I learned a lot from, from your class and, you know from your original thinking as well. I thank you for your contribution in educating the community about Deep Learning. I think that's gonna be very, very impactful for the field as well, because we need more, you know more people to move the field forward as well. - Thanks, thanks Quoc. Wasn't expecting you to say that. It was very, very, very very kind of you know, it means, it means a lot. - Thank you. - Thanks for being with me on this interview series. It's wonderful to see all the tremendous contributions you're making to NLP Deep Learning. It's great chatting as always. - Yeah, yeah, thank you. - [Announcer] For more interviews with NLP thought leaders, check out the DeepLearning.ai YouTube channel or enroll in the NLP specialization on Coursera. 