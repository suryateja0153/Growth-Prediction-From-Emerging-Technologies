 Progress is kind of skyrocketing. And this is due to a couple of factors. First, we have this like volume of computation that's available. It's much larger now than it used to be. There's also data, more and more data available natural language processing and other other domains. And this increasing that compute and data kind of directly has led to better and more powerful models. We found that basically, faster computers and more data kind of directly translate into better ML-- better AI. Thanks for that intro. And can you guys hear me I think it sounds like this is on. Oh, thank you. Yeah, I just woke up. So I don't actually lead Uber AI labs although I was one of the co founders just want to make that straight. I'm, I'm a researcher at Uber, and I work on AI and machine learning. Who here does anything with machine learning at all? Okay, a little few people. What do you do with machine learning? to predict one? Okay, okay, based on what type of data? Okay, okay. Okay, got it. Got it. Got it. That's cool. That's cool. Anyone else want to give it an example? Yeah, please. Okay, what? What? application? Okay, an MLP for social media Cool, cool. I think when I came here in the spring, maybe nobody used AI for anything. Or maybe like one or two people said they used it for something. So I'm gonna talk to you today about some of my research and research and collaborators in machine learning. Broadly, I'm going to talk about ML why it works well like how it works, what we know about how it works and what we don't know. Let's just get started quickly. So if we look like machine learning progress over the last five or 10 or more years, we've seen basically like progress is kind of skyrocketing. And this is due to a couple of factors. First we have this like volume of computation is available, it's much larger now than it used to be. So in log space, you know, in linear space, this is like hockey sticks, like you guys are, hopefully used to seeing in log space is just a nice straight line. This is compute. These are computers getting faster and faster and Moore's law. There's also data, more and more data available natural language processing and other other domains. And this increasing that compute and data kind of directly has led to better and more powerful models. This has been a little bit surprising over the last decade or so, we found that basically faster computers and more data kind of directly translate into just better and better AI. We've seen it in a couple areas. So I'll give you a couple quick examples. This is an algorithm from DeepMind called AlphaGo that beat the world champion in Go a couple years ago a lot of people thought Go is this game that will be so hard to beat-- For AI to beat humans, it'll take until 2050 or something. And here we are. This is 2016, I guess this is published. Here's an example from my own work. This is little robot in our lab and it's going to sound on. I don't know if that'll work, we had this little 3d printed robot in our lab. So this is kind of cool. If you look carefully, there's nine servers, so like 12345678, and there's a nine one in the middle here, which is like a hip joint kind of the whole robot is 3d printed. So you just like click Print, and like a day or two later, out pops this crazy assembly of plastic and you screw it together with some screws with Office shelf servers. And we want to make this thing walk, we want to make it like go in some direction. So the first thing we tried is like hand coding gate, this is hand coded by a grad student. And you can see like, if you imagine how you should make this walk, you might imagine it kind of like leans this way leans this way back and forth, back and forth. And it is kind of slowly making progress right. There. Of course we do machine learning. We want to make it Learn to walk by itself. We try to shallow neural network not to go into too many of the details, and eventually learned to kind of move his limbs a little faster. It's walking a bit, but it's not moving much, much faster. We switch to a different type of neural network called-- Well, it's a simple network that paints a recurrent neural network using an algorithm called hyper neat. And using this algorithm, we were able to get much more organic motion. So here the limbs are kind of moving together, but it's not really going anywhere. So we thought this is like a step in the right direction it represents in progress, but it's not like kind of vaulting over the floor like we hoped. Here's sorry, here's, after a bit more work. That's the same robot from before but I was experiencing the world's learning it tries something actually measure his position via this LED on top. Every time it moves, we tell it how far it moved and it learns to move further and faster. At the end, we finally found this gait here with the robots kind of like wandering that is pretty fast, pretty coordinated. This gate is nine times faster than the gate I showed you in the beginning that was coded by human. So robotics, natural language processing actions is a huge amount of progress being made recently motivated by a couple bits of work. In particular, the transformer models from Vaswani et all in 2017, from Google. And then some folks from OpenAI, I kind of took these to the next level, train the biggest one at the time to date. And these language models, basically the AI kind of reads, reads, millions and millions of web pages gets a feel for how humans tend to speak. And then it has a model that has a generative model for what text is natural. So for example, one thing you can do to this is you can say, I am the as a human, I'm going to type in this prompt. In a shocking finding, scientists discovered a herd of unicorns living in a remote Valley in the Andes and so on. I'm going to type this problem, I'm gonna give it to the model I'm going to say hey, "AI if I started a second Or a web page like this? How do you think it would end?" So I type this in or rather the researchers that OpenAI type this in and ask the model to complete it. And the model spits out all of this stuff. The scientist named the population after their distinctive horn, Ovid's unicorn, dot dot dot. Down here, something I like a lot, Dr. Jorge Perez, and evolutionary biologist from the University of Le Paz dot dot dot. So what did the model do? What did this ML do? First, they invented a name for them, right? They named them Ovid's unicorn. That's pretty cool. Ovid's unicorn wasn't in this like prompt text at all. So like these models can be can be creative. Second, I like this little detail about Jorge Perez. So it makes up a fake doctor, a fake biologist from the University of Le Paz. Why is that kind of cool. So University of Le Paz here is it's like it's a university that plausibly would be in the Andes Mountains. And so somehow this model just by reading a bunch of webpages about random stuff around the world learned that like in the end these there might be a biologist named Jorge Perez at University of Le Paz. So these types of models are really, really starting to change the world. 