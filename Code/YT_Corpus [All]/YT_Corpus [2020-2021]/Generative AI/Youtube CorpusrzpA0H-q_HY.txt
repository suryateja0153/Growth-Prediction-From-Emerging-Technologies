 Good morning everyone, Matchue here. Image manipulation using AI is extremely useful in many ways. One particular use for it is in learning abstract representations of images, also called feature learning. In feature learning, an AI looks at an image and translates it into a set of numbers which represent the features of the image. These representations can be used to compare images more similarly to how humans would. For example, any human would likely say the left image is much more similar to the center one than the right. However, traditional techniques would say that the right image is more similar. With feature learning, the feature vectors give us an abstract representation which can lead to the correct answer. The difficulty of feature learning, however, is that there is no single correct answer of what the feature vector should be. Thus, the representation must be learned indirectly. This is where the Bidirectional Generative Adversarial Network technique, also called BiGAN, comes in. For background, I will quickly explain the concept of a GAN. A basic GAN is comprised of two AI models, a Discriminator and a Generator. The Discriminator’s goal during training is to classify whether an image is real, or if it is generated by the Generator. The Generator’s objective is to generate images, starting from some random numbers called a latent code, which fool the Discriminator into thinking they’re real. Over training, the Generator and Discriminator learn how to perform their respective objectives better, leading to the Generator generating more and more realistic images. The BiGAN architecture adds one more model into the network, which is called an Encoder. This encoder does the opposite of the Generator. The Generator takes random latent codes and generates images from those codes. The Encoder takes real images, and attempts to generate latent codes from them. The way that the Encoder is incorporated into the GAN is by changing the Discriminator. The Discriminator now looks at both a latent code and an image. Its objective is to classify whether it is looking at a real latent code and a fake image, or a fake latent code and a real image. Just like with a basic GAN, the Generator and Encoder both aim to fool the Discriminator into misclassifying their respective outputs as being real. Over training, the encoder naturally converges with the Generator, learning which values in the latent codes correspond with high-level features in images. Once training is complete, the Generator and Discriminator can be discarded, as the Encoder has now learned how to build an abstract representation for an image. This satisfies the objective, which was to build an AI model which can build a feature representation for an image. That is the main concept of the Bidirectional GAN. If you want to know more, I encourage you to check out the original paper, or the follow-up paper called BigBiGAN, both of which I will link in the description. If you enjoyed this video, give it a like and check out some of my other videos. Thanks for watching! 