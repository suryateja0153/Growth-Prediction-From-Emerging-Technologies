 you good afternoon and welcome to the day's program at the Commonwealth Club of California My name is Gerald Harris and I am chair of the Technology and Society Forum. I'll be your host for today this afternoon's program and the club's new virtual efforts are generously supported by the Chan Zuckerberg initiative and a collaborative of local funders and donors we are grateful for their support and hope others will follow their example to support the club during these uncertain times of the technology and science limb performed in two explosive members and attendees to the current and emerging developments in science and technology and in the process generate thinking and ideas about organization of technology and creating a better world for all we welcome your participation some sub members and we will be delighted to receive your ideas on future programming our contact information can be found at the club's website today's program features dr. Susan Snyder who recently wrote a book entitled artificial huge AI and the future of the mine this program will be moderated by gilepsy a former president and current member of the sub Board of Governors he would introduce dr. Snyder and lead a discussion we will save some time at the back end the program for your questions and hopefully get to admitting as we can't and now take it away Joe thank you very much teacher to Paris dr. Schneider Susan if I may it's really great to finally get to do this Commonwealth Club special interview with you for your commitment to make this program happen since your mom and dad have been friends of mine for many years it's a particular pleasure for me to have this opportunity but before we begin and for those who may not know you let me just say a few words about you dr. Susan Schneider grew up in Tracy California where her father is a high school football coaching legend and a member of the Football Coaches Hall of Fame Susan went to public schools but she did reject football as a career and suit moved on to get a BA degree from the University of California at Berkeley graduating with honors she then received her PhD in philosophy at Rutgers University dr. Schneider is currently an associate professor at the University of Connecticut and is the nasa Beru lumber chair of astrobiology after Schneider currently hold the distinguished chair at the Library of Congress and as a director there she has been featured by the New York Times Science magazine Nautilus magazine the Smithsonian and has made numerous TV and radio appearances on PBS the History Channel and more she's written four books the language of thought the Blackwell companion of consciousness science fiction and philosophy and of course her new book artificial you Susan as my favorite CNN news anchor Chris Cuomo says let's get after it so I have some questions and the first one has to do about religion religion plays an important part in the lives of many of us but true believers think that God has designed us as humans with anatomical and evolutionary constraints each of us being designed as individuals a little different from each other so in mind design you talk about the artificial enhancement of our natural or god-given minds stating that my design is done by humans and not God do you expect a backlash as you proceed on mine design from some of these religious groups because of your stated position think so I mean who knows though like you know but um I worked with the center's the electrical inquiry in Princeton in fact the last event I just did involved an interview by will store who runs the center and I think that the challenge here as I discuss is really that as AI technology gets better and better the next logical step in the development of AI like it or not is to go inside the head so a I will not just change the world around us creating smarter robots better Google searches and what not it may create better minds and so as a philosopher I think I have something to say that even theologians will appreciate which is if we are going inside the head we better ask what the fundamental nature of the self and mind really is and I call this mind design the idea that a I might sculpt the human brain because it's a form believe it or not of intelligent design right but we not some God purport to be the designers so this is really humbling we better think it through this really is much different to what the evangelicals said many many years ago and took many of us by surprising by hand by shock when they talked about intelligent design they didn't mean what you mean as mind design no and I did a movie with Dawkins and he says it's intelligent design Richard Dawkins in the film in that in the preview so I think that the point here is not to go back to the debates you know about evolution and all of that it's to think about something very different here that we can all agree that if AI technology and neuro technology starts to tweak the human brain in ways that you know I can talk about today we're purporting to design the brain and so it is intelligent design or unintelligent design if we do a bad idea so we still evolve but the evolution is partly in our own hands so the evolutionary forces they're not entirely Darwinian tell us Susan a little bit more about your reference to the Carl Sagan film contact you talk about a dialogue between the alien and a human being in the film and you state our social development lags behind our technological prowess what do you mean by this statement and how will the development of AI affect the growth of our social development oh that's lovely yeah that's my favorite film Carl Sagan wrote lines in it and I believe it was derived from him his work and that's a moment in the film where Jodie Foster's character meets for the first like first ever human contact a sophisticated alien BA and the alien being is sort of depicted as being like her father like visually she sees her father who's deceased because that's supposed to comfort her and he says you're an interesting species you have such extraordinary potential I'm paraphrasing you know you you can do all kinds of wonderful things technologically but you're also cruel species and you know I love that moment in film although I can't remember the lines verbatim because I think it's reflective of what happens with emerging technologies often our emerging technologies are developed in ways that are not socially wise so our technological prowess is ahead of our social ability to see the proper use of these technologies and I think that's why it's important that we discuss AI regulation and the future of artificial intelligence because if we get this wrong there could be catastrophic consequences and we've already seen misuses of AI technology I mean their algorithms that discriminate because their data is bad there are deep fake videos which you know could get in the wrong hands and tweak people's sense of reality there are internet bubbles you know there are all kinds of bad uses of the technology and the technology itself isn't intrinsically bad but if we just sit back and you know let AI companies only decide what the proper uses of the technology is without regulation without public discussion that's not a good thing well we're going to get to some questions a little later on about regulation of AI but I want to get to you what I call your central theme or your primary theme at least as I took it in the book and in other writings and it has to do with consciousness and consciousness engineering so with consciousness being the philosophical cornerstone of our moral existence I take it that consciousness is what separates one as a self or a person from automation you talk about smelling your coffee in the morning your appreciating a sunset I guess this is consciousness as you develop it so talk about the ethical dilemma you refer to in your book between human consciousness and synthetic consciousness along with the general term and topic of consciousness awesome so yeah consciousness is the felt quality of experience so throughout your waking life and even when you're dreaming it always feels like something from the inside to be you so you know yes the the lovely aroma of your coffee but also bad things like the feeling of a bad headache all of these things are conscious experience and it's important that we know that it is the fact that we're conscious beings which makes joy and suffering so meaningful and if you believe that non-human animals feel it's what makes it ethically important that we treat them well as well the fact that they to our conscious beings so consciousness is morally significant suffering is bad and we want AI to be developed in a way that ensures that humans flourish now there's a question here about synthetic consciousness that is would machines be capable of feeling something would it feel like something to be Nai we see this depicted in a lot of science fiction think of Rachel in Blade Runner for example or the little boy in this bill Berg film AI um films tug at our heartstrings I urge however that it's far from clear that we could develop conscious AI we don't currently know if microchips are the right stuff if you will to underlie conscious experience and I develop tests at Princeton University with edwin turner professor of astrophysics is a professor of astrophysics there on ways to determine whether the machines can be conscious so i think there's a lot of she's here and our kind of initial feeling might be that machines can be conscious but I urge that we should take a wait-and-see approach and test it and that there are a lot of reasons why a AI companies may not even want to develop conscious systems so I talked about consciousness engineering the possibility that certain companies may deliberately engineer consciousness out of machines or conversely some AI designers might choose to actually engineer consciousness into machines so sort of like Anthony Hopkins character in West world's well how can you not love a machine like r2d2 for example I think I think this question follows naturally and it's a great segue you make a reference to robots like r2d2 Star Wars Fame and the TV program the Jetsons and you said that the Jetsons were surrounded by a a I all the time but they remained unenhanced themselves and I couldn't quite yet why was it just too early in the game for the writers of The Jetsons to enumerate artificial enhancement in their script for the program and yeah like Star Wars - in Star Wars r2d2 awesome right and tons at the heartstrings but the humans are unenhanced but the historian Michael best says that we're all committing what he calls the Jetsons fallacy assuming that in the future we will have worlds in which humans themselves are unenhanced by the AI technologies but all around us are these amazing robots like Rachel and Blade Runner or RTG - um I actually urge as I mentioned that we just don't know yet if we will even build conscious machines and we need to really think hard whether we want to and in what context we would want to but people are going to inevitably assume that something like r2d2 which squeaks and is cute is conscious and I call that the cute and fluffy fallacy right similarly you know if you see an Android that looks human and there already are very human looking androids under development in Japan to take care of the elderly population for example it's very easy to assume that because they look human at least from a distance it feels like something to be them and I think that's that's dangerous from a moral standpoint because if you assume something is conscious when it's not you're including it in the domain of moral consideration right with other conscious beings and that can lead to very bad things I mean if an AI that looks human is simply not conscious but fools people there could be trade-offs situations where we have to decide how many people die like you know philosophers talk about trolley problems so you know you've got a train going down the tracks and if it goes to the left it kills for humans if it goes to the right it kills five androids which do you choose well if you believe those androids are sentient if it feels like something to be those Androids but you're wrong if you believe it feels you know like they're conscious but they're not then you've killed for humans to save five androids they aren't conscious robotics are so amazing I just had a my wife and I just had a brief experience a few months ago visiting our grandson who's a freshman at Purdue unfortunately he's learning now in a distance way because of the virus so they he was pointing out robots on the sidewalk and Purdue delivering food to the students in the dorms and we would follow them and the robots would actually stop at a stop saying not because they saw the red light but because the student in front of them or to the side of them was not going across the street a student was watching the red light the robot seemed to be at least that's the way it was explained to us the robot was watching the student but anyhow that was an amazing experience for us to see this is my first venture in really trying to learn about AI so I really appreciate the opportunity to read your book and to talk with you about this the first thing I thought about was Mary Shelley's character in her 19th century book Frankenstein the modern Prometheus and she writes about Victor Frankenstein and created the Frankenstein monster I still have nightmares about that is there any scientific relevance to Mary Shelley's writings oh yeah Frankenstein is canonical in the field of bioethics you know people thinking about the ethics of emerging technologies often think of the storyline in which you know technology goes awry and a monster is created and it really resonates when it comes to debates about artificial intelligence because there's a lot of discussion right now about the safe use of artificial intelligence and you know some people think that if we develop intelligence that rivals humans at the level of intelligence that we have it could be quite dangerous because the machine could eventually surpass us in intelligence and become what is called super intelligent AI a hypothetical form of AI that is able to out think humans in every way possible social skills scientific reasoning and more and so you know Mary Shelley envisions this machine I mean this creature which is very dangerous to its creators and so you know we have to bear in mind the possibility that we may be playing with fire right one of your largest concerns is what happens to privacy and security in a society where people have merged their minds with artificial growth you've been touching on this in your first few answers in this case wouldn't hacking of the mechanisms of artificial growth be a danger with cybercrime and hacking existing at an alarming rate today what is to prevent an artificially enhanced human brain from extreme risks good question um so I work with Congress in Washington on artificial intelligence legislation and I've had the pleasure of presenting my book to Congress and they rely here and now issues which are super important and I think relate a lot to the issue of whether AI should go inside the head so right now you can already tell that when you're using your smartphone it's collecting data right these apps are selling your data to the highest bidder and some of us are really irritated by that and sometimes people lose important information it's made public we've seen elections tampered with by foreign powers we've seen all sorts of misuses of algorithms already so if AI technology is something that then becomes you know encoded in a microchip goes inside your head in principle without careful regulations your thoughts can be sold to the highest bidder an example I like to use is suppose you download your memories of your child's first few years onto a brain ship and then it becomes part of your cloud subscription you keep paying every month to keep those memories but you somehow lose access maybe you don't have the money or maybe some nefarious government steals access to your data then your innermost thoughts are somewhere else right so I think there's a lot we have to do to get it right I don't mean to sound grim during a pandemic sorry but but the reason I bring these things up is to actually avoid you know awful stuff from happening right and I think given what's going on right now with AI it's good to have these kinds of conversations so that we can make our future better and make sure that our children and our grandchildren don't encounter these kinds of problems I just had another flashback to my grandson at Purdue as I'm looking at another question that I think we're going to segue to hopefully he'll listen to this program he'll give me his thoughts on this but I think there's a shortage of STEM jobs STEM education and STEM jobs a recent article in The New York Times Magazine indicates that in a faster tech world of 5g speeds there's a shortage shortage of people with a solid knowledge of STEM disciplines the article specifically refers to calculus can you talk about this and tell us about the importance of calculus itself as part of the STEM education in the writing of algorithms which is as I understand it the lifeblood of a AI well I think the really important thing here is that there's just a lack of suitable training there's like at various universities they're quickly trying to create data ethics and AI programs data science programs where people are getting not just coding skills and mathematical skills but they're also thinking about the social impact of technologies so they as a society these students are trained right and we're better able to handle the technological challenges that the future brings I mean one thing to consider is the future of work and how AI affects it you know if you're thinking if I have a college-age child and you know it's really interesting to think that there are a lot of projections right now that AI will out mode us in the workforce so we're already seeing you know supermarket checkers autonomous vehicles or under development you know all kinds of technologies that will create unemployment and so the challenge here for our young people that are interested in STEM education is really how to frame themselves in an intellectually rich way so that they can respond to possible changes in the labor force because things are going to change and they're going to change rapidly and so that's why I think actually there's an importance to having a broad-ranging liberal arts education not just mathematics which I love but you know other areas philosophy um political science Joey I know you you said you study that at Berkeley we were just talking about it yeah so I think you know really we need to focus on on that as well as getting good training at the universities in data science AI and the ethical uses of technology right so we we did mention before we went on air doctor dr. Russell and I want to just give you the proper key on this so Russell's premise and you're you're going to be doing some work as I understand it with dr. Russell dr. Russell is differntly you said yes and so we're talking about Stuart Russell on who read the Russell human compatible and I think in a week or so we're doing a joint event at the Mechanics Institute online right so his premise in his book entitled human compatible is how would you place or his concern with designing super intelligent machines and that they should be Zion design they have objectives that are in line with our own or your own or that whoever is designing that machine the machine should not run off on a tangent it should be designed to do what it was supposed to do so you agree with that premise and how would you place a safety net in this design to make sure that undesirable results would not occur from for example supercomputers and to make sure that dr. Russell desired objectives are met a lot of people agree with Stuart in fact there's something called the control problem which was articulated by Nick Bostrom in a New York Times bestseller called super intelligence and so the issue here is how do you control super intelligent AI should exist because you know it seems like every way that we can control the machine the machine can out think so you know you might think well good Killswitch well you know it's gonna think about that it's gonna think of other ways to bypass kill switches you might think will bake in some algorithms with ethical coding well no two philosophers can agree about what the proper ethical system is for the first thing and then also think about the famous genie in a bottle case where you get three wishes right that you know and the wishes are you think that they would be okay the way you statum right but the thing is if you don't stay to write what you see is what we call a perverse implementation of what you want because there are a million ways in general that people will misunderstand you right so a machine if you code in and it's true into the machine there are a million ways it could go wrong right I mean think about it like all right machine I want you to end global warming well what if it decides then to knock out the human race cuz we are in fact the cause quite possibly of global warming and that would be not what we wanted so I think it's a super tricky issue I don't have you know a great suggestion I think let many flowers bloom and there are there's a lot of work on the control problems my suggestion I do have you know a humble suggestion is that we learn more about whether machines are conscious because if you think about it think about your dog or cat okay why is it it so awful when your dog is in pain or your cat is in pain it's because you're a conscious being you know what it feels like to be in pain and you believe that your daughter can't feel something too so consciousness is what makes you kind it's the fact that you have a kind of inner sense that it's bad to harm right well if a machine is conscious perhaps that is the key so maybe through experimentation to see what consciousness we do to the parameters of an AI we might be able to help solve the control problem but that's on the assumption that we can even build conscious machines and we again we just don't know because we don't even know what microchips would be used there's so many different kinds of microchips under development right now so well I want to just I want to talk about a conscious being I don't think a discussion about AI would be complete without talking about Elon Musk as you state musk is pushing a product line of enhancements the Tesla car which driverless car capabilities privately designed and own rockets previously unimaginable power which stems from modern-day batteries so give us your view on Elon Musk and his relevance into today's world of AI thank you Elon for my cars you should see what's out front right now and how fast I Drive it zero to 60 and what is it like 3.8 so I like him okay but on a serious note I complained about him in my book so don't turn off my car um here's here's my worry right so in the domain of AI um he's doing great things actually with AI safety but when it comes to AI in the head the idea that he promotes is that humans should merge with artificial intelligence through the use of brain chips in the head okay so he founded a company called neuro Lane and that company's goal is to make brain chips as commonplace as LASIK so that you and I when we feel like we need to keep our jobs to you know out think AI to stay marketable or whatever can go in to a brain enhancement Center and buy a chip to stay smart or get smarter and that worries me for a lot of reasons um you know why I said a minute ago we don't even have AI technology now that respects our privacy so we need to be really really careful science fiction writers have long depicted science fiction dystopias involving brain chips and whatnot but the other issue which I actually discuss in about half of the book actually that I'm really worried about is if you or I decide we want to enhance our brain in radical ways and you say do this at some mind design center if you will at what point when you add all these chips are you still even you at some point are you so radically transformed that you've actually ceased to exist so that you walk into the Center for my design you pay buckets of money you order all kinds of funky brain chips to get you to do all kinds of things like you can you know echolocation like a bat you can meditate like a Zen master you can calculate like a savant but at some point you paid money and you've died in there sorry again I I when I wrote this book there was not a pandemic I think your car's gonna be safe outside hopefully Elon Musk will watch this program it'd be interesting for him uh yeah I mean I wrote an op-ed in the Financial Times and it got written up like all over the place it was like the big news item for AI for the week and I wonder if it messed up their stock because I was complaining about them yeah I used this thought experiment which i think is great it's like um you know suppose you go into a Center for my design and you start replacing you know parts of your brain with chips and so you buy the works what's the works well the works allows you to fully replace every part of your brain with microchips so that at the end of the day you're actually you have an artificial brain well I call that brain drain because if you believe that the self is the brain and the nervous system where the mind is enabled by the brain you have just paid money and scooped out your brain so you're dead well you mentioned the pandemic and probably anticipated that we couldn't get through this program without discussing it the coded 19 virus seems to be the elephant in the room today when discussing possible medical advances through enhanced artificial capacity my belief is that we may not return to a true normal until we have a vaccine against the corona virus so wouldn't it be possible to accelerate the creation of a vaccine with high speed supercomputers to help us understand and mitigate COBIT 19 couldn't these computers be helpful in developing testing data that may ordinarily take one to two years to do and reduce that time significantly I'm a little skeptical of a vaccine since we don't have vaccines for other coronaviruses but yes in principle AI because it can calculate it's such an extraordinary rate and sift through so much data it could be tremendous in medicine and for finding disease cures and indeed many of the world's supercomputers or at work right now on the issue and it may be that they find instead of a vaccine they find a treatment too and in fact you know there are drugs that have been identified as possibilities by AI technology and that I think is an exciting use of AI I think that the potential here for AI in medicine is so great I mean if you think about medical errors human error if we had AI watching and advising physicians so that errors in medical diagnosis don't happen as often that could be transformative but that's why we need data regulation so that our privacy is protected so that we can be confident in sharing our medical data I think the future of AI has been changed by kovat in all sorts of ways yeah yeah so the underlying theme the groundbreaking theme in your book is really a suggestion a suggestion that in order to maintain intellectual parity with advances in AI some of us should really consider surgically adding a microchip to our brain you talked about that going to the center of my design and picking out what you want what you want to accomplish what menu of things but you also wrote about this as an op-ed piece in The New York Times as you stated and by the way I have to say this the editor of the op-ed page you probably know where I'm going with this refer to your article as fiction so is it fiction at all or is this really the next phase of true AI oh yeah and the editor asked me to do something for a series called op eds from the future in which you skip ahead like 30 years and you write from the vantage point of where you think science and technology will be that was a fun series you should read that series if you like science fiction and AI that was really cool so yeah so Joey did you have more question though because that I'm not sure I answer at all with what you said oh yeah no that's that's basically I wanted to know if you had any retort to the to the editor because he asked you to write the article and he say well it's fiction that doesn't sound like it might be a criticism itself oh no no she she who by the way was times Woman of the Year now the page editor over at the New York Times had requested me to do it and the other people who did it were really interesting they did really good work like Chang the guy who wrote the film arrival he's a great science fiction writer he did a great one so anyway that was really cool it's a good series you can read that um I think it's important to grab future and send make him think about where it's all headed and I do consider myself a futurist okay I just want a mentioned to our host Gerald Harris that I have maybe a couple of more questions that I want to put on your platter Susan and then maybe Gerald can bring in the questions that he's now receiving you on the internet for you so one of the questions is that you human-level AI is still the stuff of science fiction according to some people I believe that in your work for NASA you've studied the possibility of machine life existing on other planets you refer to this as alien and intelligence can you discuss this please oh sure yeah so I had a project with NASA on this and now I'm in ask the chair and so my work is very theoretical because I'm a philosopher and what I was interested in was this okay there's a lot of research on exoplanets these planets that people claim who identify them are in principle planets that could be habitable they're earth-like okay they're friendly to Lights as we know it but are they really inhabited we just don't know right and we actually don't really know exactly how life's sprung up on earth there's still a lot of active research on that in the field of astrobiology but let's assume that these exoplanets some of them are actually inhabited okay which would be exciting there could be life elsewhere let's make that assumption and let's further assume that some of those planets survive their own technological maturity so they avoid stupid stuff nuclear war that you know kills everybody global catastrophes sorry I didn't mean to get back to catastrophes and so anyway these civilizations thrives and as they develop they start slipping on their own computers they start enhancing their brains with AI technology well that's all happening elsewhere if other worlds have AI revolutions then I think there's something really interesting that we can say about alien lights the most intelligent aliens maybe post biological they may be synthetic beings that sprung up from biological civilizations so I think that's a trip and I do I'm sorry to say it I think machines can eventually out think us well I'm not going to end on that know it although it would be a good place in and give us a lot to think about but I do have just one more question and it happens to be a legal one I know you're a philosopher you're you're an astro philosopher if I can use that term but here's the legal question in the United States do the same laws apply to the intellectual property rice used in the creation of the database underlying the creation of AI as they do for other intellectual property do you think companies are protective of these property rights when doing business for example in China and how about the Chinese might they be aggressively pursuing the theft of American AI technology or maybe they're even ahead of us in that area oh you're asking a philosopher about the law alright I'll do my best algorithms are like really hard to copyright or patents because I tried though I worked sometimes with the business office I've had some fun conversations with them you know because we tried to patent one of my a eye tests Princeton actually is trying to patent it so intellectual properties tricky with algorithms you know how do you how do you even patent it now in terms of China okay are they ahead of us the word on the street in Washington is no they're not are they listening to our conversations online like mine half of my website visits are from China I mean yeah yeah yeah oh my god um but I mean that doesn't mean that we can't work together right in a sense I mean we have got to come together globally the US needs to protect its strategic supremacy I'm a bit of a hawk but at the same time we all want to work as a team right we're out to promote human flourishing as much as we can I thought that was a great answer and with that Gerald let me turn it over to you and I really enjoy me well yeah here but let me just tell you some of the things I picked up and maybe you can comment on them one in particular this is just a lot of distrust of sort of human intentions and picked up on a little bit of it with you know what China might do is we know I think I did a leap ahead on being editing and seen there's a couple of babies though is this some set of values or oversight or whatever that you can envision so that the level of distrust and fear that people have about this to be addressed at all I think we're right to think that the ethical limits that our businesses and our military follow may not be followed by authoritarian dictatorships and we need to anticipate that but it does not mean that we should violate our sense of what's right and we need to also understand that regimes change and respond to global pressures yeah right so if you were to look maybe wanted to sort of overarching value anything pop up for you there global regulation is not something that I would you know have particular ideas on when it comes to AI let me just say I oppose a global ban on the development of super intelligent AI I don't think it would work okay we are now you know in the United States working on all sorts of privacy regulations and they're you know I don't know what you do with authoritarian dictatorships that have absolutely no sense of the import of privacy and are actually using AI to exploit their people right I mean a have these sesame point systems it's kind of like Facebook gone insane right where people tell on each other I mean I lived in a communist country by the way I went to college in the Eastern Bloc under communism so I've seen this kind of thing and you know we may not be able to stop it but we need to just say like let's try to observe pressure to encourage more open and humane treatment of people great there was a lot of it he would imagine people talking about science fiction and I know you mentioned Western world and some of your comments there's a giant computer ball that knows and judges every day and everybody on that show can you talk about AI being you know sort of embedded in the system at an individual but in the system in some time weighted surveilling and monitoring and judging and all that I mean on that one yeah yeah yeah I mean it reminds me of the philosopher Michel Foucault who Joey by the way he was a professor at Berkeley very hurtful interesting guy a wonderful writer and he wrote up the panoptic on which you know was not written about in the context of AI but he thought about disciplinary institutions like prisons and you know when you have a central watcher it changes the social dynamic if you're always feeling like you're being watched right I mean knowledge is power and data is the ultimate form of knowledge and so we need to be as humble as possible with our use of AI because I mean this is the age of surveillance capitalism money-hungry AI companies they make the apps they make the programs to get your data that's the economic model and I think that's a bad economic model I I'm all on pro business I think you know it's very important that we have a data economy but I think that model is something that's intrinsically messed up so you know let me switch boards a little bit in terms of how he thought of quicken or alive and one of them is in the middle and as you know a lot of things are done to do for some medical purposes a lot of breakthroughs in terms of systems that we go wah so they're here plants and all these kinds of things can you imagine that these brain implanted we were talking about that some benevolent use of those that comes out of helping people injured or something like that yes um in fact Ted Berger at USC has an artificial hippocampus that's already in phase 2 clinical trials so the hippocampus is part of the brain that allows you to encode new memory into long-term memory store and there are people right now who have damaged hippocampus ha's and who can't lay down new memory and Berger's been working on this project for 15 years and he's really done wonderful work and so that area of research is involving the use of brain implant technology not for the purpose of enhancing ordinary people but for therapeutic purposes and I think that's transformative it can't happen quick enough it's very exciting think about walked in patients um you know and I'm very excited to be on a project with the Templeton Foundation on these issues so you know we can contrast the use of invasive brain enhancement technologies in ordinary people who you know don't have brain disorders from neural prosthetics a class of medical items that could be transformative I mean think of the use of AI and the head for Parkinson's patients right now I mean you may know someone whose tremors have gone away because they've had that implant you know one day I I mean I don't mean to sound like a Luddite I think if we get it right if we move forward with constructive AI regulations you know not I'm I I wouldn't want to see this in an authoritarian dictatorship right I would want to see in a free society the option for people to actually upgrade their minds if they'd liked to but what I stress in the book is you better think what is the mind what is the self what is the person these are classic philosophical issues and they have actually no easy answer and that's where I encourage the reader to think hard about what it is to be a self what is it I mean if you're religious you have to think about the nature of the soul right I mean would you what would happen to your soul if you removed various parts of your brain and replace them well you could die so you could be ending your earthly life and maybe maybe some other creature there but it wouldn't be the case that your soul is correlated with the existence of that creature so depending upon what you think the self is that can make a huge difference to whether you should enhance at all some philosophers think there's no such thing as a persisting self and in fact that is something that Buddhists have long discussed as well as the philosopher Friedrich Nietzsche and Hume famously had that kind of a position maybe that's the case if you believe that if you think you're going into a mind design center to survive that's not right because you know there is no survival if there's no self okay let me put curveball on you on that one you may have seen this couple weeks ago 60 minutes out of peace on where there was some deep like almost 10 days of recording of people who were all across Survivor and it was a quarter from all these different angles and then they put it in a kind of machine and you can literally go in and ask that person a question and some intelligent systems go through all of that and give you the answer that that person has reported but I'm wondering if you can see that in the hands further that once a I saw the pattern of that person thinking they can answer all kinds of questions because it knows the model misses person is thinking so in essence you are sending the consciousness of that person in a very interesting way so and this needs to be something that people are already doing because they you know it was on 60 minutes apparently not to do it so what you're thinking about that kind of almost life or consciousness extension I don't think your consciousness would be extended I think it's an important technology so think about it like this suppose you're getting into your 80s and you want your great-grandchildren to know you so you pay money to a corporation to create a digital you bat use these algorithms to answer questions the way you would and you record content I mean it sounds kind of like that that could be a wonderful way for your grandchildren to know you but it wouldn't really be you your consciousness dies with you and just because you create a computer program that mimics your behavior doesn't mean that you continue to survive in a real sense I mean maybe metaphorically right but I think virtual reality technology and augmented reality you know has amazing potential to educate people about the plight of others so you know I've often told people about how about VR in schools so instead of reading about Rosa Parks in the back of the bus let the kids go to the back of the bus and experience people staring them down and experiencing fear for yourself say you know I think some of the concentration camp things would scare the kids to death and they are so vivid right you certainly have to be careful about that you don't want to inspire trauma but I mean the use of virtual reality and augmented reality technology for these kinds of purposes could be transformative I'm gonna turn it back over to Joe you've done a fantastic job thank you so much for insuring your intelligence and ideas so you may want to hose it off and they think you worked well sure thank you very much general Harris I just wanted to comment actually on that last question because I thought about asking dr. Schneider that question in fact we spoke about it about a week ago on the phone and I saw the 60 minutes program and what came to my mind is the expression that is used not only amongst Jewish people but amongst many people nowadays which has never forget and so the recreation of the testimony in the Shoah project which is a Steven Spielberg nonprofit and they they've acquired for years test a live testimony from people that experienced the Holocaust camp victims those people are almost gone now I know a few they're almost gone and so the value to me was that never forget that those that come after us our children and grandchildren will be able to remember such a terrible event so that it never has a chance to reappear again but thank you very much Gerald for asking me to do this program and I want to say thanks to dr. Susan Schneider philosopher futurist not lawyer but with knowledge of mental actual property law thanks all of you for listening to this program in the Commonwealth flow of California and to those of you who submitted questions for this program please check our website for future programs tonight's program and the club's new virtual efforts are as Gerald said earlier generously supported by the Chan Zuckerberg initiative and a collaborative of local funders and donors we're grateful for their support and we hope that others will follow their example to support the club during these uncertain times and now this meeting of the Commonwealth Club of California it's the place where you are in the know is adjourned Thank You Joey it was so great to work with you and Gerald um on an honor yeah you would you were really terrific you mate you made the job easy and fun you 