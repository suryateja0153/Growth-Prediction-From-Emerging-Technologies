 hey guys and welcome back so this lecture will be a brief lecture where we talk about the latest features and updates do for Vuforia version 8 so noteworthy points was mentioning our model targets with deep learning as well as generator enhancements for model targets recognize multiple objects from multiple angles instantly and first lamp for markoulis AR let's take a look at each one in a bit more detail so model targets is one of the foyers coolest features which allows developers to use objects as targets for the AR applications rather than just plain old boring images so a version 8 of the FOIA provides us with the option to train models using deep learning for instant and automatic object recognition which i think is really really cool so this intelligence enables us to use multiple models in a single application scene switching seamlessly between each experience and to have those models be recognized from multiple angles from my past experience using model target generator info for 6 & 7 I found it really difficult to detect my models so I'm really hoping that deep learning will help improve the cetacean experience we will be testing models targets in an upcoming lecture of this course so really looking forward to that to make the deep learning process go smoothly before it has an updated model target generator that allows you to select an automatic default finger ange for preferred recognition angles so this is necessary because of the limited computing power of mobile devices you can expect to detect your model from all possible angles well not yet hence there is a limited range of angles for recognition which triggers another algorithm or model to track the image features once detection has been initiated before finalizing model guide views the program will warn the user if the angle or chosen angle will be appropriate for training version 8 also adds the slam also known as visual inertial simultaneous localization and mapping that provides a much more robust Markerless AR experience on devices that do not offer this technology natively so this would apply to phones that do not have air core or a archit so what fuller has done what's up red is to make development simple by allowing you to create one application logic that works on all platforms whether the device is aerco or airtight compliant or not stereo or with mono cameras other than that minor improvements are our support for external cameras for iOS devices Android already has this functionality for external cameras if you are interested in learning more about augmented reality then I have three courses that I've mentioned one is the complete course on AR with the foyer and the other second course is on integrating augmented reality with the Internet of Things or IOT ah and the third is my AR co master class if you want to be an AR expert then check out the links down below thank you for watching I will see you in the next lecture 41 00:03:04,700 -- 00:00:00,000 you 