 thank you my name is Eric Boyd I lead the Azure AI team and I'm here to talk to you about some of the many things that we have got going on honestly there's so many new announcements that we have we're really rushing to cram them into this hour but you know I really love the opening of that video where they say AI isn't coming it's here because a lot of what we're gonna do today is we're gonna talk to you with customers about the things that they're doing to use AI in their business and help really inspire you how can you use it in yours one of the opportunities that you have and how can we really take all of this forward and we start with customers that we're working with we've had so much just explosion of AI over the last several years and it's really every industry every company every vertical that you can think of people are out doing things just to pick a couple of these examples you know ABB is using AI in their workforce management and so they have cognitive services and and they're using the pot platform to really help connect their mobile workers all around the planet much more efficiently and they see a 20% increase in customer satisfaction as a result of that towel is the largest insurance provider in Australia and they've been using Azure ai to Azure machine learning to build more models and to employ them faster and as a result of having these models they're able to really look at many more insurance cases and review them to make sure they're making the right decisions forty times more cases they're able to get through so these and many more customers are working with Azure and really you know driving a lot of value through them and so I want to spend some time talking about how do we think about AI how do we think about these services that we build and what are the principles that we use to sort of bring them together and for Microsoft it starts with breakthrough research at Microsoft we have a research department from in Microsoft research that's been around for 27 years which is longer than many of our competitors have even been companies and the research that they've done has been just nothing short of mind-blowing spread all across the globe we have research centers where we tap into the best minds anywhere we can find them and we've been the first to human parity in a whole slew of AI categories across speech recognition across machine translation across the most recent one earlier this this year the Stanford you know conversational QA tests and we were the only ones to be at human parity we won that contest and so we're really leading the way with this groundbreaking research of how you can use AI to just do incredible and amazing things and then we take that and make that the foundation of the products that we go and build and so we take that research and quickly instill it into the products that we have and at Microsoft were really fortunate we have a wide suite of internal customers of these internal products that we can then use to really harden and prove out that this stuff really works at scale if you look at Bing Bing has millions of advertisers and we make 280,000 recommendations of those advertisers on how they can improve their campaign on Bing ads so should they improve their their bids for a particular keyword should they add more keywords that they should search and really help drive the value to them help them connect with the customers they want more quickly power point designer is rescuing us from terrible power points one slide at a time by really making recommendations based on AI of these terrible bullet points that I probably put together and translating them into really expressive slides that show what are they trying to say what is a much more effective way to communicate this and that's based on AI and learning what's the content that they're expressing and how are they trying to say it Xbox is delivering personalized experiences to millions of users every single day recommending what different things they should use and so we use those you know different foundations of how we can sort of explore this internally with Microsoft and then we invest in other areas based on these principles first and foremost we want to make people productive regardless of the skill level of the tools that you're using we are going to make you more productive on the things that you're doing if you're a novice at AI if you're an expert at AI we have tools that are really going to accelerate your work so you can get more done faster second we have a long history and really the benefit of having worked with many companies Enterprises thousands of them over the years and we've learned what our enterprise is looking for what are the challenge that they have is they need to work at a particular scale or is they need to integrate what their existing frameworks and their legacy and we've really learned how do you put that together to make that work for enterprises and most importantly is trust at Microsoft we have the most stringent set of privacy controls that we operate under really across the industry and we have the broadest set of compliance certifications of any of the cloud providers and we know that customers really value that their data is their data it's gonna be used only in ways that they have told us that they want to use it for and we're not gonna use it for any other purposes other than that that's a critically important point for us and so we pull all this together into the service that we call as your AI and so really as you developers are thinking through how can you bring solutions to market there are three primary areas that we see solutions landing versus an absent agents second is a knowledge mining and third is in machine learning and so I'm going to talk about each of these in turn so why don't we start with apps and agents so if you're a developer and you're trying to add AI into your app the easiest way to do it is to start with cognitive services so cognitive services are a suite of pre trained AI models you know very powerful models that we've built and used for our internal services much of that groundbreaking research showing up very quickly in the actual products within months and so these suite of cognitive services across speech and language and other categories like that really can just plug directly into your application and they combine really well with the bot framework the bot framework makes it easy for you to very quickly create very powerful BOTS so digging into those in turn as we look at the cognitive services we've thought about them in different categories the set of speech services that we offer the set of languages services that we offer the set of vision and then we surround that really with web search but as you've heard Sasha and Scott say today we're announcing a new category called the decision category and really we want to help take it from just perceiving what's still going on in the world to really help making decisions and the first service that we're really excited to talk about here is personalized er so personalized er is a service that really takes all the inputs it's a reinforcement learning based system and it takes all the inputs of what your users are doing to really match them to the content and that is and the experience that is most relevant to them and what they're trying to do and so personalize ER is really easy API for you to integrate with your systems and we've been using it at scale with Xbox you know making millions of recommendations on it and we're now announcing this is available in preview another service to we're excited to announce is ink recognizer really you can bring the natural interfaces of pen and paper directly to your application where you can translate the text and the drawings directly into a digital form and really bring your applications to life that way across speech it really if you saw such as keynote there was a fantastic demo of the conversation language transcriptions service we're really you can have multiple multiple people talking and transcribe it and really even the crosstalk of multiple people talking over that and really get a nice clean translation of a transcription of what the people are talking about and those are the ones we want to highlight we've really been making advances across a whole set of these services we had an anomaly detector as a new service we have neural text-to-speech which creates really natural sounding human voices the Q&A maker has been updated to have much more you know interactions and multi-turn conversations a whole host of our new features coming out all across the board and really when you pull it all together as your cognitive Services is the broadest set the most comprehensive set of services that you can then use to go and build your applications and let's go a little bit deeper on one of them I talked about personalized let's talk a little bit about how exactly that works so in xbox one of the things that we do often is the user gets to a home screen and we want to make a recommendation to them here's a new game that you might want to think about playing or a person you might want to connect to excuse me or an activity or something like that and so we want to make recommendations on that and so you start with all the things that we know about the user the games that they've played their achievements their friends even the time of day and you make recommendations based on what you think you know about them but doing it for one person is hard you now have to scale it to every single user across Xbox so if I'm a data scientist I would start by going and gathering a data set and thinking through what are the features and training a model and let's put it into production let's test it and see how well does this perform at making recommendations and then I'd measure the results and probably the first version wouldn't work very well and so I go back through and I iterate I try some new features and some new data and try this again and again it's a very tiresome process and one of the big changes that we have with personalized err is using a different form of machine learning called reinforcement learning and so here you start by simply defining the goal I want to increase the user engagement and here are the activities that we can recommend to a user and you feed that into the personalized ur system and then you take the same set of things that the user is doing the same activities and feed that in to personalize ER and then personalize is going to use that to make its own guesses its own suggestions of what the user ought to try and then measure the result and calculate a reward function based off of that and it'll do this over and over with all the different users across the service and so even if you don't have a data set say a new game came out that I don't know how well it performs personalize is going to learn from all these activities in this reinforcement loop of all the things that it can do and really make it scale across all of your users and all of your games so that each individual person is connecting with the content that's relevant to them at the time that it's relevant for them and you know Xbox has been doing this for a while and so you know there are a lot of personalization systems out there it's not like it's a new category but by using a reinforcement learning approach we think this is really different and Xbox a 40% lift and user engagement from using this service and so this is a service that we're excited to announce in preview and we think is gonna have a ton of applications all across you know that the industries landscape another thing that we've done a lot with cognitive services is we've really helped customers take it from the cloud to the edge and so you can take our set of cognitive services and deploy them in containers which you can run on Prem you can run it on an edge device you can run it wherever you want to and it's literally the exact same service the exact same models wrapped up and a standard docker container that you can take and deploy and customers are telling us this is really differentiated in cases where they have disconnected service like Carnival Cruise Line is not always connected other places where maybe the date is just too sensitive to share and send to the cloud and so we announced this in December of this past year and today we're announcing that we have new services in containers the anomaly detector and then our speech detects in Texas speech services and this is the direction you can expect us to look to continue to head in with our cognitive services to really make it easy for people to take them wherever they need to additionally on the bot services side of things we really focus on two primary ways that we're thinking about them one is we want to focus on using open source tools and so we've had over 4,000 commits into the Microsoft bot framework from hundreds of developers most of those developers aren't even Microsoft employees which really showcases we've got great community involvement on this project and then on the other side we want to make it really easy to deploy and manage these BOTS and we see that by seeing we have 35,000 active BOTS and we're seeing 3,000 new BOTS show up each week really showing that it's getting even easier to create and manage these services but we're not stopping there we have a bunch of new things coming there as well we've got the bot framework 4.5 SDK which adds adaptive dialogues which makes it much easier to do multiple conversation multiple turn conversations and sort of sub workflows within a conversation as well we talked about the open source virtual assistant solution accelerator which really shows you how do you put a virtual assistant together and now we have skills templates making even easier for you to add your skills to your virtual assistant as you're deploying it and so it's great to talk about these different things that we're doing things like the the bot development framework but to really pull it together it's great to see it with a customer and so we'll do that all throughout this is look at what our customers are doing and one of my favorite customers is La Liga La Liga does is the largest premier league soccer team in in Spain with some of the biggest soccer names in the world and they've been using our cognitive service and let's watch this short video to see exactly how they're using them we are very lucky to have fun if we sum the followers in social media for clubs players and illegal we reach 1.6 billion our goals are to be the first choice of entertainment for the fans worldwide we decide to party Microsoft for technology developing a huge digital ecosystem comprised by mobile labs mobile games websites and digital assistant based on boats and official entities Microsoft plays a key role we are working with them as data platform help us gather all the information that we get from the fans in a unique place we use Microsoft Oracle to do that we use also assure both cells to host the vault and we use a ship cognitive services to understand what the fans want especially the speech and language understanding we want to have one global product that will cover different fans from different parts of the world being able to trigger what the fans want in the right moment it's the most important thing we have been able to increase our social media followers but our new safety person technology is helping us to drive the Brown near to the fans this is key for our success and our growth Microsoft has provided the tools to improve our produce and services for our fans and so I want to thank you and I want to show you a little bit more about that we really we invited Lionel Messi to come and give this next demo but apparently he was busy this weekend so instead we've got william mendoza who's gonna come and walk us through exactly the products that la liga is using will la liga is the most followed sports league in the world with over 1.6 billion fans while he gets consistently looking for new ways to interact with their fans and they're doing just that with a legal assistant the assistant allows fans to experience the liga across multiple platforms let me show you an example so here I am in mobile I mean my mobile here on skype and I see I'm greeted here with a menu of different things I can ask it but in addition to touch I can actually use natural language natural language my voice because it's powered by a language understanding so let me show you an example did Barcelona win on Saturday so much to my dismay I noticed they didn't win but that's ok I can look at the highlights to understand a little bit more and get some context on the match I can also get statistics as well as player lineups and the moment I see that the starting lineup really wasn't involved I got a little bit more ok with it now you notice that I use English but that's ok too because natural language processing is also available in Spanish through language understanding models so let me show you an example cuando si look see what at either they say V yeah so I've asked it when if suvir's next match a different team and they're playing Atletico on the 12th of May but what's also interesting is that not only does it recommend where I can watch the match but it also tells me that they played before earlier in the season so now I'm gonna ask about that and I can get highlights and other things so now I could have gotten all this information through standard web search but what's interesting here is through one place I got one consistent experience now La Liga is a global brand and so they're looking to be wherever they're their users are and so in addition to this this same bot was deployed as a skill on Google assistant let me show you that experience talk to La Liga and so I've asked Google assistant to talk to the Liga and it's bringing that skill and to this chat so I'll ask it who's the best player in the league so this could be a controversial take but most people will probably assume that it's a specific player and you're probably right however what's interesting here is there's a nuance to answer and this answer is actually essentially they considered both occult scorers as well as gold keepers and so they take into account statistics and you can see with 0.72 goals per match oblak is actually another recommended player to investigate so now I've showed you how this application works let me show you what the reference architecture how it was built so you can see here the bot the assistant was built with Microsoft bot framework it's an open source SDK available on github as Eric mentioned you can get started today additionally with Azure bought service you can host the bot in Azure and do a couple of things one is you can integrate natively with some of those cognitive services here you know I mentioned language understanding but an interesting scenario is content moderator so if I were to use profanity the bot can give me a yellow card additionally you can also natively integrate with the majority of these channels here and so you noticed I mentioned Google assistant and some others down the pike so thank you very much and Eric thanks thanks will and next up I'd like to invite someone from who works at La Liga who I think has probably the most amazing job out there the director of innovation working with La Liga so Minerva if you could please join me so welcome and yeah why don't you tell I mean you sound like you have an amazing job tell us a little bit about what you do well in fact I'm the director of innovation in La Liga and La Liga we are constantly thinking about how technology can help us to develop new ways to live football for our fans and now we are focused basically on fun knowledge with the help of the details for platform and the analytics platform that we are developing with Microsoft and also we are focused on fan engagement we are developing mixed reality and virtual reality content and also applying artificial intelligence for better fun knowledge and to improve our business decision making process it sounds great and then of course we'll walked us through you know sort of the assistant tell us a little bit more about how you know a dream machine Asher's AI really helped you with that yeah of course as you could see in the demo before we not it's a trend of people globally using voice enabled devices and assistant to communicate with different brands so to support our mission our starting to be top of nine of our fans and to be the first choice for entertainment for them we develop La Liga a virtual system based on Azure community service from Microsoft fans can interact with the assistant and asking in different channel in Skype and also in Google assistant and asking result for the matches Alex tanning aesthetics is for the players and also viewing video highlights we develop the bath engine in Microsoft bot framework and then we were able to introduced Asia about services to host the debod but also to a scale it which was very compelling to create a digital about capable to to release it globally and we are planning to deploy this but in different channels soon because what for support up to 11 different platform we also are using Microsoft language understanding service HR language understanding and to solve some things like the term for example toll keeper have different assumption and different ways to say in depending on the spanish-speaking region so we are using language understanding to solve these kind of things that's perfect great and then tell us about you know you do this to help try and connect with your friends what's the impact it's done how has this worked for you well Lolita has a lot of fans and globally 14 million people setting this La Liga stadiums last season and also 2.7 billion people watch La Liga matches on on TV but also when we think of fans we think all those people that engage with our product through digital channels also we have 74 million people following in or in social channels and we are increase our fan base in 30 percent in the last year's and we hope to continue growing and this kind of platform a multi-platform capabilities help us with this woody goals that's great well I really look forward to continue to work with you and and maybe next year I can become one of those 14 million fans that attends in person at a game but thank you very much for coming thanks for sharing with us so we talked about apps and agents the cognitive services in the bot framework and and now I want to talk about knowledge mining the the next solution area so we think about knowledge mining what we're really trying to solve is these customers have all this data locked in all of these different formats in PDFs and JPEGs and invoices that get scanned in and all these different things and they can't unlock the value in it and so what we do with knowledge mining is we take that data and we ingest it into the cloud and then we run those same sets of cognitive services that we just talked about we run OCR against it the entity extraction the key phrases the P locations and pull all that together into a graph and we build this graph that annotates all the different documents that the users have and then we take that graph and we make it available in Azure search and so we call this process cognitive search and so we're happy to announce that this is now generally available and the new generally available version of this is 30 times faster than the version that we had in preview and so really excited about the capability that you can do with this and you know this the one of the great things about this area is that not only does it work with documents it works with all kinds of different media and one of the most interesting ones to talk about is the work that we've done with the Metropolitan Museum of Art in New York the Met and so let's watch a video seeing what the Met has been doing with with cognitive search the met is not just a place that you visit but it's really a great service to an audience all around the world the Met receives 7 million visitors through its doors annually however we're interested in reaching the 3.9 billion Internet connected people all around the globe the Mets open access collection seeks to make the collection the most accessible discoverable and useful on the Internet there's a lot that goes into creating a work of art there's information about the artist the artist inspired by why was an object created so all that information all that data about an artwork really helps you to get a fuller picture about why it was made our collection spans 5000 years we have art from every culture so just the sheer size of our collection makes it difficult to work with subject keyword tags enable us to find connections and patterns across eras across artistic movements now we're doing work with AI projects like using tags with cognitive search now that we can leverage cognitive search we'll be able to tag the whole collection and a much quicker pace it's been very exciting to see visually similar artworks and tag prediction through AI we can see things that we didn't have the possibility to see with our naked eye there are patterns there's information that are discoverable connecting art from one piece to the other we're really able to understand things that we couldn't possibly have dreamed of [Music] and so to look a little bit closer at this I'd like to invite Kate up to give us a demo of some of the things that we just talked about Kate hye-won so I'm gonna walk you through what we've been working on with the net and it's called the art Explorer so I was actually at the filming for the video you just watched right there and I really loved the painting of Washington Crossing the Delaware and I was in New York then but I want to take a closer look at it now so I had the art detail page for Washington Crossing the Delaware on the art Explorer and one of the core challenges when you're exploring art especially in its digital form is the fact that this is unstructured content these are JPEG files of extremely intricate and sophisticated pieces of work that have a lot going on that's not explicitly written down anywhere so that's why we've applied a vision api's like object detection that are identifying what's going on in this image and generating additional tags that you see here on the right making it searchable based off of those parameters and some of these like War and Army are actually quite abstract concepts when you think about it so this is helping me navigate all this content by what I'm visually looking for but once I've landed on one piece I might want to explore other dimensions as well and I can do that if I scroll down to this network graph view that you see here and this is serving up other things in the index like the time period and the medium giving me a bit of a left-to-right view of other things that might interest me so I'm gonna try jumping to something that's at the same time period and it turns out to be another image of George Washington but it's a sculpture this time what I want to draw your attention to though is a visually similar art panel that you see here on each page this is identifying other similar pieces across the collection based off of vision algorithms that are studying the overall pattern and composition of this image it has nothing actually to do with the object tags the titles or anything along those lines so it's quite interesting that just with that is able to pull up other items that happen to be marble busts and let's just try looking at one of them here so this piece in particular is made by an artist named and Moneo Lewis and we have that core bit of information from the Metz metadata but what we're able to do is enrich it further with this panel here bringing in our knowledge of the world with Bing web guys to generate a description from Wikipedia so now I'm able to see that Mary had ammonia Lewis actually was the first african-american and Native American woman to gain recognition in the art community as a sculptor and that's quite an interesting insight that I personally not as an art expert I'm not sure if I would have come across as myself so cognitive search is generating all this new knowledge not on this one piece but at scale across the hundreds of thousands of pieces that are in the Mets open access collection and that's what's creating all these different insights and patterns and relationships between pieces that didn't exist before and that's really enabling a great user experience and that's really important because you don't really know what's going to inspire you until you're actually able to see it and my inspiration first started me with a painting of American hero but AI landed me here on a sculpture that was made 200 a hundred years later by someone else who turns out to be an American pioneer so I hope this is giving you an idea of what's possible if you're able to deeply understand your content at scale was something that cognitive search and for reference this is how the art Explorer was built it was using Azure search to first ingest and that's open access collection which is a series of images and metadata and then enriched at using the cognitive search capability within a sure search this is creating a search indexes then explorable via Azure Web Apps thank you and back to you Eric [Applause] so what another request that we get all the time from our users is hey this as your search capability sounds really great but what I really want to do is use that data set that you created for applications outside of search and so what we're now happy to announce is a new capability within search where you can bring this knowledge store into an azure store and get it in tabular or in JSON form the exact sort of extreme things that we and that we extracted the annotations and then you can come up with new scenarios around them you could take them into power bi to sort of do new dashboards on them or to make predictions with Azure machine learning or or otherwise bring them into your application and so to show you a little bit more about how this works I'd like to invite Brian up on stage to show us how we can use this knowledge store Brian thanks Eric one of the cornerstones of our knowledge mining capabilities in Azure is the cognitive search capabilities of Azure search Kay just showed you the incredible power of cognitive search in the Met demo so I want to show you the next chapter of knowledge mining using cognitive search today about half of our cognitive search customers have completely unstructured data in the form of office documents like word and PDF the other half actually have a mixture of both structured and unstructured data and things like sequel Kosmos or even CSV files and what's cool about cognitive search is no matter what type of content you have it actually just works the same so for this demo I'm actually gonna use this CSV file which contains a mixture of both structured data over here on the left as well as unstructured data here in this improved field which is actually customer feedback about Microsoft customers experience with our support teams so now the cognitive search can unlock scenarios like analytics I want to show you how powerful and easy it is to use AI to turn something that looks like this into a full analytics experience inside a power bi to get started you just go into the Azure search portal and you select import data now as your search supports almost all major data sources inside of azure and file formats in this case I've actually already uploaded the Microsoft feedback so let's go ahead and add cognitive search to that now you might have noticed this notification up here in the background it's due technically schema so that it can actually suggest enrichments and an index shape for me so the first thing we need to do is attach our cognitive services or we can keep it free if we're just trying it out next we need to add enrichment now because I have a mixture of structured and unstructured data I actually want to go off and select this improve field which contained that feedback for enrichment granularity level I'm actually gonna select sentences because I want the finest grained level of detail on these enrichments now when I check this box all of these entities and key phrases language and sentiment will be extracted across all the sentences in all of the feedback that I selected but this is actually just the basic experience there's more skills and extensibility that US developers can tap into and you can learn about that right here from the portal now if I stopped here what this would produce is a cognitive search index that you could use to build an experience like you just saw with the Met demo but as a very Eric mentioned our customers are asking us to do more with these AI enrichments they have more scenarios that go beyond search so to enable those scenarios like analytics or machine learning or even consuming them in your own application you can now save enrichments to a knowledge store this allows you to attach an azure storage account and project these AI enrichments into blobs and tables in new hierarchical and relational shapes in the case of table projections we'll use a default shape that will produce four tables and contain all of the enrichments and create relationships in the case of blob projections will produce one JSON file per document that will contain all of these enrichments now I've actually already run all of this content through cognitive search so let's take a look at this content in generated in tables using power bi so as your tables are not a relational data source like sequel so when cognitive search projects data into tables we actually dynamically build relationship IDs so that things like power bi can understand them here you can see reviews have collections of key phrases they also have collections of sentences and entities and they have all of the enrichment sprinkled across all of that content now I can build an azure data power bi dashboard off of that data and you'll immediately see we can do aggregations of the people the locations the specific sentence is extracted in this center table right here you'll see that we can visualize the average of review sentiment by month and by language highlights an important insight right here on this blue line which is actually that we need to improve the performance of our customer feedback support in German but I I didn't even know that this file had multiple languages in it until I ran cognitive search so there's no way I'm getting that insight without that natural language now when you combine these air enrichments with power bi natural language capabilities you can ask really powerful questions like show me the counter reviews by-product and sentiment polarity and what this really shows is the power of AI across the entire Microsoft stack to enable you to understand your data now I've just shown you one simple analytic scenario but the new knowledge mining capabilities of cognitive search can unlock any scenario that requires your data to be transformed into structured knowledge so go get started with cognitive search today thank you so another area that we hear that companies have a lot of documents in is forms and so you know you think about every place that you go that you fill out some form be it the dentist office be it invoices be it receipts that you have and so how do you take all these forms and get the digital information out of them and so today we're happy to announce form recognizer a service where you can start with basically any type of form and quickly extract the information from it in a tabular or JSON structured form and so you just sort of walk through a little bit more of how this works we've worked with Chevron on their invoices and so Chevron needs to give us a set of at least five invoices that then we'll take and sort of learn hey how is this form structured and what is the different information in it and then we can extract it out in a tabular form or in JSON to really pull this data out so they can then take it wherever they need to take it and deploy in other forms and so we have thousands of companies that we talk to that have so much data locked up in forms like this and one place that we've been working with is with financial fabric and and their customers Starbucks where they have to a whole bunch of data that they're processing around there in their Treasury Department so I'd like to avoid Morgan than super on stage to come talk to me about that [Applause] so yeah why don't you guys tell us a little about yourselves well what exactly do you do sure thing so Morgan Collins Starbucks I work on the treasury side typically in investments but as a business easier actually worked with data quite a bit so no real coding knowledge don't ask me to code a darn thing but still like to work with data when possible thank you Eric I'm subra Bo's CEO furniture fabric we are a New York City FinTech provide data hub services to the 74 trillion dollar investment management industry our clients receive tens of thousands of PDF documents from where we have to extract data and empower business users like Morgan and so why don't you guys tell me a little bit about how you've been using form recognizer sure so being in the dirty world of business users we deal with a ton of unstructured semi-structured data all the time and and frankly data is kind of trapped there every quarter a member of my team would look at two forms to PDF side by side and visually reconcile to see if there were any differences and that's difficult manual out stearic yeah it's it's not great and so form recognizer and tools like that have really helped us unlock a lot of process improvement and have helped save us a ton of time so earlier we used to write code ETL code for every one of this PDF form type which would take three weeks of development time with form recognizer it's very simple we provide five document of the same type and then let the engine learn and extract data as JSON from there so our set-up time for a new form is now a few minutes of data science activity as opposed to a few weeks of ETL development which no one wants to do by the way so that is 90 percent productivity gain to go from document to insight sounds fantastic and so I mean this must be impacting the way that you guys worked in tell me a little bit more about that absolutely I mean as a business user with zero coding skills I wouldn't be able to take this data on myself and not having to go through a tech cue and to beg and plead and hustle a bunch of developers to actually write that ETL code I'm able to actually get insight from these documents and be able to run that analysis and do some improved comparisons too I mentioned how it was an extremely manual and iterative process well now we can actually systematize how to review data between periods and automate that and improve our own controls so farm recognizer gave us a way to go from document to insight without writing an ETL code practically zero eto code so back in few years ago when I was city of Ur Credit Suisse asset management we had 50 ETL developers whose job was to write code to extract data from documents at financial fabric we have zero every morning business users went four to five hours which is 60 percent of their time to get data from different documents copying and pasting all different forms we have reduced that to zero we empowered users like Morgan to focus more on insight and analytics of the actual data as opposed to getting the data we believe form recognizer is a revolutionary technology in the AI stack which is going to change data and how insight is derived from document in the business why that's really exciting well thank you both really appreciate working with both of you and looking forward to all the great future collaborations will have great thank you Eric for having us here okay so we've now talked through two of our solution areas let's dig into the third one which is the machine learning area and so an azure of course we have the full stack of everything that you need for machine learning from the pre trained models that we've talked about all the different tools you can use the frameworks the productive services and the infrastructure to really make it all come together but I want to spend a little bit more time digging into the Azure machine learning service itself when we think about the Azure machine learning service there are three areas that we really focus on the simplify how we can we can simplify machine learning for developers as well as the end-to-end lifecycle management and how we can make that easier for people as well and we do all of this on this foundation of our commitment to being an open platform so let's talk a little bit more about each of these let's talk about how we are simplifying machine learning we've announced three things this past you know as a part of this this build announcement about how our simplifying machine learning a year ago we announced automated machine learning this is a capability where the machine learning will go and create the model for you going through all the iterations that a data scientist would do well now we've added a UX on top of it a UI on top of it making it even easier so there's literally no code to write you merely take your data upload it into the automated machine learning UI say this is what I want to optimize for and it goes and produces a model for you that go against that me really making it simple for people of all skill levels to go and create AI models for their particular business needs the next thing that we've done is we've taken the the Azure machine learning service and added a visual interface to it and so now in a drag-and-drop manner you can sort of string the different components of your pipelines and your different workflow together and so in AI there's a lot of pipelines step1 step2 and how the data flows together and having a visual experience to see how all of this connects makes it much simpler for developers be they you know again skilled developers who are very experienced in this in data science what people who are much newer to it and are much happier to sort of have a drag-and-drop and visual interface for it and the third thing that we're announcing is that you can now from your Azure machine learning workspace take the work that you've already got in there and directly go to a Jupiter notebook and so you can spawn book this is the probably the most popular format for data scientists to manage and edit and and develop their work in and you can do this directly from the workspace connected it directly to the data and the models that you already have in there so we're really focused on the things that we can do to make AI simpler and machine learning simpler across the board regardless of your skill level where the tools you're using or how you want to work the other thing that we've been spending a lot of time focusing on is its end and lifecycle management and so most people have heard of this concept of DevOps how developers are constantly deploying and constantly you know managing their code well an ml there's a different concept around ml ops because the things that you do are slightly different it feels the same but it's not what do I check into source control is it the model is it the data how does all that come together how do I collaborate with the data scientists and the developers who often are very different personas and so what we've done is we've taken what looks like a fairly standard DevOps workflow but let's walk through how a data scientist would plug into this the first stage is collaboration virtually every environment every company out there uses get to store their company's code and the developers will use get and so now as your machine learning is going to directly integrate with your get environment to bring your models your data and all of the environment that you need around that in get and make it easier for your data scientists collaborate with your developers on that then I train the app and now I need to validate it I need to make sure this after this model actually does what I think it should do and so Azure machine learning has a profiling and a validation service to dramatically simplify that phase of it then the next thing I need to do is I need to deploy the model and so again Azure machine learning is gonna help you package this in a standard docker container making it simple to deploy on the cloud on Prem or to the edge and then I need to start monitoring this because one thing that happens a lot is the data changes what I trained on looks different than what my users are actually experiencing on a regular basis and so I need to do to instrument the model which our machine learning will do automatically for you as well as I need to make sure that I'm analyzing it to see how is this changing over time and then the other thing I may want to do is integrate it with Azure DevOps as your DevOps is already the leading place for people to do DevOps workflows pipelines and so now there's an extension for an agile machine learning extension for DevOps which plugs directly in and enables you to trigger workflow and as your DevOps based on changes in your Azure machine learning model and the last thing that comes with this is the audit trail often you need to say hey this model made a prediction seven months ago and I need to understand why it did that either for legal or for compliance reasons and Azure machine learning is gonna pull all that together and make it really simple for you to understand hey how what was the state of the world when I put all this together so really trying to embrace this end and workflow of all the things I need to do when I'm building a machine learning model and dramatically simplify that in addition to focusing on the ML ops side of things we're also trying to help people with really accelerated hardware we've been the only people to really focus on FPGAs to accelerate the inferencing and serving of their models and so we're happy to announce now that FPGA model serving is generally available for the vision models that we've had in in preview to date and so now you can run you know transfer learn models faster than any other service out there and cheaper than any other service out there so we bring the simplified machine learning and the end-to-end lifecycle management and it's all based on this concept of an open platform and so we want to talk about some new integrations that we've done new offerings in this space so one is ml flow ml flow is a API an open source API that really talks through how you manage your machine learning process the workflow all of the lifecycle of it and this is an open source API and this is implemented directly in Azure machine learning so you can call these exact api's directly in Azure machine learning and get the service tracking and everything that you expect expect to come with that the second is the onyx runtime onyx is a in a file format that makes it really easy to exchange models from say tensorflow to PI torch to other different formats that you may want and it runs really really fast and so what we've done with this is we focused on telling a developer you just need to focus on running it in the onyx runtime and you're gonna get the hardware acceleration for free and so in the onyx runtime which is an open source package and you can take and deploy anywhere now integrated in videos tensor RT libraries as well as Intel's n Graf libraries so hardware acceleration is going to come directly from it and you don't even have to think about which one do I want you merely just you know plug the system in and run with the Onix runtime and the third thing is as your open datasets these are a new capability that we're announcing these are highly curated data sets that are available to you in Azure that you can then join with your existing data to really simplify and then augment your machine learning process you know data sets the of different things to really expand and really flush out how all of the data could come fit together and so all of these different things that we're announcing an Azure machine learning there's a whole lot to talk about but to really show it again it's easier to see with a demo and so we've been working with Walgreens boots Alliance and so they've been they have all these different categories you know in their stores from you know Beauty to Fitness to all their different products and they wanted to understand how they can build marketing campaigns to target all their different users and so I'd like to invite sonal and Shivani onstage to walk us through how that can work thank you Eric so Walgreens boots is a health and beauty retire and pharmacy chain in the United Kingdom this is their marketing campaign dashboard as you can see they have nearly 2,500 stores and a large customer loyalty program that serves up targeted offers to shoppers in order to drive up purchasing let's see how boots leverages Azure machine learning to scale their model and model deployments as a developer that's new to machine learning I'm always on the lookout to simplify and streamline model creation because this is usually a pretty tedious and iterative process it's no wonder that so many of these campaign models still need to be built now there has to be a way to simplify this there is let's go over to the azure portal Here I am in the dashboard and I'm going to show you quickly how automated machine learning can simplify this process by building lots of models in parallel and then intelligently selecting the right models at the right time and then tweaking Hyper parameters appropriately in order to get to the optimal outcome let's see this in action right away in Azure machine learning I'm now in the new automated machine learning user experience and you'll see that it's relatively easy to set up an experiment quickly in just a matter of few clicks I'm going to set up my category based propensity model I'll select the target compute which will auto scale on the fly to meet my experiments needs it will also automatically connect to the storage accounts associated with my subscription I can also pull files from my local drive on the fly in this case I'm going to go for the CSV file because it has the information about the fitness and nutrition category of products that I'm interested in making some predictions on and you'll see here that automated machine learning has sampled the data set so that I can easily review and explore it I can include or exclude columns that I want the model to consider and I can also profile the data and see some summary statistics so what do you think this data is going to tell I think that age is going to have a big role in the purchasing affinity for the fitness and nutrition category of products but let's see if this is actually the case let me finish setting up my experiment I'm going to set this up as a classification task because I want to understand if customers will or won't purchase in this category of products I'm also going to select the fitness and nutrition column so that I can quickly get my experiment started now with the press of a button automated machine learning is going to select the runs from millions of possibilities that show promise so that instead of weeks or days I'm going to now have my model in minutes in fact let's take a look at a run that just completed a little bit earlier you'll see here that automated machine learning has picked out the models that have the highest accuracy at the top of this graph I can also drill in a little bit into a specific iteration so that I can see some key metrics associated with this run and decide if this model is right or not for me and I did all of this without writing a single line of code but for all of your data scientists and developers in the audience that prefer a code first experience you can also use automated machine learning in your favorite notebooks or IDE s so here you'll see that notebooks are now fully integrated into the authoring experience for Azure machine learning let's get our notebook running I'm going to switch to this notebook that I just ran a little bit earlier to show you that I can do everything in the notebook that I just showed you in the automated machine learning UX I can set up my automatic task I can see iterations and I have also enabled model explained ability now this is important because it gives me transparency into how the model was built and what features influenced prediction and you can see here that while age was a big factor in the purchase affinity there were other features like the number of categories purchased gender etc that pleed a much bigger role this is the power of a data centric business my model is now ready let's see what it takes to put this into production and for that I'm going to call on my DevOps engineer great thank you right so for organizations like Bhoots the motto creation process is just one part of the challenge Meeta update these models to reflect the data changes in customer preferences and trends so we really need to scale out this model creation process for the hundreds of categories and thousands of stores that boots has so what we can do here is leverage Azure machine learning pipelines so what I'll do is basically take the experiment that Stone will create it and turn it into a reproducible format what I'm doing here is running a four loop through each of the categories so I'm taking in data relative to that category training and outputting a model so at the end of this four loop I'll basically have an optimized model for each of the categories that boots has that's great but how do you put this and operationalize it so I've bought some genera my role here is to quickly package the model test it in an environment and then deploy it out into productions of the most updated model running so what we can do here is leverage the power of Azure DevOps and Azure machine learning to automate and accelerate this process so here is my as your DevOps project so what this basically does is help me collaborate manage the development and deployment of my software application what I've done on the background here is import on my code which is my training testing and deployment scripts for my github repo and I've also installed my new machine learning extension to help me run some of these machine learning tasks so first I'm going to start creating my pipelines here is my build pipeline it's a continuous integration pipeline where I'm automating the process of training and registering my model so at the end of this stage I will register my optimized model for all these categories and Azure machine learning portal so here I can see where this model is going to be deployed out later on this pipeline it's great I have this model I've registered it now at the end of this pipeline it'll trigger this release pipeline which is basically automating my deployment process it's for example every time I have a new version of this category one model it'll trigger a deployment process where I'm packaging the model into a docker container and then in my test environment so what's worth quality gates do you have in place right here great questions so what I'm doing here in my test environment is taking that container and running it on as your container instance and then I'm running my model against some test input data to make sure that it's functioning as expected now if it passes this quality gate the deployment pipeline will continue and I'm going to deploy that same container out into production now this is really great because every time I have data change or I'm updating my training scripts all I have to do is a final code commit which will then trigger these pipelines so I'll register a new model and then get it out into production as quickly as possible so what's also really great about integrating algebra XI learning here is that I have visibility into all of the artifacts and assets I created throughout this pipeline so I have my experiments my models as well as all the deployments that I just created in a CI and IKS it's not have visibility from the experimentation process all the way out to our deployment process so let's take a look at the reference to architecture to get a final overview so in summary basically what agile devops does it lays down this framework to turn your machine learning scenario into a CI CD process agile machine learning then helps you manage and track all these artifacts that you're creating as well as accelerate each stage of your machine learning model lifecycle and you also saw how automated machine learning makes it so much easier to build models faster and how with model explained ability you get transparency into the model so that machine learning is no longer a black box exactly by leveraging the power of our machine learning and Azure devops it's never been easier to take your model into production over to you Eric thank you both that was great I mean it's really powerful to talk to think about how you can just sort of script a whole bunch of different model creation using automated machine learning with Azure machine learning pipelines to wrap it around it but don't just take my word for it I'd like to invite Dan from Walgreens boots to come and tell us a little bit about how they've been using that in their business Dan okay hey so yeah tell me a little bit about what you do at Walgreens boots sure I'm Dan humble I'm the chief data analytics officer for Walgreens boots so I look after all the data scientists and the folks look after the data integrity for us and so I mean we just saw the demo of how Azure machine learning has been you know working with you guys tell us a little bit more about how you've used it sure so as you saw on the demo we've used it in our boots business which is the UK portion of our business to drive offers directly to our customers so these are personalized offers the kinds of things that you receive through email through app or even through traditional routes like mail we've starting to use it in various other aspects of our business and also bringing it to drive offers in the United States through Walgreens as well and so has the the toolset really helping accelerate your development so the the the really interesting thing that I found was when we first started the journey with machine learning I was expecting it to improve the offers and the performance of our offers somewhat you know maybe by about twenty or thirty percent but what we found is a much more dramatic acceleration of our return on investment so in some cases the model is improved by something more like 200 or 300 percent particularly for more prestige beauty brands and things like that which was great interest to us and also to our supplier base as well and a lot of this too is focused on trying to help make your developers more productive how has that worked out for you that's been amazing so the what we found is that the you know some of the simple things what you saw in the demo so the ability to share notebooks and that kind of stuff as meant that the data scientists armed able to more work much more productively we've also used order we're now to build models out so what we'll do is build a model for one category so we'll build it for something like the benefit brand or the clink brand and then we can use also ml to generate those offers for other brands that look very similar when we've tried to use it to sort of build a model from scratch it performs pretty well almost as well as if you're human build it but where we found it's quite powerful was in replicating our across different categories or new brands where there's something already in place to build upon well that sounds great well thank you very much for sharing with us and we look forward to continue working with you thanks Eric so those are our three solution areas you pull them all together and it really makes a jaray I the best place to build and do AI across any different place and we've really looked to prove this out with our customers that we've talked about but there's one more customer I want to talk about it's a little known fact if I hadn't gone into computer science I probably would have gone into particle physics but I'm not sure I was bright enough for it but we've been working with Fermilab and so let's see a video of some of the things that they've been doing is they try and push the envelopes of science and how are your machine learning is helping them [Music] what is the origin of our universe researchers at the Large Hadron Collider the world's largest particle accelerator are trying to understand why anything in our universe every bit of matter exists at all the LHC smashes protons together as they travel a 17 mile loop at close to the speed of light producing more than 500 terabytes of data every second researchers then need to filter that raw data in real-time to isolate the most interesting events scientists at Fermi National Accelerator Laboratory serve MIT the University of Washington and other collaborators working together with Microsoft have prototype their data analysis problem on Azure machine learning and demonstrated significant gains in speed with the ability to accelerate the building and training of sophisticated models Azure machine learning has the scope to handle the LHC's zettabyte sized data challenge soon it may help researchers identify the handful of collisions among millions that might give insight into the moments after the Big Bang [Music] so it sounds amazing but I'd like to invite nan out who's an actual particle physicist to tell us a little bit more about that nan thank you very much so computer science class there were a little too easy for years so yes tell us about yourself what do you do right so I'm a particle physicist I work at Fermilab which is the u.s. is a primary particle physics laboratory and I'm a collaborator on the compact muon solenoid experiment which is at the CERN Large Hadron Collider which is the world's highest energy particle collider and so I mean you guys are really pushing the envelopes of science like what are some of the things that you guys are exploring with this right so I mean we try to use the LHC to really understand fundamental questions about nature so we discovered the Higgs boson in 2012 and so the things that I'm interested in are sort of using the Higgs to really understand some of these these mysteries that are still outstanding so for example dark matter so dark matter is is all around us it makes up 80% of the matter in the universe and we don't know that much about it and so I want to understand if maybe the Higgs is somehow a portal to this Dark Sector it's this this thing that you know it lets the dark matter talk to the regular matter another one is the matter antimatter asymmetry so there was some some thing in the early universe that created some asymmetry between matter and antimatter or else it would all of it just annihilated and we wouldn't be here it's all pretty glad that didn't happen right so you know tell us about how you're using machine learning and as machine learning in this right so so actually LHC scientists have been using machine learning for a while now but we really wanted to sort of capitalize on this on this boom and so we use it from things like automatic the way we operate the experiments to filtering this data and also what you heard about in the video which is accelerating our computing because we have huge amounts of data and so just as an example so we we collide particles every 40 million times a second we get thousands of particles hundreds of thousands of detector signal every 25 nanoseconds and we want to filter that data and so we have machine learning algorithms which are really trying to isolate for example the Higgs signal and the better we can isolate it the more precisely we can understand sort of its properties and how it relates to some of these fundamental questions well it's super interesting and yeah really hope you help understand why there's stuff and not not stuff and that's all so thank you very much with that thank you really appreciate it so that concludes my talk if you're going to take a picture of one slide take a picture of this slide we have a ton of other talks and sessions that we're giving as well this github link has links to more information about many of the things that we talked about the demos the different services as well we have a huge section on the expo floor where you can go and learn more about all these different things so thank you very much for your time and I look forward to working more with you on Azure AI thank you [Applause] 