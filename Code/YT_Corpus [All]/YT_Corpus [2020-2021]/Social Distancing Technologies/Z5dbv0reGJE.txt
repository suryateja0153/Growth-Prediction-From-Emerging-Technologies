 Manufacturing creates a lot more than just physical goods it also creates a tremendous amount of data join us as we talk to Oden technologies about how they built a system to help manufacturers analyze their data using IOT on this episode of staff chat John thanks so much for joining us today tell us a little bit more about what Oden technologies does mark thanks for hosting me today Oden is a company that focuses on the Internet of Things for the industrial sector with the specific mission of improving the efficiency of the manufacturing process for example we have customers that produce you know you know 500 million to a billion dollars worth of product a year with high scrap rates and by leveraging the Oden platform they're able to reduce as one factor the amount of scrap material that they create in one case we've had a customer that has managed to reduce their scrap levels from 23% down to 9% after implementing the open solution that's great so it kind of captures a lot of data and then can somehow relay that back to the customers what does that actual architecture look like a big part of our architecture is around managing the data that we've collected from the users and making that data available and actionable the starting point for all of this is of course the collection of data we start with a device that sits on the factory floor which collects data for the PLC's that data then gets sent up to the cloud using Google IOT we pull the data off of Google ID using pub/sub we process that data in real time we run whatever learning models we have against the data we also move the data over into a time series database that sits on top of BigTable as well as into bigquery in addition to collecting data from the machinery we also collect data from other sources for example the operators through an operator interface that we on the factory floor if a machine is down or there's a production problem the operator will be able to add data or add annotations that allows us to then go back and do further analysis and that comes back in through the cloud as well much of that data then gets stored into Google sequel and we can then pull that data out as well using bigquery if you could kind of go back to when you started were there any like decisions that you think you might change in hindsight there are always decisions that we would make differently one example is our choice of to use a graph database to represent the entities that sit on the factory floor at the time that the decision was made the observation was that the factory floor does not follow a strictly hierarchical model and the way that you want to view data on the factory floor does not follow a strictly hierarchical model you will sometimes want to organize your data by factory line you will sometimes want to organize your data by for example type of type of machine we decided to use a graph database at the time we thought that it would accelerate our development efforts and it did however as we have scaled up we have started to run into the limitations of that graph of the graph database one of the areas of concern is the fact that graph databases tend to follow the schema Blas and so what we have found is that you know sometimes engineers will introduce new features and because there isn't a lot of structure you know by introducing new features assumptions that are inherent in the stimulus architecture end up creating issues down the road a second choice that we made was to use an abstraction layer on top of BigTable to support our time series database the choice of BigTable than great big table scales wonderfully and more recently Google has added replication capabilities and that has been highly beneficial to our you know redundancy strategy so we feel they were much more reliable however at the time we had a choice between a few different abstraction layers and the abstraction layer that we chose has reached somewhat of a dead end in the public community which means that it is not being actively developed or worked on by others and so features that were missing at the time remain missing while other abstraction layers have moved forward if we were to start again today we would probably use TS DB and I fully expected over the next 12 to 18 months we will be making a move to using TS to be as our abstraction layer thanks so much for coming in and telling us about how you kind of build this architecture to scale thank you for hosting me today and I really enjoyed our chat try setting up your own data pipeline by using this hands-on solution that walks through using dataflow and bigquery thanks for watching and make sure to subscribe for more great Google cloud platform content we'll see you next time on stack chat [Music] you 