 [Mike:] Good day everyone. Here we are at the beginning of our live webinar and I'm your host, Michael Lesiecki. Our topic today is Adapting Evaluations in the Era of Social Distancing. Let me remind you, that the webinar will be recorded and you'll automatically get a link to the recording. And thank you for joining today. Just a few comments, many of you know the Adobe system. But, please use the chat window to respond to our questions and to ask us questions as well. Let's begin our webinar and we're being recorded right now. We'd like to thank ATE Central. the information hub for the National Science Foundation's ATE program for making this webinar possible through their webinar hosting service. You can find out more about ATE central at atecentral.net. This webinar is brought to you by EvaluATE. EvaluATE is the evaluation hub for the ATE program. EvaluATE advances evaluation in the ATE community by offering training's, cultivating a network, researching emerging topics, and collecting data about the ATE program, and of course by producing webinars like this one. Let's talk about the webinar materials. The slides for this webinar are already on evaluates website. All you know that URL, but let me say it again evalu hyphen a-t-e dot o-r-g. So you'll find the information right there. You can download those resources from that site the recording, as I mentioned will be available in a couple of days and that will be emailed to you. That's me on the left, Mike Lesiecki, I work with Luka Partners  and I also have the privilege of working with EvaluATE on the production of these webinars. I'll be the moderator for today, and Lyssa Wilson Becho will be the main presenter for this webinar. Dr. Wilson Becho works with EvaluATE which is located at The Evaluation Center at Western Michigan University. Before we get started, we'd like to recognize our colleagues who work behind the scenes to help bring this webinar to you today. Including; the EvaluATE team, Carolyn Williams-Noren EvaluATE's editor, and working with me of Luka Partners Janet Penn horn and Shannon Pane. So thanks everyone for your help today. This webinar is designed for individuals funded by NSF's ATE Program. The Advance Technological Education Program. That program is focused on improving technician education, mainly through two-year colleges. It funds projects in high-tech areas like advanced manufacturing, engineering technologies, IT, nanotechnologies, cybersecurity, and so on. This is a good time to point out that the views expressed in this webinar are those of the presenters and do not necessarily reflect the views of the National Science Foundation. And now, I'll turn things over to Lyssa, go ahead, lyssa great picture by the way. [Lyssa:] Thanks Mike, so like Mike said, I'm Lyssa Wilson Becho and I'm coming to you today from my home office in Kalamazoo, Michigan. So you can see here me, and my daughter Maya, and my dog Sadie. So today's webinar is a little bit different than EvaluATE's typical webinars. And not just because I'm in my home, instead of on our University campus. But instead of pulling from a broad established body of knowledge and evaluation, we're all learning from each other and creating a new set of collective wisdom in this time of Covid-19. So I want to give a shout out to the evaluation community. Their ingenuity, their commitment, their passion, and their creativity. I've been really inspired by a lot of ideas for my fellow evaluators throughout the creation of this webinar. So I've posted a list of some of my favorite blogs and resources available on the webinars website. And, I also want to hear from all of you in the audience as we're all learning and  inventing in this moment. So please, share your questions, your successes, and your stories in the chat window throughout the webinar. And then after the webinar, our team will go through the chat and pull out some of the resources and strategies that you shared. Because you're an important part of creating this new collective wisdom about evaluation in the time of social distancing. So before they really dive in, I want to do a quick check-in with everyone. So we're gonna try something new here, so hang on with us this. If this doesn't happen to work but we're gonna try a word cloud in Adobe Connect. So when this loads you'll see a text box in the center of your screen. It may take a while mine is still loading. When it loads it's going to ask you to share in one word how are you currently feeling about your evaluations right now. So think about your that one word, while it loads. There we go, looks like mine loaded. Hopefully everyone else is loaded. So instead of using the chat box, actually put that question in there. Oh look! It looks like things are popping up. I see a lot of words of uncertain, delayed, anxious, challenging, overwhelming, stuck. But I also see things like excited, and whoa, and curious. I think there are just so many emotions that really come with the current situation that we're in. It looks like  that uncertain right is really popping up. Yeah, I think we're gonna talk about that a lot today. All right. Yeah. Great. All right Mike let's go ahead and close that so you can get back to the slides. And certain for sure, yeah well you know no matter what you're feeling about your evaluations, I want everyone to go ahead and take a deep breath. So I know it may sound a bit silly, but I want us to start by taking at least one deep breath together. So relax your body, and take a deep breath in and out. So we've seen a lot of rapid change in our work and in our personal lives due to Covid-19 Policies and processes were changing by the day, if not by the hour. And now things have calmed down a bit since March, we're not back to normal and we may never get back to what was normal. Tom Shwandt coined this term "Post-Normal Evaluation" calling for a shift in evaluation practice. He was reflecting on the increased complexity of our modern world and the increased rate of social change and he saw a need for a new kind of evaluation practice. And that was before Covid-19. So now in the post Covid era, the rate of change in our political environments, both national and local, will only continue to increase. As Michael Quinn Patten says "Evaluators have a responsibility to embrace change.". It is important to acknowledge that evaluation, along with the projects that they evaluate, will exist in uncertainty and change for the foreseeable future. That's scary at first, but it's also really exciting. It gives us a chance to redefine what we want normal to look like. It means more evaluation activities might occur online rather than face-to-face. It means more virtual conferences or non-traditional data collection techniques. While we are altering our activities in the midst of crisis, it's very possible that these "alterations" may continue far into the future. Making the strategies that we talked about today not just an immediate solution, but part of the post-normal evaluation. So even before we get started into strategies for adjusting your evaluation. Take a breath and recognize that your evaluation plans are going to change, and that's okay. This path opens up opportunities for us to think creatively about our evaluations. To try new things, to learn new skills, and most importantly connect with others on a more personal level, and show the importance of evaluation in social programs and decision-making. So I want to do a chat here, take a minute to consider what you hope this new normal brings for you in your evaluations. So share your answer in the chat box. You know I asked this question of our evaluate team earlier and I got answers like "looking forward to cutting down on emissions due to less travel" right or "learning new skills and being comfortable with online tools". So I think all of you start to starting to answer now. Streamlining evaluation, more equity and accessibility, great. More flexibility, creative approaches. Wow, you guys all have these really wonderful ideas. They're coming in so fast that's great! Trans-formative evaluation, creativity, new skills, clarity, and how to be ethical. These are all really great! I'll give you a moment to finish, because I want to hear from all of you. We can collect this chat later. Students,  new participatory methods, yes definitely a well thought-out approach. So Sara, yeah, I think that's really important. Great, I think these are all things that we are definitely going to talk about throughout this webinar today. So like the title says, I want to share some strategies and considerations for adjusting evaluations in this time of social distancing. So these are by no means an exhaustive list of everything that you should do or that you could do. But I hope that they provide a starting point and that they spark some ideas that you can integrate into your work today. So after you take a deep breath and you recognize that things are gonna change, press the pause button on evaluation activities and reassess what is that change that happened in your projects. Whether it was written into the evaluation plan or not, this is the time to perform a quick process evaluation. So if you haven't already, the project team and evaluation team should check in over the phone, over videoconferencing, or at six feet apart. It's important to fully understand and document how Covid and the resulting disruptions, have affected the project and their surrounding context. Evaluations need to be responsive to how each context in each culture is responding to the situation. Because each are unique and will have unique consequences for the evaluation. So revisiting a project logic model, if they have one, can be a very great way to structure this conversation. The logic model gives you a structure to ask questions like, "what's changed in terms of the input or resources for this project", "have there been any change in the budget or access to needed resources". For example, many technical education programs rely on labs and equipment to give students a hands-on experience. Closed college campuses and restricted access to the lab space have a cascading effect on the rest of the project. Which brings us to their next question, "how has the change in inputs affected the project activities?". So if colleges aren't allowing access to that lab space, has this affected the courses that can be offered? Or the certificates that can be awarded? And what changes in the outcome can we expect? Will there be a change in students knowledge or proficiency? Will there be an effect on job placement in the future? Will some students be more affected than others? All of these will have a direct impact on the evaluation. The changes might affect the evaluation questions that are most important, maybe which criteria are measured, and maybe the placement for targets for success. So remember to document these changes, and not just with sticky notes. But document them systematically in a way that will help explain patterns and evaluation data and can inform the interpretation process. So whether your evaluation is aiming to show project impact or provide formative guidance, understanding how Covid affected the project will be important when reporting these evaluated findings. Evaluation questions may change because the project changes. But they may also change, because the questions that the stakeholders want answered have now changed. Which brings us to our next strategy. Be proactive. It can be tempting to place evaluations on hold until things get quote "back to normal". But as we talked about earlier, we're headed towards a new normal. One where certainty and stability will be hard to come by. So don't just try and wait it out. So as this cartoon by Chris Licea says, uncertainty may not end. Instead of pressing pause on the evaluation plan entirely. Consider re-scaling some aspects to collect real-time relevant information. Ideas for this hopefully come from the mini process evaluation we talked about in the previous strategy. Perhaps the project staff have questions about how Covid is affecting their participants. Perhaps they want to know formative feedback on how participants like their altered activities? All of these stakeholder needs could lead to an opportunity for rapid data collection. I've heard from a couple of ATE evaluators who have included questions on existing surveys about how Covid is affecting students. And about how students are experiencing the move to online courses. This is a great use of real collecting real-time data. There's a lot of potential for collecting data in the now to inform quick moving decisions and policies. So evaluators may shy away from the idea of rapid data collection and analysis. Asking questions about their reliability and validity of these findings, but many times reacting to flawed data is better than not using any data at all. For example an academic program that's looking to move to distance learning, or a doctor's office that wants to implement tele-medicine, might need to know more about their audiences internet access. Or they might want to know what their participants need right now. So real-time evaluation data, acknowledging the potential flaws can be more helpful in decision making than not having any data at all. Recently many evaluators have pointed to the concept of "good enough evaluation". So as Rossi and Lipsey wrote "the evaluations must find a work with their balance between ensuring the validity of findings and making them timely, meaningful, and useful to the consumers". Particularly in a time of crisis, evaluators should prioritize good enough evaluation designs in order to collect useful and relevant information. Being proactive in collecting real-time evaluation data can help aid projects and tough decision making. So projects are being forced to make decisions around their activities; which to keep, which to cut, and how to adapt them. Insights from evaluation data and evaluative thinking can be invaluable in this process. Evaluation data and evaluative thinking can help determine which activities were most impactful, which served the most participants, and which are essential in the larger project theory of change. Evaluators themselves can also be a great resource in the decision-making. Evaluators can help the team think evaluatively and they have skills in collaborative decision-making and facilitation. So you know collaborative decision-making these days looks a lot less like this, and a lot more like this. So how do you make the most of virtual decision-making? Well one possibility is through the use of an online collaborative whiteboard. So this is a screenshot from the online software Miro.  You can find it at miro.com. We have a lot more examples of different virtual whiteboards you can see on our handout. So these platforms can do a variety of things, but I want to focus on how these platforms can help teams make strategic decisions. So you might consider using a whiteboard template like this, if your project needs to prioritize activities. So if the projects activity is easy to carry out while practicing social distancing, and it plays an essential role in the project theory of change, your team might put that activity in the top right corner in the high feasibility and high importance. If an activity is feasible given Covid restrictions, but past evaluation reports has shown that it hasn't had much impact, then your team might decide that it's lower in importance. Finally, if an activity has been shown by the evaluation to be of high importance and high impact, but it's currently just not feasible due to campus closures or social distancing rules, your team might place it in the top left corner. So through critical conversation, your team can place all the project activities in the template. The activities on the top right corner are the ones that your project would want to focus on first. Templates like this, paired with critical reflection of past evaluation reports or recently collected data, can support reasoned decision-making. So its projects and evaluations are making quick in the moment decision, it's important to consider equity in these decisions. So what do we mean when we say equity? Well the W.H.O defines equity as "the absence of avoidable or remediable differences among groups of people". And when I say consider equity, I'm talking about this kind of equity. Making sure that new policies and decisions are not leading to avoidable differences among groups. But I'm also talking about equity as a means, as a way of doing. That our decisions and the resulting activities are done in a way that models dignity and justice, without recreating harm or oppressive structures. We know that especially in times of crisis inequities our deepened, and Covid has proven to be no different. So when making decisions about the evaluation activities reflect on who is missing in that decision-making process, whose voices or values are not being represented, and who is likely to be disadvantaged by the changes in the evaluation plan. These same concerns apply to changes in project activities, so pay close attention to the evaluation data to see if inequities are being reproduced at the project level. For example, are rural students with limited access to the Internet being disadvantaged by the move to online courses? Does college enrollment for some students declined because of financial hardship? With a close watch, these inequities can be spotted early and addressed early. So I want to go ahead and stop here, and give some time for some reflections and some questions. I do have two quick polls to start off our reflection, but please if you have questions that you haven't asked yet in the chat, feel free to add them in there. So the first poll, Mike can we go ahead and bring up the first poll. So the first poll is going to ask "what challenges are you facing as a result of Covid-19?" So there are different options here and you can choose more than one, if you feel like you've been experiencing multiple of these. So we see a number of people, fair amount of people over half have said that evaluation or project activities have been delayed or canceled. Yeah I'm hearing a lot of that too, right. Particularly for programs that happen on college campuses, those college campuses have been closed or moved to online education. Also seeing a lot of people who say that they're just adjusting to working remotely with their team, yeah that can be such a big adjustment, right. It's really different when you're not seeing everyone face to face every day. And then maybe of shifting to phone or online data collection. Great, Mike can we move to the next poll? So the next poll is gonna ask you "What opportunities have you seized as a result of Covid-19?" and again, there are five different choices but you can choose multiple of them. So I see people are saying that they're, you know literally facilitating this reflection around the project's mission and purpose. A lot of people are exploring online tools for team collaboration, that's great. I'm also glad to see that a number of you are taking a step back to care for yourself and your family because that's so important. So Mike I might turn it over to you to see if there are any any really great questions that we can address. [Mike:] thank you Lyssa. Should I just leave this poll slide up for a moment this blank pole slide? [Lyssa:] Yeah I think that's good. [Mike:] So here's a question, it's from an evaluator. It's a difficult question she says "my projects team seems to have gone into hiding during the Covid situation. It's like it's like they're not trying anything. I want to encourage them to look at new things. How should I go about doing it? I mean how forceful can I be?" That's the question. [Lyssa:] That's a great question, and you know I've seen similar things in some of the projects that I work with as well. And I think the first thing to remember is that everyone experiences the situation differently. Right, so giving space for them to do what they need to do for themselves and for their family. And then when they feel like they're ready you know I think that there's a great opportunity to be creative and try new things here just like you said. Unfortunately this doesn't seem like it's going away anytime soon, so I think that there is certainly enough time for them to adjust to this new normal, and then to try some of those new ideas that you want to try. [Mike:] That's a good point, good point Lyssa. Here's one from our participants, What about if you've any suggestions  on the problem of online saturation. Whether it's evaluation or endless meetings. Have you seen perhaps solutions to something like that or is it just something we have to deal with, saturation? [Lyssa:] Yes right. It's like the endless back-to-back zoom calls. I think one thing to consider is you know not making your meetings a full hour. Right, because how many times do you have three full hour meetings back-to-back. But, make sure that they're like 50 minutes, so that you're giving yourself at least a 10 minute break in between so you can get up from your desk and not share the screen. But I also think just setting boundaries for yourself and participants to say you know they're gonna take a break in the middle of the day. But I think that's a tough question, and I think people that were asking to participate in virtual data collection are struggling with the same thing. [Mike:] You know, here's a good question I think from one of our participants. Today you know they have planned, I'm paraphrasing a little bit Lyssa. They have planned a fairly extensive survey you know to look at the impact of their project, but now they're thinking maybe they should limit it to a much shorter set of questions. Does that make sense? Any guidelines? [Lyssa:] Yeah I would probably agree to shorten surveys and  talk about that a little bit later in the webinar as well. Unfortunately there's no rule of thumb, in terms of how long your survey should be. But generally, I would say that it should just be shorter. Right, everyone's dealing with a lot of things, so being respectful of their time and making sure that the data that you are gathering is of high quality, when they do respond. So probably splitting it up into shorter surveys, depending on how big your population is, you might be able to split them up into different subsections and ask different questions to different groups. [Mike:] you know one of our participants just chimed right along with you. How do we avoid adding to the stress that people are already under and yet we still have to get our evaluation work done? That's the question isn't it? [Lyssa:] yeah [Mike:] One more for you and then of course we'll have other another question break further on so I encourage people to to keep coming in with their good questions. Now as you mentioned that an evaluator can be proactive and think by working with their project team how to restructure things, at what point are you actually making changes in the evaluation plan that might have to go back to the funding agency for approval? I mean how do you, how do you know where you are on that side of the line? Does that question make sense Lyssa? [Lyssa:] It does. Um so I know at least within ATE as long as you are staying with the general the initial mission and spirit of the grant you shouldn't necessarily have to go back to the funder, the NSF program officer, to approve changes. However, if the project itself drastically changes its activities or its intention then the project would have to go talk to their Program Officer, and ideally that would also include changes in evaluation. [Mike:] Great that make sense. Lyssa there's a bunch of questions, comments in the chat that say, "do you have suggestions about this or that" and you know what, that's coming up in the next part of your webinar. So let's just go ahead and take us forward. [Lyssa:] Great, yes. So we have a lot of stuff coming up, but I also want to remind you that like Mike said, we have one more question break, and then as well we want to make sure to go through this chat and really try and answer some of these questions not in a webinar and share that back to you as a resource as well. Because with almost looks like 482 people on the webinar right now, the chat questions are just going rather fast, but we want to make sure that we hear from all of you and we can answer your questions. All right so a lot of you have mentioned that the shift from traditional to in-person data collection to phone or online so let's move on to our next strategy. Which is to be creative with your data collection method. So we're all familiar with in-person interviews and surveys as a method of data collection and how to move those on to a video conferencing platform. However there are a lot of other options you can consider that don't require a face-to-face interactions with participants. So let's start by looking at alternative options for in-person paper surveys. So often these would be like feedback forms or for events or trainings that you might hand out. So like I said you can always do the online surveys using a variety of different online platforms, but you might also consider doing your surveys via SMS text message. So Sharon O'Connor at the Center for Program Design and Evaluation at Dartmouth College, she recently authored a blog about her switch to using text messages to disseminate her surveys to young adults. And so using this new method she saw a 28% increase in her response rate, which is really great. Additionally you could also administer your survey over the phone, so for phone surveys remember to keep the wording of your questions consistent between each respondent, as this is meant to be a survey and not necessarily an interview. Let's look at in-person interviews. So instead of an in-person interview, you might consider, like we said you can do video conferencing, or you can do phone interviews. So it seems that everyone has become intimately familiar with Zoom or other video conferencing programs lately. But if you find yourself inundated with zoom calls crammed into your schedule, you might consider asynchronous interviews over email. So this method of asking a question and then waiting for the response from the interviewee, here It'll take a little bit longer than a traditional interview. And you also might lose out on reading body language and pulling contextual information from the participant surrounding like you would if the interview was in person. However the asynchronous nature of this interviewing techniques, you know it allows for participants and interviewer to really carefully consider their responses. Another plus is that there's no need for transcription, because a written transcript is immediately available from the emails. Another alternative to in-person interviews is to consider asking participants to journal their experience. So journaling as a data-collection method is typically used when participants are being asked to reflect on something in real time. Either an experience or aspects of their day-to-day life. Things that would be difficult to recall later on a survey or in an interview. And then finally another creative alternative to in-person interviews is the use of Photovoice. So Photovoice is a qualitative method that uses photography to allow participants to express points of view or represent their personal experiences. Generally participants are asked to take a photo in response to a question prompt and then they provide a written explanation of how they feel that photograph responds to the initial question. So this method has been particularly successful and engaging young adults in evaluation efforts. So what if you were planning in-person focus groups? Well again you can consider video conferencing to do your focus group. So if you go this route, be strategic and intentional about your facilitation techniques. So make sure that all of your attendees know how to actually use the program before beginning, and then have a second person join you to troubleshoot technical issues, that way you can really focus on facilitation in the conversation. And then as well as making good use of the hand-raising function to keep multiple people from talking over each other. Other alternatives to video conference focus groups include doing a group message over Whatsapp?. Which is an open group messaging platform or other social media groups. You could use Facebook or Linkedin. So this method is really good for audiences who are particularly tech-savvy and are comfortable communicating in a fast-paced chat. Other alternatives to focus groups is to consider the Delphi technique. So if you're not familiar with this technique, it's a method that's particularly good if you're looking at creating a consensus among a group. So this technique uses a series of iterative surveys, which can be done online, to converge participant responses into a list of priorities or ideas. So be mindful that participants availability and time commitment. So it may not always be appropriate to continue with your original plans to collect primary data. Instead consider existing sources of secondary data that might speak to your evaluation questions. You can also reach out to local partners or organizations to see if they are already collecting a relevant source of secondary data that you might be able to use. So while it might seem simple to shift from in-person data collection to online, there's a variety of implications that you should consider. So you'll want you to ask your evaluation team whether or not your participant population has access to fast reliable internet, and then whether or not they know how to navigate the online platform that you want to use, and ask yourself how will it move to virtual really affect your sampling, and also how this move to virtual will affect the accuracy of your findings. So it's very possible that the changing methods of data collection will also change who has the capacity to participate. So for example, if you move in-person interviews to a phone interview, you may not have the utmost up-to-date phone number for all your participants. Also participants may just not pick up for an unknown phone number. So the implications for sampling in your sampling frame will need to be fully explored and understood before deciding on the method change. And then if you do decide to move forward, you'll want to include these limitations in your evaluation report. So let's pause really quick right here to do a poll to see if anyone has tried any of these remote or virtual data collections before. Mike can you pull up the pool there, great. So which of these remote or virtual data collection methods have you tried before? And if you have tried some of them and have really great lesson learned that you want to share in the chat window that would be great! So I see online surveys right, that's no surprise. It looks like a number of people have done phone interviews as well and video conference interviews. Right it's interesting, I actually did all of my dissertation work over video conference interviews and I was surprised how well it really worked. Only every once in a while you got tech issues that kind of got in the way. I see about a quarter of you have done video conference focus groups. Right, so yeah if you have any tips for that. I think facilitating online focus groups is even harder than in-person focus groups, which is already a feat in and of itself. So only a small percentage of people have done group messaging via social media or the Delphi technique and it looks like journaling and Photovoice are also pretty low on the list. So if you tried any of those techniques and they really work for you and you have something you want to share, definitely share it in chat window. because like I said were building this knowledge togeather. Mike we can go on to the next slide. [Mike:] Lyssa can I ask you a question right here. So an interesting comment came up group message via social media. Do you think that it would invoke up privacy concerns about you know you're asking it from information on essentially an open platform and when do you decide that you need to go back to an IRB to redo your protocols with these things so to be two nested questions there if you don't mind a break. [Lyssa:] yes certainly we're gonna talk about IRB protocols but, yes if you are operating under an IRB approval, you will need to go back and get approval through your IRB for any type of changes. Whether it's on social media or anything so any change in question or method of collecting that data you will need to go back to IRB to get those approved and then in terms of when to share sensitive information over social media. I think that's something that needs to be considered given the questions that you're asking. Right if you are asking very sensitive topics or for sensitive information and that's something that you are gonna have to define for yourself and for your participant. It's definitely something that you should not consider using an open social media platform for. [Mike:] Sorry couldn't resist just jumping in there with these questions. Chat is very active today. Lyssa lots of people sharing information with each other. Let me take you back into your presentation, then you can go ahead, let's see there we go. Yes okay, you've got it back now. there we [Lyssa:] Great, yes! I love the chat window   if only I could read faster and talk at the same time. All right so let's move on to the next strategy which is be compassionate. We talked about it a little about this before but by this I really mean being intentional about how you are responsive and empathetic to how the pandemic might be affecting those you're working with. So the pandemic might be compounding existing traumas and individuals and communities. Then the very least it places a haze of stress and uncertainty over all of our lives. So there are a few ways you can recognize and respond to this. So first you can integrate check-ins at the beginning of your conversations. Check-ins are quick questions or prompts that can elicit how participant are feeling or what they're thinking. So leave more time for these check-ins than you might normally leave for introductions. Might take longer than expected, but the time is important to get participants in the head-space to consider the topic that you want to talk about. I've heard from a few evaluators that this has really been essential to their work, particularly in larger group meetings. So you get a sense of the room, well the virtual room, and where everyone is and then to get them focused on the meeting at hand. Second make your meeting or interview shorter, right. So we were just talking about this it' not really sending out a really long survey, but maybe cutting it up or making it shorter or leaving out the non-essential questions. And so like I said there really is no magic length, but the shorter the better. So consider that everyone is juggling work and family and stress all at once, so be mindful of how you collect data in the most efficient way possible. And third, just recognize that things are not business as usual, and that your evaluation is not the most important thing in people's lives. So be sensitive to participants employment status and their family health. This could be as simple as they extending a survey deadline or understanding when participants cancel interviews last-minute. Showing compassion in your work should not be something that's reserved only for times of crisis, but it's certainly more needed in times like this. And so next consideration is to protect participants rights. So with the move to virtual data collection and changes in protocol remember these ethical considerations as you move towards social distant evaluations. So like we are talking about before, if you're operating under institutional review board approval remember that all changes to data collection, whether that's the question or the method that you're collecting the data, will have to be approved by the board. And so this generally involves a change of protocol form that you submit to the IRB. And so they'll want to see your new protocol or survey questions as well as any new instruments, invitation emails, or changes to your informed consent. So speaking of informed consent, this looks a little bit different when you're not face to face with participants. You probably won't be asking them to sign a document like in this photo. So some evaluators have placed informed consent in the invitation email with the assumption that if someone agrees to participate that they've also agreed to the informed consent. However, it's really good practice to verbally repeat the consent protocols at the beginning of interviews or focus groups to make sure that participants fully understand their rights. And finally the the concern for data security. Right as more activities and more people are working remotely. So make sure you're checking for end-to-end  encryption on data collection platforms such as videoconferencing and all messaging services, particularly when collecting data on sensitive topics. So here we were talking about using Facebook for say. Right, Facebook certainly does not have an end-to-end encryption but there are a number of different sites that you can do that through. And so I would check out the handout that a colleague of mine Ana created. Which I'm sure Ana can think on her feet and throw that link in the chat while I'm talking about it now, but there is a comparison of different platforms that you can use on there and it specifically mentions the end-end encryption. And then also check the security settings of any shared drive that you use. Right if you're sharing files back and forth, and particularly if you're sharing personally identifiable information of the participant. So I'm certainly not an expert in data security but I know that there are additional resources out there from your institutional's IRB or their IT Help Desk. So the final strategy to consider when adjusting evaluations and the time of social distancing is to plan for uncertainty. And so as we talked about in the beginning of the webinar uncertainty and stability are not guaranteed moving forward. It's a good idea that we have a back-up plan. So my colleagues really wanted me to use this image to encapsulate the idea of planning for uncertainty. I'm sure this cow didn't plan on getting stuck on the fence during his escape, and I'm sure the farmer didn't plan for how to get the cow off the fence. Surprises happen, changes happen. As our seats and our campuses begin to open up again, there's a chance of future Covid outbreaks which would throw us into a lockdown situation. Even post Covid, whenever that happens to be, there will always be uncertainty to contend with. So creating backup plans or contingency plans for evaluation is just good practice move in the future. So I'm sure you will see funders wanting this to be integrated into future proposals and plans, but even if they don't it's good practice for you. Think what will you do if your data collection can't be done in person? How will evaluations be affected if the project can't be carried out in person? What repercussions will that have for your evaluation questions or your criteria? Making a plan now for the potential disruptions down the road can help remove some anxiety about uncertainty and hopefully save some time, and if ever, if and when you need to get a cow un-stuck from the fence. So here's a quick overview of the strategies and considerations that we've talked about today. So before we open it up for questions and we saved a fair amount of time for questions, because I want to have that dialogue with you, but consider how and in what ways your evaluation team is already doing these things. And in what ways that they can improve. So one of the themes that I keep hearing from evaluators both internal and external to the ATE program, and I think it's been shown here today as well, is the idea of just being nervous about the uncertainty for the future. Not knowing what's next seems to be the hardest part, and in a way this takes me back to the beginning of the webinar. Take a deep breath, acknowledge that change is inevitable, and reach out to your fellow evaluators. Together we can continue to build a collective knowledge of promising practices in the era of social distancing and Covid-19. So in that vein, I'm gonna hand it back to Mike for questions and comments. [Mike:] Thank you Lyssa. for all that information, a tremendous amount of backing and forthing in the chat. Let me ask you a couple of clarifying questions. Here's one, you've addressed it a bit. But, is there a creative idea to address collecting information from study participants that have low literacy? This might be even more important right as we're trying to reach out to people via these techie methods. What if someone with a low literacy quotient is in your subject population? Do you have any suggestions of how you might address that? [Lyssa:] Yeah I think that's a that's a great question and honestly I would suggest going back to phone calls. Right, I think there are a number of ways you can do either surveys or interviews via phone calls. However I also know that getting access to those phone numbers can sometimes be an issue. I was talking to an evaluator the other day about the potential of doing surveys via text messaging. I know it's not the same thing as low literacy participants, but you know she expressed concern about the fact that they didn't originally set up collecting information like that. Contact information like that so they didn't actually have approval to contact participants for evaluation purposes. So I think that in the near future we're kind of gonna get stuck in a lot of these back-and-forth of you know we want to contact people via phone, but we don't have approval to use their phone numbers to contact them for evaluation purposes. Which brings us back to the idea of planning for the future. Right, so everything that you find is an obstacle or barrier now, make sure to write it down so that you can really address it and use it for your evaluation.  [Mike:] A number of people have talked about the use of video interviews, you can see that in the chat. It seems to be a very effective way, especially if you give them an option. One person said look I've got an online survey but I gave them a video or phone option and a lot of people took it. So I think in some ways people want to talk don't they. They're looking for another way of interaction I think that's been coming on. [Lyssa:] Yes I've heard that too I heard that people who feel stuck at home and feel like they haven't really socialized with anyone are almost more, more motivated to do things like even phone number for purchase review than they would before just because they want to talk with people. [Mike:] Here is another one for you, a number of our participants are not all familiar with the delphi technique. Do you mind talking about it a little bit again, exactly what it is do you mind going over it again? [Lyssa:] Certainly,  yeah so in the Delphi technique I believe it was created by Rand and initially it was the idea of consolidating expertise across a number of experts. And so you would essentially send a survey out, you know maybe it's prioritizing different ideas, or say coming up with different, uh sorry, I'm trying to think off the top of my head what a good example would be. I don't have one exactly. But you know maybe it's you know what activities you should do or what what are the primary drivers of student education. And so they would essentially take the the first survey and then you would receive those results and you'd do a quick analysis to combine some responses, maybe leave others out and then you would integrate those responses into a second survey. And that survey would go out to the same people and you'd ask them to prioritize that list once again. And then when you receive the feedback from that second survey you would do the same thing. Analysis again, consolidate and send it back out a third time. And so this way you are slowly forming this consensus. Right, people are either prioritizing or we're saying that they agree or disagree with different statements. And so through this iterative process you can come to something close to what you would get in an in-person focus group. Right so, if in that focus group you are saying you know there's this idea do people agree or disagree with it how are we prioritizing it. It would be something similar to that. [Mike:] okay thank you for the information. Similar to that of delphi people are new to Photovoice. As I understand it, Its a way of documenting reality of a project through photography. Is it that simple, I mean how can you adapt it for your evaluation situation? I hope that's not too broad of a question [Lyssa:] No Photovoice is a really great qualitative method to use in evaluation. I think particularly when you're looking to show things through the participants eyes right. So the fact that you can you can ask a question, you can say how is this impacting your life? Or you can say, you know what are you learning right now and how are you integrating it into your future career goals? And they can take a picture of what that means to them, and then it is followed up by a written response for people to expand on that. I'm seeing a number of people write in in the chat that there is a number of articles in peer-reviewed literature out there on on Photovoice and how its a form of evaluation. [Mike:] I am trying to put in to an ATE  situation right you might have students that are working on a home lab kit and they're documenting what they're doing either by video or photographs and someone pointed out in our chat that Photovoice is a form of evaluation itself, interesting concept isn't it. [Lyssa:] And I've also seen that stakeholders really love the integration of Photovoice. Right because instead of you know seeing numbers in terms of quantitative data or reading a full description they really get to see the fruits of projects efforts and outcomes that they're seeing and they get to really empathize with participants. [Mike:] Here;s another question, I'm here bombarding you with questions and you've been speaking the whole time. This one is, they were caught when you said you know if you're having trouble getting primary data you might be able to access secondary data that helps document your evaluation. Do you have an in  mind a top a couple examples of something like that... [Lyssa:] well that is hard because I think there are a lot of different contexts on here but if we're thinking of ATE in particular, right there's a lot of student education data out there. The National Center for Education Statistics has information on 2-year colleges and on associate's degrees. But I also want to emphasize the idea of working with partner organizations that might be really similar to you. Right so maybe someone, not these giant online databases per se, but other organizations that work with your participant population or maybe just down the street from you that maybe they already did data collection that could be useful to you and they just did it in December. So I think this is the time where we come together and we collaborate with each other. Or maybe you are an organization that recently did data collection that you think can be of use to other programs and other evaluations. You know being able to share that and really work collaboratively, I think that's how we really move forward. [Mike:] Here's a really good one, I know we keep giving you hard questions this morning. You know in the Covid world there's lots of discussions about contact tracing using a cell phone type of data. Does that cross a line to one once working on evaluation on. I don't have a situation where you might actually think about using it, but do you think that there could be issues there if you started to build cell phone tracking data into your evaluation. It's a topic for today huh, [Lyssa:] yes yeah that's a great question. I was actually looking into different mobile apps that you can use to help collect qualitative information and most of the apps that I came across are things that are pulling from that background data from your phone. Right, so either in location or usage and I do think that has a lot of ethical implications. Particularly if the person is unaware that that information is being pulled. So I would highly consider having a conversation with your institutional review board around that. And you know, I recognize that not all institutions require evaluations to go through that review process and even if your institution doesn't require you to, but if you're thinking about doing something like this if you think that using that background data collected from cell phones would be helpful to you. I think that's definitely a critical conversation that you need to have with the institutional review board along with project staff. And I would encourage you to get participants involved in the conversation. Ask them how they would feel if the data was collected [Mike:] That's a great idea, i mean that really brings it right to the front of the issues that your dealing with. Alright Lyssa, I think we've done really well today a lot of people have suggested that we try to capture this chat and I know your team is going to do that and potentially share some information associated with that. So we'll leave that to your EvaluATE to manage that. There's just a ton of stuff in there and I'm learning just from looking at the chat today.  So thank you Lyssa. [Lyssa:] I did see a question and I just want to bring up really quickly about this idea of corroborating interventions in the field when you cannot go and do direct observation. And I'm sure some of you have noticed that I don't necessarily have a lot of guidance on replacing site visits. Right, because I think that is next to impossible to replace the entire site visit. Right, so the idea of being there at a project and doing direct observations on what they're doing is really hard. I mean one, the sites themselves have moved virtually right and so that has changed, but you know for others that might not have, Maybe you're an evaluator that's across the country and you can't travel to that site. So I think if someone has good experience with that or suggestions please share it in the chat. Um because I do not find much when doing this creating this webinar in terms of a direct replacement for site visits. I think there are other ways you can get access, right but they all generally rely on talking to people and hearing from their perspective how the project is going instead of direct observation. [Mike:] You know one of our participants shares your purpose mr. Schurz your uncertainty uncertainty there. For example, how do you corroborate your virtual observations you know with other information that's certainly interesting challenging question isn't it [Lyssa:] Certainly. I did get just get a  message from Rachel who says, "how about case studies in place of focus group" and I do want to say when you're replacing different methods of data collection to really think critically about why you're using that particular data collection method. Right, so in focus groups we're generally choosing to do a focus group because we want to come away with a group understanding of something. Right so people kind of play off each other's ideas and agree or disagree and you can get a sense of the group and what they think. Versus say an individual interview. I think case studies would be potentially a little bit different focus of why you're choosing them right, because the case study is really in-depth and an expansive on a single situation instead of getting that group feedback. [Mike:] So I think that's where we're gonna pause there on the questions and ask you to take u forward into the final information for the webinar. [Lyssa:] Yeah, so we have some final closing slides. Like Mike said, I think because there's such great information in this chat we want to do two things. Probably just share it back with you as it is, but also recognizing that it's a lot to wade through. So I think we're gonna go through and pull out and organize some of your suggestions and resources that you've shared to make it a little bit more digestible. Easier to find things, but also be able to share with some people who might not have been able to make it live today. [Mike:] Colleagues that officially ends the audio portion of our webinar today. We'll leave the system up for a few minutes, we'll capture that chat window, we'll be sending out the link to the recording. Thank you for joining today. 