 a very warm welcome to everyone I'm sure she SH product manager for Google cloud storage or GCS and I have with me Chester tech lead for GCS as well and in this session we are going to learn about some important security capabilities and best practices to keep your data safe and secure at scale on GCS so agenda first we are going to look at GCS as a product and its various capabilities then we are going to go through some highly differentiated security fundamentals that GCS has to offer and then Chester is going to take you through some highlighted security features and some security best practices to secure your data at scale and then we are going to end with a demo which you put together these various security capabilities and best practices so introduction what is DCS and why it is awesome so GCS or Google Cloud Storage is GC p's object or blob storage product it's a very simple product to use from the customer perspective because of various reasons but two fundamental reasons one is that GCS offers a consistent API across all different storage classes and the second is DCS offers uniform online latency characteristics across all different storage classes so whether you are interacting with the hottest storage class or the coldest storage class your code doesn't need to change because they pay is the same and your handling in the code doesn't need to change because across all is this difference towards classes you have the same online latency characteristics this is highly reliable GCS offers various geo redundancy options ranging from a region to a country to a continent based on what your use cases and GCS is highly cost-effective you can leverage object lifecycle management to spread your cost across all different storage classes of GCS now last but not the least and the focus of this session GCS is highly secure and is inbuilt with a bunch of fundamental security capabilities that you got that you get straightaway of the box when you use GCS so in terms of key features I have already mentioned about the unified experience through the API is and the latency characteristics so yes of a strongly consistent listing worldwide and what we see is other than GCSE and other public cloud storages are being used customers usually use a key value database to drag this consistency because they do not get it of the box with other public cloud storage offerings but that is an additional unit of cost and management which you do not have to do with GCS I have already mentioned your redundancy the other great aspect of using GCS is you do not need to worry about scale at all we have single customers in GCS who scaled to exabytes of bigger now in terms of the use cases we see standard storage class being used in two different classes of use cases we see dual regional and regional standard locations location types being used for highly compute intensive use cases for example for high performance computing or for analytics or for machine learning what we also see is customers leverage GCS as multi-regional storage locations CDN like characteristics because of its intelligent edge caching and routing capabilities for content distribution use cases and Nearline is great if what you are looking to do is backup colon is great if what you are looking to do is archive and the archive storage class itself is great if what you are trying to do is to do long term archival for regulatory or compliance purposes so what we see is archive storage class is a great tape replacement but once you have your data in archive storage class your data is still live is in a serving tier and that brings me to the fact that once you have your data in GCS you have this great advantage that the entire data platform that is Google is now open to you so once you have your data in GCS whatever it is that you want to do with your data whether you want to run AI or machine learning or you want to do analytics whatever it is that you want to do you can do once you have landed your data in GCS now security is not an afterthought for us GCSE we have built GCSE with security as a fundamental primitive and this starts with Google's private network so Google possibly has the world's largest private network so we have thousands of edge node locations we have hundreds of pop node locations so wherever you are producing your data for consumer consuming your data from you are never too far away from one of Google's edge or pop locations and how that helps you a lot is say if you are in a particular location and you are writing your data to a Google Cloud Storage bucket in a different region with GCS your data packets enter Google's closest pop and then it traverses Google's private network all the way up to the region now if you compare it with another public cloud vendor what will happen is your data packets should pass through the public internet up to the region where your data is stored so you have much higher exposure that way when you use GCS your data packets are flowing through Google's private network for most of its lifetime so your exposure to public internet is as low as possible encryption is another very important aspect of security and with GCS all your data is always encrypted so whether it is your data in flight or whether it is your data at rest all of your data in Jesus is always encrypted and we offer you entire range in terms of choice for managing your encryption keys so whether you want to use customer-supplier encryption keys or you want to use customer management efficient keys or hardware security module or you just want to use Google's default automatic encryption you have all your choices when you use GCS and then the last part that I would emphasize on GCS is fundamental security fundamentals is even if you use the most sophisticated security capability with GCS for example if you use KMS keys or if you want to put your GCS buckets behind a vp c security firewall you do not have to pay any penalty in terms of your performance or your sls we have built all the security capabilities with GCS from from ground up so that your experience of using them is the same as if you are using GCS even without these features in terms of the performance and the SLS there is absolutely no penalty that you need to pay with that I'm going to hand it over to Chester who's going to take you through some security features and some best practices and then we are going to end with the demo take it over Chester thanks you the features I'll be going over today are uniform buckle access iron conditions service account each mat keys and d4 signatures uniform pocket level access when GA last year and this is a bucket level setting that lets you simplify access control across all objects within a bucket when enabled permissions are managed using the buckets ion policy disabling the use of individual object Ackles since all objects now share the same configuration it's much easier to tell if any objects are publicly exposed to the internet by inspecting your bucket policy you can quickly determine who can or cannot access your data uniform buffer level access also helps you leverage a security feature called domain restricted sharing which enforces that all members of an ion policy must be within a specified domain I am conditions brings HP based access control of GCS by extending AIIMS policy language with conditional bindings this recently GA feature allows you to grant access based on a resource name or a request timestamp a simple example that combines both attributes is if you tried to grant future access to all objects whose name started with 2020 slash I've also included a cell expression at the bottom of the slide that you could use to implement such a condition some of you may already be familiar with user account each map keys but I'd like to introduce you to service account each my keys which are now GA service account hmm keys are similar to user account in that they're also a type of credential that can be used to create signatures which you can include in your requests to GCS these signatures show that the request is authorized by the entity that owns the HVAC key delegating that entity's access to the request you managed service account each man keys by calling our API is to generate HTML credential which consists of an access key and a secret so if you're already using user account each map there's no need to change your code you can simply update the access key and secret that your code is using with service account HVAC you'll also get better key lifecycle management from the cloud console UI you can quickly create rotate disable and delete branch becky's and lastly surface account each map is interoperable with other public clouds which will enable your app for multi cloud for customers who work with multiple public clouds GCS is also gone ga with RV for signature support before enables you to access multiple object stores with the same client code and it's available for both RSA and service account page monkeys now I'd like to show you how these features can help you secure your data at scale to start I'll go over fundamentals like work policies and the differences between pod a.m. and GCS apples also explain how uniform bug level access simplifies access control at scale and then I'll conclude with some best practices for using hmm keys with GCS within GCP all resources conform to a resource hierarchy GCS is no different your buckets hold objects and they're associated with projects and projects can be nested inside folders and our tied to organizations or policies are settings that you configure at the org folder or project level to enforce a service specific behavior so remember that all resources inherit from or policy step higher in the hierarchy so if you set an ork policy at the org level it would cover all GCS buckets in its tree and lastly our policies themselves are not retroactive because they take effect after they are enforced so hypothetically if there was an org policy that prevented buckets from being created in a specific region enabling it now wouldn't impact any buckets that were created before that orc Posse was enforced the two orc policies that we recommend enabling with GCS are domain restricted sharing and uniform bug level access the first one prevents users from adding members outside your organization to ion policies controlling access to your GCS resources so if you try to make the contents of the bucket public to the Internet by adding all users member to the bucket policy this org policy when enabled what block that operation and I'll cover this in the demo the second drug policy enforces the use of uniform bucket level access so after you enable this all newly created buckets are acquiring to manage to access uniformly through the bucket policy and this is also covered in the demo the easiest way to set an orc policy is through the cloud console UI for certain or policies like domain restricted sharing you will need to know your organization's domain ID as well and if you don't have it totally fine you can always use g-cloud to find it I'd like to go over a brief history of GCS access control in the beginning GCS only supported apples and then cloud I am came along in GCS integrated with I am at the bucket level so today when you configure access to GCS you should be aware that there are actually two systems at play here there's cloud I am and in CCS apples access can be granted from either system but cloud ion behaves that pork policies and that they also follow the resource hierarchy so any object permissions when granted at the bucket level they automatically apply to all objects underneath that bucket GC has apples on the other hand they do not follow a resource hierarchy they are used at the object level and can only grant access to individual objects in general we recommend using cloud I am to authorize access to GCS because it is integrated with so many security and privacy features like domain restricted sharing in combat a lot since objects can have unique Eckles it gets harder to tell who has access to your data the longer your bucket has been in production imagine having to iterate across millions or billions of objects in order to check to see if a specific user is granted or denied access Danny objects you can see that this can quickly become a maintenance burden and our recommendation for managing lots of object ackles at scale is to not manage them at all by enabling uniform bubble level access you are disabled in object Ackles and using the bucket policy for all access control every object is treated the same and every object benefits from all of Iams feature integrations and added benefit to using this feature is that GCS can now share access to decisions for objects within the same bucket caching is improved which is great for high KPS use cases and we understand that some of our customers continue to use GCS apples for different reasons whether it's because of their multi-cloud architecture or because echoes allow you to share an object with an individual user in general it is not a best practice to put in end-users on your object ackles so I'd like to recommend some alternatives first sign URLs send URLs allow you to delegate time limited access to your GCS resources your code generates a URL which contains authentication info in the query string that's tied to a specific identity usually the service account and that URL sent to an end-user for tumblr second if you notice that certain groups of objects happen to share the same access pattern within your bucket like they have the same object Apple step then this might be a sign that you should be using separate buckets one for each use case and lastly if your app makes use of shared prefixes in object naming then you could also use I'm conditions to shard access based on those prefixes and finally I'd like to explain some best practices when using HTML keys on GCS first off we recommend service account hmm / user account each map surface accounts in general they offer more reliability because they are tied to the lifetime of the cloud project whereas user accounts or not the user account can easily be deleted outside the context of GCP for example when a collaborator leaves the organization or when an employee leaves the company if this happens deactivating that uses your account would also deactivate their HVAC keys and this would result in access to not errors for any code that was relying on those keys so we definitely recommend using surface account hmm keys in the production service other things we recommend we recommend rotating your keys and only granting your service accounts just enough permissions to accomplish whatever task they're trying to do and lastly if you're using v2 signatures we recommend setting reasonable expiration times as well as eventually migrating to V 4 V 4 enforces a max time limit of one week whereas v2 has an element which can be risky all right time for demo all right let's begin the demo by enabling the org policies that I mentioned in the best practice is section before so do this we'll go to the orc policy editor and we will configure tomato shifted sharing and uniform bucket level access so let's start with the first one and for a domain restricted sharing you're going to need your domain ID and if you don't know that off the top of your head no worries you can use g-cloud to list the organizations that you have access to you can see here I have a test org and this value on the right is going to be my domain ID so I'm gonna throw it here that here into the policy value select save great now only members of this domain ID are allowed on ion policies anywhere in my project go back to this or policy view select enforce and we will customize it set the enforcement on as well so now that I've configured this or policy if for uniform buckle-up access any new bucket will have to use that feature which will greatly simplify access control across objects in buckets from here let's go to storage browser and see these or policies in action so we create bucket let's call this bucket GCS next on here we'll use the defaults for data location in storage class and we can see here that the org policy I enabled earlier enforces uniform for access control I'm going to create the bucket now and let's make sure domain restricted sharing is also in effect as well so to do that we'll go to permissions and we'll try to add something that's outside the domain if I were to add all users which would grant access to everyone making the bucket publicly exposed on the internet that would violate the domain restricted sharing or policy and so I am expecting this to fail and we see that the policy update failed and it's because the org policy was put in place so that's good if we can't add all users as a member who can we add well most of the time when you run a production service you want to use service accounts so prior to this demo I had created an object viewer service account it doesn't actually have object viewer permissions but I just named an object viewer just for the sake of simplicity so if I go back to storage browser and I update the permissions here I should be able to add that service account to my bucket I'm going to give it the same permission that I tried before storage object viewer which has read access to objects and I'm going to select save and because this is configured at the bucket level my service account is going to have access to all objects within this bucket as you can see I haven't added any objects yet so I'm going to go ahead and do that now here I have some folders that have some text files in them let me drag and drop them here on to the UI all three folders have different prefixes but they all have the same text files and then apples bananas and cherries so how do we confirm that our surface account actually has access to all these objects well easy way to do it is to use surface account hmm go to settings interoperability create a key for your service account I already have a key set up here but I don't remember the secret for it so I'm just gonna go ahead and make a new key if I go over to terminal you can see that I have this get object metadata with HTML key script this script reads from environment variables that I have to export so I'm going to go ahead and do that down exported the XS key and we'll do the secret next great so now if I run this script and I try to access my buckets objects I should see that access is granted and you can see that we have successfully touched the metadata for this object let me try some of the other files looks like access has been granted great so if we go back to the browser I mentioned earlier that I wanted to show you an example of eye on conditions so with eye on conditions you could set an object prefix which would limit the access to objects with a certain prefix in the name so instead of granting access to every object in the bucket let's say I only wanted to grant access to those with 20/20 in the name so to do that go back to the bucket permissions page I don't need to add the member because the service account is already on the bucket policy all I have to do is edit it so from here I can add a condition let me call it 2023 fix and four condition type will do resource name starts with and we have to specify a resource name format so the format is different for each GCP service so this table right here is really nice and you can see that cloud storage objects follows this format so I'm gonna grab that copy it in here for object name it's not an object name it's gonna be a prefix I'm gonna do 2020 slash and for name I'm gonna put you see us next on air with a bucket click Save now that I had this set up I'm gonna check to make sure that I have access only to 2020 and not the other two 2018 should fail now access denied 2019 should also fail we'll try some other files also denied but if we make it 20/20 access should be granted great and that's how you set up a object prefix and condition and with that that concludes the demo thank you very much thank you tester to conclude as you have seen in this session GCSE offers planet-scale object or blob storage with a simple and unified API and online latency characteristics and it addresses a whole wide range of use cases we see customers use this for security is built into GCS by design and default not as an afterthought and as you saw from the various gia features that just I just talked about we are continuing to innovate and invest very heavily in the security capabilities to address your requirements and concerns with GCS you can confidently store your data at scale and trust us to keep your data secure and safe with that I would recommend if you haven't here tried some of this GA features or if you haven't tried some of these security best practices that we just covered give it a shot and let us know thank you 