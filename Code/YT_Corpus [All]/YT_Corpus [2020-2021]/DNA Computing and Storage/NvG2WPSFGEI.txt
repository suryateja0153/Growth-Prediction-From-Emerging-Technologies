 Martine Barons: Our next speaker Nigel Smart has come to talk to us today. He used to work at the University of Kent and the Erasmus University of Rochester and Cardiff University and then he spent three years at Hewlett-Packard before returning to academia and founding the Cryptology Research Group at the University of Bristol. He's now based at the COSIC group at the Catholic University of Leuven. He's known for his work in elliptic curve cryptography. He's also worked on pairing-based cryptography, contributing a number of performing algorithms such as the SK-KEM and the Ate-pairing. His work with Gentry and Halevi on performing the first large calculation using Fully Homomorphic Encryption won the IBM Pat Goldberg Best Paper Award for 2012. In the last decade he's worked on making multiparty computation practical. OK so we're looking forward very much to this. Nigel Smart: Hi, can you hear me and you can see my slides, yeah, and you can see me and my huge TARDIS behind brilliant OK right. So, we're gonna have a quick - it's gonna be a bit more technical and less procedural than the previous talk but we'll look at stuff - it's about knowledge transfer but more in the way a computer scientist sees it like sell stuff to people yeah. OK - oops that doesn't work, page down, that works, OK. So to introduce what we're going to talk about we - my usual thing is I talk about the Dining Bankers. Now I've given this talk at the top of skyscrapers in the city and you give this talk and the bankers are falling asleep, you know like the board level. I'm there and we go, OK so there's a problem the bankers go to lunch and they've all been given bonuses and he wants to celebrate the fact they've got bonuses and clearly the person who should pay for our lunch is the person who's got the biggest bonus but the problem is they don't want to reveal who has got the biggest - they want to reveal who's got the biggest bonus, they want to reveal who is going to pay but they don't actually want to reveal how much money the bank - the bonus they've got, you know, like you know, there's a bit of a sensitive thing if one got a million and the other one got 10 million or whatever and then at this point when you're giving this talk to bankers they suddenly all go 'oh my god, this is a problem we have every day, I mean this is going to solve our problems with respect to who pays for lunch' and they suddenly wake up. So okay, so this is what's called the Dining Bankers problem or it's actually what's called the Millionaires Problem goes back to Andy Yao in the kind of mid-to-early 1980s and what you're actually trying to do is you're trying to complete the argmax function. You're just trying to compute the index of the person who has the biggest input and so, OK so the Turing Award is the Nobel Prize in computer science; it's a bit like the Fields Medal so it's got a bigger prize money I think. Anyway when Andy won it, it didn't have a very big prize money but he got a Turin Award for basically this and other work. So how do we solve the Millionaires Problem? Well if we had a godlike figure we could actually give our input to the godlike figure, the bankers could tell how much their bonus was to the godlike figure and then the godlike figure could provide the input - provide the output, except as cryptographers, as computer scientists we're definitely atheist and we don't believe in God but we do believe in protocols so what we try to do is we try to make a God using computer protocols. So what we have is we engage in a cryptographic protocol which computes the answer to the argmax function and if you take away nothing from today, take away: one, this is the app   - this one is not a real application okay this is a bit of a joke but - one: this is an application you can explain to anybody and two: actually this is what we're doing, we replace, what we want to do is we want to compute something on data without revealing anything about the inputs but we do this without a trusted party. We do it using a cryptographic protocol and that's what we mean by multi-party computation and various other forms of privacy preserving computations, they're called 'PETS' - privacy enhancing technologies, there's a huge number and there's great interest around the world, massive, massive investment in this from you know DARPA the US agency put in at least 200 million in the last decade. VC's have probably put in another 200 million into various startup companies, EU has put in god knows how many hundred million - 200 million in various projects in this space and our UK government is currently doing stuff in this space, there's stuff but Roozy's doing, I know the Newton Gateway is doing as well trying to get people together and also in the UK the Financial Conduct Authority did something on this to do with money laundering applications, but anyway. OK so what we're trying to do is the tradition in cryptography, you look at data in transport and data at rest. So if you think about data in transport that's essentially what you do when you connect to the internet, you're sending stuff over the internet you don't want anyone to look at it so here we would use traditional uh protocols like TLS/SSL and you can think of like the enigma machine it was an example of that, OK. The other thing that you might want to do is you want to compute secure data at rest which is so that your politician doesn't - when they leave their laptop on the train - doesn't have all of the details of everything on the train so you encrypt the data on your laptops if you're working in a university you're probably absolutely fed up with your IT people telling you to encrypt the data on your laptop and this is the reason why you do it. This is the reason why you should encrypt your data on your mobile phone because you lose these devices and they've got important data so you should encrypt the data at rest. Now the thing is with data is that sending it and storing it is absolutely bloody pointless because actually what you want that you do with data is actually use the damn stuff and so what the third part of this data security triad or triangle or whatever you want to do is securing data during computation and there are a huge number of applications here. We can think of electronic voting if you think that's a good idea as a form of secure computational data; you want to encrypt your vote but you want to then compute the outcome of the election without revealing the input of your vote. There's applications in GDPR which is pushing a huge amount of industrial money in this space. There's obvious applications in genomics, in fact there's a yearly competition called IDASH from the genome community from the biology community to look at applications of secure computation on genomes. There's obviously applications in public policy which we'll come on to later that we've been investigating with the US Government and citizen privacy and kind of another one which I just added in because Chris was talking about it is that actually contact tracing apps for COVID detection is an example in terms of of privacy preserving computation and in fact the DP-3T consortium which been run out of EPFL, ETH and some others including us in Leuven has been pushing together the protocol that is now being deployed in virtually all countries in Europe bar France. So this is already live in Switzerland, Italy, Germany, Estonia Lithuania all sorts of others, UK is kind of on board with DP-3T and so there's some documents that you might want to look at of applications of this tech within the COVID stuff that's been going on. So this is kind of when you hear 'Gapple' being talked about in the media this is kind of where the people in the DP-3T consortium have been working a lot with 'Gapple' to get things working so that these apps work across Europe and the rest of the world in a privacy preserving manner. I mean these are also being deployed in South America and other places. OK so there are two major technologies for general purpose securing on computing on the encrypted data one is called multi-party computation and one is called fully homomorphic encryption and there are pros and cons to using two of the various ones. Multi-party computation - the basically it's all in the title - it's multiple parties doing computation, it has the advantage of it's relatively fast in computation but it costs you in terms of you have to talk to people. You have a protocol that you have to talk. FHE is the other way around you can kind of think it as the converse, it's very, very slow in computation but it's relatively cheap in communication despite it being very, very slow in computation it is possible for certain simple functions. At the end of the talk I'll kind of discuss through some of the startups in this space and what they're doing in these different technological areas. So fully homomorphic encryption is the one which gets all the press because it kind of is easy to explain and it's kind of funky and so it was kind of - first kind of imagined in about 1977 which in cryptographic terms is the 'dark ages,' this is like one or two years after the invention of public-key crypto and so it was first proposed then but no one knew how to do it and it's kind of considered the 'holy grail' of cryptography is what you would kind of work on and so the first scheme was actually proposed in 2008 and in theory you can compute any function with a very small overheading cost except that the implied constants are actually quite bad so asymptotically it's really, really good but for very specific functions in the real world it's not that bad but you can do very simple statistics and the functions we measure - you measure a function in terms of what's called 'multiplicative depth' in this space so you kind of express the function as a bunch of additions and multiplications - in some sense - and then you kind of, you don't care about additions you only care about multiplications and you only really care about the depth of the multiplications in the sense of FHE so so you can think basic statistics you could think a mean is good because there's no multiplications, that's kind of cool. Standard deviation, there's kind of one level of multiplications that you have to do, there may be a lot of multiplications but there's one level of them and you can do very simple machine learning algorithms which are usually, kind of like, could almost always be boiled down to some form of matrix or operations which you can kind of sometimes bound the number of multiplications in terms of depth. OK so the problem with FHE is the thing that makes it hard is you only have one computing party so what MCP does is it kind of says OK, let's relax that requirement, have multiple computing parties, this means that computation goes much much faster, there's lots of theoretical results in complexity theory that says 'communication is better than not talking, so it's good to talk' which is a phrase I can use when I give this talk to a UK audience because you understand or those of a certain age get 'it's good to talk' as a phrase but the problem is talking costs. So you have to actually bother listening to someone and that takes time so talking is expensive but it allows you to do more. So there we go, so here's an application that was actually done as part of an IDASH competition we'll talk about genomes, I'm just going to go through a bunch of applications so you can kind of see an idea of how this is actually being used in the real world or being proposed to use in the real world. So this is an application that we did at KU Leuven, you've got a DNA sequence there's three billion DNA positions, you have people with a disease people without disease and you want to know and what's called a GWAS study which is Genome-Wide Association Study basically works out which mutations are associated with a disease and which not and this was kind of one of the IDASH competition problems that are from a few years ago and a homomorphic encryption example, how you deploy this in the homomorphic encryption example manner we should have three hospitals here, you distribute your public key to the hospitals, the hospitals take their data, they correct what's called 'contingency tables' which is basically a chi-squared test so there's nothing deep here, right. OK you send the contingency tables to another server, that server actually does the - it produces an encrypted significant computation and then sends it back to this server to get the result and decrypt it and then we can find out whether some DNA position creates a disease or not. OK, so you look at this and you go OK, hold on you got two servers and the reason we need two servers is because in FHE you need - one person does the computation and one person gets the result so therefore you have to have, whilst we say you've only got one computing party, you've got one party doing the computation but the person getting the result is someone different and this is kind of important so in this application you kind of see that maybe FHE doesn't make sense because you've already got two parties so why don't you do an MPC solution so a kind of picture from an MPC solution point of view would be we touch the hospitals, they connect to a bunch of servers and PC servers, they send what's called secret share contingency tables, these then do some privacy preserving computation - a bit like emulating the gold in the Millionaires example - and then we can get the answer. So you can see in this example we can kind of do both and it's relatively fast, this is easy, this is no one even thinks about doing this now this is trivial at the time it wasn't but that was three or four years ago. OK, so following that we kind of said what other machine learning things can we do? So chi-squared tests are pretty moronic so let's do something more funky, let's do image recognition this must be hard OK. So actually - so this is a bit like if I have a bunch of cards, this is a card trick you are going to choose a card, not show me the card, you're going to encrypt it by showing me only the back of the card and I'm going to tell you what's on the front of the card. Now when we submit this kind of work to machine vision people they're kind of not interested because they kind of go 'it's not as accurate as when you see the card' they're going like no **** Sherlock yeah, you try doing this, yeah. You know your eyes can't work out what the what's on the back of the card without seeing the bloody card and we can't you know - obviously it's going to be worse but some people kind of see this as kind of interesting, imagine this is a card trick. Anyway so what we want to do, imagine example is like if you want to kind of diagnose symptoms of cancer but don't think of that for a moment. OK, so here we have three parties, we have an 'image holder' who has an image, we have the 'algorithm classification provider' so for example working out whether it's the ace of spades, whether it's the letter one, whether it's the letter two, whether it's a a picture of a cat or whatever that's the 'classification provider' and then we have the 'analyst.' So if you imagine this was a security thing you might have that the image holder is to someone at the gate of an airport the classification provider is some security services who's got a list of people on a no-fly list and the analyst here is the person who's actually going to get an answer back saying is this person, is this - should this person get on the plane or not, you know, it's the security guards at the airport. OK so the way we do this is we can cheat with image classification it's really quite easy so it turns out that you see all this stuff about AI and you've got these deep neural networks blah blah blah blah blah but for image processing deep neural networks are only normally used for what's called feature extraction so this phase up here, and you can use off-the-shelf neural networks that have been developed by Google, the ones that have developed when you go to these CAPTCHAs and you have to identify how many cats there are in the image before you're allowed access to the website or how many traffic lights there are traffic signs there are in an image. So these things train - these CAPTCHAs train neural networks, you can download these neural networks and apply them to your own image. So these extract features, so imagine you're taking a picture of a beach scene and you want to detect it's a beach scene basically it's a beach scene if it's yellow at the bottom, dark blue, light blue because that's basically a beach right. So it's extracting yellow at the bottom but the feature extraction can be very general, independent of what the algorithm classification is actually doing. So we can apply generic feature extraction here to extract features this is the hard machine learning phase which we can do in the clear and we then just encrypt the features into the gateway the detection mechanism or what you want to detect which we're also assuming secrets we're assuming image is secret and what you're trying to detect is secret these can go in as secret, the calculation is performed and then someone gets the answer and we can do this, it's actually really really quite efficient. So we have this system we called EPIC which appeared at the RSA conference in 2019 and the previous best state-of-the-art system was called GAZELLE which was based in USENIX in 2018. So this is some standard images that are used to test these things, one of which is CIFAR-10 which is a kind of standard test suite. So our EPIC system was 34 times faster, we were 50 times improved in communication and we were actually more accurate so we're more accurate, faster, better in everything. If we actually wanted to have the same accuracy of GAZELLE would just be a bit 'crapper' then we're actually 700 times faster so we actually could tune how fast we want to be versus accuracy. So this is a kind of - so you can do image classification on secure data so I can work out what your credit - what your own card, your playing card is. I can work out its the ace of spades with only seeing the back of the card in some sort of encrypted form of the card. So this is kind of an application, again, this is like trivial no one really cares about this anymore you can do statistics so there's a number of people doing statistics on this call I think and you can - suppose you want to analyze two databases you have a database a and a database b and you want to combine them together to perform some statistical analysis. So what we can do is for example we can combine credit scores, we can take bank a bank b and buying correct scores things that a number of people are looking at at the moment in the Fintech area is how can we look at transaction graphs across banks to be able to detect money laundering so there's an example here, your database is your set of transactions from Barclays, transactions from NatWest how can we combine them in a way that's GDPR compliant and yet which still allows us to detect fraudulent transactions or money laundering so this is a kind of big thing. So there's been a number of applications of MPC in the real world to do this. Probably one of the most famous is as the city of Boston did a gender equality survey you know, they had 200 of the biggest employers in Boston and they wanted to work out you know, what's the distribution of salaries or different levels in the organisation between male and female. Of course what you could do is you could go through every company and go 'can you give us your payroll information?' At which point each company will go 'bugger off' and then you're stuck, right so how do you do this statistical information? So what they did is they actually set up an MPC system which would produce the statistical information on the basis of the companies maintaining control over their data so you could do this in a privacy preserving manner, you could extract the statistical information in a privacy-preserving manner. Cybernetica which is a company based in Estonia has done a long analysis of Estonian tax and educational analysis - I'll come back to a more complex example of this later - so if you do an educational intervention does this actually improve people's life chances? Now you can spot people's life chances later on by actually looking at how much they earn, how do you get how much they earn? That's how much tax they pay. So you can work out that but then you want to merge this with maybe educational information from possibly non-state actors and therefore you kind of have to combine databases that you might not want to combine other ways, we'll come on to another example later which is the US Government has student outcomes data for colleges called 'Know before you go' which has been pushed by Senator Wyden who's one of the leading Senators in the US who understands tech, he's the Senator for Oregon if you don't know anything in tech you know that Wyden is the guy to go to and so he's been pushing privacy preserving tech within the US Senate and one of these things is 'Know before you go.' What other thing - we've been doing is working with DARPA and a US company called Galois which has actually been founded by a Brit that's actually from Oxford Uni, left to the US and formed Galois but anyway so they have - we've created a database as part of the Brandeis program which was just 70 million dollar US research effort  which allows us to merge databases together and also do this in a privacy preserving way in sense that the answer. So it's not just the fact that the computation has to be secure but also you need the answer to be secured. So for example, suppose you allow - your query is 'what's the average salary?' So if I take the average salary, so if I have a group of say 31 people I take the average salary of 31 people and then I allow the query to take the average salary of 30 people, I can now reveal the salary of the person I missed out in the second query, OK? Simple maths, now okay so what there is, there's a technology called 'differential privacy' which allows us to remove the ability to extract from statistical queries information about individuals if we modify the statistical query going forward - this is a theory called 'differential privacy' and so differential privacy is kind of orthogonal to secure computation but they too often need to be combined together especially when it comes to statistical analysis. So in the Brandeis program we created a database which combines secure data computation in the database as well as securely adding on the noise needed in differential privacy to secure the answers. Differential privacy is kind of very big at the moment, it's been it's been looked at in US census, the UK census is also looking at this, other censuses are looking at it in terms of - I think the Dutch Census Bureau is also looking at how you apply the differential privacy techniques to census data. Census data already and has for about 30 or 40 years had random noise added to it to protect it against these kind of things, it wasn't called differential privacy they called it something else but it's kind of like differential privacy. OK, so Jana uses an MPC system that we build in Leuven called SCALE-MAMBA, what happens in Jana is the SQL queries which is the language used for databases are dynamically rewritten into SCALE bytecodes and executed and then applications - differential privacy are then added to the top as part of the secure computation paradigm. So we're creating a number of US Government-style applications, the kind of most interesting I think is whats called 'Know before you go.' So imagine that you're a prospective student and what you want to do is - we want to have information about whether going to college, given your background, the subject you're going to choose, the college you're going to choose, the amount of loan you have to take, whether it's going to be worthwhile, OK. So we want to merge a lot of databases so for example one of which would be information about you as where you come from. So for example that's to do with your residence, your family size, disability employment, etc. You might want - just like in the Estonian thing - you want post graduation information: where does a person go? What's their income? What's their employment? You can't rely on colleges to collect this, we know academics do not learn what their students earn after they leave otherwise they wouldn't be academics because they just bloody leave themselves, right,  if they knew what their students earn, OK. So what we have is you have, you get this information from the IRS, you then have information that you might want to merge this also with, with the Federal Student Aid Board which will give you loans and grants. You might also want to know how did the student work at university? Did they actually engage with the course? What were their degree results? What were their actual marks during the course for assignments? Whether they got any scholarships, did they work? It's very common at Ivy League universities in the US to work for the university, did they do work for the university? Did they just work in the canteen or did they help with other forms of student - you know did they take management responsibilities within the university? So we've got information there and also when you leave the - because it's a DARPA funded program - when you leave the US Military you can get funding to attend courses so there's also your G.I service record, etc. So we want to combine all these things and it's clear Princeton does not want to share its information with the US Government, IRS. IRS does not want to share its information with Princeton,  all these people don't trust each other so how do we merge all this data together to get statistics out which are privacy preserving and so the student can ask simple questions like what's the expected time for me to graduate? What's the expected cost? What's the graduation rate? What's my employment rate? What's my loan repayment rate given how much I'm going to earn? Etc, etc so 'Know before you go', know before you take on the cost of going to university. So this has been - a trial of this has been done in the US, a simplified - not precisely this application but simplified thing related this to understand about educational interventions has been done in Estonia, there's others around the world being done. OK, the final application I'm going to look at so we have some time for questions is securing cryptographic keys. So here's an application that you have, so cryptographic keys are used to secure all sorts of things within the ecosystem so for example EMV, the CAP system is your credit card and a CAP system - here's a Barclays CAP reader - this is how - well you can't see it if I go there, no - there's a Barclays CAP reader. That's how you connect to your online banking yeah, you put your card in here, you type in a thing, that's what's called a CAP reader. So we've got keys on your credit cards that you stick in here or you stick in your ATM machine, you pay. How does the back end - how does the bank secure those cryptographic keys? These are all important things, how do you, when you connect to Amazon to buy stuff - other online retailers are available - how does the website protect the cryptographic keys that are used to secure your credit card details? When you connect to passwords there's various password protection mechanisms how are password protection mechanisms which are based on encrypting passwords - which is not often done but you can kind of think of some things of password protection like that - how do you protect those? If we're looking at cryptocurrencies like Bitcoin and whatever, how do we protect what's called the 'hot wallet signing key' - so you have these things called 'cryptocurrency exchanges' where you can try - in a normal financial exchange you can transfer pounds to dollars to euros but you might also want to transfer Bitcoin to Ethereum to Zerocoin, etc - these are done on cryptocurrency exchanges and they have what's called 'hot wallets' and 'cold wallets' to protect them and how do you actually protect the keys in doing the digital signatures for these big high volume exchanges? That's a big, big issue; it takes a lot of time. The other one is if you have authenticated blockchains, how do you actually do the signatures there to sign them? And code signing for updates, so for example imagine that you are Microsoft or IBM or another big software firm - I don't know, whatever - Sony pushing stuff out to the Playstation, how do you actually sign the the software update? How do you control the code signing key to do the push of the software out to the device. This is a kind of mission critical key that's embedded in many, many software companies. It turns out that these last three - are rather important because they kind of have, they kind of have master keys that if you get it right - it's not, that's not so much if the attacker gets the key, actually is if in a legitimate usage of the key you make a mistake, your company is 'toast.' If you've got three billion dollars of cryptocurrency and you accidentally transfer it to the wrong person, you're screwed as a company. If you push out a piece of code that makes your all your customers mobile phones turn into bricks then it's also, your company's 'toast.' So you're kind of - these are things where a legitimate but stupid usage of the key can actually make your company 'toast.' So here you have lots of key control, lots of mechanisms within a company to make sure that when you do the crypto operation, management has been involved and they all agree that this is what should happen. So the last three are kind of not just stopping an attack again in the key but legitimate usage of the key can also be bad if it's stupid. OK so the traditional way to do this, these kind of operations use what's called a 'hardware security module' which are glorified blade servers that sit in your basement. They can look kind of something like this these days, every kind of blade they just slip, slot into your rack and it can cost between ten thousand dollars up to thirty thousand dollars depending on the application. They have a very, very - you can only access the key through a very specific API, the key never leaves the hardware module, that's the theory, and they go through a very, very stringent validation process to make sure they meet minimum requirements. However, their problems: they're very expensive as I said they are just - they're just a glorified computer but they cost shed loads of money. They're not that secure; there's all sorts of issues of attacks against these things with update issues, API issues and they often have a - so if you're a big organization, if you're a very large bank you can imagine that you've got hundreds of these things and you don't buy them all at once and replace them all at once you might have bought maybe 20, 10 years ago then you bought another 20, 5 years ago then you bought another 30 and they've all got different - and so therefore they're all kind of different and therefore you actually - but they all have to talk to each other so if one supports a modern algorithm and once doesn't support that algorithm when the newer one wants to talk to the older one it has to downgrade security to the lowest common denominator which is a big, it's causes great management problems. If you're running this as a bank or another - you're doing this for your web transactions or other you actually need - because they're hardware they don't, they're not elastic like you have in a cloud environment, so in the cloud environment the provision of stuff is elastic so you can bring on more servers up and down so you actually need an HSM footprint which corresponds to your peak load not your base load which means they're much more expensive. So most of the time they're sitting around doing absolutely bloody nothing and they're very inflexible API and they're not integrated with authorisation infrastructure. This is a key issue; is that the HSM just - the design criteria of an HSM is just to secure the key from invalid attack whereas we just said that one of the big problems is actually can - is actually the authorisation infrastructure needed to do things like code signing or signing for cryptocurrency exchanges. So this is a this is a big issue, so they're kind of like - they're separated from the authorisation infrastructure. We can actually use MPC to secure the keys, we could in this way, instead of taking data and put it together you take a piece of data and you split it apart so you store the key not in one place but in multiple places, in multiple jurisdictions and this was the basic idea behind a company myself and some others founded a few years ago called Unbound Tech. We produce - one of the products of virtual HSM which enables financial and other organisations, we've got what's called 'FIPS-Level 2' approval which is kind of cool. Major administrations using financially we've got a large number of fortune 500 companies using this there's a major, major computer company that's using this for all their code signing and a very large number of the cryptocurrency exchanges around the world are using Unbound to secure their cryptocurrency exchange transactions as we speak so that's like billions of dollars a day are going through our staff securing them so this is kind of - this is how we do tech transfer in crypto: you form a company, you translate a tech. None of this meeting and having meetings and stuff like that no you just do it, so embarrassingly Chris's thing. OK so where are we, to give you an idea to sum up - where are we with this technology? We have - this is what's called a Gartner Hype Cycle for 2017 there are - they're expensive to get Gartner Hype Cycle so this is just one I nicked from 2017 and you can see that multi-party computation is on the innovation trigger, it's on the up. So this is kind of like this is if you're an investor this is where you want to be you don't want to be here, this is boring stuff, this is - this is already deployed and no one's making any money out of this. So this is why there's lots of investment in this space at the moment and this is a bunch of companies in the space. I just updated this yesterday, you know every week I'm getting an extra one so the one I updated yesterday is a company called Apheris AI which is based out in Berlin they're doing NPC and differential privacy to protect various applications. There's FHE companies here, we have Duality there's an FHE company spun out of MIT we have Enveil which is an FHE company spun out of NSA in America. Zama is an FHE company based out of - based out in Paris and so on, OK, and that's it. Any questions? I've kind of wanted to sort of talk so I've given you a sort of talk - maybe been a bit too short - but have we got any questions there? Martine Barons: Thank you very much Nigel that was absolutely fascinating. Nigel: Can you still hear me with my okay - should I tell the cleaner to stop vacuuming or is it okay?  Martine Barons: Well it's not bothering me Nigel Smart: OK fine I won't then. Martine Barons: I was wondering whether it's a vacuum cleaner or a spin dryer but you know... Martine Barons: So I'm gonna take chair's privilege and ask the first question. So I think this is really fascinating I had a little bit of an idea about about this kind of privacy preserving computation but I didn't hear it mentioned at all in relation to the NHS app or the - how do you, how do you communicate this kind of idea to the public and how do you get them to get confidence in it because for example if you wanted my data and you told me that it was going to be safe and whatever I wouldn't trust you because you're the one wanting my data, right, and I wouldn't trust the government but if we have... Nigel Smart: Yeah I wouldn't trust the government either or the NHS or anybody so the point is with the DP-3T design or the Google-Apple design if you have a contact tracing app the data never leaves your phone basically. The only data that leaves the phone is the data of people who are diagnosed with COVID so it's not a mass trawl of data. Martine Barons: but I think that's - I mean because people generally still think of data collection as like you know, writing your medical records on a piece of card or at least into the computer and then you can't - everybody can see . I was wondering, what are your thoughts in terms of in terms of public confidence would it would it help or if you had an independent body that could verify that something that somebody wanted to use with you was actually privacy preserving? Nigel Smart: That's a very interesting question except who trusts independent bodies? Martine Barons: Well that's always the case but there are independent bodies that you know generally do - are watch dogs and so on and places where you can appeal if you think you've been wronged and so on. Nigel Smart: So in terms of - so in some sense it's already there because if you're under GDPR you have data commissioners or what are - I can't remember what the phrase is - so if you are doing something which breaks GDPR and they find it out, so if you're doing something which breaks GDPR then you're basically, your company's 'toast' because you'll get a fine, yeah. So I mean there is some sense that - in terms of personal data it's there. In terms of other applications it's there. So for example I said so for Unbound we have FIPS validation here so FIPS validation has taken our product and gone through an independent lab to verify it's valid. If you look at companies here, Envale have a similar thing they've done what's called - there's another form of validation called common criteria - that's hard - and so Enveil have gone through common criteria for their things. So within very specific application domains you already have these independent bodies. So that's, yeah that's what we can, yeah. Martine Barons: Thank you, thank you very much. Now over to the questions from the participants. So uh the first one is from Richard Pinch and he said firstly, thank you. Nigel Smart: Hi Richard. Martine Barons: How do we develop a public understanding of the issues involved in privacy and personal data sufficient to deliver something that the public needs, wants and trust? Is it possible to have a genuine dialogue here, if so does the IMA have a role to play? Nigel Smart: Well, I'm not sure about if the IMA wants to also include statistics, yes. So I don't know whether you want to step on the shoes of the Royal Statistical Society but let's not worry about that for the moment. You know so there's kind of issues here between in terms of general understanding in the population. So I mean it was a really good, you know post about, you know understanding - I can be my Blofeld here - you see I'm gonna dominate the world, I'm actually in a big a hollowed out volcano at the moment. Anyway that would be a good zoom background, cool, right I know what I'm doing next. What was I saying there? So the RSS would or IMA could inform the public more about basic statistics, you know. So we see this in terms of COVID-19, we see about you know the false positive rate, false negative rates on tests and the prior knowledge we all know this example you know like if you don't test everybody and something's very rare you know and it is kind of it's, you know, this is a big problem especially when just with normal interventions if you have cancer interventions and you test positive for cancer doesn't necessarily mean you've got the disease and then you have to balance things out. So I think education with that's really useful and then you know from that it's very easy to give examples about why you should trust something that's how differential privacy hasn't gone because you know just adding noise means it's hard to get other things, you know. So it's really sort of basic numeracy as I think is important but from a statistical point of view. But the other thing is that people - I think there's an issue of 'don't ask stupid questions of the public.' There was a lot of stuff with the coded apps that have been done in various countries, Italy for one, UK definitely where they went out and asked the public 'who do you trust?' And you ask loaded questions and you know what answer you're gonna get back, you know. So again basic statistics design, don't ask surveys of the people where you basically know what the answer is at the end because then if you do that and then someone goes 'obviously it's stupid' you just ruin the trust of everybody so don't try and be too clever is what I would say is one, yeah. Martine Barons. Thank you very much I think - Nigel Smart: and yes of course the IMA has a role to play, obviously. Martine Barons: Yes I was just going to mention that actually you know saying about the IMA and the RSS working together I was I didn't mind that actually the new Mathematical Sciences Academy might actually have a very, very important role there, people can actually draw on the expertise from a broad range of mathematical sciences and put them together and be a hopefully a respected body. So Ian Phillips asks: 'how does anybody prove encryption is adequately secure?' Nigel Smart: Oh now that's a good one. I just wrote a blog post this morning for a company on that. OK so the point is first, you design an encryption scheme that's number one. Then you work out what you mean by 'adequate' and they're an adequate - no, you remove the word 'adequate' and you say 'what does it mean to be secure?' Right, in a given model and then what you need to do is you need to prove that your encryption scheme meets your security definition mathematically with a mathematical proof. if you do not have that proof you will not get even an academic paper published and we see a lot of mathematicians - I don't know let's just pick some random, what's your subject Martine? I'm just going to pick a random subject so I'm going to upset you so Martine Barons: Probabilistic graphical models. Nigel Smart: OK, so let's say you have a problem in probabilistic graphical models, yeah, working out the stuff you know it's like Markov chains, Markov models and stuff like that, yeah? So you have some Markov model and then you want to work out what the initial states are, this is a hard problem for you, OK? So you go 'oh it's a hard problem I can make money, I can make a crypto system based on the difficulty of solving the Markov model' and you come up with this really clever thing and then you publish it without a security proof. OK, that is basically as bad as the physicist telling you how to do Markov models, right. That is so bad that basically means 'go back study an undergraduate course', just because you're an expert in Markov models does not mean you're an expert in crypto, you have to learn how to do a security proof in crypto before you're allowed at the table. Before you're even allowed to open your mouth, OK? So that's step one and at that point we have, and are there standard definitions of security? Yes there are, OK, there are standard definitions of secure. OK, that's step one, now step two is that we have to understand what the security proof means which means it has to be looked at by a large number of people to accept proof but also your proof will make some assumptions: factoring is hard, solving some problem with lattices is hard, solving some problems in graphical models is hard. So it'll make some mathematical assumption that we have to understand that mathematical assumption and analyse that for a number of years and then that's not good enough. What we then have to do is we then have to go through a standards process and usually these are organised by NIST which is the American National Institute for Standards of Technology because basically they're organised and everyone else isn't. So NIST organises the standards, so in your browser you use AES, you'll use SHA3, NIST is currently doing a competition for post quantum algorithms, this has to be analysed and then what we do is that then goes through a process of many years then you also have to work out whether you can implement it securely so you have to implement it securely and then you then have to take your security implementation and send it through another body to actually check that it does actually what it does says it does and then maybe you can use it. So this process could take 20, 30 years from you as an academic having an idea through to a company actually deploying it and spending money on it unless you know how to shortcut the system. But if you could shortcut the system that's because there are ways around it, you've got some trick that someone really needs, you can speed up the standards process there's already stuff available and so you can shortlist it but from a pure academic idea - new idea through to deployment, 20 or 30 years. Your mobile phone - not your mobile phone - your credit card is still using crypto from the 1980s. Your bank is using crypto from the 1970s for its internal networks. Anyway bank networks are held together by string and tape anyway so. Martine Barons: Yeah, what about the nhs then? Nigel Smart: God knows, you'd have to ask someone who has more information about it. Martine Barons: So going back to the the COVID app, Ian asks 'informing context is one thing but what about informing governments about the numbers of people who identify local spikes?' Nigel Smart: OK so there's different issues here right. So the issues are OK so where you mustn't get confused with contract tracing. Now contract tracing physically is a very privacy invasive thing. You get the disease if you do it properly, some countries don't do it properly, we won't mention names, if you do it properly - OK Belgium is one of the ones that doesn't do it properly so it's fine, OK - right so if you do it properly you will, if you are for a major notifiable disease you will have to sit down with someone and they will go through your life for the last week or two weeks and you will have to declare everything if you don't declare everything because it's a notifiable disease in many countries that would be a criminal offence so contact tracing manual contact racing is really privacy invasive. The problem with modern - and this is what you would do with outbreaks in Africa, etc where it's much more dispersed, the trouble with a first world country is that many, many of your contacts you have no clue who they are. You're sitting on the train, you're sitting on the bus, you're doing things so to augment manual contact tracing you need an automated system that will detect people who you're close to. In normal contact tracing the person who is infected loses their privacy we want the same thing in automated contact rating that the person who is infected loses their privacy. Tip, that's all that contact tracing app should do anything else is function creep and therefore it's wrong however if you just want to identify local spikes that's what doctors are for, you know, 'hey I've got - I've been infected, I've gone through' - if I'm infected I should still go through manual contact tracing so someone should walk through where I have been for the last two weeks therefore that has manually been recorded, entered into a system and you could do whatever statistics you want. The problem with some of the ideas for function creep has been as ways of stopping having to do the manual because you can't afford to do the manual because it's easier to do it the - easier to do it by computers because we don't have to think the trouble is someone has to think it doesn't work. So yeah, these problems don't occur if you just limit yourself to manual contact tracing we're going to automate for the contacts you don't know to give a benefit then it's all relatively straightforward and that's now what's being rolled out across Europe and the world not just Europe, across other countries as well. Martine Barons: Thank you that's really interesting. I'm not quite sure if you've already answered this one - Nigel Smart: Yes, there are standard definitions turn up to a standard - well, sorry, go to a good university and turn up to a course on cryptography because there are a lot of **** courses on cryptography at universities alternatively, alternatively, hold on a second. There's a good book you could buy, yeah, this is the commercial break, yeah apart from all the other commercial breaks I've put in. So there's a good book you can buy called 'Cryptography Made Simple' which basically goes through how you do security proofs and what the security definitions are and what you should do. Martine Barons: So we've come to the end of our questions unless anybody's very quick on the draw. Any more questions that anybody wants to ask? Very quickly, I'm not seeing any come up so it's just falls to me then to thank both of our speakers again. I think you've done a splendid job, it's been an absolutely fascinating morning for us and I want to thank you very much for sparing the time to prepare these talks and to come and give them to us and we have had a very large number of participants so I'm sure that were they able, they would give you at this point a round of applause. So yes of some people coming into the Q&A with 'clap, clap, clap.' So if I can pass that on for you and thank you very much again and thank you also to the IMA team who made this possible by operating the tech seamlessly and beautifully thank you very much indeed. 