 Hi. This is the second lecture in our series or data services and IBM Bluemix. As you recall, in the first lecture, we looked at the types of services available and we gave you examples of each type of service. In this lecture, we'll dig a little deeper into some of those services, their features, to give you a better idea of how you can benefit from using these services. So the services we'll be looking at today include the following: The Cloudant NoSQL database service which as you recall is a document-oriented schema-less data store that's optimized for horizontal scaling. We'll also look at dashDB which is a relational data store that's optimized for complex analytic queries. We'll look at SQL database which is a DB2 powered service that has additional quality of service features like failover high availability automated backups and so on. Then finally we'll look at the time series database service which as you recall, is a service that's optimized for storing Internet of Things time series data. So let's start off by looking in more detail, at the cloud NoSQL service. It's a fully managed NoSQL database as a service. So it means that you don't have to do any of the database management yourself. The service is available to you on the cloud anytime, anywhere. You just need to provide your code and your data. It's a document-oriented database as we mentioned earlier. And the document format is JSON. It also comes with a RESTful API which we will discuss in much more detail in a few slides. It can spread data across data centers, devices, for scaleability and high availability. And we'll talk more about that when we talk about the Cloudant sync feature. So, it's ideal for apps that require massive elastic scaleability, high availability, geolocation services, full text search, and occasionally connected users. So users that need to be able to work offline when they're not connected to the database directly. The Cloudant database service actually grew out of a specific use case. The Large Hadron Collider project. The scientists involved in that project needed a database for distributing large volumes of data to scientists around the world. And this was the genesis of Cloudant. So Cloudant was implemented using Apache CouchDB as [a pace] and then you can see several other open source projects were also used in order to develop this scalable easy to use database as a service very quickly. The Cloudant interface or programming interface is [via] an HTTP RESTful API. And here's an example of a typical call where I can get a particular document by its ID and we'll actually talk more about this in a few more slides. So the APIs support your normal CRUD operations so creating, retrieving, updating and deleting documents as well as retrieving documents via customized searches. The API, because it's HTTP based, it's agnostic to programming languages so any programming language that has the ability of making HTTP calls will be able to interface with Cloudant. It is a hundred percent compatible with Apache CouchDB. As I mentioned in the previous slide, it was developed on top of the CouchDB code. So some of the feature highlights of the cloud on API, we already discussed your CRUD operations create retrieve update and delete operations on these JSON documents. Their primary index operations and the primary index is available for every database out of the box, every document has a field called underscore ID which serves as its primary key or unique identifier. So you can find documents or fetch documents using this primary key or ID. It also supports secondary indexes which you provide. These are built using MapReduce and we'll talk more about that in a few slides. But this gives you the ability do more complex types of querying beyond retrieving documents by their ID. So for example, you can retrieve subsets of data based on the value of other fields other than the primary key or ID fields. You can do aggregation counting, summing and so on using secondary indexes that you provide. And again, we'll talk more about that later. And then there's a search capability provided via the Lucene project, which allows you to do ad hoc queries searching on documents based on their actual contents. Before we get into the nuts and bolts of the cloud and HTTP API, there are a couple of fields that are available in every document that we need to discuss. First, there's the ID field. And as I mentioned earlier, this is unique per database. Any unique string can be supplied as an ID and if you don't provide one when you create a document, then Cloudant will generate one for you guaranteeing uniqueness for that particular database. There's also a revision number field that's maintained by the Cloudant database. And each document has a unique value of this. It's generated using an MD five hash of some document-specific information. And if you look at this example here, it's always prefixed by a number. And in this case, the number represents the number of times that the document has been updated. So for example, here, the number is two. So we know that this document has been updated two times. Whenever you're doing any kind of updates or deletes of a document, you must provide the latest rev value or the request will fail. And why this is important is this will prevent different applications from updating outdated copies of documents. So if you have two applications using the same database, one has an older copy of a particular document and tries to update that. By overriding a newer version of the same document that update will fail. So it's very important in applications to keep track of the revision numbers and if you do end up in the situation where your update fails because of an outdated document, you would then have to go back to the database, fetch the latest version of that document, merge your changes into the latest version, and then do the update again for it to be successful. So now let's go through the API and look at a few operations. So, the first operation we'll look at is a very simple one. How do you return a single document? Well, it uses HTTP get verb with the name of the database and the ID of the document in the URL. So here's an example of getting a document with ID 100 from the author's database. And as you can see, it's a get requested appropriate URL followed by the name of the database authors followed by the ID. And what's returned is the JSON document that represents the document that we just fetched. Now let's look at inserting a document. There are two ways do this. You can do this via post operation or via put operation. The key difference between these two approaches is that when using post, you need to put the document ID in the document body. Whereas with put, the document ID must be in the URL. So, let's look at a post first. We would do a post including the document that we wanted to insert. And there's our ID and some other fields that we created for a document. And when we executed this, we would get an indication that everything was okay. And we would also get the first revision number. The first generated revision number. And as you can see there, it's a one because this is the first time that this document has been written to the database. Now, if you do it via put, very similar approach. The difference is that the ID goes in the URL itself. And so now we have the document without the ID field. And when we execute that, we get a similar response. Now we'll look at an update. Well, it turns out that the updates and creates use the same operation, put or post. So these operations are essentially overloaded. And the way the semantics work is that if the ID exists for one of these operations, the ID, specific ID exists in the database and it's an update. If the ID does not exist or an ID is not provided, then it's considered a create and a new document is added to the database. If you're doing an update, as I mentioned earlier, you do need the latest rev version or the operation will fail. And similar to a create, you can do it via a post. You can do an update via post or via put. So via post, the ID is in the document body. And as you can see here, it's very similar to the create, except now you see I need to have my latest revision field or this operation will fail. And I get back a response. As note here, you can see that the revision number has been incremented to two because now I've updated the document again. Doing the same thing via put, again, the only difference here is that the ID is in the URL instead of being in the document, and as you can see here, I have the document to be updated, I have the rev field, I don't need the ID field because that's in the URL. And similarly, I get a response back with a new revision number indicating that the document has been updated again. Now, let's look at deleting a document. This also can be done with two different verbs by HTTP delete or a put. And like an update, the latest revision is required or the operation will fail. So let's look at doing a delete via the delete HTTP operation. In this case, both the document ID and the revision have to be in the URL. So I issue that HTTP delete request with the ID and revision number in the URL and then I get back an acknowledgment saying that the delete was successful. If I'm doing a delete via put, then I need to provide the document ID and the URL. But then I have to provide a revision number in the document body of the request and the deleted true combination in the document body in order to delete via put. And when I execute this, I get back an acknowledgment saying that the delete was successful. Now let's look at secondary indexes. As we mentioned earlier, these allow you to do more sophisticated searches. In Cloudant, secondary indexes are developed using MapReduce and as I mentioned, they allow you to return specific subsets of data that you define in the index code itself. You have to provide a map function which returns a list of key value peers. You must have a map function for your index. And optionally, you can also provide a reduced function which will reduce that list to a single value per key. The reduced function is optional. And I think this will become clearer, the distinction between the two will become clearer when we go through a specific example. Both map and reduce functions are written in JavaScript and they are stored in the database in special documents that are known as design documents. So let's look at the specific example. And hopefully this will make the map and reduce functions clearer. So, we'll start with a database that's a list of cars. And here we have five values. Each document has an ID. It has a make. It has a model. It has a year, and it has a book value, which is the book value of that particular car. So now let's do a map function that gives me a list of all the car makes and their book values. And here it is. It's JavaScript function that gets each document as a parameter. And then it has to do something. So in this case we're calling emit. And this is what the map function is actually returning. So we're returning the make and the book value. And the first thing that's returned is always the key and then everything else is considered a value. So, in this case, we're creating a list of makes and book values and returning those. So we also want to aggregate the book value by make. So for each make, Audi, VW, we want the aggregated book value and we do this via the reduce function. So in the reduce function, we simply return a sum of the values. And as I mentioned earlier, those will be aggregated by key so for each unique make in this case, because our key is a make, then we'll get an aggregated book value. So let's look at the results. So the results of the map function for each document, it will return the make as a key and the book value as a value. The reduce function as we mentioned will return a single line per key and since the key from the map function is the make and for each make we'll get a single line, so in this case, it will add up all the book values of the Audi documents and all the book values of the VW documents. So those are secondary indexes. And because they're written by you, you can do a lot more sophisticated thing, but this is a typical example of returning a subset of data and then doing some kind of aggregation on it. So now let's look at Cloudant sync. This is a built-in replication feature that allows you to have distributed copies of your database in mobile devices, remote facilities, sensors and any Internet enabled device or server. So it allows distributed or mobile apps to scale by replicating and syncing the data between multiple copies of the database. So and this includes databases running on IOS or Android devices. Or anywhere where Cloudant or Apache CouchDB can run. For mobile development is particularly useful because it allows you to create a single local database for every user. And it also reduces roundtrip database requests with the server because if there's not a network connection between the local database and the remote database, the app will run using the local database and automatically sync with the remote database when the network is restored. So, that's it for the Cloudant NoSQL database service. We looked at the HTTP API and we also looked at some of the advanced features like Cloudant sync. So now let's turn our attention to the dashDB service. So, this is a service that provides data warehousing capabilities to applications running in the cloud. So it's essentially a data warehouse in the cloud. The service in Bluemix does give you a perpetual free tier with up to one gigabyte of stored data and then there are various other levels that allow to you extend that to meet your needs. dashDBs are relational database and it stores relational data in a format that's optimized for doing complex queries, including data mining, predictive analytics and geospatial analytics. Under the covers it's powered by DB2 BLU Acceleration, and some in-database analytics that were initially developed for the Netezza database appliances. Load acceleration is very fast. It's very simple. It's an example of an in-memory columnar database and it does things like compresses the data to allow more of it to fit in memory and more importantly, it's blazingly fast on very complex queries. Especially those that involve a lot of aggregation. And there's also the in-database algorithms ported from Netezza that allow you to do more advanced analytics in the database itself, making it perform much better than an application could by fetching at that data and doing those calculations outside of the database. Now let's look at SQL database service. This is a relational database service available in Bluemix that's powered under the covers by DB2. Like all our other services, it has a perpetual free tier. In the case of SQL database, this includes up to a hundred megabytes of data. And there are two other tiers available to scale up into as your needs grow. So as I said, it's a relational service running on Bluemix powered by DB2. And it gives you a DB2 compatible database to handle all of your web and transactional workloads. It also offers additional features like high availability, automated backups, and some data privacy features where you can choose to mask certain data in certain columns that may have sensitive information like Social Security numbers or credit card numbers. Finally, let's look at our time series database offering. This is particularly useful for Internet of things, devices that generate a lot of time stamped data. It includes a perpetual free tier of up to one gigabyte of stored data. And then there's an entitle page sizing that goes up to ten gigabytes. It offers very efficient storage of time series data. So compared to other database technologies, it can use less than a third of the space to store the same timestamp data. And it also offers SQL extensions that make it easier to write applications because you can do more complicated operations on time series data. It also has extended functions for handling spatial data so you can do complex queries that involve GPS score nets. The time series database option is powered under the covers by Informix and for its API, there's both SQL and NoSQL JSON interface within the same database. In particular, you can use JDBC and you can also use MongoDB style queries to receive the data in JSON format. It also has the ability to move data between the two interfaces. So in summary, we looked at some of the unique features of some of the services in IBM Bluemix. In particular, we looked at the Cloudant NoSQL database service, which is document-oriented schema-less and optimized for horizontal scaling. We looked at the dashDB service, which is a data warehousing service for relational data. We looked at SQL database service, which is a DB2-backed database service with some additional features. And we also looked at the time series database service which is a managed data store that's optimized for timestamp Internet of Things data. 