 in the last video we looked at how to send a compute job from the login node to the compute cluster portion of the supercomputer one advantage of the compute cluster is that it lets you perform highly parallelized computing in other words it takes advantage of lots of computing resources that are connected together and allows you to distribute the workload for large compute tasks across many processors or even nodes in this video and the next we'll look at two approaches for parallelizing a job the first which we'll focus on in this video is to simply divide the job's computation across multiple processors on a single node on the supercomputer that i'm using here the owen supercomputer at osc each standard compute node has 28 processors a task can be distributed across this approach to parallelization is usually the easiest to implement since most of the instructions will already be embedded in the program you're running that also means though that this approach depends on the software you're using being set up for it we'll keep with the example that we used in the previous video on loops of aligning five fastq dna sequence files to a reference genome with bowtie2 here though we'll just work with one of the five files we'll go back to aligning all five in the next video information on getting the software and the files you'll need to follow along is pasted in a pinned comment under the performance options section in the bowtie 2 manual there's an argument designated with either dash p or dash dash threads that allows you to set the number of threads used in the analysis in practice the terms threads cores and processors effectively mean the same thing so in the command for the bow tie 2 run we can add the dash p argument set it to say 6 and as long as there are 6 processors available the software will divide the computational work among them now that last part is important for the software to use six processors there have to be six available so we need to make sure to request that many when submitting the job we first looked at a job script in the last video here's an example of one i might use for this bow tie two job notice i've requested 6 ppn or processors per node and then as part of the command to execute the program i use the dash p argument to tell bowtie2 to use all 6. if i had requested the 6ppn but left the dashp argument off the job would still reserve the six processors on the supercomputer but the analysis wouldn't be parallelized and would only utilize one of them not an efficient use of the resources in contrast if i only request a single processor but ask bow tie 2 to use 6 the parallelization won't happen and the job will just use the one that it has the speed increase you'll see with additional processors depends on the software in some cases it might be nearly linear with four processors the analysis would take one fourth of the time eight processors an eighth of the time etc other times adding additional processors might only slightly reduce run time software documentation and also test runs can help guide your decisions about the most efficient way to set up a run in the next video we'll look at a second approach to parallelization in which a large job is broken into multiple smaller tasks that are each submitted as separate compute jobs 