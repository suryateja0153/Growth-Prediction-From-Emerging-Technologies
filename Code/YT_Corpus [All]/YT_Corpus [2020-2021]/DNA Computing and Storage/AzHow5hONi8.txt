 uh welcome to the third short course for the ngs data analysis so today we'll be talking about the RNA-seq data analysis using the hprc resources so again my name is shichen wang i'm bioinformatics scientist in agrilife research okay so we will be talking about ionseq i assume everyone taking this course will know one or two things about ionseq so i will just go very briefly about how ionseq goes so basically when you do ion seq you'll start from mRNA but you we don't we cannot sequence mRNA directly we can transform mrna to cdna and make libraries based on cdna then put library on the sequencer so if you attend the last two courses you should know a read write sequencer speed out of data and those soft fragments we call them reads so those are ic data we're gonna get from the uh sequencing facility uh so with the read what we can do one thing we can do the number assembly so if you if you are interested in uh assemble the transcriptome yes we can use this data to run the normal assembly so another popular topic about ionization is we want to quantify a relative expression level of genes so for that we can map those reads to the referent genome so based on the alignment of the threads to each gene we count how many reads mapped to each gene and normally we're going to have a table like a list where you call count table or column matrix so you have the gene name and you have a different treatment of different conditions for based on the based on the experimental design so from this table or column matrix we can do differential expression analysis so the idea for ionseq is generally like a list and it's not very hard to understand and we will not be paid too much attention to how we make libraries you know sequencing so we're going to start from when we get the read how do we process those okay so what can we get from the ion seq data so basically we can use them to to measure the expression level but remember it's not the absolute expression that was relative and we can use those reads to enter the transcript let's say you have referent genome and you want to figure out the gene structure so you can do ionseq data and map lines the data to the transaction to the left genome to figure out the gene the internal action boundaries all those things you also can use iso data to discover a new transcript a novel transcript and another thing is we can use iso data to run variation discovery right it's similar to to what we have talked about before like a dna seq well without sequencing data we can run valuation discovery but it's not very popular because the variation the variations will be very limited within the uh exotic region and we know that genes are tend to be conserved so the variations in those regions are very small and we won't see many but you still can use that for for this purpose okay so when we start the ion seq experiment many times and you can probably ask yourself how many reads do i need for example right or if you're only doing if you are doing a uh experiment differential expression differential expression analysis you want to know how many replicas to do should i have so so all these questions are depend on your experimental objectives is is what is your goal of your project right so if the goal is to detect defense express the genes or is it goes to energy transcriptomes or to detect nuclear uh variations so when we talk about the replicates we're talking about two kind of applications the biological replicates or technical replicates so biological applications means you you sample multiple times from the same population a technical laboratory means you just run this uh sequencing or library prep library preparation multiple times so many cases for ic data the biological replication is more important than technical replicates so we're going to pay more attention to biological replicates rather than technical duplicates and here's a table summarize some um thing we need to consider so again if you want to check more details you can go to this website rnaseq.uoregon.edu so they summarize a lot of good materials there but when you're talking about let's look at some of the criteria here so biological replicates if you're trying to run annotation gene annotation is you don't have to have biological replicates because they're not interested in that right but if we are doing differentiating expression it becomes very important and the coverage across transcript yes it's very important when you are doing de novo assembly or g-annotation because you want to cover the whole gene but it's not as important as that because when you are doing a gene expression analysis because you want to count how many reads map to the gene it doesn't matter it's mapped to the end to the left end to it to the right angle to the middle of the gene so it doesn't matter at all and the depth of sequencing yes for generation is important you need to have enough coverage to to cover the whole transcript for different expression is the same you need to have enough reads but not too many i mean too many just give redundant information in this case in both of the case actually the row of sequencing dapps obtained rays overlapping along the length of transcript yes sketch enough counts is for different expression gnss oops dsn so it's uh it's it's one dsn's uh uh it's a library normalization method so it's not recommended for differential gene expression analysis since it can cause some bias and stranded on stranded people asking do i i need to have stranded or unstrained libraries when you are doing rna seq so it's important for de novo assembly and you can either identify to antisense transcript but for differential gene expression analysis is not very important you see we are counting reads for the case uh do we need to have really long reads or short rate okay so for g annotation yes you it may be better to have long rates yeah if you're doing generation or general assembly longer rate provide better information but for defensive expression you don't really need to have long rates so the the recommendation here for a differentiating expression is like a 75 base pair that'd be good enough but for g annotation it has longer the better so the last one is power and rates uh do we need the power n for annotation which instructor structure orientation yes it's important for the annotation of what for general assembly but for differentiating expression it's not important so see there are many factors there but it all depends on uh you'll project what is the goal of the project right there are papers talking about let's say if they want to do a differential gene expression so people paper talking about how many biological replicates are needed so this is a very long title for paper how many biological replicates are needed in a honest experiment and which differential expression tool should you use see how long is that so this paper actually very useful it gives you a lot of information how about the replicates and the popular tools so uh and talk about a little more a little bit more so i think the the if you yeah i would highly recommend to check out this paper i was talking about uh probably six replicates are needed for uh to get uh to have 90 percent of power detect the differential expressive genes so and the difference the tools you can use like hr and d62 so i think the recommendations like hr uh or d6 so those are still i mean it's still the those are popular ones but the only things i i've seen many projects when they come to us for sequencing they have three replicas for each condition so it's okay but according to this paper it's better to have six so see just to improve your power detect the differential expressed genes okay so those are background of iseq and the effectors you need to take into account when we design an iec project so how do we do the data analysis on hprc system i'm going to go through some of the tools and how to use them and we're going to do a hands-on analysis with the galaxy so let's start from where to find the ngs tools so on hprc you can go to hprc.tamu.edu we have a wiki page if you're looking at the bioinformatics tools on ada you're gonna this is gonna be the url you can go and also if you have a specific name like a tool name you know you wanna see even check if it's available on hprc you can use the the command here module spider or module of value so those are uh if let's say i want to see if the trinity the general assembly tool is available so i just say module spider trinity or model real trinity a module spider trinity so to give you information about two how to load that tool sometimes you have a very short example for you how to use those tools so if you have a tool that you want to use but it's not installed on ada yet you can send email to help@hprc.tamu.edu so i know because the tools are just keep being developed and many new tools you may want to try so just send us an email if you have some new tools okay so another very useful tool is developed by michael dickens so it's called the gca gca templates on ada system i think we are trying to migrate into tarot two so the thing is we list two templates provide a lot of um you see how many here one two three four 16. so a lot of templates for the how to submit the job on hprc let's say i want to do a genome assembly genome assembly uh project onto plc so if i load this gc80 template i'm gonna show you the screen here as a the terminal and you just select uh six gonna be genome assembly and i'm going to just follow the uh the instruction on the screen and then give you you know eventually going to give you a a script file uh with how to run it how to run the genome assembly and you need to fill in your own data set because in the script in the template file it has a fake one so you have to provide your own real data data file name there so it has it has ion stick data analysis pamphlet 2 so you can go try okay uh let's talk about a little bit about the general idea of data analysis for rnaseq so it's the same idea when you have a signals and data you want to check the quality so normally we're going to be using faster qc to visualize the quality scores display to display the score distributions all those things and you're going to have a summary of a lot of things for your faster qr file so fast q5 is the file you're going to receive when your sequence effects facility does synthesis for you so we have on hprc we have faster qc so you you can run it on hpsc to load this module just say module spider faster qc going to show you how to load this module so to actually load this module will be module load faster qc and it's a very it's a java uh it's two using java so it's very easy to use and okay once you check the quality of the faster qc a faster queue with faster qc you want to do something with the data right you might see some uh reach have very low qualities on on both end or one end of the reads or you see a lot of reads have adapted left overs so you might want to trip them trim them so one tool we can uh there are many tools to do that so say well we have a popular one here called trim mimetic so you can use module load chumatic to remove the local databases and the adapters and if you if you attended last course we are talking about evaluation discovery and we also talked about this quality trimming thing so for variation discovery quality trim is important so think about the if there is a if there's an arrow in the read and gonna align to reference and they're gonna report s and p but we know it's not true s and p it's just caused by that sequencing irons so it's critical for the variation discovery smps in the other things but it's not very critical for ion single data according to trimming sometimes people don't even do this qualitative treatment anymore for rna seq but i would recommend just to uh remove the adapters as this when you are doing the denoble assembly because you know assembly they're going to put those adapter together and give you a false contact but for differential expression analysis so we are simply counting how many reads aligned to a reference so this is not critical okay so other tools for helping you check the quality and everything is another popular one called RNA-SeQC and it's the same it's the same command you can use module load so module spider just basically give you a description of this tool so you to actually use this to have to use module load okay so it's what you can do you can uh if you have done alignment gonna have give you the yield and manage the yield alignment and duplication rates gc bias rna contents all those things and if you have a reference genome and the energy annotation can tell you the alignment to axon internal intelligent negative things so it's a useful tool but it depends on if you have alignment done off not okay so talking about alignment it's a step we map the ic read to relevant graphing genome or reference assembly so is it can be a so it can be a whole genome sequence a whole genome alignment a whole genome assembly or it can be a transcription assembly so you can do both okay um when we map the ion sequence to the to the genome sequence we need to pay attention to something called splicing right because in iron-c there's no intro but in the genome sequence introns ex implants are there and they're separating axons so we need to use some tools can do splice aware alignment so some tools like high stack too and if you have been doing anything before you're probably familiar with top half 2 so high stack 2 is the it's a better version of how to and st ar or star or ada would be a star star so those tools sometimes they do quite different uh it will give you different outputs like gf5 or gtf there are also tools to help us to convert gtf or to igff to gtf all those things like jff read so if you are doing bio sequencing you're doing iosec yeah some tools like star or gmat or bb map can do those too so back boundary signal give us a very long read so basically you will get the whole transcript most likely you've got a whole transcript in one single read so it's a good way to uh to do honestly because you don't have to do the nerve assembly if you are interested in the uh the gene structure but if you are interested in the difference expression it's not recommended you to do like a bio or anything okay so if you want to see how the alignment looks like if the if the reads are going to the x and according to the axon it's not going everywhere like an intro or something so they are like uh you can use like tool called igv and it's available in gps c2 but you need to log in uh using the portal so it will be pontoon.apsc.edu and once you log once you go there and click on the interactive apps and you see the igb there so igb basically going to show you the alignment so the same file or if you have is i can also show that gene notation file so basically you can load the genome sequence you can load the uh gene notation then you load the alignment file so then you're gonna see clearly if the reads are going to the axon oh it's very beautiful so i'm not sure this example looks clear yeah so this is gonna be the interface for igve and uh you can select chrome songs like the referent genome and this is the alignment files one from one of the bam files and you have the uh on the bottom you have the gene notation see the blue box they are like axons to see the rays are aligned there two axons and those thin lines just at intron so basically you see very few rays supposed to be aligned to intro so you see this like that okay so the most popular analysis for insect is to detect the differential expression genes between multiple conditions or something like that so to do that when the alignment is done we need to count the the rate back to each gene uh there are other tools like developed for non-alignment based so basically you're gonna need the you're gonna need the transcript sequence you can either left a faster kill file for the reads and it will count you're going to assign the read to its transcript based on the k-mer and the similarity so there are lots of tools for alignment based like ht count and it's gonna give you a non-normalized alignment what is what does that mean what is that non-normalized alignment counts so it means it just count how many reads it will not take into account the uh the the the library size or the the uh the gene lens all those things but they are normalized the ways the way it's known like uh there are ways to normalize accounts like ipkm fpgam uh tbcam so different tools i'm going to give you a different output the rpkm and fb cam they are similar and the tpk tpm is the actually the recommended one the ip cam and the fb cam has certain problems for different expression analysis so now uh now the tpm or cpm or lock cpm or something they uh they are highly recommended now not the rpg game fpgame anymore so for the non-alignment-based tools we can use kalisto because pseudo-alignment so it's a salmon economical salmon or sailfish and i have been trying those tools those two can go really fast because they are doing a lot they're not doing alignment so when you when we're trying to use alignment base tool you think about the alignment they're trying to figure out how each base single base aligned to that genome but we don't really need that information right we just need to know this risk goes to this gene that's all we don't know we don't know we don't want to know how exactly they're aligned so that's how the non-alignment based tool they something use pseudo alignment or not alignment at all so they can speed up the analysis really fast and if you have like uh data you can actually try to run both alignment based on non-alignment based and try to compare the difference so the tools give you different outputs so for alignment basis you might get at uh the recon matrix and you can count it the tpm based on that but the non-alignment based i think they only give you a tpm so there's no you cannot calculate rpkm if you can from the non-alignment based method okay so sometimes people got confused of the ipkm or fb game it's just a so for rpkm or fpkm just initial for reads per kilobase of transcript per million mapped reads so it's a one is a way to try to normalize the first to normalize based on the transcript lens second try to normalize based on the library size so let's say if if one gene has a gene a and a gene b gene a is one thousand pistol long and gene b is 5000 base pair long so the longer genes have have more chance to capture the reads right because the rates are generated randomly so the longer you might have higher chance to capture reads so you have one read for gene a five rate for gene b if you normalize them based on based on the gene lens they will be the same another way another thing is the library size so let's say i have this sample sequence this sample sequence is really high uh high depth it gives me say 5 10 million reads but this sample only sequenced at 1 million reads so the sample in in the first sample you might have a lot of risk to one gene compared to a second sample but it's only because the library size are different so that needs to be taken into account so ipkm and fpkm are basically the same and it was popular but now they were not really recommended they're not really recommended for running different expression analysis but the tpm is another way to measure to do normalization so it looks very similar to rpkm and fpkm even the calculation is similar but this we the tpm switched the numeration so first is normalized for gene lens then normalize the sequence defect so the tpm is more reliable and if you want to know more details you can go to these uh websites at rna-seqblog.com and have a very clear explain okay um okay let's go to the tools we can use for around this differential expression analysis so we're going to be talking about alignment base 2 so on one popular one is the tuxedo shoot and uh for the alignment we're gonna be using high sec 2 or top hat too so the old version of tuxedo should going to be using top hat 2. so now i'm going to be using high secure a high sector is a splash aware mapping tool and it was a it was a better version of top hat two so cuff links so once we have the alignment done and so besides the genes we already know with the gene notation file we might have some new genes so we can use cufflinks to assemble the aligned reads into some transcript then compare with what we already know we probably discovered a normal transcript so this step called cufflinks can can run genova assembly not uh but it's a lot it's a reference on guided general assembly and once you have the uh g annotation and digital assembly down i'm going to give you a new g annotation file and going to combine them with the old one then come out the merge generation file so based on the gene notation the new generation file we can estimate uh the abundance or expression level of genes between groups so the output will be like a list on this here have a short very short table here so first i have a test id basically it's uh it's just the id and have a gene id this is the gene id in the generation file local sample one sample two status value one by two so log 2 for change test stats p value q value and significance so when we need to pay attention to the significant or not significant the student test is based on the q value so it's a it's a fdr corrected value it's a q value so fdr as just the p value for the for the statistics so you want to see if this if the significance say yes most likely you have the q value less than 0.05 so i think we still have the same yeah if it doesn't matter how the taxi should change the tools the output the final output i think is still the same okay so the new tuxedo protocol is a paper published in 2016 it's not um you're gonna have some new tools there so uh i don't have a much project involved with this new tool yet but yeah it's higher you can't recommend to try it okay so the seller fish is one of the non-alignment alignment-free uh ic data analysis tool it's using k-mers so obviously you will need to have the target transcript either from a referent genome or form for general assembly and when you need to have a sequence read right okay so based on the based on the uh the k-mer frequency you're gonna estimate this rate what is the it's the probability acting actually what is the probability of list really belong to list and based on that you know we're gonna give you an estimation of tpm i also have a number of reads so for example we have a table here i have this gene called trinity something so this is obviously it's a general assembly from trinity and for this transcript is what is the lens effective lens and the tpm and the number rate so some tools will take some tools to only take the lower rate like the hr or the d62 or the dc yeah i think they only take the raw rate so the last column will be the one you need feed to those differential expression analysis tools okay there are many are uh packages developed for unc data analysis actually those popular ones like hr or d6 are developed in r in the r by conductor package so in hprc we have the by conductor already pre-installed so we just need to load it with the module load our timer so there are if you try on the ada say modules by the r you're going to see a lot of different versions of r so we have our regular r and r 10 move so you know to use those tools you need to install those packages let's say i will use hr you need to install it first but if you are loading this r tamu uh most likely we have those tools uh already installed for you so you don't have to install it by yourself i mean you can do it just and you have to install the packages to your local directory it's okay it's pretty easy to install okay so one more topic about rnaseq is we can use is data for some transcriptome assembly and i've been talking about a few popular tools for transcription assembly so comparing to whole genome assembly transcription okay let me just answer this question on the transfer say is possible is it possible to use output from top hat 2 and use d62 to generate the plot in galaxy gg plot um so to so first yes high set 2 yes yes we can use high second 2 output from asset 2 but we cannot directly use high set to feed to d6 right so we will have to generate the com matrix first from the high step 2 then feed the column matrix to d62 yes to generate the plot in galaxy so guys see so far we are not having that many tools for for making plots but if you have specific plot you want to use you can send email to michael and he can probably help you install those tools ggplot is very popular and it generates a very nice plot very nice figures and for the hands-on session we'll be actually using high set 2 and hr then we're going to make some plot like a volcano plot and then something a heat map thing in galaxy okay go back to the transcriptome assembly and uh popular tools like a trinity i am sure most of you heard about this if you are doing an inc assembly so trinity it can either use a referent genome or no referent genome so high stack two cufflinks i've talked about before you you have if you have cufflinks you can do some general assembly too scripture and string tie string ties part of the new tuxedo tool so yeah the chess criminal assemblies is compared to the whole genome assembly transcript assembly is much easier and it takes less resources and so we can so the hprc has good resources computing power to do that so and you know innova assembly was with no different genome so they can do it and another tool like oasis or yeah actually some other tools can also do everything list all those tools here but trinity is a popular one alternatively is not only one tool it actually has a lot of uh tools for for downstream for once you finish the assembly or downstream like i finished assembly i want to see the operating frame i want to have the proton stick protein sequence even i can i can run some functional annotation let's say i have this transcript i'm going to blast this sequence against on our database figure out what is the possible function or plus or the uh geo category or the keg pathway so trinity has a lot of tools for doing the downstream analysis too okay but for running trinity on our hp system is one thing to remember so trinity use a lot of intermediate files it generates hundreds of thousands of files so sometimes if you're running on the htrc you're gonna get some arrows like your your file quota is exceeded or something like that so because yeah we're not expecting you to have so many files so you can contact help@hprc.tamu.edu and require a file quota to increase before running trinity so just let us know you're running trinity we know what kind of problem you're gonna have so we're gonna adjust it and don't run too many training jobs at one time and just yeah check the resources you have you can you might run out of space you might run out of file code because it's just too many intermediate files okay another point is to um 20 degrees the checkpoint can be restarted if it stops due to some arrows other memories or runtime something but if you are using a temporary folder like temp dir the temporary folder once the job is finished everything in the temp folder be deleted so if you run the temp folder that means those intermediate things can be installed in the temporary folder and once it's stopped for whatever reason those files can be deleted so you cannot be restarted so just keep in mind that and we have a trinity template in the gta template script so once we have the transform assembly done what we can do is when to check how good its assemblies are so one thing you can check is is all the uh genes um first we want to check what is the completeness of the genes like we want to see do we capture allergens or do we mix them how many of the genes are complete and how many are recommended so to do that there's a tool called bosco you're gonna use many of the single copper genes to access the transformational assembly so we so in bosco they collected some conservative genes for different taxonomic groups if you are doing bacteria or insect or vertebrate so you collect some conserved genes they'll be using those genes to estimate your transcriptional assembly so to load this either just module on load split scope so here's the output of the uh of the bosco so you will see if you if you are running different assemblies say with different parameters or different data sets you're going to see assembly one how many are completed how many are are missing how many are fragmented so from this plot assembly one to three it's just a very small difference so you can so you can use different tools you can use different um like uh different overassembly tools like uh trinity or oasis or something else so then you can use this tool to estimate the performance those tools okay do you have any questions so far i'm probably going too fast okay so so we're gonna do a hands-on analysis using the galaxy but we're gonna do we're not we're not going doing uh the general assembly because take so many times okay so we're going to do a hands-on analysis for the detect differential expressed genes so this is the steps first we're going to do our quality check with faster qc then we're going to run trim adapters and no locality basis with the tool cartridge pneumatic and third can be alignment those qc reads to referent genome with the tool called hi-sec-2 then with alignment down we're going to we're going to use these cufflinks to to do genova assembly and then the assembly gonna merge uh gonna merge with the original universe original gene notation so we're gonna use the tool called cuff merge so once we have that we can use the different expressions to call hr and to run the differential analysis once that is done we're going to run the visualization just to show how those gene expression how they are different between the two conditions we're going to make a heat map and then we're going to make a volcano block okay let's see here's the question on the chat say if you all care about the introns with those aligners and transcript assemblers account for internal differences like being able to detect iso forms with different interns i'm sure if you are talking about de novo assembly or just talking about alignment so for the nervous assembly uh yes trinity going to give you different iso forms based on the so you will see some transcript it's like you can detect other forms so from trinity i'm gonna see some introns are being uh integrated into transcript because the reader continues so if you're talking alignment uh the alignment yes alignment will be whatever it's the tools tell the wrist go to and if it's mapped to the intron it can tell you yes those are input that is part of the transcript so we're gonna show you there so the tools yeah so okay okay so we are going pretty fast okay so we will not be using the terminal as we did last time because this time i'm going to introduce you something new and it's called galaxy i know many of you have been using galaxy already so it's not a new thing to you so galaxy is a open source and web based platform for data intensive biomedical research so it has a lot of bioinformatics tools and they have a public version of galaxy and it's free you can go there i think it's called use galaxy.org or something you have to know more details about galaxy i'll be galaxyproject.org and use galaxy dog is a server for you to use and for free but because it's free so and limited computing resources you can probably sit in the queue for a long time before your job can get executed and look you can also install guidance on the local server for example uh maco installed the galaxy on hprc so we can use this hprc to to run the analysis and you're gonna and and the galaxy can use all the uh https resources yeah to learn more about galaxy you have like a lot of screencasts and galaxy 101 you can even involve being involved in the developing development of galaxy okay so we will be using this this is the this is the server um micro uh installed galaxy so you can click on this link to go to the galaxy if you want to follow on the hands-on practice so um you don't need to have any data i have prepared the data for you but for that if you don't have accounts on this galaxy so okay so this galaxy is ontario you can see galaxy-terra.hprc.tamu.edu/bdf so if you don't have a count on terra you probably cannot use this galaxy okay here's a question say can i use highsec 2 pipeline without trimming so i'm saying trimming is not very important unless you are doing dino assembly or you're trying to discover variations so yes the answer is yes trimming for iron sig for differential expression analysis is not critical you can just go ahead and use it okay so let's uh before we start i want you to make sure you have the account ontario first then make sure if you have account error and if if you click on this link and clan log can cannot log in that means you don't have account on this galaxy so please send the send your eid to uh to michael to michael dixon i think she he is on the yeah he's there i see him deacons so you can send send a chat to to him and ask him to add you to add your erd to this galaxy if you want to follow and let's take uh 10 minutes 10 minute break and come back i'm gonna do some hands-on exercise we'll be back in 11 20. yeah 11 25 and i have less okay so once you lock once you click once you went to this pdf galaxy you have this web you'll have this page and okay so i have the data prepared and you just need to to get it from the shared data so in the shared data data libraries and you're going to see iron sig data and i'm going to click on ic data then select all of them and gonna be export export to histories as a data set okay i'm gonna show you here so share data data libraries okay i see that i'm going to click on this unsafe data forgive me list i'm going to select all of them then i'm going to export to history okay as datasets and click it so you're asking you you want to select to you're going to export to existing history i'm going to create a new history so i'm going to create a new history called honestly july whatever 20 okay then click on this import okay so so if you don't have the if you don't see the share libraries let me see i probably need to add you there oh okay i have a lot of people i haven't added yet oh man so if you don't have them if you don't see the data just give me a second i'm gonna add in you all oh wow okay so now if you don't have the live share like share data show up maybe refresh your page and try it again okay good okay so if you remember going to be click on the iso data select all of them then say export to history as datasets then we're going to create a new uh new new history so give the name so i already have one called is july 20 so you can choose whatever you like then click on the import so once you've done that you should have a history with the data loaded and let's click on the user and histories so then click on the history just created for example mine is insect july 20 i'm going to click on that so we're going to show you on the on the right on the right side right panel we're gonna see seven uh eight files showing up there so those are gonna be something those are the days that are gonna start okay so remember let's take a look what we have here just ignore the yeah just ignore the middle part yet so on the right on the right panel we have one gene annotation.gtf so this is the annotation if uh for for the jeans if you click on the eye the eyeball here is actually view data click on it you're going to show in the middle you can tell you the sequence name the source and something so it's a gtf the first one will be the content name or chromosome name second will be the source and it can be empty and the features can also stop cooldown stop calling axon cds axon so those things and the start and and the score strength frame attribute so in the attribute you're going to see that gene id and transcript id so one gene can have multiple transcript so the grd and transcript id okay so this is for the first file and from two to seven are faster queues so those are the files you're going to receive from the sequencing facility right and we can take one of them just for a quick look let's say click on the eyeball on the file tool and click on it you'll see a faster queue so i'm sure you're familiar with the fastq format so it's read gonna be in four columns four rows and if you look if you pay attention to the file names i have mcc 12 h with 12 hour and mscc 34h which is 24 hour so for each 12 hour and 24 hour i have three biological replicates okay so there's a question here say when the data was loaded in onto galaxy what format was it in are these same spams or faster so you see i in the data center with you there are multiple files so yeah there are faster files the eight the eight is actually a faster file you can click on the file eight reference dot fa and click on the eye bar you can see it's a faster format but the the two to seven there are faster q formats those are the data the raw sequencing data we're going to be analyzing and the first one is the annotation file so it's going to be gta formats it's different and the same file the banks they're gonna be generated later so all if you already have let's say you already have have you already have the same or bam you can also upload two to galaxy two so then you can skip the alignment step because alignment you can generate a bam if you already have them you don't have to alignment for this analysis we're going to start from the beginning from the from this from the we got from the raw data we got the raw data we got a different genome gravity annotation what shall we do to go through this different expression analysis okay so remember let's go back to the slides and we have the steps here yeah so first we're going to check the quality of the sequencing i'm going to be using faster qc so the tool is already installed on the left panel you can on the top to see your search tools we're going to type in faster qc fast qc hopefully we find it so okay we have this faster qc real quality tools okay so click on the fastqc radio quality report i'm gonna see this page like a list right so we're gonna have we're gonna provide the rate say what kind of what files do you want to do by fast qc on so we have two to seven we have one two six files so we're gonna select all of them so we can instead of select one by one we can click is a multiple data set in the middle of this icon here multiple set and select two to all of them together with this shift by holding the shift key and click on the first one click on the last and the last one so you're going to select all of them i think you can probably just uh scroll yeah just scroll down scroll up so you can get all of them select all of them and contamination list we don't have that so normally you can provide some primer sequence there or something but let me see okay we don't have that adapter sequence and we don't have that but faster qc have some built-in adapter sequences so so basically we don't need to specify too much for faster qc and we just use all default parameters and here have the job resources parameters specif specified job resource parameters you can see how many cores how many memories we use and how long to run yes okay so now for fastqc is quite simple once you have the file selected you can just click on execute okay that's that's all click let's do this see execute let's keep the javascript parameter as default one core and two gb memory because the files are small should be fine okay execute yes so now you see how many jobs i've been running now there are six jobs and you're gonna generate a lot of files and uh it should take uh just a few seconds so you see here on each data set you're going to generate the two files two are gonna give us two output so one is the first qc on data seven raw data second one is five security on data seven web page so we're gonna need to see the we can use we can open the web page to see the the summary the summarize report oh it's running okay so if your job is done you can click on the eyeball on the web page and again you see just click on this okay so one job is already done for me and okay all not done so i'm going to click on the web page just pick any one of them any one of the web page for me i'm going to pick on the file 9 click on the eyeball here is the summarize report for you for the further sequencing data so you have the basic stats tell you how many reads the length of gc content per base quality score okay if you click on the purpose sequence quality and you will see the second quality on the left side of the bridge are mostly fine and you go to the right side and they drop a lot right it drops a lot so that means there are some bases they are very low quality and proton sequencing quality so you see something the red ones are not good but tired but the tile not really important for us unless you see the whole time failed that means the sequencing went wrong then you can take this report to the facility say hey you guys didn't do a good job you see the whole tire failed something like that okay so once it has problems the confessed qc will give you a big red x sign and other parts are fine let's see the uh over present overrepresented sequences adapter so it's a no over the plan sequence that's good look at the adapter contents there are very few adapters basically none so that tells us based on this report we have some low quality reads and locally basis on the end on some of the rates so we may need to trim the low quality once and based on adapter content report we don't see much adapter so it's not a big concern for us okay so this gives you a general idea how the data looks like how good or bad okay so now we know we will need to trim some low quality bases okay so let's go to the next tool the thing is trim adapters and low quality bases it can be done with the same tool called trimatic so let's go the same place on galaxy on the left side search tools type in trim mometic i just type trim okay you see trimatic we found it we found this tool so you're going to show the parameters in the middle and the first parameter you choose is single end or pale n in our case it's a single end and fastq files the same we can stack instead select one can select multiple files all of them prefer initial illumina click steps so we're going to cut adapters and the image specific sequence from grid so that's good we can say yes but do we have the sequence there probably already have them so yes you have the sequence the the illumina specific sequence already loaded there so you state i because i don't i have no idea about how this data was generated so normally when you get data back from secret facility it's going to tell you the signal was done on high c 4000 or or normal c 6 000 something and what is the kit they use so based on those information you know which here that the sequences are you you should choose here so here i'm just say pretend i'm i'm using this 263 kit and then have other parameters like a maximum missing count will be allowed for full match to be performed so those can be leave as stiff as they are i mean i i don't see problem with those parameters so we can just leave them like that so when you have uh when you have a parent reads yeah options you always give both three p specific so you can say yes or no it's like if you want to keep both rates um so even the rates are very short after trimming the adapters or low quality bases you're gonna you're gonna still there okay so the important part is here trim trimming the the trimming part you want to remove the low quality so how do you define the low quality bases okay oh there's a question on the chat say can i see the parameters again uh yes i'm going to show you how to see that later so let me finish this part and hit execute then we're going to go back to your question so here's saying going to be using a sliding window approach so it's a regular one to use so basically saying i'm gonna use the window of four base pairs for those parameters here four base pairs if the average quality of those four base pair are lower than 20 which is the parameters here then this whole those four bases will be trimmed i'm going to move the next window if the window is already higher than 20 i stopped trimming so it's already good so it's like that i'm going to use those parameters and other things can leave them as default job resource parameters one core 2gb memory should be good for those small files and 24 hours so much i just say shorter maybe is we don't really need one hour will be good enough okay but if you can you can use 24 it's no problem yeah i'm just four okay so you select the files uh basically you see you have to select the adapter sequence to use if you know the like how the library was made how the sequence was done and you should have those informations and fill in the true one here so i'm here just pick one like i just pretend it's like that then the quality one will be four basis bears a full base window and 20 average quality cut off okay then just hit execute you're gonna do a printmatic okay it submits six jobs for each of those fast q files okay so the question on the chat say can i see the parameters again so you mean the job already run before right you want to see his parameters how you were run so yes you just click for example i take the file nine i click on this file nine it's it has you show me information here 6653.6 kb for my html database question mark okay here has the download build details run this job again okay if you click on this run this job again it will bring you back all the parameters you have you have used for this job so in this case you can see all the all the parameters you'll be using and if you want to reproduce the same result you can do it okay wow see the trim magic is already finished and so it's finished but it says no summary remote report and you can click on click on this one i'm gonna give some informations how those were done click on the eyeball you're gonna see the faster q files okay so you see here some rate are still looks like a pretty long summer is already very short very short long shot right because those are low qualities if you're trimmed away they will delete it some shots done long so it means it's working okay so to really check if those trim mimetic actually worked you can we can run a fast qc again almost trimmer matrix output right not the not not the root of the raw data that we started we're going to check on the trigonometric faster q files so it's the same idea let's go to faster qc click on faster qc okay select multiple files so this time i'm going to select 26 to 21 those are triumphatic on this data set right and don't do anything else just execute select files and execute so we'll be running faster qc on those trigonometric files so we suppose what you're supposed to see we're supposed to see the slow quality base is being trimmed and we will now see a quality drop at the end of the rate so that's our hope if the traumatic actually worked it's gonna take a few seconds to run so one thing good about this guys is you have all the records here so when you've done this analysis let's say you're from this scrap from starting from the raw data and go to end you generate a general dividend of volcano plot and hit map plot those things so you can extract the whole workflow and make it like uh and make it a separate workflow so you have when you have a new data set you just need to apply that workflow to a new data set you're gonna run through everything okay so the first qc is done for this for the trim data and we're going to pick one and take a look i'm going to pick this 37 faster qc on data 26 and let's see okay so you see here this is the quality score and all on the left side on the on the right side they have it looks similar now before it looks like the quality was pretty bad on the on the right side like a list okay so you see that you see a difference and it's actually working an adapter content okay we don't have adapter so it won't change much here you won't even notice the difference so you see and we we run fast qc again on the treatment data and it seems the trim is working and we're happy with that so next step we have the basically have done the qc step now we go to the alignment step so we'll be using the high set tool and we're going to map the bridge to the reference genome that's my galaxy here yeah so we're going to map those sequence to the reference genome so we have the remember 5 8 reference dot f a that is the referential i'm going to be using so let's find a tool called a high set 2 so high set 2 click on this high side 2. oh it's going yeah i said two okay so first we need to select the referent genome we're going to be using use a genome from history that's the genome we are gonna so we're gonna select a reference dot fa then we're gonna select this single end of hand is single end and we're going to fast q files again multiple data sets we're going to select all those trim mimetic data set okay because we want to use the quality control data and unstranded okay okay there's some summary options those are not really important just uh you want this report or not no you can yes or no doesn't matter and advanced options input just default values so normally because you sometimes will ask you for the axon size the maximum axon of those things but this case we have single end and we don't have much information to provide to this high set tools so we can leave most of the advanced options default and default will work for most of cases unless you're running something really really different i don't know how different it's like if you are running um human samples planned and those default premises will mostly work but if you are running something with like fungal it might be different because fungal genome i when i remember is fungal genes have um i think it's it's because the interaction the the size of intron i think it's very different in fungal according to others so you might need to change that but otherwise just keep them as default and uh computing resources here you can just remember this alignment is gonna take uh probably a little bit longer if you're using one core 2gb so i remember last time you tried 10 call 10 db but i'm not sure you're gonna fail or not last time it failed and i was just using one called 2gb because the files are for testing so they are very small and 24 hours leave that default so basically we just select the files select reference and many times you can leave them as default for those parameters if you want to speed up use more cpus and more memories so that's all uh i'm just be safe i'm going to use one card 2gb it will take a little bit longer okay click exit execute okay one two three four six so six jobs okay it's a question asking where do you select a single end okay let me bring back this parameters okay so here you see on the screen right after you select the referent genome this is this single or pair and library so single end pair and parent is a collection all those things so i'm just like single end yep here single hand before the faster queue or faster file oh because another question say the reference should be transcriptome or genome so the referent genome should be the reference should be the genome sequence actually i think trashcan sequence will should work too but in highsec 2 is a slice aware tool so if you provide a genome sequence you can do it no problem it's better actually it's better to provide a genome sequence because that case you will probably detect some normal transcript okay so for me all the alignment is done i have six band files and i'm not sure if you can click on either box okay yes you can see it so this is the output of the one of the alignment okay so let's answer this question on chat how to get the reference genome if it's not provided by the sequencing facility uh now the sequence of facility won't provide you a referent genome because um many cases you can find referent genome in ncbi or example those data public databases if you are working with plan like weed or something they already have left in genome published so if you don't have left engine published so you need to then you need to have uh either first either you have the denoble genome assembly that require you to have a lot of whole genome sequencing done then or you provide the assembly of a transcriptome sequence so is there a limit of the total size of the file that we can upload i i don't think there's a limit of that but you can contact michael for more details it's probably if you have a really big file take a long time to upload directly from galaxy you can upload to uh to a ftp server then you're going to show up on galaxy okay so yeah i think i'm sure i'm not sure when you are talking about uh when you have data and you click on this icon on the left panel here i'm not sure if you can see my mouse moving your gear so download from uil or upload files from disk yes you can upload from the disk directly but it might take a long time so if you have a big file it's better to upload through ftp to hprc first then you will show up in the dataset yeah you can contact michael for how to upload with ftp those things okay are the band files sorted uh i don't think they are sorted but uh for this testing case there's only thing one single chromosome so um there's no obvious sorting step for the for the band for the high side too sad to just give you our products bam and some tools will require you to sort the bam but some tools won't so it's not really for iseq probably probably you don't have to do sorting for the ban let's see yeah sometimes you see those sometimes i see say solid based on coordinates i mean it can be can have those can be true sometimes i just don't see them in the bam file and michael remind me in the first line of the sam file you might see information about sorted not so it looks like this file is sorted based on coordinates so it's good okay does everyone have the band file generated already okay we have four people have alignment already finished okay let's continue then okay so when alignment is done we don't have to use cufflinks but it's sometimes recommended the column okay someone's asking if i can explain the output the bam file output the bam output okay let's take a look at the bam output so the bam file it start with some like uh like a comment or like some information you can see we start with the add sign so you can see some information here like uh it's sorted or not a chromosome information and you have the command that's actually produced this spam or same so this is the way it's did oh well it's a lot okay then after those you can have the the real data the first column is the read name then you have a flag so the flag is that is indicated is aligned or how it's aligned okay then you have the super con console name supposed to be but in my case i have super content and the position and i believe this is the the the quality score of this alignment and this is a cigar it basically is telling you how those alignment was done so you have if you look at seven uh 100 m then behind 100 aligned match so if you look at another one here so have 54 m so it's saying 54 base aligned then you have 164 165 ends so in this case that means it is axon that is intron so you have those two axons 54 base then you have the you have the separation by intron it's 6 165 and they have 646 aligned and you have some information here i'm not sure what are those i need to check the output then you have the sequence itself and the quality so to to to understand this what are those columns uh i think i mentioned those before in the in elastic class it's a send format so basically you can google send format let's say google send format okay uh click on let's see the first one should work yes send format okay do you do scroll down down okay so the alignment section column one the question name or the read name to the flag it's a bit wide it's encoded to show you it's not for you to read but the machine the tool can read how this reads a line is reversed complementary or just as regular and our name reference name should console name or something prediction map quality the cigar just explained this i got before reference name of a mate so we don't have a single end that's position of the mate we don't have a single end so the order of templated i don't know what that is so we don't see anything they have a sequence and have a quality so this is a format for bam and or sam they're the same so bam is binary sam so just for the storage or something okay so any questions so far okay so we have an alignment done so actually we can already just skip to jump to six if we want but we can also use cufflinks based on the alignment we probably will discover some normal transcript right some uh some read map to some location and there's no g annotation for that location so that tell us it might be a normal transcript so to do that we can use cufflinks let's go to this galaxy on the left panel just search cuff links okay cufflinks click on the cufflinks i say transcript assembly and fbm estimation of any single dataset so we're gonna be using the we only need to have this on checkpoint assembly we will not be using the fbkm estimation from the cufflink okay so first we're going to select the same open files the same i'm going to select multiple of them i said two on data okay here's the thing when you when cufflinks doing arduino assembly you ask your max intro length and you can pick a pretty big number here 300 000 is already pretty big so just to cover just to make sure it covers actually your um specific to your to to your species so big number is okay because let's say i if i pick a small number it's 300 so if any intron larger than 300 will be ignored right that's not good so we'll probably keep it big 3000 and mean iso form fraction per mi fraction so let's talk about the intro intro intro into intronic transcript so it's like uh some uh some gene annotations already annotate that part as an intro but you have some uh reads are covering the intro part and probably uh if your transcript is like are mostly from this intro intronic region so it's gonna be ignored if it's 15 or more so use reference annotation uh yes we do have a reference annotation gonna be the first five generation.gtf so yeah it's only one annotation file so we're going to discover new so say with this option compatible with reference only so we've when it discovers a new if we're going to say no here perform bias correction is for the fpkm or rpkm estimation so it doesn't matter to us you just say yes or no it doesn't matter so you can say yes if you want to use the bias correction click so will be reference f a do you want to use multiple root correction again this is a this is the same for fb camera rpk estimation so you have some reads mapped to multiple locations so how do you take into account those rate and it should be counted for each gene as one or just kang as a partial so do you want to use multiple real correction so since we are not using the fb game i became anyway but let's say i say yes effective lens correction is also for fb game or ipkm estimation okay so any advanced parameters you can use so those are parameters you need to really understand your species so you can fill in like uh mean distance between mid so we don't have a make pair library so those are not met that matter to us at all so many parameters it can be depends on the library depends on the species you can add adjust so for our case it's very simple so i will not change any of those maximum number fragments per logo that doesn't matter we don't have that many yes so if you have a project that's uh required to change those parameters just pay your people's attention to how to do those because it could be specific species specific or project specific okay let's jump to the job resource parameters and this step won't take that many resources so i can use the default one core and 2gb memory okay let's make sure everything everything's selected the bam file max intron didn't change all those things estimation of correction bias correction lens correction yes yes okay um let's execute see how this goes oh it's very busy wow it's generated a lot of files see it's a gonna produce 30 outputs so for each alignment file we're going to produce five outputs that's a gene expression transcript expression assemble transcript total map mass scale transcript oh wow so each bam file got five output so we will be interested in the assembled transcript the gta file i believe the gene expression you can actually take a look at the bfkm or ipkm but since we will be using nhr it will require a raw count we won't take any fpga or ipkn so we cannot use those so let's take a look well my uh yeah my jobs are all finished so i'm going to take a quick look of the assemble transcript click on the eyeball you see it's the same format as the gtm file the file one generation.gtf so you have the chrome song songs transcript the features transcript axon start and engine id all those things let me see i'm going to see if i can find a new denoble transcript uh did you use representation in parameters yes you can select use reference as guide oh okay you know what i want i'm wondering what the difference between user reference annotation or user as guide does anyone have any idea about that i thought uh your reference as a guide supposed to be for discover new transcripts so you are using reference as guide but you still still can discover novel transcripts okay okay so when the coupling step is done we're gonna give you a lot of files but the one we are interested in is assemble transcript and we should have five of them if you click on eyeball on the assemble transcript you're gonna see this uh gta file format like list like i have shown you on the screen okay so we see we have a lot of gta files we have five dj files produced from the produced by cufflinks based on the alignment and we have the gene notation file from we we upload it so i was hoping to see something new normal like a novel script generated by by cufflinks but i don't see any in this new gtf so i'm wondering maybe maybe because i used when in the parameter i select use reference now select the use reference as guide here like this so if you're running okay see there's a question here mike i'm confused by reference annotation and reference sequence data may i see parameters again okay so here is the parameters um so first you select all the band files and those max internal lenses thing just keep them as as it is and use reference annotation as guide so this case gonna ask you for the reference annotation but in our case it can be the first file file one geneannotation.gtf then basically other things can be leave as default and you have a sequence data so when testing my second data is a faster file so it's a formula history and you select the reference.fa okay use multiple corrections so it doesn't matter because we will not be using the fptk fpkm or rpkm from the cufflink output but you can choose yes in case you want to use for different programs effective lens correction yes advanced options take a look but uh i won't come back i won't change anything because it requires specific species specific knowledges okay then just execute okay this will take just one or two minutes to finish okay once this step is done we want to merge a transcript because with we possibly with cuff links we got some normal transcript so we want to merge those into the pre-existing one so make a one single uh gene annotation file so we're going to be doing this with conf merge alright this is search here cut merge on the left side i see cover much okay i'm sick of merge okay so we're gonna we're gonna need to select the assemble transcript hmm assembled okay so we'll just select once so first we're going to select all the assembled transcript but not the skill transcript and the gene annotation file we provide as a file one so we want to combine all of those together one set of two okay step one okay i'm not sure how to skip something in the middle okay so yes press ctrl key let's see it's worked for me it's not working for me maybe i should use option key oh okay so someone's saying control key worked for them it's good yes so on mac you have to use command okay i'll use command command command command okay select the gene annotation too actually use reference annotation okay if you don't select annotation here you can provide it on the usg reference annotation your sequence data will be in the history in the reference.fa okay so this step gonna merge all the gtf we have give give us a single one gtf so that would definitely be serving at the g notation for the uh next uh wrist counting okay execute good you now have one output eight input one output perfect okay it's finished let's take a look it's supposed to be a gtf yeah gtf gid transcript id why do we see something new okay so when you run merge is actually get this from cufflink so complex actually assign the new gene id for each of those genes to go back to the old ones you have to check the gene name so instead of prove this one in gene id it give its gene name here because it might be useful because one when to go to next step for the counting and you want to focus on the gene name or want to focus on gene id okay great so we have produced one single gtx for for the downstream analysis and next i'm going to use hr it's one of the popular tool for running differential expression analysis and based on the paper i showed before the table is really long titles so his uh it's a actually better performance than others okay let's search add r in the tools i'm gonna see oh okay feature count i forgot that one so to ima the i draw gonna take the counting matrix why didn't have so edge are going to take a continuity raw counting matrix so before we do that we need to count for each of the alignment file in this case i want to see okay select all the bam file on stranded locally notation file yes it can be in your history and it is the merged transcript that is it has all the it's combined all the gtf into single one so you can be using this one output format gene id recount with well yeah we don't have to change that hopefully yeah so we're going to use this format as the gene id recount multiple qcdhr compatible create genius files we don't really need it but if you want to create yes option for pair and rates we don't have pan like if you want to take a look advanced options gene okay here's the thing gfo feature type filter specify this type only rows which has a matched feature will be included for re for read counting excellence by default and here's the one thing jff gene identifier specified attribute type as we're talking before when we look at the gtfi the gene id is like list xlc1 from our original gtf it has gene names gene name pgtg06 right oh let it go back options so accounting id so if you know gtf you don't have exo you might need to okay the question is which generation file are you using here so this step we're gonna be using the uh generation file that is in our history okay i'm six i'm selecting here generating file in history you're gonna be the last one produced by cuff merge okay you see if you see the cuff merge on the door and the merge transcript that is what we're going to be using because that is one supposed to include the novel transcript if any okay so we can keep those format create the output format as it is genius create gns file yes or no doesn't matter option for pair androids we don't have pair end but if you want you can keep you can check look say disable or enable already made will be count individually so basically you have two rates for pair and you want to count them as two or count them as one fragment so i don't think it really matters only a lot of fragments with both read align so it's do you want to be really strict with this yes or no if yes so if those pair and read with single read align will be ignored exclude chimeric fragments yes or no yes this stuff will be yes gff future type filter so it's the same we have axons in our gff so actually perfect for us gf gene identifier specified attribute used to group features for genes so so the axons here the feature here will be axon and we're going to group them based on the gene id we actually can also group them based on other features but like a gene gene name for example so we can change to gene name or keep it gid so it won't change if you use gene id you'll notice in output can be xlc_01 will not be having a gene name so up to you on future level yes no by default the resume rising is performed at the meta feature level yes allow it to contribute to multiple features uh so this is a tricky part do you want to add a lot of grid to contribute to multiple features we can be strict say no count multiple mapping rate of fragments uh just yet to be strict you can disable it because if you are counting multiple mapping reads if let's say that this literally can map to multiple came up to five locations so each each feature will be kind of one-fifth it's something like that but um i think the hr will require you input like integers so let's just disable it actual intron junction yes no yes long read if special loan rate such as another port we don't have another for largest overlap if specified name refraction rate for lapping so my idea is we can leave most of those things as they are and unless you let's say minimum fraction of overlapping of a rate you want to be very like constrict you can adjust those okay here's one thing only count primary alignment so in the alignment you have the you have one read can be mapped to location as a primary alignment but it has some other locations can also be aligned and those can be identified in the band file from the from the um from the flag field so and most of the cases will be considering only primary because the second one i don't think any two of you can see the second one i cannot think of any of those tools so in this case yes we will only count the primary alignment you can always mark as duplicates um so this is another tricky step for honesty data is actually normal you have some duplicate reads because the transcript could be shot and you could have actually have duplicates so ignore yes or no i say no annotates alignment with files xd attacks describe parade and it doesn't matter for us ignore on splice alignment no so yeah some read actually have the actually have the whole axon right from the we have a long axon so we can have a whole rate from a single axon okay there are a lot of parameters so i'm saying is it depends on how strict you want this to be you can make it very strict you require a lot of um you move a lot to read say like pri only only primary and ignore duplicate read ignore the unslice element i haven't tried haven't test how you know how if you go really strict what's gonna happen so i just use a regular way like primary yes only use primary keep your duplicate rates because some uh ions data you pro you will have a lot of typical rate here and uh don't ignore the unsliced alignment okay and call on the memories i can use the default onecoin 2gb okay let's go back and check select all the band files select the cuff merge output merge transcript gene id all those things are good it looks good so i'm gonna execute okay so you're gonna generate three three fives for each band will give you a count give summary and the future length we can pretty good pretty fast okay let's take a look the all those three files it's going to be future accounts first of all the feature feature lens we're going to tell you the lens file this is the jing id and how long is that gene the second file is the summary click you're going to tell you how many reads assigned how many are on that sign you see a lot of reads are unassigned unsigned because there's no features multiple mapping chimera understand ambiguity so there are a lot of reads are unassigned it's probably it could be some new genes and didn't detect in that cufflink denoble assembly or it's mapped to multiple locations non-split and no features yeah so many cases are no features so this is basically a summary of how many reads actually being assigned to those features and in our case you have a lot of signs it's like 50 oh no less than 50. let's look at the real count table for this count table we have gene id and how many reads mapped to the string id so 15 to this one zero zero 35 to listing so this is the com matrix we can be supplied to hr for running differential expression analysis okay great we generated that we generated the count matrix file and let me see if we can run this hr now okay so hr if you click on the hr you're gonna ask you for conf file or matrix so we have a separate con files factor one so remember our sample we have 12 hour and 24 hour so we're gonna use the factor one you're going to be time this case would be say time just give it a name okay group uh we have 24 hours say i'm going to say edge 22 is 14. okay here's a tricky part to select files make sure you select the correct files what i remember is because the files are in order so seven eight so i want to make i so i know uh so the first three files will be 24 hours if that's correct and group 2 will be 12 hours so let's select the count table for the first two from this 85 yes and for the h12 we're gonna be up to 85 82 8 17 and 76. okay so we select those files we have three counts for 12 24 hour and 12 and three count for 10 for 12 hour so the contrast we want to contrast to h24 to h12 use generation foreign yeah we if you want to annotation yes we're gonna have no problem we're gonna be using the merged i don't think gonna be very hard for you okay we have contrast interest maybe 24 hours to 12 hours so basically the same is you use which which one as a base right if order is okay example here built into one type if the order is built into one type the full change in the result will be up and down in mutant in relative to wild type so here case okay in my case is i want to compare 24 hours to 12 hours so the up will be means 24 hours have upregulated and downgrading means 24 hours has down regulated compared to 24 hours data okay filter low count rates because we this is a test data and we're going to have a lot of low count and it doesn't matter if you want if you run a count per million so if you have a real data set you can remove the low express genes but how do you define low expressed genes how what is how low is low right and normally you can use say if it's like rpk massive two rates yeah two some people use two reads as a minimum some use five rates so i don't know what is the golden standard for that and probably has no golden standard because it totally depends on your library size so for my case because i know it's a test data and i don't have as many reads there so they're going to be a lot of gene with low counts so i don't want to remove those i'll output options normalized account table okay if you're on the table you can say yes i'll put our script so this is the r script actually actually run the comparison so if you want to see how the r script was written you can say yes give me our script i'll put our data file so this is output of uh of the data from the r script so you can load all data later if you want to reproduce or anything or if you check the certain output from the r the r might give you a final output but the intermediate files are going to be saved in the r data if you want to check those files you can have this one too and you can load into r later okay so those are up to you if you want to get the count table say yes if you're going to get our scripts say yes if you get our table file our data file say yes so so they're up to you and this is the moment we're gonna see the output of the differential expression let's see okay so i asked to give me a script and it's actually showing up there so it gave me a table a list and a ripple report okay let's look at the report mds report bcv tag wise common trend raw squeeze to change you know this so don't pay too much attention to those because this is the test data and it may look weird to you for example here the first plot mds plot we have the red ones we have the red ones and have a black ones so in theory you should see the radicals cluster with red and the black class was black but in this case you see is one sample actually when close to the red looks like how four samples are together and two samples separated so it means some this could be some problem with the data so when you have the output like list in your isig data you will need to go back check maybe you label the sample wrong this is not 12 hour maybe it's 24 hour or something you probably something wrong with the data so this plot give you some up and down and significant yes or no so you can see those dots those plots are not very nice but they give you information so so you have the tables here hr normal count.csv you're going to normalize the count if you click on it give you a table like list so if you want to do some uh statistic test yourself you can get this table and run some statistic tests yeah here is the table summarize how the samples are separated so 12 24 24 but this the first mds plot is probably important let's take a look and see if they are clustered together okay so see this is the or you already have the final output basically and let me see where is the where is the duty this is the the part okay yeah from the report oh yeah hr 824 s12.tsv okay so this is a file we talked about before you're gonna see the format looks weird oh okay so it's supposed to see the p value the log fc log cpm the f value and the p value so there's no f d o fdr here that's supposed to have fdr too and based on the fdr 0.05 you can see how many genes are significant significantly differentially expressed and in this case you can see some genes are like that a lot of them are and ace okay so with this is basically the output of hr and uh those figures are produced in hr2 and if you don't like those figures you can you can uh take the data for example take this data and based on the p value and something you can plot a nice figure so let's see we can have a i remember in in uh in this galaxy we have a heat mapping start so maybe you can try to produce a heat map based on yeah based on account data okay so we have it what is table okay yes we won't have we will be using this table the html4 no no we can use hey i'm just so curious why they have so many nas or just a format not good yeah so galaxies okay can you hear me now no did i mute myself yes okay yeah so i'm saying is for making plotting galaxy it's not really good the galaxy has a very limited tool it's not very flexible to making plots and if you are familiar with our programming it's much easier to export exp to export the data save as csv or tsv then load into our 2000 plot and so this thing is we have i think we have a hidden map tool in galaxy and if you want to try you can try to see if you can make some plots but i don't see very useful data collection okay tables yes we will be using these tables if we can get this plot something with this his map or title uh hit you see here we have a dataset collection in the history tables at least there's two items you might click on that's one you're gonna see two of them uh we probably need to unzip this collection before we can use this heat map tools but let's try it before we unzip it because if you don't unzip this plug it map2 are going to plot for each of those files separately okay data transformation plus it is enable data clustering wait i don't want to change anything before i want to make sure it's actually working for the escape map too so we test this tool once and i don't think it's producing very nice figures but just give you an idea you can still try to do something on galaxy trying to produce a plot okay give me some arrows okay it's not very uh it's not very good we're trying to use his map here i want to delete this one okay unzip collection okay i don't think this um keep map 2 are going to work for those tables i check this table it looks like uh has something weird format you see here we do have the uh the output the numbers for each band file but we don't see the oh okay we don't see the gene id here there's no gene id okay to check that let's get back to the to account table feature count it does have a gene id here gid no problem let's get to the edge are all right separate comp fives yes one factor different time so i'm trying to see if anything wrong why there's no uh there's no gene id produced there usb annotation yes link okay so i'm not sure what happened because i don't see the correct output from hr even it give me some output and looks weird the annotation yes okay execute let's try it again i want to see why okay so for everyone on running this dataset if you produce the table produce the output from hr can you just check on the tables and if and see if you get something like similar to mine okay there's no gene id well i didn't reduce the output the normal output okay like this if you produce the normalized account table and if you click on eyeball do you see a gene id somewhere or just like me like mine okay so good thing is i have a history i have done before trying sick test maybe okay normal count okay so okay if you're switching like this okay there's one kelsey mine is like yours i'm only seeing like this when i do not include the referendum reference annotation when using hr okay okay so yeah normally it'll be like a list so you have a gene id and you can id here and you have the uh the data like a list uh they spam at least spam and what is the normalized account for each table right and for the this is another one we have a gene id have a log flow change log cpm f p value fdr so this is a normal output it's supposed to be seen and if you don't use the genotype reference annotation according to kelsey thank you cassie so yes so if you have a table like a list normal count table like list but i bet you will get uh you will get the cables with two you look at the data set with two tables together so two you can to make them you will need to to run extract data set from a list i just type in extract on the searching and you can see that click that one and you can select the from this data set which table you want you want to um output so you can select by index so it's certain one so one will be hr h24s12 so you don't execute you got a separate table not not a data set not a list and you say if you then run again with index 1 you're gonna get the second table as our normal count okay so we'll be like a list i have a separate table net rx 24x12 add our normal count okay so next step then we can run a heat map hit map and bring it back okay so we're going to select the the table extracted from the data set we're going to use the hr and the type give the title 24 with 12 key types of whatever product device it is then we're gonna execute so this is we're gonna plot heat map based on the normalized count okay from the hr normal count table and execute okay so it's finished i believe we can look at here okay yes so you see i'm saying you can make plot but it's not really nice because you don't have the flexibility to adjust say the labels the font size all those things you don't even get to pick uh you can get you can pick colors but it's not as flexible as you can do in r okay this is for heat map a similar thing for the volcano if you if we have the uh list comparison table with fdr and p-values this one we can make a volcano plot and i probably i think i have this tool here called volcano plot typing volcano it should pop out so working in the block yes so select this one and you got to you got to tell which column is the fdr which column is a p value this column is log flow change and which column is for the label so in this case we have column six for fdr column five for p value column 2 log form change and the column 1 the gene name is the labels so the significant threshold by default 0.05 we can just divide this log4 change shuttle to color 1.0 so that means you want to pick the the genes that's all have log four change one means two two times bigger yeah two times up or down comparing uh the case to control comparison right so point to label you only want to label significant ones that's good and only show the top ten okay those are the parameters you can adjust for making this volcano plot and execute oh i don't know it's so slow so what was the input file for heat map so input file of key map let me bring it up it's a table it's a normalized count table for the you extract it from the from the data set so when you run edge r you have to say give me the normalized account table otherwise it won't generate for you so once you have that table you're going to show in the uh you're going to show in a in a data set like a list in this data set you click in it has two there's two things basically two tables so to have them separate you need to extract i'm not sure you you're doing that so extract first and extract second one and you're gonna end up two tables in your history two separate tables in your history so in my case i have 127 as one table and 125 as another table so when i have this 125 hr normal count table i'm going to run his map 2 using that table using 125 here and just give some labels other things and for the volcano plot you'll be used you're going to be using the 127 edge file in my case in your case it might be different number so and you have to specify which columns if the options p values column is labels all those things and once you are done just execute and heat map looks like a list so it's not as good as you can produce in r you can adjust the color the font the label how you want to things organized but anyway you can still get something to give you some some ideas how the data looks like at least uh we do see something how about a volcano plot so the cleanup are going to look like this you have the significant ones up and down so those live and the log for change you have is one that's cut off and pure fdi is 0.05 so the the color code is based on the fdr but on the x-axis you still have the log-10 p-value so it has a lot of information in a volcano plot well the volcano plus actually okay it's much better than the heat map plot okay so i would recommend you pull the data and then run the plot in the r script in r so you have to probably program a little bit in r to make a nicer plot with ggplot for example okay any questions yes as i'm saying so the the good thing about galaxy is you have all the data set and all the parameters here so if you want to reproduce or you want to extract or you want to repeat the workflow you can easily do that in galaxy okay you're welcome okay so yes if you have a question you can send emails to us we are happy to help you and so this class for isak uh oh there's another question say if one risk can be aligned to more than one gene how can we count it so two ways to count it one it count as a fraction if we one remap two it will become at 0.5 and or just ignore them just remove them so it's up to you i will for me i prefer just to remove them if we want to have jeans names instead of jing id as we step will we specify that i think it's at the future con step let me bring up the feature con parameters feed to count hello yeah okay is this step yes uh feature pop uh feature account and if you click on advanced options it has the gene feature type filter and gene gf of gene identifier so instead of gene id you say gene name if there are gene name in your gene in your gtf file so that case it can be clustered based on the gene name okay so thank you very much for attending this short course and this is the third one of this ngs series and we have the last one on next friday we will be talking about uh genome assembly transcription assembly so thank you very much hope see you next friday okay so the question here i tried g name but i received arrow let me see alignment file specified to get what's good we want to make sure we do have gene history merged transcript no conflict gene id transcript id action number gene name uh okay it does has a g name let's see in history merged yeah let's go oops this is the place we want to check the information why it's wrong to see if you click on this give arrows and click on the information you hope to see more details about what's going on with this command but here's we don't have too much we don't have much information about arrows error details okay okay arrow you see here failed to find the gene identifier attribute in a nice column of the provided gfa file especially for the gene files gene name example gene id transcribe the actual number okay so for some reason you didn't see the gname in the you see here an example attributes encoding gene id transcript id actual number o o id class code tssid so you didn't find the gene name in the gta 5 for some reason and i don't know why it's not fighting because obviously it's there let me see the long run yeah um i can i cannot tell directly why it's not finding but i can i take a look later hopefully we figure out why maybe it's a bug who knows well that's good we see arrows and we see how to check the address and if we if it's something we can fix we fix it it's something we cannot fix we can submit the report or you know seeking for help so click on list and click on the back and give you this the bug okay thank you very much and i think that's all for today's class send us emails if you have questions i'm happy to help you you 