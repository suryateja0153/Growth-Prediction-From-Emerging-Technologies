 NATALIE FOSTER: OK. Good evening everyone, and welcome to the Graham School. Whether you're in the room with us tonight-- we're really pleased we have a full house-- or whether you're online on our livestream, we're really excited that you were able to join us. My name is Natalie Foster, and I'm the program manager for the Master of Science and Response Management Program. And alongside my colleagues from the Master of Science and Biomedical Informatics Program, we're really excited to have you all tonight for this lecture and discussion about the importance of protecting bioscience data from cyber threats. So we'll start tonight with a short lecture from our presenters, Nate Evans and Jennifer Fowler. Nate is the lead for cyber operations analysis and research at Argonne National Lab. He is also an instructor in the threat and response management program. Nate is considered a key asset by the Department of Homeland Security in areas such as cyber vulnerability assessment, analysis of cybersecurity consequence and threat studies, and for leading the pilot Cyber-Physical regional assessment. He also works on a number of other cybersecurity research areas including transportation, satellite communications, social engineering, and offensive cybersecurity. Jennifer Fowler is a cybersecurity analyst at Argonne National Lab with the strategic cybersecurity analysis and research team where she is interested in cryptography, data privacy, biohacking, and social engineering. Before making the switch to the cyber field, she worked in crop science and genomics, including in the Illinois Long-term Selection Experiment where she explained the genetic changes in maize populations due to selection. She also worked on energy corn, which focused on developing maize as a platform for cellulosic biofuel production. So Nate and Jennifer are going to talk to you all for about 30 to 40 minutes. And at that stage, Sam Volchenboum will be joining them to moderate a discussion. So Sam is an associate professor of pediatrics and the associate chief research informatics officer for the biological sciences division at the University of Chicago. In addition to his clinical practice in pediatric oncology, he directs the University of Chicago's Center for Research Informatics. As director, he oversees things such as high performance computing, HIPAA-compliant storage and back-up, application development to support clinical trials, and the clinical research data warehouse. He is also the faculty director for the master of science in biomedical informatics program, and his major research interests include building commons to support scalable biological research. So when Sam joins us for this discussion, we really want all of you guys to get involved, too. And you can do that whether you're in the room or online. So those of you in the room will see some information in front of you, and those online will be able to find a link on your website. And on this page, you can go and ask questions that you think of so you don't have to remember them all at the end of the night. And if there is a question someone else asks that you really like, you can upvote it or downvote it depending on whether you think it's a good question. So I encourage you all to get involved on your phone or computer or your tablet so that you can be involved in the discussion too. So with that, I would love to hand it over to our wonderful presenters, Jennifer and Nate. NATE EVANS: Sorry. Hi. So, again, I'm Nate. She gave a great introduction there, so I won't go into that again. I will mention a few things she left out of the bio. So in addition to working at Argonne National Lab and teaching at University Chicago here, I also used to work for Walt Disney World. So as such, I tend to you bounce around a little bit when I talk and be a little animated. So hopefully that keeps you guys excited here and maybe excited then to actually take some cyber classes and things like that here. So with that, I'm very passionate about cybersecurity. And as I mentioned, I'm from Argonne National Lab. So for those of you guys that are not familiar with Argonne, Argonne National Lab actually got its birth from the original nuclear reaction which occurred. So here's Enrico Fermi dedicating Argonne to peaceful use for the nuclear reaction process. And as part of that, Argonne has been involved in a lot of nuclear power generation throughout the history of that. Since then, it has shifted and diversified its mission. And with that, national security has become a primary focus. And cybersecurity falls within that realm. If you're unfamiliar with national labs as a whole, there are 17 of them spread across the nation. They vary in their actual use cases according with that. Argonne's what is known as a multi-purpose laboratory. It does everything from battery research to nuclear research to cybersecurity and the national security aspects with that. There are a variety of other labs out there. Some of them have single purpose focuses based on user facilities or things like that which exist. Argonne has 3,500 employees exist in this area here and, as I mentioned, has a variety of user facilities, everything from some of the fastest supercomputers in the world to some of the brightest light sources, which can do a lot of X-ray sciences and mechanisms like that. But we're here today to talk about cyber biosecurity which is a emerging and converging technology field, which takes the traditional science of biology and takes the growing field of cybersecurity and sort of merges them together. So if we take that word and break it down, we look at a cyber aspect into that. Cyber involves communications and computers and those traditional elements. Bio looks at the bioeconomy-- which we'll talk about here in a little bit-- and looks at all the elements associated with the bioeconomy. And then security looks at the protection and the resilience of that. And we'll get into all the details of the protection and resilience here in a little bit and talk about some high-level concepts associated with that. So cyber biosecurity is a new specialty which is looking to try to understand and mitigate the biological security risk that's at that interface between biology and cybersecurity. Some just general definitions, just to make sure we're all on the same page. So biosecurity is looking at securing specifically the biological elements associated with that. So preventing unauthorized access and providing traditional security paradigms to the biological arena. Cyber physical security is that nexus, so where cyber becomes physical. So with that, where computers start controlling the actual environments out here. So you see that a lot in critical infrastructure with industrial control systems where you have a computer that's controlling a pump and that pump's controlling something in the physical world. So as such, that nexus is what's referred to as the cyber physical arena with that. Cybersecurity is looking more specifically at the general information technology infrastructure, so the computers and the communication aspects associated with that. Threat vulnerability and consequence-- we'll get into it a little bit more here in depth when we talk about risk a little bit. However, threat's looking at the human occurrence, the actual human or non-man-made occurrence, which is causing damage, potentially. Vulnerability is the specific thing which is being exploited which is causing the potential damage. And then the consequence is the actual damage that is occurring with that. So to talk about bioeconomy, I'm going to pass it over to Jennifer here to chat a little bit. JENNIFER FOWLER: Hi, everyone. As the introduction said, my name is Jennifer Fowler. I'm a cybersecurity analyst at Argonne. My background was mentioned. So I had an undergrad in genetics, and then I realized I didn't really want to do that for the rest of my life. So then I pivoted, ended up working in the cybersecurity. Still liked genetics but never thought I'd get to use it again. So I'm really excited that this is a field so now I can actually validate the fact that I spent so many years in genetics. So I'm going to talk to you today with Nate about cyber biosecurity. And we'll just go into what bioeconomy is. So basically the bioeconomy just refers to the economic activity produced via that scientific discovery and production. And so you'll see that a lot in biotech where we're producing things that are profitable. And so the bioeconomy refers to the output of that production, which is the profit and whatnot. And so we're trying to understand the mechanisms and processes from the genetics at a molecular level and applying that understanding towards improving processes. It all funnels into the bioeconomy. And it's very much, as I mentioned before, focused on the biotech sector because the ability to manipulate genetic material, create new things, that can be very profitable. It helps in turn with breakthroughs and progress in science. And the evolution of the biotech industry, specifically with my background, you see it a lot in agriculture. So making things more efficient. We need to produce more food by 2060 in order to support the population. So making things more efficient and making it work smarter, not harder, basically. And you also see that in chemical and energy industries, but you usually see that bioeconomic impact in those specific industries. Next slide. Thank you. So with the bioeconomy, when you see a lot of profit, there can be some maybe aspects at play that you want to protect, that intellectual property. You want to protect your investments and your profits. So for the United States, the bioeconomy accounts for an estimated $4 trillion annually, which is 25% of the GDP. So from everything from pharmaceuticals to renewable energy to agriculture. You'll see that, even response for emerging diseases. So we see that these sectors have this profitable impact on the bioeconomy. And protecting that intellectual property is of paramount concern because if I lose my ability to protect that intellectual property and my competitor also now has the same genetic makeup for this product that I'm conducting, I lose that edge. I lose that ability to be the only person on the market. So protecting intellectual property is huge when it comes to the bioeconomy here. And we see the explosion of genomics research and bioinformatics, using information technology, big data, cloud computing, et cetera. But when you use those technical things, now that we're merging not just the life sciences and doing this research by hand. We're using machinery. We're using big data, cloud computing, things to make it more efficient. We rely on that technology, and that may open up certain vectors for attacks. So as part of the US national security architecture, safeguarding the sciences is a priority. The protection of intellectual property is becoming an increasing concern as we open up more vectors towards attack because we're relying on that technology. And so how do we safeguard this data for both protecting privacy and addressing the data's potential for economic and intellectual value? So we want to make sure that we have things put in place like encryption and authentication and these things that not only prevent people from stealing that intellectual property but also prevent someone from maybe altering that data for nefarious uses. NATE EVANS: So if we look at the history of cyber biosecurity and even just biosecurity and the start, if you look, you can argue it started back in 1987 when the first DNA sequencer first came out. With that, there has been a variety of second generation and third generations associated with that. However, in 2010 is when they first were able to produce the first synthetic DNA, so they first were able to effectively print DNA. With that, they have, a couple years later, in 2012, were able to show that you can store data itself on DNA. So you're able to actually take traditional IT data and put that within a traditional biological element within the DNA itself. And then in 2017, just a couple years ago, they actually showed that they could invent malware within DNA and then actually infect a DNA sequencer. So with that, somebody could put malicious data in a specific DNA to be printed that could be printed out and cause some sort of compromise to occur on the DNA sequencer accordingly with that. We're starting to see the growth both in planned as well as an actual generation of biomanufacturing facilities, so facilities that have been stood up in order to basically generate synthetic biomass. So facilities that are built to take inputs from DNA sequences to other sequences and effectively print those out for a variety of uses. If you look at a standard view of a biomanufacturing facility, you see them broken into three layers associated with that. You see an initial layer, which is very focused on that initial development side. So looking at the initial creation of the bio process, and as such, you'd imagine that's very research heavy and research focused. So it tends to be a lot of things that are needed for research, lab-focused materials, lab-focused IT equipment, traditional lab microscopes, and mechanisms along those lines and all the IT infrastructure that supports that. As it continues to move up, the actual aspect that they're doing goes through a scale-up process and eventually reaches a bulk drug production process. As it continues to move towards the right, it becomes much less in the traditional research perspective and much less reliant on those technologies and more towards what you would consider traditional technologies. So looking at traditional, even like VPNs or mechanisms like that in order to manage large data elements, large even business transactions and mechanisms like that. When we look at cybersecurity, one of the traditional models we apply is something called the CIA triangle. The CIA triangle is confidentiality, integrity, and availability. So confidentiality is looking and understanding and looking at attacks that affect the protection of information. So a lot of people, when they think of cybersecurity, tend to leap towards that confidentiality element. What are the secrets that the government or that other organizations are trying to protect? That is a confidentiality element. In the cyber biosecurity world, when we think about confidentiality, we look at attacks where they may be trying to steal the specific DNA sequences accordingly. There may be some new medicine from an actual marketing perspective or mechanisms along those lines, as Jennifer mentioned in the bioeconomy. From an integrity perspective, it's looking to actually make sure that the data which is there is how it should be. So for example, if you look at society and corporations as a whole, if you think of who may have the most focus on integrity, what may pop to your mind a lot is a bank. When I log into my bank, it is important from a confidentiality perspective that my number is protected. But it's probably more important that the number I look at is the right number, that the amount of money in my bank account is how it should be. If it's more, that might be a good thing. But it should definitely not be less, accordingly. In the cyber biosecurity field, integrity is also a very valuable element. And, for example, one of the attacks I mentioned in the historical element, if I think I'm printing one thing and it ends up I'm printing something else, that can be bad. If I believe I'm printing a cure to something and it ends up I'm instead printing anthrax or some other bad element with that, that can be very bad accordingly in the process. So a malicious actor can take advantage of that. And then the third aspect associated with the CIA triangle is the availability side of that, which is another traditional type of attack. A lot of people see it across the internet as a denial of service attack. You've probably heard a lot before, trying to send a lot of data at websites or things like that in order to bring it down. Its parallel in the cyber biosecurity world is potentially trying to destroy the DNA sequencers, so trying to feed malware into it that may have a destructive process or things like that to it. In addition to looking at all these technological attacks, humans also need to be taken into account from a threat perspective. Humans are threats in the cyber biosecurity space and can be threats in three different areas. They can have malicious intent. So it could be an employee that hates their job or is trying to do damage to the corporation. Could be corporate espionage or mechanisms like that, so an insider that is really trying to do damage has that malicious intent. It can be accidental in nature, so a human that just makes a mistake, accidentally alters a specific number element or things like that that can cause damage. Or it could be humans just basically being lazy, so that unintentional consequence, or as some people refer to it as just negligence as a whole. So as such, people and that human factor within security needs to be taken into account when you're evaluating and looking at this as a whole. Looking forward, if you look at all this in a big picture, we tend to apply a traditional risk formula to this. So if you're unaware of risk from a mathematics perspective, risk is a function of threat vulnerability and consequence. So some type of threat actor out there takes advantage of some vulnerability in order to do some damage. When we're looking at cyber biosecurity and when we're looking then to try to evaluate it and try to maybe recommend specific best practices or specific standards or things like that for that, it's hard to look at and try to find ways to reduce the threat element in that. And it's obviously that there's a growing consequence with that as there's a large impact from a budget perspective. And there tends to be more and more of these facilities and technologies standing up. So as such, we tend to lock in at that vulnerability piece. So if you look at the types of vulnerabilities which exist, we believe that looking at some assessment-based framework or looking at an assessment-based aspect to cyber biosecurity will be a good and valuable step forward with that. When you're looking at assessments, there are two different types with that. There are maturity types of assessments, which are assessments that are going against a type of a standard or a best practice. But because cyber biosecurity is still so new, there aren't really standards. There aren't really best practices or things like that, at least that are agreed upon across the organization at this point. So as such, a more valuable approach might be more of a comparative-based model where as such you can assess infrastructure and assess these biofacilities against each other to see which ones are performing at a low caliber, at a moderate caliber, at a high caliber, and recommend solutions, almost compete them against each other. Especially in an organization that tends to think very well from a competitive standpoint-- profit is a motive for them-- a competitive assessment can be very valuable there. So I'm going to pass it over to Jennifer to talk a little bit more about different types of attacks and different types of potential vulnerabilities and go from there. JENNIFER FOWLER: Thanks, Nate. So as Nate mentioned before, we have the CIA triad. I usually throw up a triangle at this point. So we have the confidentiality, integrity, and availability. We won't quiz you on this, so don't worry if you don't remember. But my research ideas that I'm going to be talking about are mostly integrity-based attacks. So I'll be talking about how to target different research areas of cyber biosecurity in terms of integrity. So the first example here of potential points for vulnerabilities within cyber biosecurity has to do with the way Variant Call Format files are read into a database. So basically, the idea here is that you would use a synthetic piece of DNA to output a malicious VCF file and infect that database. So I input something. Maybe it's malware. Maybe it's some type of code into this file format. It gets read into the database. Then maybe I dump the database. Maybe I now have access to the database. I can manipulate the database but basically using the file format as a vector to have access to that database. The second example is basically exploiting sample bleeding to execute a side-channel attack. Now, side-channel attacks are something that you see in cybersecurity. But basically, the bi-directional nature of how these things are read it would allow an attacker to potentially read, alter, or modify some results. And this attack could reveal sensitive information like the identity of other samples based off of the proximity or location. Even only a few reads could identify the species of a sample where if you're doing something sensitive or proprietary, that could be pretty damaging because you could get more information that you're not supposed to get. Sample bleeding could also be used to inject the sequence with code that could be used to read base pairs from another sample. So some integrity attacks here. The last one on this slide that I'm going to be talking to you about is hijacking sequencing runs to ruin sample reads. So you could bloat the samples with a high number of one type of nucleobase, which could cause the run to fail or read reduced qualities. Some more ideas here is taking advantage of vulnerabilities in sequencing software. So some of the sequencing software that you see are open source, written by researchers, perform the task very well but perhaps may not be pen tested. So that's a term that we use in the industry is penetration testing. You're looking to break something. You're looking to find and exploit vulnerabilities and see what the output is. And then someone would get that report, and hypothetically, they're supposed to then fix those errors. We also see that with bug bounties. Different companies will have bug bounties. If you find one, they may pay you some monetary fee. And then they will then fix that so that that bug or exploit is no longer there. What we find sometimes in that this type of software is that that doesn't exist. We typically, in order to funnel and fuel innovation, science has been open. We collaborate together. We share information. So the idea of, oh, I better protect this from something nefarious hasn't really come to the mindset as much, which is interesting because you see that private sector oftentimes-- or whenever profit is involved or intellectual property-- you'll see that there is this intense need to protect this data. But you might not necessarily correlate the way a sequencer's program runs as something that could be exploited. But this is exactly an example here. So vulnerabilities in that sequencing software could allow someone to perform a buffer overflow attack, which would then ruin the data, ruin the sequencing software. So a bunch of different OWASP attacks can occur within that sequencing software due to the fact that it's open source. And then we see that next-gen sequencers often use analysis programs that were written, like I said, by research groups. But then they aren't thinking necessarily about security, so they may use insecure C function calls in their C libraries. A lot of these are written in C and C++. They may use out-of-date libraries that you could then exploit. And then the next one, which is number six, so we're exploiting the supply chain process. Nate mentioned earlier in that biomanufacturing slide that there are a bunch of different aspects involved. You'll need to go to your procurement system. You'll need to order supplies, materials, things like that. So you might have two competing pharmaceutical companies, let's say. And one is about to edge out the other on completing, let's say, a new therapy or something. An attacker could potentially go into the system on behalf of one company and look at the supply chain process here. So Company A is on the verge of beating out Company B. Company A needs to order, let's say, test tubes or a specific type of product. Someone could use and exploit that supply chain process to intercept that package, contaminate whatever it is that the pharmaceutical Company A needs, and ruin whatever product it is that they're creating because they now have contaminated products based off of that infiltration of the supply chain process. The next one is exploiting internet-connected devices in order to pivot onto other areas of the network. I try and include a GIF on every presentation I give. So basically, as I mentioned before, we're now connecting things to the internet. It helps fuel and funnel innovation. But at the same time, these ports or programs or software might not be that well protected. So if I scan something, I see it has an open port, I can exploit that and then gain access to the system, gain access to the network, pivot onto other sensitive areas of the network that you would probably not think I could have access to. But because you're plugging in insecure devices into your system and your network, I can then use that and exploit that to gain access to other areas. NATE EVANS: So [INAUDIBLE] to summarize this, in the first aspects, as she was talking about, tends to be very potential biological vulnerabilities, which are being exploited with traditional cybersecurity types of attacks as opposed to the second group is looking at IT vulnerabilities, so traditional information technology vulnerabilities, that are being exploited to cause biosecurity consequences and mechanisms like that. So overall, I mean, we really see this field of bio cybersecurity continuing to grow and continuing to have a focus area and an emphasis as well as has a lot of gaps and a lot of potential areas for research. So we're very interested in continuing to explore this field and continuing to evaluate where we can apply cybersecurity principles in order to ideally try to solve this problem or ideally try to mitigate the risk associated with this. So with that, hopefully you enjoyed the presentation and it gave you a quick overview of cyber biosecurity. We're going to open it up for questions now-- and I think there's been a few submitted online-- and turn it over to Sam to chat a little more and organize that. SAM VOLCHENBOUM: Great. Thanks. OK. So we're getting questions online, so that's good. We'll take questions in the room as well. So were you a cast member at Disney? NATE EVANS: Yes, I was. SAM VOLCHENBOUM: I mean, I think everybody is dying to know what you did there. NATE EVANS: So I was in something called guest service recovery, which is what they call making angry people happy again. So if you're at Disney and you get angry because a ride breaks or some kid spills ice cream on your shirt and you go and complain to a manager, I'd be the person that would show up to make your day happy again. And you may think this has nothing to do with my career field. So Disney taught me effectively how to manipulate people to go from angry to happy. My dissertation was actually in social engineering, which is manipulating people to gain access to passwords. So a lot of the same principles that Disney taught me, I was able to apply to break into companies and banks and organizations and was the first academic proof that social engineering is a problem. So it all is connected in a weird way. SAM VOLCHENBOUM: Disney's taken somewhat of a black eye about these new bands that everybody wears there, and they track-- do you have an opinion about how Disney is using that information or whether people should be worried about that? NATE EVANS: So I mean one of the things or one of the advantages specifically with Disney is it's an opt-in process. So it's not something required to do. There are other mechanisms and things like that you can do with that. Where I get concerned is when you're required to use a biometric aspect. So there are a lot of devices, a lot of organizations out there that require fingerprints, that require retinal, eventually even other elements like DNA or aspects like that. One of the big concerns specifically with utilizing bio as part of the authentication process is if somebody ever steals your credentials, there's no way to change that. I can easily change my password. I can easily change a PIN. I can easily change a card or something like that. I can't easily change my fingerprints. I can't easily change some of those other elements. Some people argue that, well, that doesn't matter because it's harder to get. It may be harder, but it's not impossible. We saw, for example, with the big OPM breach, so the government's loss of basically everybody that had a clearances, biological records, everybody's fingerprints that had a clearance is now out on the dark web for purchase. So as such, there is the ability to actually steal that information, and I believe utilizing it as a form of authentication isn't necessarily the smartest move. SAM VOLCHENBOUM: OK. That makes sense. We have a lot of questions, and so I encourage people to submit. Andrew Burt, who's from Immuta, who's an expert on AI and ethical algorithms and who gave a talk here a few months ago, he's wondering if actually everything we tend to think of as cybersecurity is essentially cyber biosecurity since so much of what we collect from health care data or just data in general has a biological aspect to it. So, in other words, how do we protect our biosecurity when it can be undermined by data that might seem unrelated to our health, like our shopping history or something else like that? Either of you. Be interested to hear what you think about that. NATE EVANS: Yeah, so I mean, as all the data elements continue to grow and as people start willingly giving up data about themselves, whether it's via Facebook or social media elements or even shopping habits or even, as you mentioned, Disney potentially tagging bands on people so they can start recording how many stores they may walk by or how much time they spend on certain things-- it's definitely a concern, specifically from privacy perspectives, what organizations will do with that data. And there aren't, at least in the US, effective standards and, really, laws that protect against mechanisms like that, where in Europe and other countries, you do see more stringent impacts associated with that. And it's really odd to me how people tend to trust profit companies with that amount of data much more willingly than they trust the federal government. It's a strange process to me how mechanisms even like Google, I'm more than willing to give up that information to Google because I believe this profit motive that they have protects it, where at least in the government world, there are laws. There are people that can be held accountable. There are standards and potential regulations and things like that that can go into effect. SAM VOLCHENBOUM: Right. So to that end, there's another question here that's interesting about we have a lot of laws in place to protect data when it comes to research data and protect patients' privacy with HIPAA regulations. We have some nascent laws about protecting people's risk, when if their genomic data were to get released. But do you think, in general, there needs to be more legislation in this area? And is that one of the answers, or is that not a good solution? JENNIFER FOWLER: I mean, I'm a privacy nut. So I think that all data should have some level of authentication or encryption applied to it because not everybody needs to see everything. I know that there are some genomic companies or companies within the field of bioinformatics or whatnot that, if they do get a sample that they then see is nefarious or maybe is a potential, that they have a working relationship with other labs in the area to then identify, hey, this is something that-- they're asking for access to something that could potentially be harmful, like anthrax. And then they have an agreement working with law enforcement to then identify, hey, this maybe is something. This person's requesting access to something or identification of something that could be potentially harmful. So I think there should be things in place that allow for the protection of this data because once it's out there, you can't really get it back. But I think it's nice to see that organizations are taking it upon themselves to enact this on an agreement basis. They're not required to, but they see the value in it. SAM VOLCHENBOUM: Yeah. I was thinking, as you were going through all your examples, about the security of all our genomic sequencing, everything from the sequencers to the software that we use. And I can obviously think of lots of fun examples of people putting DNA at a scene that wasn't really their DNA or manipulating results in a courtroom. But I think what's more fascinating is the biological examples in the health care setting. So you could imagine if you have a-- and I don't know if this is even possible. You can imagine if you have a panel, a sequencing panel that tells somebody what kind of cancer treatment to use, that that could potentially be manipulated-- JENNIFER FOWLER: For sure. SAM VOLCHENBOUM: --to give different results. JENNIFER FOWLER: Yeah, I mean, the nefarious possibilities are endless and terrifying to think of. So you can manipulate everything from giving the person the wrong drug to manipulating the drug itself to manipulating the data that says they're not allergic to something when they are. The possibilities are quite terrifying I think. NATE EVANS: Yes, I mean, just to tie it back to some of the slides we talked about, I mean, as you look at the CIA triangle and think about in that way, I mean, again, a lot of people are pulled to those examples that maybe availability focused or confidentiality focused, because that's where we're most comfortable. But I think that integrity element tends to be overlooked, and that could be where some of the most damage could potentially occur, that not being able to trust in the data and not being able to control when a change occurs, that it should be occurring. SAM VOLCHENBOUM: And I promised myself I wouldn't say the word tonight, but I just have to ask. Are blockchain technologies a way to help ensure the integrity of the data or the lineage of the data, and should we be thinking about trusting private blockchains to do this? And how are you thinking about technologies like that? NATE EVANS: Possibly. I mean, I think blockchain is definitely a technology we have to look at. And I think for a specific use case like that, blockchain may have a value to add. So a lot of people look at blockchain and they see it as a super solution that can solve a lot of problems where, really, it's grounded in that integrity-based solutions. And that is where blockchain tends to fit most closely. However, there have been, especially recently, three or four different proofs of concept that have demonstrated exploits and demonstrated problems with blockchain technologies and blockchain implementation. So it definitely needs to be researched, definitely needs to be explored. I would not consider it a silver bullet that would solve all problems with integrity. SAM VOLCHENBOUM: So no startup there for us to do? NATE EVANS: Maybe, if you have a great idea. SAM VOLCHENBOUM: But it's got blockchain in the title, so it must work. There's a question about how we can try to maintain our collaborative nature with other countries while trying to ensure the security of our data. And I think that is a difficult issue, especially as the data become easier and easier to manipulate. So how should the US as a economy be approaching our ability to set up partnerships with other countries and other companies? NATE EVANS: I mean, I'm not a believer that the specific types of data, which is where the security lies, needs to be released in order for research and collaboration to occur. So I believe that there can be research and collaboration with foreign entities, other countries, even potential enemies, in order to move the science forward without compromising or spilling them the data associated with that. When we're looking at the specific secret sauce, we tend to be looking at the specific DNA sequences for-- We keep bringing up anthrax, but that is an example, or other potential viruses or aspects like that which we are creating. A lot of that stuff, we can continue to hold back while continuing to talk and continuing to collaborate about how we look at the larger research questions, whether it's utilizing bioinformatics, whether it's utilizing other research platforms in the cybersecurity world [INAUDIBLE].. SAM VOLCHENBOUM: But I imagine there must be a tension between what the DoD wants and trying to maintain a good defense posture with allowing open and free research. NATE EVANS: Yeah, working at the national lab, that's problems we face all the time. I mean, one of our missions is national security. However, we are able to do open science and able to support collaborations around the world in what I would consider a very productive fashion. I mean, there are ways to do it. I mean, it can be challenging. But there are solutions, and it has been solved in both academic groups as well as research groups like national labs. SAM VOLCHENBOUM: So you might have a perspective on this. So I was at FDA yesterday on their main campus, and the security to get into FDA was 10x what it is at the airport. I've never had to go through such stringent-- both for things I was carrying. There's no network. There were no USBs. And I imagine a lot of that security is less about risk of guns and things like that but more around the kinds of things you're talking about. JENNIFER FOWLER: Yeah, you'll see hot glue in USB ports so that people can't plug in external devices. And that's really all to protect the data, that you can't gain access to the network. You can't gain access or exfiltrate some data of some kind. But yeah, it's interesting, isn't it, that the private sector and the government implement different security measures based off of what they value and what they deem as a potential security risk? SAM VOLCHENBOUM: Yeah, I was very, very interested to see that. And people that work there, I think they're used to it. But as an outsider, it was a striking, striking difference. NATE EVANS: Yep, yep, yep. And in some ways, I mean, they're there to try to protect the data from being compromised from a confidentiality type of perspective. It's an interesting of problem, mentioning that cybersecurity aspect against the physical security aspects. And one of the problems we see and one of the reasons I think we're starting to see a lot of these organizations like FDA or mechanisms like that implement much more of those cybersecurity best practices is because a lot of the agreed-upon standard practices haven't been done. It's that large nation-state perspective. So the concept of a cyberwar has not really been defined. So when an organization tries to break in and tries to steal data from a specific company or a specific government agency, that's not an act of war. If they tried to bring a spy in, they have policies, they have procedures, they have mechanisms for that. Those don't exist yet in the cybersecurity world. So as such, you tend to see this push more towards security there as we need to bring that closer to home to protect our own data as opposed to looking at treaties, looking at more political ways then to try to prevent that. SAM VOLCHENBOUM: So as a physician, I'm always trying to get people to share their data. I mean, that's one of my research interests is creating ways to share and to make data more available. But the message I got from hearing your talks were that we should be much more conscious of being careful about how we share our data. And so how do we manage that potential tension there? Because I believe the more data that are free and available, the better research we're going to be able to do. And obviously, people need to be aware of what they're sharing. So what should people be doing to protect themselves, and how can we manage that? JENNIFER FOWLER: I teach encryption on the side, so I'm always going to go back to encryption and authentication. But I think protecting your data as best you can, let's say, on a user level-- you can't always protect your data once it gets to the facility level. You just do a little prayer and hope that they're doing what they need to on their end. But at a user level, if you're logging into your email, you should be enabling two-factor authentication, where it's something you have and something that you know. So you know your password and you have your phone, which will then send a six-digit PIN to your phone that you enter after you enter your password. So enabling things on your end, on the end-user side, to help protect your data I think is important. But you're right. Enabling the free and open communication and the sharing of data is paramount to making breakthroughs. So it's a really fine line, I think, to tread on, OK, I want to share data. And I want to be helpful, and I want to help push innovation forward. But I also want to make sure that I'm protecting my own data. You see that even with submitting for a mortgage or something like that. They need everything but a blood sample in order for them to approve you for a mortgage-- having gone through that recently. You see, even with when you go to the doctor, they'll ask you things. But yet, they're using a tablet with a camera on it, and it's pointed at you. And I've had that happen to me in my doctor's office. And then I come in with electrical tape, and I'm like, let me just tape that camera for you there. So I think, combining data and technology is great for innovation, but you just have to make sure you're taking the proper steps to ensure privacy, whether that's through encryption or-- SAM VOLCHENBOUM: Right, but I would hope we're all getting the message that we need to encrypt our computers and have two-factor on and to be careful with our data. But I'm really thinking should I be afraid of going in a private Facebook group and talking about medical symptoms? Should I be worried about my 23andMe? Obviously, we're trusting 23andMe to not be nefarious, but what about the data getting stolen? I mean, what about my Fitbit or my Garmin? Am I at risk there? I mean, how should people really be thinking about their data? Because on one hand, you paint a pretty scary picture. But on the other hand, we're all being asked all the time to do these things. JENNIFER FOWLER: I think it's a fine line of security versus convenience. I use an Apple Watch, and I use that data. And I use all of that because it's helpful to me. I need to know when I'm being lazy and not standing once every hour for 12 hours. I need to be able to talk to someone about medical symptoms or something like that. I will say that it boils down to how much do you trust other people with your data? Do you trust 23andMe not to outsource that data or to protect your data? Do you trust any type of company with that data? We've seen historical use cases where security is difficult. And so it might not be for any negligence on anybody's part, but implementing security can be a very difficult process. So while they may do their best effort to secure something, in the end of the day, something slips through, an attacker gets in, and that data gets exfiltrated. So I think it's just how much you really trust the company. SAM VOLCHENBOUM: So do you have a wearable device or do you use home voice assistance? I'm curious. NATE EVANS: Yeah, I do. I use all that stuff. So I mean, I analyze it, and I look it at all from the traditional risk formula. So I mean, yes, there are vulnerabilities there which exist. And there is a potential consequence. You could argue that consequence could be higher, could be lower, depending on how much you trust the recovery mechanisms that exist out there, if I lose insurance or lose my own data, accordingly. But me personally, when I look at it from a threat perspective, I mean, I don't see that threat actor that's knocking on my specific door to steal my specific data or things like that. SAM VOLCHENBOUM: But is that an issue of cyber biosecurity, the fact that your Alexa or Google Home could be listening to your health care conversations that you're having? NATE EVANS: I mean, I think it potentially could be, yeah. And I think it potentially could be in a theoretical fashion. But what I'm saying from a risk perspective, looking at it from a threat actor perspective, the chance of a bad guy trying to break in just to listen to my health data is very low if not nonexistent. I'm probably more likely to be struck by lightning or some other aspect. SAM VOLCHENBOUM: And probably not very exciting either. NATE EVANS: Yeah, exactly. So hopefully not. And so with that, I mean, I think one of the interesting things with 23andMe and all these other organizations you brought up and Fitbit and mechanisms like that, is just one of the big frustrations I see is that lack of transparency associated with that. We all have to sign these huge things that we don't read and click Accept or put a signature on. Even when you go to the doctor, you get all these forms or sign a mortgage. You don't really read all that. Maybe a lawyer sums it up for you before you go through it all. But trying to find ways to make this more transparent, to find ways so at least you know what their intent is to do with that data is where I would like to of the organization shift towards. SAM VOLCHENBOUM: Yeah, we talk about this in the ethics class in the biomedical informatics program that it would take-- somebody calculated it would take over 70 days to read all the privacy agreements and user agreements you're given in a year. So it would be a heavy lift to make sure that we understood what was going on. But we all click that Apple iTunes agreement away and not realize what it's really saying potentially. You mentioned the concept of resilience, but we didn't talk too much about it. So if one of these supply chains or something or if something gets infiltrated, is that what you're talking about in resilience? And how do we think about resilience in terms of cyber biosecurity? NATE EVANS: Sure. So resilience is a more complicated aspect associated with security as a whole. So if I look at the traditional risk formula, threat vulnerability and consequence, resilience is a enhancement factor on to that. So it provides an additional element that can apply to all those elements as part of that. So as such, looking at resilience specifically in the bio cybersecurity world, I would look at it across the three elements with the CIA triangle. So there can be resilience applied to application consequences. Try to buy or try to make DNA sequencers cheaper. Try to buy more of them so you aren't dependent on a individual infrastructure associated with that. Could be applied to integrity aspects by doing a variety of checking associated with that, even applying something like a CRC code or some verification element to confirm that this is real DNA that I'm processing or mechanisms like that. And even on the confidentiality side, applying encryption, as Jennifer mentioned, as well as other common practices with that. So as such, resilience is a more complicated factor that can be applied across those elements with that. And yes, I definitely believe it has a place within cyber biosecurity. I don't think that's been explored heavily. I don't think cyber biosecurity as a whole has been explored heavily. I think it's definitely a new field and definitely a growing area. SAM VOLCHENBOUM: And a lot of the examples you give are things that would be preventative or preparatory, but I bet they're also-- we have a lot of ways that we do disaster recovery for data. I imagine in the same way you have to have a-- I don't think we have a plan in place at the hospital for if all of our sequencers stopped working that had to do with the security of the data. It sounds like that's a whole unexplored area that we should be thinking about. NATE EVANS: Yep. Yep. That as well as, from a resilience perspective, I look at a dependency and interdependency concept. When most organizations look at dependencies, they first think only about traditional dependencies-- power, water, et cetera-- when there are cyber dependencies. There are data elements which are needed to be taken into account, as well as potentially data-processing elements as we start moving to cloud service providers and mechanisms like that. And additionally, we tend to look at just one step away from us. We don't look at the dependencies associated with that dependencies. And so I think trying to build these larger dependency trees to try to understand how our society as a whole may function on the power plant down the road is a very valuable, eye-opening concept for an organization like a hospital or a biomedical company to go through. SAM VOLCHENBOUM: Do you have any interesting or cool examples of where you've seen cyber biosecurity being exploited or having been used nefariously? NATE EVANS: So it's a growing area for us. So personally, no. We haven't gone through that assessment process yet with a lot of different organizations. We actually just produced a paper starting to analyze in that assessment framework and to look at what elements to put in there, whether or not to tackle things like resilience or protection or some combination of that built on some of our larger assessment frameworks like looking at critical infrastructure as a whole or critical cyber services as a whole. So no, I don't have any great stories associated with that. I don't know if Jennifer does with that. JENNIFER FOWLER: A lot of the examples that I mentioned were hypothetical in theory, plausibly doable. But I haven't read of any of them actually being implemented. Now, that's not to say that they haven't. We just haven't found out about it. But I haven't experienced any of them specifically myself, no. SAM VOLCHENBOUM: I was thinking a lot about pharmacovigilance when you were speaking. And I'm not an expert on pharmacovigilance. But to me, pharmacovigilance is the process between the time a drug gets made and when it makes it to its end point. It goes through lots of different shipping and scanning and barcoding. And there's lots of questions about, can drugs be stolen and replaced? But a lot of the things you were talking about strikes me also as an issue of cyber biosecurity by being able to track those elements. And pharmacovigilance is a pretty well-thought-out paradigm. So I'm wondering if there's a lot of overlap there in the kinds of things you were talking about that would be applicable here as well. NATE EVANS: Yeah, I mean I personally haven't considered that before. But, yeah, I mean, it sounds like there would be a lot of valuable connections there. And I think that's definitely a great thing to look at and potentially explore. SAM VOLCHENBOUM: Do you see a regulatory body that would emerge as the arbiter of these types of policies? Is it the FDA? What groups in the government do you think would be the most-- DoD-- that would be the most involved in this kind of work? NATE EVANS: So I believe at some point there definitely needs to be one. I don't have an opinion where it stands. Currently right now, the Department of Homeland Security owns the biosecurity responsibility across the nation. And DHS has, I believe, one regulatory authority right now looking at chemical facilities. Whether it makes sense to put it there or makes sense to put it in a different organization, I'm not really sure. At one point, the Department of Energy owned a specific element associated with biosecurity. And it might make sense from a certain element to be there too. I think that there can be a lot of argument where to place it. I just believe it needs to be somewhere and would like to see more emphasis, more focus, either on research dollars flowing there or even regulations or even thought towards security being put there. SAM VOLCHENBOUM: OK. Good. One of the questions, interesting, is a question about our education process because, I mean, I went through med school a long time ago. But at the same time, there was very little discussion about privacy and data security. And we're focusing on this a lot in our master's programs-- in our threat and response management program, in our biomedical informatics program. Do you think that there's an opportunity in the way we teach medical students and nurses to integrate some of this into the process? Are you aware of any efforts around that? NATE EVANS: So I'm not aware of any efforts currently around that. I mean, I the same concern. My sister's a nurse practitioner for a hospital down in St. Louis, and so I asked about some of those cyber elements with that. And I was surprised that there wasn't anything with that, minus what they may do, their own aspects associated with that or what they're required to do from a training aspect around the hospital as a whole-- similar to what most universities and companies do-- some online training that you have to go through more from a legal perspective than really an education perspective. So yeah, I definitely see a gap there. I'm not sure where that would fit within a traditional medical program or not. I'm unaware of how those programs are set up and structured. I'm hesitant about adding even more school on top of what I think's probably an over-schooled element already. SAM VOLCHENBOUM: Sure. NATE EVANS: But I do see value in providing that somehow. JENNIFER FOWLER: I agree. I think providing at least one class that's a crash course on how to uphold the CIA triad and going forward in your work and even that would benefit people personally. And I think there may be more of a interest now that we see ransomware hitting hospitals. And it's brought to the forefront of, oh, me as an end user or a user of this system may be a potential threat vector for someone to utilize in order to gain access to a system. So I think it would behoove people to add maybe a class in or some educational training of some kind to help prevent not only ransomware from happening at a hospital per se, but also to protect PHI or data just in general. But, yeah, I think that would be a great thing to add in. SAM VOLCHENBOUM: Yeah, there's a fair amount of training around protecting patient privacy and security, their data, but not the elements that you were discussing. So I think there's an opportunity there, for sure. If people want to find out more about the work you're doing or perhaps even get in contact with you or we might have students that want to do capstone projects, what are the best ways to interact with you guys? NATE EVANS: Yeah, so our website's listed here on the slide, which we'll talk a lot about some of the projects we do accordingly with that. It's just coar.risc.anl.gov. We do have a semi-active blog there where we'll talk about a variety of different things across cybersecurity as a whole, not dedicated to cyber bio. However, there are elements on there we throw on there. Additionally, you can email either of us, and we can sure have a continued conversation with that, whether it's towards capstone or towards other elements. We're very interested in the field, and we'd love to continue to support whatever research and whatever great ideas all you guys have. SAM VOLCHENBOUM: That's great. So we'll be doing fingerprints and pictures on the way out. Let's have some applause for our speakers. So thanks to Nate Evans and Jennifer Fowler for coming out to speak tonight. It's been fascinating conversation. Also, big thanks to the marketing team and the recruiting team for helping put the program together tonight, along with the program staff from the masters programs in biomedical informatics and threat and response management. Tyron Harris is in the back. Wave around. If you have questions about any of the programs or any of what we do, there'll be several of us around here. And we're happy to chat with you and appreciate everybody coming out. Thanks very much. Good night. 