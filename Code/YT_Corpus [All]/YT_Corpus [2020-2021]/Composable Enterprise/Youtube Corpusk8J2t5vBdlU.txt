 Hello. My name is Joe Hardy. I am a  compute solution architect at Hewlett Packard Enterprise. Today. I want to talk to you about the options for deploying software-defined storage within the Synergy frame. We have worked on a number of other videos that are available on our YouTube Channel, which talk about external storage working within the Synergy environment. So I wanted to get into the same detail around what we have available within the hosts itself. Synergy and its 12U frame can contain up to 12 compute nodes, these are typically the Synergy SY480 Gen10 node. But we can also install the D3940 storage module. Typically, we see a pair of these deployed per frame for redundancy. And these connect by a SAS to controllers located in the back of the synergy compute nodes themselves. There is also a pair of interconnect modules that fit in in the back of the frame. And these provide all of the SAS connectivity from the drawers through to the actual hosts themselves. When we are deploying this solution, this is really targeted for SSD optimized software-defined storage solutions, things like VSAN technologies that use a lot of a backup capability as well. We also have the ability to use these drawers as shared storage and present the same drives to the same hosts, if necessary, potentially for things like applications, app storage itself, and also for Windows Storage Spaces Direct. All of these workloads are able to deploy into  this sort of form factor. I would say that the majority of connections for this are, as I mentioned over SAS, but we also have the ability to put little NVMe drives in the nodes themselves. And these this can be  NVMe with Intel Optane and also as a caching tier for the sort of workloads where we may be using NVMe to accelerate traditional software-defined storage applications. So that really give you quite a lot of flexibility because it means that a node is not limited by the number of drive bays it has on the front. Synergy also has the ability to deploy a couple of smaller sort of mezzanine style NVMe devices within the node, and these could be used for boot volumes. These could be used as a supplement to the the externally connected NVMe on the front. We are looking at where this sort of technology can grow as storage develops and we are expecting a continued presence in this space of technologies where we share a number of discs between a number of hosts. That's really where SAS has an advantage at the present time and why we sort of kept this architecture going. In terms of scaling this out, as I add on additional Synergy frames, I may well deploy a pair of storage drawers in that first one. If I have a second Synergy frame, then it will also have its own storage drawers. We keep the storage traffic within the bounds of one physical frame at the moment. So there is no sharing a SAS level between a computer node here in this frame and a set of drives that we are consuming in another one.  These drives are only available at the present time to these to these hosts, and that means, when I do any sharing of that, it's going to be using some software-defined storage technology further above. If you contrast that with the way that we typically deploy like a rack mount server , something like the DL380 Gen10 where we can take a two U 19-inch rack mount form factor, where we divide these things into three bays. Three equal space bays where I can either have eight SAS, eight NVMe, or hybrid of the two deployed in there in those same areas. This is really nice for VSAN, whether I want to leverage an awful lot of NVMe or for any sort of technology where storage performance by using PCI Express connected storage is really going to have an advantage. So you have got some real choices. I can set something up that is very high performance but is sort of constrained within that single system or a can set something up, which can still deliver great performance from SSDs that are connected over SAS. But it is programmatically controlled, it is composable through all of those APIs and can be allocated to any of those individual hosts. There is a lot of choice within these environments, and realistically, the thing that drives that choice is the choice of your software storage technology that sits on the top.  If you'd like to learn more, please check the links below, in the description.  I hope you found this video useful. 