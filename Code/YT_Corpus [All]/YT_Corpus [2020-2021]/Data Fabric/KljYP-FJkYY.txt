 hello everyone today we're going to talk about how you can enhance n 365 experiences using graph connectors the session has interesting the moves along with product details so let's get started before we go into details let me walk you through a typical day of my friend Amanda who is also a developer like you she goes to work the first thing she does is go through emails today is not going to be a boring day because she finds an email about a high priority customer Burke she follows the link in the email to JIRA portal which has details of the book she reads the exact customer scenario in the bug details and wonders if it is a valid scenario at all so she goes to the product spec file which is hosted in SharePoint after confirming the scenario is valid she starts debugging the code which is hosted in github after a few futile attempts on debugging she searches for exception in that bug description in her company Stack Overflow portal she finds a good answer and is able to arrive at the right fix the code she has modified isn't owned by her team so she finds out people who own that code and raises the review request from HR DevOps she searches wikis to understand a few terms in review comments she then pushes the final fix and leaves for home happily what we see here is amanda using 8 different data sources in what seems like a very normal day and at each point she had to proactively figure out where she can find the required information another thing to notice very few of these data sources talk to each other like when she went to Stack Overflow the portal had no idea which exception message Amanda wants resolution for the siloed structure costed time and effort now imagine all these silos broken and data sources talking to each other let's say right at the beginning when she was reading the email she is automatically suggested the Stack Overflow Ling she can look at for possible fix or when she goes to SharePoint SharePoint recognizes which file she needs and shows in homepage but when she is addressing review comments in video she suggested the wiki page she can refer what if all the employees in her organization get such benefits with all the data sources so much time and effort will be saved Microsoft graph and graph connectors is that technology which together makes such amazing experience as possible Microsoft graph creates very useful relationships between data like SharePoint recognizing which file is important for you based on email or outlook recognizing which people are important for you based on teams charts and Microsoft graph connectors augments this by breaking all silos and expanding the capability to all data sources the data you natively store in your oaths is defi tenant like users files mails they're part of graph by default using graph connectors all the other sources such as service node tickets wiki's sequel server network file shares and so on and also added to the graph let's say we collected all the data to graph what are some cool experiences that are possible let's look at a few examples let's say you're searching in SharePoint for research related items with the power of graph connectors results are so comprehensive that you see an experience like this where items from nan-oh 365 data sources show up as a results cluster once you click on this result fluster you go to a custom vertical where you see all the relevant results from that data source in that custom vertical you can refine your results based on a bunch of item level properties this is another possible experience where you can discover trending items in the homepage of various applications this of course includes external items which are plugged in wire connectors and this is a very interesting experience what we call Project cortex where you can pick any entity and the graph smartly collects all the important related items and this can include the wiki's you push to graph through connectors these are all just a few examples possibilities are not limited to this using graph api's you can create as many interesting experiences as you want of all the possible scenarios search emerged as the most sought-after experience among the customers so in last one year we focused on delivering a good end-to-end search capability through our out of box connectors and graph API we started graph API preview program in November last year with six out of box connectors and one hundred-plus partner built connectors we worked on customer feedback and made good improvements in all the components in world today we are happy to release the second preview of graffiti ice along with two new connectors all the target release students will have connectors enabled very soon we will also release a new data gateway dedicated for powering on Prem connectors most importantly we are excited to announce that graph api s-- and the connectors will be GA by ignite 2020 we discussed in detail how valuable connectors can be in search now let me quickly demo how admins can deploy these connectors for some time I'll pretend to be search admin working in the 90 services company called fabrica our company works on web development projects for multiple clients and as you can see all these projects are tracked in Azure DevOps and creating connections to these projects in a phased manner so today I am going to create connection for this project called smart hotel 360 it has a bunch of epics features bugs paths and so on now let me go to M 3 65 admin portal to create the connection for this project so that users in my organization can easily search for them this is M 365 admin Center I'm in connectors tab under Microsoft search option I already created one as a sequel connection few days back and I see that here now let me click on add to create an azure DevOps connection in this catalog I see all interesting connectors I can use we use a good number of these data sources in our company like within ServiceNow for now I'll select as your DevOps and get back to the rest later here I'm entering the name connection ID and a short description I agree to the terms and conditions and next I am entering the organization name here for authentication I need to get client ID and secret from measure apps portal I copied them already so let me quickly enter here sign-in is successful so I click Next in this page I have two options to configure the connection one is entire organization and if I select this all the projects in my company get connected as I said before I only want to do this in a phased manner so I'll select only smart hotel 360 I see a set of properties that get ingested I want to add and remove a few of them so let me click on edit we don't need retro steps property I removed it we need description property though so let me select it and hit save the preview of these properties looks alright I click Next here I want to make this property searchable and retrievable you I will click next now everyone in my organization can see the results that works all right to me so the incremental crawl which picks just the changes runs every 15 minutes and the full crawl which goes through the entire data runs once a week these look fine to me so let me click Next all the connection details looks fine to me so let me click Submit the connection is published and ready now for the users to be able to see the results I need to create a custom vertical where I can see results only from Azure DevOps connections for that I am going to customizations tab I'm going to verticals I'm adding a new one and naming it work items and this is for the connection named fabric am the one I just created I don't want to limit the scope of the vertical to few items so I'll skip this step details look fine to me I'll add the vertical along with the vertical I also need to add a result layout for the work items I'll name this layout ad of Abraham content source is fabric a machine once again I don't want to limit the layout by any property so next here I have all the properties I can use in the result layout these layouts are built over adaptive cards framework and I need to put the final JSON of the layout here I already created it so I'm just basing the JSON here summary looks fine and add the result type is added I will quickly enable the custom vertical as it has a result layout now and done let me quickly check if the results are showing up for search I already have a query here I did for something else a while back when I go to the newly created work items vertical I see the results for that query I got some test queries from the project team so let me try them out and see if the results appear yes the results are there and in the layout I created let me try out another query meagan bound is an engineer in our team and i see all the items which are assigned to her you saw how Microsoft built connector works I know many of you are eager to build your own connector my colleague Raju will explain you how it can be done thanks mom see now that you know what graph connectors are let's understand what it takes to build one over the next 15 minutes I will walk you through the basic concepts and also show how you can build your own connector in order to build a connector unity use Microsoft graph graph is the rate of fabric that powers various Microsoft experiences it contains all the data that is there in the Microsoft cloud to add your data on Microsoft graph you need to create a connection a connection is an instance of your connector and is a logical representation of a data source you could think of the connection object in graph as a container for all your external data the connection is also the unit of administration in the graph connectors platform once you have created the connection you would be able to add items inside the connection items that are added to the connection need to conform to the structure of the Microsoft graph external item which means each item in the connection needs to have a unique item ID you would use this ID to create update or delete the item in the graph we let you supply your own item ID and you could use the primary key in the source system as the item ID or derive it from one or more fields in the source system the item itself has three key sections Akal properties and content the access control lists are Akal in short has information that is used to determine whether a particular user has access to view the item in a Microsoft experience it is an array of access control entries currently we support allowing or denying access to specific ad users or groups in our aces there is also a special is called everyone which denotes every single user and the tenant the next sticky section is properties this is the place where you ingest the metadata of an item before you ingest items into a connection you are required to register the schema with these properties the connection schema is essentially a flat list of all possible properties that you plan to ingest along with the datatype labels and connection attributes we support single and multi valued variants of key data types such as string integer double date time and boolean if your data source has other data types you need to figure out a way to translate that into one of the supported data types labels are well-known tags that you add to your properties the labels of a semantic meaning to the properties and help Microsoft experiences understand your content better for instance adding labels would improve the relevance as well as the out-of-the-box experience for Microsoft search we strongly encourage that you add as many labels as applicable in your connection schema finally we have the connection attributes when a property's marked searchable the value of the property is added into a full text index that is the item would be returned if there is a search it on any of its searchable properties when a property's mark variable it allows end users to perform scoped queries such as title : canto so in this case the search results are narrowed down to items that contain the term canto so in the value of the title property when a property is marked retrievable it can be displayed in a search result make sure to only mark properties that you plan to add in your search result mplet as a retrievable marking large properties are too many properties retrievable can adversely affect query performance finally you could mark property as definable to add it as a filter in the microsoft search front end we support registering up to 128 properties per connection while this is sufficient for most data sources if you have a data source where you need more than that you need to provide an experience for the admin to pick and choose the fields that are most valuable to them content is the most important part of the item this is where the bulk of the item goes whether it be the file body or your ticket description that your interesting choosing the right content property has a significant impact on relevance as well as the graph experiences as of now we support interesting content of type text or HTML which means if you have a binary file you are expected to pass it down to text before ingesting likewise in case of images or videos you are expected to extract the metadata using OCR or video transcript service before ingesting into a graph anything added into content is full text indexed while content cannot be directly added into your search results we allow you to add auto-generated snippets of relevant sections from content into your search results now that we learnt the basic concepts about connections and items in graph let's jump into what it takes to build a graph character for the purpose of this I have built a strawman file-share connector a good connector has two key components an administrative component allowing the admin to set up and manage the connector as well as a sync component that takes care of syncing the content into grass this is the administrative console of my sample connector an admin would be able to create and manage his connections from this page in this drammen connector I allow creating connections to unauthenticated file shares in your case you might have to provide a mechanism to authorize against the content source when setting up a connection once I create the connection I display the connection schema that I've chosen for the administrator I also offer an experience where the administrator can customize it to provide a better experience for their organization then I offer the ability for the admin to schedule content sync a good scheduler would allow an admin to choose a sync frequency along with the ability to schedule calls at a specified time period for example at night time or or beacons when the load on the source system is likely to be low you would be able to add additional capabilities such as providing sync Diagnostics or connection statistics on top of the connector administration experience the same component is the cuts of the connector you need to figure out the best strategy to traverse your data source a watched majority of data sources are lists and only a small subset are a graph or hierarchical in nature you need to ensure that you expect the source permissions and craft the Akal correctly to reflect the same permissions in graph while we don't support actual inheritance or containers there are ways to model Ackles by creating pseudo groups to reflect the right permissions as in source a common best practice is to expose different cloud types a full crawl required for the initial sync and a more efficient incremental crawl that updates only the items that changed you might encounter a broad spectrum of change detection options from the source systems when the most common form of change detection is through a timestamp in the source system some provide change notifications or change Long's that could make your calls far more efficient in some rare cases your data source might not provide any mechanism to detect changes the common practice is to maintain a hash of Akal properties and content of every single item and sync only what changes you can also provide additional value to your customers by offering content enrichment services while most of these need to be handled by you as a connector developer the grants connector platform offers arrest api's to create and manage connections register connection schema and in just items in order to call these api's your app needs the permission external item dot read/write dot on once I have registered my app in Azure Active Directory and obtain the admin consent for the external item dot readwrite not all permissions I can give it access tokens to make graphic vehicles using the client credentials flow now to show a list of connections in the admin console I make a graph API call with this token to get all the connections when I create a new connection I get the friendly name description and target path as inputs in this case I have a simple logic to generate a unique connection ID out of the friendly name and then I make a history TP post to the flash external slash connections endpoint with the ID name and description to create my connection once the connection has been created I can go ahead with the schema registration and to do that I do an HTTP POST your slash connection slash schema and finally so an item I make a hasty teepee put to the items collection within the connection object the port operation here serves as an upskirt allowing me to insert a new record our update and replace existing records in case only one part of the item changes for example just the Apple changes I don't have to observe an entire item I can issue a partial update with any combination of errors properties or content and finally when the item is deleted from the source I can issue a delete call to remove it from the connection once the connection has been created I can initiate a crawl manually in this case I am choosing a full crawl you will notice that the items in the file share are getting parsed and indexed let's look at what's happening under the hood in case of a file share I need to recursively I trait through the file share to ingest content however is the sample I am just a liberating the files on the top-level folder but you get the idea the files in this directory are all binary files so I need to pass them to get the metadata as well as the text version of the content and for this I'm using Apache tika an open source parser once the file is part I construct the the item object with metadata and content from the parser output for sake of simplicity I have used allow everyone is but when implementing you need to extract the on-premise SID present in the individual files and use the graph EPA to trade it for a ad ID to construct the right echo once the item is ready I can make an absurd call to add the item into the items collection you might have noticed that parsing a file is a very costly operation and it takes quite a while so after my initial sync i would resort to an incremental crawl also I have added a crude version of incremental call that operates against the modified timestamp I scope for items that have changed after the last crawl period for parsing and addition making may call for more efficient once ingested my content immediately shows up in the microsoft search fronting as well as the search api on grass hope this was a useful session you could reach out to us on Stack Overflow we use a plea connectors and postpone connections at github and everything you need to build a graph connector is present in this one single link aka dot MMS slash graph connectors happy coding you 