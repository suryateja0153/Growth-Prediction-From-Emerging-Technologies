 Good afternoon everybody and welcome to the AI accountability and governance webinar. Please note you can submit questions to the team throughout the presentation using the live event Q and A function and we will publish questions as they come through to be taken at the end of the presentation. We're ready to go Hello I'm Carl Wiper group manager in the Innovation department at the Information Commissioner's Office and with me today are my colleagues Abigail Hackston senior policy officer in innovation and Alister Pearson also senior policy officer in our technology department. Accountability is one of the key principles in data protection law. It makes you responsible for complying with the legislation and also being able to demonstrate that compliance. For projects involving AI and personal data there can be added complexities when it comes to complying with the accountability principle. In this webinar we'll look at AI accountability and governance and provide some practical ways for ensuring that you are compliant with the accountability principle. The ICO has recently published the beta version of its general data protection accountability framework and you may have seen now that piece of work is distinct from our work on AI, but will still provide general guidance on how you can comply with the accountability principle. In this webinar we'll mostly focus on AI specific implications. The ICO has recently published two pieces of guidance on AI and data protection issues. In May 2020 together with the Alan Turing institute we published guidance on explaining decisions made with AI. that guidance provides best practice advice on how to provide explanations to individuals, when a decision using ai is made about them. The guidance is not exclusively a data protection compliance document, but it does include requirements under current data protection legislation. Then in July 2020 we published guidance on AI and data protection. this guidance will be the cornerstone of the AI auditing framework It covers what we think is best practice for data protection compliance AI, as well as how we interpret data protection law as it applies to AI systems processing personal data. The framework is designed to give us a clear methodology to audit applications and ensure that they process personal data fairly, lawfully and transparently. As part of promoting these pieces of work, we decided to collaborate to draw out common data protection themes from both. Instead of running a single webinar to provide a general high level overview of common themes, we decided to run a series of webinars that take a deeper dive into the common themes and this webinar is the first of that series. Today we'll be looking at AI accountability and governance. We are planning future webinars that will look at lawfulness, fairness and transparency,  security and data minimization and individual rights .These will run later this year. We're open to suggestions about what you want to hear from us on these topics. You can email us your suggestions at aiauditingframework@ico.org.uk. Don't worry we'll show that email address again at the end. I'll now pass over to Alister to explore the accountability principle in more detail. Alister: thanks Carl. The accountability principle is about two things, it's about being compliant with data protection legislation and being able to demonstrate that compliance. The technical complexities of AI systems can make it more difficult to be compliant with data protection law and be able to demonstrate that compliance. One reason why AI systems can make it more difficult, is the occurrence of several competing interests, for example, your AI system needs to comply with the data minimization principle that says to only process personal data that is adequate, relevant and limited to what is necessary. However by complying with this you may find that you reduce the amount of personal data in your AI system, leading it to become less statistically accurate, which could lead to non-compliance with the fairness principle. It may appear difficult to see how you can be compliant, let alone demonstrate compliance, however, we recognize that it is unrealistic to adopt a zero tolerance approach to risks the rights and freedoms and indeed the law does not require you to do so. Instead it is about ensuring that risks are identified managed and mitigated. This means you need to be able to strike the right balance to ensure you are compliant with the legislation and be able to demonstrate how you have struck the right balance to be compliant with the accountability principle. I'll now discuss a little bit about why accountability is important. and who you are accountable too. Being accountable should not just be a way to prevent unwanted attention from the regulator! Obviously failing  to be responsible for compliance with the legislation or being unable to demonstrate compliance, will increase the chances that you will be on the end of enforcement action and a possible fine, however there are other more positive reasons for you to be compliant. For example, taking responsibility for what you do with personal data and demonstrating the steps you have taken to protect people's rights not only results in better legal compliance, it could also offer you a competitive edge. Accountability is also a real opportunity for you to show and prove how you respect people's privacy. Individuals are placing more and more importance on how their data is handled. If an organization can demonstrate the procedures they follow to ensure personal data is protected, it is likely that this will help develop and sustain people's trust. As the regulator we have the powers to assess the compliance of organizations using AI to process personal data, therefore you will need to think about how you are accountable to us, including how you are compliant with the legislation and how you can demonstrate that compliance ,however, you shouldn't think you shouldn't just think about the regulator you can also think about how you are accountable to your customers, clients, stakeholders and the like. Individuals will have  reasonable expectations that you handle their personal data in a way that is compliant with the legislation. They are more likely to be more trusting if you are able to demonstrate your compliance. This can be especially important for AI systems as AI is used in more and more contexts. Individuals are likely to be greater affected by decisions made by AI. for example if AI is used to decide on whether an individual is granted a loan or is invited to a job interview or offered low insurance premiums, then AI will be used to make or help make significant decisions about an individual's choices and lives, you will always need to comply with the accountability principle but where you are using personal data to make significant decisions about people it becomes more important that you can demonstrate your compliance. i'll now talk about some practical approaches to AI governance and risk management. As mentioned earlier the introduction of AI into your organization can introduce new complexities, demonstrating these complexities is an important element of accountability. You cannot delegate these issues to data scientists or engineering teams, your senior management including data protection officers are also accountable for understanding and addressing them appropriately and promptly. Although overall accountability for data protection compliance lies with the controller i.e your organization to do so in addition to their own upskilling your senior management will need diverse well-resourced teams to support them in carrying out their responsibilities. You also need to align your internal structures, roles, and responsibility maps, training requirements, policies and incentives to your overall AI governance and risk management strategy. it is important that you do not underestimate the initial and ongoing level of investment of resources and effort that is required. Your governance and risk management capabilities need to be proportionate to your use of AI this is particularly true now while AI adoption is still in its initial stages and the technology itself as well as the associated laws, regulations, governance and risk management best practices are still developing quickly. you should document processes you follow to make choices and their outcomes to an auditable standard. This will help you to demonstrate that your processing is fair necessary, proportionate, adequate, relevant and limited. This is part of your responsibility as a controller under article 24 of the GDPR and your compliance with the accountability principle. As a worst case scenario you should also be ready to halt the deployment of any AI system, if it is not possible to achieve a balance that ensures compliance with data protection requirements. An important distinction when it comes to accountability is between controllers and processors. Often several different organizations will be involved in developing and deploying AI systems which process personal data. The GDPR recognizes that not all organizations involved in the processing will have the same degree of control or responsibility. It is important to be able to identify who is acting as a controller, a joint controller or a processor so you understand which GDPR obligations apply to which organization. If you are sourcing your AI system or significant parts of it from a third party supplier the functions and responsibilities may look different. The data controller has the primary responsibility for ensuring that the AI system used to process personal data is compliant with the legislation and for demonstrating that compliance. If you are producers of AI solutions recital 78 of the GDPR says you are encouraged to take into account the right data protection when developing and designing your system and to make sure that controllers and processors are able to fulfill their data protection obligations. During our research on the guidance on AI and data protection we identified that when assigning the roles of controllers and controllers and processors this can become quite complex. For instance when some of the processing happens in the cloud. This is an area that we will continue to explore and consult with external stakeholders on. We have general guidance on controllers and processes on our website I will now hand over to my colleague Abi who will talk about the different roles and responsibilities when designing AI ABI: thank you, as explained previously correct implementation of an AI system will involve a level of understanding by data protection officers and senior management as well as data scientists or engineering teams. However the responsibilities for each role will vary. We have identified several organizational roles involved in the development and deployment of AI systems and all of these have responsibilities in relation to accountability. Of course your organization may have different job roles and we recognize that in a small organization one person may be doing several roles. Firstly there is the product manager, they define the product requirements for the AI system and determine how it should be managed. The product manager is also responsible throughout the AI system's lifecycle. They are responsible for ensuring it is properly maintained, and that improvements are made where relevant they also need to ensure that the system is procured and retired in compliance with all relevant legislation including the GDPR and the Data Protection Act 2018. Secondly there is the AI development team who are responsible for a range of data collection and processing activities. These include selecting the data ,building the AI model, testing the AI model and training on the use of the system. If the AI system has been procured from a third party, this role may sit outside your organization. Next there is the implementer, They rely on the model developed to supplement or complete a task in their everyday work life. The system provides implementers with information that represents components of the rationale behind the model's results such as relative feature importance. Implementers take this information and consider it together with other evidence to make decision on how to proceed. There's also compliance teams which includes the data protection officer. They ensure that the development and use of the AI system comply with regulations and your own policies and governance procedures, this includes compliance with data protection law. Finally we have senior management who hold overall responsibility for the use of the AI system by your organization. We suggest that both the compliance teams including the data protection officer and senior management should expect assurances from the product manager that the system you are using is complies with data protection legislation. It is important that everyone within the organization understands what their responsibilities are and how they may need to demonstrate compliance for data protection legislation to both us as a regulator and to data subjects. Another important factor in this process is adequate documentation. it is essential to document each stage of the process behind the design and deployment of an AI decision support system in order to demonstrate accountability to data subjects and regulators. It is important to provide documentation that can be understood by people with varying level of technical knowledge and that covers the whole process from designing your AI system to the system's output. key areas should be documenting include why you chose to use an AI system, the collection, procurement, and processing of the personal data used by the system and this may include data used to train the system, and the model selection, building, testing and monitoring. However you choose to organize your documentation, you should do it in a way that is supported by your current document management system and ensures relevant levels of access to those that need to use the information contained within the documentation. The GDPR requires appropriate documentation in a number of areas including article 5 of the GDPR which says the controller should be responsible for and able to demonstrate compliance with paragraph 1 which is the accountability principle as quoted at the beginning of this presentation .in articles 13 and 14 of the GDPR it says that you are required to provide your dpo's contact details, the purposes for which you are processing the data subject's personal data, as well as the legal basis for that processing and the existence of automated decision-making including profiling referred to in article 22 1 and 4 and at least in those cases meaningful information about the logic involved as well as the significance and the envisaged consequences of such processing for the data subject. You must document all of this to ensure you remain accountable. Article 15 of the GDPR gives data subjects an additional right of access to the personal data that you hold on them. This means you should document how you will provide them with a copy of their personal data you process in your AI system. Article 21 of the gdpr gives data subjects the right to object at any time on grounds relating to their particular situation to processing a personal data concerning them including profiling. This means you should document how you ensure data subjects are aware of this right, and how you record if they have exercised this right. Article 22 of the GDPR gives individuals a right not to be subject to solely automated decisions producing legal or similarly significant effects unless certain conditions apply. it obliges you to adopt suitable measures to safeguard individuals including the right to obtain human intervention to express their view and to contest the decision. This means you need to document how you will do this . Article 30 of theGDPR helps you to fulfill the accountability principle, it states that organizations shall maintain a record of processing activities under responsibility and finally article 35 of the GDPR requires organizations to carry out a data protection impact assessment where they are doing something with personal data particularly when using new technologies which is likely to have a high risk to individuals. We discuss these in more details later in the presentation. If you plan to procure a system you should ensure the process you choose allows you to communicate with your vendor in a way that mutually manages expectations if your vendor is able to offer evidence of their compliance through justification evidence and documentation you will be able to better provide evidence of your accountability. You will also be able to assess whether the model offered by the vendor meets the acceptable criteria standards you have set for an AI system As well as ensuring your documentation is complete you will need to review your policies and procedures relating to use of AI. they are important for several reasons as they help ensure consistency and standardization clearly set out roles and responsibilities, and support the creation and adoption of your organizational culture within the AI workstream. You may want to create new policies and procedures or it might make more sense to adapt and extend thosethat already exist such as data protection and information rights management policies or broader information governance accountability frameworks. Both your policies and procedures should cover all the considerations and actions that you require from your employee from your employees from concept to the development of AI systems involving the use of personal data. Some key areas these should cover include your data protection impact assessment, data collection , model selection and training, other policies and procedures will be required, depending on how you use your AI system and what to use it for I will now pass you back to Alister who will talk more about data protection impact assessments. Ali: thanks Abi so data protection impact assessments or DPIAs are a key part of data protection law's focus on accountability and data protection by design. You should not see DPIA's as simply a box ticking compliance exercise. They can effectively act as roadmaps for you to identify and control the risks the rights and freedoms that using AI can pose. They are also an ideal opportunity for you to consider and demonstrate your accountability for the decisions you make in the design or procurement of AI systems in the vast majority of cases. The use of ai will involve a type of processing likely to result in a high risk to individuals rights and freedoms and will therefore trigger the legal requirement for you to undertake a DPIA . Article 35 3a of the GDPR requires you to undertake a DPIA if your use of AI involves systematic and extensive evaluation of personal aspects based on automated processing including profiling on which decisions are made that produce legal or similarly significant effects, or large-scale processing or special categories of personal data or systematic monitoring of publicly accessible areas. On a large scale beyond this AI can also involve several processing operations that are themselves likely to result in a high risk such as use of new technologies or novel applications of existing technologies data matching, invisible processing and tracking of locational behavior. when these involve things like evaluation or scoring systematic systematic monitoring and large-scale processing the requirement to a DPIA is triggered. In any case we suggest that if you have a major project that involves the use of personal data it is also a good practice to do a DPIA even if you may not be legally required to do so. You will need to make the assessment on whether you are legally required to do a DPIA on a case-by-case basis in those cases where you assess that a particular use of AI does not involve high risk processing you still need to document how you have made this assessment. Further guidance on how to complete a DPIA can be found on the ICO webpage in the guidance on AI and data protection where we provide guidance on DPIA that are specific to AI. i'll now hand you back to Carl who will talk about article 22. Carl: Thank you Alister if you plan to use an AI system to make significant decisions about individuals without human input you will have responsibilities under article 22 of the GDPR and article 22 says that the data controller shall implement suitable measures to safeguard data subject rights and freedoms and legitimate interests at least the right to obtain human intervention on the part of the controller to express his or her point of view and to contest the decision. Therefore it's important that you can justify why solely automated decisions are required in this case you should also identify the appropriate safeguards that you have in place and the appropriate individual or group within your organization who are responsible for any complaints related to these decisions. this information should be clearly displayed within your privacy policy further although it's not required by article 22 specifically recital 71 of the gdpr outlines measures that you should take to avoid inaccuracies errors and biases within the system and this means that you should document the decisions that you make about how you do this for accountability purposes and this also will help you to explain to data subjects that the decisions you're making are fair. Now one thing that we haven't touched on today so far is the use of AI systems to process children's data and i'll just touch on this briefly. The Age-Appropriate Design Code which we published recently is a data protection code of practice for online services likely to be accessed by children. It came into force on the 2nd of September 2020. Organizations as we said on the slide now have 12 months to get everything in place and we're committed to supporting organizations as far as we can with advice and resources to help them achieve compliance by next September. As we've said today being compliant and being able to demonstrate compliance are the responsibilities of the organizations concerned. I'd also add that the ICO sandbox is open for applications concerning children's privacy and specifically for implications of implementing the code and as you can see there's an address there for further details and guidance. So what is the ICO going to do next in this space? Well as part of the AI auditing framework we want to produce further materials that will assist you with being compliant with data protection law and being able to demonstrate your compliance .We're currently developing a product aimed at individuals in compliance focused roles and we're looking for feedback and case studies to help shape our thinking. We'll be sending out a survey in the coming week or so to gain some initial feedback. If you've already consented to receiving materials from us we will contact you about this directly, but if you haven't already provided consent but you'd like to receive materials from us including this survey, please email us at events.ico.org.uk as it says on the slide and details of how to get involved in this work will appear on our website shortly. Finally the ICO is hiring, we're seeking experts in machine learning and indeed other probabilistic computing techniques and the roles that these developments play in society and we're also looking more broadly for people who have experience in data science for further information on that you can visit the technology opportunities page which is on the ICO's website So now let's have a look at some of the questions that you've asked us and I think a number of questions have come in while we've been speaking. Suzanne: that's right thank you Carl just to reiterate there to everybody that if you opted to not hear from us in further feedback on the registration survey you can obviously change that request by sending us an email to events@ico.org.uk and I can add you back on to the list. First of all we're going to go to a question that came in via email prior to the event and that is: Given that some AI models will update over time it would prove difficult to produce a formalized process flow as AI questions will adjust or develop over time based on the knowledge it gains would you have any recommendations on how to document an AI process taking into account the changeable or non-linear approach that will develop over time? Alister i can field that question to start with It's a good question i think it's one of the challenges that AI brings to data protection and when you talk about the changeable non-linear approach that it can sometimes take. So what we would say to this is that we recognize that some AI systems do evolve over time particularly where unsupervised machine learning is used which can create difficult implications for DPIAs and other documentation. However you should generally have a sort of overall purpose of your processing at the start of using an AI system but we advise that DPIA and other documents you create as part of your initial assessment are sort of considered live documents rather than static documents meaning that they're subject to change and being updated and that you should review your DPIA and other documents regularly and undertake a reassessment where appropriate so we say in the guidance on data protection that if the nature, scope, context or purpose of your processing changes all the risks posed to individual changes. This would trigger a need for a reassessment and updating your DPIA and other documents. I'm not sure if anyone else wanted to say anything on that question? Carl: no I think you you covered it well. Suzanne okay i will read out some of the questions that have come in then through the Q and A. First up and we're basing this on number of likes so we'll we'll go with the first one now that the ICO has set out its expectations on accountability will the ICO be looking to do more audits to check compliance and how does the ICO intend to make organizations comply? Alister: I don't mind taking that to start with again. So good question So going back to an earlier slide we talk about sort of the powers that the ICO has and the specific auditing and investigation activities that we can undertake can include off-site checks, on-site check tests and interviews and in some cases recovery and analysis of evidence, including AI systems themselves. So in short we do have the powers to conduct audits of AI systems our plans in this space are very much that we will be looking to order AI systems. Obviously this is a a new and evolving space, It's something that internally we're developing our expertise on and knowledge of it before we do it and of course we also have to take into account the pandemic that we're going through and and how it's increasingly more difficult for organizations to comply due to financial restraints and other resource constraints So all these considerations we need to take before we're ready for an audit but in short we are prepared to use our powers to order AI systems. Suzanne: Thank you Alister okay another question What is the legal status of guidance that has been published by the ICO? Is there a difference in status between the explain guidance with the Alan Turing Institute and the more recent ICO guidance? guidance? Carl: i'm happy to take that one of the others may have a view on it. Certainly the guidance that we published on explainability the explain guidance was something rather new for us I think because we were asked to work with the Turing Institute by the government um to produce guidance to help organizations to explain AI decisions to the people affected by them so that was the the origin of the guidance so we weren't originally commissioned on that to to produce a piece of GDPR guidance. It was meant to be more in the way of a practical guidance document so in the explain AI guidance we give our view in there of  the relevant data protection legislation and indeed we refer to to other legislation so that represents our view on where on how we think data protection applies to that particular issue but of course the guidance does go beyond that and the bulk of the guidance as you'll know if you had a look at it is is more in the way of good practice for organizations that are building and deploying AI systems so it's those parts of the guidance are clearly not meant to to be a legal requirement really they're they're meant as good practice guidance It's a different sort of piece I think to our other guidance.  I would say as well in relation to the explain guidance that we see it as a developing piece of work and as we've indicated previously on the slide that we do intend to conduct an assessment of the usability and effectiveness of that piece of guidance and we will be asking organizations for feedback if they've used the guidance in implementing and using their systems so so look out for that as as well, as we go forward but it is rather different. our guidance is essentially in general terms our guidance that it gives our view of the law It's worth mentioning that with both pieces guidance is not meant to be a statutory code and as Carl says it's advice on how to interpret the relevant law as it applies to AI and recommendations on good practice there's certainly areas in the guidance on AI and data protection where we do talk about our interpretation of the law so a good example of that is with DPIAs so we talk about how in the vast majority of cases there is a legal requirement to conduct a DPIA if you're using AI to process personal data so that's where it's the legal requirement for you to do so but we also include lots of best practice suggestions and good practice suggestions for you to do which aren't legally required. But they are a way of for you to achieve compliance But we're keen to sort of emphasize that if there are other ways for you to achieve compliance through other methods that we we don't say then you are of course free to do that Suzanne: okay thanks Alister just a little reminder we are going with the questions that have the most likes so as i'm seeing here there's one that's just jumped up quite quickly here which follows on quite nicely from the last question. What level of detail would you envisage seeing in a DPIA a for use of AI such as facial recognition deployment in the private sector? Alister :I don't mind starting with that i think it is a it depends sort of answer i'm afraid it will be a sort of case-by-case assessment, on how much detail that you put in what we what we do say is that it can be worth sometimes making two DPIAs so one with lots of technical details which can be audited by your sort of internal data science or engineering teams and then another one which is a more high level overview which you could publish and share with the individuals whose dates personal data you'll be processing. That's sort of where the explaining decisions made with AI can come into handy because it can help you to formulate how you process personal data in a way that people can understand which will ensure that you're processing data fairly and transparently. Suzanne: okay thank you i'm moving on to another question here now that is the ICO is working with the FCA on their partnership with the Alan Turing Institute on AI are you proactively engaged to ensure these complement each other? Carl:yeah i can pick up for that question to begin with we are very much engaged with both the FCA and the Alan Turing Institute they they have this particular project which you're referring to there certainly and that's  something that they're doing together but we are we're also very much engaged with with both of those on AI issues and in terms of the fca there is quite a high level of cooperation i think between regulators not just not just us and them but but others as well around AI issues soe we meet and sort of exchange information and work together on identifying sort of trends in in AI and also how AI can assist the work of regulators themselves as a tool so yes there's a high level of cooperation with with both of those and and certainly with the Turing Institute as I said. We're intending to do some further work as a follow-on to the explain guidance  so again that's ' something where we look to involve them as well. Suzanne: okay thank you carl and moving on to probably our final questionm we are coming towards the end of the webinar now l will just remind everybody to submit any changes to your registration to events@ ico.org.uk and i will just read out this final question. Does the ICO have a view on whether the government's algorithm for exam results was gdpr compliant? Alister:  it's worth mentioning that the algorithm that Ofqual used did not use AI yeah it was is another form of statistical modeling that didn't utilize AI we have been engaging with Ofqual about their algorithm any forthcoming action on it will be published on the ICO'S website when the time is right. Suzanne: okay well since that was a sort of shorter question there alistair should we go to another one should we just have one more yeah okay let's see if a controller wishes to audit a processor over their use of AI can the processor charge the controller for the time required to be involved in the audit? AI audits will be quite time consuming and controlled audits could be quite detrimental to processors Alister:that's a good question the answer to that i'm not entirely sure off the top of my head  i'm not sure if there's anything within the data protection act that dictates whether charges can be made  so it may be on a sort of the discrepancy of the organizations involved but to get a definitive answer i'd have to come back to you on that one i'm afraid Suzanne: okay we will make a record of uh of the questions here Carl: i think on on that I don't think we can we can give a definitive answer on that but it sounds like really a matter of the contractual terms between the  controller and the processor really seems like a contract question perhaps rather than a dp question okay sUZANNE:okay just have one final question then let's have one more Does the ICO have any views on the area of voice analytics of customers being a particularly high risk area? Alister is that voice analytics did you say yes so i think voice analytics certainly in the way that they're using now will count as biometric data which is special category data as classed under the GDPR so it would and then it and then if it's on a large scale processing of voice data then it certainly would be interpreted as likely to result in high risk to individuals and therefore you would need to conduct a DPIA before you commenced with the processing of voice data using voice analytics i'm not sure if carl or abby would like to add to that? Carl: no i think you sum that up i think it would depend on on what it's being used for how it's being used and how many people be involved as you've already covered i i would say okay Suzanne: okay thank you very much let's just see if we've got one more question here. How can you work out if the use of AI in the private sector in respect of special categories of data meets the requirements of public interest where consent and other article 9 expectations are not appropriate? Abi : I think an organization would have to look at that for themselves it's not up to us to make a decision on on that so we'll be it will be up to the organization the private sector organization to look at how they're using the data what data they're using and whether it would be and they'd have to weigh up for themselves whether it be in the public interest to process that data and use AI to process that data. I don't think it's something that we can necessarily rule on without knowing the specifics of of the use case. i don't know if Carl or Alister want to add anything? Carl: no i'm happy with it with your answer Alister :yeah nothing further other than it's important just to make sure that you document that you are using that legal legal basis to process  special category data for that purpose. Suzanne okay no problem shall we just go with one more yeah if we make it so yeah okay okay i'm just looking through the most liked and those that we haven't already had, in clinical research settings are regulators MHRA and HRA being involved to upskill regulatory review of studies or trials involving the application of AI? Carl: i think it's difficult for us to to comment and probably not appropriate for us to comment on what other regulators are doing or or their practices so i can't speak for the MHRAor other regulators so certainly we can't speak for them on that but but certainly i i know  through our contacts with other regulators as i said before that that this is very much an issue which is which is on their agendas as it is on ours. We meet with with these other regulators quite regularly to discuss these issues i think it's certainly something that they they are working on I think also as i said you know some regulators are looking more at  sort of upskilling and increasing their own knowledge and skills and resources in terms of dealing with AI and as we said earlier in the presentation the the ICO is is no exception to that know we're keen to to grow our our resource in terms of knowledge of AI So i think you can you can expect to see you know a similar trend with other regulators Suzanne: okay thank you very much Carl i think that's all we have time for at the moment would you like to to wrap things up? Carl:yes happy to do so well thank you very much for those questions and i'm conscious that we haven't answered every one of them but that people have asked in in the chat but if we haven't answered your specific question please be assured that we will be considering them as we develop our guidance. So i think now it just remains for me to say thank you very much for joining us for this webinar whether you're listening live to it or to the recording and please look out for further webinars in this series all our contact details are on this slide thank you very much thank you thank you 