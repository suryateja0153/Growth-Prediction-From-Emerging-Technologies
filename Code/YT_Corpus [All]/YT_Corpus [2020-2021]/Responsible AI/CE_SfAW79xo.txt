 greetings I'm Michele English and on behalf of the Center for International Studies and MIT Mexico welcome you to today's star forum before we get started I'd like to remind everyone that we have many more events planned for the semester including one this Friday at noon on the philosophy of human rights details for this event and others are available in the foyer and for those who haven't already we also have a sign-up list so you can receive email notices on all of our events in typical format today's event will conclude with question with a question and answer session for the QA I'd like to ask everyone to please be mindful of time and to ask only one question and we will be using the microphones during Q&A and please identify yourself and your affiliation prior to asking your question it's truly an honor to have with us today luis videgaray to discuss the challenge of AI policy around the world dr. videgaray is director of the MIT AI policy for the world project and a senior lecturer at the Sloan School of Management it is also an honor to have with us Kenneth oi he's joining the conversation professor Roy is both the professor of political science in the School of Humanities Arts and Social Sciences and of data systems and society in the School of Engineering he is also director of the program on emerging technologies at the Center for International Studies at this time I'd like to invite professor Roy to the podium to provide introductory comments and to formally introduce our esteemed speaker dr. videgaray so thank you Michel it is truly a pleasure to be offering an introduction for Lewis by way of background the gentleman that you see sitting here in the front row has a long and distinguished and sometimes sordid history the distinguished part is an undergraduate degree from Eitam the sorted part is a doctorate from MIT and Lewis also served as foreign minister and finance minister of Mexico I have to tell you a little story by way of introduction Lewis spoke to a group of 85 senior American officials and after his presentation three-star general came over and he said professor is Lewis available to become Secretary of State and I indicated that that might be difficult to arrange but his duties have included working on the successor to the NAFTA the u.s. MCA on a range of issues putting out financial crises and handling problems and disputes on everything from immigration to conventional investment and trade policy Lewis will be speaking today on a ai and development and this topic takes something that is near and dear to the hearts of all of us at MIT ai but to have a serious discussion of the implications and effects of the technologies being developed here and elsewhere for development prospects around the world the format will be presentation by Lewis we'll have a little bit of a conversation up front and then we'll turn to you for questions and answers and as Michelle indicated please identify yourself and we'll have a microphone for you to speak Louise thank you so much for joining us today [Applause] thank you so much can I'm very proud to be here very thankful to the Center of International Studies and to Ken in particular for inviting me to be at the start forum today thank you for all of you for being here I see I see many friendly faces take you for the students from Sloane right here and I want to single out somebody who's here that to me is very special 35 years ago actually what I'm gonna I'm gonna mention to people because I just saw one that he just gave me but I want to start with my thesis advisor it was Jim that was my thesis was completed 22 years ago and I had the privilege to go through MIT as a student with the guidance of Jim poterba one of the best teacher is not only of economics but about a lot of things in life and it's it's a real honor for you to be here Jim thank you so much and I also by the way that your new office is looks a lot a lot better than the old one because there the building is no so it's a it's it's great I also want to mention and acknowledge the presence here of the Consul General of Mexico Thank You Consul General for being here Alberto my friend that's it's an order to have the highest representative the Mexican government here with us today so Ken was very keen was very nice in his presentation and believe me I I have a lot of let's call them war stories about my career in government about the us-mexico relationship and many other things we're not going to talk about that today of course we can always do that please feel free to approach me and and we can always talk about any of those issues but we're going to talk about artificial intelligence today and in particular we're going to talk about artificial intelligence policy and what is how is that evolve around the world why is that important and where are we are we going or are we getting somewhere with that so let's get let's get started and this shouldn't be this shouldn't be alone so what do we mean when we say artificial intelligence policy that's the first question because there's a lot of concerns about AI and so I'll try to provide here not a definition but actually a collection of themes that I would constitute a coherent or a comprehensive AI policy and as you'll see we'll start with a blank page and it will quickly quickly fill up with lots of themes and lots of complex issues first of all one key topic of AI policy is the use of AI in the delivery of government services buying goods and this is this is something that is gaining a lot of traction around the world perhaps a little bit of less visibility but it's extremely important in a lot of places health care education our core activities core services provided by the government in many of the countries like my own the government conducts anti-poverty programs but also serve core services likes a tax collection are can be aided with and can be delivered with the support of AI so the use of AI to have a better government is an important first thing by the way this is how I got involved with machine learning many years ago I was five five years ago I was a finance minister of Mexico and as Ana such a oversaw the governance of the our tax collection Authority and we were trying to do things a little bit better and and after several frustration frustrating conversations with consultants I ended up talking to computer scientists and this and realize that this new well not so new methodology called machine learning could actually help in doing things a little bit better it's a complex implementation but there's a lot of potential in having better delivery of services in in doing that by the way a lot of there's interesting research here at MIT particularly the Media Lab on how to do better delivery of anti-poverty programs with the aid of AI how to make them more effective how to make them more efficient second a key question about AI policy is how should government's invest or use public resources in AI is this something that should be completely left out for the market or should government step in and support both the development and roll out the the use of AI in society of course basic question is research and development and this is a question that looks a little bit different a country like the US or in a developing country you there's but it goes beyond that you have the question of should the government be supporting investment vehicles for startups venture capital funds with public resources this is a model that is very much used in Asia particularly China you see a lot of venture capital coming from the government into into industry so that's a second question education should the government be doing more in funding education in computing or what about tax breaks and other incentives for the use of AI in the economy I'm talking about the economy third big question third big a theme is AI in the economy and a lot of the anxiety a lot of the conversation about AI is about jobs displacement and the inequality that you can create and it's a very valid topic of discussion here mit has a very strong task force which is the future the work of future task force that is preparing a report there's already a partial delivery of that and we'll talk a little bit more about it in a second about how a I care interacts with the job market does he does it create new jobs you see that will displace human beings those those questions are central to any AI policy but it's but economic questions go beyond that it's also market power it's also called a means concentration antitrust policy today we are seeing nose from Europe on data on data policy just a few hours ago the European Union issued a new communication on how they're going to deal with internet platforms and even things like algorithmic collusion in financial markets which is a new topic but some things that there's already some indications that these things might happen so a whole block of issues on the economy then we have the socially this the the social responsibility issues of I of AI things like privacy the fact that the type of AI that has exploded is a of the statistical type it's a machine learning and in particular deep learning it consumes lots lots of information and so how do you deal with that model of learning with the right to privacy and to a private life so that's a that's a big discussion also the issue of fairness and bias and the possibility of discrimination we know that algorithm algorithms can be biased for several reasons explain ability some some type of algorithms but in particularly deep learning algorithms are hard to are hard to interpret are too hard to understand how they get to the predictions that they get to and this could be quite frustrating and quite important in some settings think of a judge that is basing a decision on a recommendation by an algorithm if the judge cannot understand why is that recommendation being done that's a problem but if you can think of that also in the medical context you can think of that in the job market robustness that is the consistency and and how how resistant the the algorithms are to either random variations in the world but also adversarial intentional attacks on their predictions the question of accountability then we have a fifth block which is ai and democracy and the use of these sophisticated techniques of learning very granular information to manipulate the minds of consumers but also of voters and to influence politics in democracies influenced opinion polls influence of course elections we have the questions of surveillance how machine learning can power new tools of surveillance starting with face recognition because well beyond face recognition and the emergence of a surveillance some people talk about surveillance capitalism some people some people talk about a surveillance state but this is clearly an issue and of course AI enabling authoritarian regimes techno or three terrorism that we see in some places some very important places around the world and finally the geopolitics way of AI this is a reality this is a little bit of the of the elephant in the room not everybody likes to talk about the geopolitical dimension today of technology but there's clear that there are clearly rival models around the world now we see a model of technology deployment in China we see a different model in Europe and we see an emerging model in the US according to culture history these are different models and countries around the world realize that there's a lot of talk about a technological decoupling happening as we speak just go to the general press and you'll see almost every day you hear you can read about a coming AI cold war or a or a lot of concerns on national security and and and these division of the world into separate camps by the way for a country that is neither China and or the u.s. nor part of the European Union this is a problem because it means where do we stand think think think for a moment of a Latin American country or an African country where country in Southeast Asia is this about choosing sides so you have these six blocks of themes we could have a lecture on each block we could have a lecture on each line within the blocks so this is a very complex problem and this is not something that will be solved you know in a single report this is this is got to be a collective conversation that's gonna take a while it's gonna is gonna be years in the in the making there's a seven topic that I've added in the middle which is sustainability and we should keep in mind that machine learning is a computational the intensive technology it needs a lot of electricity that means that there's a relevant and increasingly relevant carbon footprint about machine learning so we need to keep that in mind I would add that as a seventh that's the seventh topic okay so how are we doing in terms of developing a consistent effective policy around the world as you may imagine this is a process that is your starting and the first fact that I want to point out and these are all stylized facts is that the world of policy makers on one hand and the world of computer scientists are very different and are far far away these means first of all that there's an information lag so things that concern computer scientists today might become concerns of policymakers still a few years into the future think about the question of privacy privacy has been an issue a very important issue for computer scientists for a long long time and it's been a policy issue much more recently and and you can also almost on every topic see there's a lack but it's not just the lag they're there these are technologies that are quite complex you need if you really want to understand deep learning you have to understand a lot of math yeah computer scientists will tell you it's not that complicated well if you're if you're not a computer scientist or or an MIT scientist it's it's hard so there's need there needs to be some translation and who does that translation is also introducing noise who does the translation well you have the general press sometimes it's good sometimes it's not that good but I strongly recommend MIT News they do a lot of coverage of what happens here at MIT and also I might teach technology review that they do a very good and balanced coverage of what's happening around in the world of of machine learning a lot of work multilaterals the World Bank you'd be amazed how many countries approach the World Bank or the OECD even non-members approach these organizations seeking advice looking for advice we had MIT know that because then the World Bank or the or the OECD come to MIT to ask questions not to me but people who really know about this stuff they and and these are there's a good translation then we have the thing thanks something thanks are good some are very partisan so there's a little bit of a mix then our consultants and consultants are jumping into this opportunity because there's a need for knowledge and consultants are everywhere and they're making some very strong claims and I'll show you one in a minute and then of course one of the biggest sources of this translation of knowledge are the tech companies which is good because the tech companies are very strong in their knowledge but the problem is that they are not unbiased they have an interest they might have a conflict of interest in trying to influence through the through knowledge spreading actual policies and finally there's a language gap there's a lot there's a lot of hype a lot of buzzwords a lot of things that people write in there in the correct context in the original papers or essays and make sense but taking out of context just don't make a lot of sense and you start used to reading everywhere about iko iko iko system server innovation leapfrogging opportunities as a favorite of canon i and and and you see a lot of technical term terms used incorrectly there's there's a tendency to very rapidly adopt these these I'll give you just a couple of examples I don't know if you're familiar with this book this is a book of two authors from MIT from the Sloan School Eric and Andrew and it's a very good book it's a book written back in 2014 the second Machine Age and it's it's a brilliant book it's actually today six years after being published a very good read still and if you can see by the title they were announcing a second Machine Age does anybody today talk about a second Machine Age not really not in the policy world but people talk about is the fourth Industrial Revolution this is by the way I I know closed shop very well we're we're friends this is not a bad book but quite frankly this is a much better book but the platform in which it was in which he was not only published but publicized was much more powerful of course the the World Economic Forum as is is a loud voice around the world with a lot of convening power so nobody talks today about a second Machine Age a lot of people talk about the fourth Industrial Revolution just cast a question what about the previous three nobody knows bad people talk about the first Industrial Revolution I'll give another example MIT as I mentioned is working on the work of the future task force in the fall in October they release this report and it's a very good report if you have a chance to read it I strongly recommend it it's not final still a lot of work pending but here for example if you're interested in what's going to happen to truck drivers with it with autonomous vehicles particularly long-haul trucking what's gonna happen here you'll find a very balanced balanced approach and and and clearly the evidence is nowhere near claiming that all jobs in truck driving in long-distance driving are going to be lost that that is that is not the case at the same time literally the same month that that report was published PBS released this documentary on a i-i need has an entire 40-minute section full of anxiety essentially announcing that truck driving is going to end in a very short period of time and that is not science-based it's a lot of hype just ask me which of these two materials has been more influential has been more watch or read obviously it's a documentary on your on your right and then let me just skip to another favorite and this is I'm not going to name the consultant that this is this is from a very large consulting firm those these two blocks I've added them on purpose to hide the name of the consulting firm because I'm not gonna say something nice about them but they are making these kind of claims to me this is this is a phenomenal claim so these consultants they have a tool kit a responsible a a toolkit that enables organizations that means governments that means companies enables organizations to build high quality transparent explainable and ethical applications that generate trust and inspire confidence okay we're done we just need to go to them quite frankly it's not that easy and just spend spend a morning around csail or go to the Media Lab and you'll see that these are extremely difficult issues to deal with this is not this is not a simple so let's let's let's think what can a policymaker learn already and I want to to share with you three things that today a policymaker can actually learn about the state of a policy or the or the framework towards AI policy around the world first of all it's well-established that there's a need for a policy car driver um if you go back to the 90s and the emergence of the internet and we all some of you might be familiar with section 230 and it was we start perhaps back looking looking backwards we can now claim that a little bit naive he was thought that just the ability to share more information and to consumer information was gonna be good for the firt for everybody well it turns out that it was very good but also he had problems it was not it was not all good there was and we see those problems very very clear we sit in politics we see it in we see it in market concentration we there are many problems with that so ranging from the CEO of alphabet the parent company of Google to the president of MIT to the European Commission to the White House everybody agrees that some policy guardrails should be there to ensure socially responsible AI number two and this is something that I think is consensus this is not this will not be just solved by by the guys that know computing and by that the scientists in the field this has got to be a very interdisciplinary conversation where an a very inclusive conversation when you hear you wear the voice and the thoughts of people from different backgrounds not just from different disciplines but also different cultures come together and define a policy this is not something that we just you can you cannot just go to the computer lab and say okay get me some AI policy this has got to be this has got to be a collective conversation and then number three and this is important because there there's already in the last three years a good number of AAA principles or declarations on principles for AI have been published it depends on who you consult but clearly there are at least 80 in our account you know in the project that I lead we are identified more than 80 and there's already a literature on the documents on principles so you can even read papers criticizing comparing since it I saying the one I recommend the most is comes from the Berkman Kling Center at Harvard Law they just published last month a very good a comprehensive review of these principles and all these doc not all these documents are the same but clearly consensus is emerging so I think that right now we can we're still working on principals has very very small marginal returns we need to go to the next phase so the key question is what comes next after principals I don't I'm not saying the principal's are not important I'm saying that we've got that we've got a little progress there need to make this the next step what is the problem with principals what principles are not off using economist parlance principals are a necessary condition but not a sufficient condition for for policy why is that because policy is about making hard choices by the way in uncertain conditions and some of these principles are you can create a tension between them so you want a I to be very you and your algorithms to be very accurate so that when an a a machine learning algorithm is predicting cancer in in an x-ray you want to be very accurate but you also wanted to be explainable and you want it to be fair without bias you want the information to be you want the information to be secured so there is no risk to privacy you want the jobs of the jobs of the radiology safe so there are no radiologists are gonna go away there are many objectives that might be conflicting with each other this is all about the trainers and policy maker policy making I'm not I'm not a scientist so I I talk to scientists now but I come from the world of policymaking and I can tell you policymaking in a t-score is about understanding the trade trade-offs and making tough decisions so what's next after establishing the principles to me the key question is about the trade-offs what are the trade-offs involved so let me before going into into some of the trade-offs and explain what I'm talking about we just say it's AI it's completely unfair and absolutely inaccurate to say that computer scientists don't care about the societal effects about the ethics of AI or the economic impact of AI that's completely wrong if our computer scientists have been working for a year and these issues and have developed some quite sophisticated tools about them a few examples for instance on privacy you have just a couple of examples differential privacy has been there for four years it's a notion that's been there in computer science you have edge computing and distributed learning including federal is it learning or split learning there are many other types of ways in handling the data in the algorithm training process to protect privacy on bias there's a whole literature unconstrained optimization imposing requirements like the quality of false negatives or things that would prevent certain groups from being discriminated against or there's a there's a whole literature on that the diversity of the training data so there's and unexplained ability there's a whole set of techniques for post hoc explanations things that analysis that are done after the training of an algorithm and there's also the methodologies for making the algorithms more more interpretable more explainable like transparent design and these are just examples and we can go on like this for robustness and for accountability there is there's I'm being very unfair by just putting in a slide what is really a literature of many many people working for years on these so I'm gonna show you what these tools look like so if you go to if you if today you go and talk to people who really know art if it is visual intelligence say I wanna I wanna I'm concerned about privacy or I'm concerned about fairness and bias what can you how can you help me they won't give you a box and say okay here's an algorithm that is unbiased or here's an algorithm that protects privacy what it will give you something that looks like this what are these these are Pareto frontiers these are combinations that are efficient for instance this one is from a thesis from one of recently graduated PhD student from Media Lab probably Mexican alejandro camp arrow and this shows a trade-off between the utility or the accuracy of AI of a machine learning algorithm and the degree of privacy protection so there's a trade-off if you want more power more utility in terms of accuracy you lose privacy and vice versa this one comes from a book a book I write I really recommend is called the ethical our algorithm from broth and currents to researchers from UPenn just published last year and here they show a Pareto frontier between the unfairness of the algorithm and the accuracy of the algorithm as expressed by its error so you see here that making the algorithm more fair results in losing accuracy for some applications losing accuracy is not that much of a problem but for some applications its life with that or it's it's it's it's really an important decision that hinges on this so these are not these are not perhaps the things that people expect from the tools let me just give you an interpretation of of these what I'm seeing I say here is that technical tools won't give you straight answer but will give you a menu of options and many of options that are are efficient clearly let it just go back to here you don't want to you don't want to position yourself with a policy that gives you here that you are under the frontier so so the menu it will give you a menu it will give you a menu of options but will not do not offer policy decisions by themselves in other words these techniques answer a question with a better question and for a a policy is how we answer that question that we get back so we say give me an algorithm that is fair give me an algorithm that is explainable you'll get a sense of a trade-off and the key question to me on defining a policy is how do you set up a framework that will allow you to give a good question first of all and this comes back from a little bit of what I learned from Jim while studying economics you need to understand the nature of a trade-off and I'm using here two concepts transplanted from microeconomics one is the elasticity of a trade-off if what do I mean if you have a curve that is very vertical vertical a frontier then you know you can gain a lot of protection of safe privacy or gain a lot in in fairness without losing much in accuracy if your algorithm if the curve is flatter it means that the trade-off is real so a theoretical trade-off is not enough to present a problem the actual problems come from the slope of the curve so a policymaker that gets these kinds of answers the first question that should ask is what's the slope that's kind of a boring question it's an odd question it's an important question what's the slope of the trade-off if you really want to make to understand your options and the other one is the curvature is it is a convex frontier where you see diminishing returns if you see that you're clearly that the trade of points towards an optimal that is not going to be a current solution where you're gonna have to balance so if you have a curve that is full that is has a slope and it's curved you're gonna be most likely needing a compromise you're gonna need to to is not going to be very effective to be at extremes more important than that and this is a key concept that if I if I wanted you to take away something out of this conversation I would I would mention this one the key challenge is actually not pinpoint into the trait to the curves is to create an institutional design that would allow for democratic decision-making about the traders because and why why do i underscore the word democratic because technology is not just about technology and technologists it's it affects us all and we want to have a set up where we decide what is more important based on the opinion of society as a whole not just either the technocrats or that the scientists there's need to be a process of institutional design to get there mmm one more slide on the trade-offs the traders are not just about accuracy but about other things what about innovation what about international leadership a lot of people are concerned that imposing restrictions on machine learning or things like privacy fairness explaining ability will slow down innovation and if you slow down innovation you might lose leadership in the international arena actually you read that a lot if you don't know the general press you really are a lot and if you go to Washington I've done that the Capitol Hill and to the White House you'll hear this one and this is a very understudied question I haven't seen any paper showing what is the empirical relationship between these what is the theoretical relationship of this this is all based on this is this is this is all based on assumptions and quite frankly sometimes in emotions so let me let me just five final thoughts on regulation the man I'm gonna try to land these into more specific thoughts on regulation first of all regulation is better to build it from existing frameworks than from scratch that's it's important to assess existing frameworks for say consumer protection and build from there revising and trying to have a new law and new completely complete legal instrument about algorithms second most regulation makes more sense if it's sector specific so having just an AI act is probably gonna be not very useful you need to work through the sector's so it's it's better to look at healthcare it's better to look at consumer finance is better to to to look at mobility and transportation but some common rules of course might be beneficial it's very important to acknowledge that there are many questions that we don't know the answer for so this might not be the best time to be making hardcore commitments to certain types of regulation the use of temporal frameworks like salsa close closest sandboxes for regulatory experimentation preemption periods instead of just outright bans of technology this is relevant for instance for face recognition this make this makes sense actually some states in the US are being criticized for punting then or kicking the can that might not be such a bad idea today the state of New York is doing that the state of Vermont has actually a pretty good framework for studying the issues better before imposing regulation that is not a that is not necessarily a bad idea number pre market testing makes sense we do that for drugs clinical trials with that for cars why shouldn't we be pre market testing algorithms in rearm square it's used for meaningful decisions decisions that you have life-critical or legal or public resources are involved important decisions widen we establish market a pre market testing just as we do clinical trials for drugs it's a bit of a critique I'm gonna immerse people tick on the European model of excessive reliance and individual rights I think that it's not only about individual rights but it's also about empowering the individual through technology and establishing restrictions on the on the behavior of corporations accountability is not just a challenge but it's actually a policy tool and well define accountability helps a lot towards addressing many of these challenges so define accountability is actually a cross-sectional it's a cross-sectional activity and then the last two slides beware of regulatory fragmentation what this means i if you look at Europe may be controversial but I think it's they are doing something which is remarkable which is they're going through a very cohesive consisting process of establishing regulation some privacy and now they're moving into actual algorithm decision-making algorithmic decision-making they just made announcements today about that if you look at China China has a single policy very clear national policy the the priorities might not be the same as in Europe or the US but they do have a consistent policy what about the u.s. the u.s. does not have a well-established certainly not legislation there are some drafts in Congress in Capitol Hill but it's the states that are making steps towards establishing regulation so regulation in the u.s. can emerge to be quite fragmented so California is running away with regulation and other states are moving in different directions how do the states will look like like that so is this a problem for Facebook is this a problem for Google I don't think so they lawyer up they have enough resources to navigate through these complexity but what about startups what about students from MIT or from Cornell or or Stanford that are trying to start something and will have to go through at the extreme 50 types of legislation to deal with privacy and fairness and explain ability this is not the right approach I'm concerned that the u.s. is moving in this direction and my final slide I think I think we are having a huge problem with trust and Trust is probably the most important problem we have to defining a policy and I'm going to show you two dimensions of lack of trust one here on the on the vertical axis is trust of technology companies I think that's pretty low today I and it wasn't like that just a few years ago Google was an admired company people wanted to work at Facebook Amazon was cool today there are companies there are very field and certainly there's not a lot of trust towards them on these other axes the horizontal axis I have geopolitical trust trust between home between leading countries how's the relationship has a trust between the two leading countries where are the US and China it's pretty low so if these prevails we'll end up defining policy in this place we can call it the corner of fear this is where emotions of lack of trust and fear so we will have policies that are dominated by imposing restrictions on the use of technology restricting the companies but also restricting the flow of knowledge the cooperation between nations and you see that a lot already and if you ask me this is where we are converging very very rapidly I'm not saying that we should be here this is probably very naive there are reasons to have trust issues both in these axis and this axis companies have tech companies have given us many reasons not to trust him completely and certainly the geopolitical dimension is also true but we probably should be somewhere around here right now we are here to meet a key challenge on AI policy is how we will how we build the frameworks how do we build institutions and collective decision-making mechanisms to move us from here to here thank you very much [Applause] okay so can people in the back see us well seated okay good so what I'd like to do is just chat a little bit for five minutes and then turn to this for Asia's audience who have questions I'm sure that they wish to pose it's also frankly the most diverse audience I've seen at MIT with a mixture of CCL geeks Center for International Studies policy wonks and more than one or two nerds so this is going to be a great group so Louise in sloan school students as well yep those are the ones that are better dressed so Louise I want to push you a little bit on specifics you said on the one hand that we need to avoid fragmentation but you also took note of the need for sectors specific approaches noting that the problems will be somewhat varied if you go from medical to consumer protection for consumer goods to finance and let me ask if there is a tension between those two in that the sector's specificity may require regulations that are quite different when you move from one area to another fragmentation which you would define largely with the reference to geography but it could also be fragmentation with reference to a degree of incoherence across sectors so the question that I like to pose is on both actually in terms of sectors specificity could you give us the sector that you think poses the most difficult problems in terms of the trade-offs across utilization of the data and the methods and protection of privacy and equity and the second question I'll have is really on fragmentation and its effects but first on sector specificity what sector do you think poses the most acute difficult trade-offs I'm gonna leave my answer to the US okay because this question if you're presented internationally is a broader question but in the u.s. some of the key sectors that are in play for AI influence very rapidly healthcare finance already have federal regulation consumer protection these federal so this is certainly something that is doable by the way it's interesting to take note on how federal legislation on finance emerged it wasn't originally that I decide in its federally Federalist nature the u.s. in the 19th century and early 20th century had a very fragmented financial regulation that didn't go very well so the u.s. didn't have a central bank eventually the federal reserved emerged and in the in the in the first part of the 20th century the the federal Congress at some point preempted States from doing more financial regulation and and eventually the the regulation that we have in finance is federal so I think that the plataforms and you have that for consumer protection more broadly and and and and also if you think about the FDA the F is for federal so you already have even institutions and you think about antitrust policy and you have the FTC the F is for federal so I think that this might be a little bit in the opposite way as your question go in sectoral favors having national wider approaches because the institutions are already there what I'm more concerned is with states coming up with generic AI types of regulation and we sing that in privacy California already has its own CCPA which is inspired but not the same as the gdpr of Europe and that's that cuts across every sector and we are seeing draft legislation on algorithmic decision making overuse of algorithms to make decisions or predictions in the in the whole of the economy that's the kind of fragmentation that can be a layer that comes from from from below it can be very very problematic and very hard for for for smaller companies and innovators to navigate so I appreciate the point on small companies having difficulty having the staff to understand 50 regulations that might bear on privacy and consent and data utilization understood but one of the defenses of a federal approach of a fragmented and federal approach is that in an area characterized by significant uncertainty complexity and controversy there can be benefits having experimentation having different models being pursued in different areas to learn and see which works best or worst and I think that that has been historically the case and you see that in transportation the regulation of cars safety standards for cars in many many years it was local it was not it was not federal and these dates other regulation including speed limits are obviously local so there's yeah there's there's there's a learning process I'm a little bit concerned about two things first the u.s. is not operating in isolation a lot of things are happening in the world and you see Europe pushing towards regulation that has various territorial consequences and very influential I didn't have China that is moving ahead with a different framework so yeah I understand the value of experimentation and learning by diversity but I'm not sure that at this particular historical moment the US has the luxury of time to experiment it that's in that in in in that way I'm I think that that fragmentation can be costly in that that's so within a u.s. context you could have a federal government that would be pre-empting local experimentation or state experimentation internationally that becomes much more problematic to what extent do you believe that experimentation national differences which some would argue reflect legitimate differences in culture in values the trade-offs that you're talking about different countries may value privacy or versus utility in different ways to what extent are we likely to be facing world of increasing diversity in terms of the policies governing AI and if so what are the implications of that diversity I think that diversity is inevitable and and to some to some degree very much desirable and it reflects values and culture and history and that is that that is important but what we should be more concerned about this incompatibility I'm adversarial models I think that's that that's the big question international thing so so I was talking the other day with the Shang Wang who happens to be my neighbor my office neighbor at Sloan and he was telling me the concept of privacy didn't exist in China as such and the word privacy didn't exist in China 20 years ago this is something where I was brought in by this debate that we're seeing worldwide and the user and and the emergence of this technology so yeah it's natural that beyond the political differences and and which are a conversation on its own yeah culture we play will play a role but I think what is more concerning is to have frameworks that are clearly incompatible we're and we have conflicting values in in countries that either separate and we become a world of technological silos or a world of technological conflict I think that I think that that here's here there's a lot of room for diplomacy in this in this context and I'm very happy that we're doing this as part of the CIS because of that there's a there's a I think that that regulation again with a sectoral approach is something that should be part of a conversation in either a global platform like the UN or in bilateral negotiations like the us-china talks or even in like-minded frameworks like the OECD should so I'll ask a couple more questions noting that we'll be turning to the floor in just a couple minutes okay but we looking very broadly at development north-south poor countries rich countries and a technology which is diffusing very rapidly with significant effects on the organization of economic activity and political activity and medical activity to what extent and this is a none fairly broad question wanna preface it as such but to what extent do you think AI will have the effect of providing for opportunities for equalization limiting inequalities more rapid diffusion of useful information or to what extent are we really talking about technologies which will be owned and captured and controlled by the relatively wealthy and the largest countries and companies contributing to further a concentration of economic and political power net effects or is this too broad a question to be worthy of answering no it's a it's it's a it's definitely an extremely broad question but it's not an unfair question and I I can see both effects playing out and and policy and countries individually and collectively through diplomatic means should be focusing on both possibilities I see tremendous opportunities for Equalization on on services and the delivery of public goods the question of AI in culture is very different in Boston Massachusetts than in Bolivia or in Ghana where there is here it's a question of quality may be costs who pays for it how do we ensure that it's it's it's good Diagnostics in other countries it's a question of access it's not whether this is better than the existing doctor there are no doctors there are no specialist in many places around the world so technology can can bring healthcare to places where it is not also this happens in education it can happen it can have a profound effect in agriculture productivity in energy efficiency so there's the the let's not forget that AI is or the type of AI that is blooming right now has a lot of potential for good things and those things should be encouraged and enabled but also we are seeing it already as in previous waves of technological innovation that there there's there's a trend towards job displacement and concentration of wealth towards capital and the owners of and the owners of capital now I'm not trying to be marxist here but it's a it's a phenomenal it's not a new phenomenon we've seen that in the nineteen it seemed that in the early 20th century and we're seeing it again now and the key question is how are we going to respond to societies in the 20th century only after two very very costly Wars and a huge recession institutions were changed and there was there were situations that were balancing across across people and across groups right now it seems that we're moving in the in the opposite direction so I think it's a it's a very real policy question someone asked one last question noting that Michelle should probably get ready for harvesting questions on the floor as well to move from that very broad question to a very specific one if we take a cell phone which better not go off at this moment and we look to AI data and let's call it multiplying the effectiveness of medicine so some folks are working on a variety of very interesting cell phone applications using data that would take underserved populations be they in southern Texas or in the developing world and providing the kind of concierge medical advice that people get at MIT medical but don't necessarily get elsewhere meaning that the AI is being used in conjunction with measures personal measures and records to offer advice and check on whether people are adhering to treatment but also gathering information which feeds back in so that would be a beneficial use of the AI serving underutilized population of populations that are underserved on the other hand those very same applications are also gathering data which are potentially being sold to all kinds of folks doing research good or our pharmaceutical companies that are seeking advertising maybe not so good and the issues of privacy and consent that we were talking about would bear on the beneficial and adverse uses of that information then you turn to governments and surveillance and that very same data in the hands of governments could be used again for good or evil it could be used for good we look at the wuhan situation now and the Chinese government is using prescription orders in medical records to try to track people for purposes of containing the epidemic but it also could obviously be used for political control in ways that would be adverse I choose this one example of a 175 dollar cellphone and The Associated information because even embodied in that one example is so much of what you were talking about and my head spins because I don't even know how to answer the question with reference to that one example and we're talking about a technology with implications that go far beyond and the question very simply put is not so much to answer that question on the cell phone and the medical data but how could MIT people engage more effectively with the very difficult values issues that are raised how could we work to improve the terms of the trade-offs how should we or what duties do we as technologists have to address these issues what responsibilities and duties do we have I think those are like six questions it's unfair so I'll let me let me start with the phone and using the phone as a delivery technology for health diagnostics and treatment well first of all it's a phenomenal opportunity and in many places around the world including my home country Mexico this is extremely appealing and you're already seeing successful cases of say detection of retinopathy the IVC s associated with the diabetes that is being detected with through the cellphone a picture taken with cell phone and and you see that already and those patients are then referred to the proprietary and that that is creating a much better care of Fortuna tea for people so that that is there but I think that going back to the u.s. context and this would apply when we talk about medicine we should think of the in the same way that we think of any other technology or drugs that these don't go unregulated there's a reason why there are prescription drugs and there over-the-counter drugs again that algorithmic tools for delivery of medicine should also be regulated as such and there are some things that a patient should not be deciding just because the phone said it and there's a very powerful algorithm that everybody says works and then because of that I'm gonna take this treatment you need to go to the doctor and that that kind of algorithms that kind of promises should be regulated just as prescription drugs on the other question of information I think that we are going to see more and more technology enabling privacy coexisting with this type of delivery of systems a lot of the opportunities particularly using mobile phones a lot of the distributed learning process we we help to protect the data of pay of patients or individuals you have in your phone so and again if you are the FDA you should all it might be a good guideline to only approve for public use those technologies that have these privacy protections to tools like distributed learning and not centralized learning the difference is that that in distributed learning the out there's the the training data from your phone will never go to a central server or as or a set of servers and can be exploited it will remain on your phone and all these other things we go so so there is there is this problem I think that the larger question it's not about it's not about the technology it's not even about companies it's about government and democratic institutions and that's where I think we that we should be more concerned about and because this technology creates risks for a eroding democracy by excessive surveillance and manipulation and also enabling dictatorship and unfortunate we're seeing that around the world and we are seeing some of the technology that exports not just algorithms but social control Lise thank you we will turn to the floor for questions and I'll cover this side Michel will cover the other side and if you could hold up here your hands and we'll try to get to you all right could you stand and please identify yourself my name is Bill Weinstein I'm an MIT alum you talked about the need for the policymakers and the technologists to develop an understanding in order to develop policy well then you also pointed out that one would like to have a democratic consensus about how this moves so now you've got everybody out there yeah who are not well versed in any of the technologies and on top of that they are burdened by a plethora of cognitive biases which completely distort their ability to understand the meaning of what's going on how do you reckon with that well I I think that's I firmly believe in in the Democratic control of technology I don't think that that that that we should live in a world where technology goes rogue but I don't believe in the opposite which will be technology control through referendum or that's because and and you see an example and I'm going to be a little critical of California here if you see the CC the origin of the CCPA this is a very complex piece of legislation that didn't go through the standard congressional process of hearings and drafting and consultation of constituency's this is a guy lots of merit who drafted a draft to the bill gathered signatures and suddenly the California Senate realized that it was it was going to pass probably with 85% of the vote according to the polls so they immediately grabbed it and adopted in a day that's not necessarily what we should aim so this is I think I find this distinction I think the key question for policymaking is how do you create democratic institutions for the appropriate policies to emerge and this is not the I I don't think that this should go unchecked and that just because this is complex the people that don't know linear algebra should be out of the conversation I don't think that but you cannot do it by referendum particularly in the context of polarization and this information that we live in through in very much fuelled by this technology or enabled by this test technology this this this I think this this has to go through the the workings of representative democracy that has delivered one of the most successful political models in history that is existing democracies both in North America and in Europe ok next question and again we ask you to give your name your social security number birth date your first pet and your high school mascot so I was trying to link some of the themes and what you're talking about it seems to me that your point about the differential impacts for big tech versus startups of a patchwork of policy is really important and that policymaking needs to take into account the sort of knock-on effects of locking in too early or locking in at the wrong scale right so you have a policy that's different from California and Oregon or it's prematurely precluding or enabling certain choices so what are the new policy tools that factor in you know these increasing returns to scale the path dependence using business models as well looking at how this plays out visa V business gaining power or changing its role in society given different policy options so the traditional policy methods might benefit from simulation modeling kind of what-if here's what happens if we do this quickly here's what happens if we wait and see here's what happens if we do this temporarily it seems like this like a meta another layer of complexity on thinking of policy formulation I did a little study a few years ago with an MIT student where model malaria policy and the naive solution which is to invest in both prevention and treatment was the worst policy right it was better to go all in one or the other rather than some kind of middle ground and it made me realize how complex policymaking is when you look in this way that's a great question Ontario thank you for being here the well I certainly don't think that fragmentation is is a good idea but I also mentioned in the presentation that I strongly believe in temporal experimentation and temporal regulation as a way to learn I mention the state of Vermont I mentioned the state of New York we had at the last semester we we had one of the members of the legislation in New York that drafted they're going through a study process so I think that first of all there's got to be awareness in this in legislators and policymakers and there's got to be an understanding of what it is and to me the greatest concern is jumping too early I'm locking in establishing path dependence as you very well describe much better than actually but I I think that's the reason why tours like having preemption so there's I understand why people are very concerned about face recognition particularly in the used by police and and government but I don't think that it's there it's it's it is it's probably the the optimal solution to ban it forever and to impose a but but perhaps a moratorium or it's as much is much better until we understand better and that technology evolves and is mature enough and you go through an FDA type of process through that regulatory sandboxes pros and cons there's there's I in Mexico I led the FinTech law and we we went through the process of calibrating whatever you Latorre sandbox is is not easy but it allows you to learn there's a lot of learning to be here before committing to hard towards towards something I think the worst case scenario is where you commit too early and have fragmented commitments and unfortunately that is not a necessary oh can be discarded right now hi my name is Daniela I'm a freshman here part of csail thank you so much for your talk my question is when it comes to mitigating bias and manipulation through AI do you think that there is systemic institutional issues I want you to solve in governments such as inequality or corruption from corporations first before we can entrust these governments with creating responsible regulation for AI thank you thank you for being here I'm thinking for the questions though sorry you mentioned two two topics that are quite important but analytically they're not exactly the same manipulation and and bias and both are really really bad and things that we should be concerned about and any country should have policies about about those I think that that the problem of of bias in algorithms has been a little bit of a discovery and it was not obvious in the beginning that that was going to be the case probably if econometricians had been consulted about the problems in dealing with datasets and bias introduced by the de datasets that problem would have been identified earlier it's the same problem that you deal with identification in econometrics a lot of that looks looks looks the same but I think that the discipline was not prepared for that and something you find some truly horror stories on on that I think that the understanding of the problem is much better now and there's no one single fix for this there's no magic bullet I think that having more diverse teams both in the policy-making and in the algorithm design and training helps actually helps and this is not just soft policy because it raises awareness but that is not enough and and I think that the quality of data and the representatives of the data is a is is is a key I think that relying on fixes on constrained optimization it's always going to be problematic because you lose accuracy you lose power so the true fix is actually on on the data and the true tension therefore the two that true that your trade-off is with privacy so there's the trade-off between privacy and and biases is real and I think that's something that we don't talk that we don't talk enough is that intentional are there companies or governments that are intentionally creating bias maybe but I don't think that's the that's the general that's the general rule when inflation is a very different thing I think that manipulation almost by definition is intentional and a lot of people have discovered that these tools allow for a computer system to know a person even better than the person herself and that that that is a problem because when you you can spread very targeted information and and and abuse cognitive biases then you have an opportunity to truly manipulate markets and the political the political system to me that's that's that's the that's the key and I think that in order to be constructive and I just being gloomy here I think technologies have an opportunity in developing tools towards empowering the individual in detecting manipulation in manipulative intent and making raising awareness when a technology is trying to exploit a particular reason for for cognitive bias and we don't see that enough there are some examples some from MIT both at csail the Media Lab but we need a lot more a lot more of that and at the end of the day we need Democratic control of government which is the very essence of democracy okay let me try to work my way across here and also you know give the the make and model of your first car hi I'm Giovanni do you think Facebook should be broken up I I don't I don't I don't know what anybody who posted say yes or no I think it's lying it's not clear because there is not enough there's not enough historical experience or evidence about whether just breaking up a flat platform would that be the solution because maybe you have you break up the platform and the behavior remains the same we don't know that the problem here the things that we see as say evil might not be only attributable to economies of scale which would be the argument for breakup I think that that we need more harder thinking on that by the way Europe today established that that they are going to impose regulation on requiring Facebook and Google and Amazon to share the data just as banks - and or other industries like like the auto industry do this is this just happened five hours ago literally so and that's very different from breaking up the companies and this was more there was a commission of his tiger it was the antitrust person in Europe so not necessarily a breakup is necessary you need to look more carefully at the the true economics of the platform and what it's creating these imbalance of power and address that not just this is not the Standard Oil necessarily okay hi my name is Adam Nagy I'm at the Berkman Kline Center and one of the co-authors of the principal's report the humans thank you if that's a great report and I'm actually joined here by another co-author in LA it's right here as well thank you to both of you so my question is somewhat self-serving Lee related not to that report but to I noticed when you talked about the translators the that one of the groups that was missing was academics they weren't up there and we're in an academic institution you know the report was created an academic setting and I'm curious how in your experience as a policymaker you interacted with academics and what academics can do to get reports like ours or like the MIT report that you cited in front of policymakers and what are kind of the the challenges to that and and maybe tying that into the AI space as well well I I didn't put academics there because I don't think that they there's a lot of that interaction I don't see a lot of interaction between policymakers and academia the way that other translators do your report is an exception and a novel is a very impactful report it's a it's recommended reading for everybody but I don't see a lot of that in my experience I remember I because of my MIT background for some tough questions when I was finance minister back in 2014 we were seriously thinking about vanishing in Mexico digital currencies that cryptocurrencies in particular we were talking about Bitcoin and I came to MIT and as a result of that we were convinced that we shouldn't that I was not the appropriate course of action but that that was very very ad hoc because I had friends here and I came from a place like this but I think that it's not general the general nor my a I think that I started saying that academia and policymakers are far far away you guys are quite an exception I think that's that's very real hello my name is Alonso I'm a senior studying mathematics yes you talked about trust you talked about trust in tech companies you talked about trust between countries I think it's also worthwhile to talk about trust from you know citizens towards their governments and then trust in the academic institutions that we are charging with studying these questions of democracy and AI and ethics in AI and you kind of sit in the middle of those two as you know Finance Minister and foreign minister Mexico as Erika Pena Nieto's campaign coordinator and then as you know you're all in the state of Mexico and then also now here at MIT and so I just wanted to you know address what I feel is like a little bit of a an elephant in the room because I mean Mexico the political process in Mexico has always been been marred by serious issues and Rica Pena Nieto's president Enrique Pena Nieto's campaign is no exception whether we're talking about you know the scandals with Ellie what are we talking about oh they breached and Pemex and emilio soya who was just last week arrested and your particular role in in those scandals were talking about the embezzlement of money from the finance ministry towards the police preparatory or campaigns whether are talking about monix and the prepaid cards since Ariana so you know it I just thought that it would be worthwhile to address that in the context of your discourse on trust and democracy because I just thought it was a big sort of elephant in the room and especially you know as a Mexican national thank you well I acknowledge and I respect your your your opinions and your concerns I said it this is this is not a talk about Mexico I'm very happy to talk to you anytime you want my office is my door is always open and we can we can discuss I can tell you that I I stand by my track record and my actions I obviously as a policy maker I I did good things I've made mistakes live and I learned a lot but I stand by my actions and I'm very happy to talk to you any time you want to my door is open and we can we can talk about Mexico or any other thing that you want to okay I'm gonna recommend that we harvest a few questions short questions we can turn to you for an answer because we're running close to the end of the time thank you so I just have a quick question related to our report from the britman Science Center um so what we did was identifying AI principles that already exists but what we also found was that there were very little principals for example we couldn't find one single document from the African context and so I'm wondering from your perspective from Mexico do you think that existing principals are going to be relevant in this these countries that haven't developed an in-principle so far or will they be different and how do you see the development in Mexico or in Latin America more generally and then how do you see developments at the UN levels that there are thoughts about developing global principles of AI do you think it's going to be similar principles that are already discussed or is it different if we include all these regions that haven't yet developed anything on this issue I think it's a big concern the fact that that some regions have been mostly unaware and therefore disengaged from this this conversation I think that principals most of them are general principles that apply everywhere but there are some more more regional concerns or or Haddock concerns that should be should be addressed on I'm not sure how impactful these documents particularly from developing countries are going to be in actual policies I think that's a big question I I haven't seen much of that say in Latin America we may be the exception is Chile where we do see a little bit of a buildup of a policy but other than that I think these documents are scattered and not very not very impactful and I think that that's I also noted that in your report the lack of an african document not I mean you couldn't find one african document and that's and that's a that's a real concern particularly as African countries and African governments are embracing this technology some of it comes from China and are using it in different ways good and bad so I think that's a concern okay why don't we gather one question two questions three questions and then you can answer all or as little as you wish Louise over there okay I guess that's me I'm Tim right out I'm a Cambridge resident my mom sent MIT PhD so I learned from how to think from this world and that's actually relates to my kinetic I know right I'm not I'm not good at the math but I think in terms of sort of mathematical way of thinking about political science but actually that's my sort of my question and comes to tobias and then when AI is used in real time just the way it changes language even inadvertently and measuring political philosophies so just quick back story you know my mom was in 70s and 80s they were talking about you at the old mainframe she would carry her punch cards over to the mainframes here at MIT and you know run her regressions and whatnot and you know the way they they did it was you know they they tried to measure a political philosophy on degrees from liberal to conservative and that was the sort of the framework they went with and then that got compiled over years and you know I've read the books they read Anthony towns theory of democracy he drew a little bell curve and I was carrying these things around on my brain for years in Washington and it took me a long time to realize that it's empirically wrong and and I've been conditioned to think this way because that's what I've read and at least in the American polity we've got progressives liberals conservatives libertarians and these are different humans with different political philosophies I guess the point is first of all please say I should not be used to measure a political philosophy but also how do we as this is used in real time and to condition people to think and you think of psychographic profiling that you know the obvious case is what the Russians did to our country how do we and it's an open question I don't know the answer but how do we prevent people's to enable free thought and free expression and you know intellectual freedom so we're not sort of conditioned to think in very narrow worldview okay and we'll get a couple other quick questions in here hi my name is John I'm a grad student here my question is about the geopolitics politics of AI which address a little bit here in the United States we've seen that Google has refused to work with the DoD on their projects due to ethical concerns but in the meantime in there are other countries where there's a much closer military and research connection do you see that as a risk to global security order and how should the United States address that and get okay and that that'll be the last question of the day an easy one and I think yeah afterwards if people are interested please come up front on the particular geometry just couple of weeks ago we were Ken and I were working working with this group of senior military officials US officials and there was a talk on Russia by a fantastic scholar from Harvard Alex I don't thing you can you can it's all Chatham House rule yeah yeah that's right an anonymous senior scholar from Harvard but but an anonymous senior scholar yeah but the the point is they didn't apparently they didn't target a particular ideology or a particular label liberals progressives did you target everybody and try to infuse extremes I think that the the the regions of democracies in diversity of ideas I think the problem is polarization and going to extreme and the lack of ability to communicate with others and that's a problem that these platforms can can can create but it doesn't have to be this way it's the way we've been using technology so so I didn't think this is a liberal problem or a conservative problem no this is this is a few willing polarization to maximize engagement and profits that's that's a different problem or for geopolitical purposes as with the Russian case as with the military just just one one note that case about Google is ace has been single out but was once one episode and Google continues to have a lot of contracts with the DoD and other military the agencies so that obviously created a lot of news but it didn't change there a lot of the relationship I think it did help to put some restraint in the kind of things that were done it raised the awareness of the of the problem but I think it'll be completely inaccurate to describe us industry including the tech platforms as this engage with the US military that is not happening okay and all that remains is for us to express our thanks to luis videgaray for his oh thank you all thank you thank you 