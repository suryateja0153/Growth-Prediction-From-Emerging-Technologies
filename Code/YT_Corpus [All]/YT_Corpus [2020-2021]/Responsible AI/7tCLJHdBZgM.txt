 [Music] hi i'm adina hi i'm chin and today we'll be talking about spatial analysis and metrics advisor for the first part of this session we are going to focus on spatial analysis a new feature of the computer vision service and i'll be talking about metrics advisor a new cognitive service for matrix monitoring and root cause analysis great let's get started with special analysis which enables you to draw ai insights from the real world computer vision is an azure cognitive service which runs vision ai on images spatial analysis is a new feature of the computer vision service and it runs vision ai on live and recorded streams to understand people's movement in physical space spatial analysis ships at the edge as a docker container and it is optimal for data control privacy and network intensive workloads thus spatial analysis brings to you the power of the intelligent edge and it enables you to build powerful business applications at scale in the azure cloud let's look at the three scenarios in which we can use spatial analysis people counting social distancing and entry exit of spaces let's talk about people counting you can count people in a designated area you can monitor an alert for maximum occupancy and you can collect historical data to make decisions for how to optimize the occupancy of physical spaces this is a demo video that shows how special analysis can detect and understand people's movement in a store in this case the ai insights generated by the container it's a periodic people count in this case we have six people in the camera field of view notice that even when the people are partially occluded the ai model accuracy is not impacted the occluded people are still counted for people counting let me show you the configuration that you need to create and the structure of the ai inside json that will be emitted by the container first you need to configure the polygon in the camera field of view in which you are counting people you can configure the polygon to be the entire frame give the polygon friendly name in this case we call it storefront camera and indicate the frequency at which you need the events the field threshold indicates the ai confidence at which the events are emitted any events with confidence less than the threshold are going to be suppressed to the right we have a sample json for the ai insight events emitted by the container the type of event is person count event notice that we provide the friendly name of the polygon the same way you set it in the configuration in this case store front camera and we provide the person count in this case three for each person we also provide the rectangle of where in the frame the person has been detected it is not fully shown here the second use case is something that is top of mind these days that is social distancing with special analysis you can set a minimum required distance between people and you can warn of failure to maintain distance by saving these ai insights you can create historic reports and determine trends in pandemic compliance this is the same video footage for the store in this case instead of people counting we are running the social distancing operation notice that with a single camera you may run multiple operations simultaneously for the purpose of these demos we did run people counting and social distancing on the same video field let's look at the configuration for social distancing in this case you can still configure a polygon in which we apply the operation and additionally you provide the minimum and maximum distance threshold in feed in our sample we set the minimum to 6 feet to the right the ai inside json sample indicates the event type in this case person distance event the event name which is too close and the distance violation person count in this case two in other words two people are closer to each other than the minimum distance threshold of 6 feet the total count of people detected is also provided the third use case is about people entering and exiting physical spaces you can monitor entryways for traffic and maintain optimal occupancy you can detect when people enter a reverse zone or cross a line and you can calculate the time people spend in an area for dwell time and loitering in this demo video you can see how you can determine the wait time at the checkout queue we draw a polygon around the checkout stand and as people enter the polygon we start the timer and then stop the timer when the person exits the polygon by looking at the timestamps of the events we determine the time spent by a person at the checkout counter let's look at the configuration for the entry exit operations for the person crossing in and out of a polygon you have to configure the polygon give it a name in this case lobby camera and you have to configure the type of event you require in this case is zone crossing the edges of the polygon are numbered in the order you list the vertices that enables us to provide information about the number of the side of the polygon which is being crossed by a person to the right notice the sample for the ai inside json which indicates in this case that the person has exited the polygon and the side of the polygon that they crossed in this case this is the third side additionally we have the person crossing a directional line operation instead of a polygon you configure a line or more and the container is going to emit events when a person crosses a line to the right notice the status field in the json sample which is cross right that indicates that the person crossed the line from left to the right or in other words from west to east again the line is directional and this is best used for cameras located at doorways where you can determine when a person lives or enters through the doors now that we have explored the use cases let's see how customers are using spatial analysis we are partnering with nec technologies india to integrate special analysis into nec's video analytics platform to enable pandemic compliance back to work scenarios nec's video analytics platform is enabling customers to quickly adapt to the changing kovin-19 landscape allowing their customers to ensure social distancing and follow occupancy guidelines throughout their facilities in the reader industry retailers need to better understand how customers move to the store and how to modify the store layout they want to measure how much time people spend in line or in front of a retail display or if the store layout helps people maintain social distance with special analysis you can build your own solution for the retail industry to improve customer satisfaction protect safety and health and increase revenue special analysis effectively scales for business applications and it is also available to dynamics connected stores that's offering in manufacturing plants need to monitor zones where people's present is not recommended due to safety concerns with special analysis ai running on video from cameras can detect people in forbidden zones in real time both safety personnel as well as the employees involved can be notified on the potential danger by alerting features safety personnel can monitor incidents happening over time by storing the ai insights and building meaningful reports now let's look at how you can deploy the spatial analysis container first you need an edge device with nvidia t4 gpu we have tested special analysis on azure stack edge with two gpu units and you can order an azure stackage device from the azure portal to deploy on your own premises you may use another edge device as long as it has at least an nvidia t4 gpu you can deploy spatial analysis with azure iot hub you need to create an instance of iot hub service and register the edge device then with the deployment manifest you may deploy the spatial analysis container as an iot module for the camera devices you need to install this in your physical space following the manufacturer's instructions and since these cameras are ip connected you need to make sure the edge device can connect to these cameras over the rtsp protocol once the spatial analysis container is configured with the camera's rtsp url the ai insights about people's movement will be sent to azure iit hub as telemetry from iot hub you may create various routes to other azure services and build your own business solution let's see this in action with a demo this is a demo that illustrates how you can deploy the container for spatial analysis first you need to go to aka.mscsgate to fill in the application for gated services this is where you provide information about your company your use case and your subscription id microsoft will review your application and upon approval you will be notified in email with information for how to access the container the next step is to create a computer vision resource on azure portal using the subscription you provided in the application for gated services you fill in your subscription information select the s1 tier and click create this public preview the usage of this resource is free and there we go the resource is created at this point we copy the api key and building endpoint values we will need this later on when we have to configure the container deployment next on the azure portal we have an azure iot hub service that we already deployed and an edge device in this case an azure stack edge which we already configured and connected to deploy the spatial analysis container on the edge device we recommend using a deployment manifest file here is an example here in vs code we can see a sample of a deployment manifest json you can see the path to the container image in this case pointing to the microsoft container registry where the spatial analysis container is published we have here the create options for the container as well as the environment variables notice here at the very bottom the bidding endpoint and the api key where you need to copy the values from the computer vision resource created a bit earlier down below we have the person count configuration for a single camera notice the operation id is set to spatial analysis person count you need to fill in the video source url with the ip address for your camera you need to select on which gpu you are running this operation and you need to provide the zone configuration for the polygon as well as the desired confidence level a sample deployment manifest is available for you to download at docs.microsoft.com look for the computer vision documentation page in the deployment manifest we saw the polygon field which represents the area in which we count people to select the relative coordinates of the vertices of the polygon we follow the camera manufacturer instructions to collect a frame and in this case we are using our old friend paint to draw the polygon then we calculate the relative coordinates of the vertices by taking the absolute x y values and dividing this to the horizontal and vertical sides of the frame back to vs code we are ready to deploy the container notice the left pane where we connect it to the iot hub and the edge device we select the deployment manifest there we go and we will deploy success now let's look at the modules and we can see the spatial analysis container is up and running before we see people count in action let's look at the ai inside json events which are passed as telemetry to the iot hub we are going to start monitoring the building event endpoint and we are seeing the events passing through let's search for person count and there we go here we have the json event for person count event but the person count is eight okay the container is deployed and it is processing the video here we have a sample web application that shows the count of people in real time you can see on the bottom left the video is being processed with the rectangles around detected people and the depiction of the polygon representing the zone on top left is the video recording that you might choose to collect running in azure media player the video is available in your own azure blob storage instance microsoft doesn't collect or use your videos for ai training purposes this sample application is available for you to download and further modify visit the computer vision documentation page for details at aka.ms spatial analysis we hope this demo will help you and inspire you to build your own business applications thank you by now we've learned that spatial analysis includes ai models that detect and track people's movement responsible use of ai is a top priority for microsoft microsoft is releasing spatial analysis together with responsible ai recommendations grounded in user and societal research microsoft used many of his responsible innovation techniques to develop and test these features to ensure the technology maximizes personal privacy provides transparency and promotes trust microsoft developed responsible ai recommendations in collaboration with private preview customers to guide the use of special analysis for covet 19 public health and safety scenarios in accordance with microsoft responsible ai principles fairness reliability and safety privacy and security inclusiveness transparency and human accountability microsoft's principal approach enables developers to build rich solutions while upholding human dignity and the needs of everyone impacted by the technology visit us online to learn more about responsible ai thank you and back to you tune thanks sadina now let's dive into magic's advisor first of all i'm excited to announce the preview of matrix advisor an ai analytics service that proactively monitors metrics and diagnosis issues imagine you run a global business that has factories producing rockets and toys of course and you sell them on your own e-commerce website the health of the business lies in the financial metrics as well as kpis such as user activity indicators of the website your iet operations team that manages the website could benefit from warning ahead of id system failures and root causing during service outages the production lines could become more stable when failures are warned about ahead of time with specifics about which precise part is about to fail driven by data the common challenge across those three business scenarios is really how you can monitor the matrix data the time series matrix advisor a new platform as a service provides you an out of the box intelligent matrix monitoring platform it simplifies the monitoring lifecycle with a built-in web-based workspace where you can set up a time series monitoring alerting and diagnostics with simple user interface a rich set of rest apis and sdk libraries support developers to build your custom solutions easily because magix advisor has built an end-to-end monitoring pipeline time to value is accelerated and the pipeline starts with abundant database connectors and pre-processing of your time series data by cleaning aggregating and filling in gaps for a consistent time series flow built on cognitive services anomaly detector the core engine four time series anomaly detection matrix advisor locates each data set and automatically selects the best algorithm from the model pool for high accuracy incidents trigger alerts through emails webhooks and azure devops with dimension 3 and matrix graph matrix advisor quickly shows you the key drivers of the problem a matrix advisor is intelligent scalable and can be implemented in a simple manner so just how applicable is matrix advisor customers such as nash already experiencing the power of magic supervisor and the benefits it brings to their business nash portugal's biggest communications and entertainment group is running poc with metrics advisor the evaluation shows that matrix advisor is able to monitor and escalate potential failures on customers internet devices in time so that automation steps could be triggered to avoid true failures nash is testing the use of metrics advisor to live telemetry data to reduce customer course and to improve customer satisfaction let's look at another industry example flowey floyd is the first digital bank completely built on azure flowy is using matrix advisor to monitor their ios and android apps to protect their end user experience and ensure it runs seamlessly with matrix advisor anomalies are being detected and diagnosed quickly the flowy idea ops team saves time that can be spent on more crucial items thanks to the precise alerting and root cause analysis provided by matrix advisor finally a customer with predictive maintenance scenario is also running poc with matrix advisor renault dp world f1 team has brought their first use case of analyzing data from wind tunnel sensors the initial use case has shown promising results issues like noise flare line and inconsistency in signals are detected the alerting enables engineers to focus on fixing the issues rather than monitoring data on the screen so now that we've looked at some prominent industry use cases let's dive into a matrix advisor demo meet sam who manages the iit department of your toy rocket company sam's team owns the infrastructure of the e-commerce website thousands of vms and container instances enable hundreds of application components to support the traffic from global consumers tons of telemetries are captured and streaming a tremendous skill into a time series database on the other front as a data driven company your business critical metrics such as revenue daily active users are captured daily and stored in a relational database the challenge for sam is if something goes wrong with an application component and leads to du drop can the team be notified in time can they quickly pinpoint the unhealthy component previously sam's team has tried hard thresholds with all those metrics but eventually gave up as it ends up in alarm fatigue now sam is using matrix advisor to address the challenge [Music] like all azure services sam first goes to azure to create a matrix advisor resource [Music] then he goes to the portal of matrix advisor from there he selects his instance of matrix advisor web-based workspace and jumps into it [Music] now sam's going to on board the time sales data for both the business matrix and the iot telemetries for business metrics daily active user set the correct source type granularity and start time as well as the connection information and the query then set the right schema and a few additional configurations before submitting the data feed note that the channel column and the region column are set as dimensions as that could enable the platform to monitor the dau from all different region channel combinations and diagnose easily when there is an issue an aggregation rule is also specified so that magical visor will roll up the two dimensions automatically and monitor the dau from aggregated channels and regions for it matrix sam has created a different data feed that connects to an influx db and this time the dimension becomes different types such that all types of telemetries are monitored under the same data feed and such telemetry data doesn't grow up using some anymore as they don't add to each other next is to tune the models to ensure they detect anomalies as expected the knowledge of what values of the parameters are working with the data come from the proof of concept stage before this during that stage sam's team has run some validation with two small but representative data sets and got the best parameter value that works with the sample data sets for the best trade-off between precision and recall they apply those two sets of configurations to the production data and are ready to further fine-tune the parameters in case the production data results deviate from the poc results [Music] with that sam could set the alerting on instance which enables email alerts for both business data anomalies as well as i.t data anomalies [Music] and here comes my favorite part in order to best root cause issues sam could build a simple matrix graph to describe the dependencies between the system components and more interestingly between the system components and the business matrix what he did was to simply depict the dependencies between different time series based on his knowledge of the system architecture and his knowledge of what really contributes directly to the business matrix for example the eu is dependent on latency of the front door web app which is dependent on the database throughput which is dependent on this io and the cpu now it's all set let's give it a go and see what it can do on august the 11th the business manager joe received an alert that deu has dropped [Music] joe checked the incident diagnosed 3 and found that the overall deu job was mainly in the region of usa sam looked into the incident and found that when the du went wrong the latency of the frontal web app also gets anomalous showing as red in this cross matrix analysis graph and further following the dependency chain has led to the db throughput but not the disk io or cpu a sam's team was then quite sure that the root cause lied in the database part so they spent an hour or so checking the code updates related to the database before august 11th and quickly found a regression in database query that has caused the issue in less than 90 minutes with matrix advisor sam's team managed to fix the issue which would otherwise have taken them an entire day to root cause in the meanwhile joe was able to send a service downgrade notice to their north america customers on the website enclosed with a service recovery note joe was super grateful for sam's quick turnaround and actually sam went above and beyond what joe knew with matrix advisor sam also receives other alerts from the infrastructure data sam's team had taken preventive actions to those infrastructural incidents before they make serious impact to business now this is definitely making joe's life much easier magic's advisor also gives sam's team actionable alerts such that they are not swamped with force alarms and all that turns into the stability of the i.t system and the growth of the toy rocket business today sam is looking to customize the platform to connect deeply with their other tools luckily matrix advisor has brought with its web ui a rich set of rest apis microsoft is also soon to roll out sdk libraries for four languages java javascript dot net and python that can make coding with the service much easier today more than 300 teams are using matrix advisor inside microsoft i'm excited to bring it to you join the preview of this service at ak dot mess metrics advisor and learn more about special analysis submit your use case and review the responsible ai guidance thank you thank you 