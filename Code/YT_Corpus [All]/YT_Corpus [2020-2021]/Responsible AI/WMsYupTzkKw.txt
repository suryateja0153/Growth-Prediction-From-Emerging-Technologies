 [Music] hey everybody this is Chris madman and I'm not able to attend physically the tensorflow dev summit so I'm giving my talk remotely my talk is about tensorflow and machine learning from the trenches I'm the deputy CTO at the NASA Jet Propulsion Laboratory and I'm going to talk about our experience using tensorflow in the innovation experience center at JPL what's JPL JPL is a federally funded research and development center it's NASA's only FFRDC they call these the national labs its goal is to do first-of-a-kind missions and autonomy technology development for space in situ on-the-ground remote sensing of the earth and various other really nationally critically functions it's nestled there in the beautiful mountains of locking out of Flintridge we have about 6,000 employees about a 2.6 billion dollar business base we have a pretty large facility about 167 acres at JPL I am the lead for the innovation Experience Center I'm the deputy chief technology and innovation officer and what does our innovation experience and our look like our receipe for it is to find the most difficult space the space that looks the ugliest and make it our own take it gut it have the actual engineers and data scientists put it together and put it back together in the way that they want sit-stand desks basically follow the Sun shun shades IOT Internet devices that both Frost and unfrosted srem for smart glass and privacy and so on and so forth so that's our team we're working in all of these areas and we're really excited to be doing machine learning with tensorflow in particular we're excited in a few different areas our organization is responsible for using tensorflow in the following ways the first is that M 2020 Rover that you just see right there it's now named perseverance in that Rover in that cleanroom we measure particulates in the air to determine if that we're adding any sort of bio contamination because we don't want to do that when we send this to another planet if we discover life we actually want to do that so we have small commodity IOT Internet of Things since that are measuring particulates increasing our ability to do that increasing the density of the measurements that we have and we're doing predictions using tensor flow and machine learning to determine the next measurements the next contaminations if we had them and intervening if necessary in the bottom right you see our people counter that's another IOT device it uses tensor flow and object detection and facial recognition and so forth to basically count people's heads as they go in and out of our tents at events like RIT Expo and so forth so that we can tell people when the right times to actually attend these events so that they're not overcrowded besides that we're not just doing institutional things with tensor flow we're looking beyond that today our Mars rovers are currently running on what's called the rad 750 processor that's a radiation hardened PowerPC 750 750 like processor that's basically the amount of power that we had on an iPhone one tomorrow we'll have the ability to have a high-performance Space Flight competing and the ability to use things like snapdragons from Qualcomm so real GPU like a deep learning chips so that we could do actual computing on board and if we could do a high-performance space like competing on board we could do really cool things like make the Rovers intelligent make our Rover smart do things like drive by science which you see there highlighted in the right as one of our three ongoing tasks and initiatives to use and leverage high-performance space flight computing can we make Rovers smarter absolutely we can in particular we can take models like terrain classifiers which we've built with tensorflow we call it Spock there's a theme here at Star Trek our train classifier Spock is a CNN it's a convolutional neural network using tensor flow to do terrain classification ripples smooth smooth with rocks to figure out where the rover should drive and where it shouldn't we test this in our Arroyo Seco which is right by JPL using our test Athena Rover another tensorflow based model that we've been using and leveraging is the Google show-and-tell model for that which is a combination of a convolutional neural network and El STM or recurrent neural network long short-term memory to basically do labeling figure out the labels for a particular image for the rover and then take the labels and actually learn a sentence description for it so that scientists can review them and so that the rover when it's on Mars can instead of sending back 200 images a day to plan what to do the next day can send back millions of image captions that are scientifically validated and to increase our density of observation we in terms of our terrain classifier just some examples of that Spock looks at the geometric features and so forth and it's actually capable of recognizing terrain types from images so this is really important both from our surface operations but also to potentially plan where we should do feature Mars missions and landings beyond that one of the things we've been really challenged with and it's been a big area of research for us is putting tensorflow models and taking them and porting them to tensorflow light and moving them on to exotic hardware some of which isn't even physically here and we only have emulators for like the high-performance spaceflight computing emulator that we've been trying to look at various tensor flow models like deep lab mobile net be - and then figuring out how do we port them into a tensor flow like quantized model or tensor flow light floating point model and measuring the computation time from that one of our key observations here is that mobile net be two tests were conducted on smaller imagery and actually mobile net v2 tests performed the fastest of any of the models that we were actually testing when we use tensor flow light in a quantized fashion for that so we've got ongoing research and we're working on porting these models into these TF light environments in particular if we have drive-by science if our Rovers are smarter and you look on the right we don't want to miss that unnoticed Green Monster problem where the rover simply doesn't have enough power to be able to an in light time and bandwidth it it misses recognizing something that actually we really wanted to see like our little buddy right there in green and one of the challenges with that is that the Rover has an eight minute light time from round-trip from Earth to Mars to basically send it a communication and to hear back from it so it's got to do a lot of science and things on board it's got to recognize things even without human intervention additionally our geologists they've got a headache with too many images and so forth so having the ability to have the rover be smart do drive-by science on board and just send back again those textual captions and descriptions of images is really key because then it can get beyond only being able to send 200 images per day and could actually send millions of captions in particular all the work that we're doing on tensorflow in the book I've been collecting it I've been capturing it and I'm writing a second version of the machine learning with tensorflow book it's called machine learning with tensorflow second edition it's currently in the Manning early access program or meet MEAP please check out the link right there and I would love for you to you know basically ask me any questions there's an online developer forum for it please let me know and be happy to get back to you and you know what I'm not there physically but you can find me online at Twitter Chris madman at Chris madman and thank you for giving me the opportunity to present today [Music] 