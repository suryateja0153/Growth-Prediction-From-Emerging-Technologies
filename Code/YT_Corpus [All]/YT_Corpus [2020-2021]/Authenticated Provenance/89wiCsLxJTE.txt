 okay so um thanks for the intro so I'm going to just spend a few minutes telling you a little bit about where I think we are in AI and maybe what still needs to be done and you know how exciting the future might look so first of all you know what is what is machine learning one of the kinds of things it's good for so many of you processor familiar with this but I think it needs sort of restating from my opinion at least what really machine learning is about right so a lot of people see machine learning is say generic large-scale data analysis but I personally don't have that viewpoint I think that's a kind of a misrepresentation of what machine learning is the mean machine learning is about replicating human abilities for example in image processing speech etc so this is a kind of classical problem you might face you know given an image like this the face is this face male or female right so maybe that's something that we apply good as humans but it's maybe hard to define a compact set of rules which you would explain this right it's not easy to to write that down so the idea in machine learning is that a human will label these images for us into male or female and then we try to replicate that human labeling by the Machine right so that's a kind of like a statistical approach which has a large set of training data and then tries to replicate the humans labeling all right so in that sense it's really reproducing a human ability so one of the sort of dominant approaches right now to this is this deep learning and this actually started a long time ago and this general approach is called connectionism so already in the 1930s and 40s people were interested in this idea and actually when the first computers came into being these were some of the first things fin AI that actually were implemented on the original computers back in the 1950s and even earlier actually so the first tend to make this was actually called the perceptron in 1960 which could only solve er a simple visual tasks like recognizing certain kinds of simple shapes but that she wasn't particularly successful and there was a lot of drop in interest in a lot of cutting in the funding particularly the 1970s and this was actually the start of the circle a I went to the first AI winter and I think really what was interesting for us is that this paradigm of trying to solve these AI challenges replicating human abilities based upon machines which operate a little bit like humans do actually never really died it also it's kind of like being bubbling under the surface and then when the 80s came along with the PCs this actually made it much easier for people to get access to these kinds of compute power that you need to try these kind of technologies so they are dearest's you have some kind of you know inputs and they get propagated through some network and these weights of this network are all adjustable in some way to try to solve the test that you have a hand so for example is it a male face or is a female face so we've kind of you know sort of developed on this kind of model over the years and we've improved it significantly but we've also taken advantage of the huge improvements in compute and data power that we have right now so that's made a huge difference really so right now we can do all kinds of crazy things we can have videos like this and in real time we can we can track the limbs of the person we see where they are in real time that's something that we couldn't do even a couple of years ago at least not in real time it's really incredible but there are other things that we can't do which are quite as impressive right so for example if I were to give you this paragraph or text here at the top and ask you some questions like why did Graham power answer the door then as humans we are pretty good at this why we could read through this text as long as we're alert enough and we'll hopefully get the right answer one of those a B C or D questions but if you ask the Machine to do this it's not particularly good at it it's actually pretty bad but answering these questions it's only around maybe 50% accurate right so why is that why is this why is the Machine so poor at this kind of challenge well the reason is when the machine reads this you know has no deep understanding of what this what this paragraph is about what are these words mean it doesn't really know they're just symbols right there you're not really relatable in some way to each other there's a very shallow superficial understanding of this sentence of what these paragraph is trying to say so typically what people do is they do something like they take why did Grampa round the door or they try to scan it raster it across this paragraph desperately hoping to find some kind of similarity between the question and some part of the paragraph and then dig into that bit that looks most salmon or desperately try to find one those four answers which might be most similar within that part so essentially it's quite remarkable actually the computer guess anywhere at all you know sort of without knowing anything about it any understanding your grandpa doors etc knows no clue it's somehow guess about 50 percent accurate right so random is 25% cuz were four questions here so it's better than random but he's not particularly good so in some sense you know the challenge here for AI is not really about you know doing say processing like in videos that's cool and right that's really nice it's very exciting it's very good but the grand challenge of AI is getting access or the Machine getting access to the kinds of information that we humans have we know what doors are we know what grandpa's are we know all this kind of stuff you know the way the physical world works right this is something the machine doesn't have access to at all and if you want machines to actually really interface with us in much more natural ways they need access to that kind of information in some way either internally within the machine or somehow it needs to be queryable by some external database without that we are never really going to get much further along this this AI path so another example of this is translation so this paragraph on the left in English I used Google Translate to translate that into Chinese the opinions written here then we translate that back from opinion back into English so for some languages like English to French it's kind of okay you know the original English paragraph and it's retranslation look quite similar the meaning is preserved but here actually if you were to read this you recognize that actually quite a lot is lost right and again you know why why is that well the machine is not looking at this paragraph of text oftentimes people peel bananas from the stand and he has no clue it's not sort of thinking about this others you know there's a monkey it's peeling a banana it's doing all this kind of stuff what's going on no clue it's a totally superficial almost word by word translation which is just rearranged into the grammatically most likely structure so it's completely devoid of any understanding at all so again it's quite remarkable actually that machines do so well in translation at all without actually having any deeper sense of what's going on so that's okay in some sense you know if you're needing a superficial translation that's okay but as we go further in AI that's not enough that's not the end goal of AI we want machines which can deeply comprehend and deeply understand what's going on okay so this is interesting example in in China Microsoft had this chat board which you know had some interesting properties serving of this journalist here uploads a picture of his swollen ankle and chatbot says something like you know kiss it better or something like that right so this is the Chinese are very sort of happy to interact with these kinds of things the average number interactions is around 25 so people in China are really interacting with this chat board as if it was some kind of real person who's very successful so Microsoft then was buoyed by this enthusiastic and they released this into into the West and this was they're thinking of you a bit of a disaster where they have a similar chat board but they'd learned from interacting with humans right so the through Twitter the way that we would people would respond to the machine the machine would learn from those responses and pretty quickly you know within hours of course we cynics in the West it's like well you know let's break it right let's let's take this machine you know see how quickly we can break it so this is in some sense not necessarily criticism of Microsoft chat BOTS and natural language processing abilities but it's more criticism of the way that we in the West think about these technologies you know we're very skeptical about them we're very critical very cynical about them whereas in Asia people tend to be much receptive to these kinds of technologists so that's also something is very important to bear in mind when you're thinking about the eventual application and usage of these technology and society that's a critical thing to understand and recognize why in in Asia in my opinion things are likely to race ahead at a much faster pace than here in the West another interesting thing that we've seen a lot of excitement burden recently is things like playing games visual games like Atari games all right so space invaders you the machine just sees a sequence of the previous four video frames can you predict the next move to make which the machine should take to to win the game or to play the game well so this would be some kind of deep neural network the images gets represented here at the input layer the weights of network or just stirred until you can learn some kind of decent sequence of actions to to play the game well right so that's that's kind of cool and actually in some sense you know it's kind of interesting but is it really that interesting so in my opinion it's not that interesting because it's a whole suite of games here which this kind of Atari games and it's kind of interesting the human level performance is here and some of the machine can play much much better than the human can it's miles better than human but actually there are other areas where the machine is much worse than the human so games example like Montezuma's Revenge the machine is much much worse than the human why is that because Muslims revenge you have to go around and pick up objects like keys go down corridors eventually do something long a long sequence of actions and eventually put this key in some door or some box and unlock it right and the probability that you would actually take that long sequence of very specific actions just by randomly exploring actions to take is basically zero it never never works right so games like space invaders are easy you can just take random actions and yeah he wouldn't amount of time you'll hit something feedback relatively quickly but in these kinds of other games it's it's delayed it's massively to later you have no chance of random exploring just to find any decent result humans don't play games like that we know what keys are we know they're useful things we pick them up we know what doors are we know the relationship between these things that's why we as humans can solve this that's another example as to why we cannot progress in AI unless and until we actually include those kinds of piece of information into the machine or get happy access okay so just finally I think you know another interesting area which has come up more prominently in the last few years it's things like explain ability and adversarial machine learning so interesting example here is have a stop sign so we're very good at making speech sorry image recognition systems which can recognize say images like the stop sign but these nefarious researchers here have put these little stickers love and hate there and actually completely fools the machine has gone from a very high accuracy of recognizing the stop sign to relatively low accuracy so this is this is because we you know we didn't think about this right again you know the West will put the cynical bunch I would try to break the machine so in some ways it's kind of good but we do need to bring these considerations into the way we train the system so that's important another example is in things like ethical issues like insurance since the early 2011 and onwards it's been illegal to use gender to determine car insurance premiums but actually there were other kinds of issues too that you notice if I know that gender but I know this say you have a certain salary and you drive a Pinkberry W etc etcetera cetera I can infer perhaps your gender implicitly right so the the legal stages of this is not completely clear at the moment but it's not long in my opinion before we will see court cases where people are going to complain that actually they were in some sense discriminated against by some algorithm even though it was implicit the discrimination and not explicit and that's something that I think we all will need to also take into consideration very soon ok so yeah this has become you know much kind of important thing in the last few years and something there's a big moving right now to make fairness and transparency much more part of our so they I think I just want to summarize by saying that I think the NASA to spy is is that there's a huge potential here in Europe but I think we need more leadership we need more focus on the genuine core challenges of AI and that is about getting the information the human serve into the machine I think we need to be much smarter about the way that we do this we need much better regulations we need much better understanding of the constraints of regulations on progress that's very important but I think generally Europe and here particularly in a places like London oh we have a great opportunity for changing this to pay what I think the way the research funding is happening needs to change a little bit we need to go away from very small-scale research funding at the university level to much grander challenges but I think overall the future is very bright but I think until we solve those integration of AI information the humans have access to into the machine we're not going to make sufficient progress thank you for setting the scene so well and our next speaker is Ryan from kindy Ryan has a background in applied maths and then was a quant on Wall Street for eight years he started kindy out of Business School in 2014 I'm really looking forward to hearing his presentation okay Jesus all right good morning I'm a little jet-lagged been up since about 1:00 a.m. this morning two days ago so my name is Ryan Welsh I'm the founder and CEO of kindy were a venture backed AI company in Silicon Valley and I believe that for AI to thrive it must be explainable that's super awkward right you want me to explain to you why it needs to be explainable or isn't that weird I mean if I was a neural network I just walked offstage which means the number one reason is usability every time we interact with customers the number one thing that they want is some level of explanation what's unique about humans is our desire and our ability to ask why and the reason we give reasons is so we can judge people's belief systems and actions and the same thing with a computer so it's going to make a recommendation about taking some action I believe that it needs to provide an explanation to a user so that they can then take that action the next reason is accountability and David was just just touching on this is whether it's implicit or explicit I believe we're going to start to see these these court cases where people will be held accountable for their actions specifically when we start using AI in more impactful use cases for human beings which arrives at this little framework that I've come up with I've seen this with with our customers and how to think about explain ability and whether or not it's actually needed and what level of explained ability is needed because there's varying levels of explained ability and how people in CIOs from organizations are kind of thinking about this is what is the impact of the decision to a human being and what is the time to human confirmation and just some examples here so let's take classifying cat pictures so I have the best cat in the world and I take so many pictures of that cat and if a deep learning system were to classify a picture into the wrong folder you know who cares right and for me to determine whether or not that system actually classified it into the wrong folder it's pretty quick you just look at the picture right now you may say the impact of a decision or the impact for screening x-rays is significantly higher so you need explain ability well maybe maybe not because what's interesting about x-rays is if a system identifies a broken bone the doctor can hold it up to the light very quickly and see confirm the decisions the the system's decision so in some instances where it may be regulatory or something like that you may need explain ability but in some instances you may not now where we work at kindy and where we use all of our use cases are are out here in synthesizing military intelligence reports working with Pharma customers working with financial services all over unstructured text data so a very high impact of a decision and because it's text data it takes an incredibly long time to read and understand ultimately confirm the systems decision which leads to a really interesting finding that that we found this is by and large there's always tail cases for all this stuff but explain ability we found is most necessary on decisions that have a high impact to third parties and a long time to confirmation it actually comes from text data and when you think about it pictures worth a thousand words it takes the average person four minutes to read a thousand words it takes the top 1% of readers to read a thousand words so if I were to confirm a systems decision I would actually have to wait for minutes as opposed to holding up to the light and taking maybe four seconds so it's a really interesting framework and of course you know you there are exceptions you may have autonomous vehicles and other things out here that are image analysis or video analysis but we've seen by and large this kind of be the the way that CIOs think about it throughout the enterprise and what's what's interesting about explain ability and we positioned as explainable AI when we launched the company in in June 2014 when not many people were thinking about it but explainable AI has just been bombarded with a bunch of different definitions from from vendors you have some vendors out on the market talking about training data quality management as explainable AI so they will ensure that the training data that you use for a system is not biased thus we have an explainable AI system you'll see systems where you'll use a deep learning network to analyze another deep learning network and find the nodes of influence in and out of layers and ideally you can map that back to some input data we're seeing that position that's explainable ai we're seeing transparency being positioned as explainable ai where I know what developer used what model with what parameters on what training data and put it into production on what data and at what time that's explainable we're seeing visualizations things like provenance which is ultimately footnotes to to it to a natural language generation system then you have your classic proof and causal methods and then we're seeing some natural language explanations all of this being bundled into explainable ai and it's actually been been quite confusing out on the market and you need varying levels of these things for the different two-by-two that I just showed so Atkin D as I was I was sharing we help enterprises get value out of their unstructured text data so we work with government agencies we work with Pharma customers and we work with financial services and it's all about helping them get value out of their unstructured text data and for us explain ability came down to fusing together really three types actually the two main I call them two main paradigms of AI it's machine learning with the knowledge representation and reasoning or the symbolic approaches and the benefits that we got out of this was the explained ability then we also got data efficiency and better generalization and I'll get into how exactly we we did this and this is the technical bits for some of its technical people in the room so effectively what we're able to do with this is a proprietary system that we have is we identify objects in raw data and we're actually able to machine learn the relationships between those objects so that our learned Network actually takes advantage of the full expressive power of logic so we're essentially machine learning what we call a proto ontology from from data we then used that data model in a graph engine in this graph engine fuses together your symbolic approaches with your vector based continuous math approaches and we're able to get some scalability benefits from this engine which if people worked with graphs scaling graphs is can be quite quite challenging so when we think about explain ability at at kindy and here's just a simple query of a document that we uploaded from from UC berkeley research project ideally we get to a place where the system can provide its reasoning in natural language to the average user but today what our customers wanted to see was insights into the graph that we use to bring back certain queries so here's a very simple this is just one one word so the graph wasn't wasn't too large but you saw that the the top result that was brought back talked about a generator didn't talk about electricity so here you're able to see the nodes of influence that brought back that query and those nodes in our network are terms so you can see that the generator is an electrical generator as opposed to a random number generator or a password generator which would not have been what you wanted to come back so you're able to see what are the terms or what is the space that the system is looking at when it's ultimately reasoning over this this graph structure then you're also able to dig down into the sentence and this was the the provenance that I talked about and what we found with our summers is not only do they want some level of insight into your learned the network but they also want to be able to drill down into the underlying data to ensure that it was of quality so this document you're able to see that it was a UC Berkeley report it wasn't generated on the internet by some right-wing or left-wing American political site but you're able to have some confidence that this underlying data is quality to you so these are a few ways that we are working explain ability into the system and we found that users really enjoy being able to work with this system when they can look into what it's doing and why it's ultimately doing it so just to just to summarize real real quick I think explain ability is absolutely critical for AI to thrive if we want to see the benefits of AI throughout society I think explain ability is is critical and I think the path to explain ability is actually the combination of symbolic approaches and machine learning approaches and that's what we're doing here at kindy so thank you very much Thank You Ryan so when I'm looking forward to getting into this question of symbolic versus connectionist when we get into the panel session afterwards but next up speakers your own Wang he got his PhD in computer science from UCL in 2009 and then he's been working with Baidu and Toshiba he set up trio dai a I with two co-founders in 2016 and I think it's fair to say that this is this is a really exciting example of deep learning in the wild so looking forward to hearing from Museum thanks for the introduction my name is jor-el mom from trio I trio is a start-up in China and we provide the constitutional AI solutions for different industries so today my talk is more from the application point of view but I'll give you overview how comes you know or conversational AI works and how it can be applied to you know different scenarios okay so conversational III I mean in general means we are building virtual agents that can talk with you using natural language and when we you talk about that we are actually talking about a spike of different technologies such as speech recognition speech synthesis natural language processing and a lot of machine learning problems behind them and it can be used in like for you know consumer electronics smart devices or you know for industry or for enterprise use like constant automation which I'll talk about in details later and you know other industries like computer games for example so I mean due to the sorry due to the latest breakthroughs in speech speech technologies and natural language processing the constructional agents are more and more useful nowadays that they are actually assisting our daily lives here and there and but I mean natural language processing is still an unsolved problem in general there's no Universal solutions for natural language processing and the models has how to be build you know you know domain-specific or problem specific away so that's why there's no Universal agent like in the science and fuses fiction movies that can do everything for you so the chatbox has to be built I mean skill by skill and for work Oh demands and so on so let's let's let's start from a word kudamon like for for enterprise solutions for example call center automation which is a very typical application scenarios for conversational AI the idea is we want to build a work for agent that can answer telephone calls from your customers to replace the human reference and fields and the same technology can also be reshaped to you know to use to analyze the telephone calls by by human operators and users to like for conferences or for you know business logic optimization and so on okay so to what extent that technology helps I'll give you an example this is a this is a provincial call center of China Mobile who use our chat boards to answer their telephone calls so now they their service covers over 70 sorry 17 cities in that province and the chat bot is answering 10 million calls every month and I mean here's a figure that now 30% of the telephone calls are answered by our chat bot and there's another 40% of the cell phone calls I actually build we deal with by the traditional touchpad touchpad base hi we are is there only 30 percent of the calls are answered by human nowadays and the estimated this has Commission rate so it's over 90% and the you know overall user satisfaction rate is over 90% as well so that I mean it's it's exciting right you you see the figures shows that the chapel Oh Rory you know reduce the the labor costs in your call centers but that doesn't mean every call center should hire chaibat Oh you know do we need to invite through that technology to you know reduce your labor costs in cousin hers there also is some how deep and I mean there there are three conditions that you you you you gain from investing into this technology firstly you need to have a large call center you need to have a lot of people I mean labor costs the society or motivated to invite on the technology and the second Kaneesha is you should have a you know comprehensive infrastructures I suppose the Shabbat to complete the task otherwise your tripod come to the target has food transfer the call to human right and surely you need to have a while structured knowledge place or domain knowledge that enables the shadows to understand your users questions and so on so this these two conditions can be billed I mean there s engineering work anyway but you need have a strong motivation to actually utilize all these technologies to do so and this is a analysis based on based on Chinese industries actually you can see telecom carriers is actually the bicycle industry to apply this kind of chatbot because they have everything they have large concerts with sense of millings representatives and they have excellent infrastructures and knowledge and so on and for example garment is it's interesting right they have nothing but they have a strong motivation to build everything to upgrade everything from the ground but other industries it's kind of verbal and moderate for example banks and financial companies they have a really fuel is smaller cause interest is like thousands of representatives but there are infrastructure is its moderate it's not you know hundred percent ready for travel through to to every task and so on and this is a report cited from I research showing that the aih iPod itself has a reasonable market size but more importantly it's leveraging the downstream and upstream industry alone so you have a potentially very big market there enabled about by AI tribals okay let's look into the consumer electronic industry as well so these two figures are cited for from strategy analytics this year I think last year or this year okay so it's showing there's a fast growth of smart speaker markets in China nowadays like about half of the smart speakers are produced and sold in China a nice tablet is just nation I mean I mean your readers mass speakers are dominated by giant companies such as by those yummy and so on but there are a lot of potential opportunities for startups in China as well established cited mentioned this morning there's a subculture in China that people loves to talk to this kind of virtual agent and the social chat box is considered as a mask I will functionality for all smart devices my speakers can talk with you for example we collaborate with with Baidu and I do actually build integrate our social chat boards into their platform as a beauty in functionalities as you say anything that is irrelevant to the passive tasks specific domain so it's it will be deal divided by our social chat board and we also extend that service to you know the ACG industry anime comics and games industry and we we build like worship characters for computer games that can you know talk with you in a very expressive way and very human-like way we can also to some extent customize the language style to reflect the predefined the personality of such virtual characters and when we talk about consumer electronics we can't give smartphones which is the still the largest in terms of internet flow but what will assistant like Siri and so on it's been proven to be not a very popular product form so we actually event to another type of interaction on mobile devices this feature called smart heart is you wanted and you know promoted by us the idea is we precise tax a lot of our mobile phone everyday for example if you receive text message from your messenger and as a nice and you brought web pages and so on previously when you find some information within the taxes that interests you it's not very convenient to extract that out and to do first further search but now with this smart smart heart feature every piece of text message on your mobile screen can just long touch it to trigger our natural language understanding feature and we will automatically recognize the intent and they extract the semantics you form a semantic information from that text and we pop up this kind of information card you click on it you you will be you directly evoke a third-party service or information it's like a one-click operation to lead you to a third-party information or service that was also you know quit the Carnap so very quick video demo to show how this works this service has been integrated into 14 different brands of Android mobile phones in China and we got a lot of traffic every day right currently we support over 30 domains and over 100 the different services that back-end and please wait deployed its last year and now we receive a huge traffic every day which about like 80 million user races for Davis 20 about 20 million active daily actively users and this is the you know user activity analysis they're cowards different domains and different scenarios behind this we are doing a traffic monetization business model through for for certain domains we try to you know distribute the advertisement and the integrate service integration and so on to shared I mean core the traffic into revenue and share that revenue with mobile manufacturers okay in the end there cross industry players as well I mean for example folks come the big factory who were sample more well phones and for Apple for other you know mobile companies and so on they're actually launching a robot that can you know it's kind of in between for robot and the smart speaker with screens with touch sensors thread sensors cameras it's like a multi-modal interaction platform that is fueled by biased am i feel sorry the university does and we like build this product and imagine that the output capacity of Foxconn classes you know advanced the hardware and software design we can output this kind of robots either as a consumer electronic or all as a you know word co-domain robot for other businesses for example is now placed in the Imperial Palace in Beijing it's used like a guide for natural treasure finding the river sorry along the river in shipping is Festival so it's like a robot in the museum that gives you information about certain antique pendings and so on okay okay talking talking law does that constitutional is actually enabling many emerging markets and it's I mean for in the consumer electronics and also is the fast growing market in enterprise solutions and so on especially I mean in China there's many you know you know with you and unique features that the concessionary is enabling sands for irritations do stay here and take please and if Ryan and David would join us on stage we're going to have a short panel session now so um today we have we're trying to move the conversation from the cutting edge research that we talked about yesterday to more what does that cutting edge research enable in terms of applications we've got a short panel right now but there's a meatless speaker session after immediately afterwards so if you want to carry on the conversation then I'm just looking to see if I can see my colleague Tom over there Tommy over there we'll have a sign and please please join him to to continue talking let's let's start with an easy question and then we'll maybe delve into some of the more difficult aspects so given that we're talking about applications today can you give one example of something some research in the last five years that has enabled something really exciting impactful or surprising in terms of applications today and I'm gonna go to Ryan first sorry so there's research that's enabled me I've just been super excited about word vectors and vector embeddings for me we use them out we use them a lot so it's just been very can you give a quick little overview taking stuff from a high dimensional space to allow sure sure and then and then you get you get these words that have some semantics distance between them and you can see some similarities between those those words we then use those outputs of vector embeddings to build these ontological structures so we do apply some hierarchy to them but for me word vectors have been super interesting and been very helpful for us putting stuff into into production and kind of getting to the comprehension aspects of what they was talking about well I think there are some tools I think anything about machine learning you know that used to be really the kind of academic arena right you needed a PhD or a degree in mathematics to even starts playing around with this stuff and I think one of the really interesting things to happen is all of the tools that have been made available which really democratize access to these kinds of technologies so I think that you know the explosion that we see now in a with events like this it's not because of you know so the research breakthroughs which happen in academia but because of the ability for many many people including startups you know to get access to these technologies without that you know sort of like you know deep deep deep training that you may have previously needed so obviously the frameworks are available yeah so I mean for example you know automatic differentiation will be one but they're also open source frameworks but you know instead of applying machine learning as well and I think that's really you know really important as a story in the sense that these things are not necessarily new I think also in the same sense they're you know machine learning and some of the technologies using or not necessarily that new in some ways but the sort of the tools that you have that access those technologies are very important and I think you know they're a Polish they are really is this very it's very important so deep learning technologies like automatic differentiation will be around since the nineteen seventies HD but you know only recently if people started to use them and I think that's been key to thank you you're on would you like to yeah I'm thinking about the you know following day they would fall back to her now it's like you know the latest breakthrough in pre training models like were like who's that you can you know pressuring something you know in general with very big data and find you it in the Tasker specifically and that helps our Nokia loading that speaks again today this point and there's been a certain democratization okay so let's let's move on I wonder if you could comment on an impression I have so I work for digital catapult we're interested in encouraging the adoption of advanced machine learning methods but what we see in the real world often is that what works is symbolic methods or more established machine learning techniques do you have any comments on that putting something in production it's just the infrastructure that that an enterprise needs so we're starting to see the infrastructure startups get get traction first and I think that'll help putting models and put models into production by infrastructure sorry to interrupt you do you mean the kind of data management I mean all of that stuff that you need to to really put something in production I mean I mean Facebook Google all the big companies they built that themselves so you're seeing companies like my friends company algorithm-- you provide that infrastructure but but you're right a lot of the stuff that's that's in use today is you know you go back to whether it's semantics techniques I mean behind Cirie and Alexis there's these giant knowledge bases and and and things so yeah you use simpler machine learning techniques knowledge bases knowledge representation and reasoning but I think infrastructure is what's holding back kind of the more sophisticated deep learning techniques to be put into production at the enterprise anything else culture maybe there's some things that deep learning can't do well yeah explain ability it's another big one yeah that's that's that's the biggest one I mean I think was there's survey by by IBM showed that 88 percent of executives don't want to put people learning in a production if they can't explain its its its reasoning so it's it's really holding holding it back and yet Geron trio is largely using deep learning yeah they use deep learning a lot but it's raining and vanish in the you know real world it's always combination of small eek and people in you okay we were very specific example for concentration the quality of currency it's like a closely related to the business logic that you can learn actually directly from the data you how to use deep learning but also the beauty representations and build a very fundamental part and use the symbolic logics to combine them to actually output the product David would you like to comment a couple of things to say as a Minnesota there's certainly infrastructure is it is a challenge so if you think about say banking right so people basically tree emails like it's like electronic paper right you know basically a lot of industries are they founded on exchanging bits of paper right instead of grand-scale between themselves and the email is just an electronic version of that so the thing there were a lot of legacy issues there particularly with large-scale enterprises like banking insurance et cetera but becomes more difficult to apply these things not necessarily because of the technology per se but just getting the infrastructure really there is not to do that that's one of the things that I've I seen a lot I think another one of the challenges is just really you know getting people to sort of I think there's a perception in business that if you blinded AI systems they're like they're gonna come in and they're gonna solve everything for you right they're kind of like well just been you know excluding quit on this Watson thing or whatever it is and you know why isn't he doing what I want and there's a little bit of a sense of you know over expectations you can do but a sense of disappointment that they're not this sort of all-singing all-dancing thing and i think we need to shift the the focus away a little bit from there to actually that these tools are things that you can interface with and humans can actually help continually train these systems within organization so that's something I think that you know we're starting to see much more of but I think that's a perceptual shift that really is required for people to realize that these technologies are not necessarily what buyers all singing or dancing thing and it's gonna do everything for me but no it's a tool which will enable my company to perform more efficiently and get the most out of my my workforce but interacting naturally with the system thank you so let me flip the question a little bit then so deep learning may not always be maybe in the adoption phase and obviously shows great promise but there are other techniques that have seen less less investment less height that may be equally useful or may need some resourcing to make them useful is that is that true I'm looking at you David well you know I I'm a believer in what Ryan's or so you know talking about it I think symbolic stuff is very important you know that historically when the first day I Windsor came along whatever 1976 is you know basically people drop this connectionist idea right deep learning essentially was ditched in favor of things like symbolic reasoning and I don't think we're gonna see that dropping again but I do think that the symbiosis of these two is very important and if you think about our you know our world right we have different kinds of things a perceptual stuff right images and etc and speech and that's super useful we know we have that stuff in our phone and it's great but to go beyond that to have a system this wondrous machine that we can actually talk to and interact with much more meaningfully our culture our history everything our science is it's symbolically encoded in some way so it's super important that we we start to address those issues and I think that's it's challenging there are you know ways to think about that but I think that's something that you know we need to get much more serious about as a research community thank you I was hoping you know to say something about probabilistic reasoning actually I can tell you much more about it but because we are running out of time but I there was one question I do want to cover because it strikes me that this is quite a unique situation we have Chiron here who has built his business in Beijing Ryan's in Silicon Valley obviously David's based here in London and built businesses here and I'm interested to understand what are the different circumstances for trying to translate cutting-edge research from lab to live as it were and whether they differ in those three areas Ryan sure so I moved out to Silicon Valley from the East Coast in from New York City in 2014 and the one thing that struck me immediately was just the the ecosystem in Silicon Valley I mean people are willing to if you have an idea people are willing to code for months before they ask for anything in return as opposed on the East Coast if you come up with an idea they're like well here's a consulting agreement and I want this much equity and that's before you even start coding and I think I think that's one of the big things of the ecosystem are people are willing to take those risks people are willing to help each other in Silicon Valley it's unlike anything that I've that I've seen and there is that talent there that can help bring very advanced technologies to market I mean there's there's a bunch of great universities there and then it's it's the ecosystem is what makes Silicon Valley and yet China seems of letterheads developing you know very fast pace and so I mean I don't think the technology is you can you can you know keep for long because there are so many companies competing with you and all the algorithms they're like a treasures for the humankind and now everybody knows that but the if you to business I mean you need to go very vertical and in that industry and you build this is like industry barriers that you know you understand this industry for example we know the logics of business logics for call centers we have a lot of knowledge about that so that we compute products that fulfill the customer demands in that industry and understand yeah understanding that's you know something that people can't compete with you in a very short time they need to you know you might slot into that word codomain so thank you I think we're out of time do you have any closing comments a David I think the future is very bright I think you know we need to stay on the positive so I think you know in the if you think about a lot of the current concerns that people have about in society about machine learning and AI generally it's a little bit you know sort of people very worried about it I think we need to sort of this better than in mine but I think we need to you know we need to sort of focus on the positives and I think that's the best to shakes I think that's a great way to finish and I'm sorry that we whip through this session it was very short please do join our speakers in the halfway house afterwards I'm going to invite azim to stay to introduce to the next session but first of all please thank our speakers you 