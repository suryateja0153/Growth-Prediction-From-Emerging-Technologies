 the theme today is uh uh the intersection between the science of brain function uh and the engineering of machines how can we learn from brains to build better machines how can we capitalize on the exciting progress in machine learning to to better understand a brain brain function so um i think the order is going to be uh tommy and then josh and then jim uh with an initial introduction of about five minutes each uh and then we'll turn it over for for discussion between the three of them and also questions uh and comments from the audience tommy thanks gabriel so um this idea came up because cbmm was started as centered focused on the science and the engineering of intelligence that's something we came up um the original founder especially josh and me and and now it's uh seven years or so that have passed so it's kind of interesting i think to have a discussion about where we stand and just to set the rules of the game we're not trying to define science or engineering what i mean we mean with science and engineering this is just a definition of words so it's not very useful to to try to change that the definition we adopted is science as natural science so defined by the object of study so the object of study of science proper intelligence is human brain human intelligence maybe animal intelligence and the object of study of engineering are computing machines so these are just definitions correspond to the standard definition according to which for instance chemistry and physics and neuroscience are in the school of science and computer science is in the school of engineering it's just a definition of the object of study of the interest does not have anything to do with rigor or depth um we all agree that science and engineering are both equally important they must be rigorous they must be deep um you know depending on your taste or whether you you are on the party of aristotle is on the party of plateau you can according to this definition put mathematics in the school of science or the school of engineering so i don't buy um but both science and engineering need mathematics obviously and the rigor of modern science so um so that's something we should all agree the other thing that is important for cbm and is that i hope everybody at cbmm agrees is that we believe that if we want to understand human intelligence ultimately which means how our brain computes intelligence then we need to combine the science of the brain and the engineering of machines we need everything to to go forward and of course we need to do experiments on the brain human brain human behavior so the idea of this meeting was of this discussion was to go beyond this and address related questions which are much less clear than just the definition i gave you things like whether we need to understand human intelligence in order to build intelligent machines or maybe vice versa maybe we need to build first intelligent machines in order to understand human intelligence we don't know we can discuss about it back when we started cbmm with josh and others in 2012 we could at the time claim that neuroscience or visual cortex had led to models of visual visual recognition like neoconetron hmax and so on that were state of the art for computer vision they were a new inspiration for computer vision very different from the computer vision algorithms but in the meantime changes have things have changed and the pendulum i perhaps swung back now it seems that models that come from engineering are actually good models of the brain as it turns out and and so is is that going to continue this way with neuroscience just testing engineering models or that is uh we can expect another phase in which neuroscience will suggest to engineer a rather different type of models from the ones that are involved today so there are many such questions um i want just to stop here not to take too much time um hope people bring it many of this interesting question up um and the meantime i'll pass the microphone the screen to josh okay thanks um so yeah i'll also try to uh speak very quickly just to give other people most uh mostly what i like to hear is other people's perspectives here um tommy talked about the pendulum swinging back and forth between you know i guess two polls both of which are ones that i think we're all in cbm very interested and committed to and working on one is the idea that the science of intelligence how it arises in the mind and brain can inform engineering and can guide engineering of more human-like kinds of ai systems and the other is that the engineering tools that that are being developed can inform and guide our science you know um in the spirit that tommy has long worked with and worked out with david maher and that has inspired many of us we think in cbmm about reverse our science as reverse engineering we're trying to come to understandings of how the brain and the mind work in the same terms that engineers would use to build those systems so you know that's that tradition of bi-directional interchange between those fields is really i think what we're all about but it does seem to be that sometimes the most promising directions go one direction or the other direction as tommy said the perspective i guess i would just add which comes from my experience in my lab where we primarily work on the mind level on the cognitive science level although increasingly we are really interested in cbmm has really opened this up for me in a really significant way making contact with the brain level is that is that actually it seems that their the pendulum might be swinging at different in different directions at those different levels in a way that is really interesting and positive and synergistic right so as tommy referred to you know there's been a great progress i think jim will talk more about this his lab has been at the forefront of leading this in applying recent developments from uh from particular deep convolutional neural nets to understand the uh the ventral stream nancy's lab has been using these in all sorts of really interesting ways as well and and many others here um so that's that's a place where it seems like the engineering is in some ways kind of guiding the science now in terms of uh the neural study the neural basis of vision but on the cognitive level you know i find actually um in my lab these days most of what we seem to do is kind of cognitively guided ai honestly i i i wish there were more people in our lab who were really working on the cognitive science you know the study of human behavior and what it tells us about the mind where the action seems to be right now is using cognitive science to guide ai to make more human-like forms of ai right i i have many people whether coming coming to me coming to our lab whether they've been working in neural networks or robotics or computer vision or natural language processing and sort of asking us okay well what have you learned or what has your field learned about how computations underlie cognition that we can use to make neural networks or make ai smarter right because we know we've achieved a lot and yet we still you know mostly have systems that solve pattern recognition problems and use mechanisms of function approximation and there's something missing maybe something quite big missing and how can computational cognitive science guide that so i you know i i see us being in in different projects in our group we are both um using you know i'd say what's specifically focused on neurally based or neurally inspired engineering tools like neural networks we're both on the cognitive level using non-neural network ideas like ideas from probabilistic inference and symbolic representations and so on to try to guide and improve together with neural networks the ai side but then i'm also involved in projects looking at vision but also language um in the brain where we're using neural networks um you know today's best engineering tools um to try to understand how the brain works and i think that's really interesting that it has the promise in a sense you know like the the engineering reverse engineering process might be a little bit out of phase at the mind level at the brain level where it might be that you know if in neuroscience uh science has the most to gain from engineering but in cognitive science the science has a lot to contribute to engineering then by swinging back and forth at those two levels that might be a way that we can actually bridge the cognitive and neural levels because it still is the great i think outstanding question for us in our field is how does the mind work in the brain or how does the brain give rise to the mind and i think again um most if not all of us would agree that if we only work at the level of models framed in terms of words and intuitive concepts we're not going to be able to do that because the language and the intuitions and the classical vocabularies of cognitive science and neuroscience are too far apart but if we can translate our insights about cognition into engineering terms and we can translate engineering terms into real biological neuroscience insights then that can be a way to use the mathematics and the formal tools of engineering to make a bridge between the higher and lower levels of explanation or the you know the more at least mind and brain levels of explanation um i don't mean to imply any particular uh vertical ordering but if you guys know what i mean um uh to to link up those levels of analysis and and i think it may be our best shot for doing that i'll just point to one concrete research direction which maybe people might want to talk about later which is work that i've been very uh involved with in a very indirect or i don't know secondary capacity the main work is done in federenko's lab and by martin shrimp who's one of gym students but he's working on language models of language in the brain together with ev and nancy camwisher and me and a number of others and you know basically what martin has done together with ev is to show that to take a wide range of state-of-the-art artificial neural networks for language especially these transformer models like burt and gpt if people are familiar with this but these are the artificial neural networks that have been most responsible for transformative changes in natural language processing from the last year or two and test these together with earlier generations of neural networks as accounts of language processing from the word up to the sentence level in experiments that evan colleagues have done for a while and really shown great strides basically have come recently i won't go into the details of this work although if you're interested you could read martin's paper on bioarchive but have really shown that um you know that the that especially these transformer based models especially actually the gpt2 model which is the one from openai which has been i think getting the most attention especially in sort of natural language generation um these these models of predictive processing basically models that are trained to predict what word is going to come next given the previous context have uh are you know are really basically by far the best computational models of language processing as measured in either fmri or eco data and i think that's very exciting i think that it's by no means um you know uh uh a complete account of how language works in the brain but it kind of together with work that people like roger levy especially have done in earlier work from ted gibson here and many others not not just at mit um studying behaviorally showing that basically sentence processing can be and and online measures of sentence processing like in reading time can be really uh well predicted by predictive language models just like like engram models or probabilistic grammar models and now we have like the best predictive language models that have ever been built with these neural transformer based models the picture that emerges when you connect behavior computation and and the brain there is really exciting it suggests that a unifying paradigm coming coming into play like an account of language in the brain that might start to rival how we understand vision in the brain at the same time that picture also leaves out a huge amount which is basically um we know that um uh those models you know in some sense they predict language but they don't really understand language they don't explain how language grounds in perception they can't turn into an embodied agent and you know they they say a lot of i mean they do amazing things and yet it's very clear that they don't really have common sense or they make all sorts of errors i'm not going to go into those here so in in other work that we do we talk to people in natural language processing and we're talking about how can we take insights from other aspects of cognition common sense reasoning language grounded in perception where we have non-neural network models and take those and use those to make better engineering language models and so we see these as just different parts of different steps in this process of the pendulum swinging back and forth trying to learn from what's unfolded over now a couple of decades in the study of the visual system and seeing okay can we can we carry that same process of engineering and reverse engineering maybe even now faster because we've learned a little bit how to do it but into other cognitive domains such as language so i'll just i'll just leave it at that as one example of where i see these things going and turn it over to jim okay thanks josh and tommy um i just want to say up front i i don't think tommy or josh and i disagree on things uh broadly but more in common than the disagreement but i think for this discussion it'd be fun to find the points of disagreement but i mostly want to hear from uh other people and how they're thinking this is just a broader discussion i also want to say that josh's comments i don't deserve any credit for other cool things you mentioned that martin shrimp is doing in my lab i'm just lucky enough to have them in my lab but thank you josh for mentioning martin's work so now let me just sort of give you guys three minutes on my overview of kind of how i think about science and engineering many of you heard this before but for those who haven't i just just to lay it out there um let's take our goal as a community maybe not everybody in this room or this call wants to do this the goal is to understand the mechanisms of natural intelligence that's not everybody's goal in the world let's just state if we just take that as a goal we can discuss whether that's a good goal but i'm going to just take that as a given goal what does that mean mechanisms of intelligence that means there's questions about the mind that are explained in the biophysics of neurons and their connections that's what it would mean at least to me to have a mechanistic model of intelligence intelligence being an aspect of the mind so if you accept all that so far how are we going to actually do that if we get real about it okay now we have us assumptions do we think that the accurate assumptions are going to be more complex than the two main types of tools we used in science for building our hypotheses my assumption is yes in other words it is going to be more complex than word models that we typically use word models might be things like the brain is a prediction engine or things of that sort but it's going to be more complex than elegant mathematical equations simple mathematically so we're going to have complex models to explain natural intelligence i hope most of you agree with that but let's assume i'm just going to take that as an assumption that we have complex models as hypotheses on how you go from neurons to intelligence so that's usually going to have to be described in some language that we can transfer among humans and right now the best language is language of code or maybe hardware or some combination thereof so we're going to have a hypothesis space that's complicated and how we're going to proceed as a species to build hypotheses in that space we need a process we need to build hypotheses and then we have to test them against data so so far hopefully you know you can find the weaknesses in my assumptions but so far i don't i don't know where they are so then when you get to that point the only question you have is who's going to build these things and what data are we going to test them again those become the operational questions and i don't care if we call those people scientists that build them or engineers or companies but somebody has to build them because they're complicated and we need them otherwise we don't actually have anything to test against data so i'm agnostic about what we call that again whether that's engineering science i don't care um but we have to build things and that must be done and hypotheses must be built and they must be tested against data and that's really just science to me in understanding natural intelligence at the mechanistic level and so that's all i wanted to say big picture and kind of i just want to add for tommy's question about do we need to understand human intelligence to build intelligent machines to me that's sort of a non-question how could we ever say we understood human intelligence if we couldn't build it right so it always is going to have to be that we're going to have to build intelligent systems before we unders really understand natural intelligence i'll just say that's a natural corollary of what i just described there and i'm going to end it at that and like leave it as sort of points of discussion if people want to attack my logic i would love to respond to that but i want to let this be a discussion so i think that's just an opening position for me so i'm going to end there thank you guys okay so thank you very much uh everyone uh i want uh to emphasize that we want to hear from uh from all of you so don't be shy i don't see any um any hands here uh so maybe one one question i'll start but i really want to see um okay now as i was about to start i see nick roy uh raised his hand so nick go ahead yeah great thank you so uh it's it's true that your three positions are very similar so i i want to sort of uh make a hypothesis and get your reactions to it um maybe it's a couple hypotheses so uh first hypothesis is that it is true that in intelligence science and engineering they've talked to each other but they haven't done a great job of really sort of leveraging each other's strengths that's hypothesis one which i guess we could argue about but the more interesting hypothesis to me is that i think the reason that the science and engineering have not really engaged each other is because they think about the world in fundamentally different ways that are important that engineering to a large extent is the act of putting things together there was a thing from jerry in the chat about an engineer created which never was and to create something you basically have to compose things together so you have to figure out how things go together in new and stable and useful ways um science tends to be a bit more reductionist and just trying to figure out what the thing is and not thinking so much about the interfaces josh you made a really uh a nice point about like you know sort of figuring out the the the connection between the different layers of sort of representation but i don't know that the science of natural intelligence has really focused hard at like you know what are the compositional interfaces that let us take pieces of the architecture and put them together i can't take a piece of gpt uh gpt2 and plug it into a new architecture and expect it to work in a predictable way without having to retrain so in that sense it's not composable so i guess the question my hypothesis is that level of compositionality has been missing from our knowledge our understanding of how the brain actually works and and how do we get it what are the experiments that we can do to figure out what the interfaces are that give us more compositionality of the pieces of of the brain well i guess i i can try to respond to some of those things um yeah i mean you know i i agree with you in terms of um on the science side but that's i guess maybe that's partly the work that the kind of work that i've i've been trying to do and we're especially excited to do so you know um some of this is work that we have done using what people these days are calling like a neurosymbolic interface so together with uh initially with judge and wu who was a student in our group and part of cbmm and is now a faculty member at stanford but also um with jayan mao who's a relatively new phd student and a number of others chongon and some people from the mit ibm lab um antonio taraba's been part of these things we've built various kinds of neurosymbolic models that that basically try to do at some very limited kinds of grounded language and they combine like basically us you know some much something much simpler than um than gpt but like a stacked lstm uh sort of uh language parser that parses a question or a statement into a symbolic semantic parse and then sort of like basically a neural image interpreter that that segments and de-renders an image into a symbolic scene graph and then a reasoning engine which applies the symbolic sentence pars onto the symbolic scene parts to answer questions or talk about scenes and you know that was just one example we've done static and dynamic stimuli these are examples of things um where we're trying to build systems that put the pieces together guided by some ideas about cognitive architecture which people have studied like people like ray jackendoff have studied these ideas for many years understanding the interface between language and perception but not actually built models of these things that can run on images and so we're trying to basically be inspired by some intuitions from from cognitive science to to build these systems but i agree that i think you know a lot of especially today's neural networks they're really good when they're when they're on on on data that looks like what they were trained on but to have composability and generalizability strong generalization outside of a training set is very tough those systems that i was just talking about don't do that but here's where i think some of the probabilistic programming based systems that like the kashman singha's group has been working on and we're working with him on using these in various kind of common sense reasoning and building machine common sense projects i think there there's you have both composability and strong generalization there are other engineering challenges and scientific challenges that those things face but we think by combining these you know basically by exploring in an engineering sense guided by scientific questions of exactly the kinds that you're asking um the neurosymbolic and the probabilistic programming and those can even come together into a probabilistic neurosymbolic toolkit um you know i think i i see this as a as a as a way forward that's going to be valuable for both the science and the engineering but it's those big challenges i mean you're exactly right to point to the challenges that really neither the scientists or the engineers i think have addressed that well long ago um david mar made famous this metaphor of levels of understanding understanding a complex system like a computer and the brain at different levels you can understand the computer i can say i understand the computer because you know how to use powerpoint without knowing anything about logical units in the computers or any nothing at all about how transistors work and you can understand how transistors work and know nothing about the software and these are all you know valuable ways of understanding a system um with david we stressed the fact that these levels are kind of separate modular you know that's related to nick point um but if you go back and this was practical in really for political scientific reasons at the time it was because we thought that neuroscientists did not understand the computational algorithmic level and it was important to stress the existence of that but if you look at the history of this of what david maher wrote the history of that is a paper we wrote together about levels and that in turn came from an earlier paper i wrote about the fly where there were levels of understanding instead of the computational level there was a behavioral level and david correctly you know replaced that with a level of essentially characterizing a problem and it's possible solutions the computational level but the other thing that got lost in translation was the fact that in the work in the fly we stressed with werner reichert the fact that in a brain unlike a computer these levels of understanding are quite tight together you cannot really understand how circuits work without knowing details of transmitters and synapses and so on and i think you know in modern time people took much too much at heart the computational level it's not enough for having a theory of the brain it's important to have a theory at different levels and or models that can be tested and falsified at different levels not only you know at some higher level because if you have a model using neural network you should really ask how can neuron implement an rlu does that exist in the brain how could it possibly be otherwise this model is not biologically plausible not even falsifiable and and so with other things like of course gradient descent and back propagation and so on so i think if you are examining an engineering system because it was made up by engineers and teams of engineers you will find much more separation between the levels of understanding than you would find in a brain evolution did not have the luxury of doing that and we have to take this into account when we develop you know biologically plausible models of the brain i was just going to agree completely tommy's last point that engineers had we had to find levels of abstraction and compositionality just to manage the complexity but but but there is a hope that evolution had had to sort of also work with choices of gene replications that would then be composable so it just might not be in the language we're used to talking about so there's still some hope it's not as if it's completely non-compositional but but i think it wouldn't be in the mar levels as tommy said it's going to be in some other form of how do i replicate a few genes and build another level of the cortical loops you know another cortexes cortex's cortex these are the natural things we see that might be the composable pieces that evolution is working with um and it's the engineer in this sense right by you know engineering by trial and error so to speak and that is that's our only hope there if you don't want to say the brain version at least to me anyway thank you so i just wish we knew the objective function that was being optimized there that would be wonderful to learn survive and reproduce i think it's actually essential to for understanding to be able to break problems into pieces write systems up into parts and understand how those parts fit together and that's so that the scientific understanding is going to be essentially what looks like an engineering understanding too i mean that's always been true for very complex systems um real difference between science and engineering has nothing to do with the tools used every engineer every engineer investigates the materials he works with every scientist uh builds equipment to do his to do his experiments the honest answer is that it's really a question about what the goals are and uh but the mechanisms of thinking that are required for doing both of the same and they're basically done decomposition of the system it departs that you understand how they're put together to for perform the the to to have the behavior that's observed hey thank you uh um um we're going to move on to the next question by uh machid hi i hope you can hear me well can you hear me yes okay great so thank you all for the discussion panel i just wanted to know your opinion on a top-down approach to achieving intelligent approaches like knowledge representation and reasoning because you comment more on that part inside the bottom up approach i i guess i could comment on that at least of the official panelists um i'm not exactly sure what you have in mind but i mean i guess very broadly that is a lot of what we do in our group so we come from the cognitive science side and we a lot of what we do is we try to develop um you know formal frameworks for knowledge representation and reasoning that might be probabilistic inference it might be some kind of symbolic or probabilistic programs which combine many of the power powerful features of the abstraction that you get from symbolic language and flexibility ability to deal with uncertainty that you get from probability and there's always uncertainty when you're learning from sparse data or a few examples or in the ambiguity that confronts natural science or natural intelligence in the world um so that i think of that broadly as a knowledge representation and reasoning thesis that has been very successful in modeling many aspects of cognition at the computational level it it i think there's you know there's there's issues of modularity that really come up in human knowledge it's part of how cognitive scientists have understood how humans achieve flexible reasoning and broad generalization and you know so so that's that's how that's the toolkit by which we do that but then you know there are really big questions of how does that work in the brain what are the neural mechanisms either in the level of single neurons or networks of neurons or within single neurons it's they're great mysteries about how the these formalisms or computational tools for knowledge representation reasoning that have been successful at the cognitive level and explain and predict a lot of behavior and really explain it in terms of you know underlying general principles we can make sense of a lot of what we're looking for is really there in the cognitive level but how that works in the brain is a great mystery and part of why i'm really interested in studying language and language in the brain is because it's a way into that i also think there are aspects of common sense seen understanding this is something that jim and i and others like especially with dan yemen's and nancy people in nancy's lab two are interested in i think we can also get at some basic aspects of knowledge representation just in in trying to take our models of vision in the brain and go beyond what jim has studied with core so-called core object recognition where you're just recognizing or categorizing a single object to trying to understand a whole scene the relations like the object you know these objects are on the table these ones are balanced they're not balanced this is this object is contained inside that one so understanding multi-objects scenes and their relations that's also a very basic kind of i think symbolic uh knowledge representation and whether it's through trying to understand the neural basis of sentence meaning and understanding or the neural basis of compositional scene structure we think those are ways that we can start to understand these things in the brain and it's broadly top down in that we have models that that you know work to a certain degree at the cognitive level and fit behavior and then we're in a reductionist way trying to say okay now how might these pieces be implemented in neurons maybe we'll posit some kind of things that look sort of like neural networks but aren't exactly or aren't very much like anything we currently understand in the brain and then that will pose a further challenge maybe there's new things we have to discover in biology maybe we need to adjust those those engineering mechanisms the you know for example the transformer models which have been so successful in uh natural language processing you know they're they're really different from how we understand neurons in the brain um you know is that a fundamental thing is that just a just a compactness for getting certain things to work in gpu memory you know we don't really know um but that's broadly a top-down approach driven in the way that i think you're suggesting a general understanding will always involve both top down and bottom up uh understandings which connect together at some point yeah i absolutely agree yeah just a follow-up question if you don't mind um do you have any favorite one favorite method that you have used probably in knowledge representation reasoning like we have semantic networks we have inference great uh graphs we have asian networks we have concept graphs uh hyper graphs is there i mean well i mean we've used various things the graph representations have have a lot of value and they they look a little bit more like neurons than some other symbolic approaches or neural networks but you know i i i'm a big fan of probabilistic programs and probabilistic programming i won't go into it here but i think this is a this is a toolkit that is is generalizes subsumes and generalizes a lot of other classic knowledge representation ideas but especially really allows us to combine the power of abstraction that you don't just get in graphs but like higher order you need higher order logic or or full you know recursive programming languages like like you know i'm very inspired by jerry's work in using lisp and scheme to try to think about the structure of intelligence and some of the first probabilistic programming languages that we built in our group the kashman singha and noah goodman who's now at stanford built you know they they took basically the ideas of knowledge representation and reasoning that jerry and colleagues had worked out and but embedded that in a framework for probabilistic inference in a language called church and that that was just the beginning of what's become a really fertile program um developing these tools on the engineering side and we're trying to apply them on the science side as well gosh i think you'd agree that that level of model of that language is like say thermodynamics in physics so it's at best a phenomenological description yeah yeah or or it might be like the level it might be like the level of algorithms and data structures in computer science maybe but what i'm saying you have to make a connection to the brain exactly exactly that's what so that's why i'm saying to do that i'm looking to apply these models in the places where i see right now we can make the best connection so that includes scene understanding at the you know go vision going i also mean developing models theories of how neurons could compute those kind of absolutely yeah yeah i mean but again i i think we all agree but we're also all know that we don't know where to look for those ideas so i think like again everybody who hasn't read jerry's book on the structure interpretation of computer programs should read that as a classic example of crossing levels on the engineering side and using and trying to cross between the sort of algorithm data structure and circuit levels and that's one way to go another way to go is to look at these neurosymbolic models um which are or like graph neural networks that you know these are things that are coming from the like the modern neural network toolkit that is that's trying to give you a language for implementing these kinds of things and you know those are just two of several possibilities gosh if you look at the history of physics thermodynamics were speaking about quantities like entropy and heat without any idea what they were yeah only later that you know mechanical statistics interp brownian motion and so on they gave the mechanistic interpretation and much more power in terms of what to do with them and electricity was the same story people used um built engines generators batteries without really understanding what electricity was having some kind of fluid analogy it was when maxwell came around then then you know there was a real understanding of electromagnetism and uh you know maxwell reverse engineered electricity to use this term of gm i don't like because that's science scientists never the reverse engineer but anyway yeah i know i think i think engineering electricity and then out of it came radio telegraph uh computers the internet everything right yeah no i i mean i think here we'll probably be in a lot of agreement i i think you know the top-down route unfolds over time and we often understand things at a certain more macro level before we understand how those things are implemented and the but the but the macro level gives important guidance for the underlying microscope here exactly interesting that thermodynamics came first yeah exactly i mean so i think like chomsky used to make this point in his philosophy class that i remember going to as a grad student here that in in physics you know usually that's how things go you understand you start with like phenomena that everybody can appreciate like everybody like oh there's a moon out there and and there's some planets and they seem to be moving how are they moving right or i drop this apple and it falls why does it why does it drop you start with phenomena like that and then you go you come up with mathematical descriptions that that unify things at that level and then you start looking for you know reducing things down and and searching sometimes it takes a few years sometimes it takes a few centuries to come up with the micro level mechanisms and i think the cognitive and neurosciences seem to also follow that can also follow that trajectory agreed yes okay we have um unless jim wants to say anything we're going to move on to a few more questions that we have from the audience uh we have some next i i actually the thing that i want to ask fits very nicely in this dialogue um i think that many of us would agree in some sense with tommy that we should look to the brain for insight into how to build intelligent machines but i mean the the place where i kind of struggle and i think a lot of people struggle is what exactly about the brain matters and what doesn't matter i think that if you look at um where engineers start to scratch their heads when they try to read the neuroscience textbooks and derive something useful from that is that there's just tons of details um that seem irrelevant or even possibly detrimental to building an effective machine and i think that's true not just for the biology but also for the psychology like if you open up a psychology textbook there's all sorts of biases or apparent biases that people exhibit and i think uh many engineers while they would like to be able to emulate the intelligence of the people do uh they they i think they would be perplexed if you ask them to implement all the weird stuff that people do in addition and so how do you know what matters and and i think this is not just a philosophical question because i think that i i guess i i perceive a kind of widget model of neuroscience inspired ai right now where somebody reads about something that neurons do like consolidation and then or some particular kind of spike timing-dependent plasticity rule and then they just sort of slot that into their model and then see if it works and sometimes maybe it does sometimes it doesn't but that seems like a very inefficient way to make progress if you just by trial and error try everything that biology throws at you so i'd be curious to hear what you guys think about that i would chime in here sam i completely agree with that point i call that neural branding it's all over the place like you have an idea there's always something you can point to in the brain that says well the brain does that so i should do this in my model but it's the combination of all the things in the brain measured as behavior and neural activity that is all is all the constraints that have to be brought to bear and that's kind of where this brain score platform or that comes from for us that you it's not one thing that's just inspiration but then there's the point that you also mentioned which is there's myriad details so how do you know which things to pay attention to and brain size doesn't have that answer so the only practical answer to give is if you choose a top-down problem josh mentioned vision that's what we do you start with that then you build models of that roughly in the style of neurons and then you look in detail and say well it's so far is it matching and that helps you sort out what details matter in which you don't but it's it's the top-down approach that then lets you sort out what matters and for what reason um but i think it's a mistake to think neuroscience textbooks are going to tell ai how to build something i'm certainly not in here staying i hope people don't take my position as being let's look to the brain and that will be how we figure out how to build ai i i think of it more of the opposite of building engineered systems that try to do ai as hypotheses for how the brain works well jim can i pick up on that for something so so if if you take brains i think brain score is a really interesting example because how do you decide what goes into brain score why aren't we taking like the tertiary structure of ion channels into account when we compute brain score right there's some heuristic the practical answer is you can't build models at that level of complexity and get them to run right now so somebody's got a comment in the uh in the chat right now like we can't build a sonde or things like that there's certain things that we just can't build so that's one answer to that but then the rest of it is we don't know so it's a political answer which is a bunch of neuroscientists that measure these things and since they bothered to spend animals and money on it well you should put them in because maybe there's some value there until we later learn there isn't but i agree with you we don't know the right answer so our biases put everything in for now but that's a hard hard task that's what i'm asking is it if you could would you would you put everything in would that make sense you you'd like everything that's you could just choose the level of your measurement and say you know i put in things that apply at that level of measurement you mentioned ion channels we're not measuring ion channels then you don't put it in the model no but if you were measuring ion channels would you put it put them into brain score that's that's what i'm asking well that's the art more than science this is josh's comment about you go from big to small you don't you don't try to bridge all those levels all at once you know and i think that that's too big of an ask but again that's a practical answer of just going from mind phenomena to neural spikes is one level but it's not the whole answer and that's kind of where your question is going i mean that's you gotta break it off a piece at a time you don't solve all the physics from one day either that that was what tommy and josh did too so i you're just making practical choices along the way that's how i think of that but but but they're guided by the tools you have at the time not by a truth next we have uh mike west so jim formulated our goal as understanding natural intelligence or understanding intelligent behavior and josh proposed trying to translate cognitive science descriptions into engineering terms and people have been talking about uh you know what how we bridge macro level phenomena with the micro level explanations and and josh said how we start with the most universally agreed upon phenomena in whatever field it is and so there's different ways i could ask this question but it seems to me that the most universally agreed upon phenomena in terms of uh the intelligence of our brain is the distinction between our conscious and our unconscious brain states and conscious or unconscious processing and so one question is do we think consciousness is relevant to understanding intelligence do you all think consciousness is relevant to understanding intelligence and if so how can we translate that conscious unconscious distinction into engineering terms thanks well consciousness is still a mystery right right it's like the the statistical mechanics level description that we would hope to to uh fill in with micro level physics but but it seems that we leave that out of all of our our theorizing or a lot of our theorizing uh about yeah our model making here is a question to everybody i'm curious um you all know that to a touring test suppose you know you are you are called to say whether something in the in the room you cannot see has human level intelligence or not you can speak interact ask questions and so on so to me this is still the best definition not very satisfactory but the best definition of human intelligence now do you think that if i make a test for consciousness a touring test for consciousness would that be the same as the one for intelligence or not so the question is now you can interact with something or somebody and you have to say is it conscious or not is it going to be a different turing test with different answers from the one for intelligence i'm curious what people think about i think it's a different test i think an intelligence test is is kind of an arbitrary test that's relative to some particular task like interpreting a visual scene whereas the distinction between whether a brain state is conscious or not seems like an actual uh you know objective fact um yeah can we make a poll gabriel so for people who are interested in this question i think tommy expressed his opinion uh during the summer course and you can watch the video and then we have lectures from christophe who has a completely different opinion on these uh so you can you're welcome to join us for and watch those those videos as well so the question is whether a turing test for intelligence is the same as a touring test for for consciousness that's the poll that tommy wants to just to be explicit list of things no i think yes wait so say the question then please uh that your question is the question is if we have a turing test for consciousness it's the same thing as a touring test for uh uh intelligence in other words can you have um human intelligence without human consciousness and human consciousness and without human intelligence i think i think those two things are equivalent maybe and it's human intelligence in a broad sense not not specific to some topics i mean you're losing this one it's all news in the window can i offer can i outperform this question the engineer's version is if you had a system that could pass tommy's intelligence test would it be easy to make it pass the consciousness test like i think the answer is clearly yes but maybe people think no but okay so here's the the quick quote so you should see the poll on your screen now thank you chris uh for creating this so if you can um just submit your uh quick uh i i like this pose maybe okay we should have a few more questions that uh that i actually think i actually think that i actually think that the concept consciousness is a funny one okay and that in fact it's a one can actually decide whether or not something is like me that is i can i can talk to it and it acts and it behaves in such a way that i could interpret as being i could feel like i was like that but i don't have any idea whether or not consciousness is a subjective subjective impression and i don't see that that there's any way to test for it at all so you all know the way we're going to decide uh funding for the next 10 years is the in the field is by doing polls so depending on how people no i'm just kidding here so it's 81 percent uh uh no and and 19 uh yes i i don't know what the end is for now okay arturo go ahead there it is very interesting and i don't know if my question is going to tie up to that but hopefully it does um so there's been a lot of discussion especially at the beginning i wish i would have asked this sooner about you know science versus engineering and and i'm pretty sure almost all of us here in our training were trained somewhat funnily either as a scientist or an engineer in undergrad like we did something for example biomedical engineering mechanical engineering maybe someone in pure psychology some of the pure cognitive science or neuroscience and somehow along the way um past diverted and uh you know everyone kind of became a bit more interdisciplinary so do you guys think that in the future like it's happening now already that there's like a six nine uh cognition computation major that there's going to be a new phd major that is at the end something like a science of intelligence field or it going to be something like you know mechanical engineering for example 50 60 years ago everyone was studying turbines and electric engineers were starting transformers like the real transformers on the upside like the power grids but now mechanical engineering has evolved to another thing right so now it's controls everyone learns circuits so how do you guys see the future in terms of education wise at the graduate level even um for the intersection of understanding intelligence and maybe having more interdisciplinary psychologists and computer scientists what are your thoughts in general what do you think it's going to be separated they're never going to kind of there's never going to be a new department that does kind of i this is john paris i will quote a famous provost of mit from several generations ago that you can't separate the two if you do you make a big mistake you can guess who that person was but he was from mit i mean i think i think all of us in cbmm are committed to uh there being that kind of interesting field that you're talking about and we've been working on it i guess i don't think that that means the other enterprises are going to go away there's scientific questions about the brain that whatever today's engineering toolkit is or tomorrow's one are not necessarily especially well post answer and similarly there's engineering challenges that are not necessarily want to be informed or have any good reason to be informed by the by the science of intelligence but there's that intersection that is where we where where we think the most exciting action is and where i think many of us think the future of both fields ultimately has come from in the past like that's in the past that's where the future came from in the future that's also where the future will came from is is people who are trying to do exactly what you're saying who who were trained whatever it was as a psychologist or a neuroscientist or an engineer but were motivated by questions that are at the intersection and so tried to do work that met the challenges at the intersection and that's where many if not all of the best ideas in the field have have come from i think the intersection is is inescapable for a very simple reason to understand the brain you have to make measurements to make proper measurements you need engineering and then you can go and create science so because of that which is also what's transparent in physics of intelligence stuff you have to go you have to go back and forth because just postulating a theory without validating is not the scientific approach right sure yeah but maybe to be a little controversial but yeah i mean neuroscience both neuroscience and cognitive science have always had methodologically they've used engineering tools but those aren't necessarily the same engineering tools you know like like building amplifiers or something or of course or doing you know yeah they're not the same engineering tools needed to understand intelligence and sometimes the field has been held back i i see this both in neuroscience and in cognitive science just as sam said i think both fields are guilty of this um and just it's a structural guilt not an individual guilt that you know people learn a certain engineering tool set um just to get their work done and then they kind of maybe mistakenly over generalize and think well that's what that's that's that's that's what intelligence should look like right yeah i i want to make a comment then because i've got another meeting but if you allow me okay i mean tommy knows what i think but basically what you need to do is to get some qualitative principles out of human intelligence and see to what extent you can come close to incorporate them in whatever you call artificial systems or whatever my prediction in the end is that whatever we end up calling provably artificial intelligence it may not necessarily be anthropomorphic at all and there are many examples in science that this has happened before so you learn things like the importance of learning fine but then you have to go beyond you learn what you do with what you learn you organize concepts you compact knowledge we haven't studied we haven't addressed these questions how do you present how you're left to be able to compact how you connect this to time where is attention mechanism all these things are quality properties of the brain that we understand pieces of them we have to start putting them into something that we're building and hopefully we'll come to something that we call artificial intelligence my prediction is that it won't be anything near human intelligence and are close by saying for those of you who do not know it go go read the famous theorem of free will and don't laugh that's a mathematical theorem from history advanced study and it connects measurements to quantum mechanics and brains i enjoyed the discussion and i have to go right thank you thank you thank you very much thank you we have a question from uh elias blake and i apologize to everyone if i'm mispronouncing your names uh no that's perfect uh pronounce my name perfectly so um i have a question about what the goal even is um and we'll tie back though so jim named this goal which i which i like the mechanistic understanding of natural intelligence um and we have this other goal which is that perhaps the objective function that gives rise to intelligence is this surviving and reproducing right that's that's a good goal well i have a question on surviving and reproducing because i want intelligence that's smart enough not to destroy itself okay all right at that rate humans don't seem all that smart humans actually seem like we're you know running our society in some ways into the ground and so you can ask well what would it take for an intelligence to be smart enough to sort of solve these collective action problems like climate change and other things but it ties back and so i wonder if seeing these two different goals as perhaps the same goal can be helpful because in the same sense that humans have a collective action problem of this joint or die mentality um neurons and cells have the very same situation of joint or die and perhaps that's what gives rise to multicellular life is to see that you know cells can come together and form an intelligent organism and that organism will survive better than the single-celled organisms would have and so that the same the same way that life comes out of multicellular cooperation may be the same very principle that by which humans have to start cooperating and maybe that's sort of the intelligence that happens everywhere from the most basic to the most complex of organisms so the real question is do you guys think that these two different uh but unifying those two views is is useful well i i would add i would just say that i i think of course some mathematics would apply at both levels but i i don't think we don't have an existence proof of a species that hasn't destroyed it won't destroy itself we don't know that's true for us but we have an instance proof of we don't have machines that do things that we do so i it may not be achievable but it's a nice goal that you're imagining but again we don't know if it's possible maybe theory could tell us that but that's and that's my that's my first answer to this question but i i want to use your question to just kind of pivot to say somebody else about you know future you know brain and cognitive sciences and future of electrical engineering brain kind of sciences will not survive if it does not adopt the thing that someone's calling six nine it will become like alchemy i mean that's a strong position to take but i i'm i'm i'm you know i'm currently the head and i'm gonna kind of take that position so that if we do not adopt that we we will not survive in the long run but electrical engineering and computer science will survive regardless of branding cognitive sciences so that that's a lot of symmetry there somebody said on ecs or josh and something like that it doesn't need but science if we don't put that that engineering activity into our sciences we will become like alchemy and that's that's what i'm afraid of and that graduate students have to be trained in that and that's that was back to the question of training and that may be too strong of an alarm to sound at this stage but i i honestly believe some version of that but jim i also think that's important i raise that question i think that's important in the future for computer scientists too right because now you've seen computer vision that everyone just throws a wacky random thing to a deep net and it's the next and and the objective is state-of-the-art it's not really under like forming a theory of learning or or understanding a network architecture whatever it is right so sure it's like it's propelled an entire field forward i think in other fields yeah but i think i think you should go ahead jim yeah but that goal is not they that goal is not to understand natural intelligence so again if the goal is to understand natural intelligence then you're going to need these engineering things so but i don't disagree with of course you can build stuff and that's kind of amplifying my point that people will do that forever and they will have departments around them but the natural science of intelligence kind of you know is a more fragile thing i think that's where i'm kind of more resonant with josh and tommy's like how are we going to go forward in that regime and that's kind of why we're into that goal it's not the only goal in the world it's just one that i thought this group was most oriented around yeah i mean jim i think you know bcs has always even back before it was called bcs stood for that kind of view right that's why you know david maher was here and tommy came here and you know people did robotics in earlier generations and you know some of the very even even when it was still called the department of psychology there were people using engineering tools going back to toy burst vision so i think we're all bought into that you know i think i agree with you that like our the quest to understand the brain and the mind and intelligence if it doesn't continue to keep renewing itself with with more powerful engineering ideas tools and so on it will it will run aground right and i think we've seen that in the past and i i agree with you i think we will see that other kinds of neuroscience like to try to cure diseases you know might not need those tools they might be much benefited from them but they might not need them in quite the same way but you know that's the quest to actually understand intelligence definitely needs them and i think you see the same thing on the on the engineering side because i think you can distinguish eecs from ai right um in fact ai was just carved out from ecs i think i mean this this might be a controversial view but i think part of the reason why ai has had a series of springs and winters right is because or where do you get the winters from it's like at some point you know some breakthrough idea comes in and then you like pursue it to its logical conclusion and you scale it up as far as it can go but since you made some big great promise about human intelligence and you don't have the whole story then you disappoint expectations and you temporarily die or wither i think cs and ee and ecs can can do fine without uh the brain but ai needs it just as much as as the science of intelligence needs the engineering that is to to keep the the the really long-term vision of artificial intelligence as everybody has always wanted to understand it it's for is it for a long time from now i think it's going to need to keep looking to natural intelligence to guide to set the problems to to provide ideas about um how to approach things just where that's where the new ideas have come from whether it was neural network people inspired by the brain or judea pearl who is inspired by human causal inference right um you know or you know so many people i think um different i mean look at like bull for example as in boolean logic right he introduced many of the you know new ideas effectively into computer science before there even was such a thing he was inspired by the mind right that's why his book was called you know an uh investigation into the laws of thought right and it starts off reading like a cognitive science book so yeah for for a long time i think um in the past and in the future that's you know that's where things are have have come from and will continue to come from and just as a quick last thing uh yeah i agree that you probably don't need the brain science for the engineering stuff but i do think that there's something about the way of thinking that we're all taking for granted here that it's not that all engineers for example know how to run a control experiment or know what they're looking for when they design something um so i think that way of thinking is it's different from the other field right so yeah that's maybe going back to the other one i just wanted to add something diego mendoza here uh just just to respond or to challenge the the view of jim and maybe others that we absolutely need uh engineering for science and that we need to build something to really in order to understand that let me just bring a challenge here we might be able to do that in neuroscience we have the luxury that there's this engineering way to to to make perhaps make something that looks like a brain but what about the rest of sciences what about ecology what about um so many other sciences where that that's you know weather sciences where it's not even possible to build something will you tell all those scientists that they'll they're they're doomed because they cannot build whatever they study i want to challenge that and say yes it's great to have the possibility to build something and to validate what we're studying but i disagree that we scientists absolutely need by principle absolutely need engineering to understand whatever are we understanding what do you want to say to i don't know if that's a a valid point that's a valid point and that's a challenge again i'm not trying to dismiss science as a whole i'm just saying what good science does is build models that explain that's easiest predict that's next easiest and control and some science can't control they can only explain and predict and you mentioned some but they better at least be able to predict or i think they're barely a science they're a collection of phenomena right and then and then we're lucky that we have a field that actually we might have the possibility of building stuff that goes beyond explain and predict in in that sense is a more super science and more impactful and for exactly the reasons you say so i'm not trying to dismiss other sciences because they're not trying to do that but i think all science has to aim to predict at least otherwise it's hard to it's a collection of phenomena to start right it's it's pre-paradigmatic in the sense right so so that's and that's how we challenge back to it doesn't mean you have to build but you have to aim to predict and in our field the things we're predicting are complicated phenomena so they need complicated models which means you need engineering not just as a tool which was mentioned earlier but as a hypothesis class the models themselves are hypotheses and our field has a hard time with accepting those because they're quite complicated but that's kind of where we are and that's the only position i'm trying to take at the moment yeah but jim this is uh generally true for the all of sciences i mean there are computers there are tools like there are many other tools very powerful tool and if you have a theory of geology or evolution you can simulate your theory on a computer and check whether what comes out is consistent with the data and that's same with the brain and you know one of the some something we should be careful as a computational neuroscientist or working between the science and engineering of intelligence is to avoid thinking that the models we are testing are actually the real thing they are just simulating models of the brain right which may be true or wrong and so um and tommy i agree with that point that it's not the only activity you want to do but those models that in the examples you gave first of all the question was about geology yes you could build a model geology but you might not be able to influence geology even with the model that was where the where the question was coming from but your point of the models are not themselves sufficient i agree with and then but the models also then put together all the phenomena and principles you have and tell you where your pre where your theories are lacking and then that leads to new theory and that in complex systems that's the way you have to go you need that in your toolbox as well so i don't think we disagree i i'm not saying the models are the only thing you need to do and i think that's another point i want to quickly read a question from the audience my friend and colleague tommer ullman who's too shy to raise his hand uh he he he writes uh something uh he writes the main focus of the touring test was behavioral so perhaps the follow-up question would be should the test for human intelligence need to satisfy only behavioral tests or do they also need to take the algorithm into account as well uh and tomorrow if you're still here uh maybe you can expand on this but um the question i think for for the three panelists is whether a turin test should only concern behavior or should also match algorithms yeah it's a classic question and i'm sure that the panelists have heard this before but it's maybe worth bringing up in the context of all the participants that we have here which is again the turing test wasn't a test of intelligence it was supposed to replace the question can machines think turing said i don't know how to think about that question i'm going to replace it with a different question of the turing test but it's been taken as a test for intelligence and one of the main focuses of it was behavioral if you can do this behavior you are said to pass the test and a lot of people philosophers cognitive scientists artificial intelligence people said what's that what that is fundamentally missing is the focus on an algorithm and people like med block made this very forceful argument that you could have a giant look-up table the size of the galaxy and if that's a giant look-up table that caches all humans conversations it would pass the turing test but obviously you know ned block said this is appealing to his intuition i don't know if we ran this on mechanical turret but that book said obviously we wouldn't consider that as intelligent right this is an appeal to an intuitive theory of intelligence we wouldn't appeal we wouldn't consider that giant look up table intelligent therefore algorithms are also important for our theory of intelligence not just the purely behavioral test and then all people argued with it and one of the main counter arguments was well you can't build a galaxy sized brain to catch all possible conversations right that look up table would be insane you can't do that there's all sorts of arguments about this but i think that one of the reasons that this has come back in full force the vengeance of the blockhead since the 70s and 80s is that gvt3 is the blockhead i don't think gbt3 is actually a model of human intelligence and i i i maybe there is in the mind things like look up tables maybe there is in the mind things that are like caching and i'm sure there are and i'm sure that they're useful and i'm sure they're useful for intelligence in the sense of getting some action done quickly but in the same way that human intelligence can do five times live by appeal to a lookup table you know that's 25 without multiplying it but you can do 63 times 127 by enacting a multiplication algorithm that is in the lookup table and you can have both of these i think gdt3 is much closer to a blockhead to a lookup table to any of these things now i don't know that for sure that's one of the problems we have with this but i think our zero hypothesis should be for any one of these machine learning algorithms that if we see it doing the behavior that people can do is keep in mind that any behavior can be done by multiple algorithms and our zero hypothesis should be for all these things is that whatever it is that they're doing is not human-like intelligence because every time that we try to tweak these models push them try to do generalization including all the stuff for image net not just for gp3 and there's a bunch of people in the audience who have done these things they all broke they all don't do generalization they all don't do vision they all don't do language comprehension so i think it's a possible hypothesis that all this amazing progress that we've been making is to a certain degree building a blockhead now people can retort and say well in the mind you also have a blockhead and i agree with you to some degree but i'm not sure that we've come closer with these algorithms what we would call human intelligence so i don't know i've been throwing like a lot of fire sorry a lot of gasoline on some fire right now but maybe going back to is a behavioral test enough because then maybe gt3 is on the right track and but well by an algorithmic test tomer do you mean like what does that mean actually because i think some of us in cognitive science right like a lot of what we try to do is come up with basically better behavioral tests to get at algorithms which are otherwise invisible or neuroscientists like jim might say well no the way you study the algorithms is you have to study the neurons um and that's and that's that's makes sense for but but only gives you a certain window on algorithms and i think those are basically two incomplete ways we have to to study the algorithm so are you do you have one of those in mind or the other or some other kind of thing when you say an algorithmic level who knows what i have in mind that's the argument right but i'm sorry but that was fatigue i feel like i've taken up a case of oxygen in the room by my no it's great no no no no no no there's a famous there's an exchange i think where uh um touring asked wittgenstein what what's your point in which concerns that i have no point now chris i wanted to ask chris whether he can put up a poll asking the audience when they think that alexa will be as good as the human assistant that you can hire so maybe we can put a couple of uh numbers in there so one two five years uh five to ten yeah ten to fifty fifty to a hundred maybe uh 2030 2050 you know grace can you do that so chris if you can help us put up a paul about uh when uh alexa would be will be as good as um as a human would be at the level of a human assistant what is it the level of human system you mean when it passes the turing test you mean yes i will hire alexa instead of hiring a person that's my version of the touring test so well chris is working on this uh jim and tommy do you want to say anything about whether a turing test should also include algorithms loosely defined i think we interrupt i interrupted tommer we can continue now but i think this question i'm asking is that for i mainly wanted to hear from other people on the panel and not just on the panel i mean there's many many clever humans here that have lots of interesting thoughts and i wanted to hear from from them my answer question have been it's just an operational set point you got to list a set of questions it's a set of tests it's never going to be complete the bigger that set of tests goes the more constrained the algorithm is going to be to pass them all and then the infinite limit of a bunch of behavioral tests you're going to probably be pretty close to a human-like algorithm would be my position on that you might say well you basically built the block head and if that blockhead fits on my phone well success you go you know that's gonna take over the world in the sense that tommy's that's a very reasonable answer from an engineering perspective that says like look and i've heard this from people who say look i don't care if you would call it in children journal if i can talk in a star trek like fashion to my phone that's what i need and it's worth a trillion dollars and that's enough and that's fine but i think this gets it possibly an intuitive theory of intelligence or i don't know if it's a scientific theory intelligence i think that a lot of people would say look if you built the blockhead and i know how it works and what you've basically built as a giant lookup table and you've cached all possible human conversations and you do that by just referencing the lookup table that's great it's worth a trillion dollars i'm amazed that you can do that but i would not call that intelligent and a lot of people have said i would not call that intelligent you might retort with saying what else do you want i would call that intelligent but i think a lot of people wouldn't agree with that and if you don't agree with that that's at least highlighting the importance of it also matters how you get to the answer right um hold it tillmer i think there's a there's even worse than you say okay consider the fact that every behavior including the time behavior can be represented as a machine that takes inputs and the state does a lookup function and produces a new out a new state and new outputs okay so if you make that function you can do make a good enough function approximation to the by in fact for example storing all the possible behaviors that have ever existed okay you could which i believe is almost possible with the current with the current network okay then what you end up i'm talking about the internet okay then you could probably make something that has all the behaviors of a human okay at least that you wouldn't be able to distinguish very much because it would be close to that and then and in some about finite amount of time i don't know how long maybe 20 years i don't know but the bottom line is here would that be something you would think of as being like a human i'd say if it's for me not at all right again so uh there should be you should see a poll on your screen uh to vote on thomas questions so while people keep voting uh we have a question from uh co oh okay hi uh i i think my question kind of like goes this way so if you move away from in silico models imagine like we can look at all the neurons and can manipulate all the neurons of any species any any animal that we can think of for any living creature so so let's take c elegans or something um so is that a good endpoint so let's say we engineering uh like we engineer we have this technique now where at any point of time we can record activity of all neurons of a species or we can manipulate the activity of all units of a species for any kind of stimuli you want will that be a good endpoint to an endeavor of science or engineering for that matter because i feel like if there is still something more we want to do sounds more like a good starting point than a good day i i understand yeah exactly but i feel like that would be the end point to some extent of the way the conversation was going like we built the system completely replicating you know the the the the system that we want to understand but but then if we still want to abstract away from the real system then i feel like that's kind of not where at least thought initially where we were going like then then it feels like okay there is something more to understanding quote more than just building the system that predicts and something that we can control it's like trying to build some sort of like algorithm so are there general principles of explanation other than yeah i mean i think here tommy and i if you want to talk about the panelists tommy and i would say unequivocally yes and i i'd love to hear jim's answer i i think well i don't know i mean because jim of all of us at least he's been the one most arguing that like the the big model is the is the is the understanding but jim you tell us what you think so um jim you have to go now so maybe uh you uh uh answer uh this question and and a few uh parting thoughts uh before you leave my party thoughts of this has been fun but i i would just my quick answer is john does it would like at least building it would be powerful to do a lot of things but i hope yeah absolutely right is it necessary that there's principles underneath and if they're there they'll be shortcuts and they'll make things more efficient and that would be really nice if it was true but we have no we there's no guarantees on that is the only thing i would add and and i would also add related to that you gave up brain disorders earlier as oh we don't need this models for that that is i don't think you should give that up i i did i didn't i didn't say that or i didn't mean sorry for that i was just saying some people who study that may not need yeah yeah no i mean yeah it's um i i agree i don't i think okay so sorry i gotta run thank you guys so thank you thank you very much jim i know that you have to go so thank you very much that was great uh for those of you who wanted to know uh when alexa will be at the level of tommy's assistant or anywhere assistance the answer is uh very clearly uh and uniquely 10 to 25 years that's that's when uh that's the mode of the distribution at least so uh maybe uh interestingly broad mode it is pretty close to uniform distribution that's very true so i want to ask at this point maybe uh uh uh also to josh and tommy to have some parting thoughts on this uh on this topic sure i mean i okay well i can i guess i can say a couple of things i mean just to just to finish on what jim and i were both saying i mean i think um so jim said there's no guarantee that there'll be any principles yeah i mean i guess there's no guarantees in life certainly or in science but i think most of us are committed to the idea that like we won't be satisfied at least unless we unless um our our unless our our science leads to general principles a unifying theory in the way that science has always looked for in addition to the kinds of engineering models that we're talking about but you know it could turn out to be it could not work but but i think that's what we're aiming for and i think aiming for that has always served us well whether it's to make more efficient models as jim is saying or more efficient model building or or a lot of other things or a more flexible generalizable toolkit for modeling just as abstract knowledge helps human intelligence not just in science uh achieve flexibility and generality i guess i would also just say one other thing that's just a reflecting on um a comment that paul smalinski made at a workshop connecting ai and cognitive science that a number of us were at i know tomer was there and um and maybe some others here um which was which is very telling um and and also speaks to the difference between science and engineering but where there is sometimes a tension but often a productive one um this was there was it was this was a workshop that um was specifically well a lot of the interest was on cognitive development and you know can uh can we build models of intuitive physics or language that uh learn the way human babies and children do or can we use ai to reverse engineer how human children learn common sense and language and as often happens when ai people and neuroscience and cognizant people get together and debate that one of the things that comes up is that people on the ai side especially as well as some people in neuroscience or cognitive science are very drawn to an approach which is like kind of learn everything from scratch like the thing that makes the model the best models are the ones which where you build in the least amount of structure or the least amount of knowledge and then they learn the most out right and that's that's what you should be striving for um but many people in cognitive science as well as neuroscience have a different goal and they say well no what we should be trying to build in is what actually is built in in biology you know our genome builds an incredible amount of structure about you know the structure and function of of the brain the learning algorithms as well as you know in in some ways concepts and conceptual representation and that's a lot of what the study of very early infant cognition has has suggested um so there was this tension between people who were who were basically trying to build in as little as possible and that and like the more the less you built in the and the more you got out that was just clear that was just assumed to be better at versus people who were trying to um try to figure out what you know build in like the the key pieces that seem to be built into human babies and in a moment of some tension between people there um paul smilenski uh who if you those of you who don't know him he's a uh he was a uh physicist originally and then a computational neuroscientist and linguist and he mostly works in linguistics right now but using neural networks he's one of the people who's most advanced uh creative ideas of neural networks and language but also very much guided by what we know about human language anyway paul said to to one of the machine learning speakers he said are you trying to do something cool or are you trying to do something real and this this was him i think encapsulating the difference between science and engineering now it was it was a little disparaging the way he put it but i i as someone who's on the science side but very interested in engineering and very appreciative engineering i see what he was trying to say that it does seem like and going back to what jerry said also in terms of like you know engineering you're trying science you're trying to understand something that is in engineering you're trying to build something that has never been and that's amazing and awesome and impressive um but how do we you know what are the things we're trying to build well we might be motivated by societal applications and making the world better and it would be great for ai to be more motivated by that when when people try to say what should we build that has never been before um but often these days ai engineering has just been motivated by some sense of what would be cool and given how powerful learning systems have been the cool thing is to is to show how much you can get from the data without building stuff in whereas i think the scientist has a really healthy perspective on that and says okay well maybe that's cool but i want to know what's real and i want to use engineering tools to better understand what's real and i think that's not only the right scientific goal um but also one that will help to advance and fundamentally advance ai because we look to human intelligence and we still see something that is by whatever we mean by intelligent and i hear i go back to the definition that tommy really usefully introduced when we started the intelligence initiative you know look to the latin intelligence means to understand right intelligent um so by any notion of intelligence um you know just just what does it mean to what is it what is it what what does it mean for a system to understand the world we have really only one good example of that which is the human mind okay um and the human brain as it implements the human mind and the science that we do in cbmm and in all of our work and the scientific discussions we're having here are one of the best most salient examples of human intelligence at work trying to understand the world including itself in the world so if ai is to really have a future and an inspiring future that is also where it came from right in the early days of the field it is going to have to look to what is real not just what is today's momentary sense of what is cool is going to have to look to what is real in intelligence and be guided by that and i just i think all of us um can can gain a lot from uh that perspective whichever side we're on as we work at this joint enterprise together thank you very much george that was uh that was very nice very that was great uh tommy uh final thoughts yeah just very briefly um you know i pitched for cbmm um cbm was born um with the belief that the engineering of intelligence must be complemented not replaced but complemented by a scientific investigation of the only example that we have of natural intelligence which is homo sapiens and i think it's only if we understand better the biology of our own intelligence that will be in a situation to understand the promises and the pitfalls of ai when it will be better than it is today and in short i think you know there are probably two or three order of magnitudes in terms of money and people that goes into the engineering of intelligence compared within science of intelligence today and i think that um this effort which is great on the engineering of intelligence really calls for an equally grand and synergetic effort on the science of human intelligence so that's cbmm and i think there is more work to do beyond the first eight years very good so thank you very much uh tommy that was that was great uh i want to thank uh both uh josh and tommy and jim who's had to leave uh now and also all the people who participated through your uh through your questions and and all the comments in the chat which are which are also great i'm sorry if we didn't get to your questions uh thank you very much for participating well thank you gabriel yeah thanks gabriel and thanks everybody for thank you 