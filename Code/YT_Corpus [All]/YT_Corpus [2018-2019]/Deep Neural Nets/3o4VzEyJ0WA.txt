 [Music] so Christopher welcome to coffee with a Googler it's great to have you on it thank you for having me so I know you are one of the people you work on Google brain and you're behind this distill for a great dissemination of machine learning could you tell us all about it yeah so I guess maybe I exploited a sort of into into two parts okay so they're sort of the thing that that we're doing and then there's sort of how it is still the vehicle for that so we have this idea of there being technical debt right you can write software and you you maybe you don't always use good variable names you don't document it very well you don't you know you end up with all of these you know you're you're so you don't refactor it and your your software becomes hard for people to go and build on and work but I actually think a kind of analogous thing can happen in research where if we don't explain things well we don't sort of develop the right ways for thinking about things it can become harder to go and build on research and it sort of becomes this you know this mountain of papers where you know people and I think people take pride in it right they're like you know I spent all these years going and climbing this mountain and I got to the top and I'm gonna do more research and build up this mountain um but I think often we actually could have done a much better job of making the mountain sort of easy to climb yeah and so what still is really trying to do is to create a vehicle where people can do that kind of work and and do really amazing work of that kind and have it be acknowledged as a real sort of contribution to the community and and be the sort of thing that they can then help them get supported in in doing more of that work so it becomes like a really a best of both worlds kind of thing that's very accessible to the non-academic community but it's also referential if that's the word you know something can be referenced by the academic community you get the best of both many of these things that were sort of already just a better version of scientific papers um but they weren't being counted as such and so I think it's still sort of a legit amazing vehicle that allows and I think we also provide some help to people in doing good work in this in this way so there's all this cetera weird you know bureaucratic stuff and we just sort of you know crossed all our T's dotted all our eyes and and sort of set up you know distills also peer-reviewed and and created this you know this a scientific journal except it's a scientific journal full of interactive diagrams where you know we really you know really if somebody's writing writing in a very academic style we might you know urge them to try to do a little bit less of that right hum and and sort of subvert what a paper isn't in some sense and sort of and I think sort of explore what what's possible right I mean I'll talk about from my personal perspective and that is that like you know I have been out of academia for a long time and I've been working in software and software development that kind of stuff but as I've been getting into machine learning of course I have to start reading more and more papers and as I'm reading those papers like as soon as I start getting into mathematical notation and sigmaz and fives and that kind of stuff part of my brain begins to go to sleep and it's not that I don't understand it it's just it's so alien to me it's so long in the past and you use the image of a mountain and it's like I used to be kind of three-quarters of the way up the mountain now I'm just in the foothills and it's a lot of effort to get climbing again so if it's something like distill and what you've been doing what the still has been great for me personally so that I can start really beginning to grasp some of the concepts and and speaking those concepts is like another thing you've been working on is lucid right oh so and you're using distill to disseminate lucid could you tell us a little bit about that or yeah so I think why don't this really really traces back to to deep dream not even a little bit further you know there's there there's a there's a lot of people but there's a small cluster of us who've been working together who've been very interested for a number of years and you know how do neural networks really work and how many humans understand these sort of really really complicated systems um and you you know a couple years ago we had these really exciting results where we we came up with all these techniques for sort of visualizing you know what what do neural networks think are I think are interesting what are they really saying what work I mean really really think the right way to think about those images is they're sort of they're you know they're trying to make the most interesting image for our network as possible and so it gets filled with all the sorts of things the network you know finds finds very very interesting in some sense that writing that activates it all right now it's like it's full of you know dog slugs and that's a lot of fun and it has even become this this artistic movement we there was this event at the gray area foundation where people were like auctioning off you know art that was made with deep dream and I was like whoa you know that's right this thing that I was involved in is like there's like real artists so we're doing things I hope you have some of those I think we're all too expensive for anybody so deep cream you know I think part of what's exciting about it is is all this art um and you know I think we were we were really excited to are really lucky to you know see there's all these amazing videos but you know in addition to that I think you know we were you know it was also sort of really an attempt to understand what's going on inside neural nuts right and it didn't did stop there um you know we we sort of continued thinking about this a lot and then a you know about a year ago or like a couple months ago and we we published this article on future visualization which is sort of really exploring how can we take these techniques that we started developing with deep dream um and then go and turn them into you know turn them into tools that are sort of instead of just trying to make interesting images really understand what what individual neurons in the network are looking for okay and we discovered you know in you know early layers it's looking for edges oh come and then you know it starts to look for textures and then it uses the textures to describe you know simple patterns like stripes and fluffy balls and logos and hexagons and you know clusters of circles and you know these I don't even like me like spear like things and then those get turned in to you know simple sub parts of objects like you know a button detector or a flower detector or a patches of cloth detect or a bubble detector or a chain detector or a nose detector and then those get turned in to sort of partial you know part you know partial objects like you know parts of buildings or people walking around or helmets or dogs with fluffy or floppy ears and little insect like things right and so that was sort of a really exciting transition and then it sort of was the the result of us started fiddling a lot with ideas around keep dreamin not just ASEAN there's been a there's a big community people have been doing really exciting work in this area and we sort of have been been building on that and building up building up infrastructure really you know that just is just a means to an end where what what that work was giving us was it was giving us a way to go and understand what our individual neurons doing okay individual neurons in the networks those individual neurons that seem to know detect floppy ears and things like this okay but then what we've been doing lately um is we've been going and taking about a step further and going and saying you know how can we then use that as a building block in conjunction with other things and to try to really explore you know how the network makes decisions so I start with a simple example um so over here we we have an image right now we're looking at an image of a fluffy you know this Labrador Retriever and this tiger pad okay that's actually apparently a species of cat so there's been called a break okay yeah I mean there's real Tigers and then there's also tiger cats which I guess maybe they have stripes on them or something but this also you know like you have to have you had to have tiger cats apparently that's a tiger captain I would have known what the network does but the network does it's really amazing I would have actually wanted knowed it was a Labrador Retriever either I know the network really it's it's you know it's it's pretty phenomenal you classify as you know dogs into more than 100 species and you know I said I don't even know the names of a hundred species of dogs let alone you know how'd it go and tell them apart but the network can and one thing you might wonder is how does the network do that right um and one really exciting thing that we'll see is well let's just dive into this for a second sure if you want this this interface here it allows us to to go and look at the vectors and then the neural that runs the theme detectors at every position in the image um and normally that you know those detectors they all given a number at what the sort of describes how much they fired and normally you get this so called activation vector and it's just a list of numbers and it's sort of really inscrutable you're like you know neuron 53 was firing a lot well what does that mean the buffer useful to me doesn't tell me very much you know neuron 134 are also fired about a bunch but neuron in our own new neuron 12 it didn't fire well great thanks but that doesn't tell me anything there are on 12ax7 about yeah about what we can do is we can combine it with the these feature visualizations okay that give us a sense of what what the neurons are looking for mm-hm and we can combine it we can create this we call them semantic dictionaries where we have you know these these things that sort of give us an a name for the neuron may give a sort of a visual symbol that describes what they're looking for with how much they fired and that's that's a lot more informative so if we look over here you know all over here we see the disney's floppy eared detector that are are firing really intensely um it turns out that you know this neural net and Cokely net has a really rich vocabulary of different kinds of year so that's a really big part of how it tells the part animals so different kinds of floppy ears you know it not just floppy ears but you know this these longer floppy ears it's these mid length floppy ears and it has all sorts of pointy ears as well and like you know slightly it's like yours that are sort of in between pointy and fluffy um here what we're seeing that these really these two floppy ear detectors that are firing pretty strongly um that's really interesting but it's something that would have been completely opaque to me right without going and combining these techniques together right um and so that's sort of the first thing we're doing we can look in other places so there's a snow detector over here and that really is firing pretty strongly and if we go over here you know man we're seeing some point to your detectors and sort of a cat face like detector and you know that's what almost looks a little bit like an ape detector that's firing a little bit a little bit over here actually go down here we see you know this these fur detectors and these leg detectors that are firing you go down here to the grass you notice some grass detectors but they don't fire very strong likes that's not very interesting and we can look at other images so you know over here we have a fellow with a with a you know with sunglasses and a and a bowtie and you know turns out there's a bow tie detector oh and there's also you know a net without a bow tie detector and what I really liked about this one was that like the bowtie and sunglasses look similar right it's too dark oblongs oh they smell brilliantly and but this was actually able to detect the whole ya know it's really it you know you can see here and you can see that part of what part of what it's doing is it's like you know it's looking for the chin above the the the bowtie um and I think also for sort of the shirt with buttons a little bit below it now so these other things that are cueing it but it it actually is a pretty you know sophisticated sense of what a bow tie is and all says the suit detector and yeah the the neck detector and yeah here's you know some kind of face detector that seems to mostly be about like noses and mouths and skin texture and you notice the sunglasses detector up here and no let's look at this one and it turns out that this has you know these you know top of these detect our body of veins detector there's sort of a flower detector there's an detector that helps it detect the handle and interesting yellow spheres and that was another thing that was interesting in this one is because the lemons at the bottom of the image are yellow oblongs and the tulips at the top are yellow ha ha ha you know despite those two being very similar that it's able to detect that there are different things yeah and in fact now if we well I'll go to that in a second but there's there's some other one there's some we can see some interesting things about how these all sort of play together in a second but yeah so I think the first thing is just you know this is allowing us to understand you know sort of looking look at which neurons are firing and and see what's going on I'm gonna show you the pink for a second the pig is a great example of something that has lots of pointy red actors move around a little bit to find a place where that we're really getting all the point ear detectors to fire this too but now in this some places were more fire well maybe I'm not gonna be patient oh yeah there's a bunny here okay look the wave point to your point to your point ear and then like some kind of rabbit like thing with me with another kind of point you it has this whole vocabulary for talking about you know different kinds of your anything like that right so that's that's the first step um we we sorta we wanted to go and take that a little bit further so another thing that you can do is you can ask you know watch all these neurons together represent and so we you know there's all these neurons that are firing a different extents and if we instead of just trying to visualize individual ones we ask try to sort of visualize them all together we sort of see what the network sort of collectively saw at that position and then if you stitch those together you can kind of see how the network saw the whole image so you know here's our you know pig or hog or whatever it is or our cat and our dog and you can see you know what really seemed that the ear here and the snout and the the cat head and the legs and the grass or or over here you know the the top of the vols and the handle and the flowers and the lemons down here and the wooden surface in the background and or or over here you know there's the bird on the chain and it really sees the bird's beak and the feathers and you know the chain and all of us I mean that's kind of interesting pretty incredible and then we can actually go a step further and the way that these networks work remember is they they multiple layers they build up their understanding over the course of a bunch of layers so initially there really you know what's zoom in here you know initially they're really focused on relatively simple things in fact we don't train you the first layer but it would really be about edges right and you hear it sort of you know it's getting really simple you know combinations of edges or maybe the beginnings of textures but we go down no just two more layers we now have we're skipping a layer in the middle here we know how you know this thing or it's really got a much richer sense of textures and it starting to get a bit of 3d structure and if you go a little bit further down now we're seeing the chi and the beak and so on and if we go a little bit further it's sort of become more abstract and sort of birds and chains now similarly if we go you know let's look at the dog I had left the stalk in this cat so you know here again you know very simple sort of patterns with really mostly about edges but you know you go just a step up and now there's fur textures there's grass textures there's you know this you can really see that it's this 3d structure where there's boundaries and sort of um you know surfaces a little bit um and then you know another Stefan it's starting to understand eyes too um but now you know it's really got like the snout with eyes the ears the the leg and so you can really see any job that sophistication of understanding the object as you go up and this is part of the magic of distilled right so this isn't just a dry academic paper with illustrations in it we can see you interacting with it we can see you actually seeing what a neuron is seeing and getting hands on to that so it helped me to learn a lot more about what's going on something extremely powerful allowing people to you know there's sort of these pictures that I have in my head and there's I think it's sort of actually two interesting things going on so one of does these pictures I have in my head right I really turning them into interfaces um I'm sorry I go able to crystallize those pictures into things that I can really test my intuitions against right and that kind of um you know offload some of the thinking that I have in imagining what this would be sort of what's going on in the network and really rheya fiying it really turning it into this thing that I can interact with mm-hm and then normally do I keep that for myself but I can share it with other people and so they get to now see you know this thing that's I think deeper than what one would normally get work it's not just me telling you results but I'm really starring this way of thinking about and sort of interacting with with these this this type of problem right um and I think that's that's really really exciting I mean cuz to me there's there's two levels of opaqueness with machine learning right first of all it's learning it to begin with you know which is already opaque and then secondly is like when you start dealing with models it's it's a black box right it's a there's a there's a trained graph in this thing that you give it a picture and it tells you what's in the picture so there's a it's not like source code that you can open up and step through and see what's going on so though between those two levels of opaqueness it's really really hard for somebody to get into this and to learn and what I like about this is that this is cracking open the second of those I can begin to really see what's happening in the network and help me understand the network and then later on help me to build and tune my own networks all right so which is which is super cool so now lucid where does lucid fit into this picture so with all of this you know even we've been building up all you know we building up all these tools and we've been building a lot of infrastructure to go along with it and so one of the things we're really excited about with this paper is we're also open sourcing all of all of the infrastructure that we've built up to go and do this research ok um and so that includes both that that first to feature visualization article that I was showing you where you know all of the the tools you need to go in and produce images like this where you you visualize what a neuron is looking for and then also to go and you know that's also what underlies all of all these tools that we have here and the neurons in this one are they just trained on something like inception or yes these are for both articles we're using this network googly net okay which was at one point to stick to the air model it's now separately several years out of date but it's one that we sort of have used for a while as all sort of standard test for for visualization okay um seems like it actually there's some kind of something a little bit mysterious matter where it seems like the neurons in googly nod are like especially correspond to ideas that sort of human sort of our meaningful to humans I say Tom it's a fun one to start playing around with cool go home but you know you can go and plug in whatever model you want um and try and use these techniques on it nice nice she made these notebooks that reproduce each one of the the diagrams in the overhaul so you can go get hands-on yeah so you can you can just sort of you know it's there's sort of this continuum where you can even just read the paper passively you can you can engage with the diagrams and you can go a step deeper and go and start playing around with one of these notebooks and you know so here we have you know a notebook for these these activation grid visualizations and then you can go and and you know just you know I open in a playground but it used to be like once upon a time that you'd read a paper and you're trying to understand what was in the paper and you try to figure it out and maybe they'll be a bit of source code and you take that source code but then you'd have to go and find a data set of images to train but you'd have a different data set than the people in the paper had and they're all these like these concepts these frictions these little bumps that you have to get over and right and now we can sort of make it this continuous transition where you can be reading the paper you like I I want to play around with this diagram a little bit and sort of start doing that you know I want to go a little step further and start actually playing around with the code and fiddling with it and if you want to really dive in you know we have all of our codes open source and you can learn the library a little bit by playing around with notebooks and then go and super cool now I need you mention if you want to start playing with all the code is open source so say I'm a developer and I want to learn this stuff and I want to get started now where would I go go to tensorflow slash lucid on github um that's our repository um and from there you can get access to you know tutorials on you thinking and a list of notebooks to go and play around with okay um and then from you know the next step after that is you could you know you well you might come up with ideas after you go and play with some notebooks and you might want to just use code that's very similar to what's in the notebook so you could start writing your own own fun things and um you know a lot of this could also be used for artistic purposes where you you can certainly do you know traditional deep dream style stuff and also your papers under still I'll put links to them in the description of this video so that people can go they know yeah I think that probably what I would do first is I would read the papers and then I you know from the papers you can go and and drum jump to the the notebooks right um or or after you've read them you can also look at the Lucid repository and look at more tutorials and stuff like that to play around sounds good thank you so much Christopher this has been so John you know it's like we've just we've been sitting here for a little while geeking out about this stuff and it's one of the things I love to do so thank you so much and thank you everybody for watching this episode of coffee with a Googler if you have any questions for me or you've any questions for Christopher please leave them in the comments below we'll also have links in the description below to everything that we spoke about today so thank you so much again and don't forget to hit that subscribe button and remember we'll have a tensorflow channel on YouTube so go check it out thank you so much 