 hello thank you we thought I'd stand here for a moment to get a photograph for the M for the Royal Society archive do you mind don't wave though I think you should probably just look as though you're interested and intellectual and has that Oh keep looking interested matte now you can now you can wait if you want hello thank you for that so thank you for joining us this which is the final event of the Royal sizes you and AI series and I want to welcome everyone here tonight at the Barbican and the people well watching online so thank you for joining us I'm Professor Brian Cox the raw site is professor for public engagement in science now you have to go back to in fact we found in research Homer's Iliad in 800 BCE to find the first accounts of automata and over the centuries those ideas have developed into the more familiar ideas of robots cybernetics and now artificial intelligence and it was Ross I see fellow Alan Turing who began to grapple with the notion specifically of a machine based intelligence throughout the 1940s and in the 1950s he posed the question which has become known now as the the Turing test which is can machines think and the idea is that a machine could be understood or presumed to think if it exhibits an intelligence which a human might think was actually human and in reality this is something we'll discuss tonight that might be considered to just point to the idea that humans are gullible rather than a measure or a good a perception of machine intelligence if you like but perhaps this tells us that our relationship where there I might be just as important as their relative intelligence of the machine itself as the use of artificial intelligence grow and spreads throughout society how do we feel about it making decisions on our behalf and doing jobs for us well last year there are sites launched a landmark reports on machine learning the technology that drives many of the current advances in artificial intelligence and since then the society has been supporting a well informed public debate it's a bold idea isn't it how well informed public debates could use that in many other fields I think about the developments of AI in order to help create a society in which the benefits of AI are shared equally now with me this evening is some of the world's leading thinkers on AI and together we'll be discussing a eyes potential to revolutionize fields like health care and education but also the challenges in issues surrounding the ethics of mass use of the public's that is our data before I introduce the panel I'd like to thank deepmind who've kindly supported this whole you and AI series but now without further ado because you please welcome our panel [Applause] so by way of introduction professor Susie Surya is the joint John the see Malone assistant professor at John Hopkins University department of computer science professor peter Donnelly F med scion fr-s is professor of statistical science the University of Oxford and CEO of genomics PLC and dr. Vivian Ming is a theoretical neuroscientist technologist entrepreneur and co-founder of so costs now the first question before we really staff I think is to ask each of the panel for a definition AI has captured I think many of our imaginations perhaps our our nightmares in some sense but it does mean different things to different people so perhaps if I could ask each of you first of all to define what AI is oh ok so you know artificial intelligence I think can go by a variety of definitions one of the dullest but perhaps most accurate is it's any autonomous system that can make decisions under uncertainty so if there's a problem that has no right answer and there's no human there to make a decision an AI would be a system which could do that there's no right chest move there's no correct answer to how fast should I take this right turn in my car or should I give this person a loan or not they're just fundamentally uncertain decisions I actually like something a little more practical when I describe AI particularly because I do a lot of work in what's called the future of work and to me then AI is particularly modern AI is any brief expert human judgment we a contract decide whether to hire someone is there a mass on this x-ray made increasingly faster cheaper and often better than a human can make it I think Vivian's totally nailed it I don't have a lot to add except to mention a specific form of AI and one of the developments that's driving lots of the things that impact on our lives now and that's something called machine learning so that's a form of AI and it's the idea of computer systems that can learn for themselves from examples and data and experience the idea that instead of as in the old days programmer computer to tell it what to do in every eventualities in machine learning you program a computer so that it can study the examples and it can learn for itself what the patterns are tell but make the sorts of decisions that Vivian was talking about I think they've mostly captured most of the essence of what AI is just sort of a little bit of historical context which is AI as a field emerged in the sixties where it was primarily the ambition of researchers from a diverse group of fields all the way from physics and cognitive science to computer science if you owe engineering where the goal was to build computers that could behave intelligently the way humans did and now one might argue well do humans behave intelligently and so essentially you can see the goal was ambiguous and over the course of the last 50 years or 60 years we worked hard to determine what intelligence is what is human intelligence how should machine how should we build machines that are intelligent and should we be mimicking humans or should we be determining what is the right thing to do in a given situation and and that's sort of the field as a whole you know and it's worth noting that many of the things we really thought of as being the exemplars of intelligence like can you do a math proof or can you play chess we're in fact some of the very first Newell and Simon invented programs back in the very early 60s that could do these things whereas are any of you in the front row smiling turned out to be an enormous ly difficult problem to solve for a very long time although now it turns out we can throw it onto your phone as a free app but it turns out it's it's it's a much more complex problem that we originally appreciated it to be not just because we can't see them because it delights yes the glaring lights although the ones up front are clearly waiting to get their money value for this performance you've all well described I think in a sense what we might call general a is we should it's something that's very human-like and multi multi purpose but I thought there are also AI systems or machine learning systems that have very specific tasks they would use comments on the the difference between those to do this again alright so so they're these two big concepts in a lot of modern AI discussions one is called artificial general intelligence this is something that kind of thinks like we do it really understands and navigates through the world and I'm going to contend no such system like that exists in the world today no one is on the verge of inventing it however these systems that can take a very targeted approach to understanding the world for example is anyone in the front row smiling is there a loophole in this legal contract is there a giraffe in this picture building very targeted systems like that have been exactly where these systems have been so effective but I would contend that the one that can recognize giraffes understands nothing about giraffes it has no giraffe concept and when you look at the mistakes made between people looking at photographs and kind of looking at ambiguous photographs to make a decision is there a draft here or not you can understand why they might be wrong maybe this is a llama with head cold or something whereas when these a eyes make these errors frequently it looks nothing like a giraffe or it thinks something that looks exactly like a giraffe is not and you come to appreciate we're really making decisions in pronouncedly different ways so I would contend that these very simple systems that are really the core of AI today are approaching problems in a dramatically different way than all of us are does that mean that the word intelligence is it's a complicated word isn't it I think there's a lot of baggage associated with it when you say an intelligent system like a lot of people think of something like us rather than something that's good at a specific thing I think you know from having move traveled across you know from India moving to the u.s. at the age of 17 I got to learn new things that I didn't get to see as a child and I distinctly remember so humor humor is an example of something where you know and it's very cultural and contextual and something I find funny now I might have not found it funny when I was 15 and I lived in India but I distinctly remember thinking of it as a problem that I was back solving you know somebody was saying something people were laughing I was trying to figure out what's going on and then eventually I understood the context so what I'm getting at is I think one thing that's difficult about intelligence is almost any you know this ability to reason through things like solve a difficult math problem or to be able to recognize giraffes from llamas you can pretty much sit back and come up think of it in some deductive way or logical way in which you can I think train a computer to do it or even perhaps ask children and ask them how they're doing it and they'll describe in a way that you could get computers to do it so I think this notion of what is human intelligence and what separates you know what is that essence of human intelligence we're trying to capture I think is an open question from my point of view I don't know what do you think no I completely agree and and and also just actually to pick up on both points and Brian's earlier question in some sense the reason we're having the discussion I suspect many reasons but it's because of the advances in the machine learning in particular approaches to very specific tasks and problems the sorts of things that we interact with on smartphones every day the ability to speak into a phone and it I don't think it understands what we're saying but it knows how to react to what we're saying recommender systems when we shop online the ability to have friends tagged in in photographs on Facebook or other apps all those sorts of things are because of progress in these very specific tasks image recognition is one of them and it's been again to look back over the history for most of my academic career for example computer vision has been a very active field but throughout the eighties which sort of dates me from early in my career to through the 90s and even the early and much of the 2000s computer systems were just not very good they'd get a little bit better each year but they were nowhere near as good as people and then over the last six or seven years they went from being not very good at all at that specific task to now in in many tests as good as or better than people whether that's spotting giraffes whether it's it's looking for pathology in an x-ray of some kind computer systems because a machine learning can now outperform people and similarly with voice recognition similarly with some translation tasks so it's that massive progress over the last five or six or so years which has meant that we interact with this stuff all the time but we're interacting with it as you said Brian in in terms of the ability to very specific things now remarkably well okay well then let's move on to your questions so we've split them up into three sections and the first one we've titled who benefits from AI at the moment and the first question is from ER Anya and the question is who does the current system of a eyes currently benefit the most so who'd like to I guess I can lead this off every time I'm a paid pompous jackass you know I think one of the truths of almost all of technology is that at least initially it always benefits the people that need it the least the very nature particularly I've done a lot of work in educational technology and in fact applying artificial intelligence to education and everyone that goes into this field does it because let's be frank we're out to save the world we're out to say some little kid can we build a little AI tutor imagine that and every kid in every home around the world and the simple truth is a company like that is successful because it's able to sell its product to a you know wealthy set of parents that want to get a few extra points on a standardized test which will change nobody's life whatsoever and so we build these things and they tend to be adopted and part of the heart of this is because when we build them we don't actually understand people many of us understand a lot about machines whether there's so much more to learn but how machines and people interact what do people think is valuable I will certainly say in the education world if you've put an app in the App Store you have solved nothing because the people that truly need that help will never go there they will never download that app they'll never make use of it because they don't believe in their heart it will actually make a difference and so you know when we look again and again we see that this really more is a concentrating power inevitably increases inequality at least in the near term and AI in particular is interesting because it can substitute for human judgment at least in specific tasks and in particular often highly trained professional human judgments it itself is profoundly inequality increasing in ways that we've never been able to do before because now not to pick on someone who I don't think is a bad guy but now Jeff Bezos can substitute his ai's for a whole load of people he would have had to have paid to make those judgments before and that also has a big influence on inequality so you're essentially suggesting there's a subtext to this question which is it it's not necessarily of anything in the public admire your essentially taking a cynical view that many of them are just increasing corporate profits to say I wouldn't build this stuff if I didn't think it was worthwhile and and I hope we have a chance to talk about that sort of work but you know I'll be really clear building something because you think it will do good in the world is dramatically different than actually doing good in the world and we can build tremendously powerful systems they're tools they're not truly autonomous in the sense that they don't understand the world but they're tremendously powerful tools but if we simply think that a hammer by its very existence builds a house then we really have lost an understanding of how the world works I think I think this partly has to do with the way funding is structured right now so most of funding in this field right now comes through individual research grants which means no single professor or single lab has enough grants to build anything of significant consequence on the other hand venture capital and private corporations have a fair amount of funding but also the vision they see the vision for how this can bring good to the world but then like Vivian said the challenge is if you are going down that route the you have to have a sustainable business model which means you're naturally heading off in a direction where in the beginning you're going to cater to audiences where they are able to pay for it I work a lot in healthcare and I think one of the promising things I see in healthcare is because of the centralized nature of it which means data are held in large enterprises or here the NHS for example if we're able to take advantage of this data and identify ways to you know diagnose diseases earlier treat patients in a more targeted way that technology can really be distributed at scale and we can benefit many so I I think I'm optimistic I agree with both previous comments effect I'll say that many times sir it's a kind of complex and layered question who benefits from these systems at the moment there's a sense in which most of us benefit because they make our lives a bit easier through our smartphones and the systems we interact with there there's a convenience I mean those of you who would be my age and have kids they found it impossible to imagine how you ever managed to meet anybody in the days before you could use these systems to find out where you are and where they are and converge for somehow or other we muddle through so there's a sense in which our lives are more convenient at the moment because of these systems I think there's a real sense that I'm hugely positive about it about the potential benefit in really important areas healthcare is one of them and education is another one and the people on each side of me are making a difference in both of those where the possibility to improve so many aspects of our lives is real and yet I think Vivian's absolutely right that we need to think very hard as a society about how we want to play out I think if we let this happen without intervening or worrying or stewarding it in any way there's a very real danger that the short-term and medium-term consequences will be not to improve the world as as we hope but to increase inequality and I think as society we have a massive duty to be active and to work out how to steward this we need to be stewards we need to look ahead and think here are different scenarios as to how this might play out which are the ones where the society want to happen and which ones are we less keen on and how can we try and use the levers we have to drive things in the right direction because I think it's pretty clear it's really insane if we don't do very much then the impact in the short term medium term will be to increase inequality to make lives better for the people who are already pretty well-off and not to help the people who aren't and to make those gaps bigger which I don't think we want but we need to be active in working and by increasingly close you mean by the the most obvious route which is replacing low-skilled jobs is that essentially what is the more time I would be even more provocative you can go read the lunch with the FTPS I did that got very provocatively titled the professional middle class is about to get blindsided turns out it's not impossible to build robot to pick strawberries or to drive cards but it's actually very difficult and much more difficult than building a robot to do financial analyst or to read x-rays so those latter things seem like very sophisticated jobs we pay people an enormous amount of money to make those sorts of decisions even though often those decisions are very rote well if the rote an economically valuable and people make them on a regular basis you have just described a machine learning training set and so it turns out it's a lot easier to build an AI to do those jobs than to build an AI to pick strawberries and it's it has interesting implications because in a lot of the discussions that I'm sure many of you have read about or heard on the radio it's very much about what do we do with all of these low-skilled workers that will be put out of jobs which is still a legitimate question even if AI is good I grew up in Salinas California which is where John Steinbeck is from so I grew up in the realm of the grapes of wrath' and you know the devaluation of humanity out on the field twelve hours a day and it still goes on every day and it would be a human good for that to end it would be good if we could build robots they could go out and collect all of this for us and and so it's diligent my question to say what do we do with millions that this the largest job vertical in the world is agriculture and the next is transportation but what do we do with a group of people that were told if they went to university and worked really hard they would have an amazing job that would take care of them for the rest of their life and it's very possible that many of those jobs they won't disappear but they will be as I call it d professionalized well it'll be possible to hire a much less educated person and essentially stick an AI in their hands to do the hard judgments and then pay them so much less we've seen it happen through globalization we've seen it happen through autumn ization of factories then the first instinct of CFOs everywhere is chased labour cost to zero and AI won't necessarily it may well create more jobs than it destroys but how many people will be qualified for those very elite creative jobs and how many will fall down into a sort of low agency service sector where they really are no distinguishable from anyone else because has this got anything specifically to do with AI in the sense that you described many instances in history when technology has caused these problems as displaced particular sets of workers and so on and is this really the first time though that we know we're thinking about that when a new tool has become available or is there something unique about AI and machine learning systems that you think will cause a bigger dislocation than the dislocations of the past I've got an opinion we're gonna shut up for a lot of well I mean I think one thing - okay one of Evans comments one thing that's likely to be different this time round is that so artificial intelligence machine learning it will impact the world of work probably in substantial ways and ways I think that aren't so easy to predict in any kind of detail and there are like 10 different learned reports which also diametrically opposite things so that it's more evidence that it's hard to predict but I think one thing that is clear is it'll have a much bigger impact than previous revolution like the Industrial Revolution and so on on kind of white-collar work in the way Vivian was describing many of those tasks can be done or or many at least many parts of those jobs can now be done or will soon be able to be done as efficiently or better using machine learning systems than the people who had years of training they're interesting questions about how that whether that will change roles in the way you know first of all calculators help lots of people but probably didn't drive too many out of work I mean there were were people in the old days who actually people call computers who were responsible for doing the sums they don't exist anymore but they've been they were a small segment the calculators and then spreadsheets they've probably augmented our ability to do things rather than replaced but I think there's a real chance that the impact this time will be on across the piece but much more than previously at that level compared to say the Industrial English just so I can give it a little bit of a face this is one of my favorite examples it's not my own personal project but there was this sort of notorious little competition run recently at Columbia University between a startup that had made an AI to read contracts and a bunch of human lawyers and in the competition they'd engineered these non-disclosure agreements a form of contract with a whole bunch of en't loopholes in them and then they had the two groups go at it the AI and these are very rough numbers the a I found 95 percent of the loopholes the human lawyers found 88 percent so whatever they're only human so let's call it a tie but the actual much more interesting number is the human lawyers took 90 minutes to read each contract and the ai's took 22 seconds now what you do with those loopholes how you make judgments that's still a fundamentally human task but the vast majority of lawyers particularly junior lawyers spend their time reading contracts and finding loopholes or doing case study work doing busy work to learn how to be this other kind of lawyer and it may well be that that kind of work disappears those tasks disappear and then it becomes a choice do we do what Peter says which is all the lawyers all of them that are out there become sort of super lawyers Augmented in a moment they know all the loopholes and they begin thinking about what to do with them or do we say well gosh then you know let's take keep the five best lawyers and we'll get rid of all the rest well wouldn't it be great if we could you know have instead of lawyers just everybody is a super lawyer and effectively if we could have our contracts be read in half an hour of its solutions as opposed to five days of reading and cost us you know a tenth of what it costs now it seems like everybody would be more productive so in a way I think in that I think the role will change so it's that version of you said right now we need to we don't have a choice you have to spend your your junior lawyers have to spend time reading those documents or loopholes and they'd rather be doing more interest things so I really appreciate I mean I genuinely appreciate cuz when I say this is a choice I think it's genuinely a choice and the ability of so we I'm not gonna describe it in the moment but we built a little system that can analyze kids artwork and it adds to our ability of one of our systems to do some education interventions so there are like six people in the world that study children's art and look at its implications for their cognitive and emotional development and we took their work and we were able to build it into a system and train it on these kids artwork and now we give it away for free as part of this little system which itself we give away for free and in that sense yeah you can reach out probably even the better example is the idea that you could just even have a dumb mobile phone if I can take pictures take a picture of a mole you're worried about and have it tell you whether it's cancerous or not or at least whether you should go in and see a doctor that would be amazingly valuable but in this question of have we been here before well it really depends because we've been here in multiple ways in America we have this chain called Jiffy Lube you bring your car and forgive me if you have it here also but you bring your car in and they change your oil and your air filter and do all this sort of work well that used to be a middle-class job where an actual you know auto engineer would come in and do the tuneups on your car now it's a job you get if you didn't do so well in high school and you have no agency you just follow a script a computer does all the diagnostic work you do a little upsell on an air filter and the car goes out and the next one comes in so all I'm saying is the overwhelming economic trend of the last 30 years has been towards deep professionalization it doesn't have to be it could be very much what you're talking about but it requires an explicit choice on all of our parts and let me tell you if you leave it up to the entrepreneurs of the world we're gonna try and extract the wage value out of the system and keep half for ourselves and half offer half their other half to you as a discount and as a result that class will disappear when's the last time someone used a travel agent for example so 10 or 15 years ago travel agents were absent essential in the world because they were the only people who knew the complicated things and could read the airline timetables and so on and they still exist but but I think we interact them with them much much less because it's possible to do most of these things yourself through various apps online we should them we've obviously gone over time already office time the first I just waited so very very briefly we've got a demonstration I'm gonna go City minute but just just a question from Emily the last question in this section which is so we can be brief how do you think artificial intelligence in films has impacted our view on AIS and the potential they have to how many people here have heard of a deep reinforcement learning model okay there's a few hands how many people have heard of Skynet so there's a partial answer I think most people's conception of what AI ends comes from Dark Mirror which is actually not a bad depiction of some of the ethical choices if not great depiction of the technology it comes from the Terminator movies it comes with many and and probably reflects more of our fears I mean it feels a little more deep spiritual than anything else and and I don't know that it's done a great service to anyone in trying to get them to understand the implications of these technologies do define this when you say with a field that you work and the people tend to use movie and allergies and film analogies to imagine what you're doing oh yeah absolutely people get very excited and fascinated and they want to know more and immediately they think of not mathematics statistics and algorithms they think of powerful robots and so absolutely and do I take advantage of that 100% kidding it's interesting how if you talk about the future of work and people think what you're talking about is c-3po is gonna come and literally tap you on the shoulder and say you're out that's my seat and there's nothing like that actually taking place I should say there is a report a piece of work has been done by the Leverhulme Center for the future of intelligence today which is available it's published today it's available on the Royal Society websites if you want to look at more of the these questions dig deeper into that question you can go there through our site in and have a look I am going to go to this demo over here which is a demo it's Macedo if it's a new another example in fact of a machine learning and AI and so i'd like to invite to the stage professor Adrian hilton and his team from the University of Surrey thanks I like I'm gonna I say it later perhaps perhaps you could just introduce the team actually so um we have Charles and Marco and Hannah's going to perform live for us yeah so what are we going to be this is using a I machine learning for motion capture yes so so what we're doing is converting video into 3d models of people's movements um over on the left hand side you can see the kind of video input what happens then is that's transformed into a a three-dimensional representation of the person's movement and then we can map it onto a character both indoor and outdoor so this is a very portable system yeah and then what was the the breakthrough here what what are the difficulties in capturing human motion so so what machine learning and AI has enabled us to do is take this video data and really extract some high-level understanding so in this case what we're doing is understanding that there's a person in the video and on top of that we're understanding where their joint positions are in that video and that's something that we've not been able to do until the last few years and it's it's a powerful technology in this case going into the entertainment industry yeah because I suppose I used to see these things in film and the use of little dots all over everybody you know so you could see how what the visual system was doing but in this case it is just looking at a person so there's a lot of intelligence in there to recognize that's a hand that's a head is that exactly so so what is happening is the AI machine learning is taking the video and detecting that there's a person there and then labeling the body parts of the person purely from the video and the challenge really is to be able to do that in complex scenes so in someone's home for instance you're detecting their motion or in an outdoor scene like we just saw so we're going to see what are we going to see here so so up on the top left there we have yeah we have it's just calibrating itself and then in the middle we have now Hannah moving and her movements conveyed in 3d and then on the right hand side we have a computer-generated scene of the Barbican courtyard which is directly above us here and the model being animated in that scene I see so there's got to be that there's the recognition part of it but there's also a human model in there to say this hand is moving in this way so this is how we would that's so it's so the AI is mapping out where the person is in each view and then we combine that together into a three-dimensional model what are the applications I mean obviously for filmmaking this is useful so this system was specifically developed to get around some of the problems in filmmaking and games production and things like that so to have portable systems that you can take and put on a set but the technology itself is applicable to a wide range of things so for instance one of the things we're looking at is the use in healthcare and how you can have very passive sensing technologies that we'll be able to understand your movement and behavior and why is that important well if if you want people to be able to live at home independently for longer then you have to have systems that can understand their behavior and particularly when there's changes in behavior because that signals that maybe they have an infection or something like that so we've actually shown with some of this technology but using again machine learning you can pick out some of those characteristics from relatively simple behaviors yeah well I think do you think I should ever go just to sit so you can see that it doesn't only work with the a trained dancer so so could you talk through what what's happening so as I stand here so fine so what's happening so first of all you can see the images up on the screen there and what we have to do first is just calibrate the two models because we've got Brian in in the picture now and they should be that it's now picking up his motion and he's being converted into this lovely skelter he's changed into a another character here so you've got a a very simple pipeline without wearing any sensors or anything like that that can really interpret someone's movement and behavior and that's that's one of the kind of powerful technologies so the in terms of processing power and how long have we been able to do this what's the difficulties the algorithms is at the computer power is it that is it a collection of all of those so the real challenge has been how do you analyze an image in a general scene and understand that's a person and we've all got used over the last maybe ten years to our smartphones having ways to detect faces but this goes a long way beyond that and it's only been the last couple of years where we've really been able to pick out people in general scenes and then convert that or analyze that motion and that sounds a machine-learning understanding from very large groups of images what a person looks like in an image you know and you know the variety of people in the audience here with different clothing has to deal with all that complexity in the understanding ya know are very impressive so yes thank you thank you very much thank you clever stuff receiving a lecture from a superhero with Parkinson's yeah I know they chose a very flattering sort of I don't know yeah Iron Man type thing for me them it could've been anything anyway the next question it's a question from Alex who is asked who will be the last actually get we've talked about this little bit it's interesting could you talked about I made the mistake I think of thinking that new technologies always displace less skilled labor less your John you said no it's a perhaps the more professional classes that should be more concerned and the question relates to us who will be the last employed but is a creative artists or software engineers so it's going to the essence of what a what's the most what's the the most difficult thing for an AI to replace I've now taken the lead here on the whole thing so this will be an absolutely shameless plug I have a book coming out next year called how to robot proof your kids and the heart of that story is that there are some good answers to that at least for the time being and tell something advanced or more advanced comes along but we look at the sorts of things that generalize the best you know this idea that the future is unknown well let's build people for the unknown rather than trying to guess what you ought to know I think all of those reports the one thing that those future of work reports seem to have in common is everyone should go learn how to program which is one of the skills I've literally seen an AI do where a designer just describes the website that they want and it writes the code and so in ten years if that isn't most of the code isn't written by a eyes I would be rather shocked they'll still be people writing code to build really novel database structures and going out and exploring the unknown but there probably won't be people writing a bunch of boilerplate code just to fill in websites which is the core of these jobs but that's points to the other side i no one's really developed a eyes in a sense to explore the unknown so when you look at the qualities associated with that things and I'm gonna be very broad here like emotional intelligence and social skills creativity and metacognition those are the things that even talking about AI is doing those sorts of qualities doesn't even make sense because they don't really have you know emotions to have intelligence about so when you look further at who are the people that have the most creative jobs in the world today and I mean creative very broadly defined so scientists are creative and so are engineers but so are the people that are usually on this stage those are the things that will be the hardest to automate and really focusing our education system and even our hiring on those sorts of qualities rather than focusing on a bunch of rote skills that two years from now you're gonna have to retrain again is the heart of the sorts of qualities that we need to live that's the point that you made earlier isn't it that you open up possibilities by enabling people to focus more on those really productive areas even lawyers you said actually the legal profession absolutely and I think in general if you think about you know else arts and I'm Katz the entrance exams for medical school or law school at the moment they mostly are testing for you know what we typically describe as IQ but increasingly I think schools should change their admission criteria to focus more on EQ and identify individuals who can balance the two because that's where these professions will shift I'm going to agree again and I think the first next I think I think this question of how even the Nazi philosophy that we know that I am a machine do not quote me out of context it's been broadcast online faithfully just going to click it out and put it on Twitter I think thinking about the right way to train and retrain people is a major challenge for us there'll obvious things about helping people learn to to to think in the kind of old-fashioned sense rather than just to know and learn things that's bound to be increasingly important and we need to be thinking about that throughout but the standard educational curriculum and then the rest of people's lives let me add in a really fascinating finding so for a little while I was the chief scientist one of the very first companies using AI for hiring which I hope we talk about because it is one of those very profoundly controversial things and we had this really interesting finding we built a database of a hundred and twenty-two million people of which 11 million were pretty much all of the professional software developers in the world so I mentioned software social skills are one of those things that are robust to displacement by computers so in fact we found social skills empathy perspective-taking communication skills you could go on and on we're very predictive of people's quality of work and in fact just as predictive of the quality of code written by software developers as the amount of sales by salespeople yes it was much less common for software developers to have super strong social skills when they existed they were just as predictive so one of the misinterpretations of a question like that is oh well then we need to train everyone to do social jobs you know care for the elderly which is a wonderful job but the economics aren't great you know greeter at a store but in fact every job is made better by understanding other people and that's a really important thing to remember ok well let's move on to section 2 which we called it how could society benefit from AI we've covered many of these issues but Malcolm has a question so I'll come to you first Peter so the question was if a computer gives me a diagnosis should he also have to explain how it reached that diagnosis it's a really really interesting question and I think there are a couple of different levels of there's a specific question in the context of diagnosis there's a much more general issue about these AI systems which is how important is it that we understand why they're reaching a decision and it's worth saying by way of background that many of the incredibly successful systems we do there's no sense in which we can ask them why did you get that decision we can just measure how often they get it right and there are very interesting questions about the extent to which in different contexts we value the ability to be able to understand the reasoning behind the decision and I think those things tend to be context specific either the question was explicitly I think about medical diagnosis and it's part of the Royal Society's work on machine learning as Brian mentioned earlier one of the things we did was outreach and we talked to people we saw some already helped us to get people's views and actually those views were very interesting in the context of medical diagnosis let me don't tell you what they are let's actually do the experiment except I can't quite see so imagine you're it's kind of got to be slightly hypothetical and you've got a vote for one of the two possibilities here you're sick with something pretty serious and you have a choice of having your treatment decision made on the one hand by you know the consultant at the local hospital who's good at his or her job and we know from lots of data that they get this decision right 90% of the time so that's choice one choice two is you can have an AI system examine your symptoms and make a treatment decision and again we know from lots and lots of data that the AR system gets it right 97 percent of the time and except that there's no way you're going to understand the decision the AI person that the AI system is made ok so you've all got a vote unfortunately can't see very easily where you're voting so in those situations you're seriously ill slightly hypothetical as I said who would choose the doctor who gets it right 90% of the time the doctor and who would choose the AI system wow this is a really biased audience yes I think I think how many of you are wearing a badge that says I love c-3po right now this is a Royal Society event so it's statistically literate audience haven't quite finished my experiment so let me finish so so I think different people take different views as we've seen now if I give you a third option which is actually you can have your doctor who gets at 90 percent of the time who knows the result of the AI system that gets it right 97 percent of the time and can revise his or her opinion who'd go for that yeah so that's kind of easy then I'm and it that's the sense in which probably these systems will augment at least in that kind of medicine that old meant what doctors are doing final version of the question and those we have oh let me ask you two different way so here's something complex that gets used all the time in medical systems MRI scanners so they work on pretty what depends on how into physics you are but from a distance so a fairly sophisticated physics there are complicated algorithms that interpret the raw signal from the machine that gives something that gets fed back to the doctor I think it's probably fair to say that many of the doctors who do a brilliant job of reading the outcomes of MRI machines or CT scans or PET scans or whatever don't understand any of the details of the algorithm now somehow that doesn't seem to worry us currently we just know that they work well because we've checked so I think as I said it's an interesting question that that ability to understand the decision is a good one lot last verge of my kind of audience participation how often do you think in those complex situations when the doctor says we think we should do X B cause and then there's a kind of short simple statement how often do you think you actually really understand the doctors thinking and the reason the doctor came to a decision doctors probably some of you do and and so the question for us is when should we want different when should we were different criteria about decision making from algorithms from that of people I mean people can give an explanation but we know from our daily experience that most of the time the explanation well that's not aimed at any of the people I interact with all the time but sometimes what we experience the fact that someone comes up with an explanation after the fact which isn't really an explanation it's just you know it's a way of them saying or just justifying what they've done anyway long rounds but I think it's complicated and we have to think hard about it I think sort of building on what Peter said though I don't entirely agree with them because I have to disagree with him the this notion of you know I don't actually think we need an explanation what we need is the ability to trust and the ability to work together it's that example the lawyer example contract reading example we got earlier from Vivian but also the same thing in medical diagnosis if you had a way of knowing you know when you interact with the trust colleague you understand how they work you understand how they think they're going to say something to you helps you build your own thinking which allows you to evolve and say something that they react to and that notion of collaborative reasoning is what we need with four subsystems a thing that's really exciting and powerful here is that you know computers possess the ability you know these algorithms can look through tons and tons of data to determine in any given scenario what has happened to other patients who when the same scenario and what was done and how they reacted and can summarize it in a very nice and succinct way so what this means is if we could figure out a way to build complimentary expertise where we can use that knowledge to be able to collaborate arrive at a decision I think that's where we want to be at but I think this is an open science and something we're actively working on personal answer here seven years ago just before the u.s. Thanksgiving holiday my son got sick and it wasn't clear what it was at first but that was a Sunday by that Wednesday he'd lost 25% of his body mass and couldn't stand up so we rush into the hospital and it turns out in retrospect it should have been obvious you could actually just smell what was wrong with him he had type 1 diabetes and his sweat was sweet now I got some fancy smancy degrees but it turns out being a neuroscientist doesn't mean you know anything about diabetes per se so that was a very hard long four days in a pediatric intensive care unit my wife and I both happen to be scientists so the minute we come out we record everything we were crashing Google Docs on a regular basis recording everything he ate to the gram did he have the sniffles that morning what was his blood glucose readings what's his heart rate everything and then before I go in to meet with his new endocrinologist I don't know how many people here get to have an endocrinologist but that's a fun part of your life and she's someone I should really respect and she's still his doctor I emailed her all this data thank you she's gonna laugh this and and we got no response so I figure what's what's going on here I mean I love data then truly all of you love data what's wrong with this woman so then I realized what it is so I print up about an inch thick of spreadsheet and bring it in with me and plunk it on the desk in front of her and they were pissed this was not what they wanted what am I supposed to do with this data um so instead they gave us a little photocopied sheet diabetes gotten Basti better even in the last seven years but at the time they give us a little photocopied sheet it had five days three boxes for each day morning afternoon evening right a blood glucose level in each box 15 numbers we had 15,000 numbers but what a human can't really process 15,000 numbers but I'm gonna admit and forgive me if I'm reading the room wrong here but this is my genuine feeling you've got to be kidding me I make models of the brain are you telling me diabetes is more complex in the brain so that night I bought a book on endocrinology and the next morning we hacked all of my son medical equipment turns out we broke several federal US laws and I redirected the data to my personal server and then I took a model of predictive coding in the retina I don't know if you realize it but your retina literally predicts the future and I repurposed it for diabetes the details don't matter except that it really helped I mean it profoundly helped it allows the the insulin pump to sort of make its own decisions and there's all sorts of implications it was it was wonderful and and we got to give it away and all sorts of things I gotta admit I don't care what my endocrinologist has to say about the treatment for my son I care what my model has to say her job is all the stuff that's not day to day because it's day to day literally every five minutes it gets a new number and it makes a new judgment and it updates the model and there's a very exciting a lots of new work in this space we've been able to do the same thing with bipolar disorder and work in Parkinson's so what I'm getting at is I actually think models ought to be explainable both in medicine and a variety of other domains I need to be able to tell you why I didn't hire you or maybe why I did but it doesn't mean you have to understand the model it doesn't mean that we have to probe the and sometimes incredibly complex into relations of a very very big system but somewhere along the line if you've been denied a loan or job or if the judge doesn't believe you for some reason that won't be disclosed you should have a right to understand why and if they can't provide you with one you should be able to second-guess it and in the case specifically of medicine this is why because there's no right answer to the treatment so understanding you what it means to get this diagnosis what kind of cancer do I have what does it imply how does it interact I think there's cool ideas about how a eyes can explore vast possible treatment plans also and then linking a whole bunch of them together but somewhere I believe there should be a person and there should be a why and it should be something that you actually understand because otherwise we need to think about what happens over time and we get very used to the idea that there is no you know intelligence the way we understand it in assistance in making these decisions is interesting because it's again it's some of the issues we're discussing you're not specific to a is and in this case it's a the human need to understand if if a mistake is made which I might mean the wrong diagnosis even though 99% of the time the expert system might get it right as opposed to 90% for the human we want to know why the mistake was made don't we the brutal statistical approach would be it doesn't matter because it gets it right more often you see this with driverless cars actually that is well the question is well driverless cars will be much safer than drive at human controlled cars but when the car runs over and kills a pedestrian we want to know what the decision-making process was but it's something nasty about Elon Musk in a sense not particularly logical and not about the AI isn't it we're talking about the need to know why it may have made a mistake I don't know if that desire to know that and that instance is logical in other words I'm conflicted at this choice of if I had a system that was 99% accurate versus using a system that was only ninety percent accurate but one could make up an explanation like Peter said though we had no way to assess if that explanation was correct yes versus a different system that happened to say I don't know though I disagree I actually think we can hold complete these algorithms to a much higher bar and there is a lot of creative work going on and being able to elicit explanations that can allow you to collaborate with the machine but even in that dire scenario where the system said you know this is my decision then unless the issue is that when it gets it wrong it gets it very wrong and it's very damaging I would say we should be willing to operate with the 99% accurate yes I agree but it's a so that's why I was thinking the heart of this question is a should should the thing you have to explain how it got to them that's the point isn't it what we're saying is well no if it gets it right most of the time and more often than the human it doesn't matter is that what we're is that the consensus I think for some people it'll matter a lot and for others it'll matter lifts and and you know people might want to take their choices there Suchi was just saying there's a very very active area of research within machine learning which is about building systems that that are much better at explaining why they got there and it must be in everyone's interest for that research to be to be supported and and strongly developed so it's president Peter and I were actually an event Royal Society Plus National Academy of Sciences event in Palo Alto and there was a young man who is making this very provocative statement the understanding of explain ability of AI on its face is silly and gave all of these very very good reasons for that all of which apply to us every single one reason he gave for not bothering to understand AI applies completely validly to understanding our own minds and I I hope we don't take that as a policy position of why bother understanding why we make decisions either because really it feels very parallel to me okay so let's get to another question from Jeremy perhaps we'll start with you sushi the question is given how much Google already knows of answers should we be worried about them guessing into health oh boy who's sponsoring this event again Google they didn't pay for my flights somebody dead I suppose well I mean I suppose we don't have to that was the question but we don't a specific company what we're saying is big companies have a lot of data about us in general Apple Apple also have a loss of data and they have nothing to do with this event itself good point but it signifies it so health I suppose it's the most personal of data in many ways I suppose that's the point yeah I do think I think that's a great question it's very interesting and it's half question I don't know if I can really answer that question with like five seconds of thinking but I'll take a crack at it I am concerned about I do think it should be concerning to us if a small number of corporations or decision makers have access to both a large amount of data and a lot of the requisite skill set and personnel to be able to develop these types of approaches so I do think it's important for us to decentralize but I don't think that should happen at the cost of us not having access so in other words if I had to choose a world where we could use machine learning that we could take advantage of a group of individuals who could develop really smart algorithms that could then allow us to improve healthcare I would absolutely support that and I'd prefer that over a world where we didn't have it but my preference would be we decentralized the development of these and be broaden out education we make funding available broadly and build systems where you know like the data isn't sort of held or bound by a single organization and people involved yeah this is quite specific isn't it because Google as a company are providing services right the NHS and so it's like in the UK's I think there are really interesting and special issues about healthcare data I mean it's true that Google and many of the other tech companies have a lot of information about us in a certain sense that's because we consent to it now you know we we tick a box after pages and pages and consent forms we don't read but but I think everyone thinks differently about healthcare system and health care systems certainly that the healthcare systems themselves do I know in our case in the UK it's something the NHS and our politicians think very hard about there's huge potential in the data from the NHS to analyze that in ways that will lead to improved efficiencies to better outcomes for individuals for people living longer avoiding complications being given the right drugs and so on the potential is massive in the data in large healthcare systems and in particular we're in a very special place in the UK because we have a single provider system so the potentials there nobody wants to kind of give that data away to companies well for two reasons first of all I think because we naturally think of the NHS as sort of our resources something people in the UK care strongly about rightly I think so any version of that data being used must have benefits both for the NHS and for those of us in the UK who are who are patients within the NHS system but also because we all appreciate that healthcare data is special and even more private so there must be and encouragingly there is a kind of serious debate going on as to what are the right levels of safeguards what are the right levels of anonymizing data that might then allow that data to be made available exactly for these potential benefits to accrue and I think the other thing to say which is obvious is that I don't think anyone would say it should only be the big tech companies that can benefit from that there'll be lots of small startups I shall run one myself but there'll be lots of small startups who can play a role in that as well so so when you think really hard about healthcare data we've got a fantastic opportunity in the UK but we absolutely need to get it right and understand the right way to respect privacy and anonymity the right way to have a dialogue with those of us who are all of us effectively who are patients and the NHS to make sure we're happy with that the benefits to do everything we can to minimize the potential downsides and that they're real that we can do things to minimise them and then to make sure we're happy that the upsides justified and my own view is eventually is huge but we need to get it right just add to that I think there's also this I mean I could imagine us this is it's certainly this way in the US where large and health systems which are large enterprises they prefer to interact with large corporations or companies because they inherently think that they're probably able to store the data more securely and keep it private and as a result you know implicitly they're creating a scenario where they're locking down the data with one or two or three large organizations I went to school in California in the land of you know startups and you know historically my experience has been that some of the most innovative and disruptive ideas come out of small groups of people who are mission oriented who are completely committed to making a difference and so as a result I think in this area at least what I see is this mismatch and potential where you know the ability to make change by small groups or small companies who may be well equipped but large enterprises are you know very skeptical or afraid to work with them so I want to expand this a little bit Health Care's great but it goes beyond that in my opinion and also expand beyond the question of data this is data has been a big issue here the whole idea of gdpr is to protect people's data health and education data data about kids are people everyone gets very productive in all over the world I've you know the one place where they're really productive about data internet for example is around kids but here's the thing if you don't actually have any ability to actually exert a right around your data and yes I realized through GPR there's a lawsuit mechanism but you know right now someone's missing using your data what are you gonna do about it file a lawsuit so that six months from now we'll lose in court you know that's not very satisfying right now one of the biggest advantages these large companies have and I don't think any of them are bad guys I've done collaborative work and been recruited to work at almost all of them it might say something that I never said yes but nonetheless they're not bad guys they are all guys for the most part is that they don't simply have masses of data no one else has available to them they have masses of talent because they have raided the university system and I'm not out here to tell anyone they can't go get a big paycheck but when Google will throw a million dollar bonus at someone just to keep them out of another company that tells you something about how they value Talent and they also have infrastructure which is hard to find anywhere else even for my own companies we can't run massive scale high throughput GPU systems on our own we don't build that stuff we use Google's so they have a monopoly on multiple multiple dimensions in this new AI space and that does genuinely concern me now we can actually throw in China and America themselves as formal entities as well a very small number of entities essentially control all of the computing power around artificial intelligence in the world and I could build a company and my best hope is to get it bought the likelihood that I will become a massive new competitor to Google or Facebook is virtually zero most of my work is philanthropic but I'm still under these same constraints I have thoughts about this but I just want to put out there instead of my own personal philosophy how do we think about how we as individuals are able to exert our own rights to how decisions are being made about us not just control of our data per se but the right the same way we have a right to judicial review the same way that we have a right to seek a second opinion from a doctor I should have a right to how AIS are targeting me with their ads I should have some participation in how these systems interact with me and right now none of us have any and I'm as empowered as you get in this space as you heard through my diabetes story but I am NOT going to engage in that because I I'm enough time in my life to build a separate AI to deal with everything and I think we really need to think right now our homes are filled with these little embassies embassies from Amazon embassies from Google from Apple from Baidu from Alibaba and these are our phones and our smart home systems and they operate under their own laws even though they're in our homes wouldn't it be great if we could think of how we could operate in the public interest in the public trust I don't necessarily mean governments because I'm throwing them in as part of that concentration of power how do we actually exert our right to make decisions about our own life okay well let's I didn't have any minute like that I thought I could the point is we could talk about that it raises so many issues but we've got about what 20 minutes left or so and quite a lot of questions and a whole section to get through right so very briefly but there's a couple of questions here which is sort of links about the future so maybe we could briefly address these one is them to look into the future to see where where a IO is AI is going in a in a biological sense the question is will there be artificial intelligence created on such a level that it can perhaps fight cancer and various of the diseases perhaps begin to I suppose it's looking at the potential in in biology so maybe briefly tell you that one how far are you away from AI has been used in that respect they're already being used not kind of just in their own right so science in biology cancer biomedical sciences there are increasingly larger and larger amounts of data our ability to read exquisite detail about biological systems is unparalleled and it's exploding rapidly we can study individual cells and realize in a cancer tumor for example we can realize what's going on that's different in each of the individual cells in the tumor and how some of those have some properties that ultimately lead to resistance to a particular drug regime and so on so that area of science is massively massively data-rich in a way that just hasn't been true for most of of bhaiyya certainly biology human biology history where AI systems will be incredibly helpful there is in helping us as scientists to make sense of the data to learn things from the data and that's already happening and it'll keep happening and and it will be one of the big drivers of the progress we make in fighting against cancer and in improving medicine more generally and there was from Jeff oh by the way that question um yeah I agree with Peter there I think the I kind of think of it as the spectrum from discovery to delivery so discovery is you know discovering new ideas about human biology how our body works how do we care try disease to delivery where we will figure out new and more efficient ways to get the right medications and the right therapeutics and to the right people and I think that entire spectrum in the last five to ten years has gone has been going through a transformation I think in the next 10 to 15 years we'll see some of the most exciting discoveries and even in our own work we've seen disease areas where physicians had a hard time diagnosing it but now by working with machines they're able to not only diagnose it sooner by getting treatments to the right patients they're actually seeing improvements and conditions I just went to ask this final question in this section it's a fascinating question actually someone said almost like a blade runner-esque question in a sense is from will and yes that in the future will there become a will be a section of society he calls it an upper echelon of society actually maybe the very rich who completely shun AI the firt forum for a more costly human experience so does it does it yet the ubiquity of AI yeah this is this is the version of wanting to use a travel agent when you can go even deeper than that human traveling in let me just go back so in the Royal Society's work in we tried to engage and get people's views and one of the things people were genuinely worried about in the growth of AI was a kind of depersonalization of experiences so it's a legitimate concern and it's something that people in general worry about and I think we should be thinking out about I'm actually thinking I will make experiences more personalized not less personalized because by knowing a lot about you you're able to identify you know imagine when you go on a trip you want to find the people who I very much like you see what they enjoyed and based upon that determine what would be fun to do and right now it's not really easy to figure out who these people are you know so again I've done a lot of work in education in fact in education as a term for this personalized education and the whole idea is to use technology and in particular artificial intelligence to target kids with just what they need but this is what I brought up before the difference between our aspirations and then the way it actually gets used so the term personalized education has frankly in common technological terms simply means we're on a fixed track are you and so it in a sense it profoundly D personalizes the experience of Education by putting on everyone on the same educational track and then it's personalized because it places you at some level if you're different than that sort of tempered that that trajectory then it doesn't account for you at all so it is possible for us to build those models tonight I do a lot of work that myself but the truth is it's a lot easier to build a much Dumber model that doesn't actually personalize everything it just has it as a marketing term and that gets really disturbing and disappointing but I actually want to offer a contrary proposal I very much understand this idea of and people have thrown it out there that imagine some day when only the wealthy can get their hair cut by an actual human being you know you need to exert your authority by ordering people around I have a real assistant not Alexa I have got real Alexa I actually think it will be the exact opposite so very early on I answered a question by talking this idea of general artificial intelligence versus the sort of thing we are now experiencing and I said I didn't know when if ever we would invent such a thing however and this is a bit provocative I think I can give you a very rough timeline for when there are people that are artificially smarter than other people so one of my fields of research in fact my core academic field of research is what's called neural prosthetics which is really the literal merging of computer systems and people so we have three organizations for example one is working on people that are locked in they look like they're in a coma we're building systems to allow them to communicate with the outside world another one is working in performance optimization and athletes less interesting to me but I get to learn things through the collaboration the last is perhaps the most provocative which is a company called hum and we're helping them build a technology which turns out exists you can go pre-order it right now it's a wearable headband so not yet jamming things in your brain but we're getting there so I'll take volunteers the survival rates are so-so and but in this case with the hum band you flip a switch and working memory increases by about 20% so I don't know if anyone's ever played the Simon game you know where you push buttons and colors in a row largely in this audience most people will be able to go up to about five six or seven patterns before you start to room you can't quite remember which pattern it was and we flipped the switch and it adds one or two to that memory span now that may not sound all that exciting but people with the larger market working memory spans literally live longer they go further in education they earn more money it's not true on an individual level but sort of at a population level if some of you are sevens and some of you are fives you will have much better lives and now we can build a device that makes you a seven now that's probably not what this device does at least you shouldn't be wearing it long-term trust me I'm not selling this to you it's steroids for your brain and God knows what the long-term implications are but we're helping develop this because for example kids with traumatic brain injury you know maybe they fell off their bike and in a moment who they were could have been was taken away from them and so we're developing a an intervention to be paired with it 15 minutes a day we flip the switch we do a deep literacy and math intervention and we try and put the pen back in their hand to write their own life story if we say no to technologies like that then we're saying no to changing the lives of all these kids but by saying yes to it we are saying that sometime in perhaps the not-too-distant future we might be fundamentally changing what it means to be human and the ultimate question there is for whom and I think if we're talking about the wealthy and these sorts of technologies it will be inevitable that there will be an effort for them to get the first access and to be it a sweet-16 gift for their kids actually work much better if you do it when they're babies and I love experimenting on defenseless orphans so so that's another of those clips it's going to be soon but is this a human right like a vaccine or is it something the wealthy get to do before anyone else does and and and it shouldn't be me that makes that decision no matter what I think of myself there should be a decision that we all make and right now I feel like that's not happening yeah or indeed the market which is the sense of it yeah the question ok well let's let's move on to the final section section 3 which is titled how do we get there so I supposed to see the route to the future to be so rather broader and there's a question from Gary who says the AI could be a brilliant opportunity to expand our knowledge should there be restrictions so that it does not become that knowledge doesn't become owned by big corporations I stated crosses over to what you've just been saying actually that's basically the regulatory framework so perhaps we broaden it to that sure I think there's a anything doesn't make sure of you know Hollywood painting movies with you know strange abstractions that aren't quite real depictions of AI but sort of evoke an image of Apocalypse and you know the Terminator and so on so what so I think that's motivating our understanding of what we need to regulate and how we need to regulate let's take a step back and go to the right like how do you regulate math I mean that's kind of a strange question should we be regulating math how do we regulate math if we go one level deeper the use of math and say you know making decisions to decide whether to insure somebody or not now we can start thinking about it in a much more concrete way which is yes we should not deny insurance to somebody with a pre-existing condition so effectively I think in the same vein for AI will need to go several levels deep to understand very specific areas where I will be used how it's being used and then determine what the appropriate regulatory framework will be and we very much need for other education to engage people from other fields you know to think about the ethics and the you know consequence of its use and in a variety of different scenarios and and is this really any more complex question than talking about any other new technology we regulate everything then we regulate aircraft we regulate cars we obviously you have to don't you say is there a specific issue here that makes it more complicated to regulate I think one part of it I entirely agree with su Chi is that we need to think very differently in different contexts and some of those contexts already have a pretty good regulatory framework so if AI technologies words we use they're not currently used but if they were to be used in flying aircraft then there's an incredibly strong regulatory framework that would be involved in testing them if they're used in medicine as new medical devices again there's a framework may or might may or may not be perfect for this purpose but there's a framework there that thinks about how to do the regulation so I think we need to think different because the costs of getting it wrong are very different from flying a plane to recommending the wrong movie from Netflix and we need we need to respect that and see the different context some of those contexts have good regulatory frameworks and some which near Vivian will have a better sense in education may or may not have them and and others don't have them or we need to start thinking about them but it but we should deal with it differently in different contexts you know I having guidelines and and regulatory frameworks principles being laid out I met with actually someone today from the UN they have a big council that sort of should we have some principles about how data and artificial intelligence get used in the world I genuinely appreciate these sorts of things but frankly I don't know how clearly people make decisions particularly decisions that are very technically complicated and be very hard to understand for anyone else about how they deploy these sorts of technologies out in the world you know one of the things I've heard is we should have ethics classes in computer science schools because it's worked so well in business schools I actually think this isn't a magic solution to anything but one of the interesting things and I'm gonna labor through a metaphor here but I used it earlier that artificial intelligence is an exquisitely powerful and sophisticated tool it can't make decisions on its own it can't solve your problems for you if you don't understand the solution it's very unlikely in my opinion that it will figure it out but it is immensely powerful and completely changing the economics of those solutions the problem as I see it and I'm not here to criticize computer science schools but I am going to say this that we sort of deploy this army of largely very young and certainly very male machine learning experts that have spent their entire very short career learning how to construct a hammer but they've never actually built a house they get given and this will be a little wonky but they'll get it they given these perfect data sets like imagenet and they're asked to solve pre-specified problems like name all of the breeds of dogs in these pictures but what they don't get is four year old with diabetes what they don't get is here's the hiring history of Amazon build a deep neural network that hires the right kind of people while Amazon tried to recruit me to do that and I told him it wouldn't work but they wouldn't had to did it anyways and if anyone read the news about this it wouldn't hire you if you use the word women's on your resume take what you will that says about Amazon's hiring history because that's where it learned it from but this is one of the most sophisticated companies in the world it has an army of machine learning experts that they brought in house and they ended up having to drag this thing around the back of the barn and shoot it in the head because it was unresolvable e sexist and they tried for a year to fix this problem by manipulating the data sets and manipulating the algorithm and it didn't work so I really want to be incredibly careful that may be part of this problem not the total solution but maybe part of this problem is actually training people on how to solve problems rather than how to build models we're almost out of time I wanted to get to the M there's a question I think we've covered the question it was in Nandi Sarah asks what impact could the growth of artificial intelligent have on society I think we've almost answered that in every question so but maybe I think in one word right let's say positive or negative let's do that just what impact do you think you'd have to answer almost all spheres of daily lives if we get if we as a society get it right we pay attention to it and we had involved actively as stewards I think the potential is huge and positive you are insist AI is used to make better people and I believe it could actually have a positive influence in the world or I wouldn't do this work right now I'm not so hardened okay and the final I can merge the final two questions actually one form in halogen one from Chris because they're very similar what one is do the panel think that we will ever achieve a general AI or will it remain a fiction and a related question I think which follows on from that of the answers yes is do you think we will always have control over the AIS in our society even if they begin to demonstrate higher intelligence than humans so there's two related questions there this is an exciting one yeah so since I get to study brains and machines I fundamentally think we are a phenomenally complicated computing system nothing like any of the AIS that anyone's ever put together on an actual computer but in that sense theoretically there's no reason why we shouldn't be able to do this practically speaking is a different question we'll need a whole new set of models so I got to do this one really fun thing once at a conference I got to debate this guy named Ray Kurzweil on stage about artificial intelligence so he wrote a book called the singularity is near about the emergence of super intelligences he thought it'd be great like they'll make so much better decisions they'd never vote for brexit sorry and or trump or what have you all right clearly not everyone agrees with that but the but you know we had this sort of debate about super intelligences and so forth and one of the things a lot of people don't even think about is if we invented something like that wouldn't even care about us would in fact even have a conversation with us where somewhere we might need such a super intelligence not to drive a car because we already have dumb intelligence that can do that us and the existing systems maybe to manage the entire transportation network of Britain something that has to manage this massive distributed system and optimize all the pieces it doesn't have two eyes it has millions and millions of them and ears and bodies all spread over what the hell would it ever even have to say to us what would it wouldn't it possibly be so alien that it understands we're intelligent and we can infer that it is but it manages transportation and we manage our lives and there's nothing really to exchange there we want to think that it'll desperately want to talk to us that'll be just like we are but I think that might be a it certainly divorces itself from a lot of research about what's called embodied cognition and how much of who we are is the very body that we inhabit well that's a wildly different body III I think we we shouldn't think that to echo Vivian's point we shouldn't think the technologies will kind of be like us in any sense in the in the early days when people wanted to fly what people did and I'm sure you've read about it or even seen paintings all that people kind of stuck feathers onto their arms and flapped their arms quite a lot and weren't very successful at the flying thing and so eventually we came up with a technical solution for flying which is actually really different in many crucial respects from the way it happens in nature and it's very very likely to be the same with artificial intelligence both specifically and the systems that are there now do them differently from the way we do it and and in terms of general intelligence will it ever happen I think it would be brave to rule it out but happily it's a long way off I think we should try to understand what AGI is I bet you if we interview 10 experts in the field they will give you very different answers for what is artificial general intelligence in general they'll all say it's much smarter than whatever it is we have now so I think part of the challenge is it's this as soon as we start to understand something we call it AI and whatever we don't understand that's AGI so it's kind of a strange thing to describe so I think we have algorithms we'll continue to build algorithms to solve problems I don't know we have V I don't think there's any evidence or imagined evidence of a version where we see the superhuman or supernatural or algorithm that can exhibit behavior we're you know often we're humanizing it right in the go player it's very easy to understand what it's doing in search face but we go back and we are putting human-like qualities in it to see its thinking it's stepping back it's coming back it's trying to trick you but all it's really doing is searching through board configurations to figure out what's the right thing to do it's amusing it's whether we them we'd you'd have to choose to build one I mean if you suggested if you have a system that's really the global transport network I say then okay I suppose what many people's fear is this science fiction fear that the thing is is so intelligent running the transport network it decides to run everything else as well of its own accord kind of thing so presumably we talk about AGI if we if it is possible to build one so the question is would we have to build it with the intention of building it or could it somehow emerge from a lower level complex system so I will say this and it's actually a debate very literally that's going on in our field right now which is are the current technologies specifically deep neural networks enough to someday create a GI or do we invent need to invent something completely new I happen to be in the category that thinks we need something dramatically different but I will and and part of my belief there is just maybe hopefully to put some concern harassed you can add more processors to our existing system you can teach it more things you can show it more newspapers you can play it the BBC on a constant feed all the time everything in the world it will never wake up it will never have an opinion about the issues of the day it will never approve of Trump it's supposed to be smarter than us right it just that sort of thing is not going to in some sense magically emerge your toaster is never going to wake up and threaten our very existence but could we invent something new might that lead to this again I see no theoretical reason why that's not possible it's just I don't know what form it takes and I don't know what infrastructure it takes example there like right now we have computer systems that control you know the basic public utility system like water electricity and what if we had a different you know algorithm or computer come in and interfere and take down a node by you know clogging it with traffic and such or hacking the system now would you call that a GI that particular example I'm describing is very possible today basically by building a system that has very you know where points of failure very concentrated you can go attack those points of failure and the system can go down and you could now easily attribute it to a GI but I think all it is is you know computers that are optimized to build an objective function and often we're programming them to do that but I do love one of my favorite examples though of a system waking up is I'm blanking on his name so if anyone's going to get the reference pull it up a Scottish writer who wrote a murder mystery and it's just it starts off purely as a murder mystery and then it turns out what's happening the thing that all these people have in common is that they run spam they're all a bunch of spammers a spam bot training getting more and more complex and the constant cat-and-mouse game against spammer reaches sentience and realizes the way to stop the spam is to kill the people producing it in the first place and that's what the police eventually figure out in the end and you know again I don't think that anything like that is in the works right just me yes it was pure fiction but there are some things out there that are genuinely exciting that still don't require us to reach AGI and some of them that are kind of fearful it doesn't require artificial general intelligence to build autonomous weapons and program a little drone with a bunch of c4 packed into it too literally recognize my face and just zoom in as fast as it can and make a smart bullet for lack of a better description it doesn't require artificial and general intelligence to build technologies that keep autocracies in power some of the out the very first system I ever worked on 20 years ago my introduction to machine learning was building real-time lie detection systems for the CIA now that is very morally gray needless to say it was incredibly cool I would just read people's facial expressions and by the way we were able to later use that same system or I used those same algorithms one case to build a system for Google glass that could read people's facial expressions for autistic kids to learn how to read facial expressions and another case to reunite orphan refugees with their extended family in refugee camps around the world so it's not always so clear what's a good and a bad technology but I will say some of those algorithms we developed 20 years ago one they're all in your iPhone 10 I mean literally that lab got bought as a start-up by Apple so we power all of your faces stuff so if you are have you ever done the an emojis so you can sort of smile and talk into your phone and it animates a cat that cat is 50 million dollars worth of CIA funding all innovation in the end animates cats on phones but at the same time those algorithms are being used I think someday we must surely have a smart toaster that's maybe just a little too smart so but the last is that those same algorithms are now being used in western China in ways that I fundamentally disagree with but you know this was just academic work we published our algorithms and now they're out there and I you can't always necessarily control these things that's right norm setting norms are so important just finally just to go right back to the start I mentioned the Turing test at the start so just an AGI right how do you define it is that something that passes the Turing test is that the definition really we perceive the thing to be intelligent if not what is the definition so let's quickly go with I think it'd be really worthwhile for an ever so slightly deeper definition of the Turing test so the Turing test is that there are sort of two black boxes and I'm asking each of them questions and I'm getting answers out of them one's a person one is an AI and they're both trying to make me believe that they're a person and then if I run this test over and over again I am at chance at getting it right a lot of people throw up in the news hey Twitter or Facebook just beat the Turing test because you know someone got on a phone and they heard a voice that sounded like a person and so it beats no no I have to be actively trying to trick that was Turing's actual thing and I'm not saying it's a magical test that's right or wrong just it has a lot more nuance than people put to it so if someone could violate the Turing test where you're actively trying to figure it out and over time there's no difference I'm not saying that's the magic ingredient for artificial general intelligence but you have to admit you might just as well have a conversation with one of them versus another one and there probably is some point at which the differences for specific tasks maybe don't matter that much yeah I just want to say one thing you sit me next to an extraordinary woman who sort out one weekend her son's diabetes and gets all the day that she unites orphans with their families in far-flung parts of the world helps autistic kids and I agree with it from time to time you give me grief for agreeing with them I agree [Applause] well you can have the last word if you'd like I think in that case of Turing test that you described if somebody told me here are the six things or seven or eight or nine or ten things we're gonna test the Turing test on I could set up ten deep Minds each one's gonna work very very hard on one of those and then I'm gonna cycle between them so that the human on the other side is kind of working against a very competent machine I could easily see a scenario where you know we passed the Turing test so I still don't think that's qualitatively very different from where we are right now in terms of so I'm not sure that definition of the Turing test is very relevant and defining AGI I don't think we have a good one I think that's what I started my premise with which is I have a hard time understanding what human intelligence is it's really hard to think about what is AGI I think that's a very good place to end so thank you to everyone that thank the sensing questions and we've not been able to ask them all tonight but then we do encourage you to carry on the conversation keep asking questions the Royal Society website it's got a lot of background information on this area if you're interested but for now I'd just like to say could we thank this superb panel [Music] thank you very much thank you good night I'm gonna ask you what you thought you 