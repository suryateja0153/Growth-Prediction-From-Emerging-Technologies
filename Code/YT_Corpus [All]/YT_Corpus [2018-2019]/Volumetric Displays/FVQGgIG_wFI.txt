 JOI ITO: Good  morning, everybody Welcome to the  Media Lab I'm the director here. My name  is Joi Ito. And I'm  super excited. As somebody whose only formal accreditation  is scuba instructor trainer, this  is sort of -- and this is actually --  becoming an Explorer was the  thing I was trying to do before I got recruited  to the Media Lab. So I  feel like I'm coming full circle. And actually a year  after I joined, I met  Jane Wilson from the New England Aquarium. And I  had been talking to  her about ways to collaborate, hoping that  a collaboration with the  aquarium would allow me to continue to work  on my passion for the  oceans. And then later in 2014 I think it was  I met Katy Croff Bell and  recruited her to be a directors fellow. And she  started bringing ocean stuff  to the Media Lab. And she was I think  the Chief Scientist of the  Nautilus project then And that was -- most of  you probably know. But it  was this wonderful project where there was a boat  that would go. There was an  ROV. And a lot of students could build things and  deploy them on the vessel.  So she ran a series of projects for  our students and faculty.  Really got engaged and started to understanding  oceans exploration through  actually doing things But it's been a  while. And it's taken a  while. And we've been in conversations with National Geographic through -- with the  help of Katy for many years trying to  get this going. So this  is sort of the inaugural event. And I see Dava  here, as well. I think there's  -- the general idea of exploration -- so we  have a space initiative that  we're working with Dava and others on at MIT,  which is -- just broadly  I think exploration is a tremendously important thing  for academia to be  involved in, for humanity to be involved  in. So there's sort  of an interesting sister relationship between the oceans  and space. And I  know often when we talk about climate, we  talk about the atmosphere.  But obviously oceans are really an essential  part. And I think just  focusing on atmosphere isn't enough. And also for  me, there's really a key  relationship with what we're working on at the  Media Lab. We're very excited  about things like the idea of protecting  climate through the protection  of indigenous people. And there are some  really great efforts in Cook  Islands and other places where you see  the indigenous minorities working  on conservation efforts and understanding it at a deep level is one of the projects that we're working on. There's obviously the engineering of exploration and understanding the oceans.  And most important,  I think, getting passionate about the oceans.  At the Media Lab we  have a group called Lifelong Kindergarten. And they  have a thing called they  call the four Ps of creative learning. So their  view is -- this has  a long lineage that starts with Piaget and goes to  Seymour Papert. And it's a  whole idea of learning through doing, which is a  key piece of the Media  Lab. And the Media Lab, for those who haven't  been here before, we're  an academic program. But we're peculiar at MIT because  we're also a lab. So  we're the only lab that has our own academic program.  And the part of the  reason we have that is we think we  learn best through doing projects.  So we say through construction rather than  instruction. And when we  talk about creative learning and we call  them the four Ps, it's  projects, peers, passion, play. So there's about ten  years of pedagogy that  shows that learning in textbooks isn't as  effective as learning through  doing, doing projects. And I remember when I  teach -- my favorite thing  is teaching scuba to junior high school kids.  Because when the teacher  drops the kids off, they will say, watch out  for those two. They are  troublemakers Or they are not good students. And they  are always the ones that  are the best scuba students. Because they get  excited. They learn the  science. They want to figure out Boyle's law. Because  I can tell them, you're  going to need to learn all of this stuff  because you're going to be  out in the ocean pretty soon and these things will  be useful for you. And  the kids who are interest driven and passion  driven I think really are  attracted to these four Ps. So projects Peers,  which is learning together  and learning with each other, which is another I  think key element of exploration  and the kinds of things that we do.  And passion is tremendously  important. We don't measure passion in education  But passion actually is  the reason why most of us are here  and the reason people get  so involved in something that they are able to contribute to the field. And play is the last P. Which is the idea that it has to be playful. It has to be fun to get the creative juices going. There's a lot  of research that shows  that pressure and financial returns can get people  to do incremental and linear  work. But it's very difficult to get people  to be extremely creative unless  you have a sense of play. So I'm looking  at the program and seeing  everybody here. I think that this conference will  be full of the four  Ps, passion, peers, projects, and play. And I hope  that we can move the  field forward by getting everyone excited about  it and advancing  science. Thank you. (Applause).  ALEX MOEN: Good  morning, everyone. I'm Alex  Moen. I'll start by saying, Here Be Dragons, I  love that name. I did  notice on the MIT Media Lab Web site that there  was another event called the  how to make breast pumps not suck hackathon.  And I think this  is a little catchier. (Chuckles).  ALEX MOEN: This is  great. So I just want to  start by out saying thank you to Joi, Katy  and the MIT Media Lab  for hosting this summit of idea generators  and problem solvers. So  since 1888, National Geographic has been  pushing the boundaries  of exploration, better understand our planets,  better understand ourselves  as human beings, but with the ultimate  aim of trying to secure  a healthier, more sustainable future. a planet in balance,  as we call it. And I  notice that the Media Lab's mission is to design  technologies to make a better  future for people. And I think that that sounds  very complementary to me. And  a great kind of foundation for collaboration So  I'm Alex Moen. I  head up our Explorer Programs. My team and  I are focused every  day on essentially empowering our  scientists, researchers,  conservationists, storytellers, technologists, educators. And you  know, ultimately the idea  is that these individuals are the ones who  are going to be driving  change. And we have several of them in  the audience. And actually who  are going to be participating. Can I just  get some hands? Yeah,  great. These are Explorers,  National Geographic  Explorers. (Applause).  ALEX MOEN:  That universe and  community. And I'm lucky. I get to  work with them basically  on a daily basis. And I consider myself very  lucky to do so. Most  of the time, Kenny. (Chuckles).  ALEX MOEN:  So anyway, extremely excited  to be here. When Katy came to  us and said, I've  got this great idea. National Geographic, MIT  Media Lab gets  together. You know, kind of leverage  bleeding edge technology in  support of exploration. I said, this is  fantastic. This is great. You  know, what a great project for Katy as a  new National Geographic Fellow. But  this is also a great way for us to kind  of test and pilot new ways  for us to extend our ability to support Explorers out  in the field. And that's  one of the ways that we empower. We  empower our Explorers, yes,  through funding. But also through training.  Through mentorship. Kind  of elevation. Recognition. And access to  tools and technology. And  the timing couldn't be better for this. Because  we just have recently brought  on a new VP of our Nat Geo Labs  Fabian Laurier, who is with  us actually. Fabian has been working feverishly  in developing a strategy  to really drive exponential growth in  terms of better understanding,  exploring the planet by scaling up  break-through technologies, finding new ways to measure and visualize the vital  signs of the planet. And  then also trying to mobilize a whole new  army of citizen explorers.  So basically we're building that capacity both  internally as well as  working with important partners like MIT Media  Lab. And really trying to  push that forward. So this is really happening at  a perfect time. So just  in closing, we're very excited to be here.  Looking forward to not just  the identification of the challenges that we face  in terms of ocean  exploration and storytelling. But actually the creative,  rapid and urgent ideas that  are going to come out of this in  response to those challenges.  So thanks. And thanks especially to Katy for bringing  this idea, for organizing all  of this and for making it  happen. So  thank you. (Applause).  KATY CROFF  BELL: Thanks, Alex and Joi.  And thank you all for being here today.  My name is Katy Croff  Bell I'm the founder and lead of the  Open Ocean Initiative here at  the MIT Media Lab. And as Alex said,  a National Geographic Fellow.  So I started down the path of  exploration when I was  an undergraduate student here at MIT in  ocean engineering a couple of  years ago. And it was really after my first  research cruise when I was  a rising senior that I dedicated my career to  exploration of the ocean, be  it looking for ancient shipwrecks or new species  or new geological processes,  and sharing our discoveries with the world.  But in the past few  years, I've noticed that there have been so  many technological advances in  other industries that haven't yet been applied  to oceanographic challenges. Really  on a large scale. There are little pieces  and little seeds of things  all over the place, which is fantastic. But we  really need to bust this  open. So it was just over a year ago that  I went to Alex and  Joi with this cockamamie idea. And fortunately, they said  yes. Really to bring  together the strengths of these two wonderful  organizations. The creativity  and the technology and the irreverence for  boundaries of the Media  Lab along with the global knowledge and the  reach of National Geographic.  So that we could really start to  deploy and design new  ways to better understand the ocean and connect people  to it. So that we  can empower a global community of explorers to  better take care of and  ensure that our blue planet thrives. So  today and tomorrow we're  bringing together explorers, scientists, engineers, artists,  designers. Not just  from the oceanographic community but also  from neuroscience and aerospace  and genetics and agriculture and music. So  that we can really  get together and identify what are those gaps that  still exist. What are those  dragons that are still lurking at the edges  of the maps. Are they  in scientific knowledge, in technological capabilities, in  storytelling, in community  building, in passion and in play? So  we have an amazing two  days lined up. But I really believe that together  we will really be  able to discover the unknowns, to unlock those  mysteries and the wonders  of the oceans. Because the ocean really is  for everyone. So to do  that, we have a few logistics here. So at the  end of tomorrow, we are --  our goal is to come out of this event with about  10 to 12 teams to pose  rapid -- or pitch rapid field deployments. These are  projects we hope that will  be -- that will move the needle on  both better understanding the  ocean and connecting people to it. They should  be deployed within about the  next 6 to 9 months. They should be  uniquely suited to the  combinations of the National Geographic and  MIT communities. They  should be innovative, impactful, compelling to  a broader audience and  achievable within the timeframe and the  resources available. And  National Geographic -- excuse me -- has  committed up to $200,000 to  support some of these projects that we'll be  pitching together tomorrow. So  tomorrow -- sorry; today we have an  amazing array of speakers, both  on panels and as Lightening Talks. I think the  count is up to like  60. And I got reprimanded yesterday for too much content.  So get ready for the  fire hose. We also have about a dozen demos  out on the main floor  here and an art exhibition for the reception  this evening down on the  5th Floor. We also have a graphic facilitator,  Marcia Dunn, who will be  over in this corner taking notes in a graphic  form on all of our  ideas and discussions that come up over the next  two days. She also, as  she finishes panels, will be bringing them out to  the main floor. So please  definitely come either here or out there to check  out her work. She has also  set up a project board and an opportunities board just  outside of this room. So  as you think of ideas or as you see  other peoples' ideas going up  on the board that you might be interested in joining  a team, please put them  up on the wall so we can start to  coalesce them throughout the day  and really hit the ground running tomorrow. If  you have opportunities available,  you have a particular expertise or ship  time or fieldwork destination,  a secret talent that you might want to  share, also grab a Post-It and  put that up on the board. I'm super excited to  share the next two days  with you and beyond. I couldn't be more thrilled  that this is happening. And  I would now like to introduce our morning Keynote  Speaker, Robert Ballard. I  met -- oh, my picture didn't go up.  That's too bad. Sorry. Did  you take it out? You talked  to Carrie. There  we go. (Chuckles).  KATY CROFF BELL: So  I met Bob here on this  campus about 20 years ago. And I've learned a lot  from Bob over the years,  for better or for worse. (Chuckles).  KATY CROFF BELL:  But one of the things  that has really struck me the most and has  really had a huge impact  is that he's really shown me how  critical it is  to combine rigorous science with compelling  storytelling to move  ocean exploration forward. From going to sea with  some of the best --  the very best ocean scientists and engineers  and using telepresence  to share our discoveries with the world,  to having a National  Geographic film crew on board filming a  multi-part series while discovering  dozens of shipwrecks in the Mediterranean Sea,  to sharing what we do  with Members of Congress and telling them just how  critical the ocean is for  us, for the country and for the world.  And doing all of those  things simultaneously. Of course. So ladies  and gentlemen,  Bob Ballard. (Applause).  ROBERT BALLARD:  I won't use  the ramp. (Chuckles).  ROBERT BALLARD: I  need your clicker. And in  sort of true National Geographic tradition, I  feel like Louis  Leakey just being introduced by Jane Goodall.  Most of you have  heard my speel. Like TEDTalks I'm  standing on a  trapdoor within 20 minutes is going to free fall  me into a pit of dragons.  So I'll try to stay on -- I wanted to  say something different. Because you know what I would normally say, ocean exploration  is critical. It's so  important to the human life. But you know that.  And it's sort of like  we're talking amongst one another. But I've been  thinking about where we're  headed as a species. And it's not in a  very good direction. And I'm hoping  -- because all of you are storytellers -- that  maybe after a few minutes,  you might modify your future storytelling and add  a few other compelling  reasons on why the ocean is so important to  the human race, to its  survival. It takes a village to tell these stories. As  you know, you saw me  a moment ago with Katy with my Ocean Exploration  Trust baseball hat on. And  I have quite a number of hats I  wear. Because I don't think  any single organization can take on the kinds of  challenges that we need to take  on. So it's really all about partnerships. And  you see what's happening  here today between MIT and National Geographic,  with Katy there throwing  the gasoline on that fire, is a classic  example of how critical it  is. But the challenges that we face as the human  species, the big question is,  are we a failed experiment? And I would  say there's pretty good  evidence pointing that we are headed into a  failure as a species. And  it's simple. Read this. From our -- right up  the street. Even in the  case of maximum efficiency in which all grain grown  are dedicated to feeding  humans, in other words, everyone is a vegetarian,  the planet still has a  limited capacity to support the human species. If  the world population ate  like American omnivores, plant production would only  feed 2.5 billion human  beings. And we passed that number in 1920.  So do not export to the  rest of the world our model of food consumption.  It's a failure. Absolute  failure. Look at this number. If you want to  see -- so what is  the maximum carrying capacity of our planet based  upon these calculations? And  that's a huge assumption thrown into that  curve. And that's that  the annual growth of the world population will  continue to climb past  its lowest point ever. What's the probability? Is that  going to really, really happen?  But if it does, that rosy set of glasses  really occurs, we hit 112  billion in 2100. 80 years from now. 80 years  from now. Your generation are  going to be the generation that lives with  the consequences if we  fail to meet those numbers. And even if  we do. That's sobering.  It's not your grandchildren, it's your children. It's you.  95% of the human race lives  on less than 5% of the surface of the  earth. Obvious reasons. 72% of  our planet is oceans. And 40% of the  28 is uninhabitable. It's  polar regions, extreme desert environment. 95% of us live  on less than 5% of  earth. That's where our farmlands are. 95% of  the living space on earth  is in international waters and largely unexplored. So  there is hope. There  is hope. There's a tremendous amount of living  space that we're just not  living in. Look at what happens -- and  those curves that I  initially showed you assume steady state farmland. It's  worse than that. This --  5 million acres of farmland disappears on  Planet Earth every year.  We're building houses on them. I grew up  in Orange County California. You  know why it was called Orange County? It  grew oranges. There isn't a  single orange tree in Orange County. I have a  picture I didn't have time to  show you of where I lived in the '40s and  '50s in Los Angeles when  it was all orange groves and what it looks like  today. It's all gone. Look  at that consumption. In my speech -- we'll lose 25  acres, while I give my  talk, of farmland. It's going, it's going, it's going away.  So clearly we must turn to  the sea to find our food. Problem. Our  present fisheries are based  upon a hunter-gatherer society. And we have  already consumed 90% of  the large fish because we are eating the lions,  the tigers, and the bears  of the sea. We're eating the lions, tigers and  bears of the sea.  11,000 years ago humans domesticated sheeps and  goats, cultivated wheat and  corn. And from that we went from  a hunter-gatherer society to  a farmer-herding society. And we began to create  the city states that led us  to where we are right now. But not the sea.  We need to move away  from a human -- hunter- gatherer society in the  sea. And like on land  become farmers and herders of society. We should not  be focusing on sustaining the  life in the sea. We should be focusing  on vastly increasing the  productivity of the oceans. I was born  in Wichita, Kansas, where  all oceanographers come from. And back then,  before my family homesteaded in  Kansas, we had a Prairie grass. It took 24  acres of Prairie grass to  feed one buffalo. And that's why the buffalos  went all over the  place. Because they quickly exhausted where they  were standing. Like all  hunter-gatherers, they are, too. They had to move  on. Until someone says, you  know, why don't we take that acre in Kansas  and plant some corn? And  all of a sudden that productivity of that 1  acre increased dramatically. So  it's not about sustaining the ocean.  It's about increasing the  ocean's productivity. Let me just back up for  a second. Could you back me  up for a second? I'll show you another one in  a second. But basically what  we need to do is this cage that you see  -- this is fascinating --  I did a program with National Geographic a few  years ago on options for  the human race. The Alien Deep. And this was  a project I was introduced  to off of Hawaii by an open ocean mariculturalist  in Australia by the  name of Neil Simms. And Neil had taken a  predator fish. We call it  -- in the sushi restaurants we call it hamachi. And  hamachi is yellow tail sushi.  And it's a reef fish. And it's a predator. And he  took that reef fish and he  gave it a choice. He took it out in the  ocean off Kona. Way far from  land. So there wasn't a mariculture program near, which  is a big concern. When  I was on the President's Commission in ocean  policy, I was always  amazed at the battle going on  between the environmentalists  and the mariculture people. They were absolutely  at war with one another.  And I had the ability as a Commissioner to  get in the middle of  this fistfight and ask some questions. And one of  them was: Why do you  hate this guy so much? He's raising predators.  He's doing it in near  shore in pens where they are polluting the  local habitat and could  possibly infect the natural system. I said, that's -- I  hate you now, too, now that  I hear that. But in this case they took the  predator far away from the  reef systems. They went out in 12,000 feet of  water. 12,000 feet, miles and  miles from the coast of Kona. And because Kona  is like a ship going  through the ocean and there's huge eddies behind  it and you can  see those eddies from satellites. You can take these  cages. Put the finger lens  in it. Go out and set it in the eddy. Put  it down 90 feet so no one  ran into it. It's gone. And it would gyre around and  gyre around. So it was  free floating. And if it moved too much, they would  put it back in the  eddy. So after 6 months they came to market. But  they gave that fish a  choice, you're going to go out into fundamentally  sterile water. People always  say, isn't the Caribbean wonderful? Yes,  there's nothing in the  water. Remember, that the colder water has  the greatest carrying capacity  of nutrients. That's why all the major fisheries  are in the high latitudes  and the water is a little murky. Because there's something in it. So they are  taking a space, a tropical space, and putting  these cages and then  giving that fish a choice, eat soybean or die.  And you know, it's a  pretty smart fish. It said, well, putting it that way, I'll  eat it. And then I asked  him, I said, what does it taste like? So he  FedExed me two of them  the moment he harvested them. It takes 6 months  to come to harvest. Just like  a pig, 6 to 8 months. And I had a  sushi party. And I snuck in  these fresh -- and they were -- these are really  -- I mean, they didn't  realize they were eating farmed sushi that had  been fed soybean. The problem  with that is it's soybean. And now they  are looking at how do  we get off land-based plants to feed these  guys. And actually what's  really amazing these guys are in cages and then  when they poop, it drops 12,000  feet and they get a carbon sequestration credit. Or  they capture -- now  they are capturing the poop and growing algae  feed and they are closing  the loop. That's what we need. So we need to  be able to do that. And  then -- and this is where MIT and all of  our talent and technology  is completely automated, robotically done. And the living  space, as I said, it's  vast. 95% of the living space. There is hope to  feed us. But it will not  be eating angus cattle. But we also have a problem.  Only 50% -- 60% can  swim. 4 billion human beings on earth can't  swim. More than 60% of  Americans are afraid of the deep ocean. And 45%  are afraid of having water  over their head. So it's really hard to  excite people about the ocean  when they are absolutely terrified of it. And we need  -- and I think some of  us are guilty of it. We need to stop terrifying  people about the ocean.  The chances of being eaten by a shark, you  have a far greater chance of  dying from a bee sting. But we make it this  great white shark. You go down  to the beach and it's waiting to eat you. Well,  that's not the message you  need to be sending. But more importantly, we're  not going to depend  upon humans going there. We're not asking the  human race to go out and  live on the ocean or live under the ocean,  which is absolutely insane. The  thought that a huge number of people  would live in underwater  habitats is absolutely ridiculous. It's not going to  happen. They say -- when  we go out on ships, we have a joke  on oceanographic ships. The  only difference between going to sea and prison  is the added risk of  drowning. We go out there but we're land animals. And  we will want to not go  out there. We go out there to have fun. So  we need to overcome our  fear of the ocean and stop terrifying people about it.  And not say, you're going  to have to go out there. No, you're not going  to have to go out  there. Teach them how to swim would be a  good start. But tell them  how important this potential economic engine is  to their survival. Open  ocean aquaculture. Promote firsthand experiences with the  sea. And engage audiences,  as we work so hard to do, in  the process and make it  enjoyable. I always love Walt Disney's motto. And I'm  so excited about Geographic  teeming up with Disney. Because I guess  my ship is named after  the Nautilus. Hello. I grew up as the Disney  kid in Los Angeles. I  was the first kid to Disneyland. Because I camped  out overnight to get to  be the first kid. Because Disney's concept was  to educate, you must  entertain. It needs to be the wonderful story  that you're telling, not a  scary one. Don't scare kids. They are getting scared  enough as it is with  the society they are living in right now. So  as Katy said, we acquired  this ship, the Nautilus. It's an interesting story  of how I got the  Nautilus. Because for many, many years I stood in  a mirror and said, never own  a ship. Don't own it. It's a hole in the ocean  in which you pour money into.  And then I got this itch. Because we were working  -- as Katy said, we  were working in the Black Sea. We couldn't get  any platforms out there. No  one wanted to go out -- it was Putin's  country. No one wanted to go  over there. It was hard to get ships in the  Black Sea. I remember having  to get one from Rhode Island to get all the  way across -- remember that, Katy?  Had to go all the way across the Atlantic  Ocean and all the  way across the Mediterranean and work for a little  while and then going all the  way back. I spent more time transiting than I  was actually on-station. So I  decided let's get a ship. I asked Jim Newman,  my project engineer, let's find  a ship. And we only had a million bucks.  We didn't have a lot.  And I kept losing. And finally this -- the East  Germany -- and Germany, as  you know, is unified. And West Germany wanted to  get rid of a lot of  stuff. And they had an East German spy ship  called the Alexander Von Humboldt.  I was in naval intelligence. I knew that ship  well. And I said, we have  to get that ship. I just have to get a spy ship.  It sounds so cool. And I bid  on it and I lost. I lost that one. And I  was really upset. Because I  wanted it. It had potential, as they would say. It  was a hydrographic ship. Get  rid of all of the satellite spy stuff and all  of that. So I sent Jim  back to Germany. I said, take the guy out. Buy  him a bunch of beer. And  find out who the hell bought this ship. He comes  back and he said, some  guy -- a high speed hedge fund guy named Vinny  Viola. Wow. So I Googled  and I found his name. And he had his  company. But he had gone  to West Point and he was an Airborne Ranger before  he went and made a  billion dollars. And I called him up and I  said -- well, he didn't  answer. But someone answered. I said, I would love to  meet your boss who just got  this ship. He said, let me talk to him. I'll  call you back. Five minutes he  said, he would love to meet with you. Come  down to the Waldorf Astoria.  Stand at the clock. And at noon Vinny will  come out. Bing, bing, bing. And  I thought he was in the clock. But anyways we  sat down. We had lunch.  And i said, Vinny, why did you get this  ship? And he said, Teresa --  that's his wife. If you said, my cousin Vinny, that's  his wife. We have three  kids and they have gone off and they are  now having families. And we  thought if we had a ship and had a lot of  fun with it, we could get  the kids to come and we could get together and  go and have a lot  of fun. 220 foot ship. Yeah.  I said,  what a dad. (Chuckles).  ROBERT BALLARD: You know,  I said, let me tell  you I would more than gladly let you come on  my cruises. So he said, well,  why do you want it? I went off with this  to boldly go where no  human being has gone on Planet Earth and gave  him my elevator talk. It  took him about 39 seconds to look down  and he said, I am  so ashamed of myself. Your reason is so  much better than mine. I'll  give you the ship. And he gave me the ship.  But its mission, as we say,  is to -- it's an exploratory platform. And because  of that, we don't  know what we're going to find. So  we needed to introduce the  concept of telepresence to be able to call people  into the game and deliver  the brightest mind to the spot of delivery within  minutes. No matter when. No  matter where. But it also gave us the opportunity  to reach out to the  public. And one of the critical things, as you  can see, I'm practicing what  I'm preaching was I told Katy, I told Allison and  I told Nicole, I said, we  want to have the core of exploration. Lewis and  Clark were the core  of discovery. So we're going to be the core  of exploration. But unlike Lewis  and Clark, I want the core to be 55% women  in positions of leadership and  authority. Why did I pick 55%? Because that's  the population of college  campuses. So I could defend myself. And I also  said, beyond 55% -- once  in a while Katy would get us up to 60%. And  I would have to say, Katy,  you promised that -- and so I also want to have  the faces -- there was a  wonderful ad in the United States called the United  Shades of America. To make  sure that a child can find their face and  know that they can play in  the game. We could do a little better job  today. We need to have  much broader representation of the population. So that has  to be another thing that  you carry out of this room is you need to  really work hard to make  sure that we engage everyone in the game. As  you know, we have a  great Web site. We have ask a question.  Last deployment we took  and answered 30,000 questions from children because  we work 24 hours a  day. But this, again, is part of the  National Geographic family. I  married National Geographic. My wife, Barbara, I met  her at National Geographic. And  she was head of special projects for National  Geographic Television. I became  a special project. (Chuckles).  ROBERT BALLARD: But  they then gave us  their complete television production studios. And so  at the interspace center  we have installed an amazing production  capability. There's Katy  reaching out. And through that engaging  kids in the process.  So it's very important to engage as many  human beings as you can  in the game. And we focus on middle  schoolchildren because the game is  win or lost by middle school. Middle  school is when children  create their passions. Passion is the driving  engine. Mine was to be  Captain Nemo. And my parents didn't laugh. And I'm  sure they went in the  other room and said, Houston, we have a problem  here. But they worked with  it. So never laugh at a child's passion. Just  sort of morph it a  little. So middle school is where the game is won  or lost. So we focus a  great deal there. And we go to every conceivable place  you can imagine. And then  we have -- if any of you want to sail  the Nautilus, please look at  our Intern Program. It starts at age 15 and  goes all the way up  to collaboration with postdocs and researchers. But  the Nautilus is a  constant learning experience. Constantly mentoring young people.  And then putting them  in the hot seat. Here we are lecturing.  I'm getting them ready to  go. And then we put them in the hot seat.  And they know it's going --  they are going -- I must admit there's a  special one. That's my daughter  Emily Rose in the middle who started to go  to sea with me at 15.  And has lived on the Nautilus. This coming summer will  be the first time she's  not on it. She's finally in college. She said,  Dad, I've got to get a  job. But it's all about moving as many as we  can through that process. So  I want to thank you. But hopefully those early  comments had a little  impact. Because we don't have a lot of time.  And we may go to Mars  some day. But we're certainly not going to do  it by 2050, move a  significant number of people anywhere off this planet.  And if we ever find  intelligent humans -- or intelligent creatures  somewhere, they  -- (Chuckles).  ROBERT BALLARD:  Yeah. That was definitely  a faux pas. If we ever  find intelligent creatures somewhere, they will kill us the moment we  land. They will say,  so you screwed up. We don't want you  here. So thank you  very much. (Applause).  KATY CROFF BELL: Say  hi to everybody. Thanks, Bob.  So now we are going to break into  our individual panel sessions.  If you would like to stay for exploration  and discovery, don't move. If  you would like to hear about our thriving  ocean, head over to the  lecture hall just across the tiny little hall right  here. And we need to  stay on time. So please go to your respective  places. This is not  a break. Thank you. [Music].  PETER GIRGUIS: All right,  good morning, everyone. AUDIENCE:  Good morning.  PETER GIRGUIS: It's a pleasure to be here today. And thank you for joining us in this session, Session 1. This is At the  Edge of the Map:  Exploration and Discovery. My name is Peter Girguis.  I'm a deep sea biologist.  I'm on the faculty of Harvard University. And  it is my pleasure  to be here today. I was really excited  when Katy asked me  to moderate this session. So I thought -- I  do think it's a little bit of  a funny misnomer given the group that's speaking, since none  of us up would ever  be described as moderate. You're looking at  a group of people  who are really passionate about ocean exploration.  And I know that  what you hear today is going to  be both exciting and  stimulating. So it really is my pleasure  to moderate the session. Before  we dive into our speakers and their presentations,  let's set the stage a  little bit. Just to remind you that the ocean  is the largest habitat on  earth. And in fact, the deep-sea, that's the ocean  below a kilometer, it's  80% of our biosphere. So everything else that  you can possibly imagine,  every desert, every forest, every city, every  restaurant, every coral reef,  like the Great Barrier Reef, all of that is in  the other 20%. And the more  I dwell on this, the more I realize that the deep  sea is the normal part of  our planet. We're the odd ones. But we know  so little about it. Because  water is really challenging. Any one of you can go  out on a clear night and  look at the moon a quarter of a million miles  away. But I challenge you  to go and stare down into the ocean and see  how far you can see.  And because of that, the ocean is really our last  great frontier on earth here.  And we know so little about it. So today  you're going to hear  from 4 amazing explorers, scientists and engineers, who are  going to tell you quite  a bit about their research and how they  think about not just the  ocean but our relationship with the ocean. So without  any further ado, I'll go  ahead and tell you a little bit about each  of them. But first, this  is the audience Q&A microphone. I've been told  I can throw it  out at you.  Wow.  PETER GIRGUIS: I'll try  to do so gently. I will  also use this to whack any of you who  go over your 7  minutes to be warned. (Chuckles)  PETER GIRGUIS:  But I do encourage  you to ask questions. We're going to  have our speakers  give their presentations and really we want to  hear from you. So whatever  it is that you feel compelled to ask,  please ask. Our first  speaker today is actually Adam Soule, who  is a colleague from  Woods Hole Oceanographic. He's a scientist  there for Deep Submergence.  That means his job is to oversee facilities  to run their deep-sea vehicles  and to be the liaison with we scientists  and the broader public.  He uses deep-sea vehicles to understand  how tectonic processes,  the movements of plates and the like,  influence the geology, the  geochemistry and the biology of the deep  sea. Next will be Kakani  Katija. She's a Principal Engineer at my  alma mater, the Monterey  Bay Aquarium Research Institute. There she  develops underwater technologies  to better understand how animals actually  contribute to the mixing  of our ocean and also to  understand the ecology of  these numerous gelatinous organisms that live in  the midwater. After Kakani  we have Beverly Goodman. She's an  Assistant Professor of marine  geosciences at the University of Haifa. And  she blends her talents  in archeology, geology and anthropology to explore  the way in which  nature and humans interact on coastlines.  Her work concentrates on  ancient events like tsunamis and floods to  better understand what risks  are present today. And last but not  least, we have Kenny  Broad. He's an environmental anthropologist who has  participated in so-called  extreme scientific and filmmaking expeditions on  every continent to  gather information and samples that shed  light on the little-known  environmental and cultural subjects ranging from  risk perception to venomous  snakes. So without any further  ado, Adam, it's  your show.  ADAM SOULE: Great,  thank you, Pete. So  I click this? Or how do I  make this go? The green  button there we go. Great. So I'm going to  talk a bit about volcanos  in the deep sea. And I didn't want to be  left out of the theme of  dragons and monsters so I put up a picture of  Te Ka, who is the  ocean dwelling lava monster from the Disney picture Moana. I  did not know at the  time that we would have representation from Disney. I  didn't ask permission or  pay any royalties for this. So I'm  asking permission now. And if  I'm not here tomorrow morning, check the dungeon of  Cinderella's castle to see if  you can find me there. (Chuckles)  ADAM SOULE: So to  start off I wanted to  show a couple of images of volcanic eruptions.  On the left is the  May 1980 eruption of Mount St. Helens on land.  And on the right, an  eruption of West Mata, a submarine volcano near  Fiji in 2009. And  I love volcanos. And I think they are  a wonderful avenue to talk  about the issues that Pete mentioned in the ocean that  so much of it is hidden  from our view. I think our public also likes  these in terms of  storytelling, likes volcanic eruptions. It's one of  the few places that we  can see the massive dynamism of Planet Earth  on a kind of human  relatable time scale. And the reason I'm showing  these two pictures is to  make the point that volcanic eruptions on land,  like the Mount St.  Helens eruption, there are millions and millions of  images of these eruptions  and drawings and stories from folklore. They  have been part of our  culture since we've been walking on the planet.  The images of an active  eruption in the deep ocean number less than  five. So there's this  really stark contrast between what we know about eruptions  on land and what we  know in the oceans. One of the ways that  this is an even bigger issue  than just the number of images is that we expect  that 75% of the volcanic  output of this planet occurs in the ocean. Only  25% on land. And when  you compare that with the number of confirmed  eruptions on land and in  the oceans, you can see this amazing contrast.  Only about .5% of  the confirmed eruptions, those that we have seen,  that we have dated, that  we have detected and looked at, are about 72  compared to nearly 10,000 on  land. So this raises the question of where  are all of the submarine  volcanic eruptions. Are we correct on our assumption  that 75% of the  eruptions occur underwater? This is kind of  canon in the scientific literature.  Based on first principles, it should be correct.  Or are we not seeing  the eruptions underwater? And I think the latter is  probably the case. So we happen  to be very good at detecting eruptions on land.  That's part of the  reason for this discrepancy. I would say  that there is no volcanic  eruption that occurs on land that we don't detect  within minutes to hours. And  part of that is through satellites. And these  are systems that were  not developed to detect eruptions but were  co-opted by the research  communities to do so. So using satellites  we can detect deformation  of the earth's surface as magma comes from the  deep earth up into the  shallow crust. And this way we can actually  see volcanic unrest before  it actually happens. We can see where the  hotspots. We can see where  the temperature on the earth's surface gave gone  way above ambient conditions  and we can detect eruptions that way.  We have a global  network of seismometers so we can detect earthquakes  that happen when you  move magma in the crust or when you erupt it  on to the surface of the  earth. And we have of course direct observations,  as well. So we  have made tremendous progress in technology and  our ability to explore the  oceans over the past few decades. And my  assumption was that because of  that, the rates at which we are detecting  eruptions has gotten better. You  can see some of the technology. These are  the vehicles we run out  of the Woods Hole Oceanographic Institution for  the national Deep  Submergence facility. The human-occupied  submarine Alvin. The  remotely-operated vehicle Jason. And autonomous  underwater vehicle, Sentry. But  when I started to count up the  eruptions that we have  detected or confirmed under water, we see a  pretty linear trend with time.  That on average, we're detecting one or two  eruptions per year. And that  has not changed, even as our technology has  improved. So in the vein  of throwing out some interesting or wild ideas, I  am going to suggest that  we have the potential to monitor the ocean's  volcanos in a much better  way, in much more comprehensive way, than we do  now. And I have a  few examples of that to show you. On the  left is a satellite image of  the sea surface from just after a volcanic eruption  in the Havre volcano in  the Kermadec Arc in 2012. This is an eruption  on the scale of the  Mount St. Helen's eruption in terms of volume produced.  And one of the products  of that eruption was a lot of that pumice. And  a great deal lot of that  pumice floated up to the sea surface and made a  raft. So you can see  in the satellite image where the yellow arrows are pointing. You can see the pumice raft floating on the surface. This by the way, was detected when an airplane flew over the ocean and a  woman looked out the  window and saw something unusual in the water  and contacted authorities and a  Navy ship went out there and found that  it was pumice. So it  was a serendipitous discovery. Again but it was  recorded by satellites. And  we have decades and decades of satellite imagery  of the ocean surface.  That same eruption was also potentially detected  by something called an  ARGO float. So this is a passive package that  floats around in the ocean,  sinks down to a couple thousand meters, and  comes back up. There  are about 4,000 of these floating throughout the  ocean basins. And by looking  at the kind of ambient temperatures and  salinities recorded by these,  a couple of fellows from the  University of California-Berkeley  have detected this eruption. So there's another  way in which we can  detect an eruption that puts out not only  lava but chemically distinct water.  Then in addition to those two -- and also  with the ARGO data, there  are years and years of data. And then lastly,  eruptions produce seismic energy.  And the ocean has this beautiful SOFAR  channel where seismic energy  can travel long distances and we can  use floating hydrophones to  detect those. We don't necessarily have a huge  constellation of those. But  it's another means we have to detect eruption.  So I think there's some  potential to use what we have and build  on that to really improve  our ocean detection or monitoring. And I'm out of  time. Sorry, Pete. You didn't  whack me. That's great.  PETER GIRGUIS: You did perfect. (Applause).  KAKANI KATIJA: We're  just to go right into  it. Thank you everyone for coming. I'm really excited  to be able to talk  with you all today. I was trying to  figure out a good  way to start. Because I think  what's really interesting  about ocean exploration is how interdisciplinary  it is. And it  really brings in people from a lot  of different areas. Because I'm  really not a marine scientist. I'm actually  trained as an aerospace  engineer. What you'll notice here, I kind of think  I haven't aged a day. I  won't tell you how long ago this photo was taken.  But if you can't recognize  me, I'm the one suspended in microgravity  waiting for that  very handsome mustachioed gentleman to whirl me around  in this airline as part  of the vomit comet project. And I've always been  really excited by the search  for life in outer planets. But then at some  point in time, I stopped  looking for life in outer space and started instead  looking for life in our  oceans. What you may not know is that this clip  right now is not a star  field. It's actually what the ocean looks like at  400 meters in Monterey Bay.  And although the search for life in outer planets  has so far been unsuccessful,  the oceans are just teeming with life and we do  not know a lot about that  life. So I am a bioengineer and my lab  at Monterey Bay Aquarium  Research Institute or MBARI is combining  several things. Not only  using innovation outlook platforms but also developing  state of the art  instrumentation. And in particular we're developing and  deploying new kinds of  imaging tool. And then we're also using  these -- this equipment  on ocean-going research vessels to try to study  animals in the deep sea,  particularly animals in the midwater range of the  ocean. With the goal  of taking this information and applying it to  bioinspired designs. So what  that means is potentially we might some day  have technologies that are based  on some of the lessons we learned from animals  that live in the midwater.  And I kind of -- the reason why this is  I think very important is  if we think about birds, animals that first inspired us  to become -- to have  flight. And there's a lot we could potentially be inspired  to do if we were  able to study animals in midwater. So that's kind  of the perspective I have.  And here is an example of an animal. This  is an anglerfish. You can  see its lure. This animal bioluminescences. And about  75% of animals in  the deep sea use bioluminescence. This is  schistosoma. Animals like  these are being studied, not only the  visual systems, but also  their transparent tissues for applications related to imaging.  And then this is  a siphonophore. You may not have ever heard  of these. But they can be  as long as a blue whale. And they  undergo these really long  distance burrow migrations. How do they do that?  And then finally this is  a Humboldt squid. Not only are these animals voracious  predators, as you'll see  here. But they have soft bodies. And they  utilize dual modes of  propulsion, which is making us rethink the ways  in which we might  develop underwater vehicles for deep-sea exploration. And I just  want to say that if  you were to check the MBARI YouTube page,  the comments are pretty  hilarious. Because they think this footage isn't  real. Somehow we went out  and paid a Hollywood studio to make these videos.  But what is really required  is a lot of development and a lot  of infrastructure investments. Not  only do we have research vessels like  this one, the Western Flyer.  On board each of these research vessels,  we have big robots  like this remotely-operated vehicle. And in addition  to that, we develop  these different kinds of imaging packages or instrument  packages that could be  onboard. And in my case in my team,  we have developed a laser  imaging tool called deep PIV that allows us to  see organizations in the deep  sea in a completely different way. And one  of these animals are  giant larvations. Again, you probably have never heard  of the animals. But we  can find them in Monterey Bay anywhere from  50 to 400 meters  deep. The animal, you can see there, is actually  beating its tail. And these  animals can be as long as 10 centimeters in  length. And what you'll notice  is the animal is attached to this large  diaphanous structure. This is  known as the house. It's made out of mucous  that the animal secretes from  the top of the animal's head. And  these houses serve as  filtration structures to separate particles in food  from the water around  these animals. And these houses can be as  large as a meter across. So  we can use our deep PIV instrument to get  a completely different view  of these animals. And just to orient you, this is  -- think of it in terms  of X-ray vision. In order to get this kind of footage, an  ROV pilot has to fly a  vehicle to an animal that might be 200 meters  deep and position a 1  millimeter thick laser sheath on an animal that's about  2 centimeters wide. And what  you'll see is that as the animal is starting  to beat its tail, you  can see particles moving in and around the house.  Those particles are actually used  as a proxy for fluid motion. And we  can do things like estimate  the filtration rates of these animals. And we have  so far measured up to  80 liters per hour that these animals are processing.  And we can scale that  up based on the maximum abundance numbers we  have of these animals.  Such that right now based on our  estimates we can say that  giant larvations are filtering their principle depth range  in less than two weeks.  But another thing we can also do with this is  use deep PIV in a scanning  mode. So a lot like an MRI where you might have  a stack of images, we  then can get planes of images of not only  gelatinous tissues but also  mucous tissues. So what we can then do is  use that image stack and  get a really unprecedented view of what an  interior structure might look like.  So what you're seeing are internal chambers. Again  all made of mucous.  That is -- eventually leads to the mouth of  this animal and allows the  animal to feed. So really we're just scratching the  surface of how we can  do these sorts of measurements. We're also  hoping not only to  understand the structure which we're getting here  but also the function  of these houses to hopefully some day have  an inspiration for submicron  filters that might be useful to us. So I  just want to end, though, with  this idea that I think it's a very exciting time  for exploration, particularly as  we start developing tools and techniques to  study processes in midwater.  And with this exploration, I think we'll be  very inspired by the things  we see and learn. And some day maybe  that inspiration can lead  to innovations that we take for granted. But I think  we're just really at the start  of that. So thank you. (Applause).  BEVERLY GOODMAN: Good  morning. So my name  is Beverly Goodman. And I'm involved with  National Geographic and the  University of Haifa. As he mentioned,  I'm a marine  geoarcheologist. So what that means is  I'm using earth sciences  techniques to try to reconstruct to understand  the back history of  the relationship between people and coastlines and the  sea. So to try to  explain how that works, it's sort of as if  I'm as interested in what's  surrounding the artifacts as the artifacts themselves. Or if --  some of my students like  to tease me that I'm an expert at  harassing and interrogating sand  and mud and shells. That's basically what I do. I  try to get all of the  answers out of them. So the reason this is --  the applications for this and the  reason for doing it is that we have this  long history with living  on coastlines. And coastlines are -- to even say  coastlines, it's kind like saying  meet me at the elephant- shaped cloud. It's not going  to last long as we  see it today. Coastline is this ephemeral changing --  it's a concept really. Because  of that, we can't understand what has happened  or how we need  to live on coastlines without looking a little bit  at the history and how  it's changed and what it looked like in the  past. And also how humans  affected the coastline but also how the environment  of the coastline has  changed how we do things. Now, as we get  an idea of how the  coastline has changed, we also have to look offshore. And  we realize that not only  are there all of these gorgeous creatures and  interesting and sometimes  unusual animals doing amazing things, the  bottom of the ocean,  including in the shallows going out to on the  continental shelf it's also this  treasure trove of a record. And the record is  not only -- it's recording  the sea conditions, it's recording climate information. But  the truth is we  have this incredible amount of what was once  exposed land. Of course once  we had sea level rise, all of these  terrestrial areas that were the  places where people left Africa and arrived in  North America, we have  an incredible expanse. It's an entire continent. We're  missing a continent of  information about our own human story. So  I'm trying to go and  investigate those areas and reconstruct that story just  both for the sake  of understanding our own history but also hopefully  to apply some of  this knowledge. What has happened in the past?  How do we divide between  what is natural and what is our fault? What  we're making happen. And also  trying to get a better perspective on what  our heritage is, what our  story is. As I mentioned, humans like living  on coastlines. This is true  today and it was true in the past. But  it's really problematic. This is  changing over time. As Robert Ballard said earlier,  we're only inhabiting 5% of  the planet. And it's actually highly concentrated  on coastlines. Today with  urban growth it's happening on the coastlines  in places where people  never lived. We have cities growing to millions  in places that were  uninhabitable a million years ago because  of our advancements in  resources, air conditioners, places that had no  populations. The work we're doing  -- and of course with those people, you  have infrastructure we have  all kinds of sensitive and natural and man-made things  we want to watch out  for. In the work we're doing with the  marine geoarcheology, we love  when we have historical records. This is fantastic. This tells us the story  if we have a good record. But of course  writing is a relatively new  thing to people so we don't have the  timeframe that we're really  interested in. But fortunately the sea doesn't  care. It doesn't need writing  to tell its story. We can get the  information off the sediments offshore. What I wanted to do today is talk about  the life cycle of my  research. Because I'm at MIT. I'm with all of these brilliant  minds that are going to answer  all of my -- fix all of my problems. Right?  This is what's going to  happen in the next two days I hope. But I  want to talk about one of  my largest frustrations in the work I'm doing is the  life cycle of the research.  So typically you have an idea, you are in the  library. We are doing research  on history. There's a question in mind. Get out  to the field and do  some kind of survey. We're looking at subsurface  features. Usually we're  looking at geophysical surveys, something of that matter.  Then we do the survey.  We go back to the lab. There's post  processing. We find some  features that we're interested. Once we know  what features we're interested  in, we can go out and take some biopsies,  take some cores, do a  little bit of excavation. So we have that information.  We take that core back  into the lab, open up the core. Now the  real work begins. We have  some analysis that might take a matter of hours.  And we have other analysis  that might take the matter of a PhD. So  we have a time gap  there. We get the information back from these different  proxies, this information about  what kind of environments we're looking  at. And ultimately, we  can hopefully make some conclusions. As was  mentioned in my introduction,  thank you very much, one of the  major finds that we  made was actually about Mediterranean tsunamis. Yes, they  do exist. Yes, it's  a problem. And here for example, is one of  the signs that was recently put  up as part of a policy change in the  Eastern Mediterranean in the  country of Israel where they are doing an  entire signage program to help  with education and to prevent loss of life in  the event of a tsunami.  Now, this is all wonderful. Except it takes a lot  of time. We're looking at a  process that is years. In fact, in the example of  the tsunami sign, we're looking  at nearly a decade from start to finish. And  I would love, love, love  to shorten that length of time. Because there's so  much information in looking  at the rate of population growth. Looking at  the rate of climate  change. Looking at all of these things, it would  be very nice to get some  of these answers a lot faster. So this is  a picture of me looking  very triumphant. We have collected a difficult-to-collect core in core sediments in  the northern Red Sea. But if you know  me well enough you'll see  I'm grimacing because I'm picturing this. These are  wonderful. These are foraminifera.  I don't know if any of you are  familiar with them. But each  one of these beautiful little creatures is a size less  than a grain of sand.  And each one is removed, isolated, by hand. Okay? Hours  and hours and hours. And  then it gives us this amazing amount of  information. It can tell  us about ancient harbors. it can tell us about tsunamis.  It can tell us about sea  level. But it takes a very long time. So I  come here today hoping that  we'll have a chance to look in how to speed  up this process in order  to get more information, to get more answers faster. Because  the planet is so large.  And one of the biggest issues that we  have in terms of reconstructing  the past events is getting this larger spatial  coverage of the entire  globe. Thank you. (Applause).  KENNY BROAD:  Good morning. Thank you,  wherever Katy is, for having this. And  Joi for hosting us. I'm  Kenny Broad. I'm based down at the  University of Miami.  I'm freezing. (Chuckles).  KENNY BROAD:  Anyway, as I tell  my students down there, and a couple of them  are participating now, if you  can't be smart, be first. Which is sort  of my approach  to exploration. So I work a lot  in underwater caves. They are  not so easy to access. I know -- I recognize  I have a couple of colleagues  here who are cave divers. But that's basically  what an underwater  cave looks like. And a lot of people think that was Brian Skerry's photo. But I actually did it all myself. (Chuckles).  KENNY BROAD:  You'll see a bunch of  photos in -- my colleague, Wes Giles, the late  Wes Giles, a mentor for  me who took many, if not all, of  the photos. But that's  what an underwater cave or what are  called cenotes in Mexico or  blue holes in the Bahamas looks like from  about 100 meters above it  to divers descending down. And there are two types  of caves. I'll call them  blue holes in karst or a limestone geology  environment. And so there's  inland holes. And then the ocean holes.  The ocean holes having  formed when sea level was much lower. So  the last glacial maximum.  About 20,000 years ago the sea level was 100  meters lower in many parts  of the world. And that's where these caves formed.  And they have become  repositories or time capsules. I'll talk a little  bit about some of that. Just  to get to what we were asked to bring up  or some of the places where  I think we can use help from an interdisciplinary  approach is certainly helping  -- and you'll see how crude and  rudimentary some of the  navigation in mapping of underwater caves still is.  Certainly sampling because we  have a limited amount of time. Some places  we only have one chance  to get there and do one dive in there  before conditions go bad for  weeks if not months. And on the  human side, certainly there's  risk management, which technological advancements can help.  But there's also a  lot related to cognition that we need to  work on. So as you can  tell I use pretty high tech devices. That's why I  don't have any hair. You know,  it's a lot of trial and error to find these caves.  What's happening here?  KENNY  BROAD: Basically you  can't judge. So you really  have to put yourself  in these situations. My mother her comment is,  you went to school for how  many years to do that? So anyway, but it  really is -- it  does ground-penetrating radar. Other technologies don't allow  us to actually figure  out what's going on down there. We  have to physically go  to these places. Which is, again, good for  job security. But once you  get into these realms -- and I'll give you  some rational reasons. From  a scientific standpoint why we do it, you  just feel like you're in  inner space. Like Kakani flying through on her submersibles.  And that's four people in  that picture. And it has many of the  same challenges as working in  space. I'll show this video and talk over it.  But right when we drop  into many of the inland sinkholes, you'll go through  a poisonous hydrogen sulfide  layer. It harbors many different types of  microbial life, extremophile forms  of life, that are interesting for microbiologists from  their modern day proxies  for what we think not only the earliest  forms of life were when  life was first starting out 4.5 billion years ago  more or less to what might  be able to survive in other planets, in Europa.  So we tend not  to use communication. Communication underground is difficult. We tend to just  use light signals and hand signals. That was  kind of a gimmick for  a TV show. But you have vast rivers going  underwater. Most people don't  realize if you take away the water locked up  in ice, more than 95%  of the world's freshwater is beneath our feet  in groundwater and underground  aquifers. It's out of sight out of mind.  From a conservation standpoint  very difficult to get people to think about these  things. Along the lines --  even harder than the ocean, like Bob was talking  about this morning. So the  way we map these places is we run a  line. There's a knot tied  every 3 meters approximately in the line. Usually it's  really boring to do. So  people are drinking when they tie the knots  and it ends up  not being 3 meters. (Chuckles)  KENNY BROAD: That's  how you get distance.  I'll show a picture later but  just using a compass  you take an azimuth of the angle every  time the line changes direction.  And you record the depth. And that's the  basic line survey. And  that's how we create the lowest grade map.  And then it's very  time consuming after that to measure  the walls. And  there's some advancements in that direction. I'll better go fast. There again, that's just working underwater. That's actually  on one of  the Ocean Exploration Trust projects we're mapping  underwater sea caves in  the Bahamas -- I'm sorry in the Channel  Islands. And we use --  tend to use rebreathers. Especially if you don't want  oxygen in the system. You  end up with very elegant high tech data  collection like that. I'm  working with Corey Jaskolski, who you'll be hearing  from later, on ways  we can use underwater LiDAR and  some other techniques  underground. But Sebastian Keister invented this  machine that just came  out we've been using that's helping with the line surveys by automating it. And now that's just some examples of some of the tests that we've been doing with it. We just recently tested it  and it's much more accurate  of course than the hand surveys. Other high  tech devices that we  use for the extremophile forms of life. That's  a lucifugal. That's a new  class of crustaceans that Joe Jaeger found in  the caves of the Bahamas.  These are the hydrogen sulfide layer I mentioned.  The pink is actually  the pigmentation in the cells of the bacteria. That's  how numerous they are. And  this is at a very toxic level for humans.  You can actually smell  it because it's going through the pores in  your skin and the hydrogen  sulfide binds with the hemoglobin and stops  oxygen uptake. There  are also issues technologically. How we  can reduce our exposure?  There is some evidence of physiological changes  This is what I  looked like before I started diving in hydrogen sulfide. (Chuckles).  KENNY BROAD: Many  people will attest there  were some odd changes in physiology. But we're  also interested in what's  in the water and using environmental  DNA on  some projects. There's lots of  endocrine disrupters that are  getting into our system, as well. So I  think I'm -- of course that's  -- these are time capsules. And because of  no oxygen and saltwater,  very good for preserving fossils and their  repositories in that sense,  as well. But rather than damaging these fossils,  as this archeologist is  probably doing, we can now use again  3D photogrammetry and other  imaging and we're working with Corey on  doing that so and  we can have non-invasive techniques, as well. I thought  that was my last slide.  This is more high tech. That's a turkey  baster collecting Saharan dust.  The speleothems are actually great recorders as  Bev was talking about  for reconstructing past climate change. So we  use high tech hammers and  chisels. And you can look at the isotopic ratios,  fluid inclusions, to learn about  those. So I'll end on this slide. I  won't talk about diving  technologies. But there's certainly major advancements in that.  That's early '90s. But  you're really limited by the size. So it gets  miniaturized, it's making our job  easier. So thank you. I went a few over. I'm sorry. (Applause).  PETER GIRGUIS:  Wow. I told  you there's nothing moderate about anybody  up here. An  amazing series of talks. It's question and  answer time. So this is  your opportunity for the next about 40 minutes or  so to ask our speakers  anything that you would like to ask them. We  have folks online, as well.  And I know that someone in here is going to  be fielding questions from the  folks online. Who was that? Someone raise their  hand, whoever will  field online questions. Thank you. All right. In  the meantime, it's your show,  who wants to go first? I get  to throw this. We  will start with someone in the  front row so  we can practice.  I guess this goes to  all of you maybe and we'll  start with Bev and Kakani. What impressed me  with all of  the different presentations is how much  human thought and value content  goes into what you are doing and how that's  a painstaking part of what  you do. To what extent do the panel  think they can actually imagine  robotic systems being able enhance the progress they  make if we really  want to push forward in a significant  way in the next  generation. And that's not necessarily the technology.  Because we're at  MIT so presumably someone else can do that.  But what can you imagine  you could do if you had that technology  what would really  help you?  PETER GIRGUIS: Actually I  would love to hear each  of you address that. Who wants to kick it off?  Kenny, do you want to go?  KENNY BROAD: I'll  give you -- people  are working on that. And there's Bill Stone  from Stone Aerospace has  a device that's a non-tethered  autonomous underwater  for exploration and mapper. It's doing  amazing things. It doesn't  have the capability -- so this gets to  the value judgment. The  worry, the worry no offense to open ROV,  no offense to democratization  of technology, but you can go in there  and you can do a  lot of damage particularly for resources, ancient burial  grounds and from an  aesthetic standpoint, as well. So it's a  tradeoff in being able to  do automated machine learning. It's very impressive, what is  being done. But it's still  not to the point where you have the dexterity.  There's still quite a  worry of damaging things.  Yeah. I would have  to agree that I think  being able to automate it, especially because the  risk of putting people  in the water -- Kenny and I both  have work where we're  definitely putting the people down there to do the work.  KENNY BROAD: Mostly grad students. (Chuckles)  Depending  on the university  signatures. So certainly. But it's always  the actual manipulative abilities  are just lacking. So in  terms of  archaeological excavation, most definitely, just touch,  feel, is this wood, is  it stone, is it shell? Where do we  go from here? But I  would love to imagine -- like in my work,  if it could be more  automated with picturing little glider type things  moving along doing  the survey, recognizing something interesting and  then having some kind  of sensor-filled core liner that would insert  and get like in situ  data immediately. That's my biggest frustration is just  that gap between the collection  and just -- I mean, many of the  ways that we do things.  Of course these beautiful core scanners and things that  are giving us a lot  of data much faster. But still there are things that  simply can't be done that  way. So yeah, I would fantasize about having these  sort of rote type --  robotic gliders but we still need judgment call.  We need someone to say,  this is the ground proofing. That's what the  robot is seeing, that is  what the survey is seeing. But  there's some  merge there.  Yeah, I  could go on  on this topic. (Chuckles)  I think  there's a variety of different  approaches that people are starting to look at  for underwater robotics. You  can either try and develop technologies that are  super cheap and you  can build many of them and then try  to instrument the crap out  of the ocean. So that's one area. And then there's  kind of the other --  you know, the other approach where you might  want to have really  expensive vehicles but have the capacity to be  persistent. So figure out ways  for these robots to stay in one location or  sample a location over a  period of time. So that's being worked on. Around  the world. Not only  for defense applications obviously but then also  for science applications, as well.  I think, too, what we want to -- I spend  a lot of time doing is  thinking about what are the questions I'm interested in? Can  I do this automated? Or  approach it in an automated fashion? And if I  can, great, go down that  pathway. If I can't, then open up another  toolbox and use these more  remote tools. So for example, right now MBARI  has over the past  30 years been collecting midwater video transects. So  every month for I think  the past 28, 30 years with an ROV  we've been going down in  100 meter increments to collect video data on who  is there. And that's from  the sea surface down to 1,000 meters. So we  have amassed all of this  video data. But then what do you do  with it? And I think  that's the biggest problem independent if you're going  to be doing remote  things or human-operated things versus automated things  or automated robotics is  what do you do with all of this data  once you've collected it? In  the case of MBARI we have approached that problem  by having -- manually  annotating all of that video data. And  that's not sustainable. And then  another aspect of it is you can't really take a  ship out every time you want  to do one of these transects. So we started doing  we call it I-2 map,  an AUV that essentially replicates the setup we have  in ROVs on an AUV  and it can do these transects in an automated  fashion. But again, that  vehicle is quite large. It's a Darodo-class AUV.  And not many people can  deploy a vehicle like that. So now we're thinking  you know down the pathway  of how do we make these things more  accessible to people. There's  one project that we're working on with  WHOI and Stanford and  University of Texas Rio Grande Valley to develop  the mesobot, which is  a smaller autonomous underwater vehicle, that uses  a stereo pair of  cameras to track animals or other interesting targets  in midwater. And that  automation is going to be fantastic. But again, how do  we process all of that data?  And I think -- I did want to put in  a plug for this is this  potential project, is that MBARI has got this incredible  resource -- this video  lab that's manually annotated. Let me say  that again. It's a  manually annotated video dataset. And there's incredible  things we could be  doing with it with machine learning. We just  need the right people to  be working on that problem.  ADAM SOULE:  I agree with everything  that's been said. In terms of the value judgment  part, I just want to  make sure that while we develop robotics systems to  do things that humans  aren't capable, we shouldn't take humans out  of the loop entirely.  Not only, as Beverly mentioned, for the  ability to assimilate information  and make decisions more effectively than computers  can for kind of  the inspirational aspects of it, as well. You  can show people 50 images  of satellites. But they will want to look at the  one of the astronaut on  the space walk. And it's important, as Bob mentioned earlier,  if we're going to --  if we're going to make progress in the  oceans we need everyone  onboard as well so keeping humans in that  process of exploration I think  is important, as well.  PETER GIRGUIS: Thank you. All  right. You all are going to  kill me. I misspoke earlier. We actually have 6 minutes and  20 seconds. So please don't throw  that back at me my way. But that still  means we have  time for questions. So anybody else in  the audience? Just talk into  that fuzzy end there.  Hi. My name is Genevieve Fosbowler (phonetic). I'm a second year PhD student in the WHOI  joint program. And I  have a question. So I'm trained kind of  more as a computer scientist  than as an ocean explorer. And one of the  things that stood out to  me coming into this field and trying to take some  of the things I learn  in machine learning and in computer science and apply  it to these problems, how  much data is available? And how useful that  could be? Data has  really pushed forward Computer Science and  machine learning and computer  vision and other fields and autonomous  driving cars and image  recognition. And that same progress isn't really  happening in underwater imagery.  And I think one of the problems is  that the datasets that you  would to do this need are kind of spread across  institutions. If I want a  coral dataset, I have to email a person who  studies that specific environment  and get their data and try to compile  things. I was wondering if  you have any thoughts about how we can  try to make the data  community in the marine sciences more inclusive and  more accessible to people  who are interested.  PETER GIRGUIS: Kenny and  Beverly would you be okay  if I gave Adam and Kakani a  chance? Okay. Go  for it.  ADAM SOULE:  So we certainly from  the national Deep Submergence perspective we are  very interested and invested  in that, as well. And we try as hard  as we can to make  any data collected with those vehicles publicly available. But  there are some real  challenges to that. One of them being  video. There's a huge  amount of video not just of whatever  the scientist was pointing  the video camera out but every water  column traverse that could  be used for those purposes that is not very  accessible to the public, one  can request it. But there's a challenge in how  to archive and store that.  And right now it's really a resource challenge  until the technology catches  up. But since Kakani is here, I  would challenge her to  talk about that manually annotated dataset and  whether it's publicly  available or not.  KAKANI KATIJA: It  is. But I would  say coming from the aerospace world where  there are requirements and  there are repositories, you know, there's --  I think more broadly in  other fields there are ways in which  people share data that  make a little more sense to  me personally. There  are some institutions, at least in ocean sciences,  that think about we do  we make our data accessible. Unfortunately I can't speak  to all of them. But  I can at least speak to some of the  programs we have at MBARI  right now. So the -- interestingly, all of the  video annotations that we  have has been used using what we  call VARS it's called  video annotation reference system. You can actually access  all of this online. And  you can do a quick search if you go to our  deep sea guide. I don't know  what that URL is. But search Google. You can  actually search by species  in some instances you know whether or  not there's been annotations  for them. And then data outputs include like  where their abundance might  be in the water column. Also locations. So  GPS, the location of  that observation. So that data is available. You just  have to -- unfortunately you  have to go to specifically a Web site like  an MBARI Web site to  find it. But then there's the example, it's called  the SOCCOM project It's  ARGO's float project in the Antarctic. And I think  they are doing a fantastic  job of sharing data, where all of the  data is instantly uploaded to  satellite and is made available on a Web site. And  again Google SOCCOM, S O C  C O M. And I think that's a fantastic  model that perhaps the  rest of the oceanographic community can try  and follow. Because these  data products are incredible. But they only get  synthesized as we get to  them. So why not share it  with a much  bigger community?  ADAM SOULE: Can  I just jump in  with one more point? What MBARI does is  really great with their  video annotation. Because it's a programmatic  thing that they  have a vocabulary that they  use to annotate video  very consistently. And annotated data is really  much more useful data  for Computer Science than unannotated data. And  what we do, since we're  driven by individual PIs, we don't do a great  job of kind of consistent  annotation. So any sort of tools to advance that  part of that would make  the data much more searchable, useful.  I would add quickly,  too, that one thing to  keep in mind when it comes to data is  that the volumes of data  we generate is tremendous. The computing power  needed to automate  the analysis of t he video that Kakani was  talking about is non-trivial if  you want to do it right. And so I think what  -- we also need to keep  sort of the culture in mind of how we select  our data, and the resources  we have available. But I would say we  keep our eyes on  the Non-Government Organizations. MBARI has been pioneering  in many of these  practices. The Ocean Exploration Trust, which I  have worked quite a bit  with, is also pioneering in not only making  data and video available  but samples. Any samples they collect they  send to Harvard's Museum  of Comparative Zoology. And those available to  anyone who wants them.  Even the Schmidt Ocean Institute is doing the same  thing. So data is a  big challenge. But I would turn to folks like you  who are going to be  the next generation of leaders to really help  us solve these  issues. Sir?  (Off microphone).  Nice. Or go into football.  As Peter mentioned,  the Ocean Exploration Trust  is mandated to OpenSource its data as it  collects it. And also dealing  with a terabyte a day of video imagery and God  help us when we go to  4K and time for more HD. We take frame  graphs. We have a  person dedicated 24 hours a day dedicated to  grabbing a frame and then  annotating it. So you don't have to sit down  and go through 8 million  hours of footage. If you just check the annotation it  says, we saw the following.  And then you can call up that image. And  once you get its time  code, you now know where to find it in the vast  servers of the video data. You  always can do a better job. But we're --  we're required to do it.  Here you go, Peter.  PETER GIRGUIS: Thanks  a lot. We are  technically out of time. But I'm going to  make an executive decision  to give us one minute for  anybody to ask  one burning question they have and to let  our panel respond. Oh, man. God  help me. Here we go.  I just wanted  to pick up on  something you mentioned, Adam, at the end  of the first question  around how you integrate humans into discovery  and keep them as  part of the process. Because one of my concerns  with technology is as amazing  as it is and as much data as it  generates and it's created for  warm bodies to sit behind computers at the end,  so how do we keep  people engaged in the ocean? As you answer  that, I would love to  hear your thoughts and reflections on what experience  made you fall in love  with the ocean and what made you  have the career that  you have now.  PETER GIRGUIS: Who  wants to give it a  go? All of you? You want to do  quick answers each? Okay,  kick it off, Kenny, please.  KENNY BROAD: The  quick answer is a personal  one. I grew up near the ocean. It was  a way to escape. No one  can yell at you in the water or not. You  can get away from the  cops. All sorts of reasons. (Chuckles).  KENNY BROAD: The  other -- but I think  now particularly with the new generation of scientists and  people in the exploration  goals, there it's not, oh, you're a  storyteller or, oh,  you're a scientist. But they are integrating  it into the science  and it's being formalized through NSF or  other groups requiring broader  impacts, outreach education. So I think you  have -- it's a  different mindset from when I started in  Graduate School and whatnot.  I think we're heading in the right  direction. And this meeting is  an example of it.  BEVERLY GOODMAN: I  get asked the question  many times how does -- I'm originally  from Wisconsin. People say  how does a Wisconsin girl end  up being an  underwater archeologist? But for me, I would say  I fell in love with the  ocean in the swimming pool, in the bathtub, in shells  to my ear and my  imagination. It didn't require -- I don't think I  saw the sea --  O remember seeing the sea until I was  maybe 9 years old. But  I think for me personally if I take  my own personal experience in  my connection with the ocean, literacy, ocean literacy  as a critical part  of education. I know in the Mediterranean  now they are doing it  in the United States there's a whole policy  of what ocean literacy  should be. Some base-level education that is part  of the elementary school experience. I think that's -- you know, kids have  good imaginations. I think  that that's something at least to get  -- to put a  baseline out there.  KAKANI KATIJA: Yeah,  well, in my case I  was born in Hawaii. Same hospital as  President Obama, by  the way.  BEVERLY  GOODMAN: You  sure?  KAKANI KATIJA:  It depends on who  you talk to. I would say I really didn't return back to the oceans until I started Graduate School. Because as I  was undergoing my PhD  at Cal Tech, I was an engineer. So  I was put in a  lab in a basement somewhere. That I had an opportunity  to go out in the  field and after that I was just completely hooked.  I just felt like there  was so much we could learn from the natural  environment. And then in  terms of the human aspect of our work, I  don't see it ever going  away. I mean, just because we have more automation  and more robots, it provides  us more time to do the things we really  want to do. Instead of  going through a sediment sample and trying to find  an artifact, if we can do  it in that in an automated fashion, we can use  our time to do other things.  So I see it as an opportunity  in that  respect.  ADAM SOULE: I  have no great origin story  and part of the reason I maybe resonate  with humans and the loop  is because it was really my first dive into human-occupied submersible Alvin  that got me hooked. I think it's  a great question and  really challenging question to come up  with a defensible argument  for why humans need to dive in a  submersible onto the sea floor.  I can tell you we are much more efficient  at assimilating and choosing  the right sample and that kind of thing.  And I can tell you that  it's inspiring. But when -- NASA has this same  problem. When you weigh it  against the risks of being there and that kind  of thing, it's really hard  to defend. I'm sure there's clever people who  can tell me about the  cognition of the human brain and the eyes and  how they get them to work  together. But I have yet to have something I  go to someone with  saying absolutely you need humans there if you want  to make progress. So I  think that's a challenge for us.  PETER GIRGUIS: Thanks.  Well, let's give our panel  a round of applause. (Applause)  PETER GIRGUIS:  I think it's  break time, correct? Before you all head out  to your break, Katy has asked  each of us that if we have an exciting idea  we want to share or  been inspired by what you have heard -- and this applies  to you all, as well --  write them down on the big board over there. There  should be some markers around  I hope. If not, I'll try to drum some  up. But jot down your ideas.  And it will likely find its way into tomorrow's discussion.  So thank you all for  joining us for this session. (Break.)  It's great to be here.  What a great day. So you have  just joined the Deep Data session. It's really a great segue  from the initial session we  just had in here, lots of questions about  the data. So to  kick us off, I wanted to  show you some  supercomputer simulations. We have a quintillion  bytes of data coming  down from our Earth-observing satellites every day  tell you what you need  to know about sea temperature, the  currents, the  soil. But with a do  we do with all  of that data? Our session is how do  we curate that and share  it with all citizens? And fundamentally, how do  we bring about actions  and change human behavior? This is just  a scientific fact in terms  of our temperature rise just hitting 1 degree Celsius.  So taking a look at  all of the extreme data. And I think to have  this discussion we absolutely need  to start with the oceans. So we have  incredible panelists here. They are  going to tell us about what's going on.  And my final stimulation. Take  a look at the currents, sea level rise. And  all of us are here on  Spaceship Earth as I call it. If you know me,  I'm Dava Newman. I didn't  introduce myself. a faculty member here at MIT. It's  my great joy to be  able to moderate this session. And I've spent my  entire career trying to get  people to Mars. I have 20 years to get  people to Mars. And I think  we have 10 years to really address climate. And  I think climate starts  with the oceans and really having this discussion. So  it's a great session to  kick off. Let me introduce our panelists here.  Sorry about that. Here  we go. Katy Croff Bell needs no introduction. But  she's an MIT alum I  like to say. First and foremost, we're so glad she's  joined us at the Media  Lab to lead the Open Ocean Initiative. She's Explorer,  as you've seen from  earlier in the motion. But I want to  highlight her background in  ocean engineering and maritime archeology and  oceanography. That's bringing  the best from the engineering to the  science world to tackle  some of these really audacious problems we  have. She's also passionate  about making it available to the public.  So Katy is leading the  Open Oceans effort here. That's really important. Do  you see her little  beautiful daughter here? How do we bring all  of the kids on board? How  do we immerse them in the conversation, as well?  And then we'll hear from  Alan Turchik he's at National Geographic the  head of product development  manager for the Exploration Technology Lab.  He's a mechanical engineer  by training, so he's deployed sensors all  over throughout the sea.  And now he's focused on how we scale that  up, what can we do with  all of our technology and sensing? How do we scale  all of that information up,  again, to share with everyone? Which will be  covered by Grace Young. It's  great to see Grace again. She's an ocean  engineer at MIT and  Explorer aquanaut. How many of you are aquanauts  in the audience? Fellow  Explorers and citizens here. Grace has just  actually submitted her dissertation  at Oxford. And she will be defending in  a week. So thank you,  thank you, for being here with us. And congratulations. (Applause).  DAVA NEWMAN: We really appreciate  you making the trip. I hope  it will get the nerves down. But you'll do great.  GRACE YOUNG: Thank you.  DAVA NEWMAN: Then  Ben Woodward I would like  to introduce to you. He's the co-founder of CVision  AI. So when we talk about  how we use artificial intelligence, natural language, deep learning, to really make sense  of all of the ocean  data that we have, Ben is going to  be the authority on  that. Grace is also doing that for her  dissertation. You know, imaging,  machine learning. So we really do think some  of the solutions to make  sense of this are really now with the algorithms. And  I love the question from  the last group, as well. But people are always  in the loop. With all  of our AI and natural language, people are always  in the loop. So without  further ado we'll put Katy on. Thank you.  KATY CROFF BELL:  Thank you, Dava. I  love that sea surface temperature. I could  stare at that  all day. (Chuckles)  KATY CROFF BELL: And  in the last session actually if  you were in either room you kind of heard during  the Q&A a lot of  discussion about you have the exploration discovery and  our thriving ocean and  so much information being collected right now. What  in the world do we  do with it? So I thought it was a  great teeup to this session  here. As we discussed earlier, my background is  in deep-sea exploration. And  what that means is we go to  sea with big ships,  big vehicles, human-occupied submersibles or  remotely-operated vehicles, autonomous vehicles. And now increasingly cabled observatories that are on the  sea floor collecting data 24 hours a  day. And every day we  collect terabytes and terabytes and terabytes of data.  And oftentimes the largest  percentage of data is video. So we have high  def video. 4K is coming  online. 8K will be coming online in the near future. And  what in the world do we  do with all of this? After a cruise, the biologist  on board might go back  and look at the video for whatever particular  animal they might be  interested in. But oftentimes, a lot of this  data ends up on hard  drives, on servers, in a closest. And isn't accessible. And  even if it is accessible,  if it is publicly available, it's really hard to find  and really hard to use. I  just tried to get a bunch of NOAA data,  which is technically publicly  accessible. But it was really a good thing I  knew the right people in  the Ocean Exploration Office to contact to say, how  do I actually get what I  need? Because it was a challenge. So underwater video.  I'm going to make  all of my points painfully obvious. It's difficult  to find. And difficult to  use. Not only that, when you're on a  cruise, you'll have a wide  range of people annotating the video. You might have  an intern who has never  been to sea before or you might have a  seasoned professional like Steve  Cary. He's been going to sea for I  don't know how long,  volcanologist, expert in underwater volcanos. But when he's looking  at the sea floor, he's  trying to find rock. He's not caring about whatever  that fish is that was  swimming by. So our annotations oftentimes are biased  by both the level  and the field of expertise of the viewer. And  we heard a little bit  in the last session here that MBARI, the  Monterey Bay Aquarium Research  Institute, Kakani was talking about how they  have this video lab. But  they have the resources to pay people to sit  there and watch video and  annotate it after a cruise. I t's incredible. I don't think  anybody else does that. Do  you? No. No one else does that. (Chuckles).  KATY CROFF  BELL: So even if you  can find the video, even if you  have some sparse annotations,  it's just impossible. So what discoveries still  remain buried in the data?  We have -- the Nautilus, for example, collects  24 hours a day  for 6 months. What discoveries haven't we  made yet that's still  sitting there? Okeanos Explorer, same thing.  NSF cruises. Alucia cruises  maybe now. But anyway, the point is  we have invested millions,  tens of millions, potentially even hundreds  of millions of dollars  into collecting this information and we haven't  made all of the discoveries  that we can make from it. So that said,  we also, in addition to  all of these major oceanographic assets that Woods  Holes or the MBARIs  have, you also have coming online all  of these lower cost  technologies, drop cameras, 360 cameras, open ROVs,  all of these other tools  that are coming online. And what in the world are  we going to do with that?  We can't even get our acts together within the  scientific community to deal  with it. With the increasing ubiquity of all of  these low cost tools, how  are we going to handle the data? And how can  we do -- can we do  it? And I hope the answer is yes. I hope that's  why we're all here today. So  the next section is -- I'll preface this with a  lot of pieces of paper with  my name on it. But none in Computer Science. So  this is my dream as  a scientist for what we might put together.  And that's to combine  research data with citizen data and have some  kind of platform to crowdsource  it and annotate it and then use  those annotations to inform  machine learning algorithms that then can iteratively  go back and forth between  the people and the machines so that we can  start to build a library  of information that can then be used to  go back and either analyze  legacy data, data that's already existing, or create  tools for real-time annotations.  And this is not to take humans out of  the loop. It's really to help  us. Because we can't be the MBARI. We can't have  a room like this full  of people sitting there saying, that's a  starfish. We just  can't. It's crazy. (Chuckles)  KATY CROFF  BELL: So what would  we get from this? I think a few things  and I'm sure there would be  a lot of other things. But one is that  we can really start  to understand global trends in  ecosystem connectivity, in  biographical patterns, in potentially even  behaviors. If you're  looking at videos, you can see how  animals are moving and  responding. And there was something else I was  going to say about that.  But we're going to move on. We can  start to empower citizen  explorers. If people actually have a stake in this,  they are being a part  of how to annotate this massive system and they  are also starting to understand  and to see and to really interact with the  data, not just watch it  in a passive way. Oftentimes like we do  telepresence. But one thing that  was good with the Nautilus was the Q&A active  with people. And I thought  it was a good way to engage with people.  We can also from the  results start to develop curious robots and exploration  tools for people so  that either the robots or the people can know  when anomaly is seen. So  if you don't have the fish person seeing that fish  for the first time, you  might not even know it's a discovery. We talk about  this all the time in the  sea. Like, that's not my field so I wouldn't even  know that that's new. So if  -- but if we can aggregate all of this  intelligence, potentially we can do  that. Now, I'm also not a video producer so  this is a crude mockup.  But you can imagine having these types of  information running in the  background could then inform people in real-time  when you're at sea what  you're seeing. What is this? Is it seen in this  region? Is it new? Should we  collect it? Is this the new depth range? Is this  a new temperature range or  PH? So that you're starting to alert people  to the anomalies and  to the potential discoveries. So in conclusion, I think  that it's time to really  capitalize on all of the resources and funding and  people that we put  into oceanography and really let the discoveries  begin on data that  we have collected and moving forward into the future.  So thank you. And I'll  turn it over to Alan. (Applause).  ALAN TURCHIK: Thanks.  So hi. My name  is Alan Turchik. And I'm the  Product Development Manager  for National Geographic's Exploration Technology Lab.  So the Exploration  Technology Lab is dedicated to creating  tools and technologies  to enable National Geographic's major initiatives.  So National Geographic does  a lot of stuff. So that means we  have to be fairly flexible  in what types of devices that we create. We  create all kinds of different  tools. We have animal borne imaging systems.  we have terrestrial camera  systems. We have underwater robotics. And so  my job specifically is  to take the prototypes that we develop and scale  those for global impact. So  one of the most successful ocean platforms that  we developed is something  we call the deep ocean Dropcam. It's  a Benthic lander 6,000 meter  rated. This is our current incarnation. And it  is essentially a glass  sphere with a camera inside capturing 4K video  data. And we have  lights and a microcontroller. We'll throw it over the  side of a vessel. It's  autonomous and tetherless so it will sink down to  the bottom of wherever it  is begin to record data. After a certain amount of  time, it will release its  anchor and ascend back to the surface where we'll  collect it and begin to  look at the video data. So we have been using  these for about 7 years  now. And we've been on 21 expeditions with these  devices. And we've had  350 deployments. Over 1,000 hours of deep ocean  footage. So most of the  time the -- so these are all of the different  locations that we've been. So all  of the red dots are the different expeditions. Imagine  15 to 20 deployments  in each location. So most of the time  we're going places in the  world that these deep oceans have never been  explored so we're just  sending a camera down to see what's there. But  the question is now that  we have started to amass this kind of  global dataset and we have  these cameras looking in all of these different locations  around the world, what do  we do with this data? So actually we  do have some researchers  at the University of Hawaii that are actually  combing through all of  our video footage right now. But it's really time  consuming to do to sit there  and look and try to identify all of the  different Benthic habitats and species that you have. So being able to automate  the process will speed  up the process of discovery for us. We want  to put more drop cams  all around the world to develop a baseline for what  all of the deep ocean  habitats are. But I think a really important -- another  important aspect of what we  need to do with this data is to think  about -- and this is  especially important for National Geographic is for me  it's storytelling. We have all  of these different data sources that we have about  the deep ocean. And how  do we start to put those together to really  begin to understand the  story of what is happening in the deep  ocean? So humans naturally  are inclined to think about things in terms of  stories. So we want to  be able to really define what's going on in the  deep ocean in this way. So  it's being able to weave a narrative arc through all  of these different data points  that we have in order to be able to  tell a compelling narrative to  really draw people in to what's going on in the  deep ocean. So I just  want to end with an anecdote. So National  Geographic has been really  good about taking visual imagery and weaving  a story with this. And  so that the Dropcam has a lot of deep  ocean data. So in the  1930s there was a marine biologist named William Beebe  and he had this --  it was called the bathysphere. It's a metal  sphere. And no human had  ever been below 100 feet in the ocean before.  So this was -- he  was taking this bathysphere down thousands of feet  down into the ocean. And  as he would descend down, he would look out the  portal and shine out a light  and look at all of these alien creatures that existed  in this area. And there  was a tether that connected his bathysphere up  to his surface vessel.  And he had a telephone that would run up  and he would -- as  he's looking out his porthole, he would talk  on the telephone and describe  the scene that he was seeing before him. And  up on the surface vessel  there was a woman names Elsie Bostelmann. She  was an illustrator. And  she would be rapidly sketching out all  of these different things  that William Beebe was describing. And these  are her illustrations actually.  So these were published in the National  Geographic magazine. So imagine  being in the 1930s and opening  this magazine and seeing  these wonderful images that were there. And that's  kind of the -- what --  we want to generate that sense of wonder with the  deep ocean data that we're  collecting. So thank you. (Applause).  GRACE YOUNG: Okay.  All right. Hi. I'm Grace.  And in my 7 minutes I would like to  share some stories for how  I've seen big data management help us  answer big questions, big  problems. But first, I'll give some background  to myself so you  understand where I'm coming from. When I was here  at MIT, I missed my  graduation my senior year to live underwater in this  underwater habitat called Aquarius.  It's 60 feet deep in the Florida Keys.  And 6 of us aquanauts  were living in this habitat. We were led  by Fabien Cousteau. We were  there running about 6 different science research experiments. As you can imagine,  I was pretty excited about the ocean before  living there for 15 days.  I grew up as an avid sailor and scuba diver.  As I know many people  in this room are. But my first passion  was for technology, especially  robotics and camera systems. And it wasn't until  I got to MIT my second  year that I realized I could combine those  passions into ocean engineering.  And that's what I've been working on  ever since. So while  we were underwater, we wanted to see creatures  that are moving faster than  the human eye can see. And I was down  there because I helped adapt  this ultra high speed camera for first-time underwater  use. This is a photo  of me and my fellow aquanaut Liz operating  the camera underwater. Here  is one of the things we saw. It's a  mantis shrimp. It's only about  yea big. It's moving faster than a bullet moves  out of a gun. We  captured this at about 2,000 frames per second. Whereas,  a human eye can only  see at about 30 frames per second. It was  the first time that we  could see creatures in ultra slow motion behaving  in their natural habitat.  We have footage from dozens more creatures from  just those 15 days  underwater. I was so thrilled I got to dance  underwater. It's one of my  favorite things to do. This was at the end  of my mission. Before MIT I  studied ballet. So it all came together at this one  moment. I'm still trying to  piece it into my story. (Chuckles).  GRACE YOUNG: I  just submitted my doctoral  thesis last month. And my thesis is  on building 3D models  of coral reefs and other underwater scenes  using photogrammetry. This  is important because we know that coral  reefs are like the mega  cities of our ocean. They host over 25% of  all marine life. But they cover  less than 1% of the ocean floor. And we know  that one of the major  reasons why they are able to do that  is because they have  a gorgeous mathematically complex structural complexity. And it  provides niches for food to  grow and for fish to hide. One of the  things that the 3D models  let us do is better understand that relationship  between structure and function  on the reef. And with the 3D  models the last chapter of  my thesis, we're using machine learning to tie  the 3D models with fish  data. And the machine learning can without any  other information learn patterns  in what the fish are attracted to in terms  of 3D structure on the reef  and we can use that information to design better  artificial reefs. The nice  thing about machine learning or the hard thing  is it just gets better  and better with the more data we have. As  long as the data is  collected in some standardized format that we can use  to compare models. So we  were able to learn patterns with just 85  3D models and associated  datasets. Our guess is we're a little bit  better than -- we're  significantly better than random guesses. That doesn't sound  super exciting. But 85  is incredibly small. We really need thousands  of data points to  make our predictions powerful. It was because  of the thesis work  that NASA called last summer and I ended  up working there in this  fairly new program there called the NASA Frontier  Development Lab. This was  started in 2016. And it's -- they are  doing something that I never  heard of before called a research accelerator. The idea  is that they grouped us  into teams of 4 and in just 8  dedicated weeks, we were tackling  really tough problems in r esearch. The problem that  I was working on  was 3D modelling astroids in space. Kind of like  modelling coral under water. And  I think the NASA Frontier Development  Lab was  successful for two reasons. One is  that it was a  public-private partnership. We had these industry sponsors. And  the second was that before  we got there in the summer, we had a  specific predefined problem. I find  that if you don't come in with the  predefined problem, there's this  really bad situation where engineers just  make up problems  to solve. (Chuckles).  GRACE YOUNG:  I really hate seeing this,  especially on the ocean space where there  are so many  genuinely pressing problems where we  need our best  talent to solve. So one of the  things that made it successful  was we knew our problem. Our problem was how  do we speed up the  process of 3D modelling astroids to data  collection speed matches  data analysis speed. NASA Frontier Development  Lab was actually  based loosely on CERN openlab. I worked  at CERN openlab while  I was an undergraduate at MIT in the summer.  And like the NASA problem,  CERN openlab is this unique public-private partnership.  So CERN is an  epicenter for particle physics research. They deal  with terabytes of data  every second. So terabytes every second. And  in the process of  dealing with those huge amounts of data they  help develop the World Wide  Web. It's where that started, where cloud  computing started. They  made these incredible technology innovations along the  way. And again, what  I think CERN has been really successful at  is having a very clearly  defined problem. It was to find the Higgs boson.  And everyone felt part of  that mission even me just as a coding intern  in the summer. It's really  motivating and helps us all stay focused on a  big goal. How many here  have heard of the Nekton deep sea exploration project?  Not that many. Okay;  okay. It's a really incredible program. They  are using man submersibles  to explore the ocean with a focus  on science and also storytelling.  And one thing -- well, my supervisor at  Oxford, he is their Science  Director. And one thing they have done is  before their next expedition,  they had a standardizations workshop where  they decided how  they would collect the data and in what  format. They realized they had  to do it for two reasons. One is it's so  expensive and rare to get  to visit some of these deep-sea sites that they will  probably only have one chance  to do so. So they better do it right. And  they better do it in a  way so the data can be compared across efforts.  And then the second  reason was that apparently we have collected  more data about the ocean  in the past 2 years than all other years  combined. And yet that data  is -- can be worthless unless it's  collected with some  sort of thoughtout standardized methodology. And  again, towards answering  big focus questions. So my ending point  is to ask you all  here, what is the big questions that we're trying  to answer? Is it how  do we analyze thousands of hours of video footage  to find new species? Is  it how do we detect new metabolic processes  under water? Jeff asked  that question earlier. Is it how do we  use our ocean without using  it up? Ayana asked that question earlier. I've shown  some success stories for  how big data has been used to answer  big questions. Those models are  ready for us to use and apply to ocean  science. We just need to  know what our big question is. Thanks. (Applause).  BEN WOODWARD: All  right. Thank you. My  name is Ben Woodward. And I am the founder of CVision AI. I'm an applied machine learning researcher. Not so much an  ocean person, like many of  the other people here. But I come at  the problem from a  Computer Science aspect. So what I'm going talk  about a little today is what  I have been working on. How I see the  problem. What are some of  the themes and needs, which you have  heard a lot echoed  from the previous speakers in previous  sessions. And also what  -- the solutions that we see being  tenable going forward. So  myself and my business partner, we founded this  company a couple of years  ago. We spent most of the last 20  plus years between us in  the defense industry designing image processing, video  processing, for various  systems. Aircraft self- protection systems, which we  like to describe as  teaching computers to shoot missiles out of  the sky with lasers.  Because it sounds awesome. Satellite image registration  for things like  vision-aided navigation in GPS- denied environments. And  then more recently  underwater wildlife identification. We are  essentially applied researchers  with domain expertise in video  image processing. We  know signal processing. Classical methods. We do  things like open CV,  standard computer vision and also deep learning  for a lot of the object classification algorithms that you see making  headlines today out of  places like Google and Facebook for various kind  of automatic image tagging  and things like that. So drowning in data  for poor ocean puns. I  apologize for. As you've heard, it's easier than  ever to put optical  survey equipment pretty much anywhere. As you've also  heard it's almost impossible  to actually handle all of that data to do  all of the things that we  want to do. And the problem is only getting  worse. We already do not  have the resources to process all of this data.  How are we going to  continue to collect more data and hope that we can  get ahead of the game. The  other part of it is that many of these  datasets, as you've heard,  are actually difficult to actually get at. They  exist in disconnected domains  and research labs. And they are not able  to be put together. Even  though they have similar characteristics and can use  many of the same  algorithms to process them, they just don't exist  in a single place for people  to get at and apply those algorithms. And together  the scale of these  datasets are very similar to what you see  coming out of standard everyday  I'll call it object identification. This is my kid  on vacation. This is an  animal. This is a car. All of that stuff. Those  datasets are on the same  scale as the ones we're collecting in ocean  engineering. The difference  is annotation and curation. So I  listed three datasets here.  YouTube (inaudible) has 450,000 hours of  annotated data. Over 5,000  classes between them. ImageNet has 14 million  images in it. a million  of them with bounding box annotations and  over 14,000 classes. Microsoft  Cogo, which stands for common objects  in common contexts or  something like that. Basically they have 330,000  images with not just  localization data but also segmentation masks, key  point detectors, over 150  different kind of image descriptor characteristics  that help people  really develop algorithms that can help  in automated analysis. So how  do we get there? We now have all of  this data. But there's data.  And then there's data that's useful for applying  algorithms to. And that  requires annotation. So how do we get there?  I'll say that even data  that is annotated now doesn't necessarily have  the information that we  want. So computer vision algorithms, especially  object detection, tracking,  requires precise localization data. So what you  see there is an example  of a software tool that we have developed  to essentially allow people  to draw boxes, lines, dots, what have you,  within imagery and video.  And that information, when exported and then  fed into training algorithms,  is what you really need to start driving  down the problems that we're  seeing in this space. So the MBARI having  rooms of people doing  data. Alan mentioned they also have rooms of people  looking at data. Well, you  know, the issue isn't necessarily always a  constraint of resources. It's  a constraint of resources to do everything  you want with that  imagery. Okay? So you can't watch hundreds of  thousands of hours of  video. So maybe you subsample it and watch  every 20 seconds of video.  And then you do counting of all of the species  you see in that. And you  write it in an Excel spreadsheet. Well, that's great.  Now you can submit  your analysis for that. But you don't  have an auditable record. It's  not repeatable. It's not useful for giving to,  say, storytellers who may  want to recognize species or bring up lots of  images of that species. It  doesn't have a record that can be brought back  to the broader kind of  scientific community. So we say we need an  annotated curation dataset. Once  you have that, then you can start enriching  the data with algorithms. So  I've got two videos playing here. One of which  shows early on in the  process you can do kind of computer vision  algorithms on untrained yearly  data. And they can already draw boxes around  all of the fish. Now  you can go to your analyst and say, just  identify what each of those  boxes are. And now you're inserting into the  existing workflow that they  are already doing. But you're creating the  dataset that's needed to  further get higher quality annotations like you see in  the second video. Where you  can now start to do thing like species  identification. And then the  harder problem of multi- target tracking within  kind of occluded and  difficult environments. And those types of algorithms require  a lot, a lot of  annotated data and a lot of training data for these  kind of problems. So that's  what we see as how we move forward in this.  Is get a platform for  people, as Katy mentioned, to get their data out  there. Get it annotated in a  way that starts a virtuous cycle. You can just  pay someone on Amazon Mechanical  Turk or get a citizens science web platform  to draw boxes around all  of the fish. Draw boxes around all of the  things that are interesting in  this image. Then you can iteratively then send those  to an algorithm to train.  Or you can send them to an expert  to then do actual identification.  And you can focus their time. And that's really  a critical aspect of what  we're doing is we're enabling people to focus  their time on their  maximum effectiveness in these types of datasets. So  I'm all out of time. But  I'll just say the next step is now that you are  able to process all of this  data, how do you save it? So we need not  just larger databases but  smarter ones. We need tools that can --  fast scalable analytics and  then also visualization tools to help point the way  for people who may want to  use that data to tell stories like many of the  other people you have heard  talk here today. And so I'll finish. Bring the  ocean to life. That's kind of  what we want to do. We want to enable people  to tell the stories and  do the analysis they want to do while keeping  up with the way they  collect data now. Thank you. (Applause).  DAVA NEWMAN: Thank  you. Thank you to all  four speakers to get us kicked off. So i'm  going to start. So let's  imagine we have this incredible platform we all  want and we can curate  some of that data with some of the tools  that are available to us  now. Back to Grace's question. But Katy I'll tart  start with you. In terms  if we have your creation platform, what is  the one question that  you want help answering?  KATY  CROFF BELL: In  what way?  DAVA  NEWMAN: What's your  favorite question? We'll open it  here. Let's say we  have the magical platform. I know we  have to make this  platform. So magically we get this platform  for everyone to use. We're  curating the data. What's the first question you'll  inquire about? What will  you ask about?  KATY CROFF BELL: The  first question? I want to  know where all of the shipwrecks are  in the Mediterranean  Sea. Woohoo. (Chuckles)  DAVA NEWMAN: Alan, what's your first question?  KATY CROFF BELL: And what they are.  DAVA NEWMAN:  And what they are.  So identifying them.  KATY CROFF BELL: Identifying them.  DAVA NEWMAN: Yes. It has to be specific.  ALAN TURCHIK: I think it's being able to identify -- just to know all of the creatures in the deep sea and  be able to identify the different  habitats that they are in. Just know  what's down  there.  DAVA NEWMAN:  Right. Has to  be three dimensional. Right? It's a three dimensional  space so we can identify  it. Grace, how about you? You posed the question to  us. But we'll throw it  back to you real quickly here . GRACE YOUNG:  There's so many great questions.  And to be honest, I'm really most interested in developing the data and technology solutions. I want the scientists and the policymakers to define the best question. And then as  engineers we'll tackle it, we'll  do it, if they can give us functional  requirements.  DAVA NEWMAN: Like your cartoon. We need to be solving the right question from the scientist or the most urgent. There are to many questions. But what can  we help them do.  Ben, go ahead.  BEN WOODWARD: Yeah, the  same thing what I want  to do is enable the technology for people to parse through  the data, to tell the stories  that they want to tell. So as Bob said  at the beginning, help  inspire and tell stories. And part of  that is giving  storytellers quick access to the types of things  they want. If they want to  tell a story about killer whales or a certain  type of squid or something  more exotic than that, can we give them  the tools necessary to  quickly find either footage of that or information  about that? And quickly have  them not have to pour over 1,000 hours of  videos for one blurry shot  of that particular instance. So it's enabling people  to use the data  that they have effectively.  I actually have  one specific question. What  was the green net in the  video that the fish  were going into?  BEN WOODWARD: Oh,  so that was an  open end trawl survey. So essentially what  they did was created  a trawl net wide open that narrowed  down. And they put  a camera system in. And what  they usually do before  optical sampling was basically close that net, bring  it to the deck and  count all of the species. Well, by putting cameras  there, they can essentially  do open-ended surveys. They can sample for  longer and do the  video review and have non-destructive sampling. That's what you're seeing there, the  bright green net.  Thanks.  DAVA NEWMAN: Kathy, go ahead.  KATY CROFF BELL: I wanted  to add to my answer. I  read a book last year about Alexander Von Humboldt.  That was the original  name of the Nautilus before  Bob changed  it to Nautilus. If you're not familiar  with him, he basically invented  the concept of nature and biogeography. He  went all over  the world. Scaled mountains  barefoot. Carrying sensors  and glass tubes. Seriously crazy. But  incredible. And put together  the fact you have different geological areas that  led to habitats for  different plants and animals, which we all  take for granted now. It's  like obvious. But he realized that. Wrote  multi-volume treatises on  the subject, incorporating both the state of the  art in scientific knowledge but  also art and music and design and brought it  altogether. And so I feel  like that is something that we're really lacking in  the ocean. We can only  go when we have a submersible or an ROV. You  go to one spot. You  look at that. And then you come back up. And  there's no way to really  connect all of these studies that are going on  around the world. So being  able to see those kinds of biogeographical  patterns worldwide I think  would be huge.  DAVA NEWMAN:  The ocean is a  system of systems. We're going to open it  up. And you please interact  and ask us questions. Again, how do we  curate this data? How  do we share it? To bring all of  the kids on board.  How do we share it? Only a few lucky  explorers or aquanauts. But how  do we share it and bring everyone with  us to this? We're  here with your questions and look forward  to interacting. Who wants to  go first? All right.  It's a pretty simple  question. As I watch video  data from the '80s and the '90s deteriorate on  shelves, should all video data  be saved and archived?  I can take that.  So CERN, like I say,  deals with terabytes every second. But they don't save all  of that. There's no way  like anyone wants that. So they do like  right at the sensor  actually selectively delete data that we don't care  about because it's a  really well understood phenomenon, for example. But  they can do that  because they know what they are looking for  like the Higgs boson.  And they know what's completely irrelevant. I think  with the oceans, we don't  even know. I was thinking, Katy, during  the videos and in  your presentation, there's probably things we're looking  at that we don't  really understand right now. So again, like we  need to know what we're looking  -- have a little bit of an idea what  we're looking for before  we can delete data.  DAVA NEWMAN: But  hopefully -- being formerly  in the Government, but hopefully for  any PI and  investigation that's Government funded at least to  make sure that all  investigators do have -- we have an archive  of that video data  so we can have it. Because those discoveries to be  made, we might not go back  to that place anywhere soon.  I'm asking  the question of whether  we should do that.  Because right  now you're having tapes  sitting on shelves.  Legacy  data used to  make discovery.  DAVA NEWMAN: Data  policy, we talked about  standards. I mean, just the labeling, things like that.  What do you guys think  about it? We don't want to lose  really that precious data  that we have.  One thing I'll  say is possible even  without training data -- I learned this last  night from Gayle who might  be in the audience. It's possible to make a  highlights reel of the anomalies  or what it thinks are interesting clips of  the video. So say  you have 1,000 hours of video on  tapes, you could have  a system automatically create a highlight reel.  It might be missing  some stuff. But you might at least get a  better idea of what it is  or whether or not you should throw it away  or invest in putting  it on hard drives.  DANA NEWMAN: Where  did our ball go. We  have another question. Great.  I guess it's  more of a comment than  a question, a continuation of that. In a lot  of my work looking at  going back to excavations that were done in  the '20s, '30s, '40s,  even the '90s, one of the biggest problems  is we don't know what  needs to be saved. We just don't know. And  it's a difficult decision because  on the one hand, save everything because  down the road who  knows if the particles are falling in  just that angle and  telling us something important that seems  like nothing now. So  it's a huge challenge. I know that  I'm endlessly frustrated all  the time because of the things that we're selective  -- the judgment issue of  things that at the time didn't relate to  the question being asked or  they simply didn't record those things so they threw  them out. And then you go  back to it and it's not there.  Just throwing  it out.  In a similar  vein, the Okeanos Explorer,  so the NOAA Office of Exploration  when they started, I  don't think they recorded anything during  ascents and descents.  They would start recording once they got  to the deep floor. And  marine biologists said, hey, what about -- you're  going through this area twice  every dive so why aren't you recording what's going  on? So now they do.  But it's a good question. There's a lot  of information. What do you  do with it? Should you save it? Could you  analyze a whole bunch of  video that's digital now and run those tapes through  it and just save the  things that you think might be important and pull  it down a little bit but  then you still get into the  judgment  question.  Then again there are  petabytes of cats online. So  why not ocean videos? (Chuckles)  DAVA NEWMAN: We  have infinite storage. We don't  have to make sense of it.  There's a  couple of bunnies with  waffles on their heads.  DAVA NEWMAN: Storage is free.  Right? How we make them go  viral is maybe more the question.  I guess  in this room we  probably all have relatively close shared  values on the  use of this information for  fundamental science, conservation,  or cultural resources. But the history of  the early adopters of technologies  tends to be industry. And the technology  far outpaces our regulatory  and enforcement capabilities. So are we  opening up new  fisheries in places people wouldn't have been  found otherwise by identifying  all of the shipwrecks? We're  not so good  at protecting.  DAVA NEWMAN: Who wants  to take that getting into the regulation and policy decisions?  I  think it's a  great question. But I also think  that it's important to  know what's there. Because deep sea  mining is imminent.  You've seen pictures of these huge  sea floor chomping machines.  Have we even looked to see what's there  in advance of that happening?  So I think we need to get ahead of  the curve on the exploitation  of the ocean. Because it's going to happen. Sorry,  I hate to say it. But  you want your cell phones, you want your laptops,  we need these various  elements. So what should we be doing --  what should scientists be  doing, what should conservationists be doing in  advance of that to  ensure that, hey, maybe that is a habitat that  should be conserved. Let's block  it off and do your thing over there.  DAVA NEWMAN: Opening  some things up. I  love that citizens can track all of the ship traffic.  So we do have eyes on  it for the first time ever. So I think it  empowers citizens in that  sense. That gives citizens the data that they  can be watchful and mindful. Thanks  again for the comment. Please.  I love the  comment that we need  more targeted questions so that we know what  is meaningful data to  collect so we can build the platforms to do  that so reverse engineer it.  One thing I see from where I'm coming from  is it's really easy to  get funders excited about building technology. It's not  so easy to get  funders excited about analyzing data. So I  was wondering what your thoughts  are on that. And how we can start  telling the story around  that, as well.  I wish I  had the answer. But that's  a problem I face, as well. I think  the answer though would be  to look at the CERN lab model  and NASA Development  Frontier Lab model. They are using  existing technologies with  industry. But really pushing them to the  limit. And companies were  interested in sponsoring that activity because it  informs them what the future  is probably going to be. And it helps  them innovate on their own  technology. So that's one way I can see of  pitching it. I would actually be  really curious to hear if anyone in the  audience has other  ideas for that.  You're kind  of working on  that right now.  I would love to  hear suggestions. But I think  machine learning and AI are such buzzy things  right now that it  may be easier now than it once was to be  able to do that. I saw a  hand up with maybe a suggestion.  DAVA NEWMAN: Yeah,  go ahead. We'll throw  the mic over here. We'll come back to you, Alan.  This thing is awesome.  Yeah, this thing is  great. I guess my question  is have you guys explored commercial applications  of the algorithms  you're developing? Some of the  stuff around curious robots,  identifying interesting photos, that seems pretty valuable  to a lot of industries and consumer technologies.   DAVA NEWMAN: Ben,  go ahead.  BEN WOODWARD: I  think what I find is  is actually the opposite. Where what we're going  to find most successful  is using the algorithms from commercial aspects  to apply to this  type of data. So what you'll  find is that  Google, Facebook, or whatever,  they will publish  their algorithms. And they will publish  their code online. Because  they recognize that it's not -- it does have  benefit. But the benefit is in  the data. So that's why we're here having this  conversation is that we  can use commercially available stuff. And so  from already commercial aspects.  So from a funding point of view it's  almost the reverse of that.  It's how can we leverage existing investments to  bring to basically extend  the reach of that technology.  But do we  have challenges that are unique  that haven't been solved yet  in other  industries? Yeah.  You tell me.  I think so. I don't know.  BEN WOODWARD:  I mean I  would say --  From  an algorithm building  point of view.  From an algorithm  point of view so it's  -- you know, the way I see it is  that a lot of the low  hanging fruit is very similar. And we can follow  the exact same pattern that  we have used to now identify all of the  cats in your video. We  can identify all of the sunfish or the sharks.  We can do the common  stuff first. And then people who do analyses of  that stuff can quickly move  on to other things that are of more interest.  Because they don't have to  guess at how many of the common things are.  But that's also part of  their workflow. So it's unburdening people on things  that can easily be  automated to have them focus on defining  what are those problems  that are unique to ocean engineering. I  think that's what  I would say.  I guess I would  also build on that to  ask is there any partnership with industry you  can make where  the data you gather is directly valuable  to one of their activities?  Like a paid service where the data that  you happen to gather  is not only highly valuable to your research but also highly valuable to helping your company comply with some of those regulations.  BEN WOODWARD:  I'm sorry; but  it's --  DAVA  NEWMAN: Go  for it.  BEN WOODWARD: There's a  lot of work on that in specifically commercial fisheries. So having -- fish  captains having the ability  to watch in real-time and have algorithms,  know what's coming  into their net so if they  run into a school of  protected species, they can quickly close their net  in order to be  able to maximize their actual fishing time  because they have  regulations on bringing those and landing them.  So as well as compliance  for things like buy, catch, discard. So  there's definitely a commercial  tie-in that has both a regular video  and also underwater video to  develop these kinds of technologies that dovetails very  quickly with the research  aspect of it.  DAVA NEWMAN: Great. A question in  the back. Let's toss the ball back  there. I see a hand. MBARI.  I'm sorry. Kakani.  So I do have  something to add, too. We have a partnership  with I think the  California Coastal Commission and some offshore  renewable energy companies  to map the bottom of I think  it's in the southern California  coast so they can pick or select a favorable  site for an offshore  wind facility. So there's definitely opportunities  in that area,  as well.  DAVA NEWMAN:  Here comes another  hand here. Go ahead and toss the  ball there. I want to  make a quick comment on the partnerships and  alliances. I think it's really  a new era where Government funded but  working with the  private companies. It's great that we're at the  Media Lab. So again there's a  win-win in it for everyone. Some of the  Government funding. But being  seated by governments. And then just individuals,  too. So it seems  how do we raise all of this up.  It seems by some of  these alliances have lots of great people working on  it. But making it available looking at those public-private partnerships, too. And  I think the ball  is over there.  Yes. So  Grace, you mentioned  that collecting -- working with the  data that you're working  with it's very important to be thoughtful  about the methodology of  collecting the data so it's not worthless  and that these are  often rare one-off events. So this is a question  for the panel. How do  you see that standardized methodology shaping  up? And I  imagine there's probably some iteration  with as technology  improves we are probably able to collect  data with more precision  and with more granularity. So how would  the methodology need  to evolve as t echnologies continue  to evolve,  as well?  Thank you.  I have two quick  comments. One is in general more  data is better than less data. So collect  as much as  you can. You can always toss  it out later. But  two, for the Nekton, it really just took a two-day workshop. They put 16 experts  in a conference room at Oxford with tea and  coffee and they developed  their standardized protocol. They are experts and put it  together. It's not that hard. But  what do you guys think?  Yeah, that's the  thing. We start to  collect more data, it's important that we think about  what we're doing with that  data and as we're -- yeah, it's a -- sorry.  My -- if you want to  go ahead and answer that?  Sure. Well, too,  Grace talked about Nekton.  But with the Nautilus program we didn't  do data center standardization  on a cruise-by-cruise basis. All of the  data collection and annotation  is done throughout the whole program. And in the  same way. So that it  is possible if one were able to get it and use  it to know what formats it's  in and folders and that sort of thing. But  then you have to look  at across the academic community, across if you're  talking about citizen exploration,  how can you possibly get all these  people to agree on  common formats or naming conventions, NSF and the  National Oceanic Laboratory got  together a few years ago put together a  video. And one of the  big takeaways was, okay, we need to  name the video files  the same way. (Chuckles).  But then you've got  to get somebody to change  because if you don't one person -- so  it's hard to change  that kind of culture and community and this  is the way we  have always done it. But if you're  going to move forward within  the research community and within the ocean community  at large, there has  to be some kind of consensus to  be able to  do that. Yeah. (Off microphone).  Yeah, there's a balance.  Yeah, I think  for us, when we -- like originally when we were deploying the drop  cams, we didn't  have a standardized methodology in what we were  doing. It was kind of  just as an exploration tool. So I think that  is something important for us  going forward is that we start to  standardize exactly how we're  using these devices. Every single time we're  doing the same thing  over and over again. And there is kind  of the exploratory aspect.  We want to try something different and see what  happens. But I think it  can't be just that we're trying something different  each time. Because we  want to have consistent data. And so  when we're doing an analysis,  we can do really good comparisons. Like we  want to be able to  compare one section of the deep ocean with another  section of the deep ocean  and there has to be a standard baseline that  we have to agree on  in order to have that comparison. So there's a space  to try to do different  things. But I think in order to create some  kind of baseline, you have  to standardize your measurements.  Yeah, and if you're  looking for innovation in the  data and the data analysis, then you have to  have some sort of like  -- if you're innovating your naming file convention  like I don't think that's  the most important thing. But if everyone is  able to agree on  certain parameters, then you can start to see those  global trends and innovate in  the data and the -- sort of data mining I guess rather than necessarily are you going to buy a Sievert CTD or something else?  DAVA NEWMAN: Maybe  we start with some  of the lessons learned with some of the  standardization and then deep  data, deep mining. I want to thank all  of you participants. We're going  to end on time because we have some great  Lightening Talks I understand now  by some our students. So thank you so  much. Thanks for starting the  discussion. To be continued.  Thanks,  Dava. (Applause).  (Standing by).  Hi everyone.  I'm Devora. I'm a member  of the Open Ocean Initiative. I'll be speaking to  you in a few minutes about  what I'm personally interested in. But we have an  amazing lineup of a lot  of different types of researchers and students that are  all thinking about how to  explore the ocean using art, using sensing, technology,  data analysis. And  we're very excited to have everybody present  to you. We're hoping this  can be a springboard for a lot of  the discussions later in the  day and also tomorrow pitching projects. Getting  funding for some of  the projects hopefully. So we're very excited.  There's going to be a  sound that the AV will put on when your  3 minutes are up. Can  you guys play the sound? (Beep).  That's going to be  your key that you have  gone over. But the structure is 3 slides in  3 minutes. And we'll go  through a bunch of really interesting projects. Hopefully over  lunch you can get  a chance to maybe take a deeper dive into  some of the work. So  we'll get started with Marty who will talk to us  about the Loch Ness Monster. And  we'll take it from there. Thanks. (Applause).  Well, I want  to thank Katy. I don't know  if she's here. And Roxa. This is my first  Lightening Talk. I just  had to learn by Googling what is a Lightening  Talk. So I want to talk about monsters. You guys are techies. So I assume  none of you believe in  silly things like monsters. Well, back -- I was  a student here in the  class of 1962. And after I graduated, I  started making sonar equipment of  all sorts. And I wonder if -- we're starting  on my wrong slide. If  we could go back a picture. I don't know how  to do it. Okay. Well, in  1970, a good friend, my company lawyer, a guy  named Bob Brians, was  obsessed with the Loch Ness Monster. And he asked  me if I would take  my sonars to Loch Ness and work with them to  see if we could find the  monster. So I went along. There was a group called  the Academy of Applied Science.  Or if you read Doonesbury, the academy of  implied science. There's me  in the boat. If you're going to go monster  hunting, you have to wear  a deer stalker. And with Tim Dinsdale and Bob  Brians. Next slide. Oops, I  guess I do it. Well, for years and years  and years people have  been talking about this monster in Loch Ness.  And they have been  standing there with cameras for days and nights. People  have given up their whole  careers to move to the Loch. And 99% of the  time they are looking at the  surface. And a lot of you folks work in  the ocean. You know most  creatures don't ever surface. They are down -- you can  sit in Boston Harbor all your  life and look at the surface, you might see a  few things. You might see  a whale or a dolphin. But most things are submerged.  So when we first went  to the Loch, there was a group called  the Loch Ness Investigation Group.  So I came along. And I decided to try  my sonars. And what I did  was set them up looking into the Loch. This is 1970. And in fact, on my sonar, I saw blobs. And to this day, this is 50 years ago, people are still looking at blobs in the ocean. And sending me pictures of blobs. So I want to get a group together. I want to stop this nonsense, get a group of you together, and find out -- classify these blobs. What are  they? And that's  my story. (Applause).  Hi. I'm -- I  don't know if that's right.  Hi. I'm Shannon Johnson, grad student in the  synthetic neurobiology group at  the Media Lab. So in our group we  have a robot that can  do experiments similar to humans. And we've used  it to accelerate doing  protein engineering or directed evolution. And so I  want to talk to you  about this. Because it allows us the opportunity  to screen genes from  around the world. And open up new frontiers  in having tools for  seeing and repairing biology, depending on what we find.  So it works with a --  you insert a gene of interest into a cell and  culture it for 24 hours.  Then the robot, using a microscope, will look at  the cells, it will  select the ones with characteristics that we want  to look for. The genes  then from those cells are sequenced. And we can  then insert that gene into  other cell types or into animals. And so --  and so we used this  process to create a fluorescent voltage sensor called  Arc on 1. It's  optimized for it's brightness and localization. And so  you can see that we  were able to use it in fish larva as  well as sea elegans and  mouse brain slices. And the robot was made with  official parts and can  work with any microscope that has a motorized  stage. So it's a really  powerful tool for high throughput, screening, looking  at multiple dimensions in  your screen. But it also really democratizes  the process of this. And  so you can imagine instead of looking at  millions of variances from one  gene we are now going to look at millions  of genes just from around  the world and the ocean and every corner that  we can possibly find genes.  So from that find new drugs, new biotechnology  for cures and therapies.  So if you're interested in collaborating and setting up a robot in your  own lab or you want to just discuss things  to search for, you can  come talk to me or email me  at slj@MIT.edu.  Thank you. (Applause).  Hi again, everyone.  I'm not going to  do that. I'm Devora. I am a student in the sculpting evolution group at the Media Lab. I do a lot  of bioengineering but I have  a passion for microbiome. Sort of generally  I have done  terrestrial microbiome research and now I'm  getting interested in deep  water biome research. So for ships you can  obviously go very, very deep  and collect tons of samples. And it's really exciting.  And my slide is  messed up. But you can do photogenic  analysis and you can do  functional analysis on a lot of the microbiomes  you find in the deep  ocean. Anything from viruses to bacteria to archaea. And  all of these things are  super important to the existence of the ecosystem  of the ocean. The  viruses produce and illustrate a lot of  really important material that  gets regenerated and microbes do a lot  of important work with  chemicals and basically just sustaining the functionality. And  so when thinking about  that, the way that we currently collect samples  and try to do analysis  is you send these deep containers down various  depths and then you  basically take them back to your lab and  start doing analysis after you're  already off the ship. But I'm hoping we  can work towards an  on-ship genetic analysis. So doing on-ship genomics  would incorporate collection. But  then you would probably actually do the extraction  on the ship of all  of the DNA. And then you can actually do  sequencing with these nanopore  sequencers you can keep on your ship and  you can use very simple  library preps and try to analyze the particular -- I  guess if you have a  sequence of interest you can try to focus on that  or just try to look at  the total breadth of what you're getting. And then close  the loop. Do the analysis  on the ship. And maybe go back and  direct your different acquisitions  of water based on the initial analysis you  have. So you can  actually reiterate within one exploration on what you  want to work on instead  of basically getting the material, going back to  your lab, realizing you  wish you would have collected something else,  maybe another time point  or another location because you didn't find  what you wanted and  then alternatively you can also try to do  on-ship transcriptomics using a  system that was developed in the Feng Zhang Lab  in the Broad Institute. You  can use this in extracting DNA you have  library prepped and put  through for genomics. And use it for transcriptomics  and try to get more  of a functional analysis by taking this DNA and  making like libraries of RNA  based off of that. And then doing on-ship detection of  the RNA in order to  try to get a better sense of the different types  of genes that you're turning  on and off. Or just the general type  of genes that are available  within the DNA material that you're looking at.  So you can get two  different views. So the functional analysis of the  different properties of the  microbes that you have, whether or not you  actually know what they are.  And you can also get a sense of the  different types of -- or like  variety of the DNA available. Thanks. (Applause).  Greetings. Yeah, that's  me. I'm Mark Adams.  I'm actually -- I work for the  National Park Service on  Cape Cod in cooperation with the Center  for Coastal Studies. And  I'm part of a Research Team that's  doing coastal sediment  monitoring literal sediment processes in sea floor mapping.  And we get to use a  lot of sort of low tech high tech cool  technology like -- well,  with precision GPS, LiDAR imagery, interferometric sonar  to keep track  of sediment movement around the coast. And it's  based on early surveys that  were done in the 1880s by a coastal  surveyor Henry Marindin (phonetic) we occupy a lot of his stations and have  a century scale record  of sedimentary movement. One of the results of  which is we can see as  sea level rises over Georgia's bank, the whole of  Cape Cod is rotating as  more wave exposure comes from the southeast. But I  get to be my own artist  in residence on this. So what I thought a lot  about was the context --  how we convey the context of this data and  information to people and have  them understand not just that they are on Cape  Cod, they are on a  coast of Massachusetts, but they are in the Gulf  of Maine they are in a  larger system part of another larger system. So as an  artist, I was thinking of ways  that I could do this. And I took charts, bathymetry.  And I hand painted this  sea floor map of the Gulf of Maine and  installed it in a museum where  it was for about 6 weeks as a sort of  an arena, a platform, for people  to tell stories in and explore and discover that  there's this whole landscape  under the surface of the water. When you  go to the viewpoint where  we count waves and do our observations, you see  a flat sea. But underneath  it is this whole geography with stories behind  it and interesting names.  And you know, you see the continental shelf  in Georgia's bank. Cape Cod  on the left. Also my canoe is hanging out  in the lobby, which was  inspired by partly by the war canoes of the  Pacific Northwest but also  by Tiepolo's ceilings in Venice as he used  this planets as inspiration  for creating these beautiful crystal blue skies. And yeah,  it's been really fun. But  I'm looking at -- for other ways to apply these  kind of uses of art like  looking at the Solas (phonetic) Sea on the other  coast as a setting that  is normally thought of as a lot of international  and state boundaries and stuff  but actually has a whole ecology of salmon  runs, watersheds, and tribal  territories that don't appear on the map. But  when you look at the  geography stripped of its boundaries, you see there's  a whole other story  underneath it. Thank you. (Applause).  Hi. I'm  Andrea. I'm in the Mediated  Matter group. And I'm to talk about the  exhibition that's downstairs. So  this research began in 2014 with the  development of a fabrication  system that could pneumatically extrude water  based chitosan composites  into geometries that are designed to  respond to structural environmental  maps. So with this printing system  the group could make  these lightweight functionally graded structures. And they  used chitosan which is  from chitin, which is found in the ocean in  all crustaceans as well as  in insects and fungus walls. It's the second  most abundant biopolymer on the  planet. So this is the group that's working on  it now. And in the  second iteration of the project we find that  by tuning the chemical  composition and adding different amounts of  chitosan, cellulose, calcium  carbonate and things like pectin, we can  change material properties and  control the rigidity, flexibility, color of the  structures. With the microscale  chemical tuning we can -- in combination  with the geometries, we  can make these functionally graded structures  that have different  amounts of flexibility and stability and translucency  all within one graded form.  So all of the constructions are highly  environmentally dependent. And  so they are really responsive to humidity  and temperature. And this  points towards a more dynamic material  system that has the  advantage of being biocompatible. So we  spent about a year  developing and characterizing the different chitosan composites  and we formed this  large library on exhibit that shows the  characteristics between flexible to  rigid, dense to sparse, neutral to oxidized  light to dark and  permanent to dissociated. And you can see  them downstairs and we used  this material library to inform the design of the  pavilion where we had a  rigid skeleton with the different skins of  different chitosan composites  that are also biodegradable in water. So the  pattern of the skin is  based on sun, rain and structural mappings  where there are materially  dense regions are more rigid and durable  than the materially sparse  regions. So the panels will change color and  degrade over time. And  especially in the presence of water. And this  degradation will start at  the more sparse transition areas. So the panels  were 3D printed. With  a similar robotic fabrication system. Using all of  these biologically derived materials. We made this pavilion kind of in an  attempt to point towards a  future with what is grown and what is made  and manufactured are linked. And  where the decay of the material is as  important as the formation. So  yeah. Some final still shots. If you have  any questions we're on the  3rd floor in Mediated Matter. Yes, that's it. Thank you. (Applause).  My name is  Xin. I thought there  were only 3 slides. That's what I was told. So  I'm probably the only one who  is actually following the rules. (Chuckles).  So this is  a photo of an  audience experiencing how it feels to be in  tree at the Sundance  Film Festival last year. It's a collaboration project  with me and lots of  people and two directors. Inside this we are  asking a very simple  question, is it possible to feel like you're  someone else or something  else, like a cuddle fish or here is a  tree? So the way we did  it is like we give people this multi-model  stimulations throughout the whole  7 minutes film. So during that time the  audience can see their body  turn into a trunk, their arms turn into  branches and at the same  time their visual elements in a headset and  their body movements as  very, very precisely synchronized with physical  sensations, such as how  the summer evening breeze is feeling like and  the warmth of the sunlight.  And we even give them the smell of the  forest and vibration of a  thunderstorm. Is it playing? So this is our teaser.  So you are going to be  that gigantic tree in the Peruvian forest. So in the  whole film what we did  was we take the audience through the whole  lifetime of the tree.  Starting from the seedling. You can see  at the beginning you're like  this little seed. And then trying to burst out  through the soil. And slowly  you grow into this massive giant tree. And then  in the end is kind  of a set destiny. There should be music  but . .  . Thank you. (Background noise.)  So it's interesting that  actually if you think about  the life of a tree, they  don't really  do much. But the audiences of course  want to move a lot so  what we did was mapping your arm movements  with the branches and  then we have lots of animals and  ants and birds and  flying around and running around and the audience  tends to be very interested because they don't really interact with the  animals as if they are  humans and they were acting rigid as if they were a tree. (Video).  It was very  surprising and powerful for  me to see sometimes the audience  come out of experience  burst into tears. And I think -- I  won't say they believe they  were a tree but I think something else must  have happened there. So when  it comes to nature, I really believe that  empathy is not enough.  We cannot observe everything just from the other  side. Because we are invisibly already part of it. Thank you. (Applause).  Good afternoon,  everybody. We are  Daniel and Siranush. We are both  students in the  synthetic neurobiology group. And we're going to talk  a bit about an art  project we're working towards. So -- sorry. How do  I back up? There. All  right. So throughout the ages, bioluminescence has inspired  myths. And it's no  wonder when massive blooms of jelly fish or  algae can turn the ocean  into a reflection of the night sky ripe with stars  from the depths. One such  myth has long stuck with us. Long ago  sailors in the Indian  Ocean would sometimes encounter massive bioluminescent  blooms. And as  they sailed through the waters, the wake of  their ships would light up  like the spokes of a wheel. As though they  were being carried to their  destination in a chariot of wind and water.  This is called the wheels  of Poseidon. After learning about this I couldn't help  but think, what if the  source of such myths could itself become a medium  for storytelling? What if forms  could be made to appear and fade away  in an ephemeral dance  much like these dolphins etched out from the  ocean as glowing ghosts? To  that end, we've been working towards creating  something new. A  volumetric bioluminescent display. Even scientists  who study bioluminescence cannot  help but be enwrapped by its methos.  You see, the angel Lucifer  or bright star, was cast from heaven into  the depths of the underworld  where he came to reign. And indeed it's in  the depths that we find  our bright and biological stars. For it is  where bioluminescence reigns  supreme. Scientists knowing this named the  molecules that produced this  light for the angel, once a bright star in  the sky, cast into the depths of hell, luciferin and luciferase.  Luciferin is  a collective term for  light emitting compounds found in organisms  that generate bioluminescence to  produce light that's catalyzed from one oxidation  of luciferin using the  enzymes referred to as luciferases. What you  see is the flagellates  (phonetic) luciferin and luciferase of the  firefly. Remarkably, luciferin and  luciferase pairs have evolved independently in almost  each branch of the  tree of life. They serve numerous roles  ranging from communication  to offense and defense. Here you see  the (inaudible), a species  of dinoflagellates with many light emitting  organelles. In the  case of bioluminescence dinoflagellates, luciferin is thought to be a derivative  of chlorophyll that emits light when  the cell experiences mechanical  threats. And it's believed that a sudden  flash of life serves to  startle and illuminates their aggressors so the larger  predators nearby can be  alerted to the tasty morsel attacking the  single cell organism.  And therefore, bioluminescence is a  defensive adaptation of  the species. We hypothesized that this response  can be hacked to  create programable 3D displays made of living  cells and bioluminescence. In  fact, we already have experimental confirmation  that dinoflagellates light  up in response to otoacoustic waves. But  still protruding the dinos  with sound waves won't allow us 3D  control. Instead, we must  rely on interferometric effects. Here you see a pattern  of waves being generated in  water by two sources. And varying the phase  and period of each  millimeter it becomes possible to alter the  patterns being generated. If enough  is involved in the system then a much  larger degree of control  can be obtained.  For instance,  a simple array of  emitters where phase is controlled can be  used to steer and  focus a beam of waves. With a  two dimensional array  of emitters, it becomes possible  to dictate in three  dimensions where the beams are coming  together and therefore, disturbing.  And what's more because of the dinoflagellates  have a non-linear response  to force, that can then be localized  in just one area where  you're focusing these waves. By doing this with an  ultrasonic phase array, then you  should be able to create essentially whatever  image you want etched  out into three dimensions made up of  this bioluminescent light. And  by doing this and building such a thing we  really hope it might be  possible to create a medium for telling new  myths as well as old  ones from the depths.  Thank you.  Thanks. (Applause).  Hi. I'm Ben  Bray. I'm a geospatial applications  developer at MIT sea grant. I'm here to  entertain you for 3 minutes  with a vitreous approach to public oceanography.  My graduate thesis was  actually a simple method for estimating  precambrian atmospheric oxygen using a 3 box ocean circulation model. Here  we go. But as  my visual art practice developed, the lens I  used to view the ocean  morphed from being boxed models to being thin  laminate layers. And the  more deep ocean discoveries I read about, the  more I saw the ocean  as deep and dark in terms of our knowledge.  But very thin and  shallow relative to our influence. So for a recent  art project, I had ladled  glass into a drawn path of the overturn circulation  in the Pacific. And I  took the glass and projected model ocean  temperature change through the  glass onto a rear projection screen  and photographed the refractive  pattern from the other side. That's what  you're seeing here. And that's  what you can see on the 5th floor. You can  see the glass and the print.  And this is a video. Can we play it? Yeah.  At Mass Art I had  the opportunity as a visiting artist to work with  the students in the glass  department and we actually laid in the glass  and the paper. What's  remarkable was during the residency, we talked with  -- I talked with the  glass students as much about oceanography as I  did about art or  glass properties. We talked heat flux, we talked  about circulation and temperature  and salinity. And many times we were  talking about glass properties  and that would segue to a conversation  on oceanography and vice versa  it was a very two-way synergetic opportunity.  This project really involved  a lot of students and teachers and  other artists and as  part of talks, exhibitions and demos. The last thing  I want to show you is  a couple of years ago or more than a couple of  years ago I took a couple  of trips to the arctic. And the first trip was  to Svalbard. And while I  was in Svalbard, I did scanning of Arctic Sea ice  with the 3D scans. In  the year between the trips to the arctic I  took the scans and I  converted to cast glass replicas. And then a year  later after that Svalbard, I  went up to Barrow, Alaska, to the coast and  I brought the sea ice  with me. And I photographed the sea ice  on the coast to produce  what you see here, which is called a gift  from Monacobreen to Chukchi. It's  called a gift for two reasons. One reason is  I lost one of the  pieces in the ocean when the waves washed over  it when I was  photographing it. There's one piece is in the ocean.  The other reason it's called  a gift is because Monacobreen is a region  in Svalbard. And the  Chukchi is the Chukchi Sea. But the other reason  it's called a gift was when  I was on the coast photographing the sea ice,  Brian, Dylan, Aaron and  Simean came over. They were playing soccer  on the coast, regardless of  the fact there were polar bears nearby. We were  all playing on the coast.  They asked what I was doing. I explained it  was arctic sea ice from  Svalbard. I explained to them where Svalbard was.  And we talked about arctic  sea ice in the little time I had. What  I could learn from them  about arctic sea ice because they lived there. And  the other gift I gave  was to them. I gave them one of the other  glass pieces. So I guess I  want to iterate all along the way that when you  talk about artwork, if you're  eager to talk about your artwork and talk  about oceanography, it's very  easy to go between the two. And  I really enjoyed  doing so. Thanks. (Applause)  Hello. My name  is Miriam Simun. That's  how you pronounce. I'm in the  design fiction group at  the Media Lab. So this is  a picture of our  global collective future. At least in the  coastal cities where most  half of the human population resides. And  pictured here are  two humans underwater. Two different approaches  to overcoming challenges to  the human body. Two strategies for  adapting to harsh  environments. And two ways of being  in the natural world. Both  have their benefits and their drawbacks. Inscribed in  them both is a  set of resources, ideologies, techniques and  technologies. Some may  say what is pictured here is the past  and future. But are we  really so sure what r epresents which? What will  the future of the human  look like? So rather than building walls against  the sea, walls that will  often fail and walls that are metaphors  against perceived oncoming threats,  I propose we embrace our rising oceans  onward and upward. How  can we live more intimately with our rising  seas? So experienced divers  can descend on 1 breath for 6 or 7  minutes. This is 28 seconds.  At the core of training transhumanism program that I'm  developing is a question,  how do we know what technologies we  need for human augmentation  if we don't yet have a full picture  of all that's possible with  the biology we already have? It's a call for  evolving the human from the  inside out. To live more intimately with our  changing environment. A  project rooted in embodiment and ethics and  equity. And very much  in love for cephalopods. So the  training transhumanism program  will develop within the human  three key sensitivities and  capacities of a cephalopod. Embodied  tactile awareness and  cognition. Camouflage, which I define  as the hyperlocal awareness  of your hyperlocal environment. And the  ability, flexibility, resiliency to  respond swiftly to the changes in  that environment by morphing  your identity, your behavior, your actions.  And then distributed  intelligence. Because the human is a highly centralized neurological organism, I have a brain attached to the spine  running through the center of  my body, perhaps it takes more than one  person to become a  cephalopod. So I'm interested in our ability to form  and act upon a single  intention with other bodies while retaining  independent decision making.  Beyond negotiation, beyond collaboration, a kind  of radical coming together  into a single organism. And the ability to  come in and out of  that state. So this training at its  core is embodied emotional  and fundamentally group work. Proposing new ways  of being together. Positing  that the future of the human will  come away from increasing hyperindividualism brought on by many of  our digital tools and increasing the neoliberalist values. But rather a training and  love for labor that will  improve our ability to empathize with each  other and with non-humans  while learning to come together in radical  and intimate ways as  the massive ecological catastrophes we face  will require. Thanks  very much. (Applause).  Hello. My name is  Guy Satat. I'm a PhD  student at the Cultural Center at the Media Lab.  And as you know, one  of the big challenges in underwater exploration  is the ability  to take photographs and images  at deep water and  at long ranges. It's hard because  of the degradation  and reduced visibility into deep water  due to dirt, bubbles  and just the attenuation of flight in water.  One of the things I  do in my PhD is developing technologies to  see through turbidity  and scattering materials. So this is an  example of a recent experiment  that I did in imaging through turbid water.  So this system has a  water tank that has water and into the water  we add Maalox. That's good  if you have gas. And if you need to  add scattering into water, it's  good for doing both. So on the far side of  the water tank we have a  target you don't see because of the scattering. And the  imaging system is based on  a post laser and a single photo avalanche  diode or SPAD camera  capturing the data and of course there's an  algorithm that is used to  process the data and recover the images. What you  see on the right is  a comparison of a regular camera, what a  regular camera would image  in these scenarios. And on the bottom  is our approach. And we're  looking at two targets. One that has the shape of  a W. And the other one  has a shape of the plus sign. And the left  column is the case of  just clear water. And the right column is a case  of what happened when we  add the Maalox to the water. So obviously  the regular camera doesn't  add much once you have scattering in the water.  And that's what you see  on the right. It's very hard to distinguish  between or identify these targets.  We see in the bottom our method is  basically almost adherent to  the scattering. When we add the Maalox  to the water, we basically  recover almost the same image. We can literally  see through the scattering  material. In fact between the left column  and right column, there's  100 X more turbidity or scattering in the  water. If you compare our  method to the regular camera, we improved the contrast  in these images by a  factor of 5. We have a different version of  this that's used to see  through fog that's a little bit more advanced. We  can also recover depth in  the case of fog. And we hope to expand  it into the water case, as  well. So what am I looking for? So I'm trying  to expand this and looking  at larger tanks and more interesting scenes. Of  course trying to test  this outside the lab and see if this  actually scales. I'm very interested in looking at different sorts of degradation of the  signals due to dirt and  bubbles and not just scaling in turbidity. And very  curious to talk to people  if you have some interesting applications that  you think this technology  can be helpful for, then I would be  very happy to talk to  you about this. Thank you. (Applause).  Hi. My name is  Allan Adams. And I want  to tell you about the work I do in my lab here  at MIT. So I have -- there  are two parts of our lab. One dedicated to  imaging and one  dedicated to technology development. For the imaging,  please see the demo  we have in the back. I wanted to  tell you about some of  the technology issues that came up when we were  creating the cameras we work  on. So one of the things that frustrates me  tremendously as a physicist  that came into oceanography late in my career  the cost of tools is  a huge barrier to progress whether it's  for science or conservation  or filming. For example I want to control  a camera and place it  30 feet away from me. How do you control that? You're  going to put a line to  it? If you buy an acoustic modem, a  communication device that  uses sound under water, they cost tens of  thousands of dollars, more than  the cost of the light itself so part of  the lab was to tackle  that I started the future oceans lab specifically to  tackle problems like that,  where there's a cost of technology that needs  to be brought down in  particular. So we want to identify key bottlenecks  and tackle them with  things that are familiar from the supercomputers that  we have in our  pockets that we strangely refer to as  telephones. Electronics are basically free. And rapid manufacturing is these days  extremely easy and low  cost. We also are bringing in ideas from  well outside of the field  wherever we need them. So the first project along  these lines is the open  modem. And what the open modem does is  it allows you to  communicate using extremely low cost and low power  tools, sparse data, meaning  sensored data for example. Things that  aren't video but temperature,  connectivity, the sort of things we care  about in conservation and  oceanography. And control. I would like a remote  controller that helps me have  a sensor on a reef without having to dive down  and interact with it directly  or send a cable. And what we have  managed to do is by  focusing specifically on the requirements, the minimal  requirements we need  for those purposes for conversation and for  exploration, we brought down  the cost, both the dollar cost and  the power cost, by several  orders of magnitude. The prototype -- if you go  and buy an acoustic modem  now to control a camera on a reef, the  modem costs on the order  of $10,000. In our lab we have a prototype that  costs us $35 to build. And  the key thing there is focusing on just the  minimal requirements you need  and also treating electronics not as something  to be coddled and  protected by thousands of dollars of titanium  but instead to be used  and distributed and accept the fact that they  will break sometimes. Similarly,  there's a huge problem with biofouling.  So we brought some  ideas from optical physics and from  optical engineering to deal  with the biofouling problem. So this is  the rescanning project we've  been working on. And the goal here again is  to bring the cost down  and the power demands down by orders of magnitude.  And what that let's us  do is it let's us build a camera we  can put into an  extremely rapidly fouling environment. For example a  tank that our colleagues let  us use at BU. And the Charles River  where we can keep  in a rapidly fouling environment, we can keep  our domes optically clear  for a month without any power and for  multiple months using UV. And  I've run out of time.  Thanks  a lot. (Beep) (Applause).  All right. Hi  everyone. I'm Miranda Kotidis. And  I am a graduate student in mechanical and ocean engineering more specifically I work at the MIT towing tank. The tow tank is a bunch of tanks one has a wave maker as you can  see. We do all sorts  of testing of -- we also have a small  tank where we do --  we have lasers set up where we can  do flow imaging. So  the kinds of experiments we run in this  tank are -- just a little  bit of an overview here. So we do some fluid  structure interactions like what you see on the left where you see a  wake behind a cylinder. It's  a very classical problem. Those of you in  fluid mechanics have figured this  out. We also have vortex-induced vibrations. You can see there's a lab set up in the big tank where we towed a flexible cylinder. You can actually see it vibrating. And that's due to the wake behind the structure and we do naval architecture where we can study the wake behind ships and originally this tank was designed for naval architecture.  But we have adapted it to  do all sorts of stuff. On the other side,  we do a little  bit of design work. So we do a  lot of bioinspired design because  we all know that animals are really good at  swimming in water. So we  look at robotic fish. Our advisor the director  of the tow tank  built the first robotic tuna and you can see  our demo in the back  of the area. And we also look at aerial  aquatic wings. We have  this demo available today. You can see this is  a wing using dye visualization  you can see the wake behind it is relatively  clear. That's good because  it helps us with propulsion. And we also  look at seal whiskers.  Seal whiskers have evolved to be able  to very accurately and very  creatively detect the flow around them and you can  check that out for yourself  in our little tank in the demo. And we  also have some pectoral  fin propulsions. This is actually my research. It should  be -- oh can we  go back? That last one should be a video. I don't  know if we can play that.  -- we might not be able to. There we go.  So I actually work on  some transient flopping foil motion to mimic how  pectoral fins on fish actually  work. If you have questions come check us out  in the back of the  demo area. And if you want a tour or come  visit the tank, let us know  and we'll try to schedule a tour for  you. Thank you  very much. (Applause).  Hello everyone. My name  is Veevee Cai. And I'm  an assistant in the Mediated Matte r group here at  the MIT Media Lab and  I'll be talking about my research in  onsite specific construction  using autonomous robotic vehicles and hopefully how  they might apply to  the underwater settings. So my most of  my research involves trying  to use autonomous systems to  enable onsite  construction paths. So the first project  I helped on we retrofitted  one of these vehicles. This is an  aerial lift platform which  provides us with mobility as well as a  large scale arm for gross  positioning. On top of that we put on this  KUKA arm that you see  to position the controls. And we have this large scale  3D printer. But the whole  point is to create this adaptive platform where you  can swap out to be  able to do subtractive, additive or all sorts  of other types of  manufacturing tasks onsite. And so that was pretty cool.  There's that. So -- but --  so that was really cool. But what we were really  curious about is how to  scale this even more. How do you get  robotic systems to do build  things faster and increase their build volume? To  do that we wanted to  create a very simple platform where you could  build lots of them  that would inherently enable collaborative fabrication to  take place. So we  built these little robots. We built 16 to  20 of them. And you can  see the results of them outside over the next  couple of days hopefully. And  they use a UV carrying resin coupled with fiberglass materials to create woven tubular architectures. So in order to apply this in the underwater setting like I said we were very interested in extreme environments or places where humans aren't necessarily able to  go very frequently or at  all and one of those applications might  be for underwater settings  so pictured here you can see the  conch shell sea lab tech  type and currently operational Aquarius project. These are  all underwater facilities for  deep dives. Not really deep dives but for  tests and research and they sort  of did a lot of different types of  week-long, two-week long,  month-long expeditions in order to observe ocean  communities or do tests  on divers and long-term effects of diving on  divers as well as even  as a training facility for NASA astronauts. I'm  hoping some of the  technologies we have developed so far  in terms of onsite  specific construction and autonomous construction you might  be able to build  these sort of temporary research facilities for  quicker and for cheaper.  And one thing to note is that  actually most of these  projects have now been decommissioned and are mostly  because they were so  difficult and so expensive to be able  to accomplish. But I think  they contributed quite a lot to the marine  research ecosystem. And hopefully  some of these platforms might be  able to help do  future experiments. Yeah. (Applause).  Hello everyone  my name is Danielle  Wood. I'm the newest faculty member here  at the Media Lab. I  lead a research group called Space Enabled where  we use technology from  space to support improving life on earth.  In particular our goal is  to help support the United Nations Sustainable  Development Goals. And  data from the ocean we can gain  from satellite observations is one  of the types of information we need to  inform decision making by  governments, by its citizens, by companies. So  we can all help think  about how to improve our life on earth to  address issues such as ensuring  we all have access to clean water, food to  eat, and to the energy  we'll need to move forward. I want to  highlight in particular our  team brings together knowledge and complex  system engineering, satellite  engineering, as well as the ability  to harness social science, art  and design and use data science so we  can invest and make  applications of space for development. I'll take us back  to one of the things  we saw earlier. In particular this satellite-derived  model that shows us  both the sea surface temperature and  the ocean circulation. It's  produced by NASA and brings together a  lot of knowledge from  academics around the world. And it also  is an important of  the physics-based modelling that really is a complex  system model harnessing and  using satellite based and in situ based observations  to give us the best  estimate we have of these complex dynamics in  the ocean. I worked  for NASA for some time and learned from  the hydrologist there to  understand if there's going to be food to  eat in African countries, you  want to start by asking, what's the temperature  in the Indian Ocean?  That sea surface temperature drives the rainfall.  The rainfall drives the  soil moisture as well as of course  many other factors. That's  of course how we understand whether we have  food security and whether  we need to bring food aid and  national collaboration to make  sure there's food to eat on the land. Another  way to look at that from  space is to ask, where is the vegetation and floor  filled based life both on  land and in the ocean. Satellites are one of  the tools that we use  to understand this on a global scale. Of  course we need to make  decisions on regional and community based scales. Part  of my team's goal is  to think about how to design new  small satellites that are  particularly focused on answering questions on  local and regional scales,  combined with this knowledge we have from  the excellent global knowledge  we have from existing satellites and make that information even more useful and even more action oriented for those who are addressing these challenges on an  everyday basis. I'll highlight  in this particular visualization one of the key  benefits is to see also  the changes at the poles, both north and south.  I had the pleasure to  join Dava Newman for a chance to fly over  Antarctica for a day where  the land and ocean meets closely and in  fact are in a sense  indistinguishable. Part of our team's goal is how to  work with artists using the  data we have from space and planes and  doing studies on the ground  in Antarctica to help the world community understand  better how we all  have stewardship of this fragile region of the  world. I look forward to  sharing with you going forward. And I  thank you for  being here today. (Applause).  Hello, everyone. I  believe I am the  last presentation before lunch so I'll promise  to keep it prompt. My  name is Ariel Ekblaw I'm the founder of  Space Exploration Initiative at  the Media Lab. For those of you who  may not know, the Media  Lab is an incredibly diverse place. We have 27  or 28 now different  research groups that span the gamut  from synthetic neurobiology  and art and architecture and design  and now space. The  idea for the space initiative is to be  a launchpad for the entire lab.  So any time a researcher, staff or faculty, student  want to be able  to deploy their existing research into space  or create a net  new space technology that we think is interesting for the frontier of exploration, the space initiative is here to help them do that. In the context of Here Be Dragons, I really think of the  Space Initiative and the Ocean  Initiative -- the Open Ocean Initiative and our  initiative as sister initiatives.  We would love to do projects together and  collaborate on research. In  terms of our mission we take three  concrete approaches to the work  that we do. The first in really  guiding principle is democratizing  access for space exploration technology so the  way we do this  is both through keeping the work and the  research we do ourselves as  open as possible. And also do a few  capstone STEM outreach programs  that are taking off right now here in  Boston and eventually will  scale nationally to support students co-building satellite  hardware that will  ultimately launched into l ow earth orbit here  locally collaborating around the  theme of climate science and climate  investigations. The second is  to build space technologies that revolutionize  the future of earth  while also profoundly benefit life on earth. So  future exploration and life on  earth need not be separate. We are not thinking  of this initiative as a  way to escape the bounds of earth but  rather it's a wonderful  tradition of space technology to benefit life on earth  and how we can take  that thread throughout the work we do.  And finally uniting engineers,  scientists, artists and designers, which I think  is something really unique  about working here at the Media Lab  to push forward on active  prototyping of our scifi future features at scale so  this is when you get  to see what the initiative is. We have 25  plus different research projects in  our portfolio right now and a group of now  over 50 student staff and  faculty who are involved. This is a sampling of  our research. To give you  a sneak peek of what we're working on. Some  of these are now public.  14 of our research projects launched on a  zero gravity flight last year  so in November. You can get a sense  of the diversity of projects  of different fields we're working in, astronaut  tethers, astronaut augmentation.  You guys heard earlier from Xin Liu, who  I believe is still sitting  in the audience, about her fantastic suit in  orbit and looking at augmentation  and how to move and transition in a zero  gravity space. But I would  love to start putting up here our analogues  between ocean and space. I  want to inspire the audience to think about what  we can do together. Is  it telepresence, is it working with groups like  transhumanism, is it working  in groups like Dava Newman is leading  on robotic exploration and  tools for robotic exploration. Maybe wearables  for Europa or technologies  for Europa in a deep sea IC world looking at all of those different opportunities. And finally, if you're around in two weeks come to Beyond the Cradle, an event very similar to this  one where we'll be hosting  to tell you all about the space and the  future exploration. And these  are our deployment platforms that we are  currently researching and launching. Thank you. (Applause)  Thank you so  much to all of  our wonderful speakers. We'll have more Lightening  Talks at 3:30. We're going  to have lunch and demos right now outside  until 2:30 p.m. and  then we're actually immediately going into the  breakoff groups. So stay in  here if you want to be part of Sea Stories.  And go to the lecture if  you want to go to Democratization of the Ocean.  And also make sure  you use the projects and opportunities board. Write  out ideas and try  to get pitches going and just collaborate  and speak with  everybody. Thank you. (Lunch)  Well, good  afternoon and welcome to  the next session. My name is Michael  Bove. I'm here at  the Media Laboratory. We're going  to be talking  about Sea Stories. One bit  of background that  I suppose suits me for moderating this  panel is that I  at one point co-directed something called the Center  for Future Storytelling. Sea  Stories, I'm not entirely sure about that  phrase, just given that  I remember once talking to a sea captain who  said that the kinds of  stories sea captains tell another when they get  together are just like fish  stories but they have better obscenities in them.  But I don't think we'll  be talking about that kind of sea stories  today. But maybe we are.  (Chuckles) But yeah, what we are going to be talking  about is in some ways the  other end of a lot of what we talked  about this morning. This morning  we talked in great depth in multiple sessions  about the acquisition of  information. But the acquisition does not  make the information useful.  What makes the information useful, as we  saw, is the curation  that creates metadata, the distribution, the  weaving together the different  threads from people with different specialties in  order to create a  more holistic picture of what it is that's actually  happening in this majority of  the earth that's the subject of today's  and tomorrow's event. To  help illuminate these issues, I'm joined by  four panelists. The first  one, Corey Jaskolski, is also a graduate alumnus  of MIT. And he's  the founder of Hydro Technologies, which engineers  wireless sensors for  very, very harsh environments like  the ones  we've been talking about all day.  And he's developing new  image solutions to capture imagery. And we'll be hearing  more about that. Also we  have put some of his 3D models on the  very large 8K display that's  just outside the room. If you haven't seen that,  you should. And it's a  touchscreen to you can move things around with  your finger. Susan Poulton  is Chief Digital Officer of the Franklin  Institute in Philadelphia where  she oversees all of the digital content,  including integration of  advanced technologies like VR and AR into  the exhibition space. This is  something that's near and dear to my heart because  one of the things we  do in my research group here in the Media Laboratory  is we look in ways  in which the digital intersects with the physical.  And the goal is not  to replace the physical with the digital. It's to  use the digital to make  the physical more magic. So we spend a lot  of time thinking about how  not to undermine the physicality of an experience in  a place like a museum  by replacing it with an app. Kaitlin Yarnell  is Vice President of  media innovation at the National Geographic Society.  She looks to  identify key partnerships, grants and fellowship  opportunities and works with  creative talent. And she's an expert  on storytelling and data  visualization, visual narratives and mapping. And Brian  Skerry is a photojournalist  who specializes in marine wildlife and  underwater environments. He's  been a contract photographer for National  Geographic magazine since 1998.  And he has spent more than 10,000  hours under water for  the past 40 years.  BRIAN SKERRY:  Not in a row.  Not continually. (Chuckles)  MIKE BOVE: With  that I'll turn over  the screens to Corey. And it's the  green button that  you want.  COREY JASKOLSKI: Thank  you. All right. So  I'm Corey Jaskolski. I'm a fellow at  National Geographic and also  the Chief Technology Officer at Virtual  Wonders, a company  that scans cultural and natural environments like  some of the ones you're  going to see. And as was mentioned, I am  an alumni from here at  MIT. This is me getting ready to go down on  Titanic while I was actually  still a grad student to work on Titanic, on a  Russian sub, 12,500 feet deep.  And looking at some students I see that the  mullet hasn't really made it  back yet. It's possible it wasn't actually in style  when I was here, either.  But I can't believe that. (Chuckles)  COREY JASKOLSKI: So  we have done a  lot of terrestrial scanning. And then later I'll  show you how we adapt that into underwater scanning. But some of  the work we have  done includes scanning of dinosaur finds. This is  a Nothosaur. And this  dinosaur find actually washed out in the  sea and buried in the  silt and became more mummified than fossilized.  But using the 3D  scanning techniques using laser scanning and  photogrammetry, we can  develop these incredible models. Submillimeter accurate.  We can take  them in multi-spectral imaging so we can get  UV and IR data as well.  And get a perfect replica of an object like this  to preserve it for all time.  So along with doing sort of smaller objects like this,  a lot of our work  has been in larger environments. As an example,  we just recently scanned  the church of the holy sepulchre in Jerusalem.  This is the church,  many people believe it contains the tomb of  Christ. And the middle building  there is actually the edicule in which the tomb  lies. And it's actually right  now the subject of a museum exhibit at National  Geographic. We're using sort  of a shared virtual reality by using  projectors on the ceiling we  can turn an entire space into a shared  virtual reality space we  you wear IMAX movie glasses and you and the  people with you fly through  the church and get to experience it in a  way you couldn't even as  a tourist because of how populated it is. Along with  that I can show you  scans with the church. Again, this is combined  laser scanning and photogrammetry.  We can do this by using the 3D  camera using the scan data and  you can get an idea of the sort of resolution  and the color reproduction that  we can do. This is the edicule coming into  view again here. So we  scan the entire place and the beauty of it is  it took 3D scanning techniques is  it took 3 days to scan the entire church and we get a record that lasts forever. Along with that, what got me into underwater scanning and underwater 3D digitalization of these places  was work we were  doing in Mexico. We were developing an  archeologic search drone called  the Ikyakshai (phonetic), eye of the jungle  or eye of the green  in Mayan. This system has a laser system, LiDAR  on it. It's has a  shiny object, the cylindrical object on the front and we  can fly it over the jungle  and take scans of the archeology but also look  beneath the trees because  some of the laser beams make it through the  trees and reflect of the  ground and we can get surface maps  and start finding these  underwater sinkholes, these cenotes, that were so  important to the Mayan  mythology. Given that, we started to document these  sites by 3D scanning them.  This is a picture of one of the places  called Holtun cenote. It's about  a mile from the main the pyramid of Chichen  Itza. The passages into  the water-filled caves or water-filled sinkholes were thought  to be passages of  the underworld to the Maya. And that  was their version of heaven  and thus the most important holy site to  the Mayans. And when the  sea level started going down -- when the  freshwater table started going  down due to drought about 2,000 years ago  or so in Mexico, the  Mayans believed it was because they angered the  rain god, Chaac. They  believed they had to make sacrifices to the rain  god in order to have  it rain again and restore the crops, fill their  cisterns and allow their civilization to thrive. So they would go down into these  places. And the water table  was 20 or 30 feet l ower back then. And  they would sacrifice human  beings and animals and ritual kill pottery as a  tribute to the god Chaac to  try to make it rain again. Well, in one of  these places about 80 feet  down from the surface and then about 20 to  30 feet underwater we found  this shelf. And this shelf underwater contained  some amazing things including  Ice Age bear skulls, human skulls, dog skulls  and pottery. I can show  you a little bit of the process we took to  do the scanning of these  artifacts and the shelf itself. So to get down  there first we have to  repel down into the cave system before we can  even scuba dive. The 3D  scanning we do primarily underwater is photogrammetry  based. We're just using  a camera. We're not even using laser  scanners. We're actually working  on developing a l aser scanner for underwater  application, which we hope  to talk to some of the MIT students about  while we're here. But this  is an Ice Age bear skulls. And nobody actually  knew these Ice Age  bears existed in Mexico. This is the first  one found in Mexico. Anywhere  I believe. So the archeologist is Guillerermo de  Anda, my collaborator, who  found the bear skull got permits for us  to not take it out  of the environment where it would start to degrade but  actually 3D scan it in  situ underwater. We put i t on an underwater  turntable and the process  takes hundreds of photographs of it we  can then reconstruct in our  software to get a perfect 3D model of it.  So this 3D model we  have scanned it in three pieces, because the mandible  is broken in half. But  you can see the resolution and detail we  can get in the resulting  3D model simply from the photographs and 3D  processing of it. The  bear skull actually coming around on the other  cheekbone, they are very subtle  but it actually has cut marks on the  side of the cheekbone which  either could have been rodent post death predation  or butchering marks as it  could have been a trophy site. Interestingly, we  only found skulls down  there. There are no long bones, no backs, no  ribs so. Just the skulls.  So we think it might have been an ancient  trophy site. So along with  smaller objects we can scan entire environments. This  is the sacrificial shelf. There  is a skull in the corner you can hardly  see. This is about 120 foot  long shelf. If we drill in on the 3D model, you  can see the level of detail  we can actually get. So we're able to actually  map these archeology sites and  save the context of all of the parts in relation  to one another. But we're also  able to drill in in detail on a single item.  This is a human mandible  we 3D scanned at that site. You can see the  level of detail. And in fact  on the back of the left- hand side of the jawbone  you can see an impacted  wisdom tooth that we didn't notice while scuba  diving but looking at  the scan after processing it we realized with  an impacted wisdom tooth  that makes this individual probably around 20 or 22  years old so we were  able to date the individual in terms of age. And  along with the 3D scans we  can project on this sort of media, we can actually 3D  print them in color. This is  a color copy of a vase that we printed in  3D from that same site. And  I think I'm almost out of time. But I will  show you one more application  is we use the HoloLens a lot to display this  stuff in augmented reality. What  we can do with this is bring the augmented  reality headset along with us  to the field and show the local  Mayan stakeholders and landowners  what's right beneath their feet. We found  this engenders them caring  about the place and helps them to want to  protect it. Not just Ice Age  bears but they can see the skulls with their ancestors  and interact with it by  way you simply can't do by video. And we  are telling the story of  their ancestors and get them to help want  to protect these areas,  as well. Thank you. (Applause).  SUSAN POULTON:  Hello. So I'm  Susan Poulton. I'm the Chief  Digital Officer at  the Franklin Institute. And what I do for a living is broad based science communication to the general public. And I started -- I'm  all digital. I started at  AOL back when the Internet was just a  baby. And I was  there for 10 years. Then I  was at National Geographic  as the Vice President of digital  media for 8 years  working on science communication. And I actually  worked for Dr. Ballard  in the Nautilus still doing media outreach  and social media  strategy around ocean communication. And now am  at a museum. So I'm  in the business of making things go viral so  we have a lot of  talk about public outreach and how things go viral. And  what we have learned is  people love the ocean. They really do. It's  -- getting them excited about  the ocean is actually really, really easy. I don't  know if any of you  guys recognize this little dude, little stubby eyed  squid. Right? Found this guy  a couple of years ago. Accidentally. It was not  -- we just drifted across  him. And he looked amazing. And we released a  YouTube video on it. And  all of a sudden we had ourselves a phenomenon.  And over 40 million  people saw this video. 40 probably to 75 million  people even got a pair  of googly eyed squid tights. Googly eyed squid  even have their own  Etsy store. So people really love this. People  will get excited very, very  easily about the ocean. So the viral thing  isn't necessarily the challenge.  Really the challenge is moving into action. How do  you take that to the  next step and make it meaningful? So in my  career I had always  believed that bigger was better. That if we reach  75 million people or 50  million people, it was always better than 75 people.  And so I was in  the business of making things huge. And then I  went to work for a  science museum about 2 years ago. I was  volunteering one night at our  astronomy event. I'm a huge space nerd as well.  And this little girl came  up to me. And she's asking question after  question after question. And  she's exhausting my knowledge base. And everything  from the first humans  she got to me how were numbers invented.  I was like okay. And  then she leaves and walks away. And about  a few seconds later  she comes running back around the corner and  she wraps her arms around  my legs. And she says, thank you so  much for answering my questions.  And then she left. And I'm crying. And  the bartender is crying. This  won't shock anybody if you're a parent or teacher  or used to doing things  for the community. But for me I really  came to understand how  important that face-to-face communication was. And  just how much more  it emphasized the message and the stickiness  and really came to  appreciate that. So it won't shock you if you  have raised kids. But what  might shock you is how many people museums  reach. Museums reach more  than 850 million people annually in the  U.S. alone, double the  attendance for all major league sporting events  and theme parks combined.  You expand that globally, it's 25 billion people  will visit a museum in  one year. There are new science centers  and science museums  being created everywhere. The reach is phenomenal.  And the other thing  that's really interesting -- you have 62% of  Americans visiting an informal  science and learning venue in the past year.  In this era of truth decay  and a real lack of confidence in facts,  Pew just came out  with science communication report they said science  museums are the most likely  to get facts and sources right over  all other kinds  of content communications, magazines, TV, everything. We  are in this incredibly  unique position in the museum world at  the intersection of trust  and information distribution that is right now I  think incredibly critical and  important. And if you start to like dig even deeper  into the research -- and  I can provide these sources -- that museums  are a more highly  credible source of information than NGOs,  Federal agencies, newspapers.  More trusted. Less likely to have  a political agenda. And this  one is phenomenal. That they actually should recommend  behaviors and actions --  to take actions over an NGO, over  Government agencies. Museums are  seen by the public to actually recommend  a course of action.  How powerful is that? They actually feel like  we should. That's difficult  waters to navigate. We don't want to end up  at the back, at the  bottom, in a distrusted environment. But what an  amazing position to be  in. And the real challenge is -- we've  been in the content  creation and distribution business for a long  time. But we need help.  And museums need help getting out of their own  way to deliver relevant and  timely content to the public. We need better  technologies. Better content. And  better ways to deliver that to the public.  So what I focus on  at the Franklin Institute is bringing all of these experiences  to the floor of the  museum as well as taking what the museum  is doing out to the  world digital media. Virtual r eality. We are partnering  with Corey and his team  to do amazing stuff around augmented reality.  VR. Mixed reality  devices. Artificial intelligence. All of these things  you are working at MIT  can play a role in the space in delivering  these messages to the public  in making it more relevant and combining this  place based and this  digital experience. I'm going to say like I was  not a believer. I kind of  thought I was going to go to museums and fix them  and make them more digital.  And I think I had my mind changed because  I realized that that  personal experience, that it's really at that  intersection of the digital and  the physical where the future of communication about  science really lies. So  thank you very much. (Applause).  KAITLIN YARNELL:  Hi everybody. My  name is Kaitlin. I work at National  Geographic. I want to talk  to you today a little bit about how we  are innovating and how we're  working with the best storytellers in the world. Before  I get into that, I want  to talk a little bit about history. And when  I think about National  Geographic's history and its history of storytelling  and its history of storytelling  in the ocean, it goes way back. In  telling the history of  Geographic's you know mapping and graphics and photography,  it lines up pretty  squarely with my own story within the company. So  this map here was actually  based off of a bathymetric model that  was designed by Marie  Sarp (phonetic). Does anyone know who Marie is?  She's one of the great  unsung heroes I think of ocean exploration and  of cartography. She was  a woman who basically figured bathymetry  before we could scan.  Before we had satellites. Before we had  sonar. She figured this  out based on gravitational models. And then  she worked to paint  this and worked with our artists at National  Geographic to represent this.  Marie was also a woman and wasn't allowed  to actually go on the  ships to ground source this. But she  represents the innovation that  National Geographic was covering even then. So  I started at Geographic 12  years ago as a cartographer. I was working  on atlases and the big  pullout maps that are in the magazine. And ocean  topics were one of my  favorite. I then over time moved into more  information graphics like this  one. So this is looking at tsunamis around  the world. The map  shows where the tsunamis are happening and  then on the left here  we have a diagram showing how a  tsunami actually works. What's  the geophysical process that makes these happen?  So I moved from  cartography into the magazine and worked  with an incredibly talented  team of information graphic artists and  illustrators and cartographers to  bring these stories to life. And what I  think is special about Geographic,  what I loved, why I stayed there so long it  wasn't just about the art  or wasn't just about the mapping. It wasn't about  the cartography. It was  how did we combine this altogether to tell the  best stories? So I always  used to say with the graphics and mapping  department that we covered  things that were either too big or too  small or too old to  photograph. So you'll hear from Brian next who will  show some work that we  collaborated with. And we would provide context around  that. So often people  would ask me, why wouldn't you take a  picture of that? Or the  photographer is doing this what are you doing beside  them? I would go through  the filter of what are the stories that need to  be told that are too big,  too small, too old, too complicated to take a  picture of. And you  can usually illustrate that through maps or graphics. I  had the great pleasure to  work on this piece in the magazine. And I  think Bob is in the room  and will know this ship well. But I want to  dissect how we work on  this. Because I think it's relevant today. This was a  print piece. It went in  the magazine. It was a poster that pulled out.  It showed how the  Titanic came together. And people see these finished  products thinking that's great  you just looked at some pictures or saw  a model and drew what  the boat looked like. Well, as you guys know  no one was there to  watch this happen. No one was that deep. Everyone  who was involved in  this tragedy was thinking about other things rather  than how the ship was  breaking apart at its moment. So we worked with  the best sources. And this  is a thing that I think is very, very  key to storytelling. And visual  storytelling is no different to get the accuracy  and the facts exactly right.  You can often write around a fact. You  can write around a  process. But when you're illustrating it, it has to  be precise. You can't qualify.  So this was an email that was sent to  me from JC, who is  James Cameron, who had developed a model of how  the ship broke apart. He  was working with the best engineers at the  time to talk about the  different stages. And you don't have to read it  all. But he's going frame  by frame by frame pointing out errors. And this was  the grayscale model. I was  working with a 3D illustrator named Nick  Kaladracus (phonetic), who  is incredibly talented. We kept sending drafts not  only to James but about  8 to 10 experts. Versions and versions of this  in which we would move  the angle 10%, 20%. And those of you who  work in 3D know that  this is one of the beautiful things about 3D is  you can change it but  it's not easy to render, render, render at this  quality. But the point is  Geographic gave us the space and time to fact check  and get it right. So this  is what it looks like when you zoom in there.  And we're finally getting it  right. To produce this final piece of content. And  the reason I wanted to  go through one piece is to show the level of  accuracy that we work at.  It's a different form of storytelling that I think can  be just as informative. So  what am I doing now? I'm working on  the nonprofit side of Geographic.  We are looking to fund this list of types  of individuals. We have a  lot of our Explorers into the room some fall  into these categories. Some  are more traditional explorers, which are  scientists and conservationists. But one of the qualifications I always make  when I talk about funding  these is we want to fund them in partnership.  We want to pair them  together. So how do you take a team  that is a cartographer and  a wildlife biologist or oceanographer and photographer to  tell better stories? In  the same way we couldn't have  done that Titanic illustration  without having the scientists there, I think  that applies to all of  these groups. And then finally, I wanted to end  with Katy asked me to talk  a little bit about what she thinks I think the  future of storytelling is. And  that is a big question. But I really want us  to focus on what's the  right method for the narrative. One of the first things  you learn in design school  is what is your purpose and audience? Who are you  designing for? And to what  end? And I think that that's not going to  change. We can get very caught  up in the AR and VR and what's going to  be the next thing. And  thank goodness there are institutions like the Media  Lab and MIT who are  thinking and pushing the boundaries because we will  employ it for storytelling.  But I think sometimes we just have  to think about what  does the audience actually want? How will you reach  them? Where will they be?  And a still frame may still be the best  way to move action. A  three-minute doc may be the best method we have. It  may be a map. Oftentimes  it's a combination of all of those. But I  would challenge us as we  think about tomorrow and the students here to not  just go for the new  and the cutting edge. Yes, figure out how to go  there. But think about what  are you actually trying to tell? What's the story  you're trying to tell? Who  is the audience you're trying to reach? And I  think that will inform the  best story line. Thanks. (Applause).  BRIAN SKERRY: Right to the  second. I was told I had  10 minutes, by the way. (Chuckles)  BRIAN SKERRY:  Good afternoon. My name  is Brian Skerry. I'm a wildlife  photographer photojournalist working in the ocean. Always a little intimidating  being in a room  full of scientists. Especially with this on I feel  like I should be asking you  if you want fries with that. (Chuckles)  BRIAN SKERRY: But  anyway, I have been scuba  diving for 40 years. I made my first  dive here in Massachusetts just  about 40 years ago. And the last  20 years telling  stories for National Geographic as a photojournalist.  During that time, during  these 40 years, I've spent as much time  as I could underwater to  seek out those illusive moments, those pictures  that might resonate with  readers around the world. I've sort of come  to see my role as an  artistic interpreter of all that I see. The 10,000 hours  that I've spent underwater is  really about trying to find those illusive moments.  I need to understand  the science. But what I'm really trying to  capture is the poetry. Because  I've learned over the years that a single  image can resonate with people,  on an emotional or visceral way. And that  people will remember still frames  in their brain for the rest of their lives.  So if we're going to move  the dial in favor of conservation or storytelling,  getting people to care  about our planet, specifically the ocean, it's  about spending time under  water and trying to find those illusive moments.  Now, in natural history  storytelling some of the more exciting pictures  I guess are those of  wildlife behavior. It could be a leatherback sea  turtle, an illusive animal  feeding on a pyrosome. This is a picture I  made in the pelagic waters  off of the Azores. Pure serendipity. I was out looking  for bluefin tuna and out  in the distance, I saw this leatherback feeding.  And prior to this  picture, we didn't even know they ate pyrosomes,  this colonial tunicate animal.  Or it could be opalescent squid over the  Channel Islands in California  mating at night, when the male embraces his  female his arms turn red  to warn off other competing males that, hands  off. This is my girlfriend.  It's those kind of pictures I've looked for  over the years. Generally  speaking throughout my own personal career, my  history, I've wanted to do  this as simply as possible. Just getting in the  water by myself with my  scuba gear and my camera. This isn't me. It's  a photo I took of another  diver. But the point is trying to do this as  easily as possible without a  lot of equipment has usually been my goal. Because  I like to have that  camera in my hands. I want to compose the  picture. Adjust the light. Do  all of the photographic sort of fundamentals to get  that image right. But I've  also learned that it is important to embrace  technology as a storyteller.  It would be foolish not to do that.  Some of my more recent  pieces for National Geographic magazine were 4  consecutive stories about the  top most predatory species of sharks on the  planet as a way of  giving sharks a makeover. We still kill 100 million  sharks every year on Planet  Earth. And I wanted the reader to come  away with a sense of  magnificence of these animals. So one of the stories,  the most recent one, was  the story about mako sharks. Not trying to  portray them as puppy  dogs or something we s hould hug. But as a  predator that should be respected.  And this is an animal that is endothermic.  It can generate heat in  its body. Because of that, its musculature is  more superior maybe than  other sharks. It can swim at bursts of 60  miles an hour. So I had  the idea although I typically work in print medium I'm  also doing a lot of video  these days I had the idea of trying to build  a camera system that would  show the high speed predatory nature of this  animal. So I found an  industrial camera used in manufacturing. And I put it  inside a tote cam. Built  it at Woods Hole my friend Lou Lamar. And was  able to deploy it one  day in New Zealand. I only had one day. I  was working with a marlin  fisherman was towing a mullet bait. And he said  makos would come in on  that bait as well. So shooting at 720 frames a  second I was able to  get this very high speed slow motion predation attack  on the mullet bait here  of a mako shark. And this runs for a  couple of minutes. I'll show  a few more seconds of this. But I think as  a storyteller it's important to  do these kinds of things, use technology, find new ways  to embrace them to get  people to see a new way with these  animals and hopefully gain  some appreciation along the way. Also, another story  that I did for the  magazine about great white sharks. I worked in two  locations. In Australia, because it  was a place I could work in the Benthic  area to create images that  are not usually seen of great white sharks  swimming through forests. But  I also worked here in Cape Cod in  Massachusetts because what's happening here is unique in the Animal Kingdom.  We have a newly emerging  hub of white shark activity only since 2009. This  is an aerial view of  a white shark hunting along Monomoy Island. To try  to get pictures of these  animals I had to build a seal decoy.  Because these animals they  can't be chummed in. They are singularly focused  on the gray seal population  out there and no bait in the world would  get them close. Couldn't use  a cage. It was very shallow. High current area.  Murky water. So thanks  to the National Geographic Society I was able  to get funding to build  this high tech gray seal. We had an  anatomically corrected head with a  model maker. I had fiberoptic cables with video  cameras, still cameras. We  deployed it night and day. And sharks just  laughed it at. They had  absolutely no interest in this thing at all. So  Version 2 of my seal decoy  was a much scaled down version. But still I had to  figure out how to put a  still camera that I could wirelessly trigger. I didn't want  any cables in the water.  I had to have a video camera I could see  in real-time what was happening.  The hope is a great white shark would swim  over and sort of just  smile for the camera. I wanted to be able  to make a portrait so  people could see these mysterious beasts that they  had heard about. I  was hoping the shark didn't eat it because then  it would be back to  the drawing board. Well, sometimes the shark ate  it. As we see happening  here off of Monomoy. It was about 50 yards  off the beach where he  was eating my decoy. But nonetheless, it did work.  Incidentally this was published  as a double page spread in National  Geographic a couple of years  ago in July and Cape Cod Chamber of  Commerce was very happy  about that. They sent me a big  fruit basket they  were thrilled. (Chuckles)  BRIAN SKERRY: But using that technology I was able to make the first high resolution photograph of a great white shark, a portrait of  one of these animals  in shallow water. So I think it put  a face on these animals for  readers of the magazine and showed that science is  just beginning in this  newly developing hub. But you know, technology itself with cameras just for the photographer has really progressed magnitudes in recent years. This  is a photo I made  of a leatherback sea turtle in St. Croy crawling  back in the sea at 2:00  o'clock in the morning. I made this picture under  moonlight. Something I couldn't  have done years ago with film. Or another  image I made in Toyama  Bay in Japan with this type of squid called  a firefly squid. After  mating the female washes ashore when the currents are  just right on a few  nights each year. And they glow on that  volcanic sand. Again, the low  light of capabilities of cameras allow photographers to  do things we couldn't do.  This is a story I did on  the Mesoamerican Reef. I  photographed cubera snapper spawning at dusk, an  image that simply couldn't  have been done with film. But today I can  do it in essentially darkness  -- almost darkness and show this amazing  wildlife event that  encompasses astronomy, biology and oceanography. So I  have also worked in  the deep ocean with submarines. But you know as  interesting as this is, this  was a project I did in a place called  los Camellos off of Costa  Rica where I was photographing a submarine with  an ROV that we  adapted with cameras. It was great. It was  a three dimensional sort of  chess game we were trying to control everything.  And we make these  images. It was interesting. It was over  a dormant volcano, the  caldera of a dormant volcano. But in terms  of trying to photograph wildlife  for me inside the sub, it was very cumbersome.  I had a laptop. I  had to open windows and close windows. For wildlife  moving quickly I really  couldn't do anything really in terms of real  behavior. So Katy had said, you  know, talk a little bit about what you do and  then what you would like to  do but can't do now. So my latest project  for National Geographic is  a multi-year effort looking at whale culture. Sort of  looking at these societies in  the sea. And helping people to understand their  identities, that they do  have personalities and family groups and what we  would define as culture. And  I think it could be a game changer in  terms of how we see the  ocean. But we need those tender moments. This is a  picture I made of a mom  and calf in the Cook Islands last year. But what  I really want to be able  to do is see what's happening in the deep  ocean. Animals like sperm  whales spend most of their life in the deep  sea. They only come up for  maybe 20 minutes at a time to breathe. And in  those 20 minutes I have to  get close if the animal will let me. I have  to photograph interesting behavior. So the real action is happening down deep. I  would love to see an  autonomous vehicle that is stealthy, that's quiet, that  can move fast, can  maybe be programmed with an algorithm to hone in  on the sonar of the  whales when they are feeding on squid at 600 meters.  And be able to shoot  in virtual darkness, get these pictures of what's  happening down there. I'll close  with this photo I made in Dominico last year.  This is not a mom  and calf. This is actually babysitting. It's culture in  these whales where the  mom is down deep diving on squid. And while  she's diving, the calf is  up in shallow water being looked after by one  of the other adults in  that family unit. And that's the important story telling  picture. But if I could  combine that with a photo of mom at  600 meters swimming through a  prey field of squid, with technology, wow, then  we would really have a  story. So that's what my hope is. And  I've got until April until  that can be invented. (Chuckles).  BRIAN SKERRY: So if  you can get on that,  I would appreciate it. All right. Thank you very much. (Applause).  MIKE BOVE: All right.  This is your opportunity to  engage with the panelists. Who would like to  go first? Can somebody  pass this -- oh, took somebody out. (Chuckles).  MIKE BOVE: Sorry I missed.  Hello. My  name is Blake. Relatively  new graduate student here. So I  had a question kind  of generally about storytelling and new strategies  for reaching people. So  quick story, yeah, I recently watched the new Planet  Earth series. And I was  surprised at how -- I'm ashamed to admit  this. But how kind of  unimpressed I was relative to the first Planet Earth  series. I think the first  one was so ground breaking in the angles that  they were able to get.  And it seemed like 10 years later the amount  of CGI and technology that  we had been exposed to since then I think  it kind of desensitizes you  almost to how truly amazing these shots are. So  I guess my question to  that is, can you think of any ways -- anything  in your playbook that would  still allow people to be impacted by the  beauty of the natural world  if these techniques might be going stale? And  I'm not sure they  are. But --  I would only  say to that, if  I can jump in, for me it's  about context. I think having  powerful visuals is essential. You have to have  pictures that sort of  grab the viewer. But ultimately, we're a  culture of storytellers. And  from the days around the campfire, it's  really about that. So the  image or the motion picture, becomes that much  more powerful if it's told  in the context of something that matters to you.  And I really believe that  -- and that's not always done well. But it  can be. So I believe that,  as I think Kaitlin said, the quest for technology is  going to be essential. But  along the way, let's not lose that storytelling  component. Because if it's  just about sort of whiz, bang, and what's  the latest and greatest,  then we lose something. So it's really  about that, as far  as I'm concerned.  I would just  add onto that and  say that, you know, there's been  so much fear  about Google Maps is going to  make cartographers obsolete. And  Instagram is going to make photographers obsolete.  And I think what  it's actually done and what you're seeing is that  it's taken all of our  visual literacy and just bumped it up. So it  means we're all exposed to  all of this great imagery. And we know how a  map works. So our standards are  up here. And so it means that photographers like  Brian or the best  filmmakers or people who work in these  new forms of immersive  mapping have an audience that's harder to please.  But what a wonderful  thing. Right? Because it means that people will appreciate  the best. And the best  will rise out of the volume. But to Brian's  point I think it doesn't  take away the need for narrative. In fact, I think  it makes it more. Because  to use cartography as an example everyone today  can take a good  picture, especially with what we have  in our  pocket. Right?  Well -- (Chuckles).  Many people  can take a  good picture. But very, very  few people can craft  a good narrative and put it in context and  can make it apply to peoples'  lives, especially a broad public.  Right. I just --  something came to mind. I  look at my good friend Scott Kraus a great  whale biologists at the  New England Aquarium. I did a story with  Scott ten years ago on  right whales. And now that I'm working on whales  again, we have been talking  a lot recently. He reminded me of a story.  It will probably feature in  this new story that I'm doing for the Geographic  now. But it's a story  about the most endangered whale in the world, the  North Atlantic right whale. And  several years ago -- you can correct me where  I'm wrong with this. But  several years ago a right whale was seen off  the coast of Norway where  they don't ever see North Atlantic right whales.  And somebody saw that  whale out there for several days just swimming  across this stretch of  coast. They took a picture of it and sent it  over to Scott's team at the  aquarium to see if they could identify it. And they  did because they have an  ID database of all of the animals. They knew the  whale and said why was  it over there in Norway. Some further research  was done. It was  determined that that stretch of coastline in  Norway, many years ago, I  don't know how many years it was ago, Scott,  a long time ago there  was a whale factory where they processed and killed  right whales. And the right  whales had all been wiped out. There are none  anymore over there as a  rule. And the only thing that these dyed  in the wool scientists could  imagine was that this story had been passed  down of the eradication  of their ancestors. And this whale was going over  to sort of pine for  that. Now, that's a big stretch. But if you do  a story on right whales and  can include a story like that, again that will have  to be at the text but  that's what we do at National Geographic magazine,  it becomes something  much more powerful. You begin to  see these animals as more  than just an animal. That they actually have  these identities. And as a  storyteller you have to get the great pictures. For  me it's about getting the  guy in the dentist office just flipping through  the magazine, you have  to make one that's going to grab his  attention. But maybe he reads  the legend, the caption, and then wants to read  the story and you walk  away with a much more complete story. Those  are parts of the  equation, as well.  Great. Thank you very  much. And also those were  fantastic photos, really beautiful.   Thanks.  I would say to  your point too on Planet  Earth I think the second time around you  saw it and weren't as  impressed with the new one is we do get  jaded with seeing the same sort  of media and same sort of formats. Again, as  storytellers or competing with  media eyeballs on stuff, we have to  compete with the sneezing  panda on YouTube. And that's hard to do.  So from my perspective using  technology as a display technique, using new augmented  reality and virtual reality  type tools, I think we can get people  engaged with stuff a little  bit longer and impress people again like the Planet  Earth did. So I'm hopeful  we can find ways to use these new technologies  to still bake your  noodle and keep you excited about the ocean  and other places you  might see in them.  And I think  thinking through 4D and  a place based experience it's the right  technology for the right  story and the medium. And I'm not  sure we know what  all of those are. We haven't  figured out how  to communicate climate change to the public  in a broad and effective  way. That hasn't yet happened. We were just  talking the 4D experience.  Where you feel the warming of the planet  and actually feel these  things, is that more effective. And in some cases  it could be an image  of a starving polar bear that goes out.  And that single image  -- different moments, different mediums can capture it.  But I love this  intersection with the augmented reality and virtual reality and  4D. It opens up an  entirely new world of storytelling. Disney has been doing  it for years. But how  do we make it more affordable than Disney and  take it to more people  to make it connect?  There's a topic I  would like to address to  all of you because nowadays each of us sees  more photographs per day than  at any point in history. And we're starting to  see more video or at  least more parallel bits of video that we can  have access to. How do  you make people care about quality given the  huge quantity of material  that's there? We could say the same thing about  CGI. We could say the  same thing about 3D scans. There are enormous numbers  of 3D scans of  things that are online that people  can play with  and game engines.  I think it's easier.  I think the more volume  and more low level, the more the  stuff like Brian's  images just pop out. I think it's  easier in that sense.  I think it's much harder for those of us  who work at editors because  you have to weed through it. But I think  to my point before, I  think there's -- our visual literacy is so much higher  that we're looking for the  things that are better. We're all reading -- an  analogy is we're reading at  a higher grade level than we used to,  which allows you to  appreciate James Joyce.  That's  a good  analogy. I don't think  it existed before. I don't  mean to oversimplify it. But I think  particularly with some of  the advances in technology in terms of how do  you weed out a lot of  the noise and a lot of the things that  don't matter. I was interested  in the conversation in here before about data and  how do you use some  AI to pull out the footage that doesn't matter. I think  we're doing that. But right now  we're doing it with editors.  Yeah, at the end  of the day I think  we can get very wrapped up in how great a  photograph is or is not.  And obviously at a magazine like National  Geographic there are very  high standards. And with the reduction of  pages these days because  of budget cuts, it becomes a reality where  instead of the photo story  it's more the story photo. One photo sometimes  can tell an entire  story. So photographers have to be creative and  look for layers in the  picture. And you try to include many elements and that's  not always easy to do  in the wild. But at the end of the day  I'm also a believer in not  -- I'm not being a snob about it. I think  that photography like so many  things is an individual pursuit. It's not totally  objective. And if you like  a certain picture, then that's fine. If you're  on Instagram and something speaks  to you, you know, that's fine. You don't  have to know everything there  is to know about photography or be a  professional. I mean, it's  how you communicate with people. So the  best photographers, storytellers,  ultimately have learned how to do that effectively  over time. And do it  time and time again every time they go out in the  field. But no, I don't think  it has to be rocket science,  either.  I also  think that the more  that people are taking pictures with their phones, their an  appreciation of how it is to  take a great picture. Right?  That's true.  Yeah; yeah. I  think so.  My immediate reaction  to your question was  you can't make people do  anything.  (Chuckles).  I think I've  learned that, if I have learned  one thing in my career. It's also meeting people where they  are and bringing the content to  them in a way -- I feel like we've often  been like this is us. And  we'll drag you to us. And museums are very,  very good at that. It's  like this is how we tell stories and if you  don't like it. And it's like  no, that's not how it works. We have to come  to where peoples' expectations  will be about how they will consume  this content. Where they will  consume it and meet each other in the middle on  that front. So I think there has  to be that acquiescence, as well.  And I think,  too, although there's tons  of videos and photos and CGI 3D models  out there, people are  still drawn to genuineness. You know, at National  Geographic we don't take  pictures of game farms. It's actually a wild  tiger or a wild  elephant. Likewise when we do 3D scans, they're  ultra high resolution copies of the  real place, not a 3D model. And I think that  an honest real look at  things still draws people in. And there are lots  of studies show that  that engenders caring more than modelled and  staged photos and that  sort of thing.  I don't know  where the pillow is.  Somewhere in the back.  They have it over here.  Hi. My name is  Matt. And I had a question.  Since a lot of the conversation has been around  the visual medium, video,  photos, quality and whatnot. But I wanted to  know how you see  other forms of communication, particularly the written  word and also  the spoken word. Since I'm a huge consumer  of podcasts. That's how I  get a lot of my hard- hitting analysis and news.  How have you seen  those mediums change? And then as a follow-on  to that is what of  these mediums are most effective in the ocean  space like in the sectors  that you're talking about or what are they  most underutilized? Like do there  need to be more podcasts or more blogs out  there talking about the kinds  of issues that you address?  I mean, I think that  to go back to what's the  best medium to tell the story, oftentimes the written word  is like -- I  alluded to this. You can provide context and you  can qualify things in a  way you can't visually. Visually it's like, here  it is. Unless you're making  a process video or something. But I think the  written, spoken word is so  great at that and so great at analogy and  metaphor and ways that we  can't visually. I would also say, though, you know,  we are -- and Susan  talked about this. We are competing for peoples' time  more than anything. So we  all I think you know all of us that  once were fortunate to be  at a certain socioeconomic level your most valuable  resource is your time. And  that spare time is you're competing against the  viral videos but the  podcasts or you're reading James Joyce or  looking at Brian's pictures  or interacting through a headset with Corey. But I  think -- it is a zero  sum game to some extent. But we should reach all  of the audiences where they  are. But I'll let the more ocean people  talk about the  lack --  I would agree. I  think a lot of it  comes down to the realities of what you can  do with a given amount  of money for budget. So if there's a limited  amount as a storyteller, you  have to find, as Kaitlin, the best medium.  And usually there is  perhaps one best. But if you are fortunate  enough to be able to  sort of reach people through multiple media platforms,  if it's an important  enough story, then it's worth trying to do  that. So with those shark  stories I did, for example, we did magazine stories  we did four magazine  stories. But we did television documentaries. There  was a museum exhibit  at the National Geographic Museum last  summer and now it's  traveling in different venues throughout the country.  There was a book --  I did radio interviews. It wasn't a podcast. I  think a podcast really has a  great value. Even as a visual person, I think telling  a story about sharks or  whales or whatever it might be through audio is  very exciting. I love to listen  to them. I think it's like an old fashioned radio  of a by-gone era. And  I think it's another way to reach people. So if  you can do it, if you  can partner with entities who will tell those stories in  multiple ways, I think it's  effective. And I think it's a very exciting time to  be a storyteller because there  are so many ways. You know, I remember all  I cared was about the  print edition of National Geographic for many  years. As technology became  available, I was interested in it. But I  didn't see a value in Instagram  and so forth. But now I get it. I can  reach an entirely different demographic and with maybe just a caption communicate something  that I think is important.  And I think if as a storyteller you miss  those opportunities, it's a waste.  So I'm not sure if that answers your  question. But I certainly  encourage all of those things. And I think, you  know, it comes down to  the resources, what you can do. But if  you have the luxury,  do it all.  All. Uh-huh.  One of the  things I think is underutilized  in storytelling in the ocean especially is audio. You  know, a lot of  the video footage you see, there's no  audio or you just  hear scuba bubbles going. But when you're diving  in quiet underwater, it's  such an amazing place. Whether it's parrotfish eating the reefs or a big bait ball of  fish all moving at once, it sounds  like thunder. Or  dolphins clicking. Or Kenny grumbling at  me in his mask  because it's time to move one. But at  any rate, there's so much rich  audio there. Not that it would make for a  stand-alone podcast. But I think  in the ocean imagery we see, really good audio  could add an awful lot  to that, as well.  There's a new venue  in Manhattan in New York  you can go to. It's called Ocean Odyssey encounter. It's a  branded product through  National Geographic. But it's largely  done through animation.  But you basically take a trip to the  Pacific as like a creature  drifting through the Pacific. And go through these  different rooms and you see  squid fighting or bait ball and all of this really  cool stuff. Some of it is  3D. Other parts are video. It looks real. But there's  one part of that where you  sit on little benches in this room and it's the  night ocean in the middle  of the Pacific. And I've been diving for 40  years and I never experienced  anything like that. You hear whales. And you know,  cetaceans. And you sort of  see this dimly lit thing in the distance. It's  a whale through moonlight. I just  -- I found that -- it gave me chills because  I left there feeling like  I had experienced that, even though in reality, I  never had. But to me,  that was a really creative use of sound in a  way that I had never experienced  before. So I don't think there's any limit to what we  can do. And that's what this  event I think is about.  I think  there was another  question over here.  It's heavier than you think. (Chuckles)  Hello. So  first, Katy, thank you  so much for bringing these amazing folks together  to talk to us about  all of the ways that you're reaching all  of these different audiences. So  if the challenge is to reach a broader  demographic, we're all used to  preaching to the choir. We're doing the same thing  here today. So if the  challenge is to reach a broader demographic and it  seems like you're able to  figure out how to reach across generations, but  a culturally diverse group,  we have all of these different techniques up  there. You use visual  imagery to make things more accessible. You  can change the narrative  and use different media and tools. And you're  using all kinds of digital  crazy ways to reach different audiences. And you  showed a really great  example of how you were able to reach  across cultures with technology.  So if your challenge is to reach a  broader spectrum of the American  public, what do you envision for the future?  I think -- one  of the things I can  speak to, like I didn't have a really good  grasp on a digital  demographic. And then when we went to the  museum and actually seeing the  individuals that come to the Franklin Institute and  this broad spectrum of interest  in science. And I think we tend to  have this perspective of who  is interested in science, that we're often preaching to  the choir. And it really is  -- I mean, we get everybody. Absolutely everyone  walks into a  museum from incredible diverse backgrounds. And  I think the challenge  is presenting the information in a way that's  relevant to them. And I  think that's a big issue is that sometimes you're  just kind of broadcasting  to everyone. And you're not narrowing in on  what's going to be more  relevant to a certain culture or certain socioeconomic  group or different --  thinking through it in different ways, even  just translation and language and  all of those and presentations. So that relevancy  factor I think is  really key to reaching that broader audience and putting  it -- the challenge is you  just can't do it -- you can't slice and dice  it 50 different ways to  reach everybody. So it's kind of going through  when you're telling that  story and just imagining every different person  coming up. That's why  sometimes the one-to-one, having museum educators on the  floor, we can do it  on the fly. Someone walks up to us I  can see their age, who they  are, and I can immediately position what I'm telling them  in a totally different way  and then the next person comes up the  next person comes up.  We are actually most effective at doing that the fastest.  That's the section  when you talked about  the physical and digital.   Yeah.  I would also say  this is one of the  things I'm working on and National Geographic focuses on  is we need to  diversify the storytellers. Because we all have  our own perspective we  have been as fortunate as everyone on  this panel to travel  and interact with people from all different parts  of the world and all  different types of people, our reality and our  perception is only our own.  So if we start diversifying the storytellers, A,  the stories will just be  told from a different perspective. And B, it  will inspire the next  generation to someone who doesn't look like Brian to  go spend 10,000 hours under  the water. So I think that's an important thing  that we talk about. I  hear the narrative a lot in tech. But  it's just as  important to storytelling.  That's an excellent  point. I don't know  a lot about this but I would  also say a big  part of the story I do these days  when I write proposals, part  of that equation is an educational component. I think  with school curriculums, if  we can get a lot of this material that  we're producing -- this new  whale project that I'm doing, when I wrote  the original proposal, you know  I talked about the various media arms within  National Geographic that I  thought it could apply to. But a big  part of that was education.  And while I'm not an educator and I don't know  a whole lot about that, I  think that it wouldn't be that difficult to get  the stills and video  and acoustic recordings of humpback whale songs and  all of these other  amazing sounds into schools. And that could be  a real game changer. You  know, if what I believe is true,  that people understanding that  these animals have societies, that they  have parenting techniques and  feeding strategies, and they isolate themselves by  dialect and language. You  know, in so many ways we can see parallels  to our own culture. I think  if that gets into the psyche, if that gets into  sort of the belief of  our own culture, we won't treat the ocean the same  way. You know, I think  it's going to have that game-changing effect. At least  that's my hope that  without being overtly about conservation, it  will have a conservation  dividend. Because once you know that, you  can't unknow it. That  story of the Norwegian humpback -- right whale. So  I think as -- all  of these things are great points. But I think  getting it into schools everywhere  will be an important part of that equation.  MIKE BOVE: Great.  Thank you very much  to our panelists. We have to move on  to the next session. And  thank you to the audience, as well, for engaging them. (Applause)  This session  is still focused  on exploration and science but also has  a lot of components of  education and public outreach, which will be very  exciting. We have a  new sound for when you go over  time can you play  it for us, please? (Dolphin  noise)  So try to keep  the three minutes or else  you'll hear the dolphins. So the first person will  come up who will be  Nick speaking about sharks. Yeah, sharks? Nick will  be speaking about sharks.  So here is Nick, everyone, from  the New  England Aquarium. (Applause).  Thank you.  Okay. So I see my  clock is already ticking. So I have very little  time. So I'll give you  just very brief background. Much briefer than  usual. I was born  in Jackson, Michigan. And later I discovered  that shark populations are  in trouble worldwide. Mostly due to  overfishing. And that's  because fishing for sharks is different from  fishing for bony fish,  for example. Because sharks have a very  different history. Sharks, compared  to bony fish, give birth to very few offspring  and only when they are  older. They are very long lived. So in  order to manage sharks, we  often institute catch and release rules, where you  have to turn animals loose.  The problem is it's very easy to count how  many sharks you kill when  you keep them. But when we turn them loose  it's hard to find that  number. We assume they will swim off and live  long happy lives. When in  reality we know a certain percentage are going to  die anyway. So we actually  go out with fisherman and tag the animals  that they catch with  these accelerated DataLoggers, these new tags, that we attach  to the fin of the shark  and they can tell us the same technology found  in your Fitbit or  SmartPhone and measure the depth, pitch and tail beat  so we can see second  by second how the sharks swim and whether  they live and whether they  die. So these tags record so much information,  about 100 data points  every second, it's actually too much to transmit  back to us. It has  to be stored to memory. We have to get the  tags back from the sharks  and collect blood as we're doing here. But we  invented this float package here  that attaches to the fin and allows the tag  to be on the shark and  record data and then later release from the fin and  float up to the surface.  You'll see in a second here we attach it with  a tether with a galvanic  release that corrodes in sea water. And once that  link corrodes, the tag floats  up to the surface. We go out in a boat  and listen with an antenna. And  as long as we get within about 10 miles of the  tag, we can find it, pick  it up and not only get the data back, but we  can reuse the same tag  over and over again. This means we can actually get  a much larger sample size  for lower cost than you could we conventional  satellite tags. So these  are the results from work we're doing with  commercial long line fishermen.  You can see we've already tagged over 300  animals. You'll notice certain  species have very l ow post release mortality.  So it's almost impossible to  kill a sandbar or tiger shark for instance.  But other species have  much higher post release mortality. So we're learning  you can't take a  what fisheries managers have been forced to do  for years, which is take  a post release mortality rate from one species and  apply it to another species  and assume it will be the same. You actually  have to get out on the  water and put tags on the actual species you're  working with. And so  that's what we're doing. And that's one of  the ways that we are  transforming science into action at the Anderson Cabot Center  for Ocean Life at New  England Aquarium. Thank you. (Applause).  I think he timed that. Okay. I'm Scott Kraus. I'm Vice President and Senior Science Advisor at the New  England Aquarium. I'm going take  you into a big picture question that's been  bothering me for a  little while. So generally because of the storytelling  that's been going on  here today, everyone knows there's lots of interesting  wildlife in the ocean. And  there are a lot of components to it. Most  of which none of you  have ever seen. And most of the public has  never seen. So for example,  this includes a lot of sea birds which travel from  land to shore. From land  to the open ocean. Fin whales. You have  bluefin tuna on the left  side there. Beaked whales, which I'm sure none  of you have even seen.  Obscure common shelf edge animals at very deep  depths. In the lower right-hand  corner for those who aren't biologists, this is  the only animal ever  developed by committee. Leatherback sea turtles. And  then all of the  midwater fish, including commercial fish species, which  you mostly ever see  in a supermarket. Now, this is what we  do in the oceans. And  most people don't think about it. We are very  heavily industrialized our section  of the north Atlantic. This includes commercial fish  density in the yellow  orange heat map colors. All of the  purple lines represent cables  or undersea cable lines, usually transatlantic and so  on. The large red  blocks are military operations. And there are  light blue colors in there,  which will be wind farms. It does not  include things like deep  ocean dumping sites. It doesn't include the proposed  seismic operations off the  East Coast of the United States. Nor  does it include any  future industrialization that we might think about. So here  is the trick, we don't  actually know what most of those animals require  to survive in the ocean.  The definition of critical habitat by the Federal Government  right now is it's got  to be some place to eat. So if you have  a place where there's a lot  of food for your animal, that's critical habitat. That's like  saying you can live in  a house as long as it only has a kitchen.  Everything else you don't need.  Right? So the way to think about this is  we are imposing an  industrial civilization into the oceans without actually  understanding what the  consequences are for most species that live there.  And it's important for us  to get a handle on this. And our failure  to do so represents actually  a failure in storytelling. Scientists have been too  caught up in the  95% confidence intervals and all of the details  about their science and  not about enough concerned about the long-term consequences  of industrializing across multiple  taxa. Thank you. (Applause).  Hello, everyone. I'm  Mara Frilich. I'm a  graduate student at MIT and at  Woods Hole  Oceanographic Institution. And so I grew up and  I had a garden where I  could plant tomatoes and I could plant strawberries.  I noticed how things  changed throughout the season. The different weeds  would grow depending on  what I planted. Now I'm a physical  oceanographer and I'm interested  in studying how life in the ocean is  affected by ocean physics. And  what's different about the ocean is you can't go  back to the same place day  after day and year after year and notice how  it changes. So what I'm  really excited about and interested in is how can  we do this? How can  we follow particular water masses, particular habitats for  ocean life and see  how they are changing through time in order to  really understand the ecology of  the ocean at the scale at which that ecology  is taking place? So more  than 99% of the biomass in the ocean is  microscopic. So as much as  we can talk about whales and these  macroscopic organisms that are  so charismatic, the foundation of life is life that  we can't see. So one way  we can do this is if we have intimate knowledge  of the ocean physics, then  we can follow a particular water mass. And  as we follow that water  mass, look at how life evolves on this water  mass. We were able to  do this this summer in the Mediterranean Sea. We  saw high chlorophyll water,  which means it came from the surface  where life can grow.  Subducted it below the surface. And we were  able to sample it  repeatedly. We noticed the biomass decreased as we  went down. So the  organisms die as they moved out of the  light. But also that the  community seemed to change. So there was something  happening in the community  process. And this is something we don't  yet know. I just collected  these samples a few months ago where  we saw more prochlorococcus.  These aren't very charismatic. These are  green cells. The  others, sonococcus (phonetic), are orange cells. And  eukaryotes are a little bit  more diverse but still pretty much just round  green cells. But other  changes happened as we went down. For example,  the organisms consume nitrate.  And as they are consumed, the nitrate  goes back into the  water. We saw that happening. The organisms  produce oxygen. As  they were consumed, oxygen was consumed, as  well. Lastly, the amount  of chlorophyll -- of light-harvesting pigment called  chlorophyll increased as we  went down in the ocean, as well. So  I think these organisms were  adapting to being in these lower light conditions.  And what I'm really,  really excited about is not just knowing about  how these ecosystems change  as we follow a particular water mass, but  it's really difficult to  measure the motion of water in the ocean itself.  Could we use the rate  of change of these organisms as they go  through the water to  measure things about the physical oceanography as  well? So using  both physical oceanography and biology at an intimate  level to understand the dynamics  of each of those. (Applause).  Hi, everyone.  I'm Clement Duhart.  I'm on the responsive environments group at  the Media Lab. I will  start my talk with recent research. We show  that 80% of populations  appear in our (inaudible) during the last  20 years. And more than  that 50% of the species cannot be  found anymore. The author  concludes that this happened because of  the large industrial developments  and the large scale industry which has  destroyed most of the  natural habitat of animals. That's why -- this  raised a lot of questions  about the futures that we can expect. The  next generation can discovers  animals and more than that what can  be the long-term consequences  of such drop-down of the biodiversity. That's why  our research group has been  taking part in a restoration a program of  scale in the southwest  of Massachusetts into a (inaudible). We deployed a  lot of sensors in order  to monitor the iteration process during the local  (inaudible) as well as  wildlife activity. Indeed the wildlife activity is  a determinant authentication about  the well-being of the restoration process. For  that we deploy 24  microfunnels in the areas that are processed in  order to detect the  animals. We used deploying technology a system developed  by our own using  this technology in order to learn directly  from the acoustics in the  different sound from the animal. We use a  closed learning loop between  the system. And the visiter of the site,  which includes scientists in order  to teach to the system what we are --  it's supposed to make a  sound. Yeah. So the system can progressively learn  what it looks like  on the animal. And some experts can indicate  to the system, oh, this  animal is probably a frog or a bird or a  -- and for each one in  order to improve the classifier environment. Something that  can be interesting for  the Open Ocean Initiative  is deployed  -- (Background  noise.)  All  right. Is to  develop such technology in the ocean in  order to monitor the immigration  paths of the animal like whale and whatever.  I think I'm over. Thank  you for your attention. (Applause).  Hello. So  where Clement talked  about how we can using sensing and  AI to learn more about  the environment in a restoration setting, I'm going to  talk a bit about that  setting, as well. But also talk about another  kind of restoration we're  doing there. And so yeah, so time and  nature restores our attention.  And this is something that technology tends to  take away. Particularly when  it comes to natural settings. So technology takes  our attention to everything  but the natural world. And it also tends  in a similar way to  hue to these grids, industrialized processes,  managed ecosystems for  productivity by making grids, much like  technology does for the kinds  of tasks that we imagine. And so we've  been experimenting with ways  of connecting to this network of sensors  in microphones in ways  that enhance presence while also giving access  to this additional layer  of knowledge. Our most recent effort in this  regard is called Hear There.  It's a wearable device you can put on. And  it gives access to this  augmented layer of sound. It doesn't block your ears.  It gives you additional  sound by bone conduction. And let's you  hear through the microphones  that are all around you, the hydrophones  in the water, and  sonification of the sensor data in the environment. So  it gives you new sensitivities.  a lot of people go into a forest they  think it's so quiet and peaceful  here. But as soon as they leave they get  very loud and cacophonous.  And that's because humans disturb wildlife when  they walk in forests. So  being able to hear at a distance let's  you discover these new interactions  that is can occur. You can go back in  time and listen to what  it sounded like before the restoration when it was really  quiet or kind of in  the present expand your perception. Here is a quick  video of some of the subjects  that I had in a recent study  describing their  experience.  As I move  my head, I go from  hearing the tree birds. And now I'm  hearing more ducks and  geese. And I put on my super sonic  beam action. And now that's  really all I'm getting.  There's that confusion  between is it coming  from the headphones or is it coming from my  ears? I hear the crows.  Do you hear them?  Yes.   It must be  the microphones.  I'm getting  a sense of distant  insects. Right there.  I can hear geese flying  north as well as south, which  is what they're doing right now. Wind that's  coming and going.  Over there.  So if I was  here on a hot, humid  day, I would be hearing something different? Oh  . . .  that is nuts.  This is  a tool for  exploring the landscape. (Chuckles).  The last thing I'll  say about this is there's a  real potential to consider -- (Dolphin  noise).  Dolphins --  the way in  which AI can extend this  dramatically further. Already  we use Clement's AI to adjust the balance  of the different sounds. But  we can start to think of finding rare birds but  at a safe distance. So  we don't disturb them or finding -- walking through  the first historic appearance of  new wildlife in a restored setting.  And that's all.  Thank you. (Applause).  Awesome. Hi  everyone. My name  is Katherine McConachie. I'm a member of  the Learning Initiative Team  here at the Media Lab. I'm very excited  to be here today speaking  with you all because the Open Ocean  Initiative and the  Learning Initiative are soon to embark  on a new  project together. And I thought this would be  a great time for me to  tell this community a little bit more about the work  that the Learning Initiative is  doing here at the lab. So we work  to design and support  creative learning communities, both inside the lab and  outside the lab. Within the  lab we support a fellowship program for Media  Lab graduate students who  are working on research related to learning  and education. You can  see their beautiful faces up here behind  me, in addition to supporting  and funding their time here at the lab,  we run monthly meetings with  them, we bring in interesting speakers, host  seminars, plan events, things  like that. Outside the lab, we work  with Media Lab researchers and  research groups to take their work and wrap it  in a learning experience that  can then be shared with broader communities. A  couple of examples of  those types of projects, you can see  here. One we did in  collaboration with the Lifelong Kindergarten group. It  was called Learning  Creative Learning. We designed an online  course and community  for educators, parents, designers, tinkerers, who  were interested in learning  more about the pedagogies and design  values behind tools like  Scratch, integrating them into their classrooms with  their children and things like  that. So with the Lifelong Kindergarten group  we designed software  tools, some learning activities, to support this  very non-traditional type of  online course that's not about lectures  and transmission of content  and assessment. But rather is about building  a community, getting these  types of activities into classrooms, getting  teachers to support each  other. Reflecting and practicing hands-on activities  together. Another project we  have is the Public Library Innovation Exchange  where we're working with  a variety of researchers from the Media  Lab to take their  work and help them translate it into the  context of public libraries.  We're very excited about public libraries as  the spaces for local  community-based learning. And we want to see  more Media Lab researchers  working with public librarians. So in order to  do that this project is  pairing up Media Lab researchers with public  librarians to design projects  together. And we're also building this community  of librarians who are  interested in deploying Media Lab research in their  public libraries. So that's sort  of just to give you a quick overview of  the type of work that  the Learning Initiative is doing in collaboration with  Media Lab research groups.  And we'll be starting this soon with  Open Ocean as well as  the Open Agriculture and Space Initiatives, specifically  targeting K12 teachers  and students. And we're very excited to start  this project. So if you're  interested at all in learning more, please  feel free to reach  out. Thank you. (Applause).  I'm Laura  Perovich. I'm in the  object-based media group. So this  project started with  sea boat. So this is  a tool we created  to help communities visualize the water quality  data in their neighborhood,  onsite and real-time. So it's basically a  remote control boat with  custom sensors that measure water quality and  then display the data as  an LED color that's visible to people immediately.  So they can drive  their boat around and explore the local water  quality and see if it  corresponds to any industry activity or sewage overflow  pipes that might be in  the area. They can also create -- use  long exposure photography to  create artistic images t hat represents and documents  this data for them.  So we started by deploying this at a small  scale on the trial server.  But then we wanted to partner with a community  group to really scale it  up. So we partnered with Green Roots,  who is an environmental  organizing nonprofit in Chelsea, Massachusetts, to deploy  it there. So Chelsea  is a really energized community. They  are very engaged. Chelsea  is also the industrial center for the  Greater Boston area. A lot  of the waterfront is zoned for industry. And  it has oil storage  facilities, a fruit distribution center. It has all of  the road salts for the  Greater Boston area. And Logan airport is right nearby, as  well. So these resources are  used by the whole broader region. But  the environmental and health  burden of these organizations are really --  impact the Chelsea community  the most. So we're really excited to see  if Sea Boat can be  useful there and do a summer of series of  workshops with Eco, who is  their high school group. We took Sea Boat there.  We found there were a  lot of other problems to address before we could get  the boat on the water. First  of all it was just accessing the water. Since  it's zoned for industry there's  not a lot of community access points.  So we partnered with  some local businesses to try to borrow their  docks from time to time. And  also were part of the participatory Pokemon GO project  and created a Poke stop  in one of the local parks, which was one  of the few access points in  the area, to try to get people more aware of  it and using it. Second,  we need to know more about local infrastructure.  So information about the  outflow pipes from industry into the water is  not readily available so we  went out on kayaks and explored the area ourselves  to try to find these.  Finally, we needed to know more about the baseline  data for the river so  we looked at the open data available by the  EPA and quickly found  it's something you really need a lot of research background and expertise to  access it. So we're working now to try to  make this data more open  so communities can use it, as well. And we're  really eager to go forward  with this project over the summer.  Thanks. (Applause).  Hi everyone. My  name is Jeremy. I'm an  undergraduate senior at the MIT Astro Department.  But today I would  like to talk about some of  my research involving methods  of using data visualization and imagery to  convey and spread a  wider understanding of ocean climate change  issues, such as sea  overrise, ocean warming, acidification, hypoxia, overfishing. We're living in a Golden Age of satellite observation. Some of you  may have seen this  graphic earlier today. It was on one of the  panel. But we can track  everything from cloud cover to soil moisture to ocean  currents. But in these couple  of minutes, I'm going to be sharing on a  sea level rise and how we  can use data visualization to engage people on more  personal level to be aware  of this issue. This graphic produced by JPL, it  shows 22 years of sea  level rise. A recent study found that on  average we've been seeing  about 3 millimeters globally of sea level rise  for the past 20 years. Not  only that this rate is accelerating so by 2100  we're pretty much locked in  by 65 centimeters or a little over 2 feet of  global sea level rise. You can  see the graph in the bottom right is  tracking these over time  even through seasonal variations. Also of note,  the El Nino events of  1998, 2014, 2015 can clearly be seen in the  equatorial band off the course  of South America in the Pacific where we  see huge thermal masses  of water increasing local sea level rise in  those areas. So it's interesting  to have this global perspective. But to really  make these issues relevant  to people, you need to do a couple more  things. First, you need to  make this local. People generally care most about  what's in their immediate  vicinity. So in terms of the Boston area, we  can make this point much  stronger by showing on this map in the upper  left low lying areas in  the Boston region that are particularly susceptible to sea  level rise and storm  surge inundation in the coming years. On the  bottom left, you can see a  graph in the past ten years we have already  experienced about twice as  much coastal flooding events as the decadal  average for the past  century. Now, sharing these bit of information can  be startling and alarming  and get peoples' attention but to truly  keep people engaged you  need to provide actionable -- opportunities for  action for people to  get involved in these things. In the context of  sea level rise one of the  -- perhaps the best thing we can all do is  individually reduce our carbon footprint and an easy way to do this is make  simple changes in your diet.  This data from the USDA shows that even just  removing beef from your diet  can reduce the effects of carbon effects from that  portion of your footprint 25  to 45%. For those who want a more  direct involvement, there's plenty  of citizen and Government initiatives to  begin installing artificial oyster  reef barriers or other such initiatives on  coasts all across the  Atlantic. This picture shows an effort in  Alabama. But similar to  seagrass beds and natural coral reefs, these  barriers provide additional buffer  against storm surges and sea level rise in  the coming years. So this  is just one example, one area of ocean climate  change issues, that we  can map visualization to then direct action. And  I'm hoping to continue with  these other issues to provide solutions for people  to feel engaged in these  global problems. Thank you. (Applause).  Hi. My name  is Max. I'm going to  start with a question. What if we could  use every day English  language to interact with environmental databases? I  don't know if you  have the same experience I have, but  when you're looking for data,  there's so much data. It's hard to find what  you need. If you're trying  to get more people engaged in solving these  sorts of questions, you  need to make these tools not just available  but accessible. I think one  of the biggest barriers is just in the language  itself. So I've demonstrated this  by looking at two publication records. One of  them is scientific journals.  One of them is from newspaper journals. So on  the left of this graph,  you can see words that are used almost  exclusively in scientific publications. On the right it's words used almost  exclusively mostly in  public facing journalistic publications. So I think  this graph shows that there's  a huge gap between how scientists and journalists  talk about climate change.  And I think that this presents a problem if  we want to get people to  be able to answer the questions that they care  about on the right of  this graph. Like what's happening with the  politics. What's happening with  fossil fuels. If scientists are only  speaking about precipitation and  models and species, there's a divide between  these groups. And I  think there's an opportunity for us to bridge  this divide using machine  learning and specifically some natural language processing tools.  So I'm part of a  research group at MIT that is working in  collaboration with researchers at  IBM to develop these sorts of tools. But essentially  we want to be able  to link topics from the environmental databases to  topics that people naturally  ask about from your natural language, from  your natural queries that  you would ask of these databases. And we  think that it's entirely possible  to use tools that already exist to make  these linkages between these  topics. And I think that by doing this  we're going to put the  true power of these environmental databases  into the hands  of everyone. (Applause).  Hello. My name is Travis Rich. And for a  few years now  I've been working on an open publishing platform  called PubPub. So I spend  a lot of time talking to people, to  scientists, who care a lot  about how their research and how their our  science gets communicated. The  thing that comes up almost every single time is  how hard it is to  distinguish science from the profession of science. By that  I mean that so much  of what scientists do and how they perform,  we think of ourselves as  Balkan like logic based people but really what we're  doing at the end of the  day is kind of fashion over time. It's not to  say that fashion isn't useful  but it's based on culture and opinion much more  so than logic and  evidence based paths forward so the most embarrassing place  I see this all the time  is the way that we as scientists are pushed  to portray ourselves and  how it's changed over time. On the left  you have Dr. Verdar (phonetic)  and Nikola Tesla reading a book we can all  relate to. On the right  you have pictures our university pushed us to take us  wearing lab coats we never  wore before. Us doing all these really intense  break-throughs things. If this  is the most embarrassing the important thing  is how we communicate  our work and to Max's point how we relate  it to the public. On the  left you can relate to reading a book. You can't  relate to wearing a lab  coat and playing with these fancy lasers. So I  think a lot of these  fashions are often not based on, like I was  saying, efficiency and usefulness and things like that. But are based on the  business models of corporate  publishers and what they want science to look like.  And so I think we  know that this doesn't have to be the case  because it hasn't always been  this case. Like these pictures, the history of science  did not always look like  it does today. The history of peer review  and structure didn't look like  it does today. And Isaac Newton was not sending  papers to Elsevier in a  call for papers for his approval. He was  sending letters to other nobility  that could afford to be scientists. They were  much less doing peer  review and much more doing pen pal review. Here  is a rare photo of  Newton at the Post Office. (Chuckles)  What we are  doing with PubPub is we're  hoping to not let people be boxed in  by the fashion of professional  science and let be people creative and experimental  -- creative in the  way they publish. Whether that means  publishing visualizations, publishing data and publishing it for scientists  and then publishing it again  for laymen. If it means you're pretending your  Matt Damon in the  Martian and you're doing a video log of  what you did every day  in your exploration, that's all important. So if this sounds  nifty to you guys, feel  free to check out PubPub.org or check out  one of the communities  that have been running on PubPub for a little  while. Katy and Arial and  myself have been putting some time -- mostly Katy  and Arial -- into the  Journal of Open Exploration which is hopefully going to capture  a lot of this stuff. So  let's build this thing. Thanks. (Applause).  The magic  stage. Hello. My name  is Casey Zakroff. I'm in the  MIT WHOI Joint Program  in biological oceanography. And I spend most  of my time raising squid  eggs under ocean acidification. But I'm not here  to talk to you about  that. I'm actually here to talk to you  about my other passion,  which is science communication and in particular science  communication in the form  of comics. How we can learn through  comics and apply  science communication through c omics. So my point here,  the thing I'm positing as  my hypothesis, is that scientists and comic artists  share a pretty common  goal. It's to communicate and show  visual narratives as efficiently  and concisely as possible in order to  convey a story, to convey  information. Whether it's an illustration of my own  work or something like  a newspaper comic you might be more familiar with.  And I bring this up,  A, because it's Monday. So Garfield is relevant. But  B, because I want you  to look past the bias comics as pulp, comics  as juvenile or comics  as throw-away superhero material. And really look at  the structure of this in  which the design and intent is three panels in  sequence brought to you to  tell a story as digestibly and effectively as  possible. It's quick and  it's effective. And really question, is that  not what I am doing  right here right now? Presenting three panels  to you in juxtaposed  deliberate sequence in order to convey a  narrative to you as quickly  and effectively as possible. So I have put together  a poster on this that  I presented at conference talking about how posters  are essentially comics as  they are sequences with images telling a  story. And I'm actually  putting together a journal article for integrative  and comparative biology talking  about how posters, oral presentations and journal  articles all can be  sort of interfaced with comics so we as  science communicators can learn  from an existing methodology how to tell  sequential visual narratives better. Now, on the flip side, science a really  good narrative to put into  the comics genre and it's actually a growing genre  in comics. So this is  Primates. This was a New York Times best seller  by Jim Ottaviani and Maris  Wicks. And this is talking about the field  science of Jane Goodall,  Birute Gaklikas and Dian Fossey. And how they  were foundational in bringing  women into science and sort of changing  primatology. And comics have  the advantage of being immediately engaging  and accessible to a  wide variety of audiences because they don't  feel as daunting as  the typical non-fiction scientific narrative. In part,  cartooning has this advantage  of the more simplified a form is --  and again I'm asking you  to look at cartoons without the bias you  might have of their  juvenility. There's a psychology to making a form more  simple as we as humans  impose a sense of self on more simplified faces  and forms. And so  comics in effect become more participatory. We see  ourselves in the roles  of the characters. We see ourselves as Jane  Goodall. And in that we  can experience what it's like to do fieldwork  while she's doing the  fieldwork, while she's dealing with the weather and while  she's talking about what it  is to be a non- academic, to be changing the  way they did primate behavior  and to be a woman in science. So I really  want to -- if you guys  want to talk to me about either of these points,  I'm available to chat about  these things. Thank you. (Applause).  Water has been  in the news quite  a bit lately. All eyes are currently  on Cape Town as Day  Zero approaches when it could become the first major  city to run out of  water. Last summer 40 million people in South  Asia were devastated by  floods and landslides. Closer to home residents  of Flint, Michigan, were exposed  to lead in their drinking water after a  botched water supply switch.  These kinds of stories won't go away  any time soon. We'll  be seeing stronger storms, longer droughts, larger  populations and aging  infrastructure. So cities and their water utilities  are going to be stressed  more than ever. My name is Quantum Wei.  I'm with the MIT Water  Club. And we're developing Thirsty Cities, which is a  game that places students in  the shoes of a water utility. We think this  is super important. And I'm  going to tell you why. Turn on a faucet  and clean water comes out.  It's kind of magical. We don't have to think about  how the water got to the  tap. Or where it goes after it flows down the  drain. Hint, a lot of that  stuff ends up in the ocean. We only hear  about water utilities when  something goes wrong. And so it's out of sight,  out of mind. That in itself  isn't an issue. But it becomes an issue when  people aren't willing to pay  for their water. Water utility budgets get slashed  because there's lack of  public support. And they can't pay to fix  the leaking pipes. So with  Thirsty Cities, we want to get students to think  about their water delivery  systems and raise awareness about all of the  hard work it takes to  ensure a clean, reliable supply of water. Every city  in the world right now  has access to a consistent supply of water.  Even the ones that are  currently in a drought. It's wastewater. The water that  we flush down a toilet.  We can take that wastewater, purify it, and  drink it. It's called  water reuse. And Namibia has been doing it for over  50 years. San Diego tried it  out in 1989. But the project got dubbed toilet to  tap. And it died off  due to public opposition. So public perception is  crucial. Through Thirsty Cities  we want to familiarize people with the  tools that are going  to help us solve tomorrow's water problem. The  next time a water  reuse project comes along, people might think, oh,  cool, I know what that  is. Let's give it a shot. Our climate change  models tell us that  there are some places where we're going to see  either too much rain or  none of it. That's too much rain or no rain at  all. How do you plan for  that? We need to get the next generation thinking  about the challenges that  lie ahead. Because they are going to be  the ones that will have  to solve those problems. Today's kids will be  the ones running tomorrow's  water utilities. And we want to inspire them. So  above all we want Thirsty  Cities to be fun to play. And we've had a  blast play testing it so  far. So if you're passionate about water or outreach and  want to help us out, please  get in touch. Thank you. (Applause).  Hi. My name is  Galtiero. I am a PhD  student in oceanography at MIT and WHOI. But I'm  also here to represent  the MIT Water Club. As Quantum mentioned,  we are a  student group that engages and  fosters collaboration and  communication amongst students, researchers across  campus to talk about  their research related to water. And that  ranges from filtration technologies  to urban planning, rural development, climate  change, oceanography, hydrology.  And what I'm -- why I'm here  is offering you an opportunity to  tell your story. One of our major events is happening  next month. It's on the  UN World Water Day. And this is an  opportunity to engage with an  audience and share the research, the work that  you're doing, your lab  is doing, the local universities are doing related  to water. It's a  night of communicating, of practicing your story, of  sharing what you do.  It happens in Walker Memorial. It features  research posters, technology  exhibits. The first time this year  we're featuring art, installations,  interactive exhibits. And the key is really we  want to connect with the  whole community, be that scientists in your  discipline, scientists across  departments, families, children. We feature a  keynote by an astronaut  and professor on campus. So we're trying  to connect the space  picture, the ocean picture and water being a  unifying theme across these  domains. The focus this year is on outreach.  So we have the Thirsty  City games happening. We are contacting local high  school community groups to  engage them with the research at MIT. And  I think this is an  opportunity, again, to present your work. So if you  are interested, I've seen a  lot of artwork and research presented earlier today, reach out  to us. We would love  to present it to you. But it can  be a really engaging experience  to talk and communicate and get out of the  bubble of your research and  your lab and really connect about  your work.  Thank you. (Applause).  Okay. Hello. My name  is Tom Consi with the  MIT Sea Grant Program. And I would like  to talk to you about  an idea that's been kicking around for  some time. Actually  I conceived it back in the  days when PowerPoint was  the high technology. So forgive my slides.  But anyway, the idea is  -- I think our second talk a fellow mentioned  a lot of the creatures  that are in the water aren't seen. And he talked  about the large pelagic fish  that are out there, things you can't put in the  fish tank. But I would say,  also, if you went to a New England Aquarium and went  out to a pier say  it was in the summer and there was lots of  junk going on there. And  if you went down and scraped your hand along the  pier and your hand came  up all sticky and gooey, well, that's  filled with amazing, amazing  creatures. And that's microorganisms or the tiny  millimeter size organisms. And  they are really the constellation or the  world of creatures that are  not commonly seen in zoos or science museums  or public aquariums. And  that's what this idea is focused on is how  can I look at a  small organism, a protozoan, a paramecium, or a copepod as if  it were a fish in a fish  tank so I can see it moving around in all of  its 3D glory. So any of  you who have used a microscope realize because of  optics and things like  depth of field that we have to squish  these poor creatures down  into two dimensions you but this Larsen comic says  I don't know if that's  Uncle Floyd or an air bubble. Pretty much you  have that situation when  looking at microscopic features their world is  squashed down and not  moving correctly and probably even misshapen. So  our idea was to  create a movable microscope that can --  using a motorized XYZ gantry  move around in a small tank pool full of  pond scum, if you will, or  other types of marine or brackish water creatures. Here  I use a borescope,  one of the things surgeons use to look  into people. But maybe  nowadays with iPhones imaging technology and tiny  lenses have advanced so  much that we can get good images out of  that. But the whole idea  is I have my microscope. And I can drive it around  in a small tank of water  as if I were driving the Alvin. And indeed my idea  of the exhibit in a  New England Aquarium was for the user interface to  look like the panel of the  Alvin. I can drive it through. And on the  video camera, I actually  see what this roving microscope sees. And I can  see the rock full of fuzzy  thing. And I move a little closer and I can  see it's some sort of  hydroids and they are eating little crustaceans. In the future  -- for one thing this  slide shows you the really varied communities we  can look at. Biofouling  communities as I mentioned when scraping off  a thing. Live rock  coral communities. Even a diseased dead fish  will have a variety --  a whole microscopic kingdom, if you  will, growing on  its side. (Dolphin  noise).  In the future we  can use all kinds of  technology listed up there. So if anybody is  interested in this, there's  a lot of research that can branch out from  it. I'm happy to talk  to you. Thank you. (Applause).  Hi. My name is  Yihyun Lim. I'm from MIT  Design Lab where we focus on human centered  experience design and  really thinking about how you  can situate use  new technologies within society. How many of  you have been to  the aquarium in Boston? Yes, it's their 50th  anniversary of the aquarium coming  up very soon. And together with the Media  Lab, the aquarium and  also the Open Ocean Initiative we've started to  think about the future  of the aquarium. The aquarium in 2069. So  what would the experience be  like in the aquarium in the future? What is  the role of the aquarium  in future society and the future city? What could  be a potential experience  if we start prototyping now with tools and the  technology that we have at  hand? So what we did was during IAP last  -- in January we invited  students from MIT, from undergraduate/graduate programs and  also schools nearby  like Wesley and Boston College and so  forth to start to think  about this future of the aquarium experience. It  was a one-week really  intense workshop. And t his is really a source  of the collaboration. And I  brought a short video of the workshop I would like  to share with you. If  we can get the sound.  Our idea for wanting  to partner with both the Design  Lab and the Media Lab at MIT was really  just the notion of  thinking about both engagement and technology and  how they can  work together.  The MIT Design  Lab partnered with the  New England Aquarium and we created  disciplinary teams to  brainstorm and to imagine and envision  how many technologies  can and improve the experience of the  digital technology and also educate  citizens to different issues.  I really would like  to get some ideas that  I never even thought about. That's probably my No. 1  hope. Because we want to  be able to break the mold of the  way people think about  structures like the aquarium.  I think one  of the most important  things students will bring to the table  at the workshop is really  their openness and again really their creativity  in bringing their  skills and expertise which is extremely varied  to these deeper problems to  look into the future.  I'm thinking of this  not just as a workshop  where we do something and then we go back to  our day jobs. But rather I'm  looking at this as the opening of what I hope  will be a very rich  ongoing set of research projects.  So one of  the big issues we've been  working on in this workshop is how to  imagine the aquarium 50  years from now. So what we have been encouraging  the student to do is  not think about this project in terms of artifacts  or what the details of  the tech will be. But instead think of  the human experience  of this.  I'm a member of  the New England Aquarium. So I  go there all the time. So it's really great  to hear how to  engage with the Cambridge and Boston communities.  I also really liked  hearing about their Mission Statement: Engage,  educate and action.  I think that will be really  important design principles  for this project.  If I'm going to  think about the aquarium of  the future, I think we should think about  how storytelling and technology  can integrate in the design and the  process of how people  engage with the aquarium.  How can you go  to the aquarium and have  all of this information presented to you  in the right  way so it's relevant so you're learning so you  can retain it and have it  stick with you after you leave?  Even beyond  just what was accomplished  within that short period of time is what  could be done in the next  year and a half leading up to  the 50th anniversary  of the aquarium and how much broader  it will be and really  honing in on what the learnings will actually do both  for be in the short-term  and longer term vision.  So where we are  is not the end but rather  the beginning of the collaboration. We at the Design Lab  and Media Lab will continue  to push forward technology but really focus  on the experience  and dream up new ways  that the aquarium can  further it's mission. With the 50th anniversary  with the aquarium coming  up we're very excited to take on the  challenge to envision the future  of the New England Aquarium.  So this really  sums up the whole  workshop we did. And we had really  interesting projects the students'  teams explored. And we really look forward  to collaborating continuously with  both the Media Lab and the aquarium and the Open  Ocean Initiative in the next year  and a half. Thank you. (Applause). 