 We present Haptic Revolver, a reconfigurable VR controller that enables touch, sheer, texture, and shape rendering on interactive surfaces. Existing VR controllers only support vibrotactile stimulation which is limited in its ability to render different textures and shapes. What if, as you explored a virtual scene,  you could feel the surfaces you touched? Our device haptically renders the scene by making contact with your finger when you touch the surface and positioning arbitrary haptic elements in virtual space allowing you to feel what's beneath your finger. The haptic revolver consists of a wheel  that contains various haptic elements. A servo motor moves this wheel up and  down as you contact a virtual surface. A DC motor spins the wheel to render shear forces and position haptic elements under the fingertip. The thumb button on the side of the controller enables input. Because our device is tracked we can spatially register haptic elements with the environment. The motor spins the haptic wheel to ensure alignment between the features on the wheel and the virtual scene. Through a perceptual user evaluation we found that we can adjust the wheel speed and direction to manipulate the size of virtual objects and even simulate motion in multiple dimensions. The haptic wheels are interchangeable and can  contain different haptic elements such as shapes, textures, or active electronic components. Wheels can also be custom-designed for different applications. For example, here we show a card table using a wheel with various textures and edges. When the user moves from one surface to another our rendering engine positions the wheel so that the appropriate texture lies beneath the finger and that the edge is felt in the correct spot. In this scene we show how shapes on the wheel can add to the realism of a virtual keyboard. A user can even brush along the rows of keys to feel the grooves. By sensing the force the finger exerts on the wheel we turn passive elements into interactive tools. Here we show how a simple plastic nub can be used as the tip of a scan of spray paint. For additional customization electronic components such as buttons and joysticks can be placed on the wheel. In this scene, when the user approaches a virtual interactive widget, the rendering engine places an appropriate physical widget under the fingertip. Here we show how the user can physically interact with virtual knobs, buttons, and switches. 