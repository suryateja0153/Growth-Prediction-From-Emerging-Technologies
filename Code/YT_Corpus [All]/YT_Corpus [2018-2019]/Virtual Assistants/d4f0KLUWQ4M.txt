 I want to know when to leave home to work, so I need to open an app to see the weather, and then to see the traffic, and then to see my schedule, and then to remember if there is fuel in the car. And so many things I need to do, and remember to do. Instead of that, there is an assistant who will just tell me, "Gabi, you should leave today at 7:30." That's enough. Assistant's can file a complaint or just interact with the insurance company. I think overtime if these become really personalized and know the preferences of the user, then the whole interaction around ... the entire portfolio of insurance, becomes much more efficient for them. There are ethics that needs to be taken into account. So, people talk with the assistants for what they were intended and built for, but they may also start to say things that these assistants were not trained for. Maybe somebody would even say that he wants to terminate his life, unfortunately. So, again, we cannot ignore these things even though these assistants were not meant to be for that. So, it is all of these ethical things that we also need to take into account as we move ahead. 