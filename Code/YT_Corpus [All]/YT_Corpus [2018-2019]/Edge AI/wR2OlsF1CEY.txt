 Dear Fellow Scholars, this is Two Minute Papers with Károly Zsolnai-Fehér. In this video series, we often see how these amazing new machine learning algorithms can make our lives easier, and fortunately, some of them are also useful for serious medical applications. Specifically, medical imaging. Medical imaging is commonly used in most healthcare systems where an image of a chosen set of organs and tissues is made for a doctor to look at and decide whether medical intervention is required. The main issue is that the amount of diagnostic images out there in the wild increases at a staggering pace, and it makes it more and more infeasible for doctors to look at. But wait a minute, as more and more images are created, this also means that we have more training data for machine learning algorithms, so at the same time as human doctors get more and more swamped, the AI should get better and better over time! These methods can process orders of magnitude more of these images than humans, and after that, the final decision is put back into the hands of the doctor, who can now focus more on the edge cases and prioritize which patients should be seen immediately. This work from scientists at DeepMind was trained on about 14 thousand optical coherence tomography scans, this is the OCT label you see on the the left, these images are cross sections of the human retina. We first start our with this OCT scan, then, a manual segmentation step follows, where a doctor marks up this image to show where the most relevant parts, like the retinal fluids or the elevations of retinal pigments are. Before we proceed, let's stop here for a moment and look at some images of how the network can learn from the doctors and reproduce these segmentations by itself. Look at that! It's almost pixel perfect! This looks like science fiction. Now that we have the segmentation map, it is time to perform classification. This means that we look at this map and assign a probability to each possible condition that may be present. Finally, based on these, a final verdict is made whether the patient needs to be urgently seen, or just a routine check, or perhaps no check is required. The algorithm also learns this classification step and creates these verdicts itself. And of course, the question naturally arises: how accurate is this? Well, let's look at the confusion matrices! A confusion matrix shows us how many of the urgent cases were correctly classified as urgent, and how often it was misclassified as something else and what the something else was. The same analysis is performed to all other classes. Here is how the retina specialist doctors did, and here is how the AI did. I'll leave it there for a few seconds for you to inspect it. Really good! Here is also a different way of aggregating this data - the algorithm did significantly better than all of the optometrists and matched the performance of the number one retina specialist. I wouldn't believe any of these results if I didn't see these reports with my own eyes in the paper. An additional advantage of this technique is that it works on different kinds of imaging devices and it is among the first methods that works with 3D data. Another plus that I really liked is that this was developed as a close collaboration with a top tier eye hospital in London to make sure that the results are as practical as possible. The paper contains a ton of more information, so make sure to have a look! This was a herculean effort from the side of DeepMind, and the results are truly staggering. What a time to be alive! Thanks for watching and for your generous support, and I'll see you next time! 