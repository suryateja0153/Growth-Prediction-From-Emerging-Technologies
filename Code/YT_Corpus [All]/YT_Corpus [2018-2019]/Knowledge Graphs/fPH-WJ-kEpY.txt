 okay welcome everyone I'm happy that you've made it all here after lunch and afternoon snack and really excited to talk about analytics of graphs meaning graph algorithms and more I'm Michael hunger director of developer relations engineering at neo and my colleague Amy hello everybody I'm Amy Hodler I handle the analytics marketing for neo4j okay Amy we'll begin and yeah so so first just to congratulate you all from Cote for coming to a session that I think is actually one of the most exciting topics in the study of graphs next few minutes we're going to talk about two main topics one is the study of real world networks and the other is graph algorithms and analytics which is what you use to study those now the reason why I think this is the most exciting area in the graph space is that it's all about understanding the world we live in and the networks that we live in and among so when you think about what we're really trying to accomplish when we study these it's it's understanding the complex behavior and dynamics of these holistic systems that are in the world and those behaviors are usually fall into about three different areas one is how do things spread through a network the other is how does something flow it's the capacity for things to move through a network and the other is of course what's the resiliency of the groups that I'm looking at what's the influence on that so if we take just a quick look at each one of those if we think about propagation pathways this is a very practical example of why you would want to study how something spreads this is an example from 2010 it has to do with cascading failures it's actually delayed failures that were happening in the US airline industry in 2010 they actually had two really bad failures the items in purple will actually have significant delays Green's okay if I had a time sequence you would see the ripple from one coast to the other coast but this is just a at one example this one can very easily be an IT Network cascading failures there there's some examples using electrical grids or this could be the spread of information let's say you want something to spread and to propagate how best to get that pathway to do that another example very practical again is flow so this is this kind of routing planning is used a lot to plan for things like least-cost routing very common in the telecom industry you need to get something from A to B you have certain service levels to me but you have to do it in an efficient manner but this could very well be how to get the flow of goods transported to your customer in the most efficient manner or perhaps it's the most fastest manner maybe you're providing goods to an emergency service so very different ways you could take a look at it and the other area that is really interesting is group resiliency really fascinating area in general because you're looking at how do groups possibly break apart or how do you bring groups together what's the stability of a group over time and what are the influence points this is actually from a really interesting study this diagram is from a study of hierarchies in a Belgian telecom network the items in red are French speakers and the items in green are Dutch speakers the first thing you notice is there's a lot of call volume going between each group it within their group and they saw this throughout their network that there is an affinity by language except for this one little cluster in the middle that's a bridge that bridge cluster has communication mostly going in between the different groups but not by language so they didn't see a cluster by language within that node so it's a really interesting bridge and as we saw this morning yet this might not be a telecom scenario you could look at this from a fraud scenario maybe your middle bridge is a middleman in this case let's say we wanted to bring these two communities closer together the way to disseminate information and try to gain more consensus would be to focus on that bridge so group resiliency a very fascinating area overall so when we think about what graph algorithms can do to help us understand these complex behaviors it's all about extracting structure so we can then model processes and make those really valuable predictions and when you think about structure what's interesting is in the real world you don't really see much that's random so it may feel like that some days but in general what we've seen and observed is that over time there's this preferential attachment which means if you're a node you have a more likely chance to attach to a node that already has connections and you might think of that as the good get better the rich get richer that kind of an experience and what's really interesting about that is it really displays how entangled network structure and the evolution of networks are and there's a lot of debate over why this is maybe it's some local heuristics maybe there's some global cost estimation going in but they really don't know yet but what they do know is this is how networks grow is there's a propensity in nature for things to have preferential treatment or preferential attachment and what that leads to over time is very concentrated distributions so it's a very lovely picture that shows a concentrated distribution in a online gaming network and so here we've got over 380 sub communities of this overall community the top five sub community touch 50% of that community so preferential attachment more likely to get end up with these hubs and spokes and grow in the influence of the hubs and as you can imagine if you kind of visualize that what we're really looking at here is a power-law distribution and what that means is there's a lot of nodes with just a few connections and a few nodes with a lot of connections we see this on the World Wide Web we see this in business we see this in nature this is very common to see and it is so common that a lot of network scientists believe that in nature you really don't see random networks and when they think about random networks what they're talking about is average distribution not a lot of humps things are fairly flat not a lot of structure on average things look like everything else but what we really do see so we don't see that in nature but what we do see is especially in social networks is this very small world network behavior so you have these clusters where things are very well connected inside your little network your little friend network and you're never too many hops away from somebody else and you see this in like the seven degrees of separation or the old Kevin Bacon game if you guys are familiar with that very common in social networks and then the other thing that we see is also these scale-free networks so you still get the hub-and-spoke but what's interesting in a scale-free network is that you see the same hub-and-spoke structure over different scales whether you're looking at 10 units or 10 thousand or a hundred thousand that's really kind of fascinating in the the scale-free has a extremely strong power distribution to it so this looks great we've got some models we know that the world kind of looks more scale-free and small world but then what happens when we get the real data on our desk and we have to deal with this mess so you can kind of look at this and go well I can see that there's structure but I didn't really know what to do with this and there's a lot of research into how to unfold these messy globby networks and unfortunately when presented with this there's a real temptation to go with average because that looked pretty messy and on average if I assume most of my customers kind of look alike and there's some similarities here in distribution I can ignore the out layers I'll just go with an average to really need to resist that temptation because you can see here mathematically these are very different types of networks and we know just from what we looked at that we more likely to see small world or scale-free and on top of that the structures are very different you have flat versus hierarchy and topology and I have a little video of what it looks like if you actually try to apply a random approach to a real network and this is a network where we're trying to remove influence you can either take a random approach and just kind of really nilly grab notes and remove them or you target the most influential in this case they use centrality you figure out what's the most influential notes then you go ahead and remove them 19 clicks here exceptionally different totally different results and you think about what this could mean if we were targeting let's say a diseased Network and we needed to figure out what nodes really need to take out that's interesting is this approach is commonly used in that cascading failure example so there was a European Grid electrical grid where they looked at they were having trouble with some cascading outages and vulnerabilities they looked at their network and they thought well we're having troubles with us maybe we should do we should be more redundant exactly opposite result is what they ended up by taking looking at the centrality and where the influence was they actually found with this kind of approach that if they remove just four nodes in their network they reduce their vulnerabilities to cascading failures because that was almost like propagating failure information so pretty interesting and it's not surprising that a model developed for connected data is taking off in our connected networked world and that's really what we're seeing now is graph analytics taking off and you have to wonder it's been a little while this math has been around for a while what's taking so long and I think I think for the change is happening because we're really starting to see this critical mass of a few different things you know first off it's just big data you know the ability to collect analyze affordable compute affordable storage we can really bring information together love big data the other thing that's really interesting is this observation that there are these common structures so those structures we were just looking at the scale for the small world network the recognition there are structures that are common across domains but there's also behaviors that are common across domains so PageRank is a really interesting example because you see that use everywhere from biology to neuroscience to ranking pages to economic viability so you can use these same methods and fortunately the math is there the mathematical tools are well-known they're established they're tools that we can use today the fourth thing that I think has really brought about some change is just this frustration this unfulfilled promise of big data we collected all this stuff we know there are Nuggets out there but the tools that are using this random approach that we had talked about the approach of averages haven't really revealed the information that we need to be valuable so with that I'm going to let Michael talk about how we move forward yeah thank you thank you so I did the interesting bit about graph structures and and graph data's actually that not only they capture information information as attributes of your entity or attributes of your connections but there's a lot of information hidden in the structure of the data that's something that email showed in the morning that the context is actually king right so I could look at all these individual elements at a separate loan entities but only by putting them into context that actually can infer so much more wisdom about all all these all these things and graph analytics and graph algorithms helped us using this structure to get more insight in our data and usually what you what you can infer from graph I burdens are things like I get metrics about a graph like what is the degree distribution of this graph what's the size of this graph what's the longest shortest path stuff like that and something that's really interesting is what Amy mentioned in terms of relevance so in the last few slides so what are the influential nodes what are the nodes that connect clusters what are you what are the entities that have within a class there's really a high influence and the next thing is of course how is this craft structured on a larger scale so what kind of groupings or clusterings do I find in this graph which might not be visible at a first glance but for instance by looking at weighted relationships between nodes you suddenly can realize that okay not all relationships are created equal but there are some that having higher relevance and others that have a laurel events and by applying that you kind of suddenly see these clusters emerge and it all leads us to order these structural insights we won't talk too much about machine learning today by there's a lots of really interesting bits and pieces that I am looking forward to work on in the future with graphs the machine learning from NLP - prediction of structure and data presenting neural networks in the graph being able to query neural networks compare neural networks and things like that so that's just a teaser for where we want to go and in general it's only interesting no matter if you look at for instance like builders at political network of joint voting for births or if you have things like software architecture where you D structure large system in smaller and smaller components and perhaps you don't see the structure near in your code but actually if you kind of analyze the code you see actually structures emerging by something like communication behavior behavior which which entities in your in your system communicate with each other the same is true for human organizations they see communication flows revealing structures in your organization which can be completely orthogonal to the actual organizational structure and which you should actually support so it has a lot of stuff in there one of my favorite examples for this is the Game of Thrones detection Network because this made me actually realize that death content or just information that we know so people that have read books or seen these years kind of know stuff about us about its universe but by just applying graph analytics and stupid algorithmic with no clue about Westeros can in the end infer the same information so the algorithm connection for who are the important people who connects other people which classes exist and in his in his story network and it was for me actually kind of like an epiphany to see even without knowing anything about the domain such an algorithm can reveal a lot of insight about that and it was quite quite interesting how do you run this graph analytics processing so far there have been a number of options there spark just fling 50 Ollie just graph like giraffe group as well and so many many things where you can take your data put them into a graph processing system run compute and then take the results and moved up somewhere else to continue to compute um this was it is a steadily very valuable it's also very scalable you can use GPUs and so on but what I've wanted all this wanted to do is to simplify the process for the most common use cases right so this is kind of the petabyte use case when you have like tens or hundreds or thousands of billions of notes and relationships but what what's about the common use case when my graph has like a hundred million nodes a billion nodes 10 billion notes or something like that I really wanted to always simplify this approach and that's where we are going to so basically we have an example from a loftiest graph connect John Swain presented the network influenced analytics on Twitter data both for brexit but also for the u.s. elections which both turned out not to be that great but how about what it is to chain and workflow look like so he hadn't really kind of complex to child he pulled the data from Twitter started in message queue put it into MongoDB put it into neo4j extracted out of neo4j put it in are computed something put it back into neo4j took it out of me again so several iterations there here and and then he put it into a my sequel to a visualizer InterPro or the exported as a graph ml to version updated in Jeffie so it's a quite complex workflow as you can see right and there were lots of moving parts and it was a lot of data lots of time spent in just data import/export converting data from A to B affixing conversion problems and so on so it was a quite tedious problem and what we actually wanted to achieve is move some of these moving parts so for instance we can we don't need to phone set store treats among we can just store them in e4j in a proper graph structure so it's one moving part can go on the other thing is that actually as a graph database we should also be to run graphics ourselves so there shouldn't be a need to export data from neo4j to ought to run something and write it in a backhand back and forth but we actually wanted all to happen within the kind of graph model that's in here for J and of course if you want to visualize something in tableau you shouldn't need to put it in my secured first so there's a tableau connector for neo4j deck you can use and we can stream graph data directly to get here now as well so there's also no need to export it as graphing as first so we can kind of simplify the whole workflow into into like three four components and I think that's much more manageable for someone also for getting started leftie whole graph analytics problem so a funny for J yes just a number of tools and techniques that we can apply for graph I craft varying graph analytics so one is of course Seifer as the lingua franca of graphs for creating and training graphs both in nee for J but in lot of other systems as you saw today my my baby a POC has grown also quite a lot and encompasses now a lot of data analytics tooling and you can do a lot of compute and update of a single procedure call in India J we have the algorithms that I'll talk about in a minute and we also are working on a lot of other analytics integrations with VI tools and other things as well they're week 10 can prove stuff easier together and don't have to go the extra mile ok what are the algorithms that we looking at that they are currently available for near 4 J as as efficiently implemented algorithm so first of all the absurd LTI drones which capture capture things like pitch rank betweenness centrality closest centrality degree centrality and so on so everything that kind of explores how important is in or what's the relevance of a node what's the influence of a node second one is clustering that means a set of community detection algorithms like like Union Phi and blue vein elaborate propagation and so on a strongly connected components and it last one is pathfinding which is all about Dijkstra so show findings past finding all shortest paths between a number of nodes and and single source shortest paths and so on so there's a there's a right range of errands already available but as part of the work we also build an infrastructure makes it easier to add new algorithms as well so from from now on we also have the ability to add new ways of doing graph analytics pretty quickly so within a few days or a week you can add new capabilities to this library as well basically since last year Seifer only added the ability to write your own user-defined procedures and functions which allow you to extend cipher as a language so whatever feature you are missing in size we can just build yourself at any jvm language deploy to near 4j and then it's available as part of the language to be called the single procedure call and that's what's also the way how we wanted to expose these algorithms so we one didn't want to invent a new language or put a layer on top of side we just wanted to have an easy way of take your data passing a few parameter select your algorithm run it and and be done so it shouldn't be more than like a few lines of code necessary to run even an advanced algorithm so basically we have two two ways of doing that so one way the algorithm works is that it streams results back to you so imagine you are on something like a centrality algorithm it would could turn each node with the ID and it's not ready T score that it's computed for the node the problem there is from a certain size it's hard to come to actually process the millions or hundreds of millions or billions of notes that are gets thrown at you body by the algorithm and that's why we added a second wave which is able to take the results and write it back in a really efficient manner to neo4j as properties on you note so whatever is computed you can specify a property name and it will be written back really efficiently a 2d graph the other thing that I'm actually super excited about is projected projected graphs so oftentimes the graph that we working with doesn't have to structure that we want to run on so it could be a bipartite graph if you want to project into a either direction so for instance I want to say okay if I have for instance users that rated products so I can project it into a product graph by the user side right at them or I can project it into a user graph by the products they jointly rated and then run actually I wrote Monday's graph and so what we did is you can just instead of passing in something like a label relationship type into the Eiger room you can also chest pass in to cipher statements want to create a node list and want to create an edge list or relationship list and then it will use the results of this projected graph to build up dat necessary data structures to Randy IBM and that's a super powerful approach because that allows you to apply any of your cipher skills to a you know filter group reduce projected graph that you have to a higher grade Euler graph to to use for your algorithm and that's actually available for all the algorithms so this general syntax of calling these algorithms is consistent across all your algorithms so if you ran one then you can also should be able to run all the others okay and as I said already for sexuality we have patroness based on a grown between a sexuality closest a twenty and degree centrality for a community direction we have label propagation union-find we have through vein strongly connected component and we also added trying accounts which are actually sitting between community detection and and sexualities and also a computing clustering coefficient and for path finding algorithms we have as I said single shorter swing source shortest paths or walnut shortest paths and then also implementations for pella Dijkstra parallel breadth-first search and depth-first search if that's something that's useful okay basically what we want to enable everyone to do is take your data pull it together in one graph or on your compute and rich the data and then use this new information that you've got from running the algorithms to improve the quality of your transactional queries be it either for recommendations be it for detecting certain things bead for providing more information to decision makers and so on and as Ryan showed in the beginning today of course we can also use this information to provide a better visualization experience so for instance if you run a clustering algorithm then we can use this information in the UI in the visualization to render klieg large complex graphs at as higher higher level clusters for instance then NL our drill down mechanism to go down or we can for instance highlight certain nodes with a especially high or load sexuality as something that we want to look at and because we added it as a to cipher as user defined procedures you can call it from any API so you can't call it from from neo4j browser you can call it from safer shell you can call it from any programming language from any driver you can even integrate it with an object graph mapper like spin it in 4j by just adding its procedures to your repositories so it has no limit in terms of which are the API is that I can can use this from even from embedded okay cool demo time so I will not be able to show all demos in full lengths because even I see a fast some of these algorithms still run few for few minutes on large graphs so bear with me and ever only be able to show some of them live and others others are only a summary so I want to a quick look at four graphs so one is senior Fuji community graph as you know a developer community is very widespread and activity is happening everywhere on Twitter and github on Stack Overflow and Meetup and so on and absolutely hard to keep track that's why I've used our favorite graph database to keep track of all the activity for our community members and that is one crafted about to look at dbpedia is a really quick example that I could can all show life the yet business craft I said really interesting really rich data set that we only started to explore as so much more in there and then Bitcoin as one of the larger graph examples which is representative for typical money transfer graphs and and similar things okay the near future community graph if a Mariam keeps all these users in continuously imported so all the activity on Twitter second flow and so on and so I just have an effigy desktop with my community graph here and if I look for instance at users here and I can see that I have a number of users so do you think that I want to look at today is mostly a Detroit a bit so first of all for Ronnie DS graph algorithms it's really useful to have something guys say okay I have a node which has it's a relationship to a similar type of node so for instance a user to a user I talked him out to a document or a product to a product because that's what most of these algorithms are of it for kind of the typical mass graphs so what I want to start with I want to take tweets and look at the heat-treat graphs so I have tweets which are heat treated batter tweets so that's my kind of baseline graph and I just want to quickly around pitch rang on that I ran a stream message so I get it turned back all the nodes in a score and then I want to just output it did the tweets yeah degree and the score and I take a look at the top it's called so this actually now took the data in the graph rainy algorithm computed it and returned the scores from from from this so you see it's it's pretty fast and we see some tweets which are very generic but which have an high degrees or have been retweeted quite a lot but this also corresponds 50 high PageRank score so no big surprise here the next thing I want to look at is actually a inferred graph so we can look at it users on Twitter by users posting tweets and these tweets mention other users so we can actually do an inferred graph it's also called dimension graph where I am mentioned someone else as my connection to this other person right so and this is what we what we do here so I have in this graph I take this pattern of user posted tweet which mentions another user and then I a great them by the to users counter often that happened and then just create a virtual relationship for a POC to go to again notice and this is now my my inferred virtual graph where we have Nia for JJ in the middle you could also remove info Jade and you see that lots of the graph gets disconnected like Amy showed before and this is kind of my my computer or my computer model that I want to run these algorithms on so it's kind of people having mentioned other people it's my basic social graph model here so and now I can for instance run something like picturing on this and can look at who are the most influential people on or accounts on the animatron graph so you see and of course because it is near forge a community nephrogenic graph connect on top but there are also some other people like Constance Kirk on position 3 who's been very activated database space and kind of publishing in and and and treating a lot of things so his even if he's not a core member of Geneva J community his sweets card or he got mentioned so often that gets a really high PageRank I'm there as well Colin Emil is there a drink Euler the morning paper guy from from spring source and and some others velocity as well so people that have been mentioned more often than others and especially at transitively so not just directly but also transitively over much of the hops and then I can take page featuring as well and write your sales back so I don't call this three message here but I call the procedure of if out stream and if I run this I actually get just a summary back that says I look at that many notes so filling those notes ran for 28 durations it took that many seconds or milliseconds to load the graph compute it and write it back and now I have this PageRank property here on all my notes and can use that to vary my data again and which I can do here for instance by saying okay I I look at my Twitter users that have a PageRank property take D top n I skipped me for J and graph connect because I don't want to see them and then I actually continued to query right so I can take these top users and then say okay what tweet city post what texture they use and then I actually created virtual graft it says what are the top tags used by my most influential users for instance right and if I run this then I see sodium that see that the red ones are the users and the gray ones are didn't know these are the text actually so this is user these architects so we can actually see what kind of activities that my top users exhibit in in this case and so on so the other examples I'll show you here on this a little bit larger machine so here I have a dbpedia which is a dump of Wikipedia actually which has in total 11 million nodes at hundred twenty million relationships so it's a smallest graph but quite useful to to run stuff on so what you can do as fonts if you can here again run patron Gandhi dbpedia and if we do this then we can see also really nicely actually not let me run this this variant of PageRank here so it loads the data from neo4j computes the PageRank writes the data back 120 or iteration on PageRank touches 320 million relationships 20 times because it's a twenty iterations and or actually it's more often because it does it per note and if you look at it so the machine gets utilized completely so it has 144 CPUs and all this cpus are busy and it took us a total twenty seconds to run PageRank so get it data for me for a run PageRank in memory variety data back to new for j was done in 20 seconds on dbpedia which is quite nice okay we can also run other things like clustering and so on I can also here use this projected grass once it if I'm only interested for instance then pitch is in a certain category or Pichet surface certain tag or that cover certain aspect then I can also run sup ranking algorithm so for instance I can also decide I want to cluster my graph first and then run for instance ranking on on top of that but to show you that not only large machines can run this I actually ran this patron algorithm also on my Mac here which has actually two CPUs and I ran it with I think four gigs of RAM I saw and even he had computed on dbpedia within two minutes and thirty seconds or something like that so even if I don't have to monster machine available even on my shitty mag it's still fast enough to compute page rank on dbpedia in a reasonable time which is pretty cool okay the next graph so you can also do clustering their phones it's on on dbpedia by saying okay what are the most most occurring clusters and then for instance you said to visualize the central nodes of each cluster in India for Jeff yeah this is really interesting data set has been used for I think almost 10 years now as a scientific data set and for competitions and so on so it's business reviews by users with where businesses have locations and there's also users friend network in there and you can project this user to business network of course into a user to user business to business networks and then you can run things on top of that so this is just a basic computation on ratings where we can do some statistical analysis but we can also run something like a patron on the friends networking and Yelp and he can also run algorithms on these Android networks so I actually computed it so the user to users haven't jointly reviewed a business actually avatars in 1.3 billion path in total and if you flip it around by busy to businesses that have been jointly that they're both versus have been interviewed by the same user its 252 and 30 million paths so that's kind of the data that you can run it on and then you can for instance try clusters of similar businesses you can't find peer groups or people that have similar preferences for businesses and so on so there are some really interesting stuff and here what we created is an HEV a persistent echo occurrence relationship for Las Vegas so we kind of said ok all the businesses that have at least I think 5 reviews and I on Las Vegas and have peer reviewed by the same people I want to actually pull them together into a graph and then run algorithms on that for instance you don't find so what's interesting is I actually don't get a lot of large clusters just a single large cluster so I seems to be a quite large overlap between all the businesses in Vegas could be because it's all I don't know on this river you know and then you can also run picturing on this projected business network there interestingly businesses showed up which don't have an high paid ranking on Yelp which let me actually to investigate it does to bution after year ranking on yet which is actually pretty bad because it's only between three point eight and five so it's kind of what lol are the numbers are not available in reasonable amounts so it's kind of interesting and the last example is Bitcoin bitcoin is a really nice payment network so we got it from from Greg Craig Craig Walker vodcast lured me a Bitcoin and imports continuously all the data from VidCon into neo4j and it has 1.7 billion notes 2.7 billion relationships it's about six hundred gigabytes of this and we can use iatest network for instance to compute different things one was a degree distribution where I actually learned that people on Bitcoin don't reuse addresses right so when you want to send data money on Bitcoin you're always spread in your addresses so you're not trackable so did something that I for instance didn't know so first inside for me and the second thing that we did was to look at what classes of communities can we see in like this projective network from from address to our to transaction to our to address so it's kind of an five hop distance projected network and then we take this network and project it to a to a virtual graph randy algorithm on it and then in likes 200 seconds we get a clustering on top of these projected addresses in Bitcoin so this was with with ten million a subset of ten million because I didn't want to spend more time to wait for this but of course you can also do it on there under whole or whole network as well okay and the design considerations for implementing this we really wanted it to be a efficient and fast so pretty paralyzed everything so we've paralyzed deloading from your virginity computation and the writing back so we can utilize all your CPUs if you have a lot of cpus like on a new cloud instances you get handed 28 CPUs which are really cool and we wanted to implement in higher level API that you can use to override graphic iran's against which we call a graph api and so far we're my largest crafted I ran it on what had three billion nodes and 20 billion relationships to compute things on top of that so that's kind of what it does it loads data from neo4j pehle computing parallel or helps you create graph api and writes it back and as you've seen before it keeps a large CPU accounts really busy which is something that warms my heart somehow probably also the data center but you know and what was actually surprising for me is actually how well we did in comparison in for instance if you copy a graph to graph x paper on the twitter 2010 data set for union-find and for PageRank we actually do not so badly compared to that so that made me happy as well and as I said at scale three brain nodes 80 billion relationships on a large machine computed in one hour 47 minutes of PageRank one on top of this graph which was nice okay so what I what do we want from you we want actually you feedback we want you to try this out apply to your own data apply to your to your own problems and questions give us feedback send us ideas send ours especially a call so Jamie what are the ideas that you have how did you want to use that look at the information if you know if you have a channel slack where you can come back and ask us questions and yes to get up repository for diagrams there was a release just two days ago it's quite easier to use and to install and we also have an white paper that you can use for yourself but also of course head to your colleagues to to your bosses and say look this is something that we can now do with neo4j and vegetal econ and as we all know graphs are everywhere and with that I want to leave you and thank you for your attention and have a good day oh no sorry I forgot something sorry my bed and of course all this work for thought would have been possible with my amazing contributors so I've worked with a group of people who actually did all the work so I just you know get feedback and so Paul and Martin from avantgarde labs did the took the crunch off the implementation work and tomash did an amazing job in documenting all of that so I'm really grateful for this team to help me with building this and with that I want to close and thank you for your attention [Applause] 