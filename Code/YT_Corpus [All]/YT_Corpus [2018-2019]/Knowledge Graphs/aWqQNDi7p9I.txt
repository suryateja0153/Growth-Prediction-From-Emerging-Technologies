 cool all right so like Angelica said we're going to be looking at how to do import and modeling with the dataset that we've taken off the internet so I do a just a quick introduction to me just in case you you want to get in contact afterwards you can either do that by email directly to me or we have a developer relations email and that will go to me and a few of my colleagues so with that this is our plan for the next 45 50 minutes or so so we're gonna have a look at a dataset so I'll explain what that is in a minute and then most of the session we're gonna spend looking at how we would go about modeling that in a graph and then we'll look at some different ways that we can import that data so we'll look at a few tools that are available to you if you're building your neo4j application and then we'll finish up with just a couple of queries that we can do on that we're not going to spend much time on that we're focusing mainly on the other two sections so the data what are we gonna what they decide are we gonna look at so we're gonna look at the yup data set challenge so this is a competition that Yelp have been running for probably the last five or six years and you can see there's a link to it down the bottom of the screen so we'll just quickly go out of the view and go over to that see here yo calm slash data set challenge so this is what the website looks like and they do a bit of explanation of the data set and they give you a few ways that you can download it so you can either get a JSON version or sequel version and then if I go over to the second tab over here you can see what the data looks like so we get we get some businesses we've got some reviews we've got some users we've got some check-ins and I've got some tips oh that's pointers so it's reason hopefully reasonably accessible type today so if you've if you used even if you haven't used you up probably those things are still reasonably familiar to you we're going to come back to these and look at how we go from these JSON files to our neo4j structure in just a minute I'm just going to come back here ii want to do a quick introduction to to the graph data model so like I said so this is an overview from that page of what data we're working with so there are five million reviews off one hundred and seventy four thousand businesses people have taken two hundred thousand pictures we're going to ignore the pictures for this session but that could be another area of interest if you're if you're interested in doing image analysis and they're across 11 metropolitan area so they're across several cities and Germany the UK in the US and then there are there are a bunch of attributes on each of those businesses which you probably saw on the previous when we looked at the web page so they include the opening hours when they are parking what availability they have and the ambiance at each place okay so how do we go from the yup set of JSON files to graph 10 well so Nouveau Joe uses what we call the labeled property graph model and there's a diagram of it on the screen at the moment so at the center we have nodes and these are representing the pieces of data in our domain so they would be if you're familiar with a relational database that would be pretty similar to a record and in there they're then those nodes are then connected together by relationships so you could consider that a pre computed index between the nodes so we can effectively go between those nodes that do have a relationship really quickly so rather but in a sequel query we might have to calculate that join a query time in neo4j we write that relationship or that join into the database it's actually stored and then the last bit R is are the properties so those are the key value pairs that you see around that can go on nodes and relationships and those would be used to store attributes or metadata for our nodes or relationships so for example in the yup dataset maybe we're going to store it on a business name you might store a name so that could be an example and can be Java primitive values or you can store literal arrays another way to think about it if you're yeah if you prefer using the sort of English parts of speech terminology I'm not the greatest at this that if you are then this is another nice way to think about it is that nodes are often represented by nouns the properties would be adjectives and the relationship would be an adverb connecting them together these are these ideas that's a rule of thumb one they'll certainly be examples where maybe that doesn't quite work but it's a good starting point here this is an example showing the property graph model with some sample data so this is what we've got on the screen at the moment is a very small graph so we've got three people oh it was two people rather Dan and Ann at the top and we've got their car and you can see we've got some relationships going between the two peoples so luckily they both love each other and then they live with each other as well and we're saying that Dan drives the car but Ann owns the car and so that covers all the things so we've got our nodes so the Dan and structures and the Volvic structure and the properties and then defining what exactly does that node represents her in this case we've got the and no it has a name and the born property the Dan one has a name born and Twitter property that's one thing to notice that's a bit different from what you might be used to just because I'm sorry the last bit is that we've got labels on there so you can see we've got a person label on both the people is that just because both of those nodes have the same label it doesn't mean that we have to have the same set of properties to go alongside so you can see and doesn't have a Twitter account in a relational model we might have to specify that there is a twitter column and then we just have it null in the this graph what do we we just don't specify properly and then we've got some properties on the relationships as well indicating when down has been driving the car so it's okay so we want to try and make a model like that for our dataset we're going to follow this structure so we're going to try and work out what are the entities are you one of the main pieces of data that we've got in our dataset well then look at what properties are interesting we need to find a unique identifier for each of our nose well for each of our entities so that we we don't end up creating the same data twice we'll then look at how the basis of data can be connected and then we'll repeat the process as necessary for this section of the talk I'm going to I'm going to show you a tool called Harrods now which I've got over here on my fourth tab so we're gonna have arrows on one side of the screen and we're gonna have the data set on the other so we can we can remember what it is so this is we can share the link with this tool after it's written by one of my colleagues after allowing you to quickly sketch out graph mop so we'll start at the top so we've got some businesses and those those seem like an important thing and this domain so let's start up so where it says caption we can fill in the label and we'll put a we'll call it a business and there's a business ID we don't really need to include business that in the name because it's already on a node with that label but we'll cap we'll call it ID I guess the name is probably quite interesting and then there are some other things as well perhaps we want to capture the city the city seems like a reasonable thing to capture we can we could probably also add the state in the postal code as well we've got categories so we could add categories in here as a set of strings we could go it write it in like that but categories actually seems like something that might be interesting for graph querying so for example if we found a business that we like and we wanted to find other similar businesses it may well be that we want to go through those categories to try and find those similar businesses so we're gonna we're gonna Park the idea of having categories as an array of strings for now but we'll just we'll just finish creating our business so you can see here we've got our business node and we're just indicating what type of data those those properties that now we're gonna we're gonna handle the category so what we want to do is actually will create category and this will allow us to query through it so we'll create a category node and they've only got one thing there's no identify four categories they just have a name so we'll just do that it's a category name and now we need to work out what should be the connection between these two Thanks so we just draw we can if you hover around the edge of it you get a little arrow comes up and we can draw a relationship between what we need to do now is name and so what you normally try and do is keep it in the present tense and keep it use an active um I think in category that works pretty well for this so we've got at the moment our graph would be business is in a category where we can scroll down there's some other stuff in there but probably we've captured the main the main the main stuff we want perhaps you could do something clever around the hours if you wanted to model that sort of stuff but for now let's go down and have a look at reviews so the way reviews works you can see we've got a review ID at the top and then we've got a user ID just below it and then we got a business ID so there's three things involved with this so the review ID is representing okay this is a specific review the user IDs on sleep referring to who wrote the review and the business ID is indicating what business is about so the kind of indicates we need to have a user and then the user writes the review about a business and one way we can model that so let's put the will put the evening we'll start with the user so let's go down here will create we're gonna create a name for our user so we'll put in a caption user well again we've got an ID for the user and we've got a name for the user and we'll just have that information for now and the user one way of doing this could be we could do it like this because they can use a roller review about the business and we could capture the text and we could capture the number of stars that they came and that would work okay but it now becomes like imagine you can imagine that one thing we might want to do is pull out interesting entities or interesting commonly used phrases in our reviews and then enhance our graph with that with a sort of NLP type information and is it's not possible to connect other things into a relationship so actually this model doesn't work very well for what we might want to do so one of what I want to do instead is actually have review as a note so I'm gonna I'm gonna bring that in over here so let's just check what properties do we have on a review so we'll put in our caption for our review we've got an identifier and we've got our number of stars and we've got our text there's other information on here as well that you can see on the left-hand side but we're not going to put all of it in for this example so we got our review and the review reviews a business so let's connect that together we'll call it reviews so prison presents again and we're saying that the user wrote the review and now we don't really need this this one anymore so you can we can just click on it so we've got a reasonably this is a good model to use a read review and about business and it's in a particular category there's other stuff that we could that we could do if we wanted to this check in information there are tips as well but I think this is pretty good pretty good to start with so what we'll do now is we'll just put this back to the full screen will download SVG of that and we'll take a print screen this and we're gonna stick it into our presentation so we've got our got our model ready to go so let's get that got massive arrow there let's get real app and we'll just switch back yeah and we can put up and our little model in the bottom and bottom right-hand side of our slide so there we go so we've got a model that we're gonna work with so that's what we're gonna we that's what we want to get to what as we won't use a way to review reviews reviewing a business and the business is in Academy next thing we need to figure out is how we going to import data into that model we're going to look at three tools for doing this so we've got a pop which is they're awesome procedures on slide 4 library procedures library procedures or procedures and functions rather we've got the neo4j drivers and so we can put data into our application directly from our programming language of choice and then we've got the near phonetic import tool which is very good for doing initial imports of big data sets so we'll start with a book and so what is a Bock I guess would be the first question so this is a procedures and functions library that the community has been building since I think it was about March 2016 or around them so it's had a couple of years efforts for a nice way of thinking of this is it is basically the Swiss Army knife of libraries there is something for everybody and at the moment there are more than 400 procedures and functions in here so there's beyond just doing data import you can probably find something in here that will help you with data cleaning with any other utility or problem that you might end up coming across it's actually now really easy to install so this is a screenshot of the neo4j desktop that was released in October 2017 so on the 33 release series and this is the the new place for doing all your neo4j I'm gonna I'm gonna demo using this but just to show you if you want to install a pockets as simple as clicking that install button on the left-hand side of the screen in previous versions you would have had to go to github the github release page finally appropriate jar for your neo4j version and put it into the plugins folder so that's all completely automated for you now so it's easier than ever to get up and running with this now the first thing we want to do is we want to make we want to set up our indexes and schema for the date for the database so indexes in neo4j are used to just find the starting points of the query and those are the first two things we see is you can see category name and business name so we might want to search you can imagine we might want to go and find the businesses in a certain category or we might want to go and look up a specific business by name so we're going to put some indexes on there and then the second argument given to this procedure is creating what we call unique constraints and what this does is it says that we can't have any cheaper so if we go from left to right we can't have any duplicate nodes which have the business label and an ID property so there can only be one unique version of ID property for that business label and then we're doing the same thing for users and reviews so we don't want duplicate businesses users or reviews and we want to be able to quickly find what we use indexes to find what we call the starting points of queries and we'll see some queries where where I'll point out later on how exactly that so this is a this is a nice procedure that wraps up having to go and execute create index on or creating a constraint on syntax and ciphers and this wraps a little bit for you well where we were going to really focus for the next part of the session is on the a POC load Jason function so this is a in case you haven't seen procedures this is a procedure and you can see down the bottom of the screen I've taken a a print screen off the documentation floor library and this is how you went this is a simple example of how you would call a book load jason so at the top we're defining a URL where our jason file exists that can either be somewhere on the internet so it could be actually to be linked or it can be a filesystem link and so we're going to look at fastest and links in case use you notice the discrepancy between the examples once we've gotten that URL we say call a book jason we pass it in and what it gives us back is a proper parameter call variable named call value and we can then in this case we're just changing that so that we refer to it as person and it will have a map of all the properties that the json file contained in this case it's a fairly simple one so it only has an array of name of people and they have name property and age property and a children property and so we're creating a person from that Jason for us we've obviously got different JSON files so this is how what we're going to start with is we're just going to do some exploration of the data so I've got an example here of how we would query the business Jason far from the dead sir at this point I'm just gonna I'm gonna step out of the presentation I'm going to come over to the near future just so in case you haven't seen it what I have on the screen now this is the the near-future desktop this is where this is what you'll get if you download neo4j today and you can see on the left hand side you can create yourself projects for whatever application you're working on so you can see I've got a few a few different ones for stuff I've been working on but today we're in my yup one that I've got the mouse on now and I get I can create lots of different databases in here so you can see I've got I've got a few versions and we'll have a look at those later on and then at the top I've got the the neo4j browser and I'm just going to switch over to that so this is my new FJ browser instance and I've got some saved scripts I've cheated a bit here so in the browser when you write a query you can actually save it with a comment and I'm going to use one of those so this on the screen at the moment is a query for exploring the data set that's if I just run it so you can see how it works and we'll just go through it so we're saying I want to call that a pop load jason function and i've got a file and it's in this location on my machine and secrecy's in my projects your algorithms data set business jason I know we're doing here is we're just returning the first 10 businesses in that file and it comes back we've got the hours we've got the address we've got the city it's exactly the same as what we saw on the website but this time it's obviously filled in with so whether we're those specific companies or information rather than just being an outline and we can scroll through we can see what it looks like for for a few of the different business and if you wanted to you could say okay I just want to get the name so I could change this they just returned name and then we just get the top that the names of the top ten businesses in that file those files are they they're not actually like completely valid a since it's streaming Jason sits one row has one valid piece of Jason and so a pop load jason is able to handle that the structure for you any special data cleansing or anything of that sort what I want to do next I'll show you how we might create that structure that we looked at before so on the screen now we've got the first lines the same as before and I'm just filtering it so that we just process the first 1000 businesses once we've got them so we get this gets us the first this but here loads in the first thousand records from the business JSON file we're then calling the merge function so merge is a Slifer clause and it will create the business based on this ID remember that's that if it doesn't exist and if it does exist it will just return it so we'll just have the B will be what we're doing on the next line is we're saying I want to then set some properties on that business note that I've just created and we're cheating a bit here so we've got a nice function in a clean and we can tell it which properties we don't want to have so we're just saying take out attributes take our hours takeout business ID because we've already got it take out categories because we're gonna create a relationship to that takeout address take out postcode but it will keep everything else it's quite a nice tool for filtering incoming Maps and then on the next few lines we are we're working we're working on how to connect the business to its categories so we the categories are on the categories property on the original jason and we're using me and they come as an array and so we're using the unwind function so this another cipher clause and it takes an array and explodes it out into individual rows and this is very helpful because we can then connect those to use it to help us connect the categories to businesses so I'm just going to run that it should take a few seconds so you can see it's now created 1,500 nodes 10,000 properties 3000 relationships and we could go over here and we can click on that we can see what's been created so for example what we've got on the screen at the moment you put it full screen so you can see what it does we've got a bunch of dentists so we've zoomed in on a fun part of the graph and chill for everybody and there's a whole load of dentists from different places looks like they're different places in the US you notice there's two different categories so we've got dentists and we've got general dentistry for now I'm going to switch back to the presentation again so I can just I'll just walk through your eye I think I've done this kind of done this a bit in the in the browser but we'll just walk through it on here as well so as I said this is removing properties and this is this we're using me and in this bit we're using the unwind command we can then do the same thing for users so this is what this is what the equivalent code looks like for creating the users part of the graph so it's pretty similar to before but rather than processing the business Jason we're using word processing user Jason and we're creating some nodes with the user label and this time we actually have a friends graph so there's a Yelp social network that we are putting into our new FJ graph and we can do a similar thing with reviews as well so this is the equivalent code for reviews so again different JSON file and now we're connecting businesses users and reviews together it's a bit tedious running all these commands in the near-future browser because you can only run one at a time and so what we might want to do is put them all together in the script and we have a tool called the cipher shell that is really helpful for allowing us to do this and it's yes it's designed for can run it interactively but it's also very very works very well for running multi-line sucks scripts and this is what it would look like so we can create a file with all of those size of statements that we created before we can pipe it into this size of shelter let me just show you how we would do that so if I come back over to the near-future desktop and I'll go back to my my home screen if I click on the manage button I get a few more options than a before and one of them is terminal and if I just scroll up this is big enough for you to read it but we're just cutting a file and import a pop-top cipher and then piping it through to the cipher shelter only other thing I'm doing they obviously you can see Matt the password if my my local me everyday you don't have to pass that in on the command line you could it could prompt you for it and then I'm saying I want it to to give me some verbose output by default it will it will it has a different formatting but for doing scripts that import data it's useful to see what exactly is happening and so you can see here we've created 500 nodes on the first statement we've got another 58,000 on the second one and then 88 thousand on the third one let me just show you what this looks like so this is what the file looks like so a lot of it is similar to what you've seen already so we create the businesses and categories and then we've got the users and reviews it's exactly what we had on the slide but we are just restricting it to a thousand businesses thousand users and 50,000 reviews only other thing to notice is we are semicolons separating these statements that's how the cyber shell knows that we've got another statement coming up now okay so that's cool so we've now loaded in a decent subset of the data but what can we do better so the limitations of what we're doing at the moment are that it's all running single threaded and we're and we've got to make sure that what we're importing the transaction state that gets generated from that I can fit into the realm of the machine so I've got 16 gigabytes on this machine on my laptop for example the transaction state is the state that gets created when you when you try to do a write query so for example if we did a query that was creating a node there would be a command called that creates that note if we then connect it to a relationship and set some properties they would also be commands for that from those are all pieces of data or pieces of state that live in memory for the duration of the transaction and that works pretty well when you're just doing small transactions there's not there's not actually a lot a lot of stuff to keep in memory there but when we're doing big imports we can cook if we do it on a file that's too big we can easily run out of memory on them cheap and so we what we actually want to do is is get some help and not do all of that in one big transaction but maybe batch it up a bit and there's a tool called epoch periodic iterator which is very handy for these big data imports when we're just starting out with a data set and it does exactly what we needs it splits up a transactions batches and then optionally runs those batches in parallel so let's have a look so here we're doing we're running the the same Jason stripper command in the middle of processing that the business JSON file but this time you can see we've split it up into two queries come here on the first one we say we need to feed it a stream of values so what it would it would you want me to process and in this case we're just giving it every one of those lines from the JSON file and then in your second statement you say okay what do you want me to do with it and in this case we're just saying I want you to create business nodes if they don't exist and set a bunch of properties on it now you notice down here we're within indicating a batch size of 500 and we're saying that it can be parallel so it's splitting up those streams of business pieces of JSON missing 500 of those in batches of 500 and then it will it will try and paralyze the creation of when you're using the parallel truth parameter you've got to be careful that it can actually successfully parameterize this if you've got queries where they might be touching the same part of the graph then you're going to end up with with with failures and from deadlock detection exceptions and so you there's also another parameter called retries that you can use in that case but a safer thing to do is try and work out is that are there some bits that are really easily parallelizable so for example in here I know that the businesses are all are all unique in that file so I can parallelize that quite trivially and so yeah I didn't even realize I don't even I'd even helped us out so that's just seeming and on the the loading Jason and then where as I said we can go and print run a particular command over every line afterwards so we've got it we've got a script showing how you would how you would convert everything for that as well so I just quickly go back into our import a POC so this is what it looks like if we do if we process using a pocket periodic it's pretty similar to before I just split some okay so that's a good starting points of view if that's completely programming language agnostic and you can do all of that just using the native browser and the sniper shell and your knowledge of neo4j - but we can actually probably do a bit better if we use the new drivers so near j the company has four official drivers and we've got drivers for Java JavaScript and Python but there are also community drivers for Ruby go Swift Alexia and PHP so there's there's almost certainly a driver for whichever language you're working in for this session we're going to keep the people who like - very happy and the others of you will have to we'll have to just follow along and hopefully there's not too much complex coding but all the drivers are roughly roughly follow the same the same structure to install the Python near-peer driver we we can use the pip libraries which go pip install new FJ driver and now we can we can import the data directly from Python rather than having to you to go into the new FJ browser so on our first line we're creating the driver so all of the languages have something similar to this see say I want to create the driver you indicate to it where is new FJ running and then you can pass in your authentication details if you were doing this in a real application feed that in from an environment variable rather than hard coding it I just done that to save space on the slide on our next line we're then opening we've got to do so we're a POC to load up Jason process the JSON file for us we've got to do that ourselves now so say I want to open the file and then we need to create what we call a session so a session is so driver lives for the duration of an application and a session would be off and on a request response basis and within a session we can run multiple cipher queries and so you see in this one we're going we're iterating through the file we're then loading that the jason for that file so we've got a representation of the business and then we're executing a cipher query that creates the business and connects it to a category if you want to look at the look at this in more detail i've got the link for it down the bottom so angelica we'll send out the slides afterwards and you can as you can you can take a look at that if you haven't got a screenshot of the link the problem with this version is that we're processing every single business in an individual transaction so it's going to take a long time to do this so we might want to do instead is handle more businesses in one go and so this big piece of code here is an iteration on the previous one where we're batching up the businesses into groups of 1,000 and so there's a syntax here where we can say i want to begin a transaction and then i can run a load of statements in it and once i get to a thousand then i'm going to commit it and i'm gonna start a new transaction and so that works that works a bit better than the previous one but it's still like there's a lot more code to do if we want to do this approach so a nicer way than that i think is to make use of the unwind statement so will do will still do our batching but this time we'll we'll just build a bunch of lists so we're building me the items list up here and then after when we get to a thousand we will we'll call our US cyprus statement and we'll use the unwind statement to go through each of the items and again execute our merge business then connected to categories piece of code and this what we're doing on this on the screen here in python is is effectively what the periodic iterate is takes it's taking okay you've given me some jason i'm on every thousand i'm gonna run this run the statement and it also uses the unwind as well okay so that works that works okay but it will take quite a long time to get the whole Yelp dataset in because there's lots of lots of stuff there all we might want to do instead is use the new FJ import tool to get the initial data set in and then if there were some changes that we wanted to make to the dataset afterwards or if yelp release more data that we want to update our us data set with then we could use one of those previous tools to do that so the near view in porto let's have a look at this so this is a kimono tool for bog importing initial data sets from custom so first thing command line tool so this is available where I was running the bin cyber shell you have a bin new FJ admin and there are a bunch of commands on there and one of them is import and I've got the capture of get printed if you just call that on its own on here so you can see it's got you can indicate which database so you want to write - you can say where it should read notes and relationships from and there are a few extra pieces of information down there as well now this still is a bit different than the other ones so with the a popular Jason and with the Python driver versions of the import we were running we had neo4j the database was running and we were executing it directly on there with this tool we're doing an offline inform we'll just will go into what exactly that means but first this is this is this is really handy for doing initial dataset loads and so yeah so this is this just diagram explains what we've been doing so so far with our previous two examples we've got the raw data in this case it's Jason we then move it through when we execute a cipher query it will create an entry in the transaction log in if J and it will then write that that the entries of that transaction log into the still files the advantage of that is that if something crashes we have a way of recovering and with the import tool we don't have any of that any of that safety we don't also can't we don't have the goodness of cipher anymore so we're effectively going straight from the raw data over to the store files so when you're running this it's going to be faster because we've skipped out that whole transaction safety stage but if your process crashes in the middle of creating these still files you're gonna have to you're gonna have to start again there's not the recovery and mechanics are I'm not there the advantages it's really quick so before we look at how to use it let's just have a look what exactly are these custom CSV files that we need so imagine that we're trying we want to create a graph and we just we've just zoomed in on a particular part of it so we've got a user Bob with ID 1 2 3 4 and Bob wrote a review and the reviewers IDs 6 7 8 text is awesome stars is 3 and we want to know this is what this this is what the file format would look like for the neo4j import tool so if we go from the top so we've got one file representing the users we've got one file representing the review and then we've got one file representing the relationships between them on the top row we've got what we call the header and we're using a grouping there and the groupings are pretty similar to label name so here we're saying everything you see in this column you can you can indicate you can refer to it as being in the user group and then if we come across to the middle one this is the review and the way they get used these the review and the user is that when we come down to our relationships relationships file we have to indicate a start ID and an end ID and we're just saying that the ID that you see in here is going to be unique inside this label inside this group brother so so 1 2 3 4 here good versity 1 2 3 4 there 6 7 8 6 7 8 1 2 3 4 5 and so on and then we've got some properties as well that will be created so that's the that's the file format that we need so how do we get those files so I've got a Python script that does it but you could you can equally use any other programming language it's not have to use Python Lissa is the code that generates the business CSV file so I do zoom in a so one thing I like to do is keep the header files separate so this is particularly useful if you're working with really big data sets often I think the idea came around from from what people were doing in Hadoop where you often get part files and the nice thing about splitting up the header is that if we make a mistake in it we'd have to run the whole process again or open up a massive CSV file and try to just change the first row which can be quite quite painful so I'm creating a separate header file and it just contains the business ID the name the address the city in the state and then we're going to write the business CSV file and we're just going to put in we're gonna have a CSV file which has each of these items it's we're just pulling out out from the JSON business ID name address city and state maybe we can have we can have a quick look what that looks like so I'll just go back to that brother said let's just check where we've I remember where I put it I think I might have it over yeah so if we just go here so this is this repository is all online so I'll just see if I copy the path to them and we'll just go back into our Brandon that's just you will get the first ten things from that file so that's what the the business CSB found looks like see we've got a business ID we've got a name with on an address and then there's a header file there as well so we just paste that in that's even simpler so you can see it's just she's got one row business name address city and state now anybody just clear this screen so you can see everything that's in this folder these are all the files that were so I've created this is the structure so you can see we've got I've got a bit further than what we're gonna do in this in this tool but we've got users wrote reviews we've got users of friends with users we've got obviously the individual users we've got reviews of reviewing a business we've got then got a bunch of extra stuff I've been doing around location so we've got businesses in the city businesses and businesses in the city cities in an area areas in a country so I'll just built a a bit of an extra thing that we're not you can see these are this is what the CSV files look like and I've got one big script that generates all of those we'll just have a look at one other one in a bit more detail this is the category the code that generates the category CSV file and it's and it's header it's pretty I mean all of this code is pretty similar the only extra thing we have to do here is we have to have we have to build a set of unique efficient set categories actually rather than cities I must have done some some refactoring that's got a bit wrong so unique categories because you'll see the same category come up in lots of businesses and we don't want to put that into the CSV files multiple times and then that just means that we just have to delay when we write the categories into the file but yeah you can do this in any in any programming language and expect it would be you you could probably paralyze some of this and maybe do it more easily in okay so we've got our CSV files how do we use the neo4j import tool with our CSV files this is an example this is an example of creating the same graph that we created with the a Pablo Jason and the new drivers good this is what it looks like so first thing is we've got to indicate that we are importing CSV files there's also a mode for importing another database so we're trying to move a database from one place to another we can use this tool to do that as well but in this case we're creating a new database by default it will create it under data databases graph dB but you can override that name if you wanted to if there is a database there already it will fail straight away and say you've already got a database I'm not going to create it so keep that in mind this is a tool for creating a brand new database but it will not trample over stuff that's already that so we've got our mode CSV next we need to indicate where should I read notes from the app so you can see on the right-hand side of this line we have we're saying we've got a business header we've got a business CSV the colon business on the left hand side of the line is indicating that I want every node in that file to be to have the business label remember we want to label all of our business foods with that's what we're doing that and then we do the same for categories and then for relationships we've got a pretty much the same thing we just pointed out the the relationships file and we're saying this time I want the relationship time for all of the connections in this file to be in underscore category and then the last interesting thing so the other the other bits of this coder are just repeating the previous sections we're saying if you find a missing node it's okay to ignore it so by default if in one of these files there's a node there's an identifier that doesn't that isn't the relationship that isn't in the node corresponding node far it will it will fail here we're saying it's okay just report it back to me at the end and we're indicating that some of our fields have multiple lines so for example the review text field reviews often have line breaks in them and said those can go over multiple Lots if we run this over the whole dataset I got a badges typical in screen because I figured we probably don't want to wait 11 minutes for this to run but you can import the the whole of the in 11 minutes and then you'll have a database ready okay so they're just going to finish up to show you a couple of queries that we might want to run on this so here's an example of finding businesses with the best reviews so you can see there are some there are some businesses that have been reviewed five by everyone so probably this is a we want to make this maybe limit only show businesses that had been reviewed more than five times perhaps awesome higher number out of that all these businesses are just amazing I know it's like completely by accident there's a need of law firm down in the second to me and then another query where you could do would be can we find similar categories so imagine we like businesses under the dinner-theater category and we want to know what other similar categories are there one way of working out that similarity is to have a look at what businesses what other categories businesses that are dinner theatres are also coming under and so in in this case not too many great surprise I imagine restaurants and nightlife also sure okay so that is the end so I'm gonna come back to Angelica in case we have some questions yeah definitely thank you so much Marc that was great and just a reminder to everybody if you do have some questions for mark please just enter them in your questions box and your go to webinar control panel and we'll start it off with a couple here so I'm does the neo4j driver for Python required page description know all the drivers are are about but you can you can just you can just if you want it to run that on neo4j enterprise then you would obviously have to follow the guidelines for licensing around using that version but the drivers work with the community version and with the ok great and how can we export the node and relation to JSON I think there might be a procedure in a POC they would allow you to do that but I thought you'd have to check a lot of functions if you search for new procedures and there's a there's a list of all of them if you search for export you can check ok can I use the import tool to load additional large data sets somehow so at the moment the tool is only for doing initial yeah people do often ask and I can use it to to add extra things and so we do we do have a project that is internally working on how we can how we can do that but it's but it's not released released yet but so you'll have to watch this space for now great I'm I mean your example you were using a CSV to do your import is there a reason for using a CSV versus an XLS so the name for the reason I was using CSV files is because the neo4j import tool relies on CSV files if you had in a spreadsheet and you exported it to CSV that would I mean that would be that would be effectively equivalent in in some respects but obviously that tool has no idea how to read macros that might be in a spreadsheet for example and it also has no idea how to read if you had multiple sheets inside a spreadsheet so that's why the simpler CSV format you can actually also get that that the tool underlying that yeah there is obviously a java program running and so you could just run that against any data source and you didn't want to convert your you're dead it's a CSV but that's a bit more of a that's a bit more complicated piece of work than just running this tool from the command make sense I'm and there a couple of questions here around working from an AR DBMS and moving it to neo4j so is there a library or a way to import data already modeled and stored in an AR DBMS I'm moving into new for J yeah so we got there's a few different ways that you can do that depending on what tools you're you're comfortable with if you like doing stuff in a POC there's an a POC load JDBC and so you can pass in a JDBC connection string and that works pretty well of you if you're just prototyping something and you and you want to quickly see just how does this work in a graph if you want to do an offline or DBMS you neo4j import them there's a tool called the neo4j import all of you we can we can share a link a link for that afterwards see you can either run that as a command line tool or oh there's a way of getting it inside the near video desktop as well I can angelic will send out a link which has all the instructions for how to do that my colleague Praveena did a webinar on this about a month ago as well so maybe we can also point you towards that one yeah definitely I'm and can use spark for bulk load instead so I'm assuming you mean can you write those files the the can effectively we're writing store files using that tool so you want to use spark to do that bulk load I think someone did try doing that at some point and I don't know that it's actually faster than this tool so this tool if you run it I mean I'm just running it on my laptop it took 11 minutes on there it will use all the cause of any machine you have so I if you I would suggest try trying it out on a big machine first to get get like a big Amazon instance and try and create that import your data on there because it it does do like multi-billion grafts in in a couple of hours if you can sure you have you would have to you would have to check out how exactly the code works because it's doing some quite clever stuff to build that this so files as quick as it can and I don't know if it would translate directly to just stuff you could parallelizing it's okay and do you have any recommendations for handling data partition by date for example if you were to load entirely disconnected daily snapshots on a day-to-day basis so for that I'm assuming that what you mean is that you don't want any of the any of that data from today to be able to query stuff from yesterday if you were doing that probably the easiest way is to just create completely separate neo4j databases one one feature I guess we get at some point but which is which will make that a bit easier is being able to handle the multiple graphs every one the fj7 so that you could name a graph like today is my don't even know what that is today is my 14th of March graph and then I have a different graph called 15th of March and there's some work around that in the Cape's projects as open Seifer on on spocs and they're doing some of the work around there and eventually that multigraph concept will make its way back in and I think that would be the best thing for your use case okay um and if you're running neo4j how can multiple people be working on the same project in the same instance so I mean for that one it's gonna be similar to how it is for for any other database project what I've seen typically is there doesn't I mean with with relational database projects that I've worked on the often had a DBA that you had two related queries through I haven't seen that so much I'm near future projects but there's often one person who's very but yeah I mean you could you could use it with multiple people working on the same project the same as you could use any other tool okay great I'm and is there a way to export the output of the graph from neo4j into UI for users who are less tech-savvy so the visualizations that we had on the screen can be downloaded as a SVG or PNG and used somewhere else but yeah that's that that's all there that's all we there is that for the moment okay um do you have any recommendations for those who are just getting started with graph modeling maybe some different links or articles I would suggest the best there's lots of examples of this in the craft databases books the graph databases come if you ever look at that there and that book goes through lots of different graph modeling examples and if you want something in person depending where you're located we often we run every quarter we do a graph modeling session in in London and I think in several of our other year European cities as well where we actually take a data set and people or take a take an example problem domain of people try and work out how they would model it obviously with the with the help of an instructor in the room as well okay I think we have time just for a couple more so in the case of multiple users that you were describing before how can we manage the permissions is there a view and know for J essentially no there's no materialized view concept at the moment and you can if you look up near VGA user roles there are there are different roles people can have that they're currently not it's not a first class thing to control access to two different parts of the data you can only control access to a to a database itself so for example you can set people to have an architect role or a Mina role or a writer or than they have different permissions that they have I think that might also answer another question that we've got in case of multiple users how can we manage permissions so if you search for neo4j user roles as a whole section of the operational guide explaining and then we'll certainly be more features added around that because it's a very commonly commonly asked for thing okay and what is the easiest way to create multiple databases algorithmically for example if you were to use a Python dry so if you want so for multiple databases you would have to have multiple neo4j service and for example they would be running on different ports so the default port for example where bolt runs is seven six eighty seven so you can run some other other instances but again I think there's going to be there's going to be more more features in the three four and thirty five series that make this okay and just one more here so while modeling do you have any recommendations on the direction of the relationships any recommendation essentially to have a flow in your model oh not really I mean I showed the example I showed is we could just recap quickly well it's what we mentioned so I was suggesting try and keep the actives rather than rather than pass it's that we had user wrote a review I would name it like that rather than say the review was written by a user but that's just that that's just a personal preference of naming things that you'll tend to see the examples are all written like that but there's no particular reason that it has to be like that it's just a stylistic thing okay and lastly is there a good strategy to bulk load if you don't know the structure of the data ahead of time such that modeling is tricky that's discounting the bulk load know if you're doing iterative building of the model cipher is the best tool for that the yeah as you as you observed the import tool assumes that you know exactly what what your or your structure is before you build and that's how it's able to do two runs over more quickly 