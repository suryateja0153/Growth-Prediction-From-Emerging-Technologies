 okay get started with our next speaker next presentation pleased to introduce Alessandro from Graf aware to talk about building knowledge graphs within neo4j oh cool thanks David good afternoon as they would say that I'm a listener Negra and I'm the graph every scientist today in this presentation I'm going to be talking about how to convert the information available in multiple and distributed data sillas in knowledge graph more in detail I'll walk you through the several challenges that you have to deal with and the different solutions that you can adopt along the path for converting in this data into actionable knowledge let me give you a disclaimer a note about this talk because I know that it has been scheduled after lunch so I added more image and animations in order to make it more interesting for you and avoid as much as I can you to fall asleep so we will focus on a very specific task that is converting the data that you already have in actionable knowledge so we will not talk about a general kind of knowledge but a very specific type of knowledge that you can convert into actions that could be improve the quality of your products or saving costs for your companies and this requires a mental shift from the classical let's say our house mentality based on a KPI to a more relevant approach based on thinking based on a prediction and let's say that this is necessary because we are really a lot of company maybe all of them that are already storing a different kind of data in multiple and distributed data silos and also in different kind of data sources because we are not talking about only the data available in wealth structured data silos that are designed might be on top of a relation database for the specific needs of an organizational unit but we are talking about any kind of data that could be emails that could be shut that could be product documentation that are available for any company right now and we will try to address some kind of actions that reply to different kind of questions in your company like for instance do you know what to your customers are going to need in the next 12 month and do you know all are you going to provide it or are you making the best use of information that you already have in order to make a better solutions or to deliver a better product in the next iterations so these are the the kind of actions of the question as the requires and some kind of action in order to be to be satisfied and as I said these requires a mental shift that it is a quite quite complex so I tried to collect and organize the mental path that brings a CEO a CTO or an architect to to think about the data available in their own company in a different way in order to convert them in actionable knowledge that could be as I said improving customer experience through delivering a better service order living a better product that could be saving costs for the for the company or taking better decision in the next iteration or just avoid to make the same mistakes again and again and we will see along this path oh you can occur in some kind of issues or it's a condor error and how to overcome all of them and we will see what will be the best solution that you can adapt in that sense so supposing that you are the CEO of a big company and you will like to organize all the data available in your company we are thinking I'm thinking about emails chat product documentation wiki pages blog post and so on so forth in order to gather all this knowledge that is so distributed and collect them in a trusted single source of truth that allow the CEO to really represent the current knowledge of the company or supposing that you are the CTO of an earth care company that would like to deliver a new set of services today to their present so in this case again what he can do is to gather data from multiple contact points like ambulatory like pharmacies like hospitals like call centers and organize them in a connected source of truth on top of which build the next generation of the services that they will like to deliver so putting the two you're running a manufacturing company that would like to deliver better products to their customer or just reduce the costs for maintenance in this case what you can do is to gather data from product documentation from customers complain from supply chain nodes or distribution chain nodes and learn from past experience for delivering better products in the next iteration finally supposing that - you are the the architect of a travel website and again you would like to offer a new kind of service not only to the end user but also to the hotels in this case what you can do is to gather the information available in author's description in the customers complain or the customer reviews in some open data like tourist information and organize them in a way in which you can deliver better recommendation because you can sport hotels issues or hotels strengths quite easily then use them for delivering different kinds of service to the end-user in all this case what could happen is that these a C or sitio will will call the developers team and ask them to create a new platform or use an exiting platform to gather all these data from which he would like to extract new knowledge so what they will do is to start going over the entire set of data that they have and as I said they could be different kinds of data so they could be relational database they could be textual documents and so on so forth and try to find a solution for collecting in a single source or through this data the first approach could be a relational database even though this is not quite common anymore but suddenly they notice that let's say this is not the best solution for two main reasons the first one is that the data are so a thorough genius that cannot fit easily in a relational schema and the second reason is that these data are quite a lot so organize them in this relation database could be costly in terms of maintenance in terms of creating the right index or create the backups and so on so forth so they immediately discard these solutions and go over another solution that is based on a search engine for instance let's say that the search engine a cool appear quite a better solution because in this case you can solve both of the problems that you had before in terms of structure there is no issue because you can have multiple indexes and organize the document in a way which you want and even in terms of let's say data dimension is not a big issue because you can with all the tools available like elastic search for instance you can scale quite a lot across a cluster of machines so the happy about the solution they start getting the data collecting them into some indexes fine-tuning the query and deliver these this solution to the two de Arce or CTO he or she starts looking at the a dissolution at the data it appears quite interesting because he can search for the for the knowledge but after a while the limitations of these solutions appears because let's say these a kind of solution allowed just to go over the the set of documents that you have quite in a good way to be honest because search engines work quite well but there is no way for extracting real knowledge because the documents are not connected they are just isolated you can get a list of documents and that's all and even just making a kind of a concept or search is a pain so it's not happy so again the developers team has to walk overnight try to implement some kind of aggregator or mechanism that allowed to merge multiple documents coming from multiple data sources in a single document because this is the only way that I have and also try to implement some kind of semantic search ingesting synonyms and so on so forth but again this is not the right solution because it cannot scale in terms of simplicity because as soon as a new data source has to be integrated the airport for integrating into is enormous and just changing a single synonymous will be a big pain so at the end all these solutions are wrong because they cannot reach the goal that was the beginning of goal of the CEO or the city oh so they the CEO is not at all happy because they can miss the deal they can continuously spend more money for this new platform and so on so forth there are some reasons that we can just summarize why this is not the right solution first of all that the kind of platform that we need there is a platform that has to handle all the big data because as you can imagine we are talking about different and spread the data sources were they wid part of them called store a lot of data and moreover we cannot trust all these data sources because I will never trust a chat between colleagues in my company or again even the speed at which these are generated is a quite a lot so it exposes the four V's of a Big Data Platform avatar as you know volume velocity variety and veracity but and this is why we discarded since the beginning of the solution based on the relational database because a Big Data Platform cannot fit in a relational database furthermore the problem is also that organizational leadership want a solution of for data to be integrated at speed that means not only that this new solution has to be integrated in the existing platform but also that as soon as a new data source has to be integrated this should be quite straightforward and the solution before as we saw is not that case and furthermore it should enable knowledge workers to be more efficient effective and consistent but there is a big question that area remain unresolved that is a worry is the knowledge in a kind of search engine there is no knowledge is just a way for indexing what you already have it's fast to search this is true but there is nothing more than the same documents that you have at the beginning and I will show you why supposing that you would like to implement a search engine it will be like this so you will have a textual search form with some kind of filters like day it's like topics one you once you press on search you what we would get is a set of documents like this and it's not that simple to be honest because at the end you can I mean represented the the search engine in this simple way well you have a kind of black box where you put documents from your several data sources and then the users can perform queries and get back some responses so the the most interesting part in this platform is the indexing part that is based on say oh not quite all the concept that is the inverted index I'm seeing quite a lot the concept because I think that the first book printed by Gutenberg already has these this kind of index structure that is what we find at the end of any book where you can search for the for the words and for each word you can get the list of the list of pages in which this word appear or I mean at least is used in an important way so in a more formal way we can see that we can create a inverted index in this way starting from these three different sentences we go over a process of go through a process of analysis in which for each sentence we extract the list of tags we remove the stop words that are the most common word used in the language and then once we have the list of all the words all the distinct words we can create a vocabulary like this where we assign to each word an index like an integer or a longer value just to avoid to use the entire word more and more and then using this you can create your inverted index so for instance if we consider the word best you have that in the first in the second sentence there is here and here in the third so zero is pointed to one and two the word blue appear here on the first sentence and on the second sentence so you get this so may be that there is a question in your head right now that is where is the knowledge in this index and structure there is no knowledge it's just a way for organizing the documents in a way in which you can easily access to them through a textual search engine it's to be fair with let's say with the search engine so you can do a little bit more obviously you can put in the in the middle between the extraction and the inverted index some kind of enrichment as we discussed before the developers teamwork at the overnight to create these kind of aggregators that will get our data for multiple data sources can have the different kind of context this information can extract even sentiment but at the end they end up in let's say in inverted index so the solution is quite easy to implement even to maintain and to deploy because it is based on a well-established tool like elasticsearch for instance that allow also you to spread the load across a huge set of machines if you want so at the end what you can deliver is a very fast search engine but this is not enough because at the end just tuning results is a very hard task and at the end you cannot you what we get is that every single document is related there is no way for navigating from one document to the other one and even just extending what you did at the first site is a very complicated because just adding a new synonym in a list means that you have to go over array index process for getting what just a textual search and again even with these extensions at the end a question arises again where is the knowledge you can add a small amount of knowledge but this is not enough so let's see what you can do with a complete different approach let's see with a graph approach supposing that you have a text like this this is a document it is a an article that I took from the New York Times some times ago so let's go over another kind of process in this case we are we would like to process this this article using a natural language processing tool so in this case what we can get back is something different than before because if we train the natural language processing tool we can recognize in a text that home pod is a device and the same is for eco you can recognize companies and look this is not a simple task because for instance if you consider the Apple example Apple is a fluid but it is also a company so when we are talking about extracting knowledge from the phone a text means also that we need to apply some kind of word immigration to extract from the context if we are talking about a poll like a fruit or a Apple like a company furthermore we can access to other suits or knowledge and extract information like this so that the this device the home pod is produced by Apple so we are talking about a different kind of approach to the textual processing because instead of living in just a list of tags here we are relating as some concepts to the to the world so we know that home pod is a device that Apple is a company that there are connections between these device and these companies and we can continue we can infer the list of peoples that are this I mean that are in some way involved into these articles and again using the wiki data for instance we can find that LM mask is the founder or Tesla and the founder of Martok's we can do further we can recognize money we can recognize a part of the text like it the two points to on pot we can recognize the theory that again using the consummate five allow us to know that it is a software we can extract the time we can extract the dates we can even again extract sentiments and we can for instance in this case extract the sentiment for this sentence and through this path knowing that we are talking about the on pot we can relate some metadata to this document so we can add information about when we read it where we were and on which device so already from here you can notice that too instead of using a classical base analytic approach we can go over this natural language processing approach in which we can extract a lot of the information from from the text but the problem at this point appears because we need a platform let's say a storage model that allow us to store is information in the right way so that we can access to them and we cannot use let's say an inverted index so what we can do is to use a graph and as you can see it isn't the right way because we can assign labels labels to the three elements and it's quite easy to represent them in the form of a graph obviously this is a simplified version you can do quite more but again this is not enough because what you can do is that if you go over the same process for all the documents that you have what you can have back is something like this you are creating a knowledge graph you are creating a you are really creating a data structure that allow you to extract more insight from your text because for instance the two documents that are called appear like unrelated a because one is talking about Allah masks and the other one is talking about Tesla or a very specific model of Tesla they could appear as isolated and they will in you know in elasticsearch for instance but here using the complex natural language processing tool you can store them in the formula graph you can find it here we are talking about Elon Musk you know masca is the founder of Tesla it is one of the topic in this article so these two articles are connected in some way so what you get back is a kind of graph that allow you really to store and manage the de knowledge that you have from the set of documents that you have because currently with this approach the documents are not considered isolated anymore they are connected in a way or the other and this gives you the multiple flexible and unpredictable access patterns because in a graph every single node every single relationship is an access point and once you go over this access point you can navigate a part of the graph or the entire graph following relationships and following the the different nodes so at the end what you get is a knowledge graph that can enable different kind of artificial intelligence tools so you can apply a different kind of machine learning algorithms and enrich the knowledge that you have because you can extract more insight from the from the knowledge graph that you built just analyzing the text obviously there are some drawbacks let's say the first one is related to the fact that you cannot get the same performance in terms of textual search but we will see later we can integrate this approach with the elastic search for instance and get the best the best from both you cannot charge this is true but to be honest there is no reason to share the graph we would like to access as fast as possible to this graph but you can replicate it so you can anyway deliver some kind of performance improvement replicating the same graph across a cluster of servers furthermore it is very difficult to implement and we will see how we will solve this issue but before that let's focus a little bit on the on the role of the knowledge graph in these in this goal of gathering data and create and extract knowledge let's say that the knowledge graph is the only way to manage the wall of enterprise data in a full generality first of all because knowledge graph is able to describe a real world entities and their interrelationship in the form of a graph obviously we can relate some kind any kind of classes to these entities to this relationship as we saw before we can have a device we can have companies we can have the people and for the entities and we can assign different kind or relationship like the founder product by is related to and so on so forth and the knowledge graph by itself is completely topic and Gnostic or domain and gnosis so you can use it for any kind of obscure that that you have and there currently all the big companies like Google NASA eBay Facebook Yahoo and Microsoft are already using a knowledge graph for delivering a different kind services like semantic search like I don't know smart services today user or just to deliver data to their user so currently the use of a knowledge graph is not more anymore the exception it is their rule it is the normal and supposing that now I convinced you did I what should you do to get started and as I told at some point this is not that simple because it requires a lot of tools it requires a lot of skills related to natural language processing related to managing graph in the right way so they find the right model this is why we came out with let's say the graph aware knowledge platform that is specifically designed to convert unstructured a structured data silos in knowledge graph so we created a kind of knowledge architecture where we have multiple data sources that could be data silos as well as any kind of data sources as I told you before and then you can organize them in the form of a knowledge graph that is stored on neo4j and then on them you can apply different machine learning tools even recommendation for instance and deliver different kind of user experience different kind of user access to this to this platform so for instance if you come to our boot you can see how we integrated it with Amazon Alexa so to deliver some kind of chat bot mechanism it allow you to navigate or query your knowledge graph using your voice we also create an a sort of assisted search that is based on a mix between text word search and graph navigation or you can just use the the knowledge API that we built on top of the knowledge graph to deliver any kind of service to your to your end user so this kind of platform as I said before has been explicitly designed to managing takes data but obviously once you manage the data and you store them in the form of a graph you can enrich it in the way which you want you can add the new information you can even apply any kind of machine learning tool on top of it so what the platform offers is a some way for importing your data wherever they are and reach them and then provide a set of analytics tools that allow you to easily and most Lina and supervise the way extract knowledge extract information from the Sato data that you have so let's see how it works in a very simple way so supposing that you have a lot of data sources they are converted in a form of a graph as we saw at the beginning using the natural language processing tools so we have Torrens ation named entity recognition and we can for instance train our naming entity recognition to identify things that otherwise cannot be recognized the token or our normalize the end zones of office so once you have this first graph you can go through a process of enrichment in which you can use external source or knowledge that could be consonant 5 that it could be IBM Watson or for image recognition for instance that could be microsoft concept could be your specific domain knowledge and so you see that you have a bigger graph then again you can apply on top of these other machine learning tools like keyboard extraction like Lda or else say that are mechanisms that allow you to cluster eyes your data set or using a different kind of approaches and assigned to each cluster a set of words for instance that allows you to identify the cluster you can apply similarities you can compute the war to back and so on so forth so at the end of the process you have a very huge graph well organized with a lot of indexes based on the keywords based on clustering based on whichever algorithm you have that can be navigated using similarities for instance and you use these kind of knowledge in multiple ways because you can extract a simple bag of words that could be the input for another set of machine learning algorithms that are following in the pipe or you can export multiple views and stored them in elastic search and deliver a relevant search to your user or you can just provide a different kind of visualization on top of these knowledge data set for communicating in read or just for allowing your customers to access to the same set of data in a different and complete new new way and in this scenario let me see that neo J is playing a very important role a key role because it stores the entire knowledge graph litter represents the the single trust the source of truth on which we are building our platform and in this way it delivers as multiple let's say services like a fast access patterns through the decipher query for instance and this allow us allow us to easy merging data from multiple data sources or enrich the data with external sources and since at some point we have to go live it offers us also scalability capability in terms of the replication that allows us to scale the let's say the access through an entire clusters cluster of machines so at the end we created this kind of architecture in which we can have a multiple neo4j where we installed we install our plugins the good part of them are open source there is only the NLP enterprise that is not open source yet let allow you to let's say enjoy the cluster because allowed to spread the load of the computation across the entire clusters and we offers a lot of tool for integrating at this infrastructure with external tools I already about elasticsearch for instance for indexing and searching but also we provide the interfaces for spark for tensorflow and we are designing a platform that allow you to integrate multiple kind of distributed platform in the case in which you would like to use your own architectural I'm thinking about I don't know Amazon lambda or or whatever else so in order to wrap up some conclusion we we saw how converting data in distributed and multiple and distributed data silos or data sources in actionable knowledge is a very complex task if you would like to have a solution not like a search engine but based on the knowledge graph but we saw what are the advantages of having this kind of approach and at the end the knowledge graph represent the best approach maybe the the only really useful approach for addressing this kind these kind of issues and in this direction the graph of our knowledge platform allow you to simplify there's this hard path of converting so such distributed data set in an actionable knowledge because it allows you to extract to avoid to take care of the details in terms of natural language processing in terms of exporting data in elasticsearch for instance or distributing the hardware or the heavy processor across a clusters of machine and it just hide all these these details giving you the opportunity to focus on on your business to focus on what what is the kind of knowledge that you would like to extract from the set of data that that you have that's all thanks [Applause] 