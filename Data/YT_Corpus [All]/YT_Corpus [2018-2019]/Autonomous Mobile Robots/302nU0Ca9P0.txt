 Rich Green who is one of my one of my personal friends and a guy I learn a lot from talk to you about AI, robots and all kinds of cool stuff that might be kind of fast moving but it's fun! So I'm going to hand it over to Rich. And he's going to educate us. All right. Thank you Walt. Thank you all for your patience sorry for the delay here. I've got a lot of interesting content to go through. I'm probably going to speak pretty quickly. And I'm happy to answer your questions afterward to continue the conversations. My name is Rich Green, I am a integrator in Palo Alto California which is a fascinating place to work and live. That's where the PC was invented and so many other things that we take for granted. I am a CEDIA volunteer I'm very proud of that. I've been volunteering since 1996. I'm an instructor and I encourage any of you who have not considered volunteering to get involved. We're going to talk about robots, robots have been around for a long time. Who knows where the word robot came from? Czechoslovakia, what was his name? Karel Capek, Karel Capek back in the 1920s wrote the first book and used the word robots. That concept of a robot impersonating a human being didn't come into our consciousness until around the 1920s and then it just took off. So this dream of having a fake human if you will has been around for quite some time now. Who remembers Rosie the robot from the Jetsons? It's amazing how prescient that series was that cartoon was because this is happening right now. Robots over the past 10 years or so have matured quickly. They started out as telepresence devices so now we've had industrial robots, arms that assemble cars and things like that. But the robot as we envision it interacting with human beings with personality started out as telepresence devices telepresence is like video conferencing so you put a videoconference machine onto something that's got wheels that can roll around and you've got mobile telepresence so there was this company called any bots used to see these running around in Palo Alto they would they would roll into a bakery and they would order a pastry and they'd have money in there. And then bend over and you take the money out and you know put the pastry in it off it would go. So these things were really fun to watch around and executives use them to stay in touch with their staff and so on. They're also used heavily in the medical industry so these are remote doctors, telepresence doctors, doctors can perform exams remotely. And to some extent they can actually do surgery remotely. So they have these cocoons. Now you can wrap around a soldier on a battlefield and the doctors have this ability to slice with a virtual scalpel they can slice right into the skin and they can actually feel the layers of skin the haptic response from those kinds of robots is actually quite good. So we have lots of different kinds of robots happening right now. This is another telepresence robot used in education. This is an interesting development because it's difficult to get highly qualified educators in front from enough kids. So if you can extend that educator out into telepresence robots you're in front of a lot more kids. I like that. Here's a robot making an omelet. There's a robot shopping. These are silly proofs of concept. They have robots that can pull a beer out of a refrigerator and bring it to you. Right. That's cool! We have autonomous beer coolers in Palo Alto right now. I think there are some in London who told me that. But it's a it's a box about this big. It looks like a beer cooler it's got six wheels and headlights and eyeballs and a little antenna and it just rolls around the sidewalks of Palo Alto right now to deliver you something up to 25 pounds and you open up the little lid and take out your beer. Robots are devices that have sensors and actuators in the fundamental sense. That's what they are. So there devices that sense the environment around them and then respond in some way. Now that could be a direct response from some human that's got their hand on a joystick or it could be an autonomous type of response. So the rolling beer cooler is an autonomous robot, there not exactly autonomous right now because there's somebody who walks around right behind it to make sure it doesn't roll into traffic. A few years ago Intel introduced the concept of perceptual computing robots need to know who they are, where they are, and what they're supposed to do. So we needed a way to help robots understand the context of their situation. So we give them eyeballs. We give them ears we give them radar we give them LIDAR we give them these various sensors like you would with an autonomous car that would help them get an understanding of who they are and where they are. This guy, this is somebody to watch Johnny Chung Lee he came from Carnegie Mellon University CMU and he was acquired by Google and he is the guy behind Google's Project Tango which is a perceptual computing play and with Project Tango you put stereo cameras on a mobile device and you just kind of sweep it around the room and it'll start to map the room and get a sense of 3-D what the objects are. Chair, chair, person, person, door, windows, desk. And it creates a sense of where it is so that it can now the robot can now move around within the space and know where the objects are. Now perceptual computing is quite real. This is a robo cop at Stanford Shopping Center in Palo Alto. I am not kidding. These things roll around they're communicating with security guards that are in office somewhere. The thing will scan 300 license plates per minute. It'll watch for kids spraying graffiti and you know a little arm will come out and send a 60000 volt charge and immobilize you, no it doesn't do that. But the security people will come out right away based on what this robot. So this robot has a map of the shopping center and so it knows not to run into a flower pot and things like that. It's loaded with Perceptual Computing. Sometimes it makes a little mistake. And but you know there is somewhat waterproof! You know about the vacuum cleaners right. The Roomba. Ok the Roomba is a robot and it's got sensors and it's got actuators so it follows that definition. The company behind Roomba iRobot has been doing this on a military scale for a long long time. The military is very interested in robots because they need to get into the field of action into a battlefield without hurting people. So they'll send a robot in on a suicide mission before the troops come in. So these things are becoming more and more advanced in their ability to crawl upstairs crawl through muddy tunnels jump up onto a rooftop and deliver ordnance and cause all kinds of trouble. More on that in a few minutes. This is a modern day robot who knows what this one is? Have you seen this guy? It's Baxter. Ok. First time I ever saw Baxter was in Sydney Australia. It at the technology museum there it's down in the basement. Baxter is a assembly line robot. But what's interesting about Baxter is it learns from humans so there's a there's an evolution occurring where robots merge with people and there's discussion in the artificial intelligence circles about centors which is a cyborg a centor is part animal part machine. So people are starting to turn into robots robots are starting to turn into people. It's an interesting evolution with with Baxter it'll sit there stupid and then you as a human can grab Baxter arms and Baxter clamps and hands and move Baxter to do the things that you want it to do and it will exactly reproduce what you just did. So it learns directly from human input and it's got the sensitivity to reproduce the motion of your arm and hands. So assembly line workers will simply grab the Baxter arm do this and then Baxter will do this three million times perfectly. Will Baxter replace that assembly line worker. Absolutely. Now here's Baxter again. Under brain control this is another development a little bit outside of robotics but it's generally called BCI which is brain control interfaces and what you do is you put some sensors on your scalp they can sense your EEG's and translate brainwaves into actions we're getting to a point where you can start to dictate text simply by thinking you can already turn lights on and off move windows shades and so on. So what this person is doing with a very high resolution brain control skullcap is she is directing Baxter to pick objects up out of this bucket and drop them into this bucket. She's not moving. She's not talking she's just sitting there thinking and Baxter picks up her brainwaves and does the job. We've entered the age of social robots. A lot of this research happened at MIT. And what they learned is that the robot human interface is hard. It's a challenge. People don't respond to robots unless the robot responds back with some sense of emotion. So social robots are expressing emotion. That's why they're putting eyeballs, eyebrows, cheeks, lips. They want robots to smile. They want robots to look at you. So where the eyes are in a robot they're actually putting the cameras and the cameras are trained to identify faces and eyeballs. So this social robot will scan the room it'll find somebody lock eyes and then just stare at you and watch you as you're walking around the room. It's very creepy. Right. And it looks social. It's like OK they're paying attention to me this feels good. And then they'll crack a little smile you know. So there's a lot of research going into AE, artificial emotion. It's a lot like artificial intelligence but it's at a deeper level. They're trying to understand what is the emotional condition of the person who is interacting with the robot right now so that the AI in the robot can relate to that person's condition with artificial emotion. A lot of technology new technology is based on what's called consumer engagement. This is not a nice term consumer engagement means forced pinpoint advertising. I want to persuade you to buy things. That's what consumer engagement is. That's what Web sites are built to do. That's what's so much new technology. Facebook is built to do. Google is built to do Amazon. They're all doing consumer engagement who knows what this picture is? Psycho right! Yep consumer engagement. Here's an example of consumer engagement that scares the hell out of me. This is Kuri. It comes from Masefield robotics which is a division of Bosh. It's it's a little thing about this big it's cute as can be. It's got eyes cameras built into the eyes and it'll roll around and it talks to kids, it smiles. It's got a little display there that'll crack a smile. What scares me about this is that these things are designed to be down at kid height and they're designed to persuade children's behavior? Now there's another development in artificial intelligence which is speech assistance. Digital assistants like Siri or Amazon Alexa the research now these are products that you can buy. You can train a voice into a digital assistant so that it speaks back in the voice that you prefer. This could be your mother's voice or your wife's voice. Now if you take that technology and put it into Kuri, so Kuri is now speaking to this child in the child's mothers voice. You're in a very dangerous situation. And this is exactly what's happening. Ok. These are social robots that are designed to persuade people. This may be the most terrifying development in consumer electronics. This is a robot called Jibo. Jibo has been in prototype stage for about three years that also comes from MIT robotics laboratory. It is an emotional and social robot. It doesn't move it's something you just plunked down on a table top. It's about this big and it's got these joints so the head moves around and the waste moves around and the thing makes these really cute moves. It has stereo eyes you can see them up there. It has stereo microphones for its ears and it has a display and it's got its a digital assistant but it's got a lot of artificial intelligence and artificial emotion baked into it. You can do a lot of things with Jibo just like you would with Amazon Alexa. Hey Jibo, what's in the news today? Let's do a photo shoot. Hey Gebo can you set a timer? They all do timers. Hey Jibo, What's the weather today. Jibo is looking at you. It's building through artificial intelligence the context of who you are and the details of your life. So I can be walking to my front door and Jibo will wake up turn its head around look at me and say Hey Rich. It's raining today. Take your umbrella. Now what just happened. It knows the weather. It knows my patterns it knows that I'm heading out to work and it can see that I'm not holding an umbrella. These are very invasive devices. They're understanding what's going on in the house. They understand the behaviors of people who live in that house. And who knows who they're reporting back to. So you can buy Jibo 899 dollars and if you buy this week 250 dollar coupon if you're interested in robotics in the future of social robotics and artificial emotion and so on this would be a very interesting experiment for you to get into and just start to figure out what these things are all about. This is a very powerful little device. Have you heard of Boston Dynamics? Oh my God! This is State of the art in robotics. These are very powerful machines that they're like Superman. They can leap tall buildings in a single bound. They're very fast. They're wicked fast, they're faster than people. They're agile they're extremely strong. They're loaded with artificial intelligence they have sensors all over the place. They're autonomous driving type devices. Now here's a little one called the SandFlea and it's probably about this big and rolls around, military and fire and police are all over this. This video shows it'll roll up to this building look up and go, boing! And it throws itself up into the air lands on the roof writes itself and then takes off on its mission. That is a cool robot great military applications. The SandFlea this is an amazing company. Here's here's the Rex and it's got these these legs that flip around and propel itself forward. And it'll go through muck it'll go through tunnels full of mud and water. You can submerge it and if it flips over the little arms reverse and just keep going anyway so it'll go upside down right side up. Pretty versatile robot! Big dog. So this is a robot that, does this remind you of something from Star Wars? So it's almost become a cliche now if you want to be considered serious in the robot space. You got to be able to walk down a snowy slope. That's the new test. So if your robot can make it down the slippery icy snowy slope. You're in the game and Boston Dynamics does that. They do that with the big dog. It really does look like Star Wars. This is one called Handle and it's a robot that can pick up boxes stand up on its hind legs and just roll along and deliver the box. This thing is extremely agile. It will run along the floor here. Get down on its haunches jump up land on here scoot along here jump back down onto the floor. So this thing will run an obstacle course. And they're fully balanced. This guy is called Atlas. So now they've taken it up to a human form, human scale. Atlas can walk up to a door open the door knob, pull the door walk through the door. Atlas can walk up and down stairs. Atlas can walk down a snowy slope. So this is a fully functional robot in the sense that Karel Capek had in the 1920s. This is it. This is another form of a robot. So this is more advanced than Roomba. This is made by Dyson It's called the Dyson 360I and it's a vacuum cleaner but it uses perceptual computing to figure out what the room is before it starts vacuuming as opposed to the Roomba that'll just go along until it bumps into something and then it'll back off. And you know it's kind of stupid. The 360I has sensors, lasers and it'll map the room it'll say ah coffee table, chair, sofa, wastebasket, and it maps the room and then goes off and does its little vacuuming job. So you can see what it's doing here. So it just beams out and maps the room. Now here's my little fantasy what if we take our friend Jibo our little artificial emotion persuasive device and give Jibo some wheels. Ok. This is a hack. I would love to do put a Jibo on top of a Dyson 360 and have at it. I want to talk about David Hanson. David Hanson is way out front in human robotic research and artificial emotion. He's been in the news lately. This is a robot that I photographed when David was at a Singularity Summit in San Francisco a few years ago. And this robot I took these pictures so you can this is real. The robot is loaded with actuators and pretty soft interesting flexible skin pretty convincing lips the eyeballs once again have cameras they'll lock eyes with you. So it makes eye contact while speaking with you. And this woman was asked was interviewing the robot. And so I did the same thing you just asked questions. So where did you come from? Well I came from ancient Rome and that comes up with these really clever answers and you can have a conversation with it and while you're having the conversation it's making eye contact. It's creepy. It's fascinating and it's quite real. So he likes to use this term emotionally intelligent machines. Now he's he's been doing this kind of research for many many years. Here's another one of his projects The Geminoid DK. Can you tell which one is the robot and which one is the actor? It's pretty difficult. So a lot of people look at the robot and think it's an actor imitating a robot when in fact it's a robot imitating an actor. That's how good they're getting. So this thing has very precise lip and cheek actuators and eyeballs are basically recreating a human head here mechanically and then wrapping it with soft rubbery flesh. They did a lot of research on eyeballs. So that's the actor talking to the robot. I'm making up a new term AC, artificial curiosity. It's like artificial intelligence. But most AI's are stupid. They do what they're told and then they might start doing something that they think they should be doing with artificial curiosity what they're doing is they're putting a sense of inquisitiveness into the algorithm artificial curiosity has been around for quite some time. This of course is the robot on Mars called Curiosity. So it's an active area of research. And they're programming in inquisitiveness so you can see what's happening. The robots become emotional, social, they become more and more human like. They have artificial intelligence and machine learning in them but now they're putting in artificial curiosity and creativity into these things so that they can come up with novel ideas and start acting in an autonomous sense. Have you heard about Sophia? She was in the news pretty recently. That's a David Hanson project. Sofia wants a baby and says family is really important. Now somebody programmed her to say that. But the news is all over this. Pretending like Sophie has got a mind of her own. No she doesn't but she's got a lot of artificial intelligence behind her in the computer that drives her. So the point that they're making here is we're getting to this stage where these robots seem to have a legitimate personality. She has become a Russian citizen which is weird weird weird but she has become a legal Russian citizen and it's almost like people want this to happen. They want Sofia to succeed. I'm not sure why. Why is this happening? Why are we creating robots to replace people? When you think about artificial intelligence, it's designed to replace the human mind. I like to think of IA, flip the letters around intelligence augmentation and I get this from Doug Engelbart who started it in the 1950s at Stanford Research Institute SRI with trying to figure out how computers can enhance the human condition can amplify what what people already can do. He's the guy who invented the mouse. Ok. Thank you Doug Engelbart. So robots could conceivably replace people they are replacing people in industrial assembly and so on. And this is an interesting cover from the New Yorker magazine like the dogs here. And you know this poor guy has been replaced by robots who are running around doing social things? The notion here is that robots will replace people and it will impact employment. And we have to rethink what people are best at and then retrain people to be productive in new spaces. Let the robots take over assembly lines. They're much much better at that and safer. Here's our Terminator friend. I think this is it's not much of a stretch to go from Jibo to Terminator. It is a stretch. I'm thinking that if we don't get some ethical lockdown some ethical backbone to what is being developed in artificial intelligence autonomous vehicles robots we may lose control of the situation and humanity becomes something else? The top AI researchers from the top AI companies which are Facebook, Amazon, Google, right? They're leaving the company because they're disgusted by the consumer engagement of what they're doing. You know the advertising the micro targeted advertising model and they're starting their own research institutes their own foundations their own nonprofits to look at the ethical considerations behind what's happening here. I applaud these people. So the top AI guy from Facebook left Facebook to start research in ethics in AI ethics. So God bless them. I hope they succeed. We need these people to look out for us so that the robots the AI's the machines of the future blend with and enhance the human condition and don't replace the human condition. We have entered the post human era. This is a new era in human evolution, it's already started. So we are becoming cyborgs with retinal implants, cochlear implants, artificial organs, artificial limbs. It's not much of a stretch of the imagination to just keep replacing body parts until you become a centor you become this hybrid right. This cyborg. And at what point do you stop? That's the question in the post human era where does the transition occur where we're no longer human, we're something beyond human? Now there are people like Ray Kurzweil who is the head of research at Google who is working actively in this space who think that he's a singularity optimist he's thinking yes we will replace our bodies with machines and we will live forever. We will upload our consciousness into these machines and live forever. That's the new vision of heaven. Maybe it's the new vision of hell. But this is where the chief of research at Google is going. He has infinite resources and there's nobody who can stop him? Questions comments? Are they going to buy home theaters? Well no! Are they going to build home theaters? Yes. It's still a threat. Yeah I use the term singularity optimist. We have singularity pessimists and singularity optimists a singularity optimist Ray Kurzweil. He did not coined the term singularity. Victor Venga the science fiction writer coined the term singularity the singularity by the way by definition is the point in the human evolution at which nonbiological intelligence exceeds the capacity of biological intelligence aka human beings and then continues to improve upon itself without human intervention. We can't see past that point in terms of the history of of human beings. It's a singularity in the same sense that a black hole is a singularity in physics. It's where the laws of physics collapse. So the singularity in human evolution is where the rules of human evolution collapse and nonbiological intelligence takes over. Ray Kurzweil thinks that this will be a vast improvement over the wet gooey stuff in our heads right now. We are loaded with biases where loaded with imperfections. We don't get along very well. But you know what. I'm perfectly happy to be a human being. So he is taking drugs that are not legal in order to extend his life so that he can reach what he calls life extension escape velocity and in terms of life extension escape velocity he'll reach a point where medical science will extend his life infinitely and he thinks that will happen within the next 13 years. Okay he is now in his 70s. He's going to reach life extension escape velocity. He wants to live forever and he honestly believes that he can upload his entire self his consciousness his memories everything about him which is about 5 terabytes of data. The way he sees it into the network the cloud and live forever as a conscious entity out of body. So that's a singularity optimist a singularity pessimist is. This is the end of the human race. Ok you can't do this because the human mind the human emotional structure the scent the essence of who we are our souls are part of our body the soul is not a separate entity from the body it can't exist by itself. It's part of our muscles it's part of our molecules and if you try to separate them it doesn't work. So the singularity pessimists are saying that's B.S. Ray. You can't do that. The consciousness that you take for granted the soul that you feel is in the flesh of your body and if you take the flesh of your body away you take your soul away. So those are the two points of view both considered valid right now nobody knows the answer but boy when you got somebody with the intellectual capacity of a Ray Kurzweil pursuing this with multibillion dollar you know resources from Google. Well, he's going to make something happen if your interested in this read his book called How to Create a Mind it'll scare you because he breaks down the human mind into a highly logical structured hierarchical device and he honestly believes that we are getting so good now with artificial intelligence that the chip density is gone so dense that we're going to be able to pack enough computing power into an object about the size of a human brain where that object will become conscious. So there's a theory of consciousness where the density of information is what triggers the conscious response. There's nothing more dense in terms of intelligence than a human brain and the entire universe. So if you can start to pack the synoptic, neural morphic, connections of a human brain into an object that's about the size of a human brain. The conjecture is that it will wake up and become conscious. Why based on density? Because it's the propagation of information flow, it's the speed of light. Ok. If it's spread out over a large space the intimacy of the communications goes down. It's a latency issue it's got to be a small object and it's very very dense and that's precisely what the human brain is. Yes, Once you get that density of information processing equivalent to a brain it will wake up and become conscious. And that's another definition of the singularity and the singularity is sometime around or after the year 2030. So it's it's 12 to 15 years away. It's within our lifetimes. It will happen. We don't know how this affects humanity. It will not be evenly distributed. People who have financial resources and access to the research labs are going to get added first and then they are going to become super people? They're going to become highly highly efficient creatures. And we don't know what's going to happen to them. They could become the Terminator, For real. Right. So it's a very scary proposition. We're going to live through this transition. This is the most exciting time in the history of the human species to be alive and to witness the transition. It's a gift. Thank you. 