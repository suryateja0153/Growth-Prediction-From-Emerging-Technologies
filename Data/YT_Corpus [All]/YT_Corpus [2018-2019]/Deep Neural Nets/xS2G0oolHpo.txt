 Rana El Kaliouby: When you or I look at this creature we know it’s a dog. But when a computer sees him, all it sees is this… How do I get a computer to recognize that this photo, or this one, or that one, is a photo of a dog? Oren Etzioni: It turns out that the only reliable way to solve this problem is to give the computer lots of examples and have it figure out on its own, the average, the numbers, that really represent a dog. El Kaliouby: Here’s where deep learning comes in. As you might recall, it’s a program based on the way your brain works, and it looks something like this… Here we have layers of sensors, or “nodes,” each feeds information in one direction from input to output. The input layer is kind of like your retina, the part of your eye that senses light and color. In the case of this photo of Buddy, it senses dark over there, light over here. This information gets fed to the next layer—which can recognize basic features like edges. That then goes to the next layer, which recognizes more complex features like shapes. Finally, based on all of this, the output layer labels the image as either “dog” or “not dog.” But here’s the kicker—and this is what’s revolutionary about deep learning and neural networks. At first the computer has no idea what it’s looking at. It just responds randomly. But each it gets a wrong answer… Geoff Hinton: Information flows backwards through the network saying, "You got the answer wrong,” so anybody who was supporting that answer, your connection strength should get a bit weaker. El Kaliouby: And anybody who was supporting the right answer? Their connections get stronger. Back and forth, it does this over and over again until thousands of images later the computer teaches itself the features that define “dogginess.” 