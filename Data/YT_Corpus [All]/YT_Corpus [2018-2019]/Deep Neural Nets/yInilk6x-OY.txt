 [Music] so let's go on to the next module which is attention mechanism so let us motivate not the task of attention there is motivate attention mechanisms with the help of machine translation ok so what is happening in the models that we have seen so far the current model that we saw for machine translation by the way all the models that I have shown you so far are wrong or rather incomplete we will complete all of them and that's where attention fits in ok that was for the camera the encoder reads the sentence and it computes the encoding once rate we read the entire sentence and we encoded it and then we had these two options either the passed the encoding at the zero time step or pass this encoding at every time step is this how humans translate a sentence what's the human analogy for this you have read the sentence once done and now you're going to remember this entire thing throughout and then translate imagine if you are doing this for sentences which have 25 words which is a typical Wikipedia sentence what's wrong with this you have read the input once and you have encoded it what's likely to happen you will forget some things you are going to lose information not just that is the entire sentence important at every time step only certain words are important you see there is conceptually something wrong that we are doing here it is saying okay I'll encode the sentence and then start decoding from there okay that's the conceptual error that we are making so let's see how humans actually try translate right so when producing one word in the output suppose my input is the Hindi sentence and I have the output sentence when I'm trying to produce the first word I actually compute this probability distribution which tells me which of the input words that I need to focus on at this point it's okay if I don't know what's the translation for GERD or jaw or raha or whom as long as I know the translation for Mei I am done because that's the word which I first need to produce there right so I'm going to say that at this point I only need to pay attention to the first word in the input and I can ignore everything else what about the second time step I just need to focus on the last word what about the third time step is it always going to be that I only need to focus on one word at a time no what about the third time step I'm sorry I'm assuming everyone understands Hindi but I think that this is a small sentence I can assume that what will you focus on JA Henry he right so you want to focus on both these things and not on anything else and what about the next one oh right so just on God and not on anything else is this what the model encoder/decoder model is doing what is it doing actually at every time step it's focusing on the entire sentence because that's the encoding that you are feeding to every time step that's the problem that we need to correct we need to learn to pay attention to certain important parts of the sentence there is a setup clear to all of you is a motivation fine not your motivation layers is the motivation for this fine or not okay the distribution actually tells us how much attention to pay to each input word at each time step and at ideally at each time said we should face pay attention to only certain words in the input okay so let us revisit the decoder that we have seen so far this is what the decoder looks like in fact I also have the encoder there now suppose oh sorry so currently what we are doing is we are either feeding s0 at the I mean we are either feeding the input embedding or the encoder emitting at time step 0 or at every time step now suppose there was an oracle which told us exactly which are the words important at time step T all right so in our example at time step 3 suppose it told us that the word going is important actually we need to flip the input an output here also but you can still understand it so I am saying a time step 3 certain words are important and suppose an oracle actually told us that these are the words which are important what would you do assume that you have already run the encoder what will you do now and say someone told you that only this word is important but why waited I'm just saying binary waits right only this word is important what would you do ideally just feed this blue vector to the decoder and don't feed everything else does that make sense suppose I told you that two words were important send those two words but how concatenate but now at certain times its four words will be important then you can't concatenate forwards because then the dimensions will change so what do you do I waited waited some of the important inputs does that make sense at times that three we saw that Java was point five important and rahi was point five important let's take a weighted combination of those two blue vectors and feed that to the decoder so you are not changing the dimensions at each stanza because the blue vectors have the same dimension I am just taking a weighted combination of those are going to give you the same damage does that make sense okay so in effect what I am saying is that I could just take a weighted combination of all the blue vectors that I have at the encoder and the weights of this weighted combination right now I am assuming that some Oracle has given me red okay if I had these weights does this makes more sense than having the Vanille encoder decoder model avian agrees with that okay now the question of course is who is going to give us these weights we'll come back to that later but at least given the weights this makes sense so at every time step we are just going to focus on the words which are actually important just take a weighted combination of those words and we will just feed that to the decoder and intuitively this should work better because unlike before where we were overloading the decoder with the entire sentence remember 25 words 30 words entire sentence was being passed to the decoder now we are just overloading it with the amount of information that it actually needs to produce that particular word hence intuitively this should work better right okay now how do we convert this intuition into a model in practice of course there is no angel who is going to come and give us these weights there's no Oracle the machine will have to learn this from the data whenever you need to learn something you need to introduce parameters so I am going to now introduce a parametric form for the from the figure which thing for those of you can't see these are alpha one alpha 2 and so on so now from the figure we are going to introduce a parametric form for for the alphas ok ok so I'm going to introduce I will I will come to alpha but I am what do you think this weight should depend on what I'm trying to say is that at the PIAT time step of the decoder so this is e JT at the th time step of the decoder I want to find out how important is the G it would in the input that's exactly what I'm interested in at every time step of the decoder of all the input words I want to see which of them is the most important right so this is the quantity that I'm interested in is how important is the G at input word at the th time step this should depend on what what should it be a function of for 1 it should depend on what that word is wait the other it should depend on what has happened in the decoder so far what does the decoder produce so what is the input and what is the decoder state at so far right so if the decoder has already decoded the word car or home it does not need to look back at home like that's why I need to know what's the state of the decoder what captures the state of the decoder at time step T st and what is the state of all the words that we have it's captured its captured by what the edge J said this is h1 h2 h3 h4 does that make sense how many of you find at this point please raise your hands high above okay how many of you have questions please are specific questions if you have a question all I'm saying is a couple of things one is at every time step instead of the Oracle giving me these weights I want to learn these weights whenever I want to learn something I have to introduce a parametric form and then I learn those parameters okay now what M is what is the quantity that I'm interested in I'm interested in this for all the input words for the ghiyath input word I am interested in knowing how important it is for the T at time step there are several ways I could write this function I am saying that the two things that are important is one what is this J at word which is captured by HJ right and what is the state of the decoder up to this time step which is captured by HT minus one you could think of various other equations at this point I am fine if you buy the intuition that this quantity should indeed depend on these two terms it should depend on what has happened in the decoder so far and what is my current word actually look like how many of you are fine with that please raise your hands up in high okay now also the other thing that I will want is that across all the input words this should actually sum to one right I just want a weighted combination I don't want arbitrary weights it's just like taking a probability distribution over what which word is important by how much so if I have this ejt how will I convert it to a probability distribution softmax right so I'll just compute the alpha J's as the softmax of Egypt ejs is that fine vivianne gets this okay now we have still not seen what the exact form of attention is of the F attention function is so this is what the equation for the Alpha JT is that we had and alphas eight deed actually denotes the probability of focusing on the g8 word at the th time step okay now we are now trying to learn these alphas instead of and Oracle telling us what these alphas are so learning is always going to involve some parameters so let's define a parametric form for alphas and just a couple of notations so from now on hey we didn't change this we are going to refer to the decoder state as st and the encoder state as Sh ng okay so these blue vectors are SS and these blue vectors are H's okay given these new notations one among many many possible choices for F attention is the following I wanted it to depend on the current decoder state I'm making a dependent on the current Dakota State but I'm also adding a parameter in front of it wait I also wanted to make it dependent on EDA I'm making it dependent on that I am also adding a parameter here why do I need this parameter what's the dimension of this let's assume this is also what's the dimension of this remember after multiplying with you attention and after multiplying with W attention the two vectors should be audible is that fine something cross D what about this same thing cause the okay good okay so let's call that same thing as d1 what's this output then the tan edge output is vector scalar matrix vector of size you said matrix or scalar okay it's okay RH 2 d1 what's the quantity on the left hand side vector scalar matrix vector even though it has two indices it's a vector what is this quantity capturing at time step T what is the importance of the g-eight input that's aw I'll keep asking till everyone replies that's a scalar okay now you have scalar is equal to something multiplied by r raised to d1 so why do you need this something so what's the dimension of that going to be R is to do so that's the dot price so you can see why we have these parameters okay so what we have done is made it dependent on s t1 and HJ and also made sure that the output is a scalar that's what these three parameters are doing okay and these parameters will be learned along with all the other parameters of the encoder and the decoder so now this is all fine you would actually someone and given me the true alpha J's and I had predicted these alpha J's through that fancy equation which I just showed you and then I added a dash function soft but that's the safest choice in this course I want to learn something so what do i what should I add loss function what would the loss function be say squared error loss and then I want to adjust the parameters to minimize the squared error loss then all of this makes a lot of sense because then you can imagine that your you attention W attention and V attention will get tuned in a way that the predicted weights are very close to the true which this we all understand given an objective function we understand that the weights will get adjusted so that you are there to the objective function but the whole premise was that we don't have the true alphas because in the case of translation no one is going to tell you that the kate word come came from the g8 word or the set of j words do you all agree with that so if we had that true alphas this makes a lot of sense because then we could have added a loss function which takes the loss of alpha true with respect to alpha prediction and then in addition to our loss theta which was the sum of the cross entropy errors and then we could have jointly minimize this and we could have hoped that the attention parameters would have been learned accordingly in practice will not have this in our translation example we would want someone to manually annotate for every word in the output which is the set of input words from this which it came this is not going to be possible this we cannot collect so much annotated data so what do we do why why why should this model then work there does not have any supervision why should this model work in the absence of such data how many of you get the meaning of the question how many if you see the problem please raise your hands we are not giving it to alphas and that's what our problem is then why should this work better this works better because this is a better - better - choice language model better - choice what is the possibility is there better modeling choice why okay give you the answer it's because this works better because it is a better modeling choice why so so I'll give an analogy and the reinforcement learning fans will cringe but they can just go out so suppose you're trying to learn a bicycle how to ride a bicycle okay that's why I said didn't I already see some of you Kenzi as if you guys have a copyright on bicycles okay so suppose you're trying to learn a bicycle okay and for some reason you in your infinite wisdom you decide that you can learn how to write it without holding the handle okay and you start trying to do it it's conceivable that in a few years or decades you will actually learn how to ride the bicycle right even if you are not holding the handle right people do that when people can write it before without that now the only thing that I do is I come and tell you the instead of doing this why not you try to hold the handle and then try to write the bicycle that is all I am telling you I am NOT giving you any other supervision I've just given you a better model I have said that instead of just trying to adjust the parameters with respect to your feet and the pedal and your back position why not you also introduce this additional parameters when you're holding the bicycle with your hands and now try to figure out what kind of weights you need to put on your left hand right hand and so on I am NOT giving you any supervision for that that you need to still discover on your own and you'll start riding it you might fall on one side you might fall on the other side but you will eventually figure out what these weights need to be right because the second model where you hold the handle is a better model than the first model where you are not holding that in the second model you have additional parameters where you could adjust these parameters so that you could learn to drive better that's a more natural way more close to human way of learning how to ride a bicycle the same thing is happening here the second model where you have a way of learning these attention on the weights even though I am NOT all I am telling you that look maybe if you decide at every time step which word to pay attention on you might be able to do better than feeding the information from the entire sentence at every time step that's all the information that I am giving you which is very similar to saying just hold the end that's not going to teach you how to ride a bicycle okay you still have to do the extra work of learning these parameters but now you are given a chance you're giving the model a chance to learn these parameters you are telling it that this is a better way of modeling it with this you should be able to learn better right so there is the hope of doing better because now the model is actually making a more informed choice right it's a more informed way of learning how to do translation by focusing on certain words at every time step and now these parameters how will they get adjusted they will get adjusted because at every at a given time step you produced a wrong output you did that maybe because this parameter was wrong which is the V parameter or maybe because these recurrent connections were wrong or maybe because your attention weights were not proper so now I tended just the attention weights and that should given sufficient day it should be able to learn which words to focus on just as humans learn how to do translation right even when we are doing learning how to translate or when we learn translating from one language to another we are not given this word by word supervision and we just do a lot of translations or read a lot of translations and somehow understand that while translating I need to focus on certain words and at every time step this is the word that I need to focus on so given enough words it should be able to learn that at least someone gets the job good yeah so that's the hope and in practice indeed these models work better as compared to one elion code you don't know where this statement comes from fine so now let us what we will do is so this entire thing hinged on hope only right that's all that's all I am saying but it does make sense right because you have these additional parameters which you can learn and you can back propagate to them I will just not stop there will actually prove what happens not prove but it demonstrate what happens in practice wait so with this attention model in mind let us look back at the encoder/decoder model that we had for machine translation integrate the attention mechanism with it and then let us see the end-to-end equations that we could okay so this is what the diagram looks like the input and output still remains the same you are just given the source sentence and the target sentence in particular you are not given which words to pay attention to every time step way that is not given so remember that my input is not changing it still the same source sentence and the target sentence okay what's the encoder now try to work out the equations I want you to write the equation for YT which is going to be some composite function of X where X is a vector it's x1 x2 x3 all the words in the input okay and somewhere along the line it is also going to have this attention equation it's it's going to take awhile but at least try to imagine it there are some hints in the diagram itself you could take a look at it I'm just asking you to convert the diagram to a set of equations say encoded part is fine I have computed the representation of each word at time step T so this is a contextual representation of the world because it's aware of what the neighboring words are right now what's the decoder going to be what is the first thing at time step one or at time step T in the decoder what is the first thing that I'm going to compute the - Waits the last time step of the decoder of the encoder sorry what's the first thing that you need to compute at time step T the attention waits speak up please what's the first thing that you need to compute at every time step what kind of a combination I take of the inputs or rather which are the words that I need to focus on from the input who tells us this the attention waits how will you compute the attention weights using this fancy equation that we had seen earlier okay is this enough I need to convert this to a probability distribution that's just to ensure that everything is a neat combination once I know the attention weights what do I need to feed the decoder a - combination of the inputs a weighted combination how do I take a weighted combination of the inputs summation I is equal to 1 to capital T alpha J T into HJ right T is the decoder time step J is the input word so at the T at time step of the decoder I am taking a weighted combination of all my inputs the index over the inputs is going from Z equal to 1 to T by the way did that answer your question that's what you are asking right ok is that fine ok now what next now I want to produce a word at the output what's the decoder going to be first thing that I'm going to do is decoder is a - horan n okay what's the input to the RN n at every time step the previous predicted word as well as the weighted combination input that you have given it does that make sense okay and then finally how do I get the probability distribution is that fine actually this should be a distribution LT does not make sense and these are max of this and what's the loss function cross entropy there's no change in the loss function right loss and the algorithm remains the same so you've seen these set of equations now how many feel confident of going back and modifying all the wrong encoder decoder models that we have covered in the initial part of lecture modifying them to add the attention equations in them how many if you can do that please raise your hands I am NOT going to ask you just do it so that I feel happy you can't do it right any questions at this point very good okay okay so you can go back and try adding attention mechanisms to all the models that we have seen before right see how will you compute so remember the only purpose of okay what kind of a network is the attention network it's a single feed-forward neural net okay this is just transforming a simple linear transformation of the inputs and then a non-linearity on top of that and then just again one more transformation right it's a simple feed-forward neural network only these three equations somehow need to be fitted in all the other models that we have seen so far right this is a very generic framework just as the encoder decoder framework was a very generic framework the encode attend decode framework is also very generic framework you can go back and model all the applications that we saw and you can change them change them to adhere to this okay and try to answer the same set of questions what's the data what's the encoder what's the decoder what's the loss what's the training function and in particular remember that and when you go back and revisit all the applications that you have done the data is not going to change no one is going to give us the supervision for the alphas that's one thing which is not going to change okay okay so here's one more thing so this probably tied to this question like how do we be sure that the alphas actually learned something meaningful now what do I mean by this if I have to convince you that alphas are actually learning something meaningful and let's take the context of much translation what do I need to show you suppose the model has generated an output for a given input sentence it has generated a translation what do I need to show you to convinced that it's learned some kind of weights at every time step what should I show you what do the attention weights look like right so let's see this is a common trick or not that trick actually is a probably a trick only but this is a common thing which is used in several papers and that's why I call it a trick because it's a trick to get a paper accepted that you actually show what the attention weights actually look like right so on the on the this is the input document and this is the summary that you want to generate okay and what you see here is that at different times if so look at the last time step terrorism it paid maximum attention to the word terrorism in the input wait so you can draw this matrix suppose you had capital L time steps in the output and capital T time steps in the input so you could draw this L cross T time step or T matrix which tells you what was the attention paid to every input word at every output time step we get that you see what this matrix is this heat map is essentially a matrix of size L cross T and every cell here tells you how much attention you paid to a particular word at that time step and the darker the cell that means more the attention that you paid Radian gets this okay so what this is saying is that probably see when you wanted to generate Russia the maximum attention was paid to Russian and maybe some other words also sometimes it does not work very well but sometimes it does right so for calls the maximum attention was paid to called and then similarly for front what the maximum attention was paid to front and so on so you see some meaningful patterns that it is learning here and here's another example for machine translation so so roughly to quickly understand what this figure is right so this is I think English to French is it French yeah it's French or French to English translation which is largely monotonic wait that means at the fourth English word you would end up paying attention to the 4th French word that means you're almost doing a word by word translation and that's exactly what you see that most of the attention is along the diagonals so it's learning some meaningful attention weights as always helpful if you are using if you're using an attention mechanism to plot this and see if it's actually learning any meaningful attentions or attention weights or not right so that's a common trick which people use [Music] you 