 You're not going to want to miss this next episode of the AI Show, where Jason shows us how to build really good conversational bots, using something called Project Conversation Learner. Make sure you tune in. Hello and welcome to this episode of the AI show. I've got a special guest, Jason Williams, to talk about something called Project Conversation Learner. How are you doing my friend?  Good. Thanks.  Tell us a little bit about conversation learner.  Sure. So let me describe what the problem setting is here. So, the problem setting is, we want to build a task-oriented bot, a task-oriented conversational system. So, this could be something that's in a smart device in your home, like a thermostat, it could be a skill in an intelligent assistant, it could be a bot that you interact with over, say, a messenger, messaging client. And there are a lot of challenges there that we seek to solve. The first one is that when you get started designing one of these, you start with examples of conversations, but that's sort of a throwaway artifact. There's no way of going directly from that to a working system. The second is that, as you log interactions of people using your system, you'd really like to be able to look at that and directly make improvements right from looking at those examples of interactions without having to reverse engineer changes to a flowchart into a rule system. And the third is that, we know all the benefits of putting machine learning at the center of driving a dialog system. The machine learning expertise is expensive and it's rare.  And so traditionally, what you do with these bots is, you have to get a lot of examples and then you create some crazy rules and maybe they work or maybe they don't.  Exactly.  And you said also, conversation also includes speech, is what you're saying as well, because you said there are certain devices that take a speech and convert it to text as well. This all sort of fits into that same issue, right?  Yeah. So, this particular tool is agnostic to how the input comes in. It could be speech that's then converted with the speech recognizer. Our input as text. So, whether it comes from speech or you're typing, either is fine for us.  Awesome. So, show us how this works.  Yes. Sure. So, what this is, is an AI first way of building a bot. So, at the center of it is a recurrent neural network. What that means is it takes the whole of the conversation history so far and directly predicts what the system should do next. This allows it to learn directly from example conversations. You give it example conversations, it learns the function that maps from a history to the next thing the system should do. This allows designers, business owners, domain experts to directly give you those example conversations and learn from them. There's no flowchart behind the scenes. It's machine learning model that's driving the process.  So, in this case, you're not creating templates and say usually they'll say, "Hi I want to work with blank" and then you tag that button. Now, you're just saying here's some real conversations that I've had and this is what.  Not quite. So, the set of actions the system can take, you still have control over that. So, those are templates or their API calls that you write. The distinction is that the control strategy that's deciding which of those to take next, that process is being driven by a machine learning process.  I see. That makes sense. Okay. Cool.  Yeah. So, I just want to point out, too, that this approach is situated in code. So, you can also give us business rules, you can express constraints over when actions are available or not. So, for example, if you are a banking system, you want to have a rule that says, "Only let people transfer funds after they're logged in.". That's not a machine learning relationship. You can code for that relationship, you can be sure that that will be respected. You can also have actions which instead of being communicative actions, like sending a message, those can be API calls. So, that lets your decision process also have actuators to go off and do stuff in the wall.  I see. So, it's not like this thing is going to run amok in your business and do whatever it thinks it's supposed to do.  Exactly.  What you can do is you get a sort of guard out with an API call that says, Hey I suggest this, and then the API call will go into some rules. The engine then says, Hey, no, this might be an underage person. We don't do that here, or this might be some other thing that doesn't fit our business rules. You can guard against that as well.  Exactly. Yeah. You can take your business rules for your setting. You can also express common sense. The overall philosophy is to code, would it make sense to code and to learn what it make sense to learn.  That's amazing. Cool. Alright. Can we see how this works?  Yes. Sure. So, let me just describe the overall workflow and then I'm going to give a couple different demos. So, when you get started with a machine learning process, you need data to train on. The issue here is that there is no data yet. So, we solve the cold start problem in the following way. The developer, and here is could be anyone on your project I'm just saying developer, starts playing the part of the user. So, they type in with the user might say and then they interactively make corrections to what the system should do. And this allows you to just go in and start giving examples of what the system should do. That gets you started after maybe 20 or 30 conversations. What you typically find is you've got a system that's working relatively well. You can then take that system and put it in front of end users, at first friendly users, and then the developer goes and makes corrections to example cut to the conversations that have happened with them. And this process gets you from nothing to something to good. So, it's a steady progression. It's the same machine learning model you're improving the whole time. So, do you want to see how it works?  Yeah. I do. I really do. I'm starting to get a feel for, like, this is something that you want. You want something to happen based upon what people say. You have nothing, you start with the developer saying things then you move it to the friendlies internal them and then you get a really good system after all.  Exactly. Yeah. Cool. So let me switch over and show you. So, this is a Conversation Learner and here I'm going to show, this is a simple example to get started. So, this is just showing the basics. I'm going to show a second demo just so I can little kind of show the richness. And here, these are all example conversations that I've entered so far for this bot. This is a bot that helps you to reset your password. So, let me show an example of one of these. This is what the user says, "I can't remember my password", and then this is the system response, "user system", "user system". So, this is what the the machine learner is learning from. It's these whole conversations. So, to make this concrete, when it's time to predict what the system should do here at this point, it's taking everything before it as input and predicting that's the action that it should take next.  So, is this a dialogue that you have as a developer between yourself initially?  Yes. Exactly.  Okay. Okay. That makes sense now.  Yeah and I'm going to show you an example of that now. So, let's say I want to add another one of this. And the process of creating another and inspecting what the system is doing is joined up. So, you're doing both those activities at the same time. So, I can start by saying, "I lost my password". There's a first step here. We'll come back to this in the second demo. Don't worry about that for now. And what we see come out are the network's predictions. So, it's saying, okay, the very first turn of the dialogue, the network thinks with 94.9% certainty that this is what it should do first. And this is the correct action. These are the other ones in here. So, I'll go ahead and say yeah, that's the right thing. That's what you should do. And okay, so "Is that for your local account or Microsoft account?". I'll say, "my local account please". And then the predictions from the network that come back will be here, "which version of windows do you have?" And that's right. That is what I want this system to do. Right. So, the assumption here is that I know what I want this system to do. Now let me say Windows XP. Let's say that someone has that. Now this was rare, like I wasn't necessarily expecting this so far. And what you'll see here is in this set of actions that are available, there's actually no solution for Windows XP. That's fine at any point. I can add another action so I can say, "Okay, how to reset password on Windows XP?" And that could be a link to rich content. There are a variety of different types of actions. I'll come back to that in a second.  This is almost like you're training, like, a brand new support agent. This is the script that you follow or if they say this then do that. It's pretty intuitive, what's going on.  Yeah, at any point you can add more actions. I can go back later to it and change the text of these actions and you'll see later on there's a lot of richness to what these actions can be. But right now I'm just trying to give you the basic idea. So, now there's a new action that's in there. It knows something about when to take that new action. It may not get it perfectly at first but that's where machine learning is going to come in.  Cool.  Okay. So, I can go and repeat this process and you were seeing from the scores, I can develop this intuitive sense of how well the model is working. So, those scores were all kind of in the mid to high 90's. That gives me some certainty that it knows what it's doing. So, now switch over and say, let's say I'm the end user. Right. So, now I'm going to play the part of just being the end user and use this. This is the web chat control. So, this could be embedded in your webpage and this is all built on top of the bot framework. So, this could be exposed via Skype messenger or another messaging client or as a skill and an assistant. Let's say someone comes along and says, "I can't remember my password" and let's see if I'm going to say it's for my Microsoft account. So far so good, and then let's say this user says thanks. So, this is not what the system should be doing. If you've ever built a bot this is going to happen, you're going to put this out there, people are going to say things that you hadn't expected, and you may need to add some new richness to your system that you hadn't expected. That is the world of interacting with natural language. So, now, that was the end user, I'll switch over now and as a developer, I can see that that log of that conversation is now here. I can open it, and I can look at this conversation and say, okay, let's see. This is correct. This is correct. This last one, the person said thanks. What should the system have done instead? I can go in here the scores look it was pretty uncertain. Okay, and none of these is correct. I want to add another action. I would like it to say, "You're welcome." So, I'll add that action that adds it to the the palette of actions, and then say that's what you should have done instead. It then drops me into a teaching dialogue, so I could continue this if I wanted to. If I wanted to explore maybe what could happen after that. But I won't do that here I'll say, Done. It removes it from the set of logs, adds it to the set of train dialogues. One thing I haven't said so far is, every time you make any kind of correction, it immediately kicks off a training job. There is a training queue in the background that's constantly retraining the network. Every time you get a prediction that's using the most recently available model, so the model is constantly up to date.  That's pretty cool. I can see infinite use for this right now, because, generally when you're doing a bot the way, what happens if something goes wrong and you're like "Oh, that looks weird. Let me go over there and tinker with things to see if I can get it to work here." This is the right thing. Little AI, you're going to be, and so, that's pretty cool. What does this look like when you use it, like I feel like is a really good way to train, but as a programmer I want to see more in-depth.  Absolutely great. So, let me talk about that. So, let me give you the whole control loop, and then you'll see your control points as a developer.  Cool.  So, a message comes in, and one thing I haven't exercised so far is Entity Extraction. It's actually a second machine learning model that I'm going to show in just a second. That lets you pick out entity. So, here for example Seattle that substring, that will be identified as a location entity, just a string. Then, here's your first opportunity to inject code. You can take the text of that. What's the weather in Seattle. You can also take that entity detection result, and go off and do whatever you want to you're in code now. So, you can for example resolve it and say Seattle is a place that I know how to get the weather forecast for. If someone said, what's the weather on Mars? I can work out that I cannot resolve that to a place I can get the weather for even though, the Entity Extraction might have picked that out because it's location. After that happens, then you pass control back to the neural network, and also in the Entity Detection Callback, you'll see that's the place where I can be controlling which actions are going to be screened out. You can see that in just a second. So, the neural network gives me that ranking that you saw before, and here it's choosing this forecast API call as its top choice. That will execute that API call, and also these actions don't have to immediately hand control back to the user. So, I can take multiple actions in a row. So, after this forecast action in red now, those scores are now new. That's its second turn, and it can say anything else and then execute that action. So, you have these two places for code, and after anti-action happens, and then as a part of API call execution. So, I have a demo that shows you that.  Let's do that, because I'm understanding you're saying that things are coming in, but you're getting a lot of information as a developer, that you can do actions off, but all you see with it looks like it could.  Awesome. So, let me switch back and show you here. So, this is a different setting. This is going to be about ordering pizza.  Cool. How about that.  So, here I have three entities. The first one Toppings is going to recognize pizza toppings, and that's what the user says. The second two are not things that the user will say, but there are things that the system may want to output. So, these Entity values can be used both for capturing things from user input and also parameterizing actions for output.  I see.  I'll show you that here. Here are the actions for this system, so this will look straight forward. What would you like on your pizza? Actions can also refer to entities. So, you have $Toppings on your pizza. Actions can also be constrained by the presence or absence of entities, and that's the connection with business logic. So, here this you have $Toppings on your pizza, you can see this column required entities that's saying toppings has to be defined in order to take this action, and that makes sense because, it would be impossible to take that without. But you could add additional constraints there.  Cool.  There's also the opposite of that. If toppings is defined, then this action, "What would you like on your pizza," is not available. In other way this is a common sense constraint. I want to prevent the system from asking something it already knows the answer to. And finally, actions can also be API calls. So, those I've implemented in code, they're running locally on my machine in the bot.  I see. So, there's a combination of different endpoints that you could be reaching. Some of it forms part of the AI that's in there, some forms part of your business rules and processes?  Exactly. Yeah. One final note about actions, they can either be Wait actions, which means perform the action and then stop, let the user do something, or they can be Non-Wait, which means just take another action after. So, that lets me develop sequences like, "Hold on a second while I looked that up." Call some long running API, and then say "Okay here's what I found.".  That's amazing.  So, let's switch over and show what this looks like as I step through.  Cool.  So, there's in the pizza ordering domain. So, let's say, "Order a pizza with mushrooms and cheese." So, first thing that will happen is that Entity Extraction step. There are about seven or eight train dialogues in here so far. So, it's seen a couple of examples and that Entity Extraction model which uses LUIS on the back end. That's predicting that mushrooms and cheese are toppings. So, that's where that came from. That was the Entity Extraction step. If these were not right I could fix them. So, I could click on here and I could "Hey that's a topping or not," and they can span multiple words on this. So, go ahead, and score that and what you'll see is that mushrooms and cheese that now shows up as being the value for toppings. So, it's accumulating these values, and it wants to take the action "You have toppings on your pizza." That's right. So, go ahead and do that. That's a Non-Wait action. So, then now I get to choose the next action. "Would you like anything else?" It's predicting that with very high confidence, that's what I want it to do. There's some richness to entities here. I can say, "Remove mushrooms and add peppers." Here this mushrooms is labeled as Minus-Toppings, and peppers as Plus-Toppings. So, I can add and remove things from this list, and that gets reflected in the toppings entity that gets persisted. So, peppers is in bold to show you that it's arrived, that it's new. Mushrooms is now in strike through. You have $Toppings on your pizza, that looks good. "Would you like anything else?" Looks good. So, now give an example of where that Entity Extraction Callback is going to be useful. So, if I say "Add yam." Yam is our example with something that this pizza store does not have.  Right.  Here that gets labeled as topping which is right. Now, when I say score actions, you're going to see that's going to show up as being added to this out-of-stock entity. So, what just happened there was. Remember from my diagram after the model runs, then there's this code that runs. So, here this is the code for this bots running on on my machine. This is that Entity Extraction callback, and what happens there is, I grab the set of toppings that have been recognized, I step through them, and for each one if it's not in stock, then I move it from toppings to out-of-stock, and my in-stock function here is just stubbed out for the demo, it's checking to see if it's one of these toppings.  This is really typescript.  It is in typescript. Yeah.  This is amazing. Like because the challenge I've always had with these things is like, okay, they're not very smart. When something goes out of the ordinary, I need to do something. And what's cool here is that it's actually identifying when something is out of the ordinary, or at least giving you the possibility to detect out of the ordinariness, and if you can call that, and then you can react the way that you need to. Which is really cool.  Yeah. That's a good summary. So, here one thing to point out is now because this out-of-stock entity is defined, that is governing which actions are available. So, now there's a different set of actions that are available. So, one thing about these constraints, it's interesting is, they're both letting you express business rules that are important for your system. Also by expressing common sense, you're limiting the set of actions that are available that's reducing the complexity of the machine learning problem. So, that reduces the amount of data you have to put in. So, you have these multiple control levers, you can learn what it makes sense to learn, and you can code would it make sense to code. So, here let me bring this to a close here pretty soon. So, we don't have Yam, would you like anything else? Now, if I say no. So, one thing to point out here is, I'm not labeling the intent "No." You might think of an intermediary label, instead I'm just directly choosing which action the system should take next, and what I wanted to take next is this finalized order. This is an API call, and that returns this "Your order is on its way." That API call is also again a part of my bot here. This is I have access to the entities that have been defined. I'm in code here, so I can do whatever I want to. In a real system, this is the point where you would make that API call to actually send the pizza to someone's address. Here it just returns the string.  This is pretty amazing.  Cool.  I like it a lot. There's tons of use cases for this, I'm pretty excited about this. Working people go to find out more if they want to start.  Yeah. So, this is going to be launched as a Labs Cognitive Service at Build, and you can go to this page labs.cognitive.microsoft.com, and when this is available, you'll see an entry there for conversation later.  Awesome. Well, this has been impressive. Thanks so much Jason for spending some time with us. Thanks so much for watching. We're learning all about Project Conversation Learner, how to supercharge your bots to get your work done. Thanks so much for watching. We'll see you. 