 okay let's get started it is so good to see everyone here I know this has been a long three day journey and it is great to be here this is my first build anybody else to have their first build out here alright I'm in good company so you know it's as an AI person it's been an unbelievable experience for me you know we have learned about the incredible power of the azure cloud you know we've learned about amazing breakthroughs in AI and we have seen how easy it is to get started building who your own intelligent apps and services and it's almost time to get back to work and start building stuff and when you do I want to make you the case for that why you should start using cognitive services you know so I'm going to use my time today with me and some of my friends to be able to make the case for why you should and so we'll start by talking about dozens and dozens and dozens and dozens or customers using cognitive services today we'll talk about what we're learning from the field and what's more we'll hear from Symphony AI which is an incredible new AI fund and startup incubator which is you know building new a ice experiences in a number of verticals and then we'll learn more about what's next for cognitive services as we go forward and so you know between our kind of our enterprise experience and what we're doing for real customers today and what other customers are building on cognitive services I hope to make a compelling case for you all about why you should take cognitive services seriously when you're building you're making choices about building your next app so let's talk a I and when I talk about a I'm not talking about this kind of AI and I'm not talking about this kind of AI where ultimately having to build something from scratch yes yes see we can go to tutorials and we can go learn all about tensorflow and we can remember our linear algebra but there's got to be an easier way right and so I'm talking about pre build AI and pre AP and a for pre build AI it's got to be performance it's got to be customizable right well you know what AI is not one size fits all we have to have the tools and tooling to be able to necessarily take incorporate our domain expertise and domain knowledge into a service has to be compliant right if we're gonna use this for real use cases and not toy problems we have to understand what certifications we need we have to take privacy seriously we have to be able to be you look our customers in the eye understand that will safeguard their data you have to be in the cloud that's goes without saying and it's increasingly important to be at the edge whether that's an edge device like we learned about with the vision AI toolkit that we saw in Sasha's keynote on Monday or it's on a mobile device or it's on anything new kinds of hardware that's being thought of today uh and you have to be battle tested it'd be nice to be loved by more than a million developers but you know who's asking for something and so obviously I'm talking about Azure cognitive services and so as Ricardo services as you all know is our collection more than 25 intelligent api's that run the gamut from speech and natural language understanding the computer vision to knowledge representation and reasoning and search and it's been an incredible journey over the last three years I am fortunate to work with people who both in my direct team and in my partner teams who've been you know there at the very beginning in terms of the project Oxford days and we were able you know we started with a you know with a mission that's still our mission today is to make it as easy as possible for anyone regardless of their experience with AI or regardless with their skill level to be able to incorporate the very best that Microsoft has to offer in AI into their apps and experience experiences and services and so we're still following up on that we want to make AI available for every developer and no excuses and so today we are following through and that promise that you know we started in the seeds that we planted three years ago we are more Enterprise ready than ever before so I say there are 22 services that are in GA right now that's 90% of the portfolio and we're gonna be trending towards 100% of the portfolio being in GA as we go towards the end of the calendar year we're working hard to secure certifications right I know that people working in health care and you'll hear from symphony in a few minutes here about the work that they're doing in health care HIPAA and high trust our paramount ISO and sock and B CDR and PCI and if you're working with the government those are the certifications there are important in terms of building the experiences that you need to have and we are guaranteeing that we will have that this calendar year and later this month you know gdpr has been a tremendous effort for us and later this month we will stand up and be able to say that all of the cognitive services our GDP are compliant most start to give you our compliant as data processors and that means you know that's a that reflects our kind of understanding of the sacred trust that you have with your customers and that we have with you in terms of making sure that you're safeguarding and treating your data your customers data as a sacred asset and we're also increasing our investment in customizable cognitive services so currently we have seven customizable cognitive services you have seen computer vision if you spend any time on the floor in terms of custom vision we'll show a little bit of an example of some of the work that you can do there you may have heard of custom speech and custom voice part of the new integrated speech API that we often wear that we rolled out this week so custom speech allows you to be able to build custom acoustic models or custom speaker bottles custom voice lets you build the incredible your own text-to-speech font given a couple hours of recorded speech and it gets better both of these all of these services get better with the amount of care and feeding that you provide them with and how much data the ultimately offer custom translator you in the old days you had to provide bilingual corpora to be able to or the bilingual aligned corpora to be able to improve the quality of your translation now you can do that with monolingual corpora and be able to bring the quality of translation to your specific domain and the vocabularies that you and your customers use language understanding is the core of many of the BOTS that we build and in terms of being able to use supervised learning or semi-supervised learning to be able to build intent classification that will allow you to be able to understand what your customers are saying to your BOTS custom search is one of my favorite services it allows you to build you know custom search appliances ultimately modify the relevance ranking such that you can actually get the best results that are tailored to your domain and last but not least definitely not least whose content moderator which allows us you know to keep us to people to keep our workplaces and our children safe from explicit and offensive content and is customizable to the demands and changing demands of a very dangerous and treacherous internet environment so I'm gonna spend a little bit so before I talk you handed over to my some of my friends talking about why customization should be something that you can't live without customization is the super power which allows cognitive services to be enterprise ready so you know we talked about the seven customizable cognitive services we talked a lot about I talked a little bit about performance right I want to make sure that my custom speech model understands me or my tit understands my six-year-old whom you'll see in a few seconds who has a lovely voice but not enough oneness you normally train for ASR systems so how do you get the performance you need you can use customized customized 'el services like custom speech and costume voice to be able to titrate in more data and to be able to rebuild your models to be able to tailor them to your specific performance applications so here's an example I won't play it for you today but it's - it's a tree it's a transcript of two different versions of our speech recognition algorithm for calls made by currency traders right and they're using custom vocabulary right there you know it's a GBP right or they're talking about specific order numbers and if you look on the left the baseline you're using the kind of default ASR now it's pretty good it's intelligible but it doesn't reflect the custom vocabulary that the trader actually used the one on the right which was trained with a specific model based on the kinds of exchanges the currency traders ultimately had does far much but I'm much much better and we can actually cascade this for things like our speech to speech translation models so custom speech if you know sir for a speech to speech translation you're taking speech in from a foreign language you're running it through an automatic speech transcription you're bringing that back to a translation model which is doing text a text translation then you're taking the text out of the other side and then we're going putting that through text-to-speech and back out to something that somebody can hear and so custom speech a works in conjunction with custom translator and custom voice to be able to get you to make sure that you have the performance that girls when you're looking for and we have a customer today who's using this for a healthcare setting and so you go into an ER and you speak not alight we speak a language that none of the healthcare staff actually speaks you can actually use custom translator and custom speech in custom voice together to be able to have a conversation with translate the conversation you're having with a patient so you're not necessarily at the most critical time fumbling over words so the next thing you can do is focus on solving your problem you know I I talk to a lot of customers as part of my job and they you know at some point we you know they have an initial burst of enthusiasm they say wow these cognitive services are great and then they come back and say well but you don't understand my problem is very very hard very very difficult and I don't think that you know the state of the art and AI has gotten to the point where anybody can understand my problem and I say usually look at them and I listen and then I say try me because the cognitive service that we have in the customization framework that we have is often so powerful that we can actually make it make a dent in the problem so to be concrete this is a real-world real-life problem that in they can the protagonists of the kind of event here is on the left is my six-year-old daughter Mira she is a inspiring AI developer a Minecraft fan she she likes Python because she likes snakes and so I'm not sure what she thinks about go or c-sharp at this point but she's definitely into Python she has a brand new garden that she planted in our backyard in in Pine Lake and our backyard often also has his home to a family of count them six pesky varmints white-tailed deer that would love nothing more than to eat her greens and so the other night she made this appeal to me and I had to read it was tore my heart out to the point where I had to record it I can use AI to fix it well yes Mira yes we can and so I I said well you really want to use AI and she said yes that's what you all let's all that you talk about Daddy at home and I said okay fine and so we took her to custom vision dot ai which is the Kapoor Toulouse for our custom vision service and we used another cognitive service Bing image service too and we download an image search and we downloaded about 500 pictures of deer eating grass now keyword and interpretation has gotten so good with Bing that actually a query like deer eating grass actually you can bring back meaningful results and I set her up on her iPad and I had her annotate all the images of deer and she said okay good I'm done after she added a about 500 and I said no no no you actually have to actually recognize the actual image of the objects they're of the the bounty boxes corresponding to each of the deer as well and she said she looked at me and she rolled her eyes because and this is all for my garden I'm really interested in doing this true story this I I couldn't make this up and so she dries she used the custom vision AI portal with the object recognition and she was able to draw the bounding boxes around each of the deer and then she was able to deploy the model and she asked me whether 97 percent was pretty good and I said that I did sure her that it was and then I had to step in because she wanted to be able to put it on her iPad and be able to take it out in the yard and be able to see if the model worked and luckily for us custom vision that supports export of these custom trained models out to a variety of formats including onyx including a docker container including tensorflow and lucky for us core ml I was able to take the model wrap it in a xamarin app and be able to put it at put it on her iPad and kick her out the door and then spend it however spend some time in the yard going after deer she is now she saw cut Satya's keynote on Monday and she is very interested in me bringing home a custom vision AI kit the qualcomm camera that we built I am Not sure I can get my hands on one but I am sure going to try so the third thing the customization is really good for is in terms of making you making an experience uniquely yours and so we talked about custom voice and you know we this is this is an experience that I love in terms of if you can give me some recordings of your voice you can go to the custom vision I'm sorry the custom voice portal and you can build a custom voice font that you can deploy and so no more relying on generic voices that you've heard a million times no more having your customer experience sound like Cortana or Siri or Alexa you can actually own this and make this sound like you and the thing that I love about this you can get started with just a few dozens of recorded sentences yes right and you can get started with a few dozen recorded sentences and this one's about 500 recorded sentences here's one about 6,000 recorded sentences and you can see that the voice is a little bit better in terms of its prosody income you can create your own branded TTS voice with Microsoft custom voice offerings so this the interesting thing here is that you can build a entire custom experience from speech to speech a through translation without having to write a line of code right so this is there you know we're trying to not only are we Enterprise ready we're knocking down the excuses you have in terms of actually getting started with these kinds of experiences so the kind of tagline that I believe you hear with is that customization and pre-built AI allows you to get to market faster with AI that puts you in control no more kind of waiting on making sure that you can hire a data scientist no more waiting on understanding of getting through that tensorflow tutorial or that C and TK tutorial we have tools that are available and ready to go now and are being used by dozens and dozens of enterprise customers and you know as we grow our customer base we are learning tremendous amounts about the about the way customers are using our AI in their enterprise applications and I could spend all day in fact you know I think I've been early drafted my talk I basically wanted to just to talk through these from this matrix and talk about exactly all the different ways people are using cognitive services and then I was told they would not as be as entertaining as some other things I could do but we're gonna talk about two use cases we're gonna talk about predictive maintenance which many of you are familiar with in terms of understanding defects being able to predict and predict and understand the root causes of defects and then we're going to talk about business process automation which is a fancy way of saying using cognitive services and other kinds of associative reasoning technologies to be able to automate the kinds of things that we do online today so in between here I will actually shout out and show you some interesting technologies that are built by other folks not on my team and that we are fortunate enough to work with and so I will cede the mic here and yeah I'll let you see demos of interesting technologies that have kind of advanced the state-of-the-art in terms of predictive maintenance and in terms of BPA so we are working with customers all across the industrial sector and predictive maintenance whether it's auto space sorry automotive and the aerospace auto space would be something you know I'd need my flying car oil and gas and energy and different kinds of manufacturing and so you know really predictive maintenance systems offer three kinds of benefits really in terms of safety cost and efficiency and we'll talk let's take a look at the use cases themselves in terms of how we actually can recoup these for your enterprise so anomaly detection leverages computer vision Bri leverages computer vision system or cognitive services like computer vision to be able to recognize failures before they occur and so you can imagine that if whether you're trying to monitor your workplace and make sure that it's the your employees are complying with OSHA guidelines or you're necessarily trying to you know point a camera at a piece of equipment and trying to understand how its its performance changes over time cognitive services provides you a great way of being able to kind of gather the data that you need to be able to make of real-time inference recalls analysis right so once something fails can we actually look at all of the kind of multimodal kind of data that had that hangs off that event and be able to try to explain things why they've ultimately happened now we don't have a root cause analysis service we don't have a prediction service in cognitive services today but the ultimate that you we offer in Azure compare capabilities that would allow you to build those kinds of services based on the kinds of raw material that you're bringing in from your multimodal channels with cognitive services expert finding so things like you know we all if you're divet if you've worked at any time in a software development environment you've you know you know the situation where you wake up on Monday morning and you're holding the entire development team has filed bugs on the same issue the same defect right and you wake up in as a p.m. you wake up in the morning and you've got 50/50 bugs filed on the same issue and you have to understand well are there really 50 issues or are there one issue and ultimately if there is really only one who do I assign it to because who ultimately caused that problem so something like text analytics allows us to be able to do that kind of conceptual understanding and then services like prediction services that you can build and things like Azure machine learning would allow you to be able to classify those errors and ultimately find the right person and so just kind of give a concrete example you know we work with an aerospace manufacturer who's using who has a complex situation or kind of complex scenario built where they're bringing in real-time telemetry data they're passing it through an azure event hub and they're passing that to as your extreme analytics that are decorated by cognitive services and so we're using custom vision and computer vision we're using our video analysis capabilities and video indexer and we're making all this available in a search interface powered by Azure search called cognitive search which if you haven't checked it out it's it's a wonderful thing and it has been allows that this remove this month this week at Build and you can actually use all of the cognitive services in conjunction with a search appliance to be able to quickly annotate large amounts of data information whether it's in video or text or audio or transcripts or OCR documents you name it we can crack those documents and make it available with a single call to an avian API and so ultimately what we're doing is we're taking that stream analytics and we're passing it we're storing that data such that you can actually infer about it going forward you can actually look at you know to tie custom policies and actions for that and then you can actually pass it to a powered bi dashboard to understand what ultimately is happening in your shop so if you we can I continue with the shop metaphor for a second we're gonna talk a little bit you know I'm going to actually turn the floor over to Ravi odda and he can talk a little bit about one of our cognitive services which is being visual search which is one of my favorite cognitive services because it combines the power of the knowledge that is stored in the global search engine like Bing with the ability to kind of process images and understand them in a meaningful fashion and so what I really like about being visual search for a factory context is that we can actually whether it's pointing a camera at a part on the floor and try to understand where the hell that came from or pointing a a you know you can imagine pointing the camera at a problematic situation and trying to understand that being visual search provides you a framework to be able to build those skills thanks Andy so I'll be talking about big visual search so to start off I'll start with the video I think I'll kind of summarize my presentation till do it'll be less work for me [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] cool that was pretty much summarizes my presentation but let me go a little more in detail so it this basically covered three main things the first thing it covered was a Bing visual search what visual search is being able to take a picture of something and learning more or understanding more about the world around you through images input second thing and I talked about was we're announcing this as an API so you as developers enterprises and consumers can get this API use it in your products and services to improve and provide this image based search capability into your products then the third thing it talked about is the visual search developer platform so this is something new I don't we haven't seen this in industry it's something new we are announcing at Build this week and what it is is the ability for you to extend the capabilities or visual search for and customize it for your own needs so as you might have seen throughout build we have shown that we have a lot of visual search capabilities like some things you saw in the video like recognizing animals plants recognizing people landmarks or so forth so we've been using these visual search capabilities to provide a first-class experience for our what we call our visual search users users who want to learn about the world in a different way and what we also notice is that enterprises developers and others have also computer vision models have their own set of unique data that would help these visual search users but have no way to connect to these folks so that's why we announced our visual search developer platform to bridge this gap and allow you to take advantage of our visual source capabilities and get an audience with our visual search users so oops the the best way to do this is actually I'm gonna switch over to my laptop to do a live demo of building a skill so to build a skill you go to Bing visual search calm and here we provide information all the stuff I'm talking about is provided here we have documentation and step-by-step process on how to build ski and a QuickStart guide that has sample code and everything to get you started but let me go ahead and actually build a skill and the skill I'm going to build is something that you can kind of use internally in your company or maybe and use with the end consumer so a user is able to take a picture of a product and maybe learn more information about that product through your company portal so for example you can imagine it's a picture of a pair of headphones and they're broken and you as a company can provide details on how to fix it or provide a replacement and things like that so I'm going to click create new skill here and I'm going to and call it store search and it's going to find products in the Microsoft Store so the next part and building a skill is actually three simple steps the first step in configuring your skill is deciding when your skill should actually trigger so you might have seen this in voice assistants voice assistant skills where you have to kind of invoke by seeing the name of the skill here's slightly different it's based on what we call our visual intent visual intent is kind of defined as what is the most likely intent of this image based on the content in the image itself so we have a set of custom visual intent triggers that you can choose from for a set of base categories we're always working on improving and extending these categories and triggers so if you have suggestions please feel to provide it to me or through our feedback and support for this case I'm just going to choose to trigger my skill all the time and then the second thing is you want to decide what data do you want from the Bing visual search capabilities to be sent to you so for example will by default send you the visual intent that tells you why we triggered your scenario and then you can also ask for things like annotations that describe what's in the image so you do not have to build your own computer vision recognition model to recognize but in the future we're allowing you to extend these by building your own custom vision model if there is a need for it and then you can also take the raw image right now so if want to run your own processing you can as well on the image and we also detect various objects in the image like fashion and clothing so you can also leverage those and then we also provide OCR text that's on the image and we you can use that to understand more about the product that you took a picture of and then the third thing is actually providing a service URL of where your code is actually hosted so for this I've been kind of doing this in Azure as a Asha function because it's a simple HTTP request that I can make so I'm just gonna quickly save this and explain what this Azure function is doing so the actual code that I have is actually less than a hundred lines but here's a summary view so this view is just removing all the comments removing all the error handling so don't code this way but this is like the simple view and it's less than 35 lines and what it's doing here is parsing the annotations that I've configured in my skill to leverage and then based on that it's making a request to the Microsoft Store page with the product that I recognized and then providing back a skill response that's a format that we provide in our documentation and that's basically it so so while I was talking it saved this and now I can actually start testing my skill so I'm going to upload a picture I'm gonna upload two pictures here so one is this picture of this force of the video game so it's going to start generating the image metadata so this is the JSON response that's being sent to your endpoint of your skill so you can use this to debug and understand what exactly is being passed and then what you can do after that is actually click run oops I think let's wait for it to load again there we go and then you can click run and here it actually hits your endpoint so this is based on the response that I have in my code so and then it also provides a little preview so for example it provided a little preview text that says search Microsoft Store for Forza so it recognized based on the cover of that videogame that this is the Forza video game and now clicking on this link will actually take me to the Microsoft Store to learn more about Forza so you can imagine this replace this with your own product replace this with your own type of scenario where you're linking users from the real world products that you provide either on internally or to your end consumers and then providing them knowledge and actions based on it and we also are allowing you to simply test this on your mobile device as well so with the with the latest update to the bing iOS app you can actually download and enable camera skills and with this following test code for example you can run your skill that you made in this portal on your mobile device so it's a quick way for you to test and take pictures of real-world things and fine-tune your your model with that that's that's kind of it on how to build a skill so I'm gonna hand it back over to Andy so one of the things that we hear from our enterprise customers all the time is that they're looking for new ways to be able to capture data from a factory setting or in an industrial setting and so without I'm gonna bring Kyle back up who's gonna talk a little bit about project ink analysis which is the new cognitive service made available in the cognitive services labs that uses the power of Windows ink to be able to capture data thanks God thanks Andy okay yeah so I'm Kyle and I'd like to talk with you a bit today about ink and stepping back a sec you know why do we care about ink well take a look at the things that are on this slide I know ink allows you to record your thoughts in ways that no other input can so I've got things here like sketches or kind of a circuit diagram or physics notes or a to-do list here that's done in a very personal style to me and these are great expressions of how the pen as a tool allows you to make these very creative and expressive thoughts record those down we also think though the pen is a great tool for productivity especially when we pair it with AI and that's the main thing I want to talk with you about now I've been following Windows ink you'll know that we already have a rich platform of Windows API is that allow you to easily add an ink experience into your app today I'm going to focus here on the block on the left-hand side I start the right hand side there which is ink analysis and these are the api's that allow you to actually understand the ink that a user has created inside your application now these have been available in Windows locally as part of the last couple releases both as uwp and win32 api s well you know a lot of you are making applications outside of Windows whether it's iOS Android or web based apps so we're happy to announce that we are moving these api's up to the cloud as project ink analysis which is a new cognitive services lab that we just announced on Monday and now I'm going to give you a quick demo of what this allows you to do inside your apps second here to wake this up and I'll switch over okay so what I have here is an ink canvas it's using one of the platform pieces that I showed on the previous slide and what it's going to do here is it has a timer that's listening for me to stop entering an ink stroke and then after a little bit of a delay it's going to go hit our service to actually do the recognition call so I'm going to draw a simple shape here so it's just a triangle and there's a little status text up in the top that said hey the analysis ran and it completed when I tap on it I'm getting some UI here and this UI is an indication that we've actually recognized something but what did I send up and what do we actually get back and how can you kind of use that inside your apps so the requests here it looks a little intimidating but it really isn't what you're sending up is a representation of the strokes that are on the screen in this case it's just a single ink stroke and this big blob in numbers here are the XY coordinates of the points that actually make up that stroke if you're using our platform this is the exact same information that you get out of the ink stroke class so I just serialize that and sent that as part of my request up to the service what you get back is a set of essentially recognition units the local API is these are the nodes that you would get out of ink analysis and what these are is they break down the ink and they tell you what we actually recognized there in this case we understand that this is a drawing okay not let me select there but you can see it's a drawing in particular it is a right triangle you get some additional information up at the top here you get a bounding rectangle and this is the coordinates where basically can draw that bounding rectangle is inside there so it gives you kind of some spatial information at the bottom here you see another set of points and I'll show you in a second one you can use those four but those are what allow you to actually take that ink and then transform it into actually the the actual perfect version of what that shape was and the other thing that's in here sort of in the middle you'll see that the class here is a leaf so I'll show you this in a little bit when I add some more ink onto this but we returned a tree structure to actually under allow you to understand the layout of the whole document that you're sending up and I'll give you some example of what you can use that for so now I'm going to go back here I'll tap on it that little button there is going to allow me to use those points and beautify the shape so I tap on that I just converted it now it's that perfect triangle so I'll send it back to Inc and now I'm gonna do a little handwriting so there's my sloppy writing again we analyzed it I can tap on it and we're getting the recognition results for my handwriting the request again is the exact same thing where it's just the series of strokes that are being sent up now I have a few more of them to represent the letters that were in the word writing the response again I have my drawing up at the top but if I scroll down now you're seeing some additional things so we get an inked word coming back we get the recognized text which is the word writing this also has a bounding rectangle so this again allows you to do kind of layout analysis and understand where things are on the screen above that you'll also see alternates for what the recognition could have been and this will be a sorted list for you kind of an in decreasing order of probability for what that may have been but the recognized text here is always that at the top result so like I said this comes back in a tree and this is just a tool that we wrote that kind of visualizes that tree so under the root you'll have your shape there which is the right triangle and then you have a writing region underneath that is the paragraph underneath that is a line and then underneath that is the word writing and that was actually in the response here if I scroll down just a little further you'll see the the line coming in a paragraph and a writing region those also again all have bounding regions on them so that's a simple example if I want to load up some more ink here so there's some additional things inside here the tree of the response is a little more complicated now but it has the same basic structures in it it has a number of shapes it has a couple writing regions here the paragraphs now I also see list items appearing and what these are is when we recognize a few lines in a row that have a bullet in front of them instead of just telling you this is a line of text will also tell you this is a list item so throughing through using that layout analysis that we have and I can tap and select a word I'm going to double tap on that where it's gonna go up the tree so the parent of that tree it was this line and if I double tap that now I have the entire list selected if I double tap again you know I can't go up any higher because we know that's the end of that list even though I have additional text up at the top you know that Microsoft Project Inc analysis we know that's not associated with the list so we don't go up and select that what this allows you to do is with that layout information those bounding rectangles you can do things like well beautify the ink that you have there you know I wrote this list I meant for everything to be left aligned in it but I sort of messed up in the middle ones you know kind of floating off on the right-hand side a little bit so I'm gonna hit this button on the right and it's gonna left align everything in the list well leaving is my ink and that's just using that bounding information that you got back from the recognition call now of course if you wanted you can come along and you know convert the whole thing into text you know on our team we we really like the expressiveness as ink so we think about scenarios both where you want to convert things like this and also the kind of scenarios where you want to leave it as ink but still you know add some kind of intelligence on it like doing that sort of beautification or understanding what the content is and another example of understanding the content you know I want to be able to search this I want to be able to get back to the things that I wrote as handwriting but leave it as my handwriting so it's still expressive so I go along here I'll type the word ink tap it and now you see we understand what node that was so we can go find that now and just change the ink color of it and now we understand okay yep you actually wrote ink and it's sitting right there so that is the quick view into what you get out of the service and really those are kind of our initial thoughts on it and we're very excited to see what you can think of to go use this for so please reach out to us whether you have questions on how to use it feature requests or just general thoughts about ink our aliases windows ink at Microsoft comm and we would absolutely love to see you use it and get your thoughts on it [Applause] so this is we talked a little bit about business process automation before in terms of being able to use cognitive services and other AI related capabilities to to things like automate data capture windows ink and project ink analysis is a great example of that but you can imagine I was sitting there watching Kyle's demo and thinking about how we could actually use things like text analytics or computer vision to be able to even augment further the kinds of annotations that you're able to capture through ink some form filling or document processing is that's a natural place you can imagine if you had a service that could look at claims documents from whether it's a health record or whether it's an insurance claim and understand whether you're actually putting the date in the right field or signing at the right place we have customers who are actually using this now to actually process mortgage applications for you know the dozens of times you have to sign to make sure that everyone's signed in on all the right places and so in terms of workflow automation or claims processing there's been we have dozens of customers now at this point who are using combinations of cognitive services to be able to make that happen so rather than talk about some of our use cases I'm going to invite some chief jugged up to come up and talk about one of the kind of one of the kinds of workflows as nearest and dearest to the cognitive services family heart is in terms of customization for content moderation and so the internet it can be a scary place and what Sanjeev and his team are ultimately able to do is make it a little bit safer for our children and our workplaces [Music] not yet so yeah I'm part of a team called risk and protection services and I'm representing a protocol core and moderator so this team is kind of unique and at Microsoft where our mission or mandate is to protect Microsoft against the bad actors the bad content right the criminal activity suggests theft of IP licensing abuse and also counterfeit products and so on and so out of that work done over the years has emerged this coveted service which is called content moderator so if my colleagues are sitting here and that's what I'll be talking about right so so the scenario so think about this I guess the think of I guess the compare our team is that normally of all the stations here are talking about how to find the next haystack I guess to work out what we are doing in our service with our services finding those needles in the haystack right and those haystacks are growing as we know thanks to you Jesse and content and Internet and so that's the scenario that we are trying to nail by making sure the goodness Rises our fastest so the scenario and the demo that I had just to convey kind of what kind of possibilities exist in this space are that imagine that your online marketplace and you have manufacturers uploading products to your website and you're looking to moderate content for offensive content as well as kind of investigating suspicious less things which could be perhaps counterfeit products all right coming up being listed when they should not be and so one of the requirements requirements are scan catalogs for potentially illegal and offensive content it also matched that content against for those catalog against may be confidential product images or or codes that should not be online and if they are online well that's an indication that there is something else going on there and that we need to investigate and the third requirement is of course how do we automate this end-to-end work flow of content ingestion scanning taking the insights from these api's comparing it against your content facials and policies bubbling it up in a human review to and finally after the decisions are made submit the data back into perhaps another investigation system or your own in-house tools and so the solution that I'm talking about every demo is using content moderator from cognitive services primarily and we'll see in a minute how that works and so what matters most in these cases is of course in pacing speed a radience thing cost of filtering out the bad content as well as using customized AI based processes to augment human review and loop in the process so in our case we especially believe that AI augments the human review process and then when you combine them together you get the best result specially in complex nuanced cases like these all right so what is content moderator it's a platform and you might think is the collection of services which it is but it's the content moderator itself in one cognitive service and that has this collection of API is to scan your text image video for illegal explicit suggestive inoffensive content right so that's the bottommost layer on top of that is something called a review api which is of the bridge to connect your repair insights to a human in the loop process and so the review api consists of workflows to automate those life cycles jobs which are really end-to-end asynchronous processes will scan and create human reviews and the review operation which is really just to create plain old reviews in the review tool the flexibility you get as a result is that you can bring your own api's you can use the different cognitive service doesn't matter but you can still get the bill 10 out of the box to review experience with the service and of course you have these moderator sitting at the top using the UI these could be either your employees or in-out sauce vendor or even crowd-sourced companies so the demo I put together just for this is a very simple specific narrow scenario which takes some sample content right and the first problem will no raise to classify it and detect offensiveness the second problem was could match it against known data no in content right so you're really looking for exact matches here and the third is you could be using a custom region service for example to custom classify and look for custom patterns in your data right so in the demo that we'll see what happens is the classifier and the numeric stats they trigger a job process or a job step which are being driven by workflows that we look at and these workflows are the ones that are actually taking these kind outputs or the insights from the api's applying your content policies and flesh shows and criteria and then defining whether to create do an action such as in our case created human review right and the custom classification in this case I did comment out the code in my demo just in the interest of time but in this case the code actually creates the human review directly based on the custom logic in the application for itself in both of these cases the job where you call the job API or the review API what you get is a human reviews of your images text and even videos an online review told that quantum moderator includes by default and so when customers are signing up for service through a sure they're getting not just the api's but also getting a a full-blown end to end human review - right and once the human moderators have done the decision-making they can change the labels ascend and so on all the data which is both pre human review as well as post review all that metadata is submitted back to you to your callback endpoints and then you can integrate it within your in our system or third-party system such as so let's just switch to my laptop here so you can go to demo okay okay so remember we talked about workflows and I think the workflow is a great place to start right so let me open this workflow here and you will notice if I collapse all this is nothing but an if then else expression really that you're mapping out here if I expand it you will now see that all I'm doing the goal of this workflow here was to really generate reviews for all content just to demostrate what a workflow the difference book so we can make so in this case I'm saying use the content moderator API output right and use the is match output and if it's equal to true or false in the other ways so we create a river regardless what the result is that's the purpose create a review right that's the action we are specifying and then highlight the match tag if the API actually reflects it as a match right and then of course submit my submit data to my callback endpoint which is right here right now you don't see any requests but will see requests coming in as we stopped in the data and so that's an example of a workflow right that's that's a match similarly for reviews as well which is the classification scenario remember here I'm saying abrasive score is greater than zero then create a review which effectively means anything that we pass through the API it will create a review because all this is cause even if very low will be seen will be greater than zero anyways right but again keeping in mind the same idea that we only highlight those which are actually found to be received by the API which is and that will only happen if the score is actually greater than the internal default or the internal threshold right and so that's an idea of a workflow here now let me switch back to our code right so this is the code and given notice and these steps exactly match what the scenario we have been talking about right and before I run this let me show you the only difference between the classifier image and then the match images the workflow right in this case I'm calling to match workflow that we just looked at right for classify I'm calling the classify workflow but they put the code the other code is exactly the same right and so let's let's run this and see what happens and so right now it's matching the test data the content that I have sitting somewhere in my text files against the the online links that it's that I have saved it's also classifying the images and creating reviews and now it's looking at the text and data coming in right and so it's just done and go ahead and review online so the data if you're curious the actual ingest data is right here so these text files for example these images right so imagine this is your content catalog coming in with URLs the sample images right so they have been classified in this case I'm actually matching the exact image URLs these images within the images that I uploaded previously into the service right so you have these hashes of these images sitting and that's the matching going on there and so now let's go back to a review tool and click on image so what he saw was that those images that are sitting there links they were all flagged or they were all populated inside a review tool as image reviews now remember our workflows in a workflow we said pre-screen reviews for everything but only flag or only highlight those content that was flagged by the API and therefore you see it kind of a larger set here so these for example one and two these two images where's tagged as racy and I can move this zoom bar around and you can see the scores and so on right then these images the wheel D the tile and then this part motor part as well as this one I had tagged as something to check the internet for right so in this case they were found as exact matches and got flagged in the review tool right and if you wanted to see the text part here let's go and look at text reviews and so again here what was happening was that this line has it has the confidential product code which wasn't supposed to be online right and so that's why this text got matched and the M which is the match that got highlighted and so what you human moderators are doing at this time is really just submitting and saying okay do I agree with the decision not if not let's say they can clear the tag and submit their decisions and let's go ahead and do it too the same as the images right so I can say I agree with these decisions or maybe what I could do is I can say well this is not racy so I'm fine with this and we submit the next order click the next button to submit these reviews and as I'm submitting these reviews you will notice these requests or the data coming in from our callback endpoints and this is where your system your in-house or third-party tool can take in this data and integrate with the investigation system right so now if I go back to our workflow tool and very quickly make one change and then run the code again just to convey what happens now how workflows work here and so I'll say content moderator right select is match equals true and so now the reviews will be created only if a match is found and similar let's do it for image 2 it says abrasive score I'll go with the boolean this time now what we're doing is we're cutting down the actual review set data set and this is exactly how the actual process works now I go back and I run this app again and there is nothing it's it's almost done so now let's go back and look at our review or image reviews again and this time you should see only those images that were actually flagged by the API right so that's an example how the work flows very seamlessly work and with a few lines of code you can automate the end-to-end process get out of the box review tools as well as the API and combine everything and by the way everything that is that I showed here which is let me go back can how do I switch back here so let me go back so this is back to the computer to the presentation here know what I'll check that energy was it coming up the main one from 6mm yeah okay good yeah so in closing against the only thing I wanted to say was oh yeah I think this is like all of this all of the functionality that we saw here is exposed to an API and programmable right so it's not bound to an actual out-of-the-box to sign up for this service use the API is an extent reproject for your own processes thanks sandy thank you so much and I think so it's my great honor and privilege to introduce my friend and collaborator Pradeep who is the chief AI officer of symphony AI thank you Andy first of all a huge set of thanks to the Microsoft team have been incredibly generous to give us the space and times to time to talk about what we do so so I'm the chief air officer for a new and innovative vc / incubator / fund we're about a billion dollars strong and founded by dr. ramesh Wadhwani a very prominent entrepreneur in Silicon Valley we're sort of based in Los Altos so our goal and and and an approach is to create companies that are at the intersection of enterprise software and and the application of AI to transform multiple industries I mean as you well know with all the cool stuff that's that's coming through from Azure and from Microsoft in terms of the innovations the the application of these technology to specific industries such as healthcare or industrial AI or legal or Talent requires a different approach in terms of understanding the lingua franca understanding the use cases understanding the personas involved and creatively bridging the gap between product management product strategy data data intelligence and the application software that's associated with it we are about eight companies right now as of now we started about a year ago and we are in diverse areas diverse industries such as healthcare in particular folk is very much on oncology in cancer care and you know it's it behooves we just sort of spend just a few seconds on sort of the health care initiatives so we have an exclusive semi-exclusive another company also has a relationship with an organization called cancer link which gives us access to the largest longitudinal data sets about cancer patients in the u.s. the aggregation of that data said the processing of those data sets for the purposes of determining adverse events or for recruiting patients to clinical trials or to think about genomic sequences that are potentially contributors to a disease progression these are some of the sort of you know a small set of use cases there's a whole bunch of other use cases that we're working on related to ready to healthcare we are in in the retail in the CPG industry also sort of have pretty rich access to very large data sets associated with point of sale data associated with consumers loyalty card or members especially in the grocery retail chains so they the central team so one of the examples that I wanted to talk about and I'm not going to take up too much of the time here is one of these applications which is a complete as your native applications called Symphony summit this is in the IT Service Management and the IT operations management world so this is the real application it has a pretty large chunk of the market share or over in the in the APAC domain in Asia and we're bringing is a different set of cognitive services and the application of these cognitive services for the purposes of transforming how service management is done how operations management is done so I'm going to demonstrate this with with with with Cindy Cindy is our vertical bot it's a it's a bot and in this particular case it is conversational interface and decisioning engine it's sort of a an acronym for what we do and if you look at sort of like the interactions that are occurring between the end-user and Cindy here hey I'm trying I'm attempting to download a report it's not working well so it looks like you tried downloading these things and suggests that hey perhaps your is as one of these that you're referring to and the and the reference look at the context in terms of sort of a pretty close to a conversational exchange that you might be having with a service agent and it essentially attempts to auto resolve now the key point here and I'm going to describe surah Blake specifically what is what's occurring here in order to produce a conversational agent such as this most of most of us are engineers here in the room so we know that this is about the aggregation assimilation and the processing of data from a wide variety of systems in this particular case we have understood what dispersive who the specific user is right in terms of their identity has been well established their entitlements have been well established the recent history in terms of interactions with these reports have been parsed well where does that come from I mean could come from proxy servers or web server logs or other kinds of applications that they've been interacting with and the fact of the matter is you know there's a certain level of correlation and there's a certain level of Association that one needs to make about the fact that you're having trouble with this report and that downloading of the report means one of these potentially hundreds that you run but this particular instance making that classification or Association happen is a vertical b2b AI problem second is sort of understanding the context of the enterprise what is this user entitled to you know honoring the security and credentials and entitlements that this specific user was about taking that into account and then parsing the fact that you know keeping the session context in mind saying is this specific thing is this a thing that you're really asked and then realizing and in the back end on the server site that hey there appears to be some sort of a problem occurring with this HANA cluster so what does that mean well we have to look at CMDB like a topology of all of your network services and things that are occurring there what might have occurred recently and trying to determine whether that is actually potentially the reason correlated or causal sort of effect of what this user is experiencing and attempting to be helpful in a respectful manner saying let me create this report for you on the back end and at the same time I'll have this be dispatched to the right service agent that has this particular skill sets involved so here what we're talking about is sort of like looking at different Network entities software components agents people and ingesting all of that data and combining that stuff together in terms of building what we call knowledge graphs and from there arriving at decision-making from that purpose for that purpose so this is a this is the architecture that we currently have and this is not the sort of as your presence everywhere right it is this is a total azure native application we are leveraging end-to-end stack of the azure services and you know back to Andy's point I joined this fund just a segue I joined the fund about seven months ago before that I was at Adobe the first time I was exposed to to the Microsoft in the azure cognitive services as well as the entire AML sort of ecosystem was back when you guys were in the crawl phase right back in 20 2015 and at Adobe that journey has been complete and now we are we're doubling down at Microsoft and with respect to our both build as well as commercial partnerships so just to sort of you know sum up your work what are we trying to do ingest data so look at the sort of the semantic ontology driven processing this is in general true for every single vertical that were involved in whether it be health care whether it be talent or whether it be legal or whether it be retail in CPG environments the question is to ingest this data set as fast as possible and try to discern meaning out of it right and you know using classic machine learning deep learning and reinforcement learning techniques but also in terms of a focus on the end-user persona and the problem that we're attempting to solve and/or optimize downstream it's about sort of creating these semantic or vertical knowledge graphs this is you know we think of it as a multi-dimensional graph that is dynamically getting computed based on these data sets from there we determine what potentially causal causal inference thing might look like and here's sort of you know machine reasoning is one that and you also pointed pointed out - which is a big area of focus for us from from a research and an applied research perspective in terms of knowing that and as most of you know in the enterprise world explain abilities kind of a big deal right meaning that why is this thing doing what it is doing having a certain degree of transparency and being able to explain all that's occurring from machine learning in an AI perspective so that it receives some level of enterprise acceptance is a big area of focus as well so it really starts a domain and customer specific sort of like models that are that are built by ingesting these datasets by leveraging these machine learning services so I'm going to end there with basically a sort of a high five to saying given that you know all of the school stuff happening the only thing that's really left Andy is flux capacitor Oh time travel yes thanks again Thanks [Applause] if your flux capacitor has not been anounced in GA as a as a service in cognitive services so what is next for cognitive services I am going to go quickly through this I'm happy day and take any of your questions you've heard our announcements far and wide over the last three days you know we are three more services to GA and so things like custom vision is still in paid preview you can expect a GA from that in the next couple months we have a brand new unified speech platform that we're really proud of in terms of bringing infrastructures together and having a great SDK the work that we've been doing in Bing you heard Robbie talk about big visual search and some of the work that we've been doing in BOTS really is it's the things that we're very proud of we're also branching into hardware you saw Satya talked about the vision AI Developer Kit I would be remiss if I didn't talk about the speech devices SDK which allows you to actually take the power of speech and bring that to really dedicated devices this is very very slick I haven't gotten my six-year-old to convince her to be able to take a look at this yet I but you know I think the future for us going forward is much is going from customization which is you know tailoring a model to a specific kind of outcome to personalization which is tailoring massive amounts of looking at Mossman massive amounts of different kinds of targets as opposed to a single kind of domain target and where you're seeing this my colleagues who have built project personality chat really you know warm my heart every time I see this this is a new service that's in labs that will be coming to the portfolio in the next couple months that allows you to be able to use the power of natural language generation and personalization to be able to generate custom responses and integrate those into a chat bot so you can imagine here these are voices or personalities that they've generated for a chat bot that could be look like a lot like Cortana where you have different personalities where there's professional or friendly or humorous and I actually asked them to do me a favor and to generate one based on 10 years of my social media outcomes so if you have if you come up to me and say that's interesting and I may might just say isn't it or if you that I'm so funny I might be a little bit skeptical and say thanks I guess and these are services that represent the power of personalization the power of cognitive services working together a personality chat can be integrated in a number of different ways including Q&A maker the azure bot framework which is really stellar and through their own API which is coming soon I want to close today by introducing my friend and colleague John Lankford who will talk a little bit about how we're going to achieve some of this personalization and you know the the the takeaway here is that it's not necessarily through the same kinds of supervised learning paths that we've gone from before thanks John thank you Andy okay so I'm telling you something that's a new approach which is happening inside of machine learning so most of what you've seen is driven by supervised and often deep learning techniques so in these techniques what happens is you have a bunch of unlabeled data like the images over there of digits you hire somebody to label things maybe you get your daughter to label things yeah and then you shove it into a machine and then out comes a classifier right and that and then people have done great things with supervised learning and it's actually it's amazing to see when I started out in doing I'm a researcher right so when I started out I had no idea it's going to happen so it's fantastic to see what's going on and yet there's another vein of research going on inside the machine learning community which is around reinforcement learning and I wanted to tell you what that is and and why you want to be thinking about it so there's a very basic signal which comes up in many different ways it's kind of a good and bad signal and you you can encounter this many ways in your life good and bad and and now a key thing question is how do you actually learn from a reward signal and so this is this is what reinforcement learning is really about so instead of labeling things as a deer or not a deer you are saying oh that's good or that's bad now the question is why do you want to think about using this more primitive data source and there's actually a lot of good reasons I'm going to give you five reasons to be thinking about using this kind of data source okay so first of all let's go into a little bit more detail what reinforcement learning is so in reinforcement learning what happens is you have some world which gives you an observation and then based upon this observation you have a policy which is going to make a decision so I'm gonna sting machine from a classifier which would be typical supervised learning because we're making a decision which is going to affect the world important that it affect the world so we make a decision we're gonna choose some action that goes out and that affects the world in some way and they're gonna get feedback and get some sort of reward Singh well that was good or that was bad so it's important that you have a policy that whose action actually affects the world for this entire approach to work right okay so suppose we have this kind of setup our goal is to be to maximize the rewards we see receive over time and now why do we want to do this right so number one it's personal so is Ukraine interesting to John this is a pretty difficult question for an editor to answer about me but it turns out that the answer is yes because my wife is from Ukraine right so reinforcement earning by looking at the the signals that a user provides can get at sources of information which is just not available to somebody's trying to label things and that allows you to achieve a level of personalization which is not as possible okay so another really important aspect here is you can actually deal with non-stationarity some of the systems that we've worked on do personalize news for MSN and it turns out that this is an extremely non-stationary problem because there's new articles coming in every hour the interest level and an article changes over the day and you would like to be able to adapt to that very rapidly so typical supervised learning approaches aren't really designed for this kind of thing it turns out that online learning and reinforcement learning working together are much more natural solution to this and give you much better much higher quality solutions okay so another thing that's very cool so who's familiar with AV testing just about everybody good okay so that now here's a trick it turns out that when you have a reward which gives you an immediate feedback for an action that you take and you you do things in the right way you can evaluate what would have happened if you had used a different policy a different way of choosing the action this is from real data and it's messy this is that the black line here is the actual observed online performance the teal line behind the back line is the counterfactual estimate of the black line you can see there's some difference because there's statistical variation and then the this is a recommendation data set the lower teal line is the performance that that the editors had so it's cut into the supervised performance or they were trying to create a ranking over news stories so you can estimate directly okay so this is not an a/b test it's a critical thing it looks like an a/b test because I'm I'm drawing three policies up there there was actually only one policy deployed which is the black policy but because of the way we gathered the data and exactly which data we gathered we can evaluate other policies offline this is this is a very powerful trick because you can explore offline any different ways to create policies many different feature representations lots of the fun things the data scientists do instead of trying to explore them in a B test so number four is it's free so if you're trying to if you can set up these reinforcement feedback loops typically they're free do people click on a news story right or was the outcome from a medical event good or bad you could start trying to if you set up these loops you just start learning system keeps getting better and better and better we actually observe this in practice so often what we see is the system it has some warmup period it gets better and a better and better and better and she keeps getting better over time so it's a very different from the way that a lot of supervised learning approaches work it and then the last thing is that it's fun and now I'm gonna try to do this is a debate going on I think in the machine learning community right so the supervised learning approach AI means a function programmed with data right and you know that's kind of a fun definition but but but I actually think an AI is an agent that explorers learns in acts and that's what you're doing what are you doing reinforcement learning so you are you having fun right so this is maybe not the motivation you tell your manager this is the motivation for you finding the other four reasons to tell your manager right okay so Gartner says that reinforcement learning is important I agree III knew that I was coming from a research community where we definitely know that it's a very very hot thing in terms of research right now reinforcement learning is behind the Microsoft custom decision service which you can use to go and customize personalized even webpages right so there's a team of researchers on top and developers on the bottom movement working on this there's a lot going on behind the scenes and maybe some more things will come out sometime soon but even with what we have we've been able to do some pretty amazing things so on Emison it gave a big lift with various other external companies we've had pretty big lifts so this is a lot of fun stuff and lots more going on so thank you we're almost at a time I just wanted to I wanted to leave you with a final message you have many choices in this day and age in terms of what you can use in terms of cognitive server things like cognitive services we are grateful that you have with all the feedback we have gotten from our developer community you have made cognitive services better over the last three years and we can't wait to show you what's happening going forward but if I leave you with one thing is don't settle AI is not a one-size-fits-all business you shouldn't insist on AI that meets your specific need that is enterprise ready and takes care of your and your customers data and I think there's only one way to be able to take that and make that operational it's used custom cognitive services so thanks so much I'll be up here at the front we can talk about and address it in your questions but thank you so much for participating on a wonderful day and have a great rest of your build thanks again [Applause] 