 Hello and welcome to Cognitive Services Live. I'm very excited about all the cool stuff we have to show you today. We have a really packed agenda, why don't you show them the agenda slide here. We have a ton of services that we're going to be talking about. I love Cognitive Services, I feel like we don't talk about them enough, because if you want to do AI, it's pretty much the way to get started. Literally, when you see it, you can go do it two minutes afterwards. So, I'm pretty excited. So, this is the agenda for today. We have a ton of sessions for you to watch and to enjoy and to learn how to do AI. All right. So, we're going to get started here. I have my good friend here, Lance. How are you doing my friend?  Good, doing very well. Excited about this.  Fantastic. So, why don't you introduce yourself and tell us what you do.  Yeah. So, I'm Lance Olsen, I am the Program Manager for Cognitive Services. Really, what we're doing is we're focused on just making it so more people can take advantage of adding machine learning to their applications.  Fantastic. So, here's the thing about AI. I've done AI for a while and there's been a couple of hype bubble waves of AI. A lot of the stuff in AI is from the 50s. So, what can you actually do with AI, and what is the business opportunity? Let's get down to brass tacks, what is it that people can do today?  So, today there are a bunch of things you can do, where you can use AI to solve vision problems, speech problems, document understanding, like the yellow process text. There are a lot of things we find that people do that as monotonous or very time-consuming and costly that we can now automate. They're not necessarily crazy, crazy future tasks, but actually, things you can do right now that just simplify the task that you have to do, and allow you to do them in a better scale.  So, this is the concern that I hear people have, is AI going to take over people's stuff or is it going to make it a little bit better?  Well, so we think about AI as really helping people to do more and to be more effective. So, one example is we worked with Snow Leopard Trust to enable scientists to be able to find- it had all these images where they're tracking snow leopards, and for each time they would go look at these camera traps, they'd have to spend most of their time, like up to 300 hours just saying "Is there a snow leopard in this image or not?" And most of the time it wouldn't be, it would be like a goat or a blade of grass or something else. So, they can use AI to basically sort through all of the images that they collect every time. In that way, they spend their time looking at the images that actually have snow leopards, and then they're doing the things that they are actually there to do as researchers and scientists, which is understanding the populations and the health of the snow leopards themselves.  I see. So, it's not taking over humanities responsibility to be smart about things, it's just taking the menial tasks and making a little bit faster?  Yeah. There are a few different categories. It's helping people to be able to take data and then reason about things in a better way, more efficient way, being able to scale and reason over more data and then make decisions or predictions from that, that then can come back and inform us and how we work. It also lets us dig deeper into large quantities of data and extract the underlying meaning of the data. So, we can look at things like images and see faces, or product names, or product logos. We can look at large corpuses of text and we can extract the topics and the sentiment and things like that. Then finally, it's simplifying and enabling a whole new set of interaction styles. So, think of things like speech and machine understanding allow us to do things hands-free in cases where that's a better interface than keyboard and a mouse, like in the operating room as an example.  I see.  So, for those that want to get started, what is available on Azure right now?  So, there's a wide array of services and options that we have, but really the way to get started is really at the top. We have Cognitive Services, which is a set of sophisticated pre-trained models that you can use. These services don't require a data scientist, you can actually come in as a developer and use them. An increasing thing that we're doing with them is making them trainable even with your own data so you can customize them yourself, but you don't have to go into the frameworks. Beneath that then, we have layers that let you actually work with the frameworks like TensorFlow and Pytorch, and things like that directly. We have services like Azure Databricks and Azure Machine Learning, and also Machine-Learning Virtual Machines that give you a full data science environment, and really make the data science process a lot more productive for people, and make it more scalable, so we can actually do it at scale. Of course, we do that on top of hardware layer that lets you have a bunch of different options to optimize the hardware for the machine learning that you're building, and we also let you do that in a way that can be deployed in a variety of different locations, whether that's On-premises, on the Edge, or in the Cloud.  I see. So, we have the gamut from just using AI all the way to building your own AI and the infrastructure [inaudible]  Exactly. Yeah.  So, if I'm just getting started, what's the fastest way to actually start?  So, the fastest way is to go to Azure.com/ai, and then click on the "Pre-built" AI link which will take you into Cognitive Services. That will show you the different types of AI that you can use. It will show you vision, speech, language. It's actually a whole set of topics that you can drill into and capabilities there that span across these vision, speech, language, knowledge and search. Then you can see which capabilities might be applicable for your application, and just click on that link and it will actually take you into a page that lets you even try it out right there. Almost all of these actually have free trials and also free tiers that you can use on an ongoing basis that give you a bunch of calls that you can use just to try it out and get it going.  So, I was a C# developer for many years, is this basically like an SDK with an intelligent SDK that you just call? Can you give me an example of something I might do today with a piece of text? I'm imagining I have a string and some text in there, let's just say it's a support request, what kind of intelligent things can I do with that?  Yeah. That's a great question. I actually think of this a lot. I was part of building .NET many years ago, and we're focused on things like the base class libraries, and the networking libraries, and the data libraries, and really try these becoming the building blocks for applications. We look at Cognitive Services, I think of those as the future building blocks for how people build application. So, like your example in text, I could take a string of text, let's say its product feedback that's coming in about one of my products. I can run that through the text analytics service that API, and it will tell me things like what are the nouns and what are the verbs, what are the topics that people are talking about when they in this line of text, what's the sentiment for that, what are the entities that people talk about, do they talk about a date, or a building, or a restaurant. I can get all that information out of it and then reason over it.  That's pretty amazing to me because I did support. I think all of us had to do support at one time or another, and sometimes you would get these really long pieces of text and you'd have to slog through it to find out what even they're talking about, and whether it's a positive or negative thing. You're saying, I could just put that block of text, make the rest call, and then it's talking about these things, and they're unhappy.  Yeah, exactly. Imagine what you would have done before this, is you would have written a massive amount of rejects parsing code.  Right, which everyone loves.  Which we all love. I know.  Yeah, sure.  It's super productive.  I was sarcastic. Obviously like we all love pearl as well too, right?  Yeah. What we see is you can also do this over time. So, if you're sending that text into the CPI over time, you'll actually start to see, well, how you can go back and create dashboards that do things like, how did product sentiment change over time or customers happier, were they mad based on the changes we made to our products or our services, and we've seen that with customers.  That's cool. So, I don't have to do anything other than provide the string and it will give me back all the nice data that I want?  That's right.  That's awesome. Okay. So, another question that I have is, it's really cool to think about how you can do this, but as an enterprise, sometimes there's some nervousness. Is this too new, is it enterprise ready, is it something I can rely on?  Yeah. It's funny, it's like a fancy car. A fancy car that doesn't run is still really not worth very much to any of us. So, at the end of the day, one of the key priorities that we've really focused on for Cognitive Services is enterprise readiness. So, for example, in the last year, we've gone from 14 to now 19 regions that the services offered in. We've also actually moved the Cognitive Services into our Azure Gov Clouds, so now governments and outside the US government, we can actually use those services as well.  That's cool.  Yeah. It's one of those things that opens up a whole new set of options. First, you look at it and you go, "That's exciting, but then I can't use it if it doesn't run in my compliance boundary, or if it's not secure." So, those fundamentals are really important to us and to our customers. We've also focused on certification, so we've got 10 services that have been certified for SOC and ISO, and then a bunch of others that are also certified for HIPAA, and so really focusing on compliance as well.  So this is something that, like you mentioned HIPAA compliance, there's some services that you can actually use in a way that's compliant with the government regulations in United States or other places.  That's right. So like the OCR case, let's say you wanted to ingest forms inside of a hospital, and then look at them and process them, we can now do that in a way that's HIPAA compliant with the services that are now certified.  That's amazing because I've had a lot of questions about this, cause I go to places often and they're like, "I love Cognitive Services, but is it something I can use at my accounting firm, or is it something I can use in the hospital? You're saying that you can, it is enterprise ready, we have it in regions close to you and their certification.  Yeah, region availability and the certifications has been a big piece of feedback that we've seen, where people are really excited, like the productivity of these services is really great. We've had over a million developers use them in the last year or so, but the big piece of feedback we've had is, "I want in my region and I want it compliance with the requirements that my industry has," and so that's why we've really spent a lot of time and a bunch of hard work actually making them compliant and available in those regions.  So, the next thing I want to talk about and this is, I think the exciting bit for me, is I've had some people talk about, "I want to be able to use Cognitive Services but in my own environment," and I think this starts to lead into some of the announcements that we have for today.  Yeah. So this is something I'm really excited to announce today, which is that as of today, you can get five of our Cognitive Services in containers. What we've really done there is we've heard from customers that there are many cases, it could be because of scale or because of where you want to control the scale directly, you want to manage the resources or maybe you've got an application that's already running in containers, and you don't want to be doing network calls to call the remote services, you actually want to run the AI in containers right alongside that application, but people want to be able to run and call those services in a container. So what we've done here is, we've taken things like our texts analytics service, our face and emotion detection service and the OCR service, and we've moved the model portion of the service into a container, so now, when you provision the service, you'll actually get linked to the Microsoft container registry. You can bring that container into your own application contexts, whether that be on the Cloud, or on the Edge, or on the premises, wherever you can run a container, and then you control the data, your data never leaves that container. So you call that, and the API is the same. We actually took the service endpoint that we had in the Cloud and just refactored it so it's running in the container. It still will connect back to the Cloud to talk about the usage and so your reporting and that kind of stuff will not change at all, but you have complete control over the data now, and exactly where the data goes and how it runs over the AI.  So now like, look I was in New Zealand for an assignment, and someone from a hospital was telling me, "We'd sure loved to use," like just OCR you said was one of them?".  Yeah.  "We'd love to use OCR, but we're not allowed in New Zealand to ship the data out." Now you're saying they can do something like that On-premises, that data always stays there.  That's right. Another thing I've seen people do is, or tell us as we started testing this with a few customers before we got it ready for prime time here and another thing we saw them really like to do with it was, you might take all of that data in the hospital and run it over OCR over or else over text analytics to get entities, get key phrases out, and then you might take that data, that just the extracted data, and then process that more. You could process that in the Cloud if you wanted or process it all locally, but you haven't taken the core forms that you had anywhere and you control completely how you do that, so it gives people more flexibility as well.  So for those that are like, "Wow! I love this." How do they pay for this is? Is anything changing with how they pay for it?  Yeah, it's a great question. So, in the preview we really wanted to learn about how people are going to deploy and use this. This is a new thing, this pattern doesn't exist in the Clouds.  Yeah basically, it seems like counter-intuitive. Usually you want everything to run it, but those are some scenarios where you want things around the Edge or in On-premises, and this is one of them obviously.  Yeah, and so because of that, we actually, for the preview, we kept the business model and the payment exactly the same. So basically, when you pull that container down and start it, you'll take the same key that you got when you provision the service endpoint, and you can pass that key on the command line into the container, and then it will connect back to the service just to report the trend, the usage, the calls that you've made, and you can do that with the free tier or the paid tiers just like you would if you were hitting the Cloud Service. So the payment model, the pricing, none of that changes. All the documentation and the pricing of the payments are just the same as if you're hitting the Cloud, except for now, you have control over how you use the service.  It's kind of interesting how, like it's a monumental change, it's like the reverse Cloud up and it's like Cloud down, but at the same time, nothing changes as well.  Yeah.  Which is pretty cool.  We really think that the Intelligent Cloud and we talk about Intelligent Cloud and the Intelligent Edge, well this is how we enable that for real right. It's we bring them together in a way that still gives you control about the hybrid nature of your application. I've also seen customers want to do things like, let's say I have an application that for my customers, might need to run in the Cloud or On-premises, and I'm building my application and I want to have that portability, with this approach, I can standardize on these interfaces. I can use it and run it in the Cloud and have that be my preferred environment, because I get the benefits of the Cloud. But if I have a customer that says, "Actually, I love this solution, but I need to run it locally on my own network." I have that flexibility now and I don't have to be swapping out my AI layer just to get that balance.  I see, and so as people are now starting to infuse AI into their applications, if a customer requirements says, "Hey, I need this to be here," it still can be and you don't have to change what you've been doing previously to what you're doing now.  That's right. I don't have to create my own abstraction layer and then have better AI in the Cloud, and worse AI On-premises, because I've kind of tried to cobble something together wherever I don't have the services. Now I can actually just rely on the same EPI, the same functionality regardless.  That's cool because I don't think people realize, at least I didn't, initially, it takes a long time to train these models, number one and number two, it requires a severe amount of data to train them well.  Yeah.  So there's no way that I'm going to be able to replicate with the amount of data that Microsoft has, and the amount of compute power that we have, to be able to replicate the quality of the models that are being put out as a small shop.  That's right. It would be very tough, and in some cases, in some of the models, would be incredibly tough, because we didn't just build these models from scratch in the last year. In many cases, these are things that we've actually worked on for years, and in some cases, decades. If you think about the amount of investment that's gone into Word and understanding language, and understanding the processing text, we're benefiting and everybody's benefiting from all of that investment now, in a way that we probably never even thought would happen, back when our scientists were doing this for Word. But now, we can take that same language understanding capability, and factor that into a service that now you can run anywhere.  That cool. So, this isn't the only announcement for today. I understand there's a couple more. What else do you have?  Yeah. We got a like a whole lineup today that's going to be a lot of fun, but there are a couple other key things I want to show you. So, one is, one of our services that's been getting a ton of usage is Custom Vision. We have a computer vision model that you can go in and hit, and we've trained that to recognize all kinds of things and classify things. What Custom Vision does though, and this is an increasing thing that we see customers really wanting is, it lets you bring your context into the service without being a data scientist, and actually train your own model using our service, that is aware of the context that you have.  Right.  One of the big changes that we've added here for Custom Vision is Logo Detection. So we see cases where customers want to, whether they're looking at images that are coming off of social media feeds, or they're looking at some other kind of product signal that's coming from their customers, they are looking for cases where their logos, or other logos of maybe their competitors, or other things they're interested in, are showing up. So they want know when their products show up in any of that content.  Right.  This lets them upload images of their logos, or any logos that they want to track, and then train a model that will now find those logos in other signals.  Look, I'll be honest. Like I'm an AI guy, I love deep learning and I can write my own PyTorch models for example, but every time, literally, someone's like, "Hey, I want you to do a demo with AI," it's basically already been done in Cognitive Services, and so it's like it's tough because for me as a data scientist I love making new things, but you are literally doing all of the important things. Logo detection, an amazing way for a company to know. Like imagine using Logo Detection in combination with text analytics. Your picture's there, but it's negative comment. You can address that pretty quickly without having to have a human literally look at the feed the whole time.  Yes, that's right. I mean, I wish we had a million Cognitive Services because it's always easier when there's a Cognitive Service that solves a problem for you. It's just so much faster, and we see that with customers who even have data scientist teams. They spend their data scientist teams on things that we don't have Cognitive Services for, because it's just so much faster to do it this way. The other thing is that once you've built the model, if you build a custom, you still have to run and operate it, whereas if you're using Cognitive Services, you get hosted endpoints, you get a whole bunch of infrastructure, we run the service that you're using to host itself 24/7. With the containers work now you can control it and so you get that balance that you wanted and decide the control versus the cost of managing yourself, gives you that freedom or having us manage it for you.  Yeah, because refreshing models with new data obviously takes time and that's already happening in the service. If you're using the container, it also allows you the flexibility to snap to a particular version of the service as well.  Yeah, that's a great point. So, if you have an application that you want to lock on a particular version of the model, you can do that because you control the deployments, and through the container registry, you can see when there are new versions that are available and you can decide when you want to upgrade and change out new versions.  That's awesome. All right. Next announcement.  Yeah. So next one is Local Business Search. So this is a really exciting class of work that we're doing, which is with Bing, and it basically lets applications embed knowledge about the world without also having to embed ads in your application. So we've given you access to basically the power of the Bing index, so it's the power of systems that are crawling the web and indexing the web and also processing all that comes in from that, and turning it into meaningful information, but now just applied to your application. So, in this case, we have Bing Local Business Search.  That's cool.  Yes, actually I wanted to show you a little demo of this. So, if you go to azure.com/ai, that brings you to the main page in Azure that will show you all, give you links to everything we're doing in AI.  Cool.  I'll come down here and just click on- in our "Pre-built". I'll click on "Search" and there's a new component that's been added here, which is the Bing local business search pool. For most of these, what we've tried to do is make it so you could actually go and just try them out right here inside the web. So, We have basically an instance of this service running behind the web page in the docs that you can go play with, so you can actually try it right off the bat without even having to put your credit card in or create an account or any.  Right, that's cool.  So, let's say I wanted to look for pizza anywhere near the zip code of Microsoft here at Redmond. I just type in "pizza 98052" and now I can get a nice little JSON request back that shows me all the pizza places that are nearby. I can do that for any category, pizza, hamburgers, any kind of service. Basically any local business that I wouldn't want to access, and I can embed that right into the application or system experiences that I'm building.  That's pretty cool. I mean you can imagine an app that you have on your phone, and you can literally be like, "Hey, I want to know about blah around." You don't even have to tell the zip code because it knows where you are on the phone you can just send that off and then.  Yeah.  That's pretty cool.  Yeah, and you can put it in the state name or the or the city name or you can put it into lat long values. There are bunch of ways to specify how close you want the information to be related and how far you want to go out.  That's cool. And I know we have a session at the end of the day that's going to go through some of the Bing stuff, but that's pretty amazing. I mean I think it's pretty cool stuff. So, make sure you stay till the end to watch that. Okay, so those are the announcements. Now, I understand because I often look at each service individually, and I start to think about how can I put these, cobble these together into a meaningful application. Do you have any examples of what customers are doing?  Yeah.  With a bunch of services together?  Yeah, that's a great question. So, there's absolutely cases where somebody will take a specific service like search or speech revision and they'll use that just for their application and just use that service. At the same time, the most interesting applications that we see are ones where people are actually combining them, combining different capabilities. It might be a new interface or it might be insight over multiple types of media like audio.  I see.  Imaging and text. But they're doing it across a huge range of scenarios, and that's really speaks to the universality of machine learning and how profound of an impact it's having on all of the kinds of apps that we can build. But just to drill into a couple specific ones. So, this is an example I want to show you of a system that I might use to analyze and track customer sentiment. So, I would have speech to text coming in either from live agents or from call logs that I've got, and there I'm transcribing the speech into text so I can process the text. I might even translate that if it's coming in in different languages. I can use our translation service to do that. I can also then run text analytics over it, so I can extract the entities and do what we were talking about before, get the key phrases and things like that out of it. I can use our content moderator service, so I can understand maybe I want to extract offensive material out of the feed for example, and discard data. Often, what we'll see where people use that is sometimes it might be displaying feedback back into the application, so they let their users participate in the community, but they don't want people uploading things that are not in line with the values of the application.  Right.  Then, I can connect that up to feeds. I can look at my social media platforms and other sites data coming off of my site, and I can put that all into things like Cosmos DB maybe aligned with my transaction system, and then have Power BI dashboard's reporting on that. So, what I get at the end of the day are basically the key things people are saying about my products across all of these different signals.  That's actually really cool. I mean because generally, you would hire somebody to just look through feeds. But now, you can have an AI look at it and the human actually look at what the output of the AI is, and then say, "Yeah, this important. No, this isn't important."  That's right. I mean we really want to enable people to do fewer boring things and focus on the things that are most interesting and the highest value, which is the key decision-making, the trading off why, why are we seeing people happier with this product and less happy with that product.  All right.  Product? Why are we getting that feedback? Getting at the root cause, and then improve the experiences that they have.  Awesome. Well, there's some questions coming in. But there's like a modal dialog box that someone's going to need to click for me. So, don't get rid of the questions yet. Here's a question from Martin. How do you protect my data? Does Microsoft use my data to improve their AI?  Yeah, so we actually we don't. In Cognitive Services, we've specifically made a decision not to use a customer's data other than the Bing services which work more like Bing you're just-  All right.  Because you're sending a query into the system. So, you have complete control over your data, and what we do to improve the models as we go specifically, we either buy or build the data that we need independent of what a customer does.  I see. So, we're not using their data?  We're not using their data at all. In fact, and even with the container work, we won't even ever process their data, we won't even ever go through our systems. So that shows how far and how seriously we take that is we've designed into our service patterns now the ability to give our customers complete control, so they don't even have to send the data to us to be processed if they don't want to.  That's awesome. So, if you're running this service in a container, the only network traffic you'll see from the Microsoft container is this is how many times they used it?  That's right.  That's awesome. Okay, when is Cognitive Services going to support my language, Dutch?  Yes, that's another great question, and it's similar to the region conversation that we had where you look at this you go, "Oh my gosh, there's so many things I could do, but then I have a need for a language that's not supported." So, we have a tiered set of investments we're doing where we're going across all of the Cognitive Services, APIs, and adding language support for them. I don't have a specific timeline for Dutch, but I was actually just in the Netherlands a month ago, and we meeting with a bunch of folks. It's very clear to me that there's a significant demand for Dutch, and that is definitely on our radar.  Okay, next couple of questions because there's a lot of them. What does Cognitive Services do with- And I want to ask this again for emphasis because-.  Yes.  Someone else. What does Cognitive Services do with my data? You must be retraining your models on my customer's data.  Yeah, we're actually not doing that. Originally, when we first launched Cognitive Services, we actually did have terms that let us retain the data for training and we made a decision to specifically not do that anymore. We changed the terms of use, and so for all of the models except for the Bing models, for all of the rest of them, we actually we don't use the data, we don't train on the data. It's the customer's data, and that's a really important promise to us.  That's cool, you said Bing. But basically, Bing is crawling what people are putting publicly on the web.  That's right, and it's if you think about the way a search engine works when you send a query to a search engine, it processes that data to give you an answer back.  Right.  Then, the search engine itself is built to learn based on what people are asking for it.  Right.  Then what they do, what links you click on after you get the results back. So, it's kinda inherent in that system.  Are there any particular vertical industries you think resonate well with Cognitive Services portfolio, financial services, retail, media, and entertainment? I feel like the answer is yes.  Yeah, I mean it's like we're talking about before that, there are so many applications. Let me quickly drill in on one other which is this knowledge mining.  Let's do it.  This is one what we see a lot for finance health care and retail, which is people being able to take a bunch of models, run it over all kinds of content, and then extract meaning from that, and then actually get that view across all of the content that's really a higher-level semantic view based on what the models have learned. There'll be a session later today to dive deep on this one.  Awesome. So, where can people go to find out more and to actually get started?  Well, so for one I would say go to azure.com/ai, and that's a great place to start. Then, today there's actually a whole set of sessions that are going to dive deep into a bunch of topics, go into computer vision. We'll go into knowledge mining. Talk about speech and the Bing services that we just talked about, translator and content moderator. So, there's a bunch of actually great sessions that we're going to go through today.  Fantastic. Well, make sure you stay tuned. Coming up next, we're going to be talking about getting started. Our computer vision made easy. We'll be right back. Also, before I go, submit your questions, we are taking questions online. We'll see you after a tiny break.  Thanks. 