 DR. PAUL SAMMAK: Enrico Gratton is a professor at UC Irvine. He has been the director of the laboratory for fluorescence dynamics for a number of years. He was instrumental in developing lifetime imaging, back in 1980 and has been at the forefront of studying cell dynamics, using both live imaging and fluorescence. In particular lifetime imaging, where you can look at the change in very, very short times as fluorescence decays and use as an indicator of environment. Enrico? DR. ENRICO GRATTON: Yes, I don't know if you can see me, but I have a screen and my presentation. Can you see that? DR. MICHELE MCGUIRL: Everything is great. Go ahead. DR. ENRICO GRATTON: Okay, so I will talk today about the dynamic super-resolution in optical microscopy and I will define a little bit what i mean by dynamics, and what I mean by super-resolution in optical microscopy. And in this beginning slide, you have two images in the… I don't know if you see my mouse moving… and so on the left you have something has been acquired very recently, which has to do with the formation of  liquid liquid phase separation in the nucleus. And here the problem is to see molecules when the molecules came in or out of the structures, and if those have any biological significance. On the right side, you have an example of a technique, which we call Spectral Phaser, which means that we can do spectral imaging of every image that we can see. And that will be very important for what I will say in in the context of this talk. Okay, so first of all, I want to say something about super-resolution. So, super-resolution is the ruler that is used to indicate that the resolution that you can obtain in an image, is about on the order of about ten, twenty nanometers as being done today. And that is far better than the diffraction-limited resolution, which is about a factor of 10, between 100 and 200 nanometers, that you can obtain with normal microscopy and confocal microscopy. Why is that important? It is important because life, which is what we are trying to understand, and to look at the various phenomena is made of biomolecular reactions, and the biomolecular reactions occurs at the scale, which is really the nanoscale. So, if you look at the image at 200 nanometers, you cannot really recognize the molecules, which are involved with the chemical reactions. But super-resolution imaging has been used for, it's mainly used in order to obtain I would say standing images, but very little has been done, except for a few labs, in order to obtain dynamics, which is the basis of life. So, in our research at the P41 Resource Facility, we have been working in part to filling the gap by developing, what I will call enabling technologies, that will open the potential for super-resolution imaging to dynamics in the microsecond to millisecond timescale. And you will see what those enabling technologies are, probably or not they were known, but I hope after my talk you will understand what we are trying to do. So, and I will describe in this webinar the technology. So, first of all, what we have done is the following thing. We would like to acquire information about the number or location of many molecular species and that can be proteins, can be NADH, it can be ATP or whatever, in a cell. And I want to, we want to be able to do that at a very small volume and, in these very small volumes, to acquire many different parameters. And then, for example, we want to also use different techniques like multi-photon imaging, because multi-photon imaging penetrates in tissue much more than normal one photon excitation. We would like to have the capability to do fluorescence polarization, fluorescence lifetime decay, hyper-spectral imaging, and spatial correlation of fast fluctuations. Why is that important? Because that will give us, like in a single image, in a single recording, the information about the many events which are the basis of life. How do we reach that? Why have people not been able to do that? Well, because essentially, if you want to have a camera, that can look at many pixels at a time, the camera has to be fast and the cameras that we are using at the present time can obtain in terms of frames per second, which is a familiar parameter to indicate a camera, can obtain a million frames per second. So this is not a mistake, this is the capability to obtain all the parameters I am talking about in this part, but at a rate which is really incredible, and with high resolution, and with the possibility to measure many parameters at the same time. How does it work? So, it works, and you can see here, something that you imagine that you have a solution at the microscope. The point spread function, you can localize in an area which is here described at this hexagon. At the hexagon, you have the fiberoptics in each one of those coordinates of hexagons. You have the fiberoptics that then, is imaged in the camera and this is the picture of the camera. So, this camera has eight by eight elements, eight by eight elements, actually, not all can be used in a hexagonal shape, but most of it. And then each element has an output which is counted, and using this, this output as I show in the next slide, we can obtain information at every pixel of the camera, and in every pixel of the camera, using electronics developed in a part of my lab, but other labs have them also, and you can obtain information about the decay time of every species that you have there, on the nanosecond time scale in every single element of the camera. And then, in order to, use spatial information, you can use for example, two of those cameras, and in each camera… So, the sum of the two cameras will have, like, 180, 128 channels of lifetime. And this is something I think that nobody has done until now, but this is essentially almost a commercial instrument. So you start from here and you have a laser, and we use most of the information that is obtained with, in this case with the white laser unit. The white laser unit produces some pulses of light, which are about ten picoseconds which is not femtosecond so you cannot do two photon excitation. And then then it goes in a unit, which is the STED unit, and this is very important. So, the STED unit is a unit that will give us the super-resolution, basically the STED principles I will show you in a few slides. Then once the light is either passed through the STED unit or not, it will go to the microscope. And the microscope has a scanner, on which you can center the image and then acquire the image with the microscope. The fluorescence light which is emitted by the microscope is going to this detector, that will cull the best particles. It looks like, if you look at them, they look like the eyes of deer, big. So what is the, advantage of doing something like that? So, the advantage is that we can obtain a really very large number of chemical signals. And this is key then because you can read every element of the detector in a microsecond. So, everything in parallel goes to what we call the FLIM box. And we can obtain all the information I said before the location, lifetime, spectra and so on, directly but at the very high speed, and every pixel of this camera is measured separately in the FLIM. So, for example, we can obtain fluorescence decay at every pixel, the fluorescence spectrum at every pixel. I talk here specifically, spectrum, not only a wavelength selection, image out through push among all the pixels. So, for example, situation with including one pixel with another pixel and so on. And so that will give us an idea of where molecules move and it will show some examples about that. So, all the parts are commercial, are available today, so the detector, you can buy, a white laser you can buy. Essentially, it's a question of assembling and maybe to have the software to run everything. And for visitors at our center, all these instruments are ready to be used. And are used very much today. So the next slide shows some examples, and I divided the examples in three kinds of examples. In the first example, we want to exploit the content super-resolution. So, I mean, that in the same fixed cell you can measure many different molecular species, and that will give us an advantage because we can obtain information about molecular species responsible for a given biochemical reaction. Or, in this case, you know, it's causing fibrosis in the bone and you can obtain that over a relatively large area. So, this is, this is not an error again, this is two millimeters. So, those bones have on the order of 12 millimeters, something like that so it’s a relatively large sample. If you pay attention, you see that, like, regions in which we do tiling in order to get this information. What is painted here is the following thing. So it’s essentially information we want to extract from every pixel of an image. Now collagens have a combination of fluorescence and most collagens are fluorescent too, if you have enough sensitivity to see that. And produce second harmonic generation. But the fluorescence and second harmonic generation comes to exactly a given wavelength but the fluorescence can come to a very different wavelength. So, by combination of the emission filters or by using the special detector, we can separate all the different types of collagen. And so you can see here in a bone, you can see, for example, second harmonic generation, which is that signal here, how it forms and then you can see all the interior which is a different kind of collagen, because it has no second harmonic generation but it has fluorescence and so on. And in this example, you see also here, that by measuring separately the different molecular species, you can theoretically obtain maps of the different molecular species. For example, this is a map of fibrosis in a kidney in a mouse, and you can see the fiber painted in green, and when you take a normal mouse, the left one, that is the control and you can see very, very little of those fibers. So, to give you an idea, the acquisition of time, whatever, is about a few minutes in the fibers are detected only by selecting molecular species that you want to see. In other labs in which they don't have this capability, for example, the fibrils are obtained by artificial intelligence processing, which you can trace the fiber in this structure. Of course, you have to instruct the computer to do that. And then, you know, clearly, this is an entanglement of many, many fibers. So it's very difficult to obtain. But here, the resolution is obtained directly by telling the computer to plot to one particular species. And that is really what I meant by content super-resolution based on spectral and lifetime data. So, you can see that you can measure specimens that come from clinical studies directly, with our instrument and this is a collaboration with Drs. Moshe Levi and Suman Ranjit. and this is one of the original papers, also, Ron Evans from Scripps Clinic was involved with us in this research. Okay. So, let's go to the next example. So the next example requires a background, which I will try to do in only one slide. It will tell us how we measure the decay. So suppose here you have the decay, which has a lifetime Tau-1. Okay, so that Tau-1, so it can be represented by a transformation, which is called the phasor transformation, which is nothing, but a Fourier transform in the angle and the interface. The angle will be smaller, the shorter is the lifetime, in this example for example, than for a longer lifetime, so, a longer decay. And the modulation has to follow, it has to be if you say a single exponential, around this universal circle. And this is just a simple transformation. And you say, why do you want to do that? Well, we want to do that for a very simple reason that, being the coordinate of this point, if it gets transformed, that means that the coordinates are orthogonal one to the other, and then we can apply the law of linear combination of phasors. For example, suppose you have a phasor which is in this position, and that position can be for example, free NADH in solution and it has the lifetime of 0.4 nanoseconds. So it has a very low phasor, but when it binds to a protein it becomes much longer, say, 3.4 nanoseconds, for example. And that would be the point. Now when you measure in a pixel of a cell the combination of the free and unbound NADH, which is one of the indexes that we use, you know, for the metabolism of the cell, you will get, for example, a distribution of points, which indicate that different pixels in a cell have different ratios of bound to free NADH. Now that ratio, it's very important, because it’s related to a metabolic index. So if that distribution will move toward NADH-bound, that means you have more oxyphos kind of metabolism. And if you move in the other direction, you will have much more of the glycolytic kind of metabolism. So just by looking at this ratio, which is obtained with only one line of the laser, well, this is second harmonic generation, then you can obtain an index, which moves along the line, and you can determine with good precision, not only what is the average of every single cell in your field of view. But also, in within a cell, you can separate the mitochondrion from the nucleus and all the different compartments of the cell. So this is the use we make of the phasor and then you will see more, later on. So now, the question is, in this case, for example, you can see very clearly that we can distinguish one lifetime from another lifetime. What if we have others? For example, you see that combination that which indicates that there is another Tau. Well, we can, using software that was developed in my lab, you can distinguish three or four or more different solutions. So let us make an example that we use in a steady instrument and those are various kinds of Alexa, this is Alexa 647. This is ATTO 647. We use those two probes, because those are useful for cell resolution. So suppose you have those two probes and you can see if you have just in solution they occupy two very different places. If you use those two probes conjugated with DNA, and then you pattern a cell, well, you will see that, actually, they form like a cloud that goes from a point, which is the autofluorescence of the cell, of the particular cell. And then you but nevertheless, you can distinguish very clearly where the ATTO 647 is, where the Alexa is and maybe the combination of the two, because they give us completely different patterns and, you will see later on how that is. Okay. So, at the present time, based on lifetime, so you can have one, two, three, four, five, five lifetimes, and then you can have also different spectra, because they have some molecules that have different spectra. So we can distinguish about 20 different, in this case, DNA conjugates. And then, that, of course, is very important for analyses of for genes in single cells. So, let us see how that is useful in the following slides. So suppose we have three probes, one, which is, for example, ATTO, and Alexa and one which is the ATTO, and one which is a combination of the two. So you can see clearly that the probes have different lifetimes. And then, you can separate, for example, and paint in 3 colors, the blue one there, the green one and the yellow one. In this case we use an algorithm which is based on artificial intelligence. But I can tell you that you can distinguish by eye those three and trust them very well. The reason to use artificial intelligence is because you want to make many many elements when we use super-resolution of the cell, and then you will need to analyze many, many different points. And although you can see by eye where the differences are between those two probes, you cannot really beat the speed of a computer that will in a few whatever microseconds will tell you how to classify those three lifetimes. Then you can paint it or color it, that will be for that particular DNA for this particular case it’s RNA that is found. The other one is found and the other, and then you can do 3-D. And then here is the example, for example, what you see is time 1, time 2, time 3, those are different number of cells. These are the dyes that we were using. And this is the gene, a specific gene that we were trying to understand what it is. So, up to this point, I think that they are commercial instruments that can do equal or better than what we have here. The point is first of all, this is only one measurement. So we don't have to wash, to have one kind of DNA or another kind and so on. It's not essentially the same thing. But here the advantage of that comes, when you can apply super-resolution techniques, like, for example, STED. So STED, in the STED measurement you have an excitation beam, which is shown here in blue and then you have a depletion beam in which you deplete all the molecules which you have excited with the excitation beam, except a very small area. That small area can be made as small as you wish, depending on the intensity you use in the depletion. So, for example, this is a piece of an image that was in the previous slide. This is the dimension of this image. And you can see that, here you have something that you believe is, might be one RNA or something like that maybe you have enough. But when you look at the very high resolution, the resolution which is given by the STED dimensions, you can see that actually that was not one but the one, two, three, four. And that was not one, but was two and so on. In the distance, so the resolution that you can use, because you have lifetime, this particular case is on the order of 15 nanometers. So this is, those points differ one from the other by a very small distance. This is important, because you would like to know if the genes are expressed within a given part of the cell are really the same; if one gene is expressing in the other part, or in the other side of the cell. So if the proximity one to the other has any kind of advantage, or would produce different proteins in the data. So, when you look at this image, you say, well, yes, really that is different than just counting the number of spots that you see in this image. And not only, but you have a resolution, this resolution is on the order that you will need in order to see splicing if they are of the same RNA. Okay, so go to the next point, which is the other example I want to show which is in collaboration, with Hao Jiang from the University of Virginia, and in which we want to track what happens in the borders, or at the interface between the liquid and then the rest of the nucleus in this particular case. And it is known that if you FRAP or you bleach one of those phase separations, it recovers in some kind amount of time. But this measurement doesn't tell you where the molecules that have recovered are coming from. So, the question is, can we look at a stationary equilibrium at one of those spots and figure out where the molecules are coming from? So, here, they have two different mutants of the same protein, in which we can see, for example, by polarization, which means a measurement of homo-FRET, which means proximity of two molecules. It is different from one mutant than the other. This is again, one more example of the kind of measurement that you can do in those liquid liquid phase separations. And then you can obtain fractions, you can obtain a partition coefficient and all the others. But still, that doesn’t… it is telling you that what is the status of the particle. So, yes, you can have FRET, more FRET or less FRET, but it doesn't tell you, what is on a common pathway. So this can be done by another technique, which is based on the dynamics. So, the dynamics means that you measure the fluctuation at one point, for example, here, in another point and so on and you see the molecules that are producing the fluctuation moving in the image. For example, this is, in one of those spots, is the intensity. But if you measure the anisotropy of the motion, which is anisotropy of the diffusion, you can see, for example, that there are barriers in some of the regions, and there are barriers because, because simply the molecules are moving one in one direction and cannot cross that. But there are other regions, for example, in which the particles can, the molecules can move in. And then you can obtain a map of what we call the connectivity of the cell, which means how molecules will move in the presence of obstacles, which is something that is very difficult to measure with any other method as far as we know. Okay, so this is another example. So, in conclusion I want to thank all the people in my lab and in particular, the people who do some of the experiments: this is Rupsa Datta and Suman Ranjit, and Alex (Sasha) Dvornikov, who did most of the development of this kind of microscopy. And that's all. I want to say that we are part of the National Institute of General Medical Sciences. Our lab is called the LFD, you can find our lab on the website, simply Google LFD and you'll find all the activities that we have and how to get access to our center. Generally, it is very similar to what you do for a synchrotron radiation. So you say you send a proposal, there is a committee that will review your proposal. You discuss the proposal if it is feasible or not and then essentially you can come and do your measurement in our center. And I think this is the last slide. Thank you very much for your attention and thank you for giving me the opportunity to talk in this webinar. 