 holographic displays are an enabling technology in virtual and augmented reality because they have the potential to solve many long-standing challenges of near-eye displays a hologram is produced with coherent laser light that is projected on a spatial light modulator or slm which delays the phase of the wave field in a programmable manner as the field continues to propagate it creates interference patterns that are observed as an image by a user for example in a near-eye display computer-generated holography algorithms convert target intensity plane to a phase pattern on the slm direct methods propagate a wave field representing the target image to the slm and convert the complex valued field there to a phase-only pattern iterative methods propagate the field back and forth between source and target plane until an optimal phase pattern is found for a specific target intensity direct methods are typically fast but offer limited image quality iterative methods are much slower but offer better quality in this paper we propose cgh algorithms based on variants of stochastic radiant descent that outperform all existing cgh algorithms moreover we develop a neural network architecture that achieves image quality comparable to the best existing iterative methods in real time here we see a comparison of several iterative methods in simulation all methods work well with sgd mitigating remaining artifacts like noise unfortunately it is very challenging to achieve comparable image quality with the physical holographic display small amounts of phase distortion on the slm and optical operations as simulated here cause a model mismatch between the light transport used for optimizing the phase patterns and that observed in the experiment thus in practice all methods fail at actually achieving high image fidelity our sgd solver has the capability to account for this model mismatch typically we simulate the observed image for a given sln pattern compare it with the target image and back propagate the error into the phase pattern with our camera in the loop procedure we capture the image produced by the phase pattern with the camera compare that image with the target and back propagate the error using gradients of a differentiable proxy light transport model back into the face patterns compared with the idealized light transport model this camera in the loop method achieves vastly better image quality we explore variants of this procedure that train an interpretable light transport model of a specific hardware setup using a data set of images this model calibrates source intensity variation on the slm non-ideal propagation and other optical operations and parameters in a fully automatic way once calibrated a camera is not necessary to synthesize new holograms as seen in this example this camera train model achieves a better image quality than the state-of-the-art cgh algorithms here is another example scene that compares iterative cgh algorithms our camera in the loop procedures achieve the best quality we also propose an efficient neural network architecture that can synthesize high quality holograms in real time for this purpose we pass the target amplitude into a target phase generator network then apply a multi-part propagation based on the calibrated model to the resulting complex valued field finally we predict a phase-only pattern with a phase encoder network when training this network we additionally simulate the image reconstruction with our camera trained model and back propagate the error into the network parameters this network-based image synthesis achieves significantly improved image quality over real-time methods here are several additional example scenes to demonstrate that our camera in the loop image synthesis is robust to viewpoint shift we intentionally move the camera a few millimeters horizontally relative to the display as seen here the results still retain high quality we also extend the proposed algorithms to 3d holographic display modes first we demonstrate the ability to operate at multiple distances using a verifocal display where a 2d image is shifted in depth next we show the captured focal stack of a multi-plane hologram where multiple display planes are synthesized simultaneously and refocusing is successfully validated at three distances with our work we take first steps to combine classical cgh algorithms and optical systems with modern machine learning techniques to address several long-standing challenges such as speed and image quality we believe that our work paves the way for a new era of neural holographic displays 