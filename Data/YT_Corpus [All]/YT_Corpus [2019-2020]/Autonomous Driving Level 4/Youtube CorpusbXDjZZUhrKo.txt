 Ladies and gentlemen, my name is Andrei. I'm a  postdoctoral researcher at Aalto University   and I will coordinate today's event. This event  is kindly organized by Krisztina, Saara and Otto.   This event is brought to you by Aalto Center for  Autonomous Systems, in short, ACAS. Please visit   ACAS' website for more information. Today  we're talking about autonomous driving. Let me introduce the speakers. The first talk  is a group of speakers from Sensible 4   and all of the speakers are graduates from Aalto  University. Virve, technical project lead. Tuomas   Sauliala, technical marketing manager, and finally,  Antti Kangasrääsiö, head of research. Sensible 4 is   a successful and very ambitious research-driven  startup. They know about autonomous driving more   than anyone else because they challenge harsh  weather conditions. Their talk will be about   the state of autonomous driving: the history of  self-driving in Finland will be presented. It   also includes present and future opportunities for  this ambitious area. Also, they will elaborate   on cooperation opportunity between universities  and industry. The second speaker is professor Ville   Kyrki from Aalto University, professor at school of  electrical engineering and head of the Intelligent   Robotics group. His main research interests are  intelligent robotic systems and robotic vision. This talk will be about AI challenges for  autonomous cars. Machine learning and other   artificial intelligence methods are an essential  part of autonomous driving software stack. He will   speak about the challenges these AI methods face  these days. Please, people from Sensible 4, the   floor is yours now! –Okay, hello everyone my name is Tuomas Sauliala, I'm starting my presentation here if I manage,   So my name is Tuomas Sauliala, I come from Sensible 4 as mentioned. The presentation topic for today is the state  of autonomous driving. With me I have Virve Leino and   Antti Kangasrääsiö here, as mentioned, they'll be having  their talks within some minutes also. What we have as an agenda, well first of all,  I'm going to tell you who we are, Sensible 4   as a company, where we come from, something about  our history. Then Virve Leino will discuss the   actual products what we actually do here and  then I'm going to tell you briefly how we see   the future of autonomous driving globally and  here in Finland, locally. After me and Virve, we   have Antti Kangasrääsiö, a doctor of science from  Aalto University discussing the actual science   of autonomous driving and what the university and  industry may be doing together in the near future. Some words about myself. As mentioned  by Tuomas, I have done my studies at Aalto   University, which was then known as Helsinki  University of Technology. My department was   electrical engineering, but after the school  I've been mostly working with communications   and marketing activities in the Finnish IT sector,  automotive and electric   engineering, put it that way, and electric vehicles.  Then about the Sensible part. Who we are – Sensible 4   is a relatively young startup company. We're only  3 years old. The company has been founded in 2017.   When I joined this company last February,  like eight months ago, we had less than   30 people working at Sensible 4. Now we're  95. So the growth has been, should I say, fast.   The roots of our company are deep in Finnish  science and research mainly at Aalto University.   I'll discuss that a bit later. Considering  the growth we have had, I'm very happy about it, considering the tough times we have right now  with COVID-19. Sensible 4 is a software company.   We use sensors, we build cars for our own  product development, but at the end of the day, we   are a software company. We don't make sensors.  Virve will tell more about the actual product briefly.  I'd like to highlight our pilots. With the pilot,  we mean our vehicles, driving there on a public road   with real passengers, we have had multiple pilots  in Finland: in Hämeenlinna, in Espoo, near the Nokia   headquarters in Vantaa, and last spring we drove  in Helsinki Pasila area, so-called FABULOS pilot,   a European Union project. This year later, we're  heading abroad with our first pilots in Norway   near the Oslo capital region, and then  near the city of Stavanger, western Norway.   i'm really looking forward to these two pilots.  Later, maybe next year, maybe later we're opening   even further pilots in Japan, in  Dubai and in a European country. Next I'd like to discuss something about the  early days of autonomous driving in Finland.   As mentioned, in  Helsinki and Finland,   we have long roots of autonomous driving  research. Already in 1980s, when I was born,   the very first robots were researched at Otaniemi  area, at the Helsinki University of Technology.   These vehicles, these self-moving devices  are the very root of Sensible 4 and   our current status of our products – I'd like to  show you this one, let's see if I can mute it  – This one is driving in 1993. You can see the  vehicle is super slow and the devices, or   the sensors on top of the vehicle are quite big  compared to the ones we have right now. But still,  this vehicle drove long before Google was  even invented, or the DARPA project started in the US. Another project which I can show  you is this one. This one drove in 2007.   You can already see that the sensors are  way smaller, pretty much the size we have now,   the vehicle is moving faster, and  there really is a bad weather right there.   This is actually taken in Helsinki. Doesn't look like a capital but that's what it is.   So even though our company is only three years  old, we have a long history of research in Finland   regarding self-moving vehicles and robots.   And for the next speaker, I'd like to invite  Virve Leino please, about the driving kit. –Okay, and thank you Tuomas, nice  to be talking here in this ACAS event.   So my name is Virve Leino and I've graduated  from Aalto University as many of us here   at Sensible 4 are, and I was majoring in  software engineering and computer science.   For the last years I have been  working in autonomous driving industry, first   in California and then in Sweden, Gothenburg, and  currently happy to be working at Sensible 4.   So my topic today is our product. So what  we do, our product is an autonomous driving kit, and to start on a high level, if we think  about building an autonomously driving vehicle,   I think it's basically a robotics  problem. So what I mean by that is   that first, the vehicle needs to sense its  environment and it's using multiple sensors   to do that, then the vehicle is thinking, processing  this data it's receiving from the sensors.   and third, it's using actuators  to actually drive on the road   at Sensible 4, we are doing the thinking  part, this Sensible 4 autonomous driving kit. But if we start taking a  more closer look at the center first,   so first there are these line-of-sight sensors, LiDARs, radars and   cameras, and those sensors are perceiving the  world around the vehicle. Perhaps   some explanation about LiDARs if someone  is not familiar, so LiDAR is 3D,   imagine, a light imaging sensor  is sending actually light beams, a   multiple of those, 40–42 light beams  for example, and those light beams are going around   the center of 10 times per minute and the LiDAR  is producing a 3D point cloud from that data.  Then if we take a look at the other type of  sensors, there are these position-related sensors, some examples are GNSs, so  Global Navigation System. For example, GPS is that kind of   measurement. Then we have RTK, Real-Time Kinematic,  and that we are using for example at Sensible 4   to make the location more precise. And then there  are other sensors, position-related sensors as well,   IMU, the Inertial Measurement Unit,  and odometry, so for example   we are automatically measuring how many  times the wheels are spinning around. If we can move to our software, so  in addition to these typical sensors   you can also think that there are other kind of  sensors the software is using, map, and then our   software is knowing the route or then it  can get the route from the remote control   center and it can also receive other kinds  of commands from the remote control center.   The last step is actuators: steering, braking and  throttle. That's very familiar to all of you so   let's take a closer look at our software  kit. It actually contains of four parts,   first there is this position stack. The main target  of this stack is to know where the vehicle is located.   Then we have obstacle detection detecting both these kind of like moving objects   and also stationary objects and making  sure that the vehicle is not colliding   with these objects. And then at the end, we have  control stack. The control stack is then doing the   final decisions regarding the path the vehicle  is taking, and then controlling these actuators. Then this box on the top of these  three stacks is a remote operations and fleet   management API. So API is Application Interface,  and we are concentrating on building mainly the   application interfaces, and we prefer third  parties to do actual remote control operations   and fleet management. In some cases, we have been  also doing the remote operations ourselves.   And at the very top of this picture  you can see the Apps for Travellers   So by that I mean these phone apps, for example   that travelers, basically all citizens can then  use to order trips from this search,   most preferably electric shared  vehicles and autonomously trained vehicles. Okay, that was that on paper, but let's now check  how this kind of like autonomously driven   vehicle might look like. This is actually  our first autonomously driven vehicle.   It's called Juto, we always give names to these  vehicles. The vehicle itself is produced by Renault.   It's this kind of a mini vehicle, electric and  two-seated, and actually the model name is called Twizy.   But then what we did at Sensible 4, we actually  made this Twizy drive autonomously. And there is actually a term for that, so it's  retrofitting. And in this retrofitting process   the first step is to add the sensors to the  vehicle, then we added a computing platform   and our self-driving kit, and then we, as a  last step, connected that self-driving kit   to actuators with drive-by-wire. The drive-by-wire  system is this kind of system where you can   use software to control the  actuator, so steering and braking and and so on. So, a small explanation about these sensors  we installed to this Juto: Lidars for   example, one in front and one in the back  of this vehicle, you can see those, one   Lidar for example near the front lights.  Then we had short and medium range radars   and you can see radars between the middle front  wheels there, then we like to have a 360 degree   camera system because that's very handy  when we take over the control from the remote   control center, and then we also tested thermal  cameras. Thermal cameras are very handy in the dark   environment when you can see warm objects,  so for example, you can sense   pedestrians for positioning. We used RTK and GNSS, and those you can see   on top of the vehicle, and also IMU, this  Initial Measurement Unit, and an odometry.  Those are inside the vehicle. And last, there  was this 4G/5G connection, and that we need   when we are taking over, in some cases  with the remote control center. Okay, so I guess it's interesting to see  how this driving actually looks like, so   let's take a look at one of our  demonstrations, which is actually in very   harsh winter conditions, and that we are actually  very proud of. So it's recorded already   two and a half years ago at Otaniemi where our roots are   from many points of views, our founders are from  Otaniemi, many of us have been studying at Otaniemi,   and Aalto University, but of course we  have many employees coming from all around the world, like at this time, 20  countries where our employees are from. But this   demonstration is about winter driving and SLAM  object detection and localization, but let's   start the video, and I'm explaining as we go. Okay  I guess it's here and let's hope that that starts, waiting some seconds what do you think Tuomas, is the video  starting, do I need to push something, okay Okay and here we go, thank you Tuomas. So  this is about winter driving actually at Otaniemi,   and as you can see, the planes were really  invisible and the weather was just awful, yeah, that was a good  winter to test our vehicles. Okay, there the Juto is driving, and on the  right hand upper corner you can see the Lidar   in the same way as  Juto is seeing it. and it's able to keep the lane  very well already at that time. The next demonstration is about SLAM, so  simultaneous localization and mapping.   In the screen, you can actually see  the map, and the vehicle   is building the map at the same time as  it's driving, in our case it's   updating the map as the map has been already  given to it. It looks perhaps a little   bit funny, but this is actually very  very good way of doing the localization. And then one of the cases  was this obstacle detection.   Our vehicles are of course using other sensors  as well. In addition to this Lidar, they are using   cameras and radars and... Now Juto was  able to yield these pedestrians quite   nicely, and it's due to the fact that it can  understand what objects are stationary and   which objects are moving, so it's  then extra careful about those moving objects.   and the last demonstration is about this localization,  somehow this vehicle is actually able to keep its   lane, so it's comparing its Lidar cloud, which  you can see in the screen, to this   NDT map which is on the right hand upper  corner, so this kind of a normal distribution   map, and by comparisons it can understand  where it's going and   that's very exact, I would say that it's more  exact if you compare to human drivers.    So this is nice, and there are some pictures  about Juto after the winter driving case.   Okay but that's all from my side,  then I guess it's, Tuomas, your turn again. Yes, please. –Thank you. Next, I'd like to discuss briefly  about the future of autonomous driving,   how we see it at Sensible 4. I have only one slide, don't  worry, this won't take too long. There are a couple of angles which I'd like  to bring out with this topic. First of all,   we don't believe that we are going to have fully  autonomous, so-called level 5 autonomous vehicles   with zero assistance from a human being anytime  soon. I would say it would take years or   maybe even like decades to develop such a vehicle. The future of autonomous driving will most likely   happen in restricted areas, in predefined  routes, in so-called restricted operational domain   when we can set the rules of driving a bit, should  I say, narrowly compared to fully autonomous driving. The sensor stack, the computers, and maybe the  software will cost some money, so it's quite clear   that the use case of autonomous vehicles will  be somewhere where the need is big and the   predefined routes are already existing, so it's  quite clear that the very first commercial   applications will be public transportation  with the last-mile shuttle bus application.   And for us Finns, it's quite clear that the  vehicles need to be able to drive in all   weather conditions. In Finland, we have at  least six months a year really bad weather,   rainy, slushy – hopefully we have snow –  whatever vehicle we have, whatever the public   transportation solution it's going to be, it needs  to be able to drive in all weather conditions.   And when it's not able to decide if the  vehicle can go forward or if it needs to   change the lane or something like that,  it needs to have functional and working   remote assistance when needed, or remote  control if you want to call it that way. In this sense, I believe that autonomous  vehicles will not enter the normal   passenger car world anytime soon. It's going to be  professional and commercial applications for sure. Okay, this is the end of our first section.  Do we have any questions at this point? –Yes, Tuomas, thank you very much for your first  part. We already have a number of questions, so I think we can take a short time to answer those  questions. So the first one: Did you develop the   remote control center or did you give some cloud  robotics platform like Freedom Robotics a try?   –Uh well the answer – would you like to  answer – I can of course start so,   yes, mainly we believe in doing and building  things together, so that's why we like to work   with partners. So mainly in remote operations,  we are concentrating on doing extremely   high quality application interface so that we can  work with partner companies. We also   have an implementation of this remote operation  center ourselves and we are of course testing with   our own implementation and so on, but at  the end we would like our partners to do that part. This company that was mentioned there, we  haven't tried out their solutions, but for   example we are working with – I guess I can say  this – Holo, which is   one big operator in the Nordics, so we  believe in collaboration there.   Yes. –Thank you. –Thank you. –The second  question: What is the speed limit for Juto?   –As far as I know, it's 40 kilometers per hour  right now. It's actually the speed limit of all   our vehicles right now, 40 kilometers or 25 miles  per hour. –And I can also add to that   that's what we have been driving, and a little bit faster as well, but of course   it's not safe to drive super fast, but  of course we are trying to push the limits of   these vehicles and testing what they are capable  of. But this 40 kilometers per hour is,   based on current understanding, a very  good speed to drive with our vehicles, and   that's this kind of driving that we are now focusing on, we are not focusing on   highway, a very fast-speed driving, but we are  mainly focusing on this kind of like shuttle bus,   and providing this transportation for cities and citizens. –Next question in the quotes: I understand  that you also did a cooperation with Nokia   to deploy 5G for autonomous driving. Could you  describe your partners and customers? –Well once again, maybe you should take care of it [laughing] –Yeah, I don't know about all of our customers, it's  under NDA as well, but we have   many customers and are doing multiple  pilot, and Nokia was mentioned there, so   Nokia is one of our partners and  we are doing, for example, a project with   Nokia, I guess this 5G, I guess last  week you were talking about this Luxturrim   for example, that kind of project that has these  smart poles and this smart city infrastructure   actually deployed at Karamalmi area, so actually  we are part of that project as well   and as Nokia is there, so the 5G is of  course part of that project, and 5G is   important for us because, at the end, when we  are doing this level four autonomous driving,   we want in some cases to give  the control to this remote operation center   and there, as I was describing the vehicle, it has four cameras or a 360 degree   view, and we want that kind of information  to go very smoothly and fast to the remote   operation center and the remote operator to be  able to to handle the car so that's why 5G,   and small delays in the network traffic and huge bandwidths are important for our   operations. –Thank you very much, I think now  we should switch to the second part of your   presentatio,n and in case we have time left  by the end of the second part, we will continue   with the rest of the questions that we have so far.  –Yes let's do that. –Thank you. –Okay, thank you. –All right, welcome to my part of the  presentation. So my name is Antti Kangasrääsiö and   I'm the Head of Research at Sensible 4.  So when you have gone to your local car   dealership lately, you probably have noticed  that you can't really buy a level 4 self-driving   vehicle there yet, unfortunately, and  I think one main reason for that is that   there's still multiple problems, like research  problems, technical problems, that we still need   to solve, or solve so reliably that we can  actually trust that the self-driving vehicles   can drive safely in all kinds of weather  conditions and among human traffic. So in this   part of the presentation I'll quickly go through different research aspects that we have relating to self-driving vehicles.  Unfortunately due to the time, I can't   go very deeply in any of the topics, but I can  take some questions afterwards. All right.   So as you heard, we're building full stack  software that enables all weather autonomous driving   and now if you want to build a software like  that, there's a range of problems that we need to   solve, starting from planning and control. So  thinking like how should we control the vehicle   in these kinds of situations, how do we achieve  tasks among traffic, object detection and tracking   like how do we observe our surroundings, how do  we keep track and predict what other traffic   participants are doing, positioning and mapping,  how do we know where we are, how do we know how to drive to remote locations, like using maps for that, modeling and   inference, so these kind of generic or more  general scientific modeling questions,   like how do we estimate different variables  from data and signals and so on. We also need   to consider things like performance evaluation,  how can we guarantee that our solutions are safe   and secure, and also problems, for example, with  remote operation, how do we make that    cost-efficient and feasible and so on. I'll go next  through each of these topics in a bit more detail. All right, and also if you're interested  in collaboration with any of the topics, let's   talk later. So of course this is  a wide range of problems to solve.   We already have like almost 100 people  in the company solving these problems but   that probably isn't yet enough to solve  everything perfectly. So of course, there's   plenty of very interesting research going on in  Finland and other parts of the world as well,   so we're of course very interested in research  collaboration that could benefit both us and the   researchers, and also, we are hiring later on  so if you are, let's say, looking for a postdoc   in a company position or business internship  or something like that, keep us in mind! So first, let's go through playing and  control, so what we mean by that. So planning means   finding an optimal reference path, giving  some kind of a cost function that defines what is   the task that the vehicle needs to accomplish and  also some constraints that determine what   the vehicle shouldn't do. We have various  constraints in traffic, like all the traffic rules   that we have to obey, there's all kinds of other  vehicles that we can collide with, and we need   to take all of that into consideration when we  make a plan on, let's say, how do we navigate this   roundabout intersection, should we go now or  should we wait a bit, like what's our plan,   how do we get those plans, and how  do we solve those plans efficiently online.   And then a related problem is the control problem.  So once we have this plan – okay, let's wait for that   vehicle, then go and turn left – then, how do we how  if we should execute the plan perfectly, or at least   well enough to survive in the traffic. And here  we need to take into account considerations like   robustness, or perhaps the plan wasn't perfect – we need to make slight alterations to the plan,   maybe other traffic participants didn't  behave precisely as we planned. So being   reactive, being safe even when our plan  isn't perfect and there's various uncertainties   and also there's different answers than this for  the environment as well like there might be some   black ice on the road that we didn't notice  and we need to react to that instinctively, like   once we realize that "hey, we're losing  friction, we need to do something about this"  and then there's of course  this, the safety control aspect.   So usually these control methods, we  might use a bit more advanced methods there   but the drawback with advanced methods  is that it's more difficult to give a very   high reliability, guarantees to those.  We might say that this works 99.9%   of the time, but then the legislator  might ask: okay, so what about the 0.1%,   what happens there? So the safety  control is then the really reliable, isolated   way that we make sure that even though we use  advanced methods for routine control, we can still   guarantee safety even in very spurious, strange  situations that the vehicle might end up in. Then, going forward, we have problems like  object detection and tracking, so understanding   what's happening in the world around the vehicle. And here, interesting problems are for example   detection, so there's all kinds of things  happening around the vehicle, so how do we find out   which of these are interesting traffic  participants that we need to consider   and which of these are just something like  leaves flying in the wind or some birds   that we don't actually need to care about, so finding these interesting objects   and keeping then track of those.  And then of course, once we find the   objects, we might also need to do classification, so  determining what kind of an object is this,   is this a vehicle, is this a moving vehicle or a  stationary vehicle, this is a pedestrian and so on.   And then tracking, of course, so once we have  identified that this is a moving vehicle, we   might be asking so where is that vehicle going to  be in two seconds of time, in five seconds of time,   in ten seconds of time, so where is it going.  Is it heading towards us, do we need to   avoid it, or is it going away from us so we don't  actually need to care that much about the field. And then there's all kinds of other  aspects of detecting environment.   Problems like lane detection, so let's say  there's snow on the road, so how can we   estimate which are the lanes that  we are supposed to use for driving   forward or taking left turn when we might  only have a very partial observability of what the lanes are, and things like free space  estimation, like do we have space in here to make a   U-turn or do we need to maybe plan for another  kind of maneuver in this kind of situation. Then moving on, so positioning and mapping. I  guess this is one of our, let's say, crown jewels. So we have maybe the longest history of research  in this front. So here we have problems   like positioning, so answering questions  like precisely where the vehicle is, how   is it oriented in the environment, what's our  velocity relative to some map that we have,   and this is of course very important, for  example, if we have a predefined route that   we need to follow, if we can't tell where we are  then of course we cannot follow that rule either.  And then a related problem is this  mapping, so let's say that we have some   environment that we haven't been in before, so we are creating a map   of that environment as we go along  so that when we go back again,   we already know how the environment looks  and we can do more efficient planning.   And of course there are problems like updating  these maps. So you might make a map once but   then there's some road work and the situation changes  or you update those maps reliably on the fly.   Challenges here  are that the environments change   seasonally so we might have situations  where we make a map in the summer,   but in the winter there's a lot of snow so  can we still use that map for navigation   or how can we use that map for  navigation reliably, even in winter then more maybe fundamental  mathematical modelling problems   maybe more related to control engineering  for example, so we have problems like system   identification and model calibration, so we have  these nuanced models of how these vehicles behave   and then we want to do control engineering based  on those models but then we face problems like how   do we precisely set the parameters of those  models so that our predictions are reliable   and how can we estimate time  changing state variables online   reliably, and these might be things like  how much friction do we actually have,   how slippery is the road for example,  how do we estimate that reliably online. Right, so that would be the state  destination problem here. And then of course   we want to drive in very different kinds of  situations so the environment is all the time   changing so it's very important for us to be able  to estimate uncertainty of our models reliably.   So how much do we actually know of what's going on, what's our uncertainty   and then taking that kind of uncertainty  into account once we decide what to do. Then of course, performance evaluation.  A very important topic in guaranteeing   that the solution we build is actually  reliable, it actually works, and then we have   tested it.  So here we can start with solutions like evaluation in simulation   so using various simulation environments to prove  and test that our solution actually works,  and then of course we get into these kinds of  challenges like simulator management. Let's say   we want to have a thousand simulations running in  parallel and multiple people submitting different   simulation experiments, so how do we manage  all of this. Then we might also go into   this hardware interlude simulation where we use  these more realistic, or even hardware parts   as part of the stimulation, so how do we set  those kind of situations up. And of course, the   most expensive but also maybe the most relevant  is these real vehicle evaluations, so driving   real vehicles in real roads, collecting data from  there and testing that our solutions actually work.   And then, of course, we get also into  these data management problems like   if we want to store all the data from one  vehicle, it's about one terabyte per hour and   if we start to have like multiple tens of vehicles  and they drive quite a lot every day   so how do we keep track of all this data, how do we  select what data to store and manage all of this  you know, the torrent of of data that we can  get from the videos. Finally, we can talk a bit   about remote operation as well. Although we're not  doing it ourselves, these are very relevant   problems for us to understand so for example  we have these remote operations so how can we   design our software so that we can support  the remote operator workflow as efficiently   as possible so that one remote operator  can easily manage a large fleet of vehicles   and not be overwhelmed by all the kinds of  decisions that the remote operator has to do.   And also thinking problems  like bandwidth adaptivity   like our vehicles might have to drive  in different kinds of communication   environments so you might not have 5G everywhere  but maybe only 4G or 3G, so how do you optimize,   how do you communicate with the remote  control center in different situations. All right, so to summarize this part. So  full stack vehicle automation requires solving a   wide range of technical challenges which I've just  given you a slight overview of, and keep in mind   that Sensible 4 is always interested in research  collaboration and will also be hiring next year.   