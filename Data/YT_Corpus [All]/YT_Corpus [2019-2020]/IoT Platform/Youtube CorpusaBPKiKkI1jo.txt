 really appreciate you all coming out to see the latest and greatest products and technologies to make life great for developers and our ambition here no less than that as well I'm James Poulos and Whitney is be brilliant and charming little mario and modest too and we will be running through the latest windows IOT innovations what we're working on and how we're with you as developers all the way through your journey building IOT devices now I have four live demos set up here so we're gonna see how that goes and and so if fortune smiles upon us you'll see four live demos going and I'll see what we get from there great so let's get started so why do people build IOT devices using Windows you know we actually recently wasn't asked a great number of them that question and we asked them what are you doing with it why are you choosing Windows what's in it for you we know you have a lot of alternatives when you build an IOT device why do you choose Windows and of course on the screen here we have some of the kind of a synthesized answers that we get but you know let me just walk through that a little bit we hear it enables us to get some market really quickly that's probably the number one thing that we hear you know we hear that the amount of time we have to put into development and marketing that affects our competitiveness in the channel right and so Windows IOT helps us reduce the cycle that it takes for us to get a product revised a product and keep a product up-to-date and if you think about the alternative dis or if you're going to use another operating system you're generally you're going to have to staff an operating system engineering team it's just a fact of life with the other operating system choices with Windows we do that for you that means the product is a commercial scale right from the get-go so again this is what we hear back from our customers who use it they also appreciate build right they appreciate the code samples and the templates and the technical training and you know if you were on the floor you saw ms learning there's a ton of that they appreciate all that as well they appreciate that that it is up to date right it is a supported operating system across all of our platforms it's ten years of support and for device maker that's really important and the fact that Windows provides that on a wide variety of silicon spectrum is important and then of course they appreciate that it's ready to go with the cloud you know what I have is smart on the slide here and you know Microsoft is the company with a major top to your cloud offering and a major top to your operating system offering and so that enables us to have them work together in smart ways that again reduce the time to market so our customers can spend their time on their application in their solution and that's really important to them now this is the portfolio of Windows IOT editions it goes from the small side of Windows 10 IOT core which is used for very small devices and we have a number on the expo floor if you've seen them please feel free to stop by and check them out a very low bomb cost it's good stuff our bread and brother leather bra our bread and butter is Windows 10 IOT enterprise now that's the full edition of Windows and everybody appreciates they can run their entire ecosystem of applications and code that they've developed over the years on that platform and that's really you know that's that's kind of a big seller I was just recently having a bunch of dental work done and my dentist had a Windows 10 IOT Enterprise scanner that she was scanning inside my mouth and she was annotating and she was literally inking on it right there and I thank God she was using it out to you enterprise I would hate for that to get hacked while my mouth is getting worked on so I felt safe and secure about that and then of course we have our IOT server product and this is if you have kind of a dedicated data center installation perhaps out on a oil platform or ship in the North Sea this gives you the great capabilities of server in an isolated platform area and all of these ten years of support is across the entire thing we've got it all I'm gonna dive in a little more detail now these are a number of the things that we've achieved recently I think since I saw you last out here last year and of course we have our long-term support release came out and a number of other features available on that platform what's coming next or actually really even now for some of these are we have up here so we have a lot of adjure focused again work done here as well as shell launcher and our qualcomm work there to broaden the experience of those devices now these are the ones i'm going to talk about we're gonna talk about all of these plus a bonus demo of our Windows CD work through the rest of this talk so again we're gonna have four live demos and without further ado I should be with us so first time I talked about azure IOT edge I believe most of you at this point are gonna be familiar with the azure IOT edge application pattern you know this is an Internet of Things which requires an internet and things the things and the things send up signal there's reasoning done actions are done well now we can move that compute actually down to where the data is we move the compute from the Internet to the things you know that's a IOT edge in a really quick nutshell we're thrilled to announce that azure IOT edge is generally available now on Windows and and so it's it's ready now this is on Enterprise Server and IOT core will be coming very shortly and again it's our bread and butter SKU so we led with that one for folks who have been using the preview you'll notice some significant strides forward in the capabilities of azure IOT edge on Windows largely around the capability of the containers so there's access to all of the buses that we would expect an IOT device to be able to access as well as access to the GPU for hardware-accelerated machine-learning inferencing some which we will show you today as well and we have that down on the expo floor again you know Sam said in his talk that really a camera on an edge device is the ultimate sensor it's the ultimate it's the nearest thing to humans the ability to see and sense about the world and so we the the big value scenario and edge computing is machine language inferencing and so for Windows Azure diet see edge on Windows does totally support on device AI inferencing currently what you do is you'd build a model in Azure ml and then you would export that via onyx and I'll show you that in a bit there's some other ways as well you'll combine that with some dotnet code that is Windows developers you're all familiar with writing you'll create a container from that and then that will allow you to take advantage of Windows ml so another great value of Windows is this is the only Windows ml is the only evaluation engine for machine learning with ten years of support like who is doing that Microsoft's doing that and so CPU evaluations very fast and also it allows you to be not locked into any one GPU vendor and that's very important to some of our industrial customers who don't want a single source for any of their products and when is ml enables that so on the show floor we've been doing hands-on lab that's been well received and I'm gonna show it to you now hopefully if my machine wakes up from sleep properly and I just wanted to run through the architecture from what that is real quick so the idea is we start in the custom vision service where we will train a model using some images we will export that to an onyx 1.2 format if any of you around in the previous talk about the value of onyx this builds on that as well that's going to be deployed to an azure container registry as a container as your IOT hub will be used to deploy that container to a device in the case that we've been doing today Windows 10 IOT core device and that's what I'll be showing up here in a bit as well that sends the inference telemetry up to the IOT hub which will then send that to Azure time series insights where our eyes can finally receive it and so we can we can see what's happening there so I'm going thing you can try it yourself there's a link here and also there'll be a links page a little later on with this link repeated as well so this is what we're showing on the floor and you can certainly give it a roll I encourage you to do that again with dotnet development skills you'll see how windows ml net come together for that ok so now I'm going to show you my demo and I'm gonna switch over here and Greg is gonna show us my little setup here and I will narrate it just a bit here so as you can tell it's come up here this is something that I put together myself after a trip to Home Depot to get the point across oh I did this actually for a lab for my 11 year old daughter so I think we have a child or two in the audience and we use some of her toys in this lab so I decided to bring those in as well because they're really visceral and you can really see them so I have it right now focused on this little squishy lamb and we're gonna put my piggy bank in here next anyway so I've got three machines here with three different cameras I have a Windows 10 IOT core running on an AMD V 1000 which has a really strong GPU in it I've got a Intel minnowboard which is very low cost and at a sacrificing capability but that's a choice you can make and I'm running Windows 10 IOT Enterprise on an Intel Core i7 this particular one doesn't have an additional video card it's using onboard video and the same application that I'm going to show you is running on all these in a container that's been deployed via azure IOT edge now I have three different cameras these are off-the-shelf cameras the great thing about Windows is it has a full media stack so any camera that windows can see will work for this and they're all taking a look at the item that I have up there for inferencing just at the moment so I'm gonna walk through this we could get just a little higher maybe we could see from the top issue here might be a good view so we can see we've got three machines the three cameras and then my item on stage okay thank you very much for that Greg so let me jump over here great so let us start not in the Badlands but on custom vision and this is as your custom vision which is a great service anyone who's doing anything with machine learning and computer vision I highly recommend checking out custom vision it's really economical as compared to making your own model it's really simple and easy to use that you know really anybody can do this so what I've done here is I've taken a handful of images of each of my items and then I've trained them so let's see if I can train here you'll see how fast training is so fast it's not gonna happen all right trains very quickly so once I've trained my model drumroll please from this interface I can go ahead and export it now that's what I would show you is me exporting this as an Onix file our network doesn't seem to be totally cooperating here so I won't be showing you that but trust me so this is where we would export it so I would save that Onix file that I exported from my Azure custom vision service and then I'm gonna bring it into my code environment so this is a fairly straightforward dotnet application you'll see this custom vision file is is up here which is the the one that I would have exported to so let's take a look at program for a second here or fullscreen all right so this is a dining application that is going to pull in Windows platform api's so we can pull in these various windows platform API so of course I'm playing on the windows that a IDOT machine learning which is the real value here but as well I'm gonna pull in the graphics I'm gonna pull in media and those are so that I can form my image into the right size and shape for the pipeline that's gonna go into machine learning and of course I'm going to use storage to pull files off disk and you know in a way that's Windows a I would like them so let me just kind of run through what I'm doing so I'm gonna get the options off the command line which is where I've specified various things here which is not that interesting then I'm going to I'm going to initialize the edge runtime which is real simple now I'm gonna get into Windows ml here so Windows ml generates this scoring model class for me and so it provides this create from stream async method on that and so all I have to do is I've loaded up my model file and I've provided that to windows the windows ml scoring model file generated then I'm going to open my camera is a frame source and those of you who are familiar with the windows media api's will find a lot of this code very reassuring and common basically what I did is I took this link here I took the docks out microsoft.com frame source code and I just put it into a file I just made a class in it so I took the absolute code right off of our documentation and I've used that to open the frame so I'm gonna get the frame get the video frame out of it and then I'm gonna again call model dot evaluate a sink which is a Windows ml generated class that allows me to go ahead and not have these things up here sorry about that Oh drama in demo and okay this Windows ml function here method allows me to just get scoring right out of that I'm going to convert that to Jason because Jason is that what Windows IOT our IOT edge wants to see then I'm going to use the module client and I'm gonna send that event right up to the cloud and then I'm just gonna loop forever it's very simple simple dotnet code and using the power of Windows ml so then on the other side I can look at time series insights my model still voting in custom vision all right so let us look at this so this is time series insights which is another fantastic tool for Microsoft that really allows you to visualize the data that you have coming in so the first thing I'm going to look at here is my devices I have connected so I can see I have two devices connected with a very long name my minnowboard and my pc decided to connect my AMD machine didn't quite do that but that's why we have three things so that they don't work your demo still works I can see that I'm getting in about 850 hundred and 70 from my from the you know board and actually the what I'm seeing right so I'm getting in about nine events per every five seconds that's my interval from the PC and I'm getting in a smaller number of events because of the performance on the Nano board so now I can come and see what I'm getting I like the heat map as a way to visualize this so these are the various possible outcomes in this model so far and the way the time series insights UI works here with this heat map is it's going across time so we can see that until fourteen ten to ten when I switched it I had the blue lamb up there and you'll remember it was there and then I switched over to the zebra pig and so starting at this time I can see that I was getting in a number of results at that time so I can see what's coming in now you're professional developers you're paid to write code make solutions so you're probably not going to use little stuffed animals in your professional life I get that so let me translate this a little bit into how you might actually approach this imagine a steel rolling plant like I showed last year with cameras looking at the steel and evaluating the defect levels in that steel and then this lets us see over time for any one of the machines or stations kind of what level of defect we're getting at that time so let's say during this time period I had a low amount of defect this time I had almost none at this time well maybe I got spiked with a couple little defects right there and time series insights will let me visualize that in a really straightforward and easy way so that is the demo let us switch back to great cool so everything I showed here is ready now this can be put in production now there's hardware you can buy now the operating systems now how edges now it's all there I would do want to walk into the future just a little bit because I also enjoy spending time in the future and in the future we'll have tighter integration with Azure machine learning so this loop here is the Azure machine learning workflow that is used today and today it makes it really easy for data scientists to go in and train a model Python use the right libraries and everything and then put that right out to azure IOT edge coming shortly will be able to create Windows containers directly from the UI or the SDK in Azure ml as well and then we are also a later this year going to be releasing a specialized Windows container for machine learning and the idea is that this focuses on the Windows ml stack as I said it's the only inferencing engine with 10 years of support it will be in a container it will also include the top-notch median audio stack that windows provides and that's valuable because with machine learning you need some data to reason about and often that's media data our audio data video data image data that's a really common use case and so having a window stack there to make that really use that data well and prepare it well is a big value I'll also point out the size so we are targeting a 350 MB on disk size for our Windows ml container and before I did the talk I pulled the tensorflow images to docker images on that and you know for just the CPU image inferencing container that's 1gb on disk and the container offering GPU inferencing is going to be 3.5 gb on disk so you can see we're a factor of a lot factor 10 that improvement on size so we think that will be exciting as well and again that'll be coming later this year so this is my reminder of links please go ahead and give azure IOT edge on windows a shot this link will take you to the windows installation page and encourage you to do that the hands-on lab that we were doing earlier and then I gave a sneak peek on is also available here please open a github issue if you have any questions or concerns or hit me up through github on that and then we have a whole set of samples showing how to do really everything with azure IOT edge on windows specifically so you know spy buses i2c buses serial that the whole thing is all shown on our samples page so please do give that a shot okay so I talked at length about azure IOT edge on Windows and that's an important and valuable technology it's not the only thing in azure IOT though right there is more to azure IOT than azure IOT edge so we've been working hard to improve azure IOT generally on Windows as well so I'm going to walk through a handful of those we're also announcing the general availability of the second version of our azure IOT device agent so that's available now again there's a link here if you want to check that out what this does is it allows the full suite of remote device management that you might get from say connecting with in tune that is also available to folks who write applications throughout the hub so it quickly and simply makes windows management available to Azure IOT hub using the same management capabilities under the hood that Windows is provided for years or decades and and so those are all available to put into IOT solutions as well so this makes it really easy to add mask control IOT devices using the management capabilities that Windows already has built in we've also announced the IOT plug-and-play initiative and so our Windows Device agent will also support that when it's available you know I believe this is the fastest way to create a device that's certified for IOT plug-and-play really if you grab our code you build it put it on your device you're ready and that thing is ready to be managed at scale using Azure sorry using IOT plug-and-play and so we think that will be really exciting when that comes out okay so I've talked a bunch about device management but really you don't make an IOT device to manage it right you make an IOT device to sense the world to send those sensing x' to the cloud and to receive commands back to change things about the environments and so I wanted to give you a little sneak peek on some work that we're doing we're building a sensor bridge from Windows to Azure and the idea here is you know you've plugged things into Windows before I'm sure and seeing that generally speaking and those things are recognized you can put just about anything into a Windows machine and Windows will know about it so we make it then really easy for Windows to be able to make that available to the cloud as well so you do have to do a little bit of wiring to say this is my thing I wanted to go to the cloud we're going to show you that second but generally it's super easy you know code required there is a little scripting that will show you but you don't have to write up code to be P&P compliant as long as you have a Windows Device and a sensor that Windows recognizes which is pretty much all of them really and the other beauty of it is is there's no need to recertify your IOT plug-and-play certified device once this is running because we know that with the window sensor bridge you're already IOT plug-and-play compliant so this is in private preview those of you who are interested in this please feel free to hit up this email address that's on the screen right now and we'd be happy to work with you on the details of the sensor bridge yet-to-be-named so that is what's there okay so I'm now gonna ask Mahmood Hussain to come on up my mood is a program manager the think the primary program manager on the window sensor bridge here and Craig is also going to come up with his skillful camerawork and we're going to show you this in action so thank you thanks James thank you thank you guys so like James said right we want to be able to easily connect any sense that can already connect to a Windows device so before we get into the demo itself let me walk you through the setup that we have here the fancy little set up so we're here I have a commercially bought carbon dioxide carbon monoxide sensor this is something that you might typically find installed in an office or a factory right it's nothing special this does a bunch of things other than carbon dioxide like humidity for example now this is connected via an rj45 cable and I shouldn't step on that to this device over here which is in the IT closet this is a breaker board right now there's just one device connected but you can imagine if you have multiple sensors this is how they would terminate into the ID closet and I have a jumper cable here that's connecting over to a Modbus adapter this sensor is talking Modbus over rj45 and that's what we have here and this is then connected to comm port on this industrial PC this industrial pcs running Windows IOT and all the connections that you'd imagine now this sensor we're here isn't what you might typically consider to be a quote-unquote smart sensor when I take it out of the box it's not going to connect to a shoe or AWS any n of those cloud services so how do we do that right the combination of the sensor with the sensor bridge is how you make a smart sensors let's see how you do that 8 and of course this time dot so the first thing that you need to do is you need to create an interface towards a sure that says this is the sensor that I'm expecting these are the properties that I'm interested in and that's what you have over here so this JSON file so this JSON file over here is telling me that hey I need an interface exposed here which is you're seeing here and then I'm interested in certain properties I want the former version the property of the model name and so on I want the carbon-dioxide status and I'm also defining a command that allows me to clear the alarm once it's set so this is what I am exposing on the azure side now on the device side I'm already talking oh s api's but I need to let the device know how to talk to the sensor and to do that I have I have this user manual that I have product from the manufacturer as you can see this is the same user device over here and the manufacturer here has provided a handy little table that gives me all of the Modbus mappings so you can see your way here on address 4 0 0 1 as where I read the carbon by monoxide reading so on cars for 0 0 2 which is what I'm interested in is carbon dioxide so this is literally what a manufacturer would provide anybody now what do I do with this right I know now what the sensor is putting out on the rj45 I need to be able to bridge that to the device I have so let's go back to the JSON and there's yet another JSON over here which tells the sensor bridge running on the PC on the industrial PC how to talk to this sensor so first what I do is I am defining a Modbus device and I know that I'm connecting on the comp or here's of comport parameters this is the same interface ID that you saw in the previous file and then right here I'm using the address poser - zero - because I know that's where I read my carbon dioxide I'm doing the same thing for a bunch of properties you know the alarm status etc and here for example is the command to clear the carbon dioxide alarm which is at this address if I write a byte at that address it gets cleared so that's it those are the two files that a device builder will have to go and edit and now they can get the sensor up to the plot so let's see how that happens so let me bring up a application called the device Explorer this is available on github if you follow the announcement on the IOT plug-and-play it's available on github over there I've already plugged in the IOT connection string this is talking to the IOT hub already so if I look at the devices tab it's going to take a little while for it to come up and hopefully it does so here I'm looking at the device twin and a lot of the properties that I just defined so I know that this device is working well let me check the telemetry this again takes a little while so that as soon as that comes up we will be able to see the telemetry from the device and here we are you're seeing all of the latest events showing up now let's try a couple of things this is measuring carbon dioxide in this room I'm going to lower the threshold all the way down and see if it triggers in the lab so Greg if you could focus on the carbon dioxide alarm right there so you can see that happening so right now you see the threshold is 100 and I'm gonna change it to 100 and I'm switching because it happens really quickly so I change the threshold the threshold was lower than whatever is set to so the alarm went off you will see a red light if you can that's going off and it's a persistent alarm so I'll switch it back right now back to the old threshold and now let's go back to my screen and let's look at a command to clear this right so if you can see I'm just using a checkbox and before I submit I'm going to switch back because again this happens too quickly so I'll submit here and hopefully you saw that it went that it got cleared and I verify that it does indeed cleared right so you can see that the carbon dioxide reading it's a little shaky but it's in in white so that was a simple example thank you great so that was a simple example for how you could connect a sensor that we bought off the shelf to Azure and all you had to do is edit a couple of files I can do the same thing with a USB connected camera I can send the telemetry up to Azure I can do local processing just like the ml model that James showed any sensor that connects over serial I can connect to a nice Kinect sensor that connects over USB the key the key point over here is that if a sensor is is already exposed to Windows if the windows can recognize the sensor then we can have that sensor exposed to as your wireless sensor bridge so that's thank you James great thank you very much Mahmood and the windows sensor bridge is a great way to leverage windows to be able to easily get these sensors up to the cloud and IOT plug and play aware so that concludes our section on Azure IOT improvements I'm now gonna hand the floor off to Lulu Mario who's gonna walk us through a number of other client-side improvements there you go Lou thanks a lot Windows CE II was released in 1996 when Windows desktop could be installed from a stack of floppy disks now if you don't remember what a floppy disk is it's like a flat 8-track tape it grew in popularity and there were hundreds of devices or actually thousands of board support packages tens of thousands of manufacturers representing hundreds of millions of instances of Windows CE deployed in all verticals from manufacturing warehousing even medical so we're looking at how to migrate those systems to modern operating systems so you can take advantage of modern workloads take advantage of modern security and modern manageability when migrating from legacy systems like Windows 7 embedded Windows XP or Windows 8 embedded the translation from those operating systems to a Windows 10 IOT enterprise is relatively straightforward the api's that you're likely using are still in the system the they haven't been removed or most likely haven't been removed from the system so you can take a binary that has targeted those previous versions of Windows move it to Windows 10 IOT Enterprise and have it just work we work actually really hard to make that to maintain compatibility because nobody wants to upgrade and find that things don't work when we're talking about smaller opera smaller devices if you're creating new one you have a choice between IOT enterprise and IOT core IOT enterprise offers you the greatest cut and compatibility and it also works on the higher end CPUs where IOT core is designed for smaller class devices however there is a how do we take existing Windows CE II applications and run them on IOT core since I joined the team I've actually looked at how to do this a couple of times how do we actually do api compatibility using detours or trampolines how do we actually emulate cui's and things like that but we actually never we always stopped working on those as it wasn't it didn't actually meet our goals so what is the goal we wanted you to be able to take advantage of the modern versions of Windows while allowing binary compatibility for Windows CE II applications all of those hundreds of thousands of instances of Windows CE II represents a lot of software that's been built a lot of expertise that's been built up a lot of system integrators built the businesses around this and there's just a lot of software so how do we actually take that software and migrate it forward now the opportunity here is is if you take those applications and you bring them forward you can use modern techniques like machine learning you can use modern long term support at OS and you can use modern manageability and connectivity so about a year ago I was lamenting that we weren't able to solve this problem and I said you know I really wish we could just run Windows CE e on top of IOT core my manager goes why not why can't we do that so he spun up a team that went and did this and they came up with a brilliant elegant solution and I'm really honored that they are allowing me to talk about their solution today so how does this work well as you can see we have we're actually running we've taken C E and actually refactored portions of it and we're running a significant amount of it inside of a Pico process now a Pico process is the same technology that runs the windows subsystem for Linux when you start up the process it has nothing in it you just get a flat memory space and then you can drop any kind of binary you want inside of it we've taken Windows C E and split it into pieces so that most of Windows CE e actually runs inside of this Pico process and the C application binaries run directly in this process as well as any DLLs or other or sorry other components portions that actually can be directly translated to the Windows NT kernel such as handling interrupts and timers and things like that are handled at in a system process in a driver that runs on the windows side for higher-level concepts like drive printers or network support we actually have a process that runs outside of it called DK mam you wouldn't believe me if you if I told you what that stood for so we'll leave that as a mystery so the way it works is when you have a API at the in your binary executable or DLL that calls through into the OS if you if it can be serviced by the NT kernel it'll go all the way through if it doesn't it goes uses a cross process call 2d came on to service it and then returned it up through the system process so let me show you how this works if we can have a Greg come on up we've been Coen Janee hring this with Rockwell Automation and I think Clint is actually in the in the audience ah thank you very much for your the trials and tribulations of getting this up and running we really do appreciate it on the left-hand side we actually have ace Windows CE II display that is was built by Rockwell Automation and they've shipped many many instances of this the application that's running on it is called the super juicer and it's designed for applications where they're taking vats of the material and mixing it you got to keep that stuff stirring and mixing and the and deployed out to the the product line so as you you can see that what we have here is a number of custom controls that visualize in this case a simulated level of material in each of the Vettes plus there are motors that control the valves that actually will distribute the material around the factory if you if a worker were to click through any of these vats you can actually get details on it such as motor performance temperature ambient pressure and the like now if you wanted to instrument any of this and actually send it up to up to the cloud for inferencing or use machine learning to see if there's any floating material inside of it it's kind of more complicated to graph that on top but by taking this application and run it on an IOT core you can take you can take advantage of those workloads so we're going to switch over to the side here so you can see that this is the same application it's actually the same binary that was literally copied off the desktop of Windows CE II and dropped on on top of the they abstract the C II layer that we're we're talking about here and it runs directly in fact you can see that it actually even has the C II Start menu okay and that's the only applications that's running inside of it okay thank you very much sorry nothing yeah so we do really want your input we want to see what your what your going to do with this so please visit the migration website here we also have an IOT show where we wear my Deepu Thomas actually goes into detail about how this works and how you can take advantage of it so please go ahead and register for more information okay so now let's talk switch gears and talk about robots I love robots I used to work on Microsoft robotic studio I was a dev lead on that robots come in all shapes and sizes from little tiny toys that you can buy in the supermarket to building a size material movers and kind of everything in between they are an IOT device and that's actually really critical they have the same needs and once as a IOT device wants to be secure or wants to be manageable wants to be useful and usable like other IOT devices they also need to observe the world they need to sense it they need to understand it what's different about robots is they can actually reason about it understand the environment and physically manipulate it that's actually pretty cool yeah let's see we also think that robots are the best and example of an intelligent edge device because they need to be able to do all of this on the device itself they need to be able to take advantage of understanding the environment they need to be able to see it and reason about it all without with limited or potentially undesirable internet connectivity many companies are looking to onboard robots into their existing infrastructure and a lot of factories and warehouses are actually our window shops so they want to actually bring make the robots that they're bringing on board you work with their existing infrastructure there is an open-source framework that many of these companies are looking at and called the robot operating system and it's a little bit of a misnomer it's not an operating system like Linux or Windows but it's a middleware it's an open-source framework you can think of it kind of like dotnet core OpenCV it is a way of building applications and a runtime for running them we've been working with the open source robotics community and open robotics to bring that support of bring Windows or bringing Ross to Windows we announced this at Ross Khan which is a conference around Ross in October and I was a little worried that it wouldn't be accepted by the community but I was really excited when the number of people came up to us and just said thank you thank you for supporting Ross on Windows I had one cut one person come up to me and said did you really support Ross on Windows and I was like yeah I said okay honey we went away and a couple hours later and they said I've ported this major piece of code and it's working that was pretty exciting times so what is the robot operating system it is a mature framework was actually introduced in 2007 by Willow Garage who was acquired and then spun out as open robotics it is a framework for building robot applications a robot needs to be able to receive data from a number of different sensors operate on that data and then actuate and these are all happening at the same time the way Ross handles this is that actually uses at what's called an actor model so instead of an object-oriented programming language where you have an object that you make a method call you actually send messages and they're asynchronous so you have the you have things operating on data at different rates to orchestrate that there is a component called raw score which allows pieces of the robot application to discover each other and you can build what are called nodes these are behaviors or skills for your robot and they each run in a separate process and they communicate with each other over network over IP now this is kind of cool because individual nodes can run on different compute in 'its so you can actually create a composition that takes advantage of microcontrollers or multiple different CPUs a node can publish or subscribe to into topics my topic is like a named message queue that allows you to send data or receive data and we'll show how this is useful now if you're familiar with the Rope of the Microsoft robot studio you'll notice that this shares a lot of the same behaviors as robot studio did so it's a they have a the same similar history Microsoft is also a member of the Ross industrial consortium which is looking to take this open-source framework and make it industrial friendly and it's joined by tons of hundreds of companies that both produce robots consume or consume robots or produce mineral offer for robots there are nodes skills behaviors drivers for all sorts of different components for a wide range of activities such as manipulation mobility even spacecraft which is a lot of fun so yesterday we actually announced that Windows 10 IOT is ace now a support at platform for us we call it generally available from the Ross industria from the Ross community they call it a supported platform we've seen excitement both from the academic and hobbyist communities as well as the industrial communities who are excited about using on Windows so what did we actually announce if you look at Ross as a whole the robot operating system there is the raw score and this constitutes the build system the messaging system and a core set of nodes to start up and orchestrate your your robotics workloads however Ross is actually a large community of nodes representing thousands of discrete behaviors and skills and drivers and compositions we've taken a swath through mobility and manipulation if you down in the what are they call it the the showroom floor we had actually several different robots running Ross on Windows we saw one in the Microsoft day I grip as well as in the IOT group doing different tasks today I'm going to actually show you some of the mobility features using a turtle button and I'll show you a little bit more about the turtle bot we've poured at the top 40 meta packages and a meta package is made up of tons of smaller packages and company and company about 300 posit or E's so it was a huge operation for for us and the community we've also lit up a couple of Microsoft specific notes including an azure IOT hub connector which allows you to take Ross messages and stream them to the cloud as well as a Windows machine learning node which allows you to subscribe to camera data run an onyx model on it and receive output to do something interesting we're also working on a Visual Studio code extension they're the most popular vision there is actually a Ross Visual Studio code extension today that was built by dr. AJ short and we reached out and we said we would like to add support for Windows and a couple of other features he asked us to take ownership of it because it wasn't something that he was able to continue working on so we're working through the logistics of that however I'll show you a couple of things that for Visual Studio code so here we have a Ross workspace now a workspace is kind of like the Ross equivalent of a visual studio solution it's created with a Ross tooling and you pull in individual nodes that you actually want to build as part of your you're a robotics composition one of the things that we're demonstrating today is what is called a UI RDF preview now in robotics the position of a camera relative to say the keyboard if we were using a laptop as an example in an example is actually of critical importance just a slight deviation in the position can actually radically change the behavior of a robot so in order to connect sensors to actuators they use a description format called you RDF and a macro format on top of it called zacchara so let's see if this is going to render okay so it worked yay it's a preview right now just got just got it working what you can see here is the you RDF is actually being processed locally and rendered and that's a fairly accurate representation of this robot okay you can see you might be able to see in the links that connect various components together such as where the wheels are in relation to the sensor on the top as well as interesting things like the weight distribution of the robot where the center of gravity is because that's all taken to account during a simulation we'll come back to the visual studio code extension in a second that fund is really small so other things that are really interesting about the visual studio code extension is it allows you to actually manage your robotics composition a composite of as I mentioned a robot is built up of many different nodes that are all communicating together this allows you to start up the composition shut down the composition as well as other behaviors okay so I'm going to show you in a minute a demo in simulation that is about navigation so how do you actually get a robot to move around an environment so that's actually so this composition that we're using leverages one sensor actually two sensors and an actuator the first sensor is a lidar which is a spinning laser and what it does is as it spins it computes a distance to the things around it and it knows the angle of which point as when a sensor reading is taken the other sensor we're using is the inertial measuring unit which actually knows how far away it has Divya deviated from a position between those two pieces of information we can actually fuse all of that together into a map the weir for this demo we're actually using a mapping technology called Cardo which an open-source framework that we're we've enabled on Windows and then we're using a localizer called a MCL which allows you to take sensor data and turn it into a position so how does this work so first we have the lidar and the serial bridge the microcontroller bridge sending data to two different topics these top these messages are subscribed to by both the mapping technology as well as the localizer and that's fused together in order to create information about its environment and allow it to sense where it is in space and what the space looks like the cartographer is responsible for taking the fusion of that data and publishing a map and the localizer is actually responsible for saying here's where I am this is the pose I have in space which is the orientation and position relative to some global environment now that's all well and good but if I can't go from point A to point B what uses a robot well this is where move base comes in because the the position fuser will actually say this is where I am relative to the world and the move base actually says here's how I create a plan to go from point A to point B now a robots just going to sit there unless it has something to do and this is where your robotics application comes in it gets a mission that mission can come from a cloud service it can come from a human it can come from a behavior that you've coded that just says I'm bored I want to do something it creates a goal and says go over here then if that goal is attributed to move base which generates command velocities which closes the loop back on to the on to the environment or on to the robot itself ok so now we're going to switch over to the second demo so in Visual Studio code I can bring up the environment and launch a Ross launch file this particular Ross launch file exists in the Bill 2019 demo and it's called sim dot launch okay while that launches we're going to talk a little bit about what's happening here so first we're actually starting the composition we're actually launching this launch file which is kind of like an auto execute bat if you remember those that launches a whole bunch of executables and says here's the parameters associated with those binaries the as it starts up we also launch what's called gazebo which is a simulator the simulator actually implements the robot and it allows the leave code that is running behind it it doesn't really have to care whether it's running on a robot or in simulation it's just getting data from the environment processing it and doing something with it this is ace this is this particular environment was built by robot ace for their turtlebot line and you can actually buy this from their website we just picked one up and you know using it for the demo and we're also using the demo code for this project so gazebo as a simulator has physics you know if you hit a wall and the wall isn't fixed in space it'll knock the wall over you can actually knock your robot over if you're not careful in simulation it's pretty neat so on top of the simulator we're actually going to take a look at a visualizer now the visualizer takes information from the environment and actually shows you what the robot is seeing okay so in this case we're going to go ahead and launch a previously stored visualizer that's pretty cool so what we're seeing here is a couple things first I'm gonna actually turn off the one of these maps okay so this map was previously generated I drove it around and it figured out where everything was and it's called what's called an occupancy map that's about five centimeters blocks you're either can go there or you can't so that's saved off and used for for navigation purposes we can also do something like visualize the scan so I'm going to go ahead and make this visible I'd say ten points okay so this these are lidar points the green which is simulated from the Gazebo simulator this is all open source code that's been built by the the Ross community over time so we're just showing it running on Windows as the simulator is generating these rays we're actually receiving that as input and the localizer is doing what's called a cost map which says so what a cost map is is how costly is it for the robot to move into a certain spot and this takes into account certain things like I want to be this far away from an obstacle I want to be I want to optimize for being away from things that could get caused me trouble and in this case the blue Idzik is a place where I can go freely and all of the red is where it gets more costly it'll try to avoid getting near red until it actually gets to that cyan thing where it's a no-go so we're going to create a naviga which basically says I want to go here and face this direction now as it's moving around we're going to go ahead and take a look at what the cost plan or the the plan is so we can see the map that's the the trajectory that has been generated again this is all open source code that now works on Windows to be able to build your of robotic solutions so to learn more about Ross on Windows please go to aka.ms/offweb O's and start working with it today our community is the Ross community so we when you go through the Ross community it'll point you or go through our Rus our community link on the landing page it'll take you to the Ross community we're monitoring the Ross community as well as reddit for any support issues and with that I'm gonna hand it back to you awesome Lou thank you very much for that I told you he was brilliant and he did not disappoint so thank you so thank you very much everyone for having made it this far and build and we're almost to the end and so just a big shout out from all of us at Microsoft for you coming here to our hometown and attending I just put together a little quick thing for you to snap of kind of summarizing the various things that we talked about here after the talk is over they'll also be folks from the windows IOT engineering team up near the stage over here and you're welcome to come and approach with questions that you may have about technologies that we discussed today or things we haven't discussed today or your favorite pet peeve that you want to remind us about dog you're welcome to bring those up too and and we'll be right over here for that so thank you very much on that and then of course we value your feedback so if you like the session give us feedback if you didn't you probably should too and just tell us you know how to make it better for next year because we'll be here next year talking about Windows IOT then as well so thank you very much 