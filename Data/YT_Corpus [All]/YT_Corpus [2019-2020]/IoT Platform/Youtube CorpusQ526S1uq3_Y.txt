 think I'm wrong okay we get started that's not word hi everyone thanks for coming to this talk today thanks for saying how many of you are part of the azure IOT team are you here to support us okay thank you so today you're going to hear about the azure IOT platform and security innovations what's new and we wanted to do Ashley's to put some focus on data insights for IOT and security I'm actually the MC basically I'm going to introduce stuff but your star speakers will be used to cinch and Rika will then come up just after what I want to do before jumping into the presentation is give you some context on how we are approaching IOT and how we are considering you know the work we're doing to serve our customers and the way we're actually approaching that some of you might have seen that slide is we consider that IOT is enabling a feedback loop a digital feedback loop that will allow our customers to digitally transform their business by optimizing operations transforming products empowering their employees and engaging customers and to do that actually they need to have data data from the devices the things data from people data from the places and spaces that they're in and they need to harness the data and extract insights and then take action right and why would think it's all about data it's it's definitely all about data right about securing the data ingesting the data analyzing the data and one of the reasons why we think I or T is key component to that is when you look at the number of devices that we expect to have connected so that number is funny because it changes all the time going up exponentially so now the latest number is that by 2025 we're expecting to have 80 billion things connected and these 80 billion things will generate a 180 zettabyte of data per year anyone knows and the one who answers gets an MX chip board anyone knows how many zeros is a zettabyte no it's not 18 No 21:21 was down there I'm gonna kill someone so a lot of data that's more than what the Internet has generated since it exists and that's going to be per year and that's gonna be generated by IOT devices only right so that's kind of important so let's talk about what we're doing to help our customers to help you guys as well implement IT solutions and to do that I want to introduce at a high level what an IT application is the bounce an IOT application is about things right easy so that's extracting data from these things and getting insights from that data understanding the data analyzing the data and then even more important than the actual insights is the actions you're gonna take if you have valid an important important information about data coming from things and sensors and people and others well if you don't take action on that inside its kind of useless it's super important to understand is that actions set of things so it seems pretty simple right things insights actions actually it's a bit more complicated than that IOT solutions are complicated you need to think about a lot of things it goes to you know device recovery device life cycle device updates the protocols you're going to use to connect these devices the cloud to device commands was controlling whoo who's connecting where security across the board and Eustace will detail that the strategies for storing data and analyzing the data the data ownership as well the location of the devices and of the data ownership of that data as well all of these things are super complex in our part of an IOT solution and that's why IOT actually needs to be simplified what we're trying to do is to simplify IOT and this is our motor someone say that I have a second MX chip device if you can tell me whoo say that you'll get the board I'll let you read I cannot read that it's too long no yes and Stein and Stein say that and what really meant is something in the lines of everything should be made as simple as possible but not simpler believe it your view so we want to make I at ease simple as simple as possible but not simpler right so we need to provide it right set of tools for empowering our customers or partners to bill IT solutions and be successful so let me actually tell you a bit more that you know how we are trying to simplify things by going more in depth into an architecture of an IOT solution I'm not talking about IOT central here artist central is the ultimate like simplification of IOT one-click deploying you have an IT solution just works as everything in there what I want to talk about is what's under the hoods what's what's under an IT central solution that you might want to go and play with and develop your own solution spaced-out right so the various parts of minoti application that's true friday central as wealth just you need to understand how that works underneath you need to have devices you need to connect the devices you need to think about having a cloud gateway that will allow you to authenticate and to manage these devices you need to think about how you can store the data of these devices you're going to eventually want to do some live stream processing of that data to extract information immediately on that data as it just arrived you will want to integrate with your line of business application this is where you're going to take action you detect something will go wrong in the future in your factory floor you want to create a ticket for maintenance team to go maintain that machine right so you want to take action integrating into your line of business application you also want to have some tooling for visualizing that IOT data and reporting to the users but also controlling and configuring the devices back through the cloud gateway you need to also think about you know things more complicated such as some devices are are less simple than others they need to eventually run some of the workload you've been developing in the cloud at the edge we have some technologies that and I'll talk about them in a second but you need to think about the various types of devices devices that eventual are behind a gateway they're actually cluster eyes de ventually you need to think about how you're going to provision these devices at scale configuring one device that you you know buy on whatever maker website and playing with it is one thing you can actually hard code the credentials for connecting and so forth when you do that at a production IOT scale you need to think about the technology will help you provision reprovision manage the lifecycle of your devices you need to think about data transformation data as we'll talk about actually takes various shapes for your format you need to actually be able to transform the data on the flow you need to think about the various strategies for storing the data how fast you want to access the data do you want to store it for long term analytics and later analytics on some cheaper storage technology or do you want to have instant access to that data you want to do advanced analytics machine learning and others you want to use like you want to salute user management all these things are complex to do and these are all the parts that actually we are providing as a platform and this is not even mentioning the things that are what I call the cross-cutting needs security across the board end-to-end and Eustace will talk at lance about that deployment ID deploy a solution you know that you create for a customer for another one how do you deploy across geographies and so on last but not least high availability and disaster recovery you're surveying an application for customers whether the consumer or businesses you have to maintain that application up in life especially that application is about detecting from failure and improving processes let's talk about tech work quick and then we'll dive into the various things here is what we have within the azure IOT team and more in Azure to address these various bits and pieces of an IT solution IOT hub is our cloud gateway for devices IOT hub dps is a device provisioning service that pairs with Archie hub for provisioning device that skill think of it as the concierge for devices devices come up knock at the door they're recognized they are signed to an IOT hub they get the credentials and then BOOM to connect your application and it can be used for edge devices devices are smaller gateways where you want to eventually run some machine learning algorithms so on with something called as your IT edge we have a session I'll remember argument if it happen already or not but there's a session about IT edge tomorrow at noon tomorrow at noon as your r2 edge or artemon and team ash will present measure stream analytics is another service in Azure debt we are leveraging as the IOT team that is actually designed for doing real-time analytics on data time series inside customers DB Azure blob and data Laker all the technologies you will have to think about using for your storage whether it's for a worm scenario cult a scenario jindraike actually we'll talk at Lance about TSI in a minute when it comes to Qi deep transformation as a function is a great tool TSI can do some data transformation also for normalizing data and making sure everything looks as you expect after visualization websites web technologies but also services such as time series insights or Azure Maps allow you to visualize the data in context inject data from other services and other data sources and lie you to have you know some better visualization some better information for your users when it comes to business integration logic Apps is a good option or it has tons of connectors for you to directly trigger flows into your line of business applications on the advanced analytics Azure machine learning data breaks whatever you want to analyze data at scale at an IOT scale and Azure Active Directory for you to manage users all these are the azure platform services that will allow you to build an IT solution end-to-end all right we have tons of tools for you to aggregate these services and make your life easier you don't have to think about these plumbing it's there by default even better you get a sure as a platform for your IOT application to manage the role-based access control so your users who can access what in your application you and also benefit from all the paths IKS service fabric infrastructure that asher offers for you to deploy your eyes your eyes your IOT applications you know here and there so this is an IOT application this is a lot of things to ingest and think about what we want today is to focus on the middle part which is the insights focusing on IOT data is key because as I mention already lots of data you extract the insights and then you take action this is where the value is this is where you transform the business it's out of that in such extract from the data from the IOT devices things species and people but that data actually is what I call multi-dimensional different devices produce different types of data in different formats so you need to actually you know make sense of all of that and that data makes sense in a specific context very often right the temperature is actually measured in this room my not mean the same thing as the same temperature in a fridge right the the value itself has a meaning because we know it's in the fridge or in a conference room right so that's one thing which is anything that the location of the device is one of your context data points another one is time time is key right the temperature that you have here right now doesn't mean the same thing as a temperature overnight where you actually want the room to be cooler and save energy or actually harder in winter in summer but depending on time in the day that data doesn't have the same meaning is it too hot or not it depends right so you need to think about location-based data and time-based data as your to of the of the many dimensions but there are key and important for you to manage and then that are not trivial to want to manage them to understand to deal with so the first one is the location-based data and I'm going to actually fly through Azure Maps because not the expert here and we have people on the booth that can talk at length about Asian Maps which is a platform that gives you a set of API for managing in real time the integration of your things data with other third-party services or in the world of mobility think of it as you know locating devices integrating with data from other services and so forth Maps offers mapping obviously to render maps and you'll see an example of one of them in a second offers SDKs for you to build apps for the web and for Android that will allow you to integrate a map into your IOT application that will put your device's data in context in location you will have api's for doing routing so if you do fleet management right you know where the devices are actually the data is coming from by having a GPS pinpoint and you can integrate that into your app and you can decide to route that truck or whatever depending on the information which is actually the actual routes that these these trucks whatever can go on then you also will be able to do search everything that you would expect from a mapping infrastructure traffic mobility time zones geolocation spatial operations very interesting actually special operation think about of it as a few lines of code to create a geofence and then trigger an alert when a device is actually coming out of the zone that you define in your mapping application right and also the ability to store that mapped data into your own application sure because as your Maps is designed for enterprise and it's something that comes as an instance of the service in your Android subscription and you can totally partition your own data your customers data into the data center of your choice and keep it there and not share with the rest of the world through some of the generic mapping services out there we did some announcements the key one that we did during build was a partnership with move it that's a lot to have in Azure Maps mobility services day such as transit information such as you know routing using biking or scooter or whatever parameters you can then imagine tons of scenarios that are related to public transportation or to various ways of going around and if you correlate that with the rest and of the information that we got from other partners you can imagine scenarios where hey how about I'm transporting something highly flammable on my scooter and what's wrap should I take because I'm super tall and I'm gonna go under a bridge and eventually I could use the bus there right don't ask me to create IOT apps that would be crazy but mobility services is now available as a preview another announcement we're making a spatial operations being generally available for those were already are using Azure Maps any one team when you're gonna be using Azure Maps you'll realize that Special Operations is already available for production well you can actually consider a very advanced application that use in particular things such as geofencing closest points finding and things like that I think I'm already running over time so I'm gonna go on to that last slide before I giving you tisha and Rika SDKs update we actually brought in light gray map style support for drawing tools spatial map features drawing tools modules this is an enhancements to the existing and already super reach SDKs that we have for the web same thing for Android we're bringing new features in there so go out test apps as your Maps we have a link actually for demos that I'm gonna be happy to share towards the end we're actually all the sample of Azure maps are displayed into a web page and can navigate the code and test the samples it's going to be way more efficient of you guys actually as a homework you go to Azure samples and play around with it so we talked about the location-based data I want to now pass it over to Shin Drake at talk about the time-based data Thank You Olivier hi folks my name is Chandra Kishan Khanna and I leave the efforts for IT time-series analytics and I'll talk about that in a little bit before I get to the the topic itself I want to show of hands how many of you folks in this room build IOT solutions that's a lot of you how many of you folks build IT solutions using Azure services specifically agile IOT technologies that's more than half the room the last question I promise how many of you folks are using Azure time series insights today that's a very small handful okay that's good to know so I wanted to sort of understand the context of how much you folks know about Azure time series insights and how much ground I need to cover I only have now thanks to Olivia about maybe 20 less minutes each of these topics were covering in this session deserve a full hour there's a lot to cover we're gonna do our very best to do cover as much as we can and as Olivia promised we have boots please go visit them there's plenty of demos plenty of people from the product team helping as well so I'll cover as quickly as I can as much as I can and we'll leave some room for Q&A in the end next one okay so along the lines of what Olivia was talking about in terms of IOT data characteristics I want to stress a little bit more on industrial IOT data characteristics and this sort of sets the context for what we are trying to do with Azure time series insights IOT data first and foremost lacks structural consistency most data that concern yit devices or things are either unstructured or semi structured or maybe structure too so we're dealing with a combination of structured data that has structural consistency in consistency rather so there's a lot of work that needs to be done to normalize this data and we've been told we've learn from from usage scenarios that you know a large portion of this data gets thrown away only a fraction getting gets really used for analytics and insight so it is super important to get that get to that data that is useful and normalize that data and consume it for analytics right that's the first and foremost thing second thing is as Olivia pointed out IOT data needs contextualization and again another thing that we hear from customers all the time telemetry data in itself is not very useful data coming from sensors needs to be contextualized you need to see it through the lens of the context that that data is coming from and in order to do that you need things like data models you need to be able to describe the shape of that data and the context of that data and that telemetry data needs to then be correlated together with the context to be able to give you interesting insights and analytics to drive the operational intelligence you want the third thing is IOT data is used typically with other data it's useful not only to look at telemetry data coming from devices it's useful to correlate that with other data that influence your business decisions when you make business decisions together with that data for example in the in the automotive industry we talked about maps a lot in the in the prior section geospatial data is very useful in the automotive industry you combine that with data coming from sensors in order to drive your operational intelligence in the energy domain we have you know customers driving wind farms they typically rely on weather data which it which comes from third-party sources to be able to correlate weather patterns together with the performance of their devices in the in the wind farms so this kind of correlating third-party data sources and data together with telemetry data coming from sensors is a very important aspect of dealing with industrial I or T data the last but not least very important aspect of inter salinity data is that many of you folks dealing with industrial IOT are dealing with large volumes of data and you have historical data archive from years worth 10 20 years worth of data and typically you go back to that data to do things like predictive analytics troubleshooting pattern matching etc so you need that data to look back and say two years ago how did this device perform or how did this thing perform you want to be able to correlate to that pattern and say how should I predict the performance of this thing how do i do forecasting how do I compare in contracts and drive operational intelligence so for that reason you need to have infinite retention so these are the typical characteristics of industrial IOT data now why am I saying this there is a very important correlation between what the characteristic of Industry data is and what it is that we're doing with time series insights and what are we trying to achieve as far as our vision and our strategy and goal is and before I get into that since north folks have very little knowledge of what we're offering in the space in the space I want to first touch on what is it that we're offering today as your time series insights is a fully managed path solution and platform as a service solution to ingest process store and query data and I'll stop at that and that's what we're doing today we have an in market solution that allows you to do all of this now you might ask the question well what is the difference between this and any other big data analytics solution that you get from Azure from the Ephraim that from our agile cloud well the answer is what follows after we're what we're focusing on is highly contextualized time series optimized IOT scale data were a purpose-built solution for industrial IOT analytics and we'll touch on contextualization in time series optimization over in the next few slides the second big thing I want to point out is what we're offering is a highly flexible data platform I almost want to call it an open data platform but I I stopped myself from saying that because there is an industry consortium and there's a standard that P and open-source is driving towards so it's not so much to say that we're an open-source system but we're a highly collectible data platform that allows for connectivity to a variety of data scenarios and a variety of data services and again we'll give some examples down the road it's ideal for ad-hoc exploration if you don't know the shape of your data and you're asking some very generic questions of the data it's very ideal for those scenarios additionally what we're adding as a as an industrial IOT strength analytics platform is acid based operational intelligence and we'll show some demos as well it's tailored towards this it's a it's a fit for purpose in their society analytic solution as a result so let's get into the actual let me build this out why is it that we call ourselves industrial IOT data analytics platform first and foremost for those of you that do in this IOT analytics you'll know that a lot of times you're doing ad-hoc analysis over data which means that you don't know the shape of the data that coming that is coming from the assets and devices so you're asking simple questions like how often did that given event occur or can I visually spot an anomaly that's occurring based on the patterns I'm looking at the second main scenario that we see customers doing is operational analysis over the data where you're explicit modeling the data this means that you can ask some intelligent questions of the data you can query for events based on device a device ID and a time range or you can query for all daily results of a KPI across the entire installation or maybe a single installation so you can do cross time C cross queries across devices within an installation across installations these are things these are kinds of things that help you do drive operational intelligence and drive process efficiency within your IOT solution so what we're building with with TSI is time series insight short TSI I will use TSI a lot in this session to be to be short what we're building is capabilities for doing ad hoc exploration but also to be able to drive operational intelligence for where you know the shape of your data and you're explicitly modeling your data so that's the reason we think we consider ourselves a specialized solution for industrial IOT data analytics so to quickly jump into the architecture like with any other big data analytics capabilities you need to collect data you need to process data you need to store and analyze data that is standard practice you this is should not be surprising for you what we're doing it to to specifically address industrial IOT is obviously we have to consume data through a cloud gateway which should be IOT hub or event hub in our case we will also allow for batch uploading data if you have data on premises that's multi-year worth will allow you to batch upload data into our cloud cloud data leak we do some level of processing as Olivia pointed out we do no flattening of your JSON or and do type updates etc and be able to then route your data to warm or cold we'll build time-based retention based routing capabilities to store data in your warm storage or your cold storage I mentioned flexible data platform M I want to touch on it what we allow you to do is you bring your own Azure storage account so you own a storage account you provision that together with time-series insight so at the end of day you're the owner of your data you're pushing your telemetry data to your storage account what we do is we do work on your day on your telemetry data in your storage account to be able to index and partition that data such that it's available for query immediately so you we hear a lot of customers say I've already stored my data in a cloud data late I don't know what to do with it yet I want to make it available for analytics this is exactly what time series insights is useful for so when you bring your storage account you push your telemetry data we work on your data and we keep your data prep your data to be ready for for analytics another big part of this is contextualization so we support a time series model capability that allows you to model your your hierarchies your types and your variables and your instances and that allows you to if you already have a digital twin or as a framework that you're working with or a context you're working with you can map that directly into its analytical twin if you will such that you can now add context you through the telemetry that's coming through from your devices and sensors what we have is a distributed query engine that can then query both warm and cold and give you sort of signal processing semantics to be able to ask device based queries like device based do device based analysis you could be doing simple analysis that are just analytics or you may want to do very complex operational intelligence where you're going across devices we might be going across installations such that you can get up drive operational intelligence by correlating all sorts of interesting data and and we also have a visualization as was mentioned in the reference architecture we have our own app we call it the time series insights Explorer that allows you to do very rich visualizations we also provide a JavaScript control library that allows you as a customer if you want to build your own custom visualization to take our library of controls and go build your own custom application and are talking about the openness and flexibility of our data platform we store our data as a store data that's coming through telemetry that's streaming through in an open source file format which is a Apache park' what that allows you to do is to then take that data that you own in your storage account in an open source format to go push it to another system another data service to do other advanced analytics there we have several customers who want to be able to take data to HDI or data bricks or AML or even third-party data services so they can do some predictive maintenance type work do your modeling and bring it and bring it back to drive forecasting and that you've done modeling over so that's a very close that's a good open system that allows you to derive a lot of operational efficiency as you push data into that into the time series and size data Lake so very quickly I touched on this already I'm gonna skim through this time series optimized because we store data we store we first class time series as a first class object inside of our system which means that when you query you're not actually having to go look at multiple tables and do indexing and partitioning yourself we've already pre done it we've stored time series ID time series as a first class citizen and therefore you're querying by time series which means you're querying by your device or your asset and you're getting first class experience to do to do analytics and operational intelligence and this is done over cold and warm as I said we're providing rich contextualization your queries are highly scalable therefore and highly performant because of all the repartition we do on that data advanced analytics we talked about because of that openness of that data platform you can take data anywhere you want and you can bring it your data back into the same data like we talked about user experience we sit inside of the azure IOT organization which gives us a very big incentive to make our our integration with Azure IOT hub first-class so we have very good integration with IOT hub we leverage I to have you probably heard at the conference the announcement of plug-and-play model device model so we're going to be fully integrated into device models such that if you have a plug-and-play device that has a device model schema we talked about I think DT DL was announced in britain session earlier yesterday DT DL will be essentially what we call time series model will sort of be fully incorporated into DT D L such that you define your schema once for your device model for your entity twin and for your analytics such that you you're able to you may you may hook up your device through IOT hub into TSI and TSI automatically gleans that model you should have to re author the model inside of TSI so that's the idea your analytics light up the moment you have PNP enabled devices and last but not least very important one is that we have what we have for a business model is a consumption based model which means you pay as you go for what you use so we have split out the the meters such that you pay for the for how much you ingress you pay for how much you query and you pay for how much you store so based on where you store the data warm or cold you're probably paying more and warm because it's it's a ram and SSD based warm store but you're not paying for querying over warm on the other hand for cold you're not paying anything it's as your storage based very little not not being anything you are paying but very little and your queries you're paying per query over cold right so so there's a trade-off customers say hey I want to be able to do quick analytics over a short time span data and I'm willing to pay the price for storage but I want lots and lots and lots of analytics on the other hand I want to archive five years or ten years worth of data which I'm going to query very rarely for specific scenario so I'm willing to pay per query over cold so that's kind of the idea for where we went with the business model this is a very quick overview but I think what I'm going to do is skip this in the interest of the demo simply it shows similar a reference architecture that Olivier showed to show the path from ingestion to to processing to storage to analytics let me actually dive into the demo quickly so here's a adjure time series insights as it's as we released it at public as a public preview product at the end of at the beginning of December last year so what I'm gonna what I'm showing here is on the left-hand side you will see what I talked about in the time series model as hierarchy so we talked about context a lot so you'll see a bunch of context on the left-hand side so we are using a sample environment here that has a a fictitious contoso organization and Kanto so is managing a fleet of delivery trucks so they are deployed globally they have operations in Brazil Canada Mexico and USA so we kind of modeled your contours context to explore the entire hierarchy of how contours or might want to manage their fleets so if I start to open up these hierarchies I'll start to see the the region the hierarchy looks like it has the at the root node it has a region it has the the adventureworks transport system which is the servicing company Falcon which is the manufacturer themselves and the and the year the the fleet was manufactured and this is particularly specifically the model so we've described the hierarchy using a model and you can visualize that in the time series in incites Explorer application what I'm gonna do here is I'm going to look at a delivery truck 1008 and I'm going to drop a time series which is an asset so it's essentially I'm looking at a device and it's variable and I'm plotting that information what I'm trying to do is this gives you a lot of flexibility to explore and search etc what I'm gonna do is try to look for the last this is showing my last 24 hours and I'll look scan for the last 30 days worth of data and here is the specific time series there's very interesting information in here I can actually change the interval it's looking at two hour interval I can actually coarse-grain it further and look at a six hour or or a larger interval space I can do a few things here in the user experience I can I can look at you you can see that I have shadows enabled here so I'm actually not only looking at its the average information which shows me the min and Max actually looking at shadows as well so if I disable shadows I can actually look at the real data I may want to also there's probably hear some interesting data that I'm looking at there are spikes here I may want to zoom in and look at what's happening specifically with this with this particular time series I can also add some dots to show you the exact spots for sort of like simulating discrete actual discrete events themselves and feed to be able to see the exact maximum and the minimum for that particular particular time series what I want to show is a few more things in here before I get to the model let me actually add a another my running out of time not to you okay okay all right quickly quickly we looked at a specific time series we looked at a way to do analytics over a specific time series what I want to also show you is cross correlation of interesting device or different interesting variables coming from either a single installation or it could also be coming from multiple installations so here I'm looking at a single installation in this case adventureworks Works Falcon I'm looking at 2019 and specifically this and a delivery truck so you can look at you can see that my my user experience is showing me specific time series these are devices themselves delivery truck 2010 24 and I'm looking at two separate measures or variables as we call them average coolant and average temperature so they're plotted against each other against the same time span but I can start to look at correlation of what's happening when cooling goes up is to my temperature going down or how are they interacting with each other so I can also if I see it an anomaly I can actually zoom in to this and and understand what exactly is going on I can do some of the same userupp UI operations I was talking about which is you know I can remove the shadows add the shadows add discrete variables many of these things are in the supported by the engine some of these are UI specific features we're obviously making sure that our engine moves along as fast as we can to support the capabilities that we need and then I can do very I can do other things like if I want to share the query with if I have multiple users in my organization I want to share this query with other users I can share the query obviously I can save a query for later use if I want to come back and if I'm doing very very detailed analysis I may want to save this and come back later for usage as well the thing that I want to stop quickly and show you is the model itself so we talked about the hierarchy this is the hierarchy we looked at on the in the analytics user experience itself here's how I've modeled it so when your model time series model itself it's really a JSON schema you can upload the schema directly into TSI in time series insights you can also author this inside of the tool we don't expect customers with if you're dealing with you know millions of devices you're not really sitting here on authoring millions of instances right you're really authoring the JSON outside you're uploading the JSON into time series insights you may come here to edit or correct or course correct you may be adding a variable removing a variable that kind of stuff that kind of authoring is very very useful to do right here inside of the user experience I can I can certainly go and add additional sorry this I can certainly add new hierarchies I can select an existing hierarchy and edit the hierarchy as well if I want to add more levels etc your types are really your named calculations right so you can define variables for for each of those we give you a default type and we give you have the ability to add more variables to it as well your instances themselves are the actual time series and as you can see there's a number of different things that come with these instances you can you can start to define very very interesting in instance fields that allow you to bring your reference data essentially and so that you can start to do very very interesting correlations across within time series or across time series as well what I'm going to go back here in the interest of time I can also save and I'm going to skip say saving all this stuff we talked about open data platform and data connectivity to other data services I want to quickly show you how we do this so we are as part of and I'll talk about that in the next last slide which talks about roadmap we want to be able to give customers the ability to not only store data instead of time series insights data Lake but also give you the ability to take that data elsewhere for other stuff you might do a lot of our customers say hey can I take this data and go predictive analytics outside of time series insights because I have some I have a business investment in say as your data breaks so we should be able to take that and go do take the data out of time series insights and go go to as your data breaks and do your modeling there bring that model data back in to time series insights and continue to drive analytics or you may say there are there customers that come to us and say hey I want I use power bi heavily in my organization my my business users use power bi Allah wouldn't it be nice to take a few of your time series analytics over into power bi so we have we have many of these data connector work underway right now so I'll show you very quickly the power bi POC that we have in the work so we have a we built a connector that's still in in POC so if I go to a sure you'll see time series insights connector this is not publicly available to anyone just yet but we will make it available fairly soon we've given it to a few customers to go play with and give us feedback so you'll see that as your time series insights preview allows you to pick your data source what we've done with this is every query that you can you can you can experience inside of that's available every API that's available inside of a time series insights whether it's your model the model itself which is your hierarchies your types etc or the actual queries the aggregates and the raw api's themselves are available in power bi through this connector so you can take that and make those queries available inside of power bi so i can say take my saved query oops take my saved query here or use the cut the custom query that I that I'm creating that I want to create inside of power bi to push to my power bi dashboard I'm not going to do this right now because it's a slightly longer process those of you that abuse power bi know that you have to go through authentication and it's time-consuming so I'm going to quickly show you what we've done here so this is a power bi web we've taken a few of the queries from inside of time series you saw me show a verge speed Yami Yami shows speed versus temperature continuous time series those are all brought into power bi temperature versus vibration these are all the correlations that you are you doing live over streaming data inside of time series insights we've taken that same api's and exposed them inside a power bi the speed analysis scatter plotting which is another big feature that's coming into time series insights you can already start to do that if you'd get your variables inside of power bi the same power that you have in time series insights can be obtained inside of power bi by taking that same data and exposing it through the connector inside of power bi we're going we're doing the same effort across many other data connectors we have a spark connector that's in POC right now to expose data to HDI or data breaks and we'll be doing more down the road as well with that let's just quickly switch to slides and one last slide here to talk about the ten series insights roadmap there's a lot coming so feel free to stop by the boots and ask us questions about each of these line items there's a lot to go through we're bringing in warm and cold analytics what we released in public preview as of December last year is the cold long-term storage with Azure storage the open data capability that I talked about to bring in data and store it and model it and get rich operational insights what we're adding this summer is the ability to bring warm and cold into a single oops did I do that ah I didn't do that so alleviate not nice wonderful thank you so bringing warm and cold analytics into a single consumption based experience retention based routing we the plug in place and a very important takeaway for you guys from build if you've digested if you're looking to digest plug and play and digital twin concept please know that this is going to be one single offering with plug-and-play digital twin device model and time series model as a single unified schema with a single unified modeling language that's where we're driving towards to give you the end-to-end IOT solution and platform capability and everything above the platform will leverage it including IT central right there's a ton of X updates coming with time-series query we're adding scalar expressions signal reconstruction interpolation is a very big scenario for us composition with merging and joining time-weighted average discrete variables you saw some examples for taking the product to GA so enterprise readiness is big a lot of advanced advanced analytics were that's already underway including anomaly detection alerting and that sort of stuff lots of updates to the user experience you saw everything that we do in the engine will get exposed to our through our app as well of course you're free to use your own application or SDK will get updated as we go so you can take that or you can write your own app batch upload we talked about this is very important because we're taking in full-blown industrial IOT analytics as a strategy on and that means that a lot of our customers are coming from on premises so they're bringing their data to to Asher's data Lake which is the time series insights data Lake so being able to do a batch upload batch ingest as an important scenario for us data connectors we talked about we're taking ten series insights to the edge so we will be able to provide we again have some POCs underway we're serious about making sure that we provide a capable and capability or similar capability for edge scenarios as well and security not but not not the most important piece of this all we're doing a lot of work in the in the to support role based access control and multi-tenancy and data deletion so Eustace will talk a lot about security and I want to hand off to him with a minute or two delay sorry about that Eustace no problem Thank You Chandrika my name is Eustace Sangha and I'm program manager for security in Asia IOT so as shandricka integers this section is about security so when it comes in when it comes to IOT security must be end-to-end so this is not news to you but let me give me the chance to explain what it means to us it means whatever role you play in in IOT you must think about security holistically security from devices all the way to the cloud and that is the way we think about it at Microsoft so one of these ends is about device security go in the right direction security on devices so Microsoft we offer as the case in many languages out there where we implement security best practices into it we offer this for an operating system that you can use and will give you the freedom to be able to choose any route of trust in order to harden that security and the route of trust which may or may not own for Microsoft this include address fear and the guidance there is as you best know the the risk of your deployment and you can choose the security root of trust based on that then we talk about connectivity every connectivity of a device to Azure cloud is secured of a TLS so this is a very well mature standard and technology no need to spend a lot of time there and then when it comes to clouds Microsoft does a lot of investments there so one of them is the services that we implement in the cloud in order to assist device security so have services on Asia IOT hub you have services on Windows IOT and have Isis va services to assist device security then on the cloud itself there is tons of investment that Asia is doing on the if you search for either trust center you see a lot of this investment there and one objective measure of this is the number of Asia compliance the number of compliance offerings that you offer so this is Microsoft offers the most compliance for any cloud provider in the world and is one way to know how much investment Microsoft is doing because this is an object of objective way a transparent way of knowing the true investments in the cloud so as a platform of a platform that you can secure your devices on there our goal really is to have you forget about security for us to do it all but then there are certain things that really need your input there but not to worry we offer the tools to do that so one of those is about provisioning your devices so when it comes to provisioning only you know how your devices would manifest in your deployment where they are manufactured where they are going to be sold Harmonie custodians the device is going to change in its lifetime where they are retired and the one thing you don't want to worry about when you when you're provisioning your device is about moving identities from here and there what we offer you is device provisioning service which is a cloud control point a central point from the cloud we can control our devices control the provisioning of your devices so we give you that as a tool and once you provision the devices and you have your IT deployment up and running the next thing that is important is understanding the security posture of you IOT deployment at anytime and with this we offer Asia Security Center for IOT so this gives you the ability to monitor not only the security of the devices but the entire application from devices the cloud applications the operation of those applications the connectivity where are they coming from and even the administration of it including the admins of the cloud of the IOT deployment so if there's any anomalous anomalous behavior Asia IT security Center is there for you to notify you through alerts and it gives you suggestions on how you can go about remediating those alerts so we build this I will capture a lot of the common security practices the things that you need to be watching for but we also built it to be extensible so that you can add specific scenarios that are scenarios that are specific to your deployment so a platform for security and ability for you to provision the devices at scale globally and a way to monitor that you are deployment the security of your deployment so that gives you very good security today but moving forward if there's anything that you got from this presentation from Olivia and shandricka it's more than the devices it's more than the telemetry is more than the data it's about insights and having this inside generate valuable actions when it comes to this the insights we have more I'm not dependent on machines to be able to data telemetry generate actions to control infrastructure downstream sometimes critical infrastructure so in a power generation scenario for example it is not enough to gather information of the based on historical usage in order to turn on generators downstream you need to be able to manage how we turn on generators and turn those off real time based on real time consumptions and if we have this kind of compute these kinds of insights directly generating actions that control critical infrastructure down the stream or downstream the one thing that I start worrying about is who else has access into that compute environment for those insights and what can they do if they get access into it so for that we've been investing in confidential compute for the purpose of protecting these kinds of insights or even more abstractly offer a safe environment for which to carry out certain kinds of compute so what is confidential computing it's about using special hardware called trusted execution environment or enclaves that gives you a safe isolation a firewall around an enclosure where you can run sensitive workloads where you can manipulate data that is sensitive so that nobody else then gain access into it so with enclaves data workloads the sensitive workloads exist encrypted everywhere else except inside of the workloads authentication access into this environment is authenticated so that only the right personnel or the right actions can gain access into it and have policies that you can layer on it on how the compute inside of this environment how to compute work so to show how serious this is this isolation even distrust and operating systems because sometimes operating systems are vulnerable to zero day attacks so it's truly a hardware isolation down at that level some of the prominent technologies of truck of a trusted execution environment is chosen technology from arm and also software that extension SGX from Intel so this concept of trusted execution environment is not new but it's been localized in very niche industries like banking like government and the reason why why it hasn't spread out is because it's very very difficult to develop in this environment if you imagine environment where you gain no visibility into it and you using this environment for the most critical of workloads you can see that without ability to debug with the ability to write software and gain visibility into it it becomes very difficult to develop in there which is the task that Microsoft undertook in order to simplify this in IOT and the way we did this is through open anklet SDK which is an SDK abstraction over enclaves and consistent API across different enclaves technologies so our goal here is to use the same anklet API and technologies and deliver confidential computing where is at the edge or in the cloud itself so open anklet is in public preview open a cliff SDK is in public preview today but we are already getting applets in the industry so with alignment with some of our partners Skelly's being the forefront in putting what we call trust box which is an industrial brick iot in the struct great meaning that you can use the same box from your pilot and go into your pre-production so with scalise and using technologies like open end cliff and asia ith from microsoft and also trance on technology from arm and a shot from lay escape implements the transient technology we put together a solution that won the best of Innovation Awards in security and privacy as CES 2019 so this is a technology which is still in public preview but we are already winning awards on there so I'm going to switch now into demos but you have some links there I'm going to switch screens to go into demos but I have some links that are to come back to you but before I go there let me introduce the demos first time introduced the demos because I'm going to go to a different string screen so we're going to do a demo here it's about machine machine learning confidential compute ok so when it comes to machine learning and AI that is some of the area so you have intellectual property in their assets that you want to protect so in this particular example we will be doing confidential inferencing of handwritten digits so think of this as you have your AI model which is valuable to you and want to protect it you don't want anybody to gain access into it so I will show a series of demos here time permitting and this is going to build around open end clip out it is enabling this confidential compute area the first demo is going to use a UT central our SAS application on IOT so the highest level of abstraction here we're going to use it to access confidential inside of eight razn trusted transient technology inside trust box then the next one is going to showcase the use of confidential computing with Azure confidential compute so instead of our data centers today we already have Hardware trusted execution in hardware that offers trusted execution environment and also service Asia confidential computing that allows you to access confidential computing inside of the cloud and finally I'm going to show some demos about developer experience how really aim at simplifying this so these three demos I'm going to try to show and I think we have enough time to do those so switch notice fresh so in in front of me I have a trust about the device so this is trust box over here industrial grade device okay I have one of the devices in front of me and on the screen here is IOT central on there so over here the idea is you are developing in IOT central and you have these machine learning models that has been encrypted everywhere earth but loaded into the into trust zone and in there you can use it instead of trust own and do inference in there securely so what you are looking at here a series of samples the first sample is going to send a handwritten number to the second one is going to send a handwritten number one and then the third one is going to send nine we may not have time to run all of them but we'll get the idea here so sending the first sample and it's same and it's going to take a minute or two for it to come up here and while that is happening I'll go ahead and send a second sample so what is it we're doing here there is an image file and image capture of a file of a handwritten number our goal here is to be able to have machine learning detect this but does so inside of a inside of an inkless just in the next one now go to measurements so over here we have to feed back from it so the first one detected the number two the second one detected the number zero and the third one nine so two zero nine which is two zero nine which is what we expected okay now now I'm going to switch this and run the same demonstration using Azure confidential compute VMs inside of the cloud so one thing I need to do is to log in to a VM Enclave typing here okay end so what I want to do here is to start an SGS in cliff instead of HTC as your confidential computing I'll start a server there and what that is studying I'm going to launch a client from which I'm going to be running the commands from there so rock music okay as soon as I log into the client I will I'm try to zoom it may take a while to get there but see who might be able to get make sense of the result so what I'm going to do here is to send an image file into the xes and click the image file that I think is a - a handwritten - so that's the ASCII capture of the image and it influenced it and recognized - can we see this - I'm trying to zoom in so that's it - thank you Thank You Livie okay the idea there so in here we can do the nine send a nine image file for inferencing it came up with a nine trust me it's a nine out there and so on whatever number on there so I'll just write third number here an image of a hundred ten five and it detected a five so that is showing that with open end cliff using the same workload we can get the same results from trustzone instead of a device at the edge and also SGX hardware technology in Azure in in Azure okay and now the third demonstration is about the developer experience so for this a virtual machine disconnected get back into it it's loading so for the tooling our goal here is to maintain the same tools that developers are familiar with visual studio and visual studio code in order to develop to deliver the developer experience so what I'm launching here is Visual Studio code we may not have time for more than this but we're launching a Visual Studio code here then we're going to load an extension for it the extension for open anklet and in here I'm going to create an open end lift project select folder for the project choose the project type call the project open in clave so what I'm going to do before I walk to the source code I'm going to start the build in the background and take advantage of time there and it's out of the building so you have different architectures here I'm 64 and I'm 32 up there so this is going to be building in the background while I go in and show a few things on the source code so in the source code you have open as open anklet as the K here oh let's see how resilient it is built the built environment the dev kit but what I want to pull your attention to are these two folders here so there's a host for the regular application normal world application and in cliff for the trusted application that is going to be running in SGX or trustzone so in the main file in here on a main file what you see here is some function wrappers and I pull the attention to a few so here you have an open end cliff to create an end cliff called a cliff to call in to an end cliff and also closing it so let's look at the implementation of this and I'm not going to go into too too deep into it just for the sake of time so for the open end cliff what you see here is that it goes in and it decides whether it's an SGX or trust zone and cliff so what we're saying here is that for the developer you only need to call one function and this function is going to go in and create the right environment depending on the trust on the trusted application the technology behind the trusted application what as SGX or or otra Zone and for anybody who has developed in this environment though we would have noticed that in order to create an application that transfers calls between a normal wall and a secure wall and vice versa without leaking information or corrupting data this is extremely difficult and very involving we are trying to we are trying to simplify this bring that world into our normal traditional development environment one more thing so on the debug I promise to show you the deeper please just the debug terminal looks like it's still building yeah cuz of the earlier crash doesn't think we recovered a thing was gonna we're gonna catechist a obsession is one a 10 now right but anyhow it would have been the same step in step out run breakpoint the same debug experience on day I just gone through so thank you very much blimey known me for like eating few minutes at the beginning thank you guys we have other sessions we realize there was a lot of content in that one session so we'll be at the booth to answer your question for questions we'll be at the booth all day long tomorrow you have other sessions these sessions are recorded so after the event if you miss some you can actually go back and watch them thanks for attending you can go to ms to learn for learning more and then you can also answer the survey to tell us how we did and obviously give us good grades but in general we want your feedback positive or negative jokes aside so that we make better next time thanks a lot hope you enjoyed [Applause] 