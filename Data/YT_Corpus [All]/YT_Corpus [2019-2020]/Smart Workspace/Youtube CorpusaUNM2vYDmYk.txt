 hello everyone I'm Andrea and Allah knows and use a computer staff act act for VMware and I'm here today to give you an update on workspace 1 intelligence this is the August update that brings all the new features that we have been releasing on the past three months to get started let's start talking about the general improvements that we have up to this point engine responsible to generate the reports now in workspace 1 intelligence generate reports much faster you can request a report with a million records and that will be generated under a minute that is beneficial for the users that are requesting the data and also for those customers that one extract data using the workspace one intelligence API that will be beneficial for those as well we also added a new attribute called less sink time at boot for out data categories that shows the last time the record was synchronized with watch spatial intelligence and that's really beneficial for those that are troubleshooting you want to make sure they have the last version of the data a new wizard was added to the console the automated wizard that wizard allow the administrators to create automations based on existing objects for example you can have a predefined report with conditions and when you click an automated it will create a new automation reusing out the filters that you have predefined it on reports that works as well for the widgets and for out-of-the-box dashboards that we bring with workspace 1 intelligence we also add a quick filters to the console that allow the users to quickly filter objects based on the properties of those let's use this example the dashboards which contain multiple widgets in each widget access a snapshot or historical data it's based around devices apps or OS update you can quickly use the quick filters to filter only the snapshots in the device data and that will just feel that the widgets that respect those parameters you don't need to recreate the entire dashboards just to have that visualization you can easily use the quick filters for the we redesign with the app so many patient to bring out the information regarding applications consolidated into one single place that page now brings information regarding the deployment of mobile in desktop apps from the workspace on um it also includes information about the web apps launch it from what special on catalog that is integrated true identity analytics and also daily active users the app launches for the applications that contain the intelligence SDK additional information regard the top 10 apps install it is provided as well as the deployment pool platform in total app deployment on that page the security risk dashboard got some important update on this release and that's related to the vulnerabilities tab under the security risk dashboard which consolidated a view of Windows patch data from Windows 10 manage devices by um and correlated with severe metrics that provides some key charts on that page that shows you the vulnerable devices by CBS escort and also the non vulnerabilities and the impact of each one on those devices that page helps the administrator to easily identify the total number of endpoints that are current impacted by cv records and also help to take priority the seasons on which one to prioritize and apply the paths first let me show you how that look like into the console you can see here my security risk that I have the vulnerability tab and I have on this environment multiple TVs correlated with my KB's available on the device managed by you expects one um and for each TV you see the score and the number of devices impacted and the status of that specific cv is here so they are not installed below that you can see the vulnerable devices by CBS se score a score seven or higher is considered high as i impact by the CBS SI two dollars core methodology and you can see that the majority of the KB's that I don't have installed I really consider a critical or - arable by the cbss score so I really need to start taking a look at this in prioritize the application of those batches below you can see on that table that I have the no vulnerabilities and I can take a look and see the score when they will publish and impact it I can order here to help me to get some prohibition or if you wanna you can start filtering just the C fees that are related to the environment that you are looking for so you can also in addition to that go into each one of the grid the CV is available in look for the reference for the NIST article for that specific vulnerability and not just for the nice article but you can also look the Microsoft adviser article for that specific vulnerability and how that it is impacting all the Microsoft products or other Windows versions in this case here if you wanna you can drill down and look for that specific CV and see think back that's generated on your environment so you see that is installed in some devices but it's not it's available others in failing some of them in painting to installing others so I can easily use the automated wizard to approve patch for this the for this specific CV and I can start looking here that I wanna install that patch only on the devices that have that patch available or failure before and I will define an action that will approve that batch and I will use in this case here that lookup field that will look for the KB's associated to each one of that associated to that specific CV and that will approve the the patch on those devices as I defined my filter I see that 22 devices are impacted on those organization groups and three different organization groups and those are the device that we'll be getting back today and will be receiving that badge let's now talk about the enhancements regarding the automation connector when customers has workspace one uem deploy on premise and the API is hosted on the internal network some of these customers needs a gateway to provide access to the internal API server that's hosted on the internal network in general they just put the device servers in the awm server on the DMZ and everything else for security reasons must be hosted on the internal network in order to take out of my automation against the devices on that environment workspace one intelligence needs to access the API server to send the commands to those so in order to achieve that we are now supporting our customers that want to use in fie access gateway reverse proxy edge service as the Gateway to provide access to that internal API a hosted server in the order to do that they just need to configure a reverse proxy on tell unify access gate to that will be deployed on the DMZ and with that configuration they just need to provide the internal address for the API server and now so the proxy path partner that is fully documented on the in faxes scheduled documentation when they deployed a unify access Gator and the DMZ and provide that configuration of the reverse proxy they just need to go into the automation connector and enable that connector for the UM API the base URL is going to be the URL for your unified access gateway appliance and not the URL for the internal API server when you make that and provide the username password and the API key so you're gonna have the authorization from workstation um to access the internal server and with that you are just enabling the administrator to create actions that will take actions against the device or actions against the console for example move device from one organization group to another in ascent profiles and applications remove apps from the device and so on so all the actions available today with workspace one intelligence will be enabled by that architecture configuration that allows the intelligence to access the internal hosts of the API server let's now move into their workspace one intelligence connect or enhancements the intelligence connector is responsible to maintain data synchronization between what special new yem and intelligence the connector now support high availability and disaster recovery scenarios to help customers to maintain continuous synchronization and avoid any disruption on their environment and especially on the automated flows that rely on the data coming from you yet you can now deploy multiple connectors across sites and only one will be active synchronize the data although the ones going to be in standby waiting for the failure of that active one and then take place in a handful of billable scenario you can have on one side multiple connectors install it only ones gonna be the active and when we refer to active we mean the one portion data performing the synchronization between um database and intelligence all the order in this case the other one that you install it will be enabled as a service on your Windows Server but it will not be performing their replication so we don't refer to that as the active one if for any reason the connector on the host one fail after a couple seconds the intelligence connector on the second host will detect that and we'll just become the active one instead performing the replication of the data in a situation of disaster recover where you have a second site so you're going to be installing the connectors on that second site as well even if you have a situation of site one active site your passive you can have the connectors enable across all the sites because only one will be performing the replication so you don't need to be you can have the connectors on the second side disabled or down and just enable then when the dr happen but if you want to have less service to take care of in case of which one should it be activating or not you can have all of them active across sites because intelligence will be smart enough to only let one perform that synchronization in that case it's also important to remember that you need to have Seco server our zone and the server's the connector service will be connected to that listener to have access to the database and regarding to that so you now have on the sync Status page on the intelligence console you have a new property it's called server name that's the name of the server that active performing the replication between um and intelligence if you have like I said two or more connectors install it you're gonna see here the name of the one that's active performing that replication in addition to the server name of six types page we also added the date and time for the sync data category for apps always updates and device sensors you're gonna be able to see here the last time a Delta was sent for each one of those data categories in addition to that the last checking time for the intelligence connector has been improved and the information regarding when the checking time happened is available here in the sync status page you're going to be able to see the icons that represent the status of that checking time if the checking happened in less than 10 minutes you're gonna see the green icon saying everything is okay if the checking time is between 10 and 15 minutes you're gonna see the informational icon saying you are in that stage between the okay in the warning but everything should be fine and regarding that that that time if you start seeing warning icon that means the last thing checking time was beyond was 15 minutes or more and if you see a gyro it's because the last thing in sync in time was 30 minutes or more the service itself will be always checking in independent if that is their data to synchronize or not so that lets checking time really needs to be under 10 minutes so to show that everything is ok on your environment as we provide all this great information on the sync status page it's also important for IT to get automation around that so if something happened with the servers or something's about to happen you need to get notifications that something is happening the actions need to be taken so we are now exposed the intelligent stand API have status that allows you to obtain out information available the six steps page through the or the slash health API you just need to perform a request using your service account to access to perform the authentication against the API in that 200 ok response will be sent to you in addition to their results in JSON format about out there out information in matrix regarding the synchronization the intelligence connect to servers and so on if you are performing some monitoring and you want to do automation you regarded these status are the checking time of the intelligence connector there is a key that you have to look is the last dot checking that time and that is the key that will return you the status of the service it's going to be like you see on the screen here ok info warning or error so all this information about that he is nested under the ETL servers health reports which is nested under the ATL service matrix so you can use that API to perform the automation and also to perform notifications to your IT team in case your intelligence connector on-premise service is failing for some reason let's move into the app analytics arena and let me show you what's new regarding user flows user flows allows the monitoring of user behavior and performs of critical business transactions on native mobile apps iOS and Android it allows the developers to track interactions of the user on specific parts of the application for example when you perform the login when you are registering a customer during the application want to make a purchase of a product through your app and so on using the SDK that's embedded on the native mobile app you get by Defoe upload user flow that shows you the number of uploads in the time after that flow regarded a lot of the application and also although the flows that you're going to be able to customize on that if you have between those flows a crash happening or a breadcrumbed associated between those flows it will be automatically captured by the SDK and that information is also added to the intelligence console and we correlated with the user flows so let me show you a little bit how that works in the sense of the real web let's get as example a tracking of successful user login application let's say I download the application and them say it's Amazon here in this case I launch the Amazon app and on my application let's assume that I embedded SDK on this app I will get automatically upload user flow so that's come automatically because there's the case embedded on the app let's say the user click Sign In and I added on the code of their application a method called begin user flow and I named that flow login so i'm initiating the here so the user goes both Danny Mayo click continue and then when he click the container he performed the stacks will login on the application he didn't provide the password here because maybe he already had the password storage or he was using face ID or any biometric feature that's available in his phone so when he performed it login successful I the developer add a piece of code saying ain't use afloat logging so that means this whole flow was successfully completed because there is nowhere who nobody should the user perform everything as it's supposed to be let's now move into a second flow and let's show you what happened in case of an unsuccessful user login the same process installed the app click sign in you have the upload here because you are loaded up the first time and we initiate a code initiate the flow based on the code that we provide the user will type the continue that include his login click continue II provide the password in he case they provide the wrong password here and after they click sign in he may get a message saying paso do incorrect or we cannot in this case you cannot find a count with de maio address so that is a problem here so I can just finalize the flow here saying failure user flow it could be because the password in this case the passer was incorrect but let's see if they have detected some other problem like he could not authenticate the user against the backend server that is considering flouted failure so in this case I'm gonna get that information say that flow fails regarding the usage of this application on this device and so on all this data from the application regarding the user flow is getting sent to the workspace one intelligence and other the apps dashboards you can go into your specific apps and you can see information regarding in addition the deployment formation you have now a new tab saying user flows which are the flows regarding your application you're going to be able to see out of laws that are generated by this application the number of times that that one that each flows of course the average time he called you each one of them how many times they are successful how many times they are failure and you can also have this aggregated view here that shows all of those flows here combined into one single chart as you can have a separate chart showing you just the ones that are failing in addition to that you're going to be able to drill down in each flow and then you can see the related information regarding crashes for that specific flows I know that how many times the flow was call it but I also knows how many times each each occurrence that was successful and each one that are related to a crash in this case I have the crash here and you can see automatically bread crumb that came in with that crash the automatic read camp here is related to the device to last the Wi-Fi connection that could be because the user turn it off or even because some disk on automatic disconnection of their Wi-Fi for that device there is also specific custom breadcrumbs that are centered by the application so the developer called that to send some specific breadcrumbs and then I have here below the crash that was captured by the application automatic by the SDK automatically and sent to the console let me show you a little demo on how that happened in real time between Android application and watch page one Intelligence console let's go into the apps dashboards and the first thing that I have to do is search for your application that has the intelligence as the game that I have my application that's called W so app analytics and the overview page give me some nice insights about what's going on application the day lefting active users monthly active users the percentage of users engaged with the application is the correlation between daily active users the most active users also the number of loads and also the deployment application that's information that's correlated Yam show me where how many the ones I have for this application some information regarding the deployment for version since I had multiple versions of this application over the past weeks I know how the users are adopting those new versions based upon new releases and fix that I have been provided so why not install over time as well yeah in that day that's it there are couple information that's really critical for us here and I'm gonna show a couple things happening all the device at the same time you see the intelligence console you can see here that I have the daily active users on the last 24 hours as I have swelled the monthly active users over the past 30 days and the last metric the number of uploads in the past 30 days as I start loading the application on the device you can see that I loaded the application on my Android device and then I load another time here and I will refresh the console in this case when they refresh the console I see another upload to me this is almost real time so they sdk detects its accumulate a little bit of data and send the information to to the console you can also see how the user flows that I have defining on my application so this is this kind of simulation in those flows that you see in the application they look like the here on the console as well I have 235 points of the offloads combined and just want that fails at this point you can see here there on the confirmation I have some failure in 56 very very unsuccessful as I have as well on the failures shark that just the flows that are failing and the post enters related to that on a daily basis at the bottom you have the total pressures so crashes that happen between the flows you see that I don't have that much but I came here go deeper in look at exactly on the crash that's happened per flow and I'm going to be able to see where they start there they crashes the bread crumbs the automatic and the custom ones that is available here as well let's now go to that occasionally that I'm doing some simulation of starting and finishing beginning and some flows and all of this that I'm doing here is I'd refresh the application it will the flag on the console as well you can see that I keep I keep pressing beginning and I can't forgive simulating flows so they SDK to come you label those flows and send this over time so it's not actually standing make a simple time right Jamar consumed a lot of the networking the concept of only so walk but it's always well did I don't do something kind things here that will drive breadcrumbs so I see that i understanding custom breadcrumbs I just connected that Sloan phone from the Wi-Fi so that that's looking good like that and I'm now generating a section so simply in a section that crash that all my device so that now I load the application again I you refresh the console I see that the Browse user flows the reserve pops up but I don't see yet the crashes right so I just did depression in the reason I don't see the crash is because I'm disconnected from the Wi-Fi so it was not able to stand up to the fresh that information which is fine at this point so what's gonna happen is as I connected the Wi-Fi again there's the gate attack that now it send me the two phase that happen so in the new one is related to the confirm flow that I was demonstrating when I going to confirm flow you can see there I can see all the flows so I can see that I connect and I connected the Wi-Fi I was just connected from the Wi-Fi my custom breadcrumbs that I said in the exception that was generated by the crash that happened to the application in okay all the best crashes as well let's move into workspace run censors that's now GA censors is a powerful capability that allows edge administrators to run PowerShell scripts on their Windows 10 managed devices and report that data to watch based on intelligence on works based on intelligence IT administrators will be able to leverage reports and dashboards to query the devices sensor data and also create real-time automation to execute workflows against their devices or send message to is lag or creates tickets with servicing out all the sensors that you created with work special new um they are named it on the UM console and each one of the sensors in their respective name will be sending to intelligence the name that you define for the sensors become the attribute for the device sensor category on it tells us with that information available intelligence administrators can have really deep insights on what's going on on their on their devices from the support perspective there are three features available on workspace on intelligence with sensors the reports dashboards in automation and you can work with the data based on the snapshot data the historical data is not available yet but we are working the director to make that data available so from the license perspective workspace one intelligence reports is available for our workspace one new yum users however to get access for the sensors category specifically you need um advances or greater skill for that - reporting automation is to query sensor data and other data categories are available through intelligence at home or through WordPress run um Enterprise skills so it's very important to make sure that when you have your - reminder that when you have your your um standard skill that one does not include sensors you can use the report capabilities on intelligence to query device sensors and all the device sensors attribute collected by um will be available on the report as well you can take any of the attributes and add as a column and on the report when the report is generated in the CSV file downloaded those attributes will be available as a column and exportable not just for the UI but also available through the intelligence API as well in addition to that you can establish filters on the report and use any advert in ur a by sensor as part of the filtering condition to generate the report you can also query device sensor data using dashboards and add widgets to the dashboards so on the each widget that you created you can leverage the device sense of attributes as part of the condition and also add those attributes as part of the shot itself would be horizontal vertical donut metric and no matter what the type of short you can use those attributes to really define to redefine the the visualization that will help you to understand better your environment as an example you see that dashboard here where I use multiple different attributes and types of shirts to represent the information that's relevant for me and we look for the Java version attribute that returned the Java version stolen to the machines and I'm using a bar chart here that shows the number of device that has version 8.0 installed versus the devices that doesn't have Java installed so far you can see the number of the by step using the BitLocker and what is the encryption method used by those devices as tables to show me the amount of megabytes in pictures that contain in each folder of the devices and some information about the hardware itself like the TPM present or not on those devices the bio security boot equipment on those devices or not and if there is a mismatch on the md5 hash for the svchost.exe so those are some of the examples of visualization that can be created and they are fully available to leverage the data generated by sensors on what special new yam and available here on workspace one intelligence as a well let's but not lease you can leverage automation using device sensor data in this example you can take a look and see there are me looking for a specific hash on the devices that were collected previous by sensors and in case those devices have this hash identify it I'm gonna be creating surfacing all ticket with the information from the device in addition to the lookup values that I'm using here which is art related to the sensors you can also leverage the look at values for the UM device data category as part of the action on the automation as well even if they're actually serves now is like or um data when you are creating that automation you can look the results here in real time to see how many devices will be impacted by the automation that you are defining in this case I see five here so I know that five devices has this fire with that specific hash which tells me that that's a potential malware on those machines and you can for example group by by one of the attributes here in the attribute that I collected is the DNS hostname for those machines so that helped me identify what are the machines that we are working against here there are some important considerations when you are writing sensory scripts the first one is about handling exceptions make sure you hand reception's on your script if you don't hand reception's what's gonna happen is the output will not be returned it and you're gonna be seeing on the UM log that there is a hole for that specific script so that will not cancel the execution of the other sensors that you have assigned it to the device but will not just return the value for this one so there are some techniques that you can use using the who are variable your actual parameters on the commands that you were securing from PowerShell that helps you that that doesn't throw a section and return the in this case when I ever happen probably will return a new object and you can handle that no object on the PowerShell to not draw exception the second one is regarding the data type so when you write the output which means the return of the parameter for from PowerShell to watch based on new um that data will be sending true intelligence in the way how you send the data type will define how we're going to be able to query the data for example if you return the data as a string those are the operators that you can use if you return as integer those are the one that you can use so let's say you need to return a number and you return that as a string you're not going to be able to use between operator because you only have that available for that you returned as a string that's what you have available in the betweens on the integer datatype the same applies if you are returning something that is boolean you need to return true or false right so you need to return as a balloon and you can see here the operations that are available for the data time as well so make sure that you were casting converting the value of the output to the correct data type because that will impact your ability to query the data in addition to that specific for the date and time datatype you must return that in ISO format so this is just example how when you use get data in PowerShell use the - format as to convert the return of that call to the ISO format any type of compression that your script is doing it's really important at the final one the output comes in in ISO format authorized if that doesn't come on that format um you not going to be able to convert the data type and that will end up not return any results for your for for your sensors so if you just do that using the ISO format everything is gonna be working as expected and you can end up seeing the return on workspace one intelligence for troubleshooting in case you are not seeing the data on workspace one intelligence the first place you should start troubleshooting is on the device side and then you can go in the workspace on um console under the device details page on troubleshooting tab and you can start looking for the logs and see if the device is really requesting the sensors so you're going to be able to see a list of actions pretty much saying assign device sensor requested that's when the device requests a sensor and if some of the sensors fail you're gonna see one on entry log sample receive you with error this is just a notification warning for the sensors that are failing not necessarily out of it the sensors are failing but you're gonna be able to see on that log which ones are the one failing so just look in the console gives you a pretty good idea what's going on if you want to go deeper and more advanced that you can look for the logs on the device under there what unified agent logs there are couple arcs that you can take a look the task scheduler log and also see they take configuration to what they're logging for both on the task scheduler that exceed that config on the intelligence side you can look for the sync Status page to see if this the data is getting synchronized with workspace one intelligence that is under the sickle sync status page the last device sensor category sync that shows you the last time there data between you Yemen intelligence were synchronized you can if that is a lack a gap on that synchronization you can go into your device serve server the vet device service server and look for their logs on the date platform processor log which shows you their synchronization everything that's happening between the synchronization of um and workspace one intelligence with that you end up having now four data categories for what special new um and for all of them you have the ability to query data to reports and dashboards and you can now so automated workflows using automation for any of those categories another exciting news is the general availability of the intelligence API the intelligence API is the new recipe I interface allowing each administrators to query and extract snapshot data from what spatial intelligence that we all allow the IT administrators to integrate intelligence data with other systems and business tools to leverage better workflows automated process as part of the entire organization to access the API education happen using a service account that when performed our education the user get access talking to perform queries using the following api's the intelligence API documentation is available via more code you can see here a short link URL that described how the API is available in how to call them as I mentioned to access the API you need a service account credentials and in order to do that with this is like the required in the number one requirement to access the API you can go on intelligence counseling create those service accounts which will give you a client ID and client secret client ID is a user name client secret is the password when you perform the call against the talking endpoint it will return your access token that will be used on the following course when you create that service account so the client secret is generated and is gonna be available it's going to be actually when you create to the console is gonna create a JSON file with the client secret that's the only time you're going to be able to see that client secret if you lose that client secret you have to regenerate the client secret to the service account that will no not be available today why you're not going to be able to see that again after generate the first time there are a number of API is available in those are our document like I mentioned but here's some of them that you're going to be able to use like leverage the report API metadata leverage API to create running search and schedule report as download with performer report preview all set recipients like emails that you want to be assigned to the report to send automatically when they get generated so the first step to use the API is like I mentioned create your intelligence service account with that intelligence service account you're going to be requesting authorization to access the API using your service account as your grant access that will return to you access token and that access token will need to be used in every single following call this is just example so while you perform the post is a post action that you need to be performing it API return this 200 okay and this is an example of how look likes the access talking for you to perform querying against the workspace one intelligence api's with the access token in hand now we can start querying extract data the first one would be for example in this example create a report so you use the API slash reports API in pass the definition in that definition will tell the API I wanna extract um data passing the AirWatch as an integration parameter I want to query device data the name of my report the description what are the columns that I want to be the one a part of the results of this report and what are the filter filtering conditions for the report as well when you run that API you you pretty much define your report so as a result of that you're going to be able to go into the console and see that that report was created the following one is going to be a post on the API slash reports run to run that report and when you run that report you were just requesting intelligence to process that report and later download file you the report is created in this example here when you run the report you call a second API / API reports / ideas let's download / search that returns you the status of your report initially when you run the report you get the status initiated as the report get completed it will switch for the completely status with that status as completed you can go into the following API in call the download report API because the report was completed right so you now can get access to the data in looking for the API / report / tracking + / the idea of the report generated / downloads you perform a get in that will return their report that you created initially so the data for the report that you initially created this is just example how we can use the API if you want more details and learn more in depth how to call and actually do our hands on the API look for the taxes on operation tutorial getting started with workspace 1 intelligence api's that will give you a deeper insight on how to use how to call the API it's not just the ones that I presented here but also additional api's that are available for you also I recommend you to take a look on the official documentation that described in more details other api's that are available as well to use that's it for this update if you want a more technical information on workspace one intelligence and out the VMware end-user computing products visit Texan dot V eMERCOM you're going to be able to find tutorials videos quick starts reference architecture with all the technical formation about our products that will be very helpful for you to improve your skills and knowledge man around you see check very much and see you next time that's it for the unified access gateway 3.6 release if you want to learn any more visit texans via more calm and access the unify access gateway Learning Path where you can learn it through videos tutorials operational guy reference the architectures and much more about info access gateway thank you and see you soon 