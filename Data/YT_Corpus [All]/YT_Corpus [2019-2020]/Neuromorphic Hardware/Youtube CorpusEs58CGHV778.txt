 [Music] hi I'm Jeff Witek head of products at ampere computing we're a passionate experienced team committed to building the next generation processors designed for the cloud and edge when we talk about the cloud we're focused on both the hyper scale clouds as well as the emerging edge cloud as well looking back over the last 10 or 15 years the needs of the cloud have dramatically diverged from the needs of traditional enterprise IT a number of changes have occurred the software ecosystem has changed and developers have moved towards cloud native applications and the associated shift towards containers and micro services there's been a large growth in the edge which necessitates distributed computing across your entire infrastructure and also demands increases in power efficiency as well as additional demands to increase the density of computer for large hyper scalars also with the emergence and the growth in AI and machine learning this increased the need for compute capabilities across the entire infrastructure and lastly as the file service providers an optimized infrastructures they've moved towards more and more customized architectures especially those that are heterogeneous they're starting to deploy GPUs for AI training they're using smart Nix for network offload and increasingly they're looking at using non x86 CPUs in their infrastructure as well now looking back over the last 10 or 12 years the current solutions just don't meet the needs of the cloud from 2008 to 2013 x86 processors were able to increase performance by 60 percent annually and improved performance per watt at the same rate however since 2013 the rate of innovation has slowed down dramatically not only had the rate of improvement and performance lower but the performance per watt increases have similarly slowed as more and more power is needed to increase performance year after the earth and power consumption is more than just a concern around density and effects it's a global issue as well today data centers consume about 3% of the worldwide energy however experts predict that could grow to as much as 11 percent over the next decade now over the last five or ten years that 3% number has been able to be maintained because of innovations in data center D efficiency as PUA has decreased however all of the easy things have been done we need new innovation in order to continue to maintain the current levels of energy consumption and when we look at greenhouse gas emissions the airline industry is currently regarded as a major offender however data centers today currently emit as much greenhouse gas every year as they their online industry we need power efficient processors in order to continue to improve those numbers over time at ampere when we look at the needs of the modern cloud we think of three key areas one the cloud needs predictable high performance - it needs scalability across the entire platform from cores to IO to memory and three it needs power efficiency and density in order to meet these needs we've developed the world's first cloud native processor the ampere ultra processor this is the first CPU that was designed from the ground up for the unique needs of the modern flower our ampere ultra processor has 80 cores to deliver high performance exceeding any other CPU in the market its scalable across IO and across memory with more i/o bandwidth and more memory bandwidth and any other processor in the server market and it's the most power efficient serve a processor in the market as well from a processor perspective the ampere ultra processor has 80 64-bit arm horse each core is able to run at a sustained three degrees that's three gigahertz across all cores across a wide variety of cloud world once again it's important that we deliver consistent performance regardless of how many users are on the platform and regardless of what workloads are actually running in addition to the consistent turbo performance that the ampere ultra processor provides we've also designed the core to be single threaded in order to provide better performance and security isolation the 80 course are connected by a high bandwidth meshed interconnect on a model of that guy we specifically chose to design this generation of processors with a monolithic die in order to avoid bottlenecks that occur in current multi chip architectures we've also emphasized a very large cache especially our l1 and l2 private caches we have a 64 K instruction in data l1 cache and a full megabyte of private cache in the l2 you don't have to worry about the resource contention from the various scores because the l1 in the l2 cache are private and not shared additionally we chose to optimize these caches because they're closer to the core which provides higher performance and lower latency the ampere ultra processor also has a single 32 Meg shared system level cache additionally the ampere ultra processor has 220 B 8-bit 70 units for vector and floating-point performance since inference performance is becoming increasingly important as AI inference is being done across a wide variety of servers and infrastructure we've also introduced in Tait and FP 16 support for those who are using those 2 or formats for inference performance improvement now expanding on a single-threaded approach we specifically designed our course to avoid noisy neighbor issues this can show up in a performance or insecurity and by having single threaded cores where new threads are sharing the execution engine the registers are the l1 or the l2 cache we avoid this type of resource contention and were able to better provide security in isolation by reducing the attack surface this has become a particularly problematic issue over the last couple years with some of the side channel attacks that have become prevalent in the industry in addition to resource isolation the single threaded cores provide more consistent execution of instructions in the case of a multi-threaded course two threads are executing at any given time these threads typically belong to two different users on a single system and as thread one executes eventually it stalls in it because of the cache miss or branch mispredict thread two that began is executing thread one doesn't get control again until thread two stalls so this results in a larger total number of clock cycles required in order to execute user ones instructions in the case of a single threaded core like the ampere ultra processor one is able to finish executions and a much more consistent and predictable number of clock cycles meaning that each user has consistent latency the ampere ultra processor also has an optimized memory subsystem the prostitution supports eight memory channels of ddr4 memory at 3,200 megahertz it also supports two dimms per channel also at that same 32 hundred megahertz speed this allows for by the maximum possible memory bandwidth to feed the 80 cores in our processor we also support a total of four terabytes of memory in a single socket system or eight terabytes of memory in a dual socket system now not only as the ampere ultra processor have high memory bandwidth but we also need to deliver our high i/o bandwidth and family the processor supports 128 PCIe gen four lands in a one socket platform and 192 PCIe Jen for lanes and into socket platform this is more io bandwidth and connectivity than any other server platform in the market not only do we support high i/o bandwidth and fan-out but also our by 16 controller is bifurcated down two by two this means that not only do you have the option of connecting a lot of high bandwidth GPUs via our by 16 controllers but you can also connect many nvme devices in by two mode for extremely high fan-out now another thing is unique about the ampere elzar processor is that across parts to stack we're supporting the full range of i/o memory and features across all the CPUs that we produce will support full memory capacity full memory bandwidth full IO bandwidth as well as all of the other features like our raspberry noise the ampere ultra processor also supports c6 connectivity at the platform level for the attach of cache coherent accelerators or storage class memory our philosophy when it comes to i/o has been to embrace a multitude of flexible IO options especially those that rely on open standards like sea snakes from manageability perspective the ampere ultra processor supports armed SPS a level 4 so customers know that when they deploy our platforms they work seamlessly with their existing infrastructure it also has the full range of performance and thermal management features that you would expect out of a server class processor the ampere ultra processor also has a full range of Rass features now that I've told you about the ampere ultra processor and the way that we designed it for the needs of the modern cloud it's time to look at the actual data to prove how well it performs the ampere ultra processor and its 80 cores outperform the four core AMD epoch processor and the 28 core Intel Xeon processor providing leadership performance across all the performance sensitive workloads in a cloud with that's AI inference transcode or database when we take power efficiency into account the lead extends even further the ampere ultra processor leaves that am the epic processor by 14% and the Intel Xeon processor by over 2x this provides not only scale ability to deploy the ampere ultra processor out of the edge but it also provides the right level of performance and power for sensitive applications like front-end web and cloud gaming another metric that cloud service providers looked at when they're assessing the scalability and density of solutions is a number of cores that they can deploy per rack at some point they run into a rack level power limiter which constrains their ability to continue to deploy more and more coarse in the cloud more cores mean more users more services more recommended because the ampere ultra processor has the industry's lowest powered record of any data center processor we're able to deliver more cores per rack than any other solution the ampere ultra processor delivers over 3500 cores per rack that's 30% more cores per rack and am the epic processor and 173 percent more cores than the Intel Xeon processor the ampere ultra processor is the leading solution for maximum density in your data center total cost of ownership is also an important consideration for cloud service providers once again the ampere ultra processor reads both Intel and AMD the ampere ultra processor provides 41% more performance per TCO than the a.m. the epic processor and 63% more performance per TCO in the Intel Xeon processor this is true even after the recent price cuts with Intel's CASP a late refresh what's really exciting is the fact that the ampere ultra processor is sampling now we're proud to be partnered with gigabyte to bring ampere ultra to the market this all starts with the MP 32 a r0 motherboard which enables the full breadth of vampire ultra capabilities up to 80 cores eight memory channels with a total of 16 games with a ddr 4 speed of 3200 and a massive PCIe design ampere ultra uses PCIe gem for and the MP 32 can provide 2 by 16 slots and 5 by 8 slots with additional flexibility possible around m dot 2 and the OCP make the form factor of MP 32 is standard ATX which makes an extremely flexible server board the MP 32 goes into both the our 272 to use single socket server series for cloud and the e 250 to P 32 you edge computing server just like ampere gigabyte expanding the cloud from hyper scale to edge and don't worry there are many other platforms and it works and ampere we will continue to deliver the world's highest performance most scalable and most power efficient processors uniquely designed for the needs of the modern cloud and we're excited to have a gigabyte as a partner and building a truly cloud native platform you 