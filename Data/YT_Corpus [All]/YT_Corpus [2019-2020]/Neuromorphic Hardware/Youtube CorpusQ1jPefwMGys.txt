 all right well yes my name is Ryan Henry Lee and I'm a postdoc than giving this presentation on behalf of Dirk England who unfortunately can't make it because he we have this photonics conference called Clio every year at at this time so is it this talk like the many of the other talks is about accelerators for deep learning so I don't think I need to introduce this by this point deep learning has many applications including image and video processing game playing speech recognition control in the list of potential applications is growing every year in this talk I am going to well I can skip to some of the introduction we all know what neural networks are I'll briefly discuss some of the hardware accelerators for deep learning and the pros and cons and figures of merit of those accelerators and then how photonics can potentially play a role in serving as a deep learning accelerator and then I'm going to get to some of our contributions which are a new photonic approach to developing a machine learning accelerator that we call quantum photoelectric multiplication and then I'll discuss some of the some of the simulation work that we've done based on this approach and then potential extensions of that so in the field of deep learning usually people present diagrams like this this is a feed-forward deep neural network it consists of a number of layers and then each layer has a set of neurons that perform what is called a nonlinear activation function and then there are a set of connections between neurons called synapses if well this is a good way to think about deep neural network in a graph theoretic or a physical perspective what a computer sees is something that looks more like this which is it's a set of steps and they're each layer consists of two steps of two different types one is a linear matrix vector multiplication so these are the gray blocks and one are of vectorize non-linear functions or the red blocks and so any given feed-forward neural network can be can't be run at least in people in the inference mode with a very simple set of a command so if you write up this Python code here then you just iterate over all the layers of your neural network and then in each layer you are performing a matrix vector multiply and you are performing a vectorized nonlinear function and these nonlinear functions tend to be fairly simple functions like sigmoids or Raley's so a lot of this has been around for a while but what distinguishes present-day deep learning from when many of these concepts were developed in the 80s or earlier is that nowadays we have more data and as has been mentioned several times we also have much more computing so with Moore's law he compared to where we were in the 80s we have a few orders of magnitude more transistors and a similar amount of more processing power on the other hand the demand for deep learning applications is also growing exponentially and it's in fact outpacing the CPU scaling and a reason for this is that to get better accuracy at these problems and also to solve more complicated problems you need larger and deeper neural networks so a great example is one problem that many networks have been developed for or alex net or sorry image net where over time the classification accuracy has grown but that has come at the cost of an exponential growth in the number of operations required for these neural networks and a great extreme example of that is the training of the neural network that when it is to beating the champions at chess and go alpha zero that required the network to play against itself three billion games or over 20,000 TPU hours so this is something that's not only running up against the limits of what I can do with my garage but what Google can do in there centers so this has motivated the need for specialized hardware going from first from CPUs to GPUs but now going from GPUs to special-purpose chips like TP news or Asics and we believe that boat onyx can play a role here so there are a number of products already on the market that are either special-purpose chips for deep learning or they have developed or they have added special-purpose functionality undo more general-purpose chips that are designed to speed up the operation of deep neural networks and guiding the design of these accelerators are several considerations one is that a key metric and all of these devices is going to be power consumption either you're on the edge where you are fundamentally limited by power or you're in a data center where you're going to run your tip at the thermal design power of the system and the second is that the bottleneck step here is not the non-linearity in the neurons it's usually the matrix operations and that makes sense because that's an N squared versus n thing to do a matrix vector product is N squared where as the activation functions that'll only go as order n and the third and this is something that didn't we had talked about at the earlier this morning is that data movement and memory access rather than processing usually or what dominate the energy consumption here now ooh [Music] but they're the the goal that I'm going to talk about is trying to build a photonic neural network that beats the state-of-the-art of all of these digital CMOS processors and in particular in this talk I'm going to look at trying to beat the state of the art to energy consumption figure there the one Pico Joule per Mac now what we're doing it's a different from just building a an optical computer if you want to build a general-purpose optical computer you will immediately run into a number of roadblocks one of these roadblocks is that a general-purpose computer requires that is built out of gates or transistors and gates or transistors require non-linearity non-linearity is pretty straightforward to get in electronics but in optics optical non-linearity exists but it tends to be very weak so in order to operate at the required energy levels you need to work with very small high Q resonators so that's pretty hard in photonics also memory is pretty easy to get in electronics but in optics that's hard just because the photons like to be free and they fly everywhere gain is something that you can get in both electronics and in optics if you if you have gained media they're usually off chip on the other hand you are interested in communication rather than computing then you are find that optics is a better platform for that so in electronics communication is pretty straightforward over wires but you have limitations to your bandwidth and also the energy consumption of those wires fundamentally on the chip it's this CV squared charging of wires between points on a chip whereas in photonics provided that you can get your signals into an optical form then propagating through optical waveguides is essentially free and that's also true not just for one-to-one communication but also for fan-out a third a third aspect of computing that is especially relevant for deep neural networks is how well these two platforms can perform linear algebra so if you restrict yourself to digital electronics for a moment then linear algebra is hard because you have to express your linear algebra operations in terms of these Blas operations which are a bunch of multiplies and adds so there's a big overhead there but if you want to do things in photonics and you're willing to work in analog that actually becomes fairly easy because the Maxwell's equations are linear equations so if you have a way of manipulating the medium through which light propagates then you're able to solve these a linear algebra equations at potentially zero energy cost in objects and so given that most of deep learning is linear algebra in terms of the rate limiting step and that linear algebra is mostly passed can be implemented with passive looming at linear optics this is a potential way to provide high speed acceleration for these problems using photonics so motivated by that line of reasoning a year before I joined Dirk's group we our group worked on what we call the programmable nano photonic processor optical neural network this is work that was done in collaboration between Dirk and Marin so logics group also at MIT the idea here was that you want to create a some kind of an animatronic chip that if given inputs which are encoded into the optical fields that come into each of your waveguides coming onto the into the side of the chip you want this chip to be able to perform a programmable matrix vector multiplication so that the outputs which are the elements of your output vector that vector is equal to some matrix which is encoded by the states of this device times the input vector and the way that works mathematically is that what we have here are a bunch of tunable beam splitters and these beam splitters will mix the input from channel 1 and channel 2 there's a mixing angle and then there's some output phase and if you cascade enough of these beam splitters you can get all of the degrees of freedom in your matrix which allows you to fully program your matrix and the there are theorems that prove that this works so this is a demonstration that our group did is a it's a photonic tip of this size you can see it's a not small it's a couple of millimeters and on the other hand the neural network is pretty small it's four inputs and it goes to four outputs but it is a promising approach and so based on that approach the group spun off to startups one was mentioned earlier that was liked elegance and the other is like matter and they have so far acquired quite a bit of funding from Google Ventures and that PI do and they are trying to tackle this approach to photonic machine learning there are however a couple of challenges to this approach and too many photonic approaches one is that the chip area this type of device is very hungry in terms of its chip area if you look at the fundamental unit cell of this device is one of these programmable beam splitters in a programmable beam splitter to be programmable it needs to have programmable phase shifters and in optics programmable phase shifters tend to be pretty long because the change in the optical index you can acquire you know didn't buy something like thermal heating is fairly small so these programmable these programmable phase shifters tend to be at least tens of or micrometres causing this whole unit cell to be of order a 100 microns squared so so that that Kip area of these blocks is going to fundamentally limit how many of these blocks you can put on to a reticle which will fundamentally limit how large of a network you can run in this device now what approach might be maybe you just use make a very large chip and then just hope that the performance advantage of this over a comparable electronic chip is just so large that that can just you can justify having such a large chip but it is problematic for scaling and again this the number of phase shifters required is equal to the number of elements in your matrix so that goes as order N squared so the larger n is or the number of neurons it becomes very difficult to scale this in addition there is a an error propagation issue where each of these being a splitters that's an error that propagates all the way down so we had some collaborators at Lincoln lab that looked at the feasibility of this protein they came to the conclusion that it was probably going to be difficult to scale beyond hundreds of optical neurons at least on a normal sized photonic chip and based on that we had been working on a new approach which is is what we call a quantum photoelectric multiplication and this is based on the photoelectric effect which is an effect that was discovered just before the turn of the century and in fact the understanding of this effect was one of the catalysts for the development of quantum mechanics so what you have is light which is an electromagnetic wave it is incident on a metal and as a result of that you get a photo current the photo current only occurs if the frequency of the light is sufficiently high or the wavelength is sufficiently small and that was the insight that ultimately led Einstein to realize this that light is quantized two photons but what's relevant for us is not so much that fact but rather the fact that the photocurrent scales as the intensity of the light and the intensity of the light is purport formal to the electric field squared rather than the electric field so this before provides for an opto electronic squaring function where you start with an input which is encoded as Y of T and you end up with an output your current which is proportional to e squared and that can be used in combination with a beam splitter to do something that's called homodyne detection which if you have a digital encoding of your data is a way to do an optical electronic xor gate so how that works is as follows you have your inputs encoded into the phases of your optical pulses so phase zero would be a zero and then a phase PI would be a 1 and the though that light goes through these beam splitters the beam splitter as I mentioned it has a mixing angle here is a it's a 50-50 beam splitter so coming out the top port is going to be the sum of your two electric fields and coming out the bottom port is the difference of the two electric fields then both of those go into the photo detectors and the photo detectors square your signals and if you encode your output in terms of again zero goes to a plus voltage and one goes to a minus voltage then the combination of your beam splitter which replaces x and y with the sum and the difference and the photodiode which goes squaring it gives it it can give you a 1 in the two cases where the X bar should give you a 1 and then a minus 1 in the cases where it should be minus 1 this works not only for digital not only for binary data but also for analog data so you can take two inputs x and y and then send them through a beam splitter and what you get out as X plus y over root 2 and X minus y over root 2 then you send those into a photo detectors you get the square of that minus the square of that so you get the x squared + y squared cancel out but you get a cross term left over so the total current coming out of this bum benign detector is going to be the product between x and y so that's a way to do an opto electronic multiplication between your optical signals if the output is electronic and a great thing about this is that it is very easy to convert this multiplier of numbers into a multiplier of vectors or a vector dot product just by encoding your data in time so if i encode not a vector as a train of pulses here then it's very easy to multiply two vectors just by sending in the 2 pulse trains interviewing them on this beam splitter and then integrating the photo charge that comes out an ad vector vector dot product is a key component of a matrix vector product which is what we need to do the NAM to do the linear algebra for any kind of deep learning so you just imagine you have this system which to multiply two vectors only contains a three components and you just tile these thing you'll get a system that looks like this where here I have a bunch of pulse trains that encode the weights of my neural network so this is a matrix here I have an eye endless trains coming on and I have one pulse train encoding the inputs of the neural network or of the neural network layer now the inputs get fanned out to every homodyne detector whereas the weights are mapped one to one and in each homodyne detector you are performing the the the interference and then the photo detection and subtraction so in this way if you start with data that is encoded optically into the amplitudes of this these pulses in this pulse train then you'll end up with data that it's encoded electronically in into all of the voltages that come out of these and detectors then you can in electronics perform the non-linearity where it's easier to do nonlinearities in electronics and optics and then re serialize that data send it on to a module and optical modulator and then send it out to the next layer so this was the proposal that we came up with for an optical neural network which is based on this photoelectric multiplier and then also this time encoding and a big advantage this has over the previous scheme is that now we're much less hungry for our chip area and the previous scheme we needed one beam splitter for every element of our matrix but here we so that was an order n-squared components on chip but here we only need of order n components on our chip so you'll need and modulators here one modulator here and then you need n detectors here you've traded some of that spatial complexity for your time complexity because now you have multiple pulses coming in and if you it turns out that this is a it can be fairly energy-efficient too if you're able to generate these weights then the the energy then the energy consumption will be mainly dominated by generating these inputs reading out the inputs and then generating the inputs to the next player and that goes of order n where as the number of multiply accumulates being done here that goes as order N squared so you expected an ordered 1 / n / Mac and as n gets larger that becomes smaller compared to what you're competing against so we did a we've started by looking at what are some of the fundamental limits to this and it turns out one of those limits is based on the it based on quantum mechanics which which gives rise to push on shot noise in your photo detector signal and that is if you go through the math so the shot noise is going to be proportional to the square root of the number of photoelectrons you have coming out and then it turns out that that gives rise to between multiple layers you have your nonlinear function of your matrix vector product plus some noise term and that noise term depends on a number of constants and then is depends on the number of photons per pulse or the number of photons per Mac so we studied that and then looked at some basic neural networks and analyzed the effect of this quantum noise on the neural networks these were fully connected neural networks trained on M&S and we noticed that there were two regimes one is where there are where your NMAC for your number of photons is very small in that case your noise term is large compared to your signal term and you're just randomly guessing at the solution so your error rate for these digit classifications is close to 90% then there's the regime you want to be in where the signal of the noise is brought large and there this NMAC has to be large and then you get the same report performance as a digital system and then there's a crossover point where this sets the theoretical lower bound for the energy consumption of this device the optical energy below which the error starts to increase dramatically it turns out that for these neural networks is close to around 100 Zepa joules per op so if you reverse that that include that indicates that the theoretical quantum limited performance is of order xol per watt of course there are other bore practical limitations especially tune your kurma devices energy consumption so if we look at state-of-the-art CMOS electronics like the TPU they tend to operate at this an order of Pico Joule per Mac regime if you're limited by the input output energy assuming things like reasonable numbers for modulation and detectors that for a near-term technology of order of Pico joules then you would get this line for the for our proposed system if then you look at some more speculative work that's being done in very low energy closely integrated modulators and detectors for on chip in optical interconnects this is emerging technology that can go as low as a temperature burner on so in the long term that might be possible but then in no matter how far you go you'll never go below this quantum limit line which is just set by the shot noise and your detectors useful problems for deep learning tend to reside in this regime where you have a connectivity of order hundreds to thousands so that means we believe that you have attended to the two to ten to the three improvement possible versus a digital CMOS current digital CMOS with potentially near trim technology and as this improves that may grow larger no a final point that's a rather interesting is if you look at the land our limit for for irreversible digital computation so blue and our limit is KT log two and that's three Zenta joules but that's three Jeptha joules per gate and in a given multiply accumulate depends on the bit precision but you tend to have an order of thousand gates so what that means is that the land our limit for deep learning on digital processors is of order three Auto tools for Mac and the standard quantum limits for these a optical neural networks it is already below the slanderer limit suggesting that in principle it is possible to go below the Landover limit in such photonic systems well that's not entirely absurd given that photonic systems rely on reversible components which break the assumption of the way endeavor limit it is kind of exciting I think I'm running out I do I have okay okay well I think of include there and thank you all if you're interested in more you can look at these papers thank you so you mentioned because do you include the ghost of accessing the memory that halls all these inputs weights so on so that was the next slide the next flip was what about the weights and the answer is that you actually need to do matrix majors not matrix vector so you get reuse of those weights otherwise no yeah otherwise improving the compute is not going to matter if you always have to access the weeks for memory and we do have proposed scheme to do the matrix makers that are also pretty nice in terms of the use of the products the so what's shown here is a to basically two one BS LMS which could be fabricated they'd only require or and components and then you have photo detector with the order n-squared components what's nice about this is that you get the optical routing through free space which is difficult to do in either nanophotonics or electronics and you also take advantage of a very dense packing that's possible in photo detector arrays but also relaxing your constraints on your in an opponent modulator arrays so if you aren't doing all people Tim that means that maybe you for instance at once is that if you're doing fully connected but that's generally yeah yeah you're fully planted that's true and if you're doing convolutional of course we've heard several talks about how you can reduce convolutional to convolutional can be reduced again it can also be a lot of reviews with the weights so what it it ends up being the same end here so the the smaller of the two ends what matters they talk you compared it to the other talks here with the analog versions of any compared to digital versions but what about like not not rigorously I can't say I've looked over some of the papers related to mysteries it's a kind of tricky because a lot of times many of these papers will playing a dirty large speed up but then the paper was written a while ago so they're comparing against the past state of the art so you have to compare the current state of the art I think both of those like close to this regime so they're going to work at about the same energy consumption as what we would expect with the new yorker mentality if this can be built they have other engineering challenges that we heard about all through today and this will have its own engineering challenges this is newer and so I think we have just begun to explore those all right Security's right 