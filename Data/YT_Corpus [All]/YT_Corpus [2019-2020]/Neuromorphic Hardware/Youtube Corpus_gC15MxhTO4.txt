 So you reckon you always need GPUs for your AI workload? You can actually use a large number of processor technologies. That may sound complicated but it’s really quite straightforward. I’ll explain it to you right now! Expertise on artificial intelligence, high-performance computing and the cloud. Why is the choice of processor technology so important in AI projects? Well, it can save you a whole lot of money. Imagine you’ve completed your ... ... AI application and then discover that you have to start again from scratch ... ... because you need to switch to another resource. You have invested all that time and money and there is no longer any use for it. CPU, FPGA, GPU and many other processor technologies are used in AI projects. What are the differences between them? CPUs are the all-rounders that really can do everything. They are a good choice to get going with. GPUs give you your first speed boost. They’re especially useful for speech or image processing, but you need libraries, ... ... to make them work. So let’s move on to FPGAs, which are fully freely programmable and can therefore be used for applications of any kind. But you need a whole lot of knowhow to be able to use them. And then  there are NPUs, which are chips that only do artificial intelligence ... ... but they, of course, deliver peak performance in the AI environment. FPGAs are generally considered to be expensive. Why are they more suitable for some AI uses than classic CPUs? The largest cost factor for FPGAs is their procurement. But if you can use  this resource from the cloud that factor no longer applies. You can then program them in precisely the way that my application requires.  CPUs and GPUs don’t let you do that. If the hardware listens to the application ... ... you can accelerate the speed of individual processes by up to a hundredfold, which would simply not be possible ... ... with individual or other accelerators. For which AI project use are GPUs the better option? They’re best for speech, object or image recognition. That is where applications can really make use of and benefit ... ... best from the large number of small chips on a graphic card of that kind. NPUs are the exotic ones. How do they differ from other processor technologies? NPUs and TPUs are specially designed for AI tasks. That makes them significantly  more efficient than standard CPUs – by as much as 83 percent per watt! So they can be used in very small terminal devices like cellphones – and at data centers too. How can NPUs take corporate AI projects forward? The throughput or time for a forecast of NPUs compared to CPUs is up to 41 times more than a CPU could deliver. So you really can speed up your AI application enormously. TPUs. Aren’t they only from Google? How can companies benefit from the advantages of TPUs? TPU is indeed Google’s name for its tensor flow chips.  What actually lies behind TPUs are NPUs, ... ... or neural processing units, which are currently used in mobile terminal devices for better photos or face recognition. But we will shortly be launching them in the Open Telekom Cloud. How do companies find out which processor type is best suited for their AI application? Companies must first be clear about what they really want to do. Well, you either already have in-house experts—data scientists—and then you should make use of their expertise, or you don’t have them but you ... ... will still have the option of consulting partners like us, for example, ... ... for advice or to instruct them ... ... to develop customized solutions for you. Further information is in the AI white paper, it’s free to download. For the link see below in the video description. More exciting details about Artificial Intelligence, High Performance Computing and the Cloud are available on this channel. Subscribe and click on the bell. Did this whet your appetite for AI? If you’d like to implement AI projects in your company, do feel free to contact us. 