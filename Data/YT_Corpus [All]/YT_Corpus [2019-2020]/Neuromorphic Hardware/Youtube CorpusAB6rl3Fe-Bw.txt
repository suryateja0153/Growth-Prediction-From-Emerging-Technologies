 [Music] [Music] [Music] all right Thank You basis so I'm gonna go back to talking loaded about fab for AI something is founded it was about so I figured a to start I know many of you are aware when I'm not afraid and I've worked with a but but I thought I'd say a little bit about how from campus so Lincoln Laboratory is MIT s largest laboratory it's a federally funded research and development center with its main campus out in Lexington Massachusetts so there's about 4,000 employees it's spun out of my tears developed for the Department of Defense in the early 1950s so its heritage is that out of MIT in and out of the rat Lab at MIT in terms of AI generally in the laboratory it's being advanced across all eight of the technical divisions but most of these efforts leverage commercially available sort of CMOS based hardware and so there's significant expertise in applications and algorithms that we in my group leverage and that many of you working on other technologies might be interested in leveraging as well but in coordinating this talk with a sous the interest that we're going to be talking about here is really hardware for intelligence competing efforts our for AI and so I'm gonna talk about three different efforts that my group is involved with it as well as some other some other groups at Lincoln Laboratory so the first of these that we'll talk about is the quantum enhanced optimization program which is an IR book program which my group is involved in it but collaboratively with MIT campus and with men partners so this actually has some applications to artificial intelligence that's not the only application they're looking at but I'll say a little bit about that the other reason to bring this up is I wanted to talk a little bit about the model that Lincoln works in collaboratively with campus and in a model that we might be able to leverage for other efforts that many of you are working on it we heard about today the second one which I'll say just a little bit about is a couple of a couple of oscillator based computing approach in many ways this is sort of a classical analog to the to the quantum annealing approach I'll tell you about in the qeo program there's a number of people here Siraj Jeff and Sid order can tell you more about that and there's actually a poster later later about that I'm finally honest but most of my talk talking about super active neural networks that Alexandre Evan and Alex when are all working on Alexander's here today if you have more questions about that there are many larger teams in my group and across the laboratory that are helping to develop the fundamental technologies that go into all of these they're all really early-stage efforts in terms of their application day so there's a number of different ways to look at new hardware firk for intelligence computing for AI and so one way is looking at the different architectures that are used and so over here on the left are the more commonly used feed-forward architectures where you have two different layers that beef board you can have recurrence or back propagation but all the way on the other end of the spectrum of these fully connected for current networks and then additionally on the device technology there's a whole range of different device level technologies ranging from very mature technologies like CMOS that can be leveraged with billions of transistors to the other end of the spectrum looking at quantum technologies and so in my talk today all sort of pick and choose a few different combinations of architectures and context technologies and the first of those that I'll talk about is the quantum technology it's it's basically using locally connected recurrence so to set the stage a little bit as you heard this morning there's one way to do very efficient computation is to think about the physics of the devices that you're using and to try to leverage that physics to do the types of computation that you want to do and so in particular what you could imagine is that you create an energy landscape that represents the problem that you're trying to solve and you can do this by coupling together different different harmonic oscillators and these could either be classical harmonic oscillators or quantum mechanical oscillators and by doing this you you create some Hamiltonian and Ising Hamiltonian it's either a quantum mechanical or a classical Hamiltonian and this represents an energy landscape and the minima in that landscape represent optimal and near optimal solutions and you can use this type of mapping to solve a lot of np-complete you know very hard for classical computing types of problems and these so as a result of this in these network of coupled oscillators can be used to solve problems that are very difficult to solve and quotes efficiently using modern digital computers and one reason that I put solvent quotes is that oftentimes you're not trying to come up with a single correct answer there are many different answers that you might want to it might be tolerable answers that are near optimal and additionally you know it may be that you don't even set up this this problem this computer to necessarily solve the problem that you're trying to solve but instead you you're trying to represent the high-tension dimensional probability distributions that represent your problem and it's really by that that you're come these machine learning techniques and so what I mean by this is that you may not use this computer where you have these couple harmonic oscillators to solve every problem you're trying to solve you may use it in order to come up with a machine learning algorithm that you can then apply to classical hardware and so first I'll talk about the quantum mechanical version of this and then I'll come back to a classical version of this so in terms of the quantum mechanical version there's actually been an enormous amount of work done and so much of this work was pioneering work by the company d-wave at the Canadian based company that is building quantum annealer x' and so if you look at their website machine learning is one of the key applications that they highlight on their website they protect chosen a particular approach to building these quantum annealer which has allowed them to get to relatively large number of qubits and to start looking at optimization problems and the potential scaling but it doesn't capture all the physics that might be possible with the devices and so the ir / qø program quantum enhanced optimization program is really looking at a different set of trade-offs in designing the hardware so in particular looking at much higher connectivity I'll say a little bit more about the connectivity to do a system in a minute but with much higher connectivity you can imagine embedding problems much more efficiently the qeo program is also looking at much higher qubit coherence so one of the limitations from the d-wave system is that their qubits are not particularly coherent and this has limited their ability to to look at how quantum enhancement you can really play a role in quantum annealing and finer better control flexibility by more directly controlling each of the interactions between the qubits all right so this is an image of one of the packages that we've built for the qbo program and I want to say a little bit as I said about how how we're a part of this program and one of the models as you might imagine using to build larger scale demonstrations of Nea okay so so we are rolling the program is had a few few different things so one is that we host these research test beds so these are very large physical infrastructure there's going to be thousands of channels of digital to analog converters they can call each of the qubits and each of the couplers and in the system I'm the dilution refrigerator so you know relatively expensive and hard to maintain infrastructure for controlling all these systems additionally we act sort of like a foundry where we fabricate these 3d integrated chips that provide for very high coherence so they keep it and also allow routing in many different layers in order to get high connectivity between all those qubits and so this fabrication process is run and a fabrication facility at Lincoln that is a nicer certified fabrication facility runs 24 hours a day has a team of many tens of technicians and engineers that are that are hoping to maintain all the tools and then like a commercial foundry we have design guides we have design tools that allow you to stimulate what you're going to get out of building into this fabrication process and then finally we work with the performer team which includes a lot of industry participants universities from from around the world including MIT and they design into this process the process then puts packaged devices into these test beds and then they they run the test beds in order to study what they need to about how these quantum annealing system is worked and so you can imagine that this might be a similar model that be adopted for other AI technology and so if we distract this a little bit the pieces that I've shown here are really that there need to be hardware demonstrations at a scale that's useful for really building up a capability and bring it to the point where commercial markets can take over there needs to be what I'm calling technology platforms things like CMOS where you can design into a fabrication facility that it gives you the yield and but it's still the flexibility that you need and finally there's some foundational science and engineering that needs to inform what it is that you want to build what these platforms should look like helped to advance new new components into those platforms and then decide what research questions need to be answered by these demos and does all the design work and so these advances these hardware demonstrations are really gonna require cycling around this this research cycle in a way that supports both the necessary flexibility and maturity so something like advanced notice EMI certainly provide the necessary in maturity you can get the yield you need for very large-scale demos but it has limited flexibility most commercial foundries are not going to allow you to tweak the CMOS processes that they're run and so one of the roles that link it might play is that we can provide expertise and ideas in a subset of the relevant scientific and engineering disciplines we hope to design a lot of those coupler trees that are being used by the the qu program in addition to helping to maintain some of these more more infrastructural capabilities we can provide the fabrication capabilities that combine both stability and flexibility and finally we can provide engineering support for their larger scale demo so then using a model like that you might imagine that there's a couple different areas that link it has fabrication or device level technologies that could be leveraged so one is in photonics and so I'll point out very quickly an idea that a team at Lincoln is working on but looking at fully connected recurrence it's enabled by using photonics and so this similarly to the the d-wave system into the Arabic ubo program that I just told you about is a way to create these Ising Hamiltonians but rather than doing it with quantum mechanics it would be you looking at classical harmonic oscillators and so if you look at the architecture that's doctored by by D waves it's this chimera graph where there's no only a very few number of qubits that are connected to one another locally and then this unit cell is repeated in a way that has lower lower connectivity as you go out the coupler trees that we're using for the QIO program enable much higher connectivity but it's still unit cells that have tens of qubits it's not connecting tens of thousands or hundreds of thousands of elements in a fully connected way and so in order to scale up to having these fully connected graphs where it's a hundred thousand level games you're talking about billions of connections my idea that we have is to use photonics to use pairs of mixels vertically vertical cavity surface emitting lasers and photo diodes that can allow optics through free space to enable these very high connectivities and so if you're interested in hearing more about this there'll be a poster this afternoon about it so I encourage you to talk with Jeff sir Eisen and sit about the more about their work then the last section which I'm going to focus most of my time on is looking at more commonly used architectures things like feed forward or back propagation coupled with suit classical subtracting electronics so first to set the stage a little bit I'm going to give you some background on superintend electronics it's two reasons that it could be very attractive for for next generation beyond CMOS computing is that it has very low energy so you can see here this is a graph that's showing the flip energy as a function of delay and so there are technologies and Tsuburaya technologies that are approaching the Landauer limit and in fact there are ways that you might evolve these to do reversible computing and you can go beyond the land hour limit but these are very energy efficient technologies the other thing is that as we heard about today data movement to memory or otherwise is one of the main limitations of the conventional approaches and super name electronics that eliminates the losses associated with this and in terms of resistive losses because they're super active there is no resistive loss so very narrow very short pulses picosecond clasp pulses can be transmitted with essentially no loss over long distances so it's a it's a solution to the high energy overhead of david' data movement and conventional processes the other reason that I would say it's attractive is that it's it's actually a relatively far progressed technology so we have Lincoln fabricate thousands of wafers per year in this fabrication facility I mentioned that runs 24 hours a day they're highly planarize processes with many metal layers so you can do the routing and other things that are aventuras you can build relatively large scale circuits so this is about a million joseon junction circuit that we wield it and this is about a hundred x increase over the last four or five years that have enabled this so the technology progressing well and you can get to relatively large-scale demonstrations at this point but there's been fairly little work done on using it for for AI specifically the focus of efforts have been really to emulate classical CPUs and classical technologies so in looking out to neuromorphic hardware there's a couple of different parts of the trade space that you might imagine so a lot of the CMOS approaches use digital solutions digital designs the super ining technologies are really much more amenable to analog approaches there are also NIST and other groups have been looking at emulating neurons in terms of having striking behavior and the sfq pulses of these super active closest that thinka transmitted make that a natural idea to have but in fact we're looking at a different approach that uses an adiabatic so to be much more energy efficient and we believe just as fast and sort of better better match to the cigarette electronic so if you compare the energy and the time that it takes to do a multiply accumulator to do a classify you can see that these ceramic technologies actually have even including the overhead of doing cooling a very attractive energy numbers particularly is this approach that I'll be telling you about and they can also work at very high speed so few nanosecond scale classified times so going back to the way that it's done with digital electronics with CMOS what we're looking at here is if you want to emulate a neuron where you have weighting of a bunch of inputs and then anomaly or function that's applied to some of those inputs this is done in digital electronics using multipliers that are made up of adders and that involve many many many transistors and in order to do this and so what the the sort of key idea is for graduate assistants or an electronic system to move into the analog domain and to instead use a network of inductors where these the analog values of these inductors are what set the splitting what allow you to do the weighting or the multiplication and so these are very compact cells this is 10 10 cells are sort of microns on a side 10 10 microns or so on a side and in contrast to other device level technologies where it's the the fabrication of the feature that is what defines the accuracy here you actually set the weighting you suck the inductor that's digitally and so this small cell it's a small circuit the same kinds of circuits that are used in the d-wave system or what allows you to create a tunable inductor and so you can set this inductance value with very high precision in fact the fact that you use super actors actually allows for a particular kind of quantization or digitization that staight a fundamental constant and so these can be very accurate and sir aren't aren't subject to the same sort of fabrication defects that other technologies are so the using this approach these multipliers become very small they become tens of microns on a side we then King some all the currents and apply a nonlinear function and so all these pieces become much smaller than they were in the CMOS case and we can combine digital and analog functionality in a way that's sort of ideally suited to the function that it's serving and to demonstrate this is a feasible approach the team so far has been looking at simulating circuits so looking at this small neural network here they've actually done simulations of all the surrounding electronics that mapped it to an electro simulation so we're now at the stage of having designed some circuits and/or fabrication process and will soon be testing those two to see how they work but some of the results from the simulations are shown here it can in fact classify based on the simulation it can classify these different images that were in the training set and in fact the speed of this is very fast you can see this is only a few nanoseconds scale it can run a gigahertz type speed so it can do very rapid classification of images there are however a lot of remaining challenges so certainly as I said we're just getting started on the device or the hardware on demonstrations and so there be a lot of work to get to larger scale prototypes we'd like to work with others in terms of jointly identifying applications developing more automated design tools and exploring techniques for validating and debugging larger circuits there's also a lot of work needed for Network training we've we have some ideas for how to how to do back propagation and how to do training but there's still a lot more work to do there and finally at the device level on the the i/o from these circuit still a big challenge and so we're looking for collaborators who have ideas for new i/o devices packaging with many parallel connections we have some work in 3d integration foot that there's certainly other ideas that we'd like to explore more directing or integration we think generating devices is similar to what max shoe lacquer was talking about this morning in terms of directly integrate sensors and finally data compression and reduction techniques so in summary the lab is really actively pursuing and interested in further collaborations with campus and with others to develop new approaches to intelligent computing hardware we have a few technology platforms ranging from customized CMOS to photonics to severe electronics and quantum circuits that we're happy to work with campus to leverage and then there are many challenges that will benefit from more cross-disciplinary interactions so we're looking forward to working with have ideas for bringing forth technologies that we're working thank you where are you on the simulation version of supremacy there's been a lot of historical debate about quantum simulations versus best practice classical optimization but but but quantum supremacy not for fully entangled teams but just the question of historically comparisons of classical of quantum simulation have been against ancient ideas in classical simulation versus best practice and in classical like heuristics for TSP that's right and so where are you relative to best current practice for best classical solution for heuristics for hard simulation optimization problems so there there are no QBO partners still early in his faith but even outside of makyo program they are not flat they're not quantum processors they can be known classical algorithm so what qeo is doing is it's set up a method by which we're going to try to improve the way they were comparing to classical approaches so there's a team at NASA and at Texas A&M University that are working on trying to better define problems that you know really do saving the our classical approaches and compare them to quantum coaches there are certainly domains so the curio program is looking at domains the material that you are using I am assuming that you are using some low-temperature superconductors mu Bais or something and I'm curious about which temperature you support operate these kind of devices and also what is the perspective towards like high-temperature superconductors for instance it's possible to give a bunch of coherence at the device level yourself all right so further for the quantum technologies the qeo program that I mentioned first those are tens of million temperatures the leader neuromorphic technologies based on classical cybernetic electronics is at 4 Kelvin so they are in fact niobium circuits there has not been a lot of progress towards making complex integrated circuits with high temperature surrenders that's certainly an area that it could be of interest so the penalty the cooling penalty development for a relatively large scale systems on were a few hundred to a thousand packs so you could move to a higher temperature super after you get 10x easily so one thing with all these different platforms I was just curious since people on the outside know about them DC do you see any of these being driven by reasonable commercial applications or is it kind of like a commercial point of view we're still trying to find with the applications would be I've actually general for any of these platforms that you're doing because I know Lincoln of course is looking at particular applications in general that let's say aren't commercial right but from the outside products further where they're dancing they're research yeah I mean what stage they're out but if there's hope of application so you could be you could be 50 years out but you know there's a really important application right right commercially right so so I was just curious so photonics what are the applications that people are interested in this for I over existing electronics is certainly one for communications branch out in terms of the wavelengths that are used by applications it's a I think there's going to be a top nine in our approach eating four times so I think there are certainly drivers for the times eighteen more to the right date they're more exploratory and it's less clear at this point I would save it plus k1 the advantage is going to be but yeah so it's um it's essentially a plot staff flux digital analog converter and so you can get input what you want and [Music] it's theirs ok so the way we've designed it so far it's it's just forward propagation so we haven't done a lot of learning we haven't done this back propagation we certainly have ideas for how to do that but right now that salads really just meant to help set the wave all right if there are no more questions we are exit 