 next lecture is by than many Bathsheba principal engineer creases there hopefully thank you thank you dr. Katz and thank you everyone so I'm gonna actually spend the first couple of minutes just talking about what I do let's see and I will talk about Moore's law a little bit because I trying to understand what you all know about Moore's law and I'll let's see if I can guide you on the right track with respect to Moore's law and then what I'm going to do is essentially talk about a couple of emerging technologies which are probably very very relevant given where we are today so that's roughly and I'm a nag and I even prior to that just talk about how we do research at Intel because I think research is something that is on everyone's mind here so that I have my disclaimer slide as part of Intel so I will get into this talking about India's research capabilities but let me to spend a couple of minutes talking about myself I am basically a circuit designer when I when I picked up my PhD I want to say I picked it up last year but maybe a few years before that I joined at that point of time it was the the Alpha a group of digital which was already acquired by Compaq and I joined the Alpha group and they were working on alpha on the Alpha line of servers for those of you who remember and then about a year later we got our group got bought by Intel and this this is in 2001 actually and so for the first 10 10 years or so 10 12 years of my career I was working on the next generation of server server micro processors basically looking at power power delivery circuit design micro architecture to an extent architecture I did go down the stack a little bit into devices 2 and then I moved on to something closer to my heart into the research side so I did develop product experience before I moved into the research wing when I say Intel is a big company any idea on how many people work for Intel it's more than ten thirty thousand higher fifty okay oh boy we have our one hundred thousand one hundred hundred and ten thousand so V is a big company and the reason I'm saying that is it is an ecosystem in itself so you can actually really shift from quote-unquote one career to another and still work in the under the umbrella of Intel because it's such a big company so I moved from working on products to the research wing which was really very different from working in the product space and if you talk about talk about Intel's research capabilities essentially there are two two groups one is a group that is attached to the manufacturing wing of Intel which is called components research so to think of working on the process side lower down of the process side enabling looking at novel integration looking at new devices etc so that's one side and then there is Intel labs which is the other the upper part zero where they enable novel capabilities and together the components research wing and the internal labs wing essentially cover the Intel research efforts for the for the corporation we're about I want to say about thousand thousand or so people so you know one hundred thousand eight thousand people we carry a lot of weight because we basically are sitting at the front end driving intel's direction moving forward but of course we can't do this alone and so right at the bottom we have a wing called university research and and that's that's the wing that I'm actually driving I'm driving into a university research so more external facing because we can't get things done alone so we have to we have to reach out and work with you know new minds fresh outlook fresh direction reach out to the broader community in a collaborative fashion clearly because we are working with people like you who will go on to either become academics themselves or perhaps come come along to join Intel subsequently you know the next generation so and I will I'll spend a few minutes talking about what we do in the Intel's research front because I think that's you know something that you might want to understand and then I'll I'll move on further into talking about emerging technologies excellent segue into my next slide which is Moore's law thank you so let me start by actually asking you all Moore's law if I'm assuming people have heard of Moore's law so how many of you think Moore's law is about improving frequency and power by shrinking your transistors these advances I see a couple of hands okay how many of you think that the performance of a system increases by the square or doubles there were every some some amount of time if you increase the complexity raise your hands that's what what do the rest think most lawyers I don't think many hands going up any takers on what do you think does anybody have an idea of what what is Moore's law yeah go ahead some some amount of time so can you say the processing power will double at some cadence any other let me ask you how many of you think Moore's law is dead okay that the more and more people thinking Moore's Law is dead maybe that's what's doubling every couple of years right alright so let me tell you Moore's law and by the way that is the reference to the paper and if you haven't read it I would encourage you to go and read both most law essentially it is basically talking about economics it's all about cost it's not about performance it's not about power it's not about frequency it's really about cost and that is this is this is a snapshot from that paper which says with unit unit costs falling as a number of components per circuit increases this is written many years ago by 1975 economics I've highlighted economics it is essentially law of economics may dictate squeezing as many as some number of components on a single silicon chip so essentially it says that as you pack more and more functions onto a single chip the cost the cost per function is what decreases right now what someone said with respect to your frequency your power your complexity etc that's Robert Dennard Dennard scaling if people have heard of or Pollock's law different aspects those are the ones which are essentially your torturing on the edge or not surviving but moore's law is a law of economics it's really a law of nature you know from that standpoint that clear right so the question is so what's been going on so how have been how have we been essentially pushing Moore's law forward for so many years so far it's essentially CMOS scaling right that has been the key enabler for giving us the cost-benefit the economics benefit of Moore's law yes scaling is how much you're limited by physics how much can you scale right we had we announced our 10 nanometers we are in the research phase of ascent of seven nanometers and you know we're shrinking down but moving on ahead it's not just going to be CMOS scaling there's more I can open pun intended but there's more to Moore's law then just CMOS scaling they're alongside with CMOS scaling you know heterogeneous system integration do you have do the integration you have these SOC system on a chip SOC s then you have 3d integration where you have system in the package where you start stacking up in the third dimension where you bring in heterogeneous components into a system to give you the functionality that you are looking for and to give you the cost benefit that you're looking for you know we have we've been we announced FinFETs a few generations back where instead of going instead of being in the two dimension for our devices we have a third dimension on our on our gates we're looking at you know further techniques for in the process front in the design front growing in the vertical direction primarily putting that in our we are looking at novel architectures novel data processing our data patterns are changing and then obviously the changing if you change from structure to on structure then you have to be able to interpret that data differently and so you're looking at novel techniques we're looking at novel functions that come up the AI workloads that you all are familiar with they're not they're not like the traditional workloads that we have in the past and so we have to look at you know probably combining compute and memory together so that you can actually tackle those workloads etc so as long as all these things are still there more snow is a life right I mean any any questions by the way feel free to ask me any questions as you're going along yeah go ahead may not have all the answers but come in here yeah material and that's the challenge like that's the continuous challenge that we all have to work towards and so you keep finding and you know again the last 15 years I've been hearing Moore's laws there every year I mean huh you know after a while we keep so just hold on so that's a good point let me I think in my back up let's see if I have it there okay let me just hold that because I think I should be able to address what you were saying there so this is Moore's law is really not it is this expectation of continued economic innovation the other positive here about performance frequency power etc are you know look up the energy law look up Pollock's rule or whatever else and you will find those components coming together so let me think in my backup this anyway most law is alive and relentless and okay so so law of diminishing returns I mean izs this is just a curve I mean you're familiar with this is you discover something new it looks promising you have an exponential point where it's looking great and then it begins to taper off right that's law of diminishing returns okay so we've had many of these s curves or law of diminishing returns you know if you look at the process side and the design side on the architecture side software side etc you find something in the process side you know I mean if you anyway fin pets etc you can look at a single-threaded computation then you went to multi-threaded computation you went to single called my you know multi-core etc and every point you discover something you have a phase where it's performing great and then it begins to taper off right so we have a lot of these s curves and the question is in addition to that think about a law of accelerating returns which is I think is what Moore's law is and what do I mean by that in your space in your space you are you you're an expert in your own individual field and you discover your space where you have your s-curve you know your s-curve is said in the beginning yeah it's looking promising and it's a great is showing a lot of promise you get a lot of returns and then it diminishes off but then there's another s-curve that comes in play and then if you if you essentially go along that you have an exponential increases and that exponential increase which is the law of accelerating returns is basically representing ORS not you that that's always the case right that's always the case we keep discovering and discovering so for the next for the foreseeable future for the foreseeable future we we can continue for the foreseeable future because we're always finding the next s-curve we've been saying that for a long time or we keep finding the next make sense all right okay so how do I have everyone's assent you're agreeing that Moore's law is not dead it's alive its relentless and you'll hear about it for a long time I think tsmc yesterday or day before they did their I don't know what they've said in the past but they've they've announced that Moore's Law there their interpretation of saying Moore's law is alive so we're getting people to recognize that it's not it's not dead okay all right having said that so these are different these are different areas that we essentially look at we do look at communication we look at our system we look at security will look at sense making we look at normal integration we definitely look at compute and so I've actually highlighted that here because this is something that I'll be talking about a little more going forward and all fueled by making sure that we continue to sustain Moore's law okay okay so let me talk a little bit about our the research segment how what how does the model typically work most of Intel is working on a product most of interns work on a product but as I said the research wing is sitting at the front end of this pipeline feeding into our product development okay so we have something called a work stream model right there on the on your left is the entire what we work on the research front we're compelling ideas essentially generated and explored and then just like you know you you find something promising you have to prove that it works so you develop a proof of concept not all of them turn from just papers into proof of concepts or from patterns to proof of concepts but then there is a set that turns it to that but one thing that one thing which I've is having worked both on the product side and in the on the research side one key difference that we get challenged with is that you you have a you know single proof of concept it comes back you get it you get a paper out a publication out it's working but when you come to high-volume manufacturing right it doesn't work you can't afford to have a yield of 10% and 90% of your die not work when you are actually trying to push it out to the customer so high-volume manufacturing is a very key factor that comes into play when you're on the product side and so that's a trade off we trade that off with perhaps something that's the best or the most promising because if it doesn't work on every single device or every single product that goes out then it's a non-starter right so so that there's a there's a difference between you know having a research hat on and actually having an execution hat on execution hat on is what the product is oh so that final cut becomes smaller and smaller you have a proof of concept but then you realize that when you put everything else into the picture a lot of it has to be discarded and then you go into you know what you we call a transfer where it transfers from the research wing into the product teams right so when you talk of compelling ideas how do we generate our compelling ideas University collaborations is a big is a big contributor to our compelling ideas this is why we're constantly exploring what's outside what is possible or not in addition to that there are a few other efforts we have something we call a tea slope technology strategic long-range plan well on a regular cadence essentially we reach out to the Intel community to say hey you know what are some promising ideas that that you think we should be looking at you know so that's an opportunity for within Intel then then there is another side where we call them our business units the product products is called basically the business units because they are the ones who basically bringing the dollars what from their strategic standpoint what should be the emphasis areas so that also feeds into the compelling idea pipeline and then we also look at something called research velocity challenges what are some things that we can do with a quick turnaround time because you know turnover you can't sit I mean unlike research where you say yeah n plus one one more year to graduate one more year you go on no but we can't do that when you're in in in this mode you know you have okay you have able to do your regular cadence what's going to come out next year what's coming going to come out so you have your roadmap and to fit into that roadmap velocity is a big component that we we need to emphasize alright so these are these are the avenues for feeding in what's next what's next into the pool and obviously all along we look at competition because we are all trying to it's a constant race right and whoever moves forward so that's definitely there okay so on the research front how do we what do we do you know why I will said research and talking of university research what do we what do we do we obviously work with academics and we have three different buckets three different buckets we look at one focus problem solving okay then we the second tier and when I'm going down this increasing amount of investments that we put into it so it's going to show basically what I'm trying to emphasize is that there's a lot of investment that we put into university research here right so we have focused problem-solving where we are working with individual pis we have something called centers where we form a multidisciplinary commune community where we work on a particular area and then we have huge huge large sized centers where we've solved industry scale problems okay so they're in different different levels of investment yeah yeah and basically this whole thing is driven by the corporate research council and that's the one that I I essentially drive the corporate research council essentially has participants across the company remember we said 100,000 the company we have key people technologists from different areas whether they're on the server front whether they are in our AI PG Group AI product group whether they are in our a PC segment whether they are in a communication segment we have key people basically participating in corporate research council where they define what are the new areas that we should be looking at right filling the technology pipeline with promising ideas future talent so we actually have fourteen or fifteen targeted areas and these are not new look at research in the materials and patterning space look at research and the devices space look at research in the manufacturing space push for research in the software and security area and the CAD area on the architecture area and the circuits area name a particular area of interest and we have targeted teams we call them strategic research sectors we have targeted teams were as solely assigned with identifying what are the technical gaps in that area what are some of the research research ideas we should be pushing forth in that particular it just focus on that area just focus on that area but you can't work in isolation so talk to the other strategic research sectors but each of these areas we basically fund professors and our graduate PhD students on research that aligns with our technical gaps in that particular area right does that make sense and we keep adding you know if it's market driven women for example AI is of course you know something that's that's it's emerging now loud and clear and so we have a particular a is RS similarly I'll be talking a little bit about cryogenic actually quantum computing which is the cryogenic computing and so we've basically started an in that particular area in addition to that we have talent development which basically looks at bringing in talent that that is a focus across the board and then we have business development which basically works with our business units to make sure that we are aligning with the strategic direction of our business units ok so that is at the lowest level at the lowest level I'm saying lowest level eyes and we working individually with different professors in different areas one tear up is we form these we call them we we have something called TLS which has three-letter acronyms three or four letter acronyms - we have tons of them and so sometimes acronyms get reused in this case we have iced tea C's I see our eyes Intel NSF partnerships etc so as I s Ras etc yeah there'll be a quiz at the end I know about each of these are but in a beautiful for example you have Intel strategic research alliances Intel science technology centers Intel collaborative research institutes etcetera you do you have all these acronyms but basically there are centers that Intel launches not with a single professor but with multiple different universities targeting again a given area and here are some of the examples of some of the centers and this is not a comprehensive list at all and each of these efforts they basically have a cycle theater we launched them here one there's a year two it goes through an execution phase and then you know finally it goes through a mature phase and if it makes sense it gets extended for another year or two so they're always forming executing evolving as you go along and that's across the board and this is international it's not just limited to the US we have international efforts to across across the globe right and then you can you know some of them are listed over here in fact we have one at MIT which is systems approach to AI there we have mapping the mind and which is in Princeton we have continuous as learning and intelligence center which includes Harvard and UC I I think UC Irvine and UT Austin participating so again multiple universities and when I say multiple universities multiple professors and their students basically participate in research and by the way in all these cases the the goals are set very clearly in the beginning and you know what you're pushing forth forward and the question is have you overlooked something yes possibly and so it's a constant evolutionary process you know we're dynamic we form and we change direction based on what we discover along the way and then of the the next year the top tier there's an example here of its it's called jump joint University micro electronics program this is SRC sponsored as ours I told you I keep spending all these three-letter acronyms and sr c stands for semiconductor Research Corporation and you can look it up wwas RC o RG but under the banner of SRC Intel IBM there are about 1213 other companies have basically come together it's a massive effort its five-year long effort we're six centers have been formed and these six centers huge they're about I think 20 plus professors per center there is the six centers there four vertical centers one of them in the communication space called RF 2 terahertz communication that's called comm center there's one on intelligent memories called crisp there is one on distributed computing called conics there is a fourth Center on cognitive computing called C break and all these four centers supporting them there is just a fundamental Center at the packaging device materials level called ascent and then there's one of the architectural and algorithmic layer will call EDA these six centers they have a director of the the primary p.i running these centers are they're listed there and that but again the whole team has got about 20 plus P ice percenter so think about 120 professors 120 Plus professors I think they're about 400 or 500 graduate students PhD students working with respect to this and this and Intel is we are one of the companies that's involved from the other side working on these centers okay you can see the magnitude of the investment that goes into what we do right this was started again 2018 and it's it's finishing actually one and a half years through and it will probably go for another three and a half years and then there is an opportunity for extension of the efforts around here and I don't yeah if you just look at Java look up jump on the SSRC website you will see some more details on though on this and by the way this particular one because DARPA we have government agencies sponsoring this DARPA NSF in this sponsoring this this is primarily limited to the US it's not this is not international this particular effort is limited to the US right yeah actually have yeah they're 500 I have the stats here 521 students 128 faculty working across the six centers over here right okay so in addition to so we actually have a VC wing in Intel so anything that is really promising Intel actually helps out to explore a commercial angle through it so we actually have the possibility of you know seed funding helping with launching a start-up and helping with the expansion so we have we have a group which is basically Intel Capital that's really chartered with its something's promising and you want to basically take off in a direction particular direction then we are there to you know provide some initial funding to help you do that okay now okay so having said that our our data you all probably know that we are in a phase of data explosion and I think the the projection is what a hundred and sixty zettabytes of data generation per day by two twenty twenty-five words that are any ten to the twenty one the enter to twenty one bytes of data that's the projection by 2025 huge amount of data so that number one the amount of data we are producing is explore exploding number two the type of data they're moving from most structured where you know what the pattern is of the data to an unstructured format or the data right which is which means that it's harder to process it's harder to collect it's harder to analyze right so given that this is happening this is basically challenging us now to think about new optimizations whether it is you know looking at new forms of data parallelism new numeric formats new new new ways of representing that data rethinking data compression that's coming in looking at real-time quality of service requirements etcetera just just rethinking the whole the whole thing as we have it today because of where we are headed right so then the question comes up as we are moving into an era where we are essentially trying to really push the envelope and we're saying push the envelope I think what is it that we are all driven by doesn't matter if you're researchers doesn't matter if you are working on products doesn't matter if you're basically in in the in the business of wanting to make money we're all driven by hate how can we how can we improve the common good right and what does that mean how can we as technologists whether it is in the financial world in the manufacturing world in the automated world etc wherever is that how can we push the performance to levels or hitherto unthinkable not possible at all right if you're looking at precision medicine if you're looking at weather prediction across that whole huge amount of data that's generated but quickly real quickly if you're looking at developing emergency response systems if you're looking at personalized education for the next generation which are things that we are thinking about on a global scale what does that require it requires more than a thousand eggs improvement and computer efficiency given what we have today it's not easy so we're not talking for one next we are not talking of doubling we're talking of over a thousand X improvement and computer efficiency right so what does that mean that means to say that what we are doing right now is not sufficient so we have to think differently we have to think differently about how we compute compared to what we do today right so convention what do we do today it's conventional basically I mean what we've been doing so far what does that mean you have your flowchart you you know what the procedure is and then you just run it through the flowchart and you generate your answers right that's what conventional computing is we've gone into deep learning which is what we are doing today where you basically your procedures are generated through training all right and then you have your once you're done with their training you have your procedures and then you do your inference and your understanding you know your answers right now let's go look at you know we have to still move on ahead and an example of this an example of this would be you know brain inspired which is again something that you're looking at where you have many possibilities many directions that you can explore and then you adapt your answer with you know some kind of reinforcement or depending upon the environment and then another direction and I'm going to talk a little bit about these these two that neuromorphic and computing another one is quantum in quantum you have your answers available to you they're all super imposed right there and then you select and measure the correct answer these new new ways of thinking they're not really intended to replace what you have today but maybe to augment because the application suite is different right so then the new methods will probably help us with the new set of applications that come in but in addition to it doesn't mean that conventional computing is going to go away just because you have quantum computing or deep learning is going to go away because you have neuromorphic they all could come together to really produce magic so I think arthur c clarke had said that when you have us with a sufficient set of technologies they become indivisible indistinguishable from magic and we are basically at that threshold you know we're beginning to look at making magic right there so how many of you familiar with neo amorphic computing I'm gonna play a little video if I can on what we are doing with respect to neuromorphic computing let's see if I can get this on in the future I see a new class of chip one inspired by the human brain unlocking new possibilities and making the world smarter and more connected to me this is the next evolution in artificial intelligence with neuromorphic computing will redefine what's possible self-learning neuromorphic chips will transform education facial recognition manufacturing emergency services smart cities it's already here [Music] okay so back alright that's a little spiel that we've been pushing for fathers a new market computing and then some of you already familiar with it it's basically essentially saying hey let's figure out now how the brain computes and let's see if we can emulate what the brain how or how the brain does what it does into into what we're producing in terms of technology and of course one of the most fascinating things which you've heard all I've heard is that brain computer computes what it does what it does in just 20 Watts that's 20 Watts or even less which is you know I mean maybe we'll get there someday but we are all trying a little bit to do you know so what is it that basically fundamentally different from conventional computing right so here are a few things which again maybe some maybe some some of you are perhaps all of you familiar with this that number one is fine grained parallelism with massive fire fan-out how is it different from from from our conventional computers first of all you have your element of computing being or the the neuron is so much smaller than the entire brain so it's really fine green when I'm number one and secondly the every neuron is connected to so many other neurons so there's a massive fan out as compared to in conventional computing you have a clock clock is pretty much the only thing that really communicates across the chip and as opposed to in this case everything the connections are pervasive every single neuron is connected to a large number of neurons right the third thing is scalability whether you're looking at a 200 Neutron worm or human brain the basic element is still your your axons and your synapse and your you know that that whole thing has really not changed and so there's that element of scalability that the brain has which is something that our conventional computing does not yet seem to seem to replicate then the next thing is event-driven computation with time in the sense that time is really you know some kind of a variable here right in in in in the conventional computing case you have a clock I'm talking of synchronous computing you have a clock and the faster you fill you you higher your frequency the faster you finish your task and you get done right in this in the case of the brain as you all probably knows that an event can occur at time one and it's different if that same event occurred as a different point of time actually even physically may be the same but the implication of it might be different because it has occurred at a different point of time so there's a time to dependent aspect to it and these events are basically called spikes and that's what basically you know market computing is is essentially pushing for this spike driven computations over there the third thing is that it's no precision more starcast stochastic in its approach you haven't heard of a 64-bit floating-point precision operation of the brain they'd they basically need maximum of one bit and when you depend computation is done sometimes it's okay to skip a computation so we have to have models that really absorbs that randomness or stochastic approach at the brain does today's conventional and computing doesn't do that you have something you miss something then you've lost you've lost your potential output because you haven't computed that right so again just talking of the differences between what we have today and then the the other thing is that it's adapting and self modifying the brain doesn't have a training process and then and then an imprint process the whole thing is essentially just adapt so the fly it it absorbs it learns and it just executes as you go along right again that's another thing that it was something for us to to to bear in mind and then we've given the owl of this given that the brain is so fundamentally different from what we do in conventional computing how can we take steps and we are all looking at being able to take steps towards you know doing that shift and making our are what we produce in technology closer toward the brain essentially does and so neuromorphic computing chip that we've come out with is basically a first step in in that direction so we release something called it's called I don't know if you've all heard of the Loihi self learning it's a mouthful no he's self learning chip that we announced last year no he I think I believe is named after a volcano in Hawaii emerged it's supposed to be coming up so I think that's the analogy over here it has its it's memory and computer integrated into one one ship here they are 128 cores we have 128 K neutrons 128 million synapses the the learning capability is happening on the chip itself it's scalable from that standpoint it's obviously complex neural network topologies in there and they communicate asynchronously the course communicate asynchronously through these spikes it is again each little call has its own there's no master set of rules each little core has its own set of rules and again they operate with their own you know distributed set of rules and but they all communicate with each other so that's we announced that last year and then this year earlier this year so then they've been various generations of Loihi which have come out and I think earlier this year thing last month was the two months ago we announced ok like that wasn't a mouthful we are announced boy holy Hickey Beach and poor Hickey Springs which are two researched neuromorphic systems there they are basically capable of scaling from 64 to 768 Loihi chips with massive number 8 million to 100 million neurons per system you can read more about it I won't go into the details but here's what is exciting which which you might be interested in we've ok I'll talk about the applications that come back to it and again the applications again whether sparse coding or pattern matching complex system modeling etc the intent is that they are able to solve it more efficiently right so here's where this is a interest perhaps to you all well essentially Intel has announced an Intel neuromorphic research community it's AI NRC another acronym over there but it's it's essentially it's encouraging you all to participate if you want access to the platform you can essentially get access to the platform you can if you send me into IRC underscore interest at Intel or comm is but the idea is to advance the capabilities on the test ship so if you want to run your algorithms you want to try things out you want to run potential applications to look at the programming models sensors actuators etc then you all of you can get access to doing so again get on to the AI NRC community their internal neo morphic research community to do that right okay so that was with respect to again a bits a sneak preview on on the neuromorphic computing side and let me shift gears and talk about the other part which is essentially quantum computing so quantum computing okay it's taken me a while to understand this and I'm still in the process of understand visits in that quantum realm and it's not quite yet to send it down but essentially the idea is that problems which were intractable currently today whether you're talking of constraint optimization or you know looking at the material properties etc things which are in pretty hard which are today deemed which pretty much impossible quantum computing is supposed to be able to give you the capability of solving those those kind of problems right so let me just just introduce this idea to you for people familiar with quantum computing anybody familiar with Google so perhaps if there are additional questions maybe I can come to you because I'm myself learning about this but essentially here's the thing think of a coin you have a coin you typically say heads or tails that's in classical physics why did you say heads or tails right here now imagine instead of it being heads or tails you're actually spinning the coin so while it's spinning while the coin is spinning it can be heads and it can be tails it's got heads and tails basically superimposed on on the coin and so that is the quantum aspect to either be but when it stops it's either heads or its tail stops being in the coop quantum Ram so while it's spinning is when it's in the quantum realm and you call it a qubit once it has stopped it's either heads or tails it becomes a bit right so the ad well it's spinning there's the concept of superposition it's got its it's got a one Ana zero heads or a tails superposed on it while is spinning alright so number one is superposition number two is entanglement the closest example I can think about is you know atoms in a molecule they work together so I went saying and Tiger when you imagine two coin spinning instead of one coin imagine two coin spinning so in that scenario they could both be representing heads they could both be representing tails one could be heads one could be tails so you could have four possibilities that it could represent while it's spinning so in that state when the two of them are spinning in an entangle four method in other words there is some relationship between them you can have these two to the N possibilities in this case two to the two four possibilities in this case but if you have n of them n n coin spinning simultaneously you can have two to the N possible States superpose at the same instant of time and this is basically the the concept behind quantum computing so if you have 50 entangled qubits 50 entangled there most states in a supercomputer and if you have 300 that they sing most states and then then the atoms of the universe and the question is hey what's the fuss all about if it's that it's going to be that easy it's not that easy and you know why because the fragility what is fragility they lose that entanglement very very easily that entanglement remains for fraction of the time microsecond we're trying to push that to you know a slightly longer time they can remain entangled any noise any disruption an observation destroys the quantum state of that of the structure so fragility and to maintain to ensure that they are entangled ensures we have to go through to all kinds of lengths and today we operate in the cryo world in a cryogenic extreme cold extreme cold in the when millikelvin literally right down there so that they remain entangled for a very small fraction of time and that's why it's not reality today does that make sense ask me any questions or our experts because I think we have a couple of people yeah go ahead pardon ah if you want to read out your answer where this head so it's got all the states in there but if you want to read out your what is the actual answer the entanglement goes away and you observe the final result so in there in the big scenario you have all the things imagine you have all the states there and you want to direct it towards being one particular state but when you want to read that out you've lost the whole thing and then you'll have to you know regenerate so cubics have to be in reality it's not just three hundred and daniel qubits that will give you two to three hundred states because you can't observe that quickly enough you have to keep regenerating so you need thousands and thousands of qubits to do that yeah okay so so that's its conception I mean if again these are they're getting to be reality hopefully we'll see they will all see the light of day or in a in a commercial environment soon but there are many challenges that we are looking at you know so when you're talking of applications here and think of some other key the applications right through today today I'm trying to make my travel plans you're trying to make your travel you're trying to you know we're trying to optimize everyone's travel plans and it takes forever because so many of us are trying to do this but if it can it all the possibilities can be resolved simultaneously you can imagine how easy it can become so travel and logistics are one one example of where you would imagine something like quantum computing being used precision medicine or pharmacology is another one right where you have so many different possibilities but you're trying to zoom in so again just you may think of other examples when cryptography when there are encryptions that have not been solved to do date because there are so many possibilities and you can't get that it's it's actually a big area that quantum computing is essentially beginning to show potential into it and of course the way the data you have so many different possibilities how can you improve your forecasting based on all the data that you get every single place and you know trying to get that right all of it there's an aspect of you can't wait years for the answers you want the answers to come around right away and that's where the that's where the benefit or the promise of this emerges okay we have this is a an Intel working with Q Tech Research is a collaboration happening with the Netherlands we're working on this again from our standpoint Intel is the technology company and the components research side remember we have our research wing there and the component research side we're looking at the law side whether it's the patterning the atomic layer control packaging which is again a big thing on the Intel lab side we're looking at the upper end of the stack the algorithms the system architecture control electronics etc and the qubit actual operation and control we are working in partnership with with the Netherlands team to do that so it's not enough to just have the qubits and questioners you know you have to develop the entire system when you're talking about the entire system the qubits have to have to communicate with each other you need control electronics for that it's not just a single qubit they don't work in isolation then one tier app is that you want your you know you have to have compilers different compilers from what you they have today and then of course you have your applications and Gotham so at every level we have different challenges so at the lowest level where we're looking at the quantum chip there's obviously you know looking at the device design fabrication there's of course assembly and packaging there's the connectivity topology and the connectivity that's happening then you go one tier up actually there before I do that this is you know coming to your question there are two types of qubits today spin I will not go into the details but there are spin qubits and they are superconducting qubits and then this is basically the emphasis here is on the superconducting qubit progress where we've gone from just creating a resonator to a six qubit system to a seven qubit array to a 17 qubit array to a tangle lake and just hold that we have a little small video where we talk about that but that's where we are at now I think that's 46 I think that's 46 right now okay at the at the control level because you need to be able to come you need to be able to communicate with it come to it and if you need at least two connections per qubit it's hard to imagine how many connections you will require right it's not really scalable then you talk about multiplexing okay I can use the same connections for multiple qubits and the question is does it function at at the low temperatures that you want there's a lot of challenges it's coming out of you know being able to gather at effectively done can I increase the temperature from say 0.5 Kelvin to 1 Kelvin and maybe I can I can do some more multiplexing so about control electronics levels we have that you know error correction you will have errors as you as you go through it you have this area correct correction is a big challenge over there and that's simply because the qubits they lose they're fragile remember they're fragile with there's noise they lose their they lose the entanglement state and then you might have an erroneous outcome that's why because of these challenges the reason I'm mentioning this this is why it's not it's not a full-fledged reality reality today we have to navigate through these challenges but we are getting there one step at a time okay at the compiler level because you know you have some of your quantum computing operations they have to work with adjacent qubits they don't work in isolation there so the compiler they must be the compiler must be able to orchestrate the the placement of these qubits and at the right time because again there's a time factor to it they all have a limited time line so everything at that optimization and the execution has to happen during this limited time line for every qubit otherwise a qubit doesn't exist anymore so so arranging that maximum parallelism under your timing constraints you need separate compilers to be able to do that and then finally your of course in the application space you know there is a whole aspect of developing algorithms that will implement your qubits say we have a qubit simulator that has been released again out there and it's something that you know again you all can have access to there's an open source release of it for people who are working in this room to explore it further and you can look at qubit simulations there it is for for broader community exploration that's something that you can look at and yeah this I did speak to this already right you have a compelling applications you look at algorithms there and you want to develop real workloads for your for your systems for the early systems that come out and so you're you know likely so where where will it for likely sit right it's it's you would imagine it being applied basically to HPC high performance computing per se right it'll be a it's nominally place Yocum conventional or whatever you have in your data center but imagine it to be a coprocessor sitting in your data center alongside it right so you have we have 50 cube it's basically envisioned to be if you if we are able to get to 50 cube it's we imagine that to be a learning testbed for a quantum system whether it is very hard to get from 49 to 50 cubits I mean that's itself every every single step you go up it comes increasingly challenging to do so even small problems will require hundreds and thousands of qubits to solve them again because of the short time frame but each one loss it's basically the fragility that comes into that okay and so you know 1 million cubits yes that's a dream we're not even close to being there but you know that's why if we get to we'll be able to do you are our dream problems we should be able to solve by them let me show you a little video on this set see if I can get I've been working on content computing for almost 20 years and for many years it was basically a physics experiment but now we're at a different stage where more and more excellent engineering is needed in reality Q tech here in the Netherlands they are experts in all things quantum it's a very natural partnership where we bring our fabrication expertise here they bring their quantum expertise and together we co optimize orko design for quantum computing what I'm holding here is tangle Lake this is our 49 superconducting qubit quantum processor and this is our first step towards a quantum computer a funnel computer will not look like a classical computer this is a machine that's going to look like no other that we don't I mean you can't just take a quantum processor chip and plug it into an already general quantum computing system we have to really have take a systems approach to quantum computing because we have to build the whole constituting system what we are trying to do is we are trying to fundamentally create a different type of computer and where we are using the properties of fundamental properties of quantum mechanics to make computers we are not only processing zeros and one we are using zeros and ones at the same time we're currently making a spin qubit device at our 300 millimeter Factory and Hillsboro Oregon and we're shipping those devices here for analysis Cubans have several advantages they are very compact if we were to cram them together in a square millimeter there will be space for 1 billion spin qubits also their states are very long-lived compared to other qubit types and finally they are relatively robust in the sense that they can operate that ever so slightly higher temperatures than the lowest temperatures needed for some other qubits implementations endless is really unique in the sense that it can integrate billions of transistors on a single chip now imagine that those transistors can all hold a qubit that's rectly it gives us the promise that that we can scale up to millions or even beyond so there's really no better system than a quantum computer that we would use to understand Sciences such as biology such as chemistry medicine how to design drugs how to treat for cancer with quantum computing we have a goal of changing the world but changing the world takes time we still think that we're about 10 years away from something that will affect your life or mine I think the principles of quantum computing are very very solid in this lab we don't question quantum mechanics we we evidence quantum mechanics every day for me it's not a question of if one can process information with quantum mechanics it's the challenge of integrating a complete system which let me emphasize begins with the quantum ship but includes a whole lot of non quantum elements as well I was born at the tail end of the Apollo missions at the tail end of the space race and this feels like my generation space race [Music] all right so that was a little bit on quantum Si and I think that's what I have let me just get to my last slide okay all right so in summary as I said you know University research collaborations is a very very important component of really Intel's eventual product portfolio we are essentially exploring the future and we are defining the future we're basically moving ahead and so we put a lot of emphasis on that data is changing as I mentioned with it is changing and we are having to look at rethinking or our design or architecture to essentially do our part to to tap into the data revolution over there and so that requires us to essentially think differently across the entire stack whether you're looking at the process of the device level at the circuit level the micro architecture architecture level systems algorithmic level at every level and together for the foreseeable future Moore's Law is going to be in life and it's going to be relentless so that's it thank you 