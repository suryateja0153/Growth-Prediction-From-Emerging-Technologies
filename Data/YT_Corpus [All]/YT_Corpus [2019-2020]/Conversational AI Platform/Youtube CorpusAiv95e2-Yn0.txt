 You're not going to want miss this episode of the AI Show. We learn how to actually create amazing dialogues, using some new open-source software as well as testing it for the bot framework here on the AI Show coming to you from Microsoft Ignite. See you then. [MUSIC].  Hello and welcome to a special edition of the AI Show coming to you from Microsoft Ignite. I've got a special guest Rubbish. How are you doing my friend.  Good, great.  So tell us a little bit about what you're working on.  Yeah. I work on the Bot Framework team as a program manager. I work on the Bot Framework SDK and tools. We have a lot of excitement here at Ignites. So hopefully looking forward to share it with you guys.  Fantastic. So why don't you tell me a little bit about this new Bot Framework composer.  Sure. Bot Framework composer is a brand new product that we are announcing in public preview, I think tonight. All it is is an integrated development environment that brings several different key parts that are required to build a bot. So when you think about conversational applications you need language understanding.  Of course.  You need an ability to model the conversation, which is dialogue. Then you need generation, which is rewards of understanding. How is it the bot is going to communicate back to the user, what is it going to say. [inaudible] model like you know things to add information to get persisted. So composer in an integrated environment that brings all of these together, so you can stay in place, model the language understanding capabilities, model Q and A capabilities, do the dialogue, do generation and it's an open source tool available on GitHub. It's targeted at developers [inaudible] to go continue to build their bot journey.  This is pretty amazing because, I understand bot and I understand everything they need to put together but sometimes it takes a lot of work to put stuff together. So can you show us how this actually is used.  Yeah, absolutely.  All right, let's do it. Yeah. So I have composer open here. Let's go ahead and create a new board. One of the key things that I want to highlight is that a bunch of different templates that are pre-baked for you to start from. For just the purpose of this let's start from scratch. Composer as I said is an open source tool but it's running locally.  Yeah, and I see that in a local host 3,000.  So if I want to like create a new test board, right? Notice that there is just a part that I'm pointing to that is on my local file system. So composer all the files that it's generating, its generating dialogue files, ALU files, [inaudible] files. All getting written out on the desk.  That's awesome.  But not just that, when I create a brand new bot, let me switch over to the file explorer here. I'm going to composer. I just created, under my watch, we created a board called test bot, if I can find it.  There it is.  So you get a pre-baked run-time, bot run-time that you also get logged on and everything that you're doing in the composer UI, gets persisted on this. So if I go under main, there is a dialogue file. That is my ALU file. If I go back into composer and create additional dialogs and while things out, there are going to be more files that get dropped on this. The key thing here is that these composer is fully built on top of bot frameworks and [inaudible] dialogues, which is also in preview.  Okay.  That's a new dialogue in the code bot framework SDK itself.  I see.  It's also built on top of the language and ration capabilities that we are introducing in the SDK. So everything that you could do here in the UI, you could also do in code. You could start in code and then plug in some of the stuff that you did in composer into your bot, you get a nice spectrum and continuum there.  So if you already have existing things that you built, you can plug it in and use as well.  Exactly.  Let's show us how you would get started here.  Yeah. So here's composer and everything in a dialogue is modeled after an event. So you've got a trigger and now something needs to happen.  Right.  Composer gets you started with a way to welcome the user. So I've got one triggered here that says the conversation started. The way I can respond to that trigger is by adding actions. So you can do a bunch of different things like send a response or ask a question. Maybe you have business rules that you need to forward the conversation for, and if so it can do that. Or maybe you need to start us up dialogue or repeat the same dialogue and bunch of other stuff. Like I was saying early on, there is memory that also you need to manipulate because you want to remember some information throughout the conversation.  By memory you don't mean like RAM. You mean like, they set their age and that's important to their dialogue.  Or something like user's favorite color or age. You want to have the bot remember it as long as it's talking to that user. Some information like maybe you and I are in a chat, group chat together with the bot, then the bot needs to remember stuff throughout the conversation or the session. Then there are information that the bot can remember through the particular dialogue that it's on all the time. You get all of those flexibilities.  That's how you set a property. That's really cool. That's really cool.  Yeah. You can manipulate that. You can access external resources. Lot of times you need to call a back-end API. At least for [inaudible]. Maybe you need to pull information in. So we have an action that lets you do that, connecting to Q and A maker. One of the most popularly used cognitive service. You could do that if you have a Q and A maker you can connect to it. So let's just go ahead and send a simple response. So one of the things that I was chatting about is language generation.  Right.  So as you notice, this is just a simple markdown list. So you get an in-place editor, where you can provide variations. This is just saying, hey when the user connects to me for the first time, greet them but at random pick one of these variations.  That's so it doesn't feel like a robot.  Exactly. So you get to have that freshness. Let's do one more thing. I also spoke about language understanding. We have deep integration with Louis, but for just to run this demo we're going to turn it off. I mean of course you can use regular expression or you can bring your own recognizer. But I'll show a little bit a more complete bot that has it. One click you can test an emulator. Emulator is an open-source cross-platform tool that we have, that you can use to connect to and talk to your bot. So the bot only saying, hello I'm, off and going. If I restart this conversation sufficient number of times, I should see a slightly different response. It's just picking one of those at random. Now let's context which unlike show you a more complete bot. I'm going to open something, which is one of our samples to do bot.  Okay.  So now this bot is going to leverage Louis, right? Here on my intense, which are defined as simple markdown.  You're defining the Louis intense in Markdown and it just takes it.  Yeah.  That's cool. Before you used to have to write the thing in there, you have to put the end here. This is the beginning and then mark there. This is the entity,t and you just do it like that.  Yeah.  That's so cool.  So in Markdown, that's a section right? Here the section is an intent and you can provide examples of what the user could says that maps back to that intent as a list. You can also do entity definitions like I've done here. Behind the scene when I hit Restart bot, what composer is doing is creating the required lose applications, training every information.  That's really cool.  Publishing it all off, setting it up.  Yeah, this is much better. Before there was a lot of manual like busy work.  Yeah. A bunch of these are doing simple things and you can also do sophisticated things. Maybe I want to come back with cars. Maybe I want to come back with buttons. We have this concept called suggested actions. So with language generation you can not only come back with simple text, you can come back with Conditional texts, you can come back with cards.  It looks like it's running a function too.  Yes. Excellent question. So if I jump back into user input, sorry bot responses, which is where language and ration is and switch over, this is another Markdown file, right?  That's cool.  So every single thing that my bot is saying is managed in a simple Mark down format. Composer automatically creates a named template for each of the action, but then you can customize it. You can call it your own thing. Maybe this is where you are sending the welcome message and you can name it something.  That's cool.  You can also do pre-built functions. So if I scroll a little bit down here. All right. So you also have a huge suite of pre-built functions that you can use. Like for instance, in this particular line here I'm counting the number of items that are in the to-do and just reading it out.  I see.  I don't have to do that in my main dialogue logic, because the count is only applicable to the language and ration bot and what the board is responding. Now you can do multiline markdown. You can have these broken out into sub-templates. If you notice this line here, this is actually composing this template, and then some text and then another template. So you can take it out and get super-rich variability and composability there.  That's really cool. Can we play with it?  Yeah. Let's go ahead and test. Off the bat now you see buttons coming back. That's coming back through LG. So I'm going to now try to say add. We're like, "Oh, what do you want to add to the to do?" With adapter dialogues, one of the cool thing is that you want to be able to understand the user, not just initially when you take them through a specific sub-flow. But also they might be interrupting the conversation and saying they want to do something else.  Right.  Like I'm adding something to the to do but I'm like, do I already have that item. Maybe I want to first look at it.  I see.  So I'm like, "Okay, can you show my to-do first."  So this is like not the normal flow right, and we're going somewhere else and it's going to be able to do.  Exactly. Each of these are modeled as separate dialogues but adapter dialogue actually takes much of the branch out of you having to code all of this up. It's like, "Hey, I want to enable interruptions while I'm in this part of the conversation" and then adapter dialogues does the rest for you. So it actually understood this wasn't interruption, is still using Louis to do that. Then it went into that flow and then said, you still don't have any items and then it came back and reprompted me for what is it that I wanted to add.  That's cool.  Right.  So it's like, "Okay, you don't have anything but remember we were working on this, what do you got for me?"  Exactly. That's just like how people conversation will go.  Yeah, that's regular talking.  Sometimes you might be like, "Oh hold on to the third, let's get back to it later." Right? "But I'm going to, let's finish what we are talking right now and get back to it." You can do that.  I do that all the time.  But anyway, with that after you get the complete flexibility. But let's just go ahead and add something to the to do. Now it's like, "Okay, I have three different types." So I'm like, okay, let's put this in the grocery list, right? Through button clicks now I can see all the stuff that I have across all the list, here is just a standard bot. It's just going to show me what do I have in each of the sub-lists and the grocery list we just added. Milk, I can remove it. But the key things here is that how easy it was to go from your ideation through being able to in a single place do language understanding. You also can plug in Q and A and it is plugged in there. Then have your dialogue modeling do the language generation, memory management and give complete flexibility in terms of how the bot response back to the user, use cards. All of these things that you could do with the Bot Framework SDK. I can just do it in the bot.  That's awesome. Could we go back to the [inaudible] before? Where can people get that.  Yes, awesome question. So all you going to go is github Microsoft bot framework composer. As I said, we are open source, just go ahead, clone the repo. Three or four steps you can get composer running on your machine and off you go.  So that was awesome because not only am I able to use the bot framework tool to actually test the chat bot because I saw that came out recently, but now we're actually able to build dialogues using this software.  Yeah.  All right. Well, thanks so much for spending some time with us. Thanks so much for watching and learning all about how to build amazing dialogues and test them on the AI show. Special edition coming to you from Microsoft Ignite. Thanks so much for watching. We'll see you next time. Take care. [MUSIC] 