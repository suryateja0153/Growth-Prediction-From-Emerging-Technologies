 hi I'm Dale this is making with ml and today I want to talk about something you've probably experienced if you've ever been on the internet I'm talking about user-generated content that violates a platform's Terms of Service [Music] almost all content platforms whether they're u2 or Twitter or OkCupid or the New York Times have some strategy for dealing with bad user input and this is called their moderation strategy you can imagine what's okay to post on Reddit or a dating app might not fly in the New York Times so these platforms have to consider what is allowed under their Terms of Service these platform and haters also have to consider the implementation of their moderation strategy let me give you some options option number one you could hire a team of human moderators to go through every piece of user-submitted content before it's posted to okay it this is called pre moderation and as you can imagine it's really good at making sure that nothing's bad slips through the cracks because human beings are actually looking at what's being posted but it also doesn't scale very well and it takes a large human moderation team that scales with the size of your user input so you'd only use it if it's extremely extremely important that no bad bits get through the cracks option number two you could ask your users to flag bad content for you and then send this flag content to a human moderation team for later of you maybe in a sort of priority queue where they figure out what's important to review first this is called post moderation because the content is moderated after it's already been posted for example when you're served a YouTube video or a Google Ad and you have the option to report that content you're seeing a post moderation strategy the advantage to doing this is that it allows your human moderation team to scale but the disadvantage of course is that then your users have to actually see this potentially offensive content and in some instances this would be unacceptable both of these approaches have major drawbacks you're either having your cue and moderation team go through every single piece of content before it's posted or you're potentially subjecting your users to content that should have been flagged but that wasn't and neither of these approaches work for real-time moderation like for example if we're doing a video stream or add messages which brings us to option number three a I powered moderation which is what we're building today the idea is to use machine learning to analyze Khan like text speech images video and flag the content the instant that it's created you can then send that content to a team of human moderators so that your users never have to see it but your moderation team can scale better now you might wonder why not use a I should just moderate your entire moderation solution so let me add a disclaimer here the sheet learning models are always probabilistic which means that they invariably make mistakes and sometimes they're biased meaning that they make mistakes in particularly bad consistent and potentially embarrassing ways so I always recommend using AI in conjunction with human beings having this human in the loop for example you might have your algorithms put comments into a moderation queue for your moderators to review or allow users to repeal decisions that were made by the AI so knowing that today I'll show you how to make a simple AI powered moderation bot for the chat platform discord let's get started today we're gonna build a bot that sits in a discord server and analyzes user messages when the bot detects a message is toxic it will fly it with a dynamite emoji it'll also keep track of insulting flirtatious spammy and nonsensical messages and flag them with appropriate emoji it'll keep a scoreboard of emojis or Karma for each user in the chat room and if a user types too many toxic messages they'll get kicked from the room now don't worry if you've never done any machine learning before because this project we're gonna use the perspective API to do the complicated machine learning bits for us it takes in strings of text and produces scores for different attributes like toxicity insulting this explicitness and even just a coherence to create these models the prospective team use millions of comments from data sources like the New York Times Wikipedia and many other open datasets if you want to see how they built the model and architecture behind it and even learn how to train your own check out the perspective API website to use perspective you need to fill out a quick google form explaining how you plan to use the api once your project is approved you should be able to use it in your app next go ahead and download the making with ml github repo and navigate to the discord moderator folder here's all the code you'll need to run your bot the file prospective Jas shows you how to use the perspective API in JavaScript at the top you can see all the different types of attributes the tool recognizes like insult toxicity spam incoherence partition and more now let's connect the respective API to a discord bot to do that you'll need to sign up for a discord developer account once you have an account create a new application then create a new bot by clicking on bot in the left-hand panel give your bought an avatar and a cute name and you're set the brain of our discord bot lives entirely in the file discord is here at the top you can see our emoji map which tells our bot how to react to different user comments rotations get a kissy face and spam gets a fish down in the evaluate message function we call the perspective analyze text function to detect attributes in the message if an attribute is found we react with an emoji and if the user is sent too many toxic messages we temporarily kick them from the channel the next step is to run your discord bot from the command line awesome now it's ready to be added to your server in the discord developer panel under OAuth select the permission your bot needs sending messages adding reactions and kicking users copy the URL above into your browser and from here you'll be able to add your bot to a server now if we can wear a discord server boom the moderator bot is in the channel keeping track of everything I type and reacting with emojis if you want to build this discord moderator by yourself the code github and you can follow along in my very detailed blog post in the description and there you go now you have your very own AI powered chat bot moderator for discord now the moderation strategy that our bot used is very simple it just kicks users from the channel when they say too many things the AI thinks is toxic but like we discussed earlier that's actually not a very good strategy for a real in production moderation because the model can make mistakes in fact the respective website specifically says this API is not designed for fully automated moderation solutions and they even list a bunch of known biases that the model has just think of it this way ai is just one piece of the puzzle and it works better when human partners are in the loop that's all for now if you want to learn more about moderation in AI and make sure you check out the blog below and let me know what problems you want to see soft with AI in the comments below but remember those comments are moderated too that's all for now see you next time [Music] you you 