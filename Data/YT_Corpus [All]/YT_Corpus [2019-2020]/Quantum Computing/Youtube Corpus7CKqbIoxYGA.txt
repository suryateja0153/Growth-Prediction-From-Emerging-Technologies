 okay good morning everyone let's let's change a little bit of topic now I'm going to talk a little bit more about applications of corn computing and in particular in machine learning this is going to be a machine learning talk and for preparing it I did this exercise I thought let's take the last year the last period of 365 days and let's see what was in the news about machine learning and you know every once in a while you hear some news that something that has been done so on but like doing this with respective really shocked me because there's so much that has been done this year we've gone from like generating high resolution images of faces of people that do not exist to using machine learning in in medicine in helping predicting diseases to also it's also being used to as a tool in other areas of research to do actual discoveries and then the list goes on and on and on we have like now presenters that are not real we have AI creating art we have a I writing coherent text and evil a couple of days ago we had a machine making well competing in debate competition against humans and this actually well seen this with a bit of like perspective makes you think wow like from here in into a couple of years there's nothing that deep learning is not going to be able to do right well actually in this talk I want to convince you that this may not be quite the case and let me put you an example of it let's think that you are an expert in deactivating bombs okay something that most of you are probably and let's well you want to innovate and you want to implement machine learning and and try to make your your work easier by using machine learning so you have this deep learning deep learning algorithm that takes information about the particular bomb for instance a very important thing is as you as everyone knows the color of the cables right and well then you use this how you use the algorithm to predict which cable you have to cut so the answers you get are something like this okay and cool you train it it works fine perfect but then it goes the application into a real problem so you are faced with a real bomb that if you cut the wrong cable it explodes and you just get this information well I didn't know you but probably I would like a bit more information right maybe I don't know how sure are you about this isn't it that well were you more or less the same sure but just a little bit less that it was a blue cable I just wanted a bit more you know and it turns out that these questions like how sure is an algorithm about a specific prediction is a very difficult question to answer in the standard frame of framework of deep learning the reason for this is that deep learning as we we know it now is mostly based on an optimization it's based on calculus and these questions do not fit that well in contrast there's other well there's people aware of this and there's other frameworks in which machine learning operates that have a more natural frame or a more natural framework for these sorts of questions like a probability theory and that's what I what I'm going to talk about this by Asian approach to machine learning the word position should I don't want to scare people here it's just using this source of theorems about probability distributions this is essentially Bayes theorem which tells you what is the probability of some event occurring given that we have some previous information a and how to compute it given other information that is more easily accessible and this has a very nice application in machine learning you can think of what is the probability that a label is given given that I know some data been training I know some preview I have some previous experience for example and I compute I can compute that from quantities that are more accessible and more accessible in my data set for example and now the kinds of answers that we get are still not maybe not completely convincing but at least we are getting a bit more information about the solution that is being output with something like this I would be a bit more convinced I'm cutting the right cable you know okay and one so one approach so one approach to is as well doing it in classical computers people have been working on this and have been doing research and this kind of by Asian training of deep narrow and deep neural networks can be done here I just will have to warn you that here comes the boring math but I will try to keep it simple essentially the way of doing by Asian training of deep neural networks is thanks to this analogy between each layer in the network and something that is called a Gaussian process and the important thing about Gaussian processes that we need to know is that well we assume that there is a global Gaussian distribution underlying the outputs of each label and then we want to compute this quantity the the what is called the posterior distribution which is essentially the probability distribution of some label Y star given that I have some input X star and some training set which with with instances and labels and this if we assume this Gaussian processes has this form here it's just a normal distribution a Gaussian distribution with some min and some variants that are given by this formula the important thing here I wonder if this I can point with this No okay anyway the scale here is an important quantity that is called the covariance the covariance matrix and it's essentially a matrix that you build out of your data out of your data by applying what is called a covariance function to each of the if each combination of data points and a very very nice thing is that for each layer you can compute this covariance matrix just using the information from previous layers so you can do you can do this training in a recursive way awesome then so this thing exists though why is not everyone using it well it turns out that well it's not like super hard it's not it's not MP hard to compute this inverse so remember that we need this covariance function this covariance matrix but we have a power to the minus one we have to invert that big matrix and this inversion yeah it's not super super hard but it but still for very big data sets for a large amount of points the number of operations that one has to do goes with the third power of the number of data points and this at some point becomes a bit intractable and when so so so what what can we do now here is the point where quantum computing can help so why don't we do something like this we encode these vectors Y and this this K star into quantum states and we interpret our matrix as a quantum operator can we Dowe now do something easier well it turns out that yes luckily there was this algorithm by Haslam Haro Haslam and Lloyd developed in 2009 that allow us to do exactly this so you have a system a times x equals be like a linear system of equations and there exists a quantum algorithm that retrieves the solution this this vector X which has a very similar form to this KL to the minus 1 times y so we can do that part on the one hand and on the other hand we also have quantum algorithms to perform this inner product in an efficient way so we can do this and that's what we were well these are the sorts of results we were connecting in order to have and end-to-end quantum algorithm to do this by agent training of deep neural networks what we did we do essentially this is an in this paper over here that we released like half a year ago essentially we need just two ingredients which is first the recursive formula for the covariance matrix of a layer as a function of the covariance matrix of the previous layer and then we need and this it's it's true that it's not a trivial thing but we would need the initial covariance matrix the covariance matrix of the first layer encoded as a quantum state which I mean in principle you could for instance compute classically and then prepare such a state but anyway this this we don't care at least in in this project we don't care too much about it given these two things what we were able to do is to build an approximation of the covariance matrix of the last layer again well we built this and then what we also built was the time of illusion operator under this approximation so this is essentially yeah this could be encoded into a quantum circuit or or simulated by via Hamiltonian simulation and could be applied in the HL algorithm to do the matrix inversion so essentially yeah we take this state encoding the the initial covariance matrix and we developed the evolution of the time evolution operator that allows us to do the matrix inversion in in a quantum way and compute the inner products so to obtain the parameters of the distribution that we want to fit the data to not only that this was more theoretical but also we did some sort of experiments bear in mind that these are experiments done by theoreticians so they made they may not satisfy real experimentalists but well we were we were coding the core part of the algorithm this h HL part we were implementing it in various frameworks in rickety forests and in IBM q and we were doing simulations of the run of the algorithm for Imbert inverting big matrices as big as 4x4 and running the protocols in noisy simulators using different different kinds of noise in the in this figure I have both gate noise which is an X operator applied after every gate of the circuit with with some probability and you see that is awful essentially because of the the number of gates that you have in these circuits is quite big so even for low probabilities you have a lot of X operators applying on your on your state and we have this measurement noise which is just a read out error when you do measurements and this is not not that bad not only that we also did runs in real quantum computers both of IBM and Rika team and in the case of IBM we got particularly nice results in particular well we got here while I'm plotting this probability of success under a swab test just not to make too much fuss about it this can translate into a fidelity with a desired target state and in the case of IBM we get fidelities of about 78% which is which is pretty encouraging so yeah that's that's essentially all I wanted to tell you just to wrap up quickly I hope I've well they take away the take away message is that not all machine learning is deep learning and actually there's other frameworks and other and other ways of doing machine learning that may be more useful for particular applications in this context by using deep learning based in Gaussian processes it is useful you can train very large networks but it's also classically hard nevertheless for the class for the hard parts we can resort to quantum computing I have some sort of hybrid classical quantum algorithms to do the full training and in this respect the experiments that we have conducted our are encouraging as I said especially especially in the IBM platform but still there's a lot to be a lot to be done the matrices that we could invert in real computers were not bigger than 2x2 so probably it would take less time maybe doing them by hand but anyway all the tools are there we did everything open source all the code so so they are up to available for generalization or for the modifications and I guess it's it's a matter of time that we have application of these algorithms and in a more realistic scenarios and that's all thank you very much [Applause] 