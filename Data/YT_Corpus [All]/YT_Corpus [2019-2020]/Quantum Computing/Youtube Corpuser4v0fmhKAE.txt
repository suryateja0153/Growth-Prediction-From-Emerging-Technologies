 Today's computers can do a lot, but it seems the more you ask of them, the slower they get, and when it comes to certain things, classical computers start to fall short. That's why physicists have proposed the quantum computer. Unlike classical computers these use quantum bits or qubits for short. A 'bit' is a unit of information with two states often represented as 1 or 0. whereas a classical bit must be in either state at any given time, a qubit's state can be any proportion of the two states--being some degree of both at the same time. This intermediary state is called a "superposition." The catch is: any attempt to measure a superposition will cause it to decohere. In other words, the qubit will randomly assume one of its primary states--most likely the one closest to the superposition. So what's so different about computing with qubits. Fact of the matter is, a lot more information can be contained in a lot less qubits. You can create four distinct states with two bits. Yet, classical bits can only be in one of these states at a time. Now looking at two qubits, because both are in a superposition of state one and state zero, a single state contains all four of the previous classical. Quantum computers can answer certain problems in a lot less steps by performing operations on multiple states in parallel. So why don't we all have QuPhones and quantum core processors in our laptops. Fact is, qubits aren't the most stable of things. They can be easily corrected by noise. And what's noise? . . . Let's see! Loud isn't it? Wrong noise. That's better! Quantum noise is those factors that create uncertainty in a system. Remember, a bit can be a variety of two systems. In the same vein, a qubit can be any quantum mechanical system with two levels, like the spin of an electron. So, yeah! An old jazz band can be quantum noise, but when working in the quantum realm, bits are so microscopic that even a photon can decohere a superposition. Even observing a superposition, decoheres it. Think of this room as a quantum computer and these guys as logic gates--each performing some operation with the potential to alter a bit. Now say something were to disrupt a qubit midway through. The remaining operations aren't being performed on a superposition but rather a decohered state-- corrupting your output. So the current solution? Keep the computers clean colder than space and hope for the best. But!! There may be a better way to protect information than just shielding it: breaking it down! Instead of qubits being a single particle containing a system, consider a system comprised of multiple particles. Anyons are two-dimensional quasiparticles. And the state of an anyon system is determined by how those particles are spatially configured. Thus swapping particle positions creates a distinct new state. If we graph the position of these anyons versus the passage of time, we see their world lines begin to braid. If you were to encode information into the system, then each braid constitutes an operation. This is a multi-body system, and information is realized when you bring the pieces together. If a single particle gets a little noisy, then there won't be any decoherence because no lone particle carries isolated information. It may seem small scale but the next huge leap in computing may just be . . . ~ noise cancellation. ~ 