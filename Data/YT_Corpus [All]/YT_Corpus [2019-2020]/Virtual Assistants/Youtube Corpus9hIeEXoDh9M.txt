 thank you very much for coming over what I probably your lunch break so and I hope we got lots of exciting content for you and I'd really like to welcome to the stage to start the session professor Verena Rieser she is with heriot-watt University and she has been doing research into various spoken dialogue systems and interesting future-looking conversation or technology so I will let Verena introduce herself and then we'll have a panel discussion afterwards thank you so much Catherine that's very kind of you well thank you for inviting me and I hope you can always see my slides so today I give you a brief introduction to voice assistance beyond voice assistance and whether we can use machine learning or how far we can go with machine learning so in other areas of natural language processing we've seen tremendous success using especially deep learning methods with models such as bird being free trained in other areas there's really no question whether machine learning is beneficial however for conversation and agents as I like to call them it's not that clear we're still waiting for the killer application and that and the reasons for that I try to explain you at least a couple of them in in my talk so just to give you a little bit of background about myself I'm a trained linguist and I'm doing research in spoken dialogue systems or conversation and agents for almost 15 years now and my the topic of my research interests is really whether and how how far we can go with machine learning so I'm applying different types of machine learning to the problem of how can a machine have a conversation with a human so when I say conversational agents I mean all different degrees of embodiment so we start with you know voice assistance only to chatbots but also to more embodied versions of humanoid agents such as the pepper robot for example and so this is what we call a dialogue system so this is the the architecture which most of us use which is as you can see very modularized so we start here with the user uttering a waveform and these waveforms then gets translated into actual words so that's done by the speech recognizer and then these words get assigned some meaning so the machine can actually process what was said and then this type of meaning often gets represented as some sort of very abstract dialogue acts up here and this dialogue acts then gets fed into what we call the dialogue manager so you can think as the dialogue manager sort of the brain of the system and thus dialogue manager then comes up with what to say next so that's its strategy of how to reply and it comes up with this reply based off the coast on the content so what was said so far for example and also some real-world grounding so this might be a database or for those who work on visual dialogue a picture and so on and then again it comes up with a reply in terms of these very abstract looking dialogue acts which then gets fed into the natural language generation module and this module then translates this abstract representation back into a hopefully well formed string of words and that's getting synthesized back to the user into waveforms so this is the traditional architecture and I've mainly worked on dialogue management natural language generation I've done a little bit of work on text-to-speech as well so in what most people use and especially in industry for building the the brain of the dialogue system so the decision of what to do next is a very elaborate set of rules which then get organized in terms of these decision trees and as you can imagine as the application domain grows these decision trees become very hard to maintain and also very hard to port to different domains so in the early mm myself and a couple of other colleagues I'm started to investigate a more principled approach of how to learn how to have a conversation and we looked into a paradigm called reinforcement learning so this comes from robotics and the idea is really that you've got a dialogue agent here in this dialogue age and explores different actions so this is almost a bit like trial and error what can I say in this context and then observes what sort of impact these actions have on the environment in this case the user and then it also gets a reward or a punishment how good these actions are and the reward of punishment is specified from by the system designer and then based on these observations so trying different things that updates a value function and this value function basically tells the agent what's the best action to take in a certain state he's in or she's in so this is theoretically very attractive and if you want to know more about this I've written a whole book about it however it also comes with drawbacks so first of all um it's very data hungry so first of all to either you have a very patient user interacting with your system over and over again or you've been simulated users which come with a whole bunch of other problems as you might imagine secondly you have to manually specify the learning problem as I said the reward you have to specify the reward function so that's not easy and you have to specify what's got what goes in the state space and this was often referred to as the black art of reinforcement learning and lastly because the system is very modularized there's often a mismatch between these different modules especially between the dialogue management and the natural language generation module so as I said this was early 2000 so a long time deep learning and we thought great at least two of these problems can be solved using deep learning so as some of you might know deep learning get gets rid of the manual feature extraction and stay state so you can basically learn from raw data only you don't have to define features anymore so we can for dialogue system that means we can get rid of these weird dialogue acts right so if you don't have any semantic annotation anymore this also means we can learn from loads of data meaning open subtitles reddit social media all the things where people have a conversation and these are really big data set so we got very excited also it means that this architecture which was very modularized can get replaced by a very simple input output mapping so basically you treat what the user said similar to a machine translation problem you say what the user said is the foreign language and I'm going to translate this into my own language which might be English so that's what the system then is going to reply so this is called a encoder decoder model and you just train that on very large data sets and off you go so that's the theory and some of you might think well is that the end of linguistics and as you can guess from my background I tried to argue no this is not the end this is only the beginning so there are a few open questions when we deal with these end to end architectures so first of all where do we get enough suitable data from and the emphasis is here unsuitable then our bees enter and architecture is actually good for customer facing application because that's what we ultimately care about and then finally what do we actually learn when we learn from big data and that's a very interesting question which relates to other fields in this area as well so in order to answer this question myself and my team he entered the Amazon elect surprise challenge so this is an annual challenge which exists since 2017 where University teams compete to solve a very difficult problem so the problem is to converse to build a system which can converse about any topic so we call this open domain so whatever the user says you should provide a coherent answer which is also engaging for the user so this is actually the holy grail of God of AI in general so no one has solved this before so Amazon said great we give you access to to our customers so that was the main attraction for us so usually we don't really get access to that amount of customers and also real customers were the real goals so our system was released on the US market so every time the user said hey Alexa let's chat our system got on the line and or one of the system's got on the line and tried to engage the user in conversation so these were our competitors in 2017 and we were one of the three systems which went through to the finals and we ended up at third place and which we are very happy about and then next year we did it all again in 2018 again we ended up in the finals and again we ended up on third place which is great but what was also really great is the amount of data we got as I said for university that's first off to really have this type of user data to evaluate and to train your system with so as I said the goal here was to have an open domain conversational system and we thought great we've got these neural and to end models we've got huge data set data sets let's go and train up a system right so we got our sick - sick model encoder/decoder huge data sets and the first thing we found was oh it's actually really boring what our system says so it settles for very frequent short utterances so it was very often like yes no I'm sorry so nothing where the user can really engage with and the other thing which we found if the system wasn't boring it was highly in a Prius so what it actually learned from these big data sets it's nothing you want to actually have your customer interacting with so it said something like I can sleep with as many people as I want to and note that this doesn't have any profanity so it was really hard for us to filter a favorite was it's often said you will die to the user right so this is what it learned from movie data very frequently used in movies and then also very critical situations where the user had a very critical request the system didn't learn how to answer correctly so this was something where Amazon immediately took down our system saying as long as you can't handle these critical situations you don't get access to our customers and then also of one of my favorite shall I sell my stocks and shares and our system said sell sell sell again Amazon wasn't happy about that at all whereas from our perspective perspective we thought oh that's actually pretty good pretty coherent you know makes sense so again from a customer facing application not really what you want so this might remind some of you about an incident from 2016 where Microsoft released a bot on Twitter called a boat and taewoo's meant to learn from life into actions so very quickly Kay got quite racist it got quite sexist and then it also told the user why that was basically rubbish in rubbish out right and then Microsoft I think within 24 hours actually had to take down the spot because it was completely inappropriate so we thought right what if we actually learned about from clean data should be easy right so we all go there is it's it's very well known that if you got a bias data set machine learning can bring out biases so this was also discovered for example in vish where they had a vision data set trying to predict the gender of a person and as soon as they saw somebody in a kitchen they said oh this is a woman just because she's in a kitchen so these biases underlying the data can be realized using machine learning so we thought right okay let's let's start from a clean plate let's let's use clean data and we got a clean data set from a collaborator industry collaborator of ours who provided a data set which was semi manually filtered for and profanities and inappropriate behavior such as you will die and all of that however we found that it's still very highly contextual inappropriate so for example here it's very encouraging to something where it might not shouldn't be encouraging to the user so we have to come up with a plan B and we came up with an architecture which we called a learner and the Alana bot is based on multiple BOTS so we trained up partly models trained on machine learning party handcrafted models so for example the persona bot was handcrafted so the persona was very much about you know what sort of thought is that has it got a personality has it got favorite TV shows and so on and then we had a couple of machine learning based BOTS so for example the new spots crawled the news and summarized it in a concise way so the user could also ask for news or interesting facts and so on and then we had a very wide coverage natural language and then new pipeline so this was available to all the bots and then all the bots generated a possible reply and in order to choose one of the one of the replies from the bots we trained a neural anchor so so this rancor was trained on customer ratings so that's how we use the Amazon data to steadily improve our system and then finally we had a profanity filter which was eventually supplied by Amazon because they realized that that's actually a problem and by the way this is a product you can license and so we just spun out a company so if you're interested in using Alana and please and come and talk to me after this talk right so as I said and one of the attractions for us to enter this challenge was to actually get real user data and observe what real users actually do when they talk to these voice assistants and one thing which stroked me as something which I didn't expect was that we've got a very high level of customer abuse and this wasn't specific to our BOTS this is across different literature you can actually read about levels between 5 and 30 percent of abuse so here's a question why do we actually care if someone abuses abort and you know there might be frustrated that might have a hard day at work why shouldn't they you know abuse abort because it's actually not a sentient being with Felix however people are first of all concerned that more and more children are using these systems so parents obviously concerned that children are using that behavior by converse behavior by conversing with with these BOTS and then a bigger issue is what you Ness unesco cause the feminization of voice assistance so you might have noticed that all of these assistants are actually female almost all of them at least in the UK and America so this raises a lot of questions if this character gets abused and by looking into our data I can confirm that a lot of this abuse is actually actually sexual and directly directed directed to the fact that our Elana Bhat is female right so if the bot is not appropriately responding to this abuse this might actually reinforce biases towards female assistants so this is a very recent report by UNESCO which was only released last week so we thought okay so let's see what is actually the state of the art what do current systems actually do when they get abused so what we did we took the data we got from Amazon summarised it to some prototypical type of abuse so for example you know abuse about gender and sexuality abuse about sexualized comments abused about sexual insults and sexual requests as I said most of the abuse which we actually classified as such was more sexual and then we insulted a lot of BOTS so these BOTS were all state of the art these were commercial systems non-commercial rule-based systems also state of the art data driven systems and then we included a negative baseline so we talked to adult-only bots and and so how they responded and what we found was that as you can expect the adult only BOTS were flirtatious but also just a sizing the user and retaliate the insults so they were designed that way the data-driven systems very interesting as I said they produce a lot of nonsense these data-driven systems but they also can be interpreted as quite flirtatious and they were also very keen on swearing back to the user just because of the frequency of words if you utter swear word they're very likely to also come back with uh swear word to you and then finally the a lot of the commercial systems just avoid the whole issue and avoid to answer basically they haven't found a way to appropriately and deal with these type of user interactions so the next question we ask ourself what's actually a good mitigation strategy then and we tested we asked an crowd workers to rate different system responses to rank them relative to each other and it turns out that the number one ranking box according to our crowd workers is about which was specifically designed for language learning so that's a bot which was designed with some thought about you know interacting with young adults then we've got a whole cluster of bots which contain all of the commercial system which rank second so they're pretty good and then we've got a cluster down here where all of the adult bots are in the lowest cluster which you know confirms our hypothesis but also a lot of the data-driven systems are actually in this lower cluster down here which again brings me back to my point about arm is machine learning safe for commercial customer facing systems so this is obviously has some limitation to study its crowd crowd workers rather than real users though they're not engaged in this interaction so the next stage is to really test these abuse strategies with real users which are engaged with the system rather than so-called over here us which only read about the interaction which brings me to my finest night so as I said this talk is about machine learning for conversational agents so most of the commercial systems are using rules but these rules are brittle and hard to maintain but they're also easily to control right this is the main advantage for the commercial side you know how your system is going to react in a certain situation however however scalability is obviously an issue then reinforcement learning is a very attractive framework if you've got a task based system so you have a system which tries to solve a very well-defined task in a limited domain but it requires in domain data so I you need to actually have in domain data set and then finally this these deep learning methods for a response generation they're very promising for open domain systems but they're hard to control and they're pretty much a black box we don't know how the system will respond in a certain situation so this brings me to my future works or things I'm working on at the moment is obviously this type of controllable response generation and also reducing data needs for these type of reinforcement learning based systems and then finally what I'm very much interested in this how to design ethical conversational systems so this is obviously not all done by myself I've got a whole team helping me and so thank you very much to my team and here's some key references and please do get in touch if you have any questions thank you very much thank you very much that's really interesting and I hope that we will get a chance to talk a little bit more in depth about some of these issues as we have a discussion so I'd like to invite on the stage my fellow panelists grace Buzzard and Kate nil so thank you very much for coming along and joining me today so I thought we should start with introductions and maybe we could start with Farina and you can tell us a little bit about your background and how you ended up being where you are right now in voice technology in them all right so try to be brief so as I said I'm a trained linguist and did an undergraduate degree in linguistics and became more and more interested in actually the technical side of it and then did a masters at the University of Edinburgh where then also that my postdoctoral research an in-between I went back to Germany - Germany - Thailand University and got a PhD there and now I'm a professor at heriot-watt University great um so I'm grace I am the chief operating officer of the BBC's technology teams my background of strategy and so really what my job is to understand how these new technologies and approaches will affect our business and particularly how we deliver our public purpose which is why it's stuff about resonating so much around children and around how we use these systems ethically in a way that's gonna both serve consumer needs but also such as certainly it's really where I'm most interested and lots of my team in here so hello to you in there okay yeah hi I'm Kate and I've been working in speech technology since the early days of over the telephone systems yeah I'm partly to blame for all those really annoying I want to book a train took it that was me I work for nuance communications back in the late 90s and I've worked in industry and academia on all aspects of the diagrams that Verena showed you the speech recognition the text-to-speech and particularly I've built systems in many more languages that I know are something like over 50 languages which I knew three group and my name is Katherine Breslin I've been working in voice technology not quite as long as Kate but I've also been working across a broad spectrum of a lot of these technologies that verina's been talking about I used to lead the Alexa AI team in Cambridge for Amazon and recently I left there to work at a company called cobalt speech where we build custom voice and language technology for our clients and so it's been really exciting over the past maybe ten years to see the growth of this technology Siri I think was launched in 2011 and Alexa in 2014 so well this is all commonplace you have to remember that actually this virtual assistant technology is still really new and we're talking today a little bit about what's beyond virtual assistants what's happening in the future so I wanted to start with asking grace a little bit because I think the BBC are perhaps one of the largest organizations in the UK who are driving voice technology for words right now and with the user facing customer-facing applications and so I really wanted to get your opinion on how are you using voice technology at the BTC now and what are people doing really interesting so we think we are the biggest actually we're proud of that yeah we have just under a million people who use our Alexa skill we can get data from and he is just quite boring actually they're really using it to listen to the radio because it's easier to say play Radio 4 than to walk over and switch the dial and I think that we are seeing at the BBC that transactional tasks are being used on these devices stream audio stream music timers just those things that there's some friction if you have to touch the thing and it's easier to talk to but the conversation you have it is very very simple as soon as you start to try and do something more complicated with one of these voice assistants as they exist at the moment it gets very mo much more tricky because we have not trained our audiences for exactly what to say and as a member of my team that uses the phrase often when you're using one of these devices you feel I have crap wizard who don't know what spell to say I think we're deeply in the crap wizard phase of our voice technology journey and we are working really really hard to you both work out strategies to solve that in the near term so give consumers really clear direction about how they can get what they want out of these machines and anyone who hasn't used our BBC children's skill and who's got small people in their house please do submit for example about how our UX teams have built in the right commands into an experience that feels very natural to allow people to use it and at the same time we're working really hard on the more medium and long-term future stuff that says how can clever work the Varina and others are doing around NLP and using our training data sets make that spirits much more conversational and much more human and we really think that's what the future's ellaby so we want to move from a place from these transactional interactions that people I guess are doing those everyday use from these things you tend to use it more than once a week and we think that was really interesting as the uptake is very very quick so we think that the trajectory of uptake of always assistance is about the same as the smartphone which is about to quickly turn yes and you mentioned the CVB's app which I know your team recently won a Webby Award for so congratulations on the BBC so like I said there's been a huge uptick in this technology in the past ten years or so and Siri you look back was only launched publicly in 2011 I think it was 2010 and on the iPhone in 2011 so I guess the the big killer question is what are we working on as the next generation of technology that's going to make it into into future products so Kate maybe you're working on some of the future directions yes we're doing it Cambridge is about exporting the data speech is a phenomenally rich medium if I say to you please nicely I said you please there's a very different message and that one word I've conveyed to you a tremendous amount of information and we're just not using it right now you'll see everybody will talk if they talk about speech they say we do the speech recognition we throw so much away you'll also hear it when when you get it back to you we throw it away then we'd give you a nice neutral voice to listen to if we're gonna have real conversation and we need to understand what somebody asking about what's their emotional state why are they doing are they getting frustrated we need to take into account their prosody that thoughts context and so that's yeah and but we can do that by learning more from the data extract him more from the data and that's have you seen that in your work with the elect surprise as well have you looked at in any detailer anything beyond that just the text of what people are talking about in turn yes we only actually got the text transcripts from you so we didn't have access to intonation what I did notice though is that what user got a lot of value out was a real conversation meaning not only having a one-shot request and then you get back another you know short utterance and then you're sort of left hanging in the air thinking okay what can I say next but the system actually continuing to converse with you so the idea we had was it's like sitting in a pub with somebody who has read all of the koopida who knows really interesting facts and who knows about the news and you say something and the other opponent about you you're the person you're talking to might come up with a really interesting bit of information you didn't know before so this sort of proactiveness I think we are currently lacking in voice assistance so they're very passive waiting for you to assure command and then responding with a very short answer and I think the future is really moving away from this one-shot interactions I think I think that's right and if you stop to think about multi-modality as well rather than just speaking to a speaker in the corner of room you can really see the house back and evolve and half of companies like the BBC how getting that recommended next piece of content for getting that conversation right it's going to be so crucial because that becomes the way that you inform educate entertain in our case how you sell products in the cases of other businesses and it becomes from beyond the technology as I understand it we the same if you're talking to a machine or if you're looking at a screen and actually the way that online experiences are going to evolve this technology is really so crucial and so do you see I see a lot of people coming to talk with us from different areas from healthcare from financial from education all of these these different industries are looking into ways to use voice technology so as our systems get more proactive more conversational what sort of new application areas do you see opening up for to build today maybe Kate and so on the other medical side I think there's a lot obviously there issues of privacy is a bit in terms of providing people with feedback with you know healthcare in the home if you can interact partly multimodal after you have a conversation for the lonely in the elderly much more than right now everything is very static it's one way and the educational side we're also interested in helping people learn languages and and just getting someone to read a sentence or will make one response to a prompt you need to have a conversation to really judges can somebody actually communicate by speech so you've done a lot of work into getting people to learn English we have voice technologies so how do you see that playing out in the future well very much so we're only fun to work towards conversations say that we want to at the moment we can assess someone's speaking skill but we can't really set you know but if they're an industry I don't work they need to actually communicate and communicate is a conversation so we want to be able to have their voice application that allows them to actually to carry on the conversation beyond a simple yes/no your response do you think conversation is a key to language learning which really this will evolve in the future yes absolutely we'll get much better at doing this because I think it's we've talked with language learning and if you're doing it online obviously you need some technology in there to be able to scale it up to lots of users otherwise you're limited you have to have a teacher listen to each individual student which is not sustainable if you've got all these people who want to learn different kinds of languages that's right is a verb over one and a half billion people in English I said we can't sustain that just for human self exactly you need to be some technology in there to help them help them along so what are you looking at at the BBC is that the future application areas um so we're really thinking about how we can do our public mission through informing education say as in the UK and globally we currently have a digital relationship with more people around the globe for Twitter we have an enormous news particularly heritage in news and I think as you start to layer on AI in conversation to that market we know how difficult that is right we know about fake news bubbles we understand how the bad actors there can start to really start to influence a society in ways that we're not very comfortable with so with the BBC are really trying to I think take take back control not to use the rather contested phrase but really to say okay how can we make this technology work for us and work for our purposes and how can we make sure that we understand where in the value chain the value really lies and where the control lies because what we're finding is that because the friction in building these conversations are so high the it's very easy for people to go to the big America I mean the US companies which have benefited many in the room and say and they say we'll do it for you and we see a lot of Shuja kind of come societal threat to that and so in the BBC we're really thinking about how can we take where the value lies in our business which is actually an amazing training data set when you think about nearly a hundred years audio archive for example and start to think how can we turn that into it object-based audio and video type nest experience and then you get into it really really interesting consumer proposition now there are lots of problems here which I hope there are many companies at the room that can help us solve but if you can imagine how many conversation with the BBC in that way and using our brand and then allowing us to work with partners to bring in different sources and different ideas but always with that I suppose the public service at the heart so we're not deliberately trying to send each other those bubble to make money we think that's a really interesting Avenue to explore and as with you we're looking at the markets where this is going to allow us to learn the most most quickly so you know language learning but at the moment it were being really honest right we don't know what's gonna land at these spaces yet um you know we think our children's feel is amazing and it is amazing but in terms of usage it's still fairly load because we're still at the beginning people are still using this a very transactional reasons and we haven't quite found the killer application yet so technology's just cashing up really with the vision so talking about the technology I guess a lot of these systems underlying them they're data driven they use machine learning technology to do the speech to do the language to do the dialogue so how far is machine learning gonna take us towards this goal of proactive and more conversational technology I know you touched on it a little bit in your yeah I think that's the main research question of many many years and I think there's still many many more years to come to actually answer this question as I said it depends what you want to achieve there is obviously a lot of room for machine learning when you do natural language understanding which was one of the most crucial components in your system right to understand what these the string of words actually means in terms of a meaning representation then there's obviously speech recognition which is the first sort of module which has made tremendous progress using machine learning and you know we've got especially big companies half loads of data where they now can train their model so on and then there's obviously the bit in the middle which I've worked on most of my academic life is the the response generations of what to say next right and this is a bit more tricky as you've seen in my talk because this is a very complex question and often we as humans don't know what's the correct response right so there's another issue if you learn from human data you might not learn anything which is optimal in that sense so that's why reinforcement learning where you optimize towards a goal is promising if you for example want to build a system for Pizza ordering right or planning a night out so you've got a clear goal where you're working towards and also the social aspect of communication you can learn some social behavior from data for example turn-taking is a great example so turn-taking is knowing when the other person stops and when I'm supposed to speak which is really difficult and depends on lots of subtle clues in the environment so this is always a great example where we can learn from multimodal data so lots of turn-taking comes from you know visual clues where do I look for gestures and do make what's my intonation do I pause so again the sort of wealth of information is very hard to actually formalize when you use rules whereas with machine learning you can learn this type of behavior quite easily from not easily but you can learn it from data I think that's innate in there about how when you're doing a transaction the rules are quite easy but when you're doing conversation they're very hard and who writes those rules and who optimize what a good outcome is in that conversation I think is a problem we haven't even opened up the box so frankly and I think if I was to guess I would say is where plurality is to be really important if you've got a single provider and making those rules and unta - no that's context that's an interesting place to be the more that we can add for allottee into this market and then allow consumer choice allow things to learn off different outcomes the better which is difficulties things are expensive and hard to build yep I think so it sounds like reinforcement learning is a great direction to take the research in for conversation because if you've got the target well goal-directed conversation not necessarily the social conversation which I think when I was working at Alexa quite a lot of the interactions with Alexa are social a surprising number of people just want to talk to a system I get a sensible response bank they don't care about achieving a goal necessarily so that's something which also really surprised me so most of my them in life ever entire space dialogues because I thought right that's what people want to do within systems and then entering the Amazon Alexa challenge I was surprised how many people want to chat were these systems which obviously requires a completely different set of skills and mechanisms how you drive the conversation forward what sort of databases you're operating on when you operate in a task based system you have a very limited set of entities you're going to talk about that say you want to book a restaurant or you both want to book a train ticket when you have social conversation you could be talking about you know last weekend where you took your kids to the zoo you - you know philosophical issues about towards politics everything so that's where it becomes a really really hard problem and this sounds highly relevant to learning a foreign language as well because you want people to be able to converse socially as well as to achieve stuff yeah I mean actually one of the things I'll say cute of the suit if I'm talking with the cultural aspect we're saying that there's you know we don't want the systems to just learn one way to converse but actually the tea box itself is a great one that that chatbot had been running in and in Japan and China for about 18 months they like technology there they think it's nice they want to be friendly to the robots they took a pot they did not try and break it they bring it over here Brits and the Americans what was it twenty-four hours they had broken it we'd shown about it but that just shows the cultural differences that you do have to bear in mind through any of these systems working worldwide we need to sort of bear that in mind some of this we can learn from data but some of this we also need sort of human intervention to sort of give us provide the context provide background information I don't think we're looking for technology to solve human problems actually so somebody asked me that question about what have I left my children interact with the lexer and of course I do but I make them say please and thank you if I don't attend the CBBC for whatever they're expecting to get and we can't delegate these cultural norms to technology companies I don't think at the end of the day you have to just be human we touched a little bit on the problems of data use data hungry algorithms that are using data and if it's poor quality you're trying to break the box then the algorithms just just go down so there are some great data sources out there like the elect surprise data and BBC's archives but where are your challenges with obtaining the right kinds of data and the right kinds of unbiased data as so I think for social interaction we're still looking for a good data set for task based interaction one of the challenges is that if you train a system you want in domain data meaning if you want to learn how to talk about restaurants you need a whole corpus of people talking about restaurants which is often hard to get so every time you want to learn a new system for a new domain you collect the first pane sacredly collect your data set and then you learn on your data set which might actually not be such a great time-saver so what mechanisms we investigate at the moment as things like transfer learning so you imagine you've got a domain where you've got a big data set let's say people talking about pizza ordering and then you want to learn behavior where you talk about ordering let's say curry which isn't that different right so you can actually transfer behavior from one domain to the next domain or is the one an idea which we're pursuing is that there's some behavior which was actually completely domain independent I was talking about about turn-taking before you know how to turn type independent on whether you talk about pizza curry or booking a restaurant so again that's something which can actually transfer from one domain to the next yeah I think I'd say one of the issues we've dated a big issue now is of course people's concern about privacy you know they a number of people have sort of said to me oh well you know I was talking about something my friend had their mobile phone running and the next thing I know I'm seen adverts coming up my facebook for something I've not looked for you know and so there is this question of how much is listening but on the other hand as the generators of the technology we need data so this is actually over the years being one of our biggest challenge in deploying technology has been this battle of we need data to improve the systems we're not going to be able to recognize the Scottish people in the lifts if we only have data collected in the Southeast of England so but people obviously more and more concerned about privacy GDP our answers this big question now people start to look at how can they access your data without without knowing it's you without trying to strip out some of the identifying factors and I think this is a big know obviously BBC you're rich but you're rich in terms of data your own data but in going forward this is gonna this is one of the major challenges for speech applications is the concern around privacy I think that's massively true we're rich in tones abroad cars data but not funny secrets a us not that representative I know that's a certain type of the Queen's English going back quite a while despite the very important things we're doing in the car in the current era I think there's there have to be other solutions to that problem because I think the the hunger for data is not going away and I think what we get the PUC of thinking a lot about is how do you give consumers an audience more agency and who uses that data and how they use that data and so they understand the transactional nature of what they're giving and getting in return and I think what if we crack that you start I hope open up big data sets for why the consumer base to to research off because there are are companies out there that have these data sets question is to consumers know that that's not like handing over when they serve as T's and C's no thank you so you know in terms of pockets 2020 that's really the question that we're ready interested in discussing which is what does the next phase of GDP are data Portability and data agency means for how we develop these tools and these technologies going forward because we're just a tax about the moment so ethics and data privacy is something that's really come in a lot over the past couple of years to see a lot more discussions about it now than I did back then because we started to realize the impact of all these systems on society and how they how people react to them it's not necessarily how the developers of the technology anticipate that people are going to react to them so have you got thoughts about sort of concrete ways to address data privacy issues and these ethical concerns that people might have in so I know we have a live research project at the moment that is trying to make a physical manifestation the people's data so put a data box I believe there'll be a blog going live today evidence to look it up and of course it doesn't have to be a physical manifestation all this data sits on the cloud but by giving people a physical object they keep with the home and said this is the guardian of your data we're trying to research how their willingness to give and take from that pool of expectations and then the value exchange changes that's just very much the beginning at the moment is based off data sets that we own around you know consumption data audio and video we're really interested in expanding and out to understand what does that mean for financial data what does that mean for travel data etc and how can we create an ecosystem here where you have both agency but value in a in a physical rodimus for a performer yeah I think there's always a bit of a give and take between you know the user and then the company which actually gets there which actually gets their data so a lot about it's also about educating the user what happens to their data when I look at the Amazon and exa data which we got which is very much restricted to us as a university and we have very strict advice from Amazon not to share this data because they have you know issues about consumer privacy and they take it very serious on the other hand looking at the states I do think that users don't really know that their data actually gets hosted and looked at and retained I'm just looking at what people say to their today Alexis at home sometimes think well you were actually warned that you talked to a university boss and you still say these things so I think there's a bit of an education to be done similar to nowadays children at school actually get taught how to use social media you know what to post on social media but not to post in socially that what gets used what what the data gets used for and other privacy settings so for example Amazon released the function where you can tell Alexa to delete all your data from this day or delete what you've just said I don't think a lot of people are aware that these options exist and then again it's also up to the companies to actually advertise and these options and make them available to the user so I think there's some some public education to be done and even going into schools and talking to people about these things so yeah I've been into schools and talk to children and they're always very interested in these issues and they're very interested to learn that technology is not as foolproof as its are things that there is and they pick up on these ideas that there are people behind the technology building it and there are assumptions built in that are necessarily transparent when you're using it so ideas it's a good point that going into schools and teaching our children it's one way to do this so we've got a couple minutes left I think of our panel so I wanted to finish on looking towards the future so as I said at the beginning some of this technology is still is I mean there has been a long thread of research in voice and language technology for many years but it's really coming to the mainstream in the past ten years or so and so if we look maybe five or ten years into the future other things that you think would exist then which don't exist now what what would you love to see in the future say one of the things I'd love to see is some new what's requests me they said they wanted a speech to speech translation device but not not for the major languages in the world but for them to go to Africa and have a conversation with someone in Africa and one of the big difficulties there has been that we don't have translation from languages to the African languages but maybe we do have something in between and I think there's exciting technology that maybe it not be still maybe not there in five years but certainly ten years I think we'll see that will be much more connected whether it's through speech to speech translation through taking audio and video that's that's oh about Ebola in I don't know tomorrow can tell you and just gathering that data together in whatever language you need it to be sound exciting I think we um there's an idea of and anticipation and conversation that sort of coming to at the moment you haven't talked about the fact that you have to speak to one of these things to get something out of it in the first there's a really interesting thing about if you build it into our lives and have it speak to us and remind us of things and you think about societal it support for that in education in care homes in medication you understand if somebody can support and actually assist my life as well as taking instruction is a really interesting yeah I totally agree with you I think assistance is key so what I really want as a secretary which manages my life for me which knows me really well which organizes my new things which manages my phone calls which summarizes my emails and tells me what's on my schedule for today and provides me a nice summary of the news which I'm actually interested in and I think that's totally reachable within the next five years that we will all have those private secretary on our phones or in our smart speakers so so I think that's something we currently working towards - and there's still a few clinches in terms of you know how these systems are actually working in terms of the fluency but especially the function of them operating over large datasets we've talked a lot about how they learn from large data sets but I think one of their benefits is that there are filters excuse me a filter sitting on top of large data sets where they're able to summarize data for us just you know imagine your inbox at the start of a day if they could point out to you you know all of these emails are actually not important and here's a short summary of all the emails which are important to you that would be a big big help similar news politics so that's where I see the real value in these voices systems their four-day week coming on that would be great sounds very exciting and then that means we will so integrate this technology together we'll be able to link it up with different aspects of our lives and to be able to use voice to just do things more effectively in the future which again you know ethical aspects become even more prominent a few half this vision and mind you want to make sure that it's not going to be creepy and finding all sorts of things and sharing these things which is definitely a challenge to to not overreach I think and to make sure you're building building responsibly so well thank you very much this is really interesting and we're at the end of our slot now I think we'll be hanging around this I meet the speaker area outside somewhere maybe Libby can help point us in the direction yes so thank you very much thank you very much you 