 [Music] during today's session we're gonna talk a little bit about the business drivers of why Discover Financial chose to pursue a virtual assistant we used to mitigate negative perception of AI and enterprises and the process discover developed for building and deploying virtual agents as well as ideas of metrics that should be captured to ensure virtual assistants continue to be adding value to your organization so a little bit about discover discover was actually my first customer I worked with when I came to Google about fourteen months ago and I walked into the meeting after they had done a bake-off for NLP it's tools to help with a virtual assistant and I walked in and they seemed really smart and I was like oh my gosh like if all customers are this easy or this smart my whole job is going to be like the easiest job in the world and it turns out that wasn't entirely true but working with Discover has been really fantastic because they have they use really intentional decisions and careful processes for like enabling technology that enhances the customer experience across their enterprise as well as with their external customers and they are also pushing boundaries in in stretching the capabilities of what the virtual assistant and dialogue flow can do with innovation innovative approaches to testing metrics and deploying the agents across the enterprise so I'd like to welcome up price to talk about it he's a business a senior business manager for digital automation thanks Rachel so as she said I'm price fetter I lead automation and our digital servicing channels here at discover quick obligatory legal disclaimer there we go so a lot of people think of discover is mainly just a credit card company but we also offer a slew of banking products checking savings savings accounts too personal with student loans but really our goal is to help people achieve a brighter financially future and really that means that we put the customer first in everything we do from the processes we have in-house to the products we deliver to our customers it's a little bit more about us were available in 190 plus countries we have 15 Network partners around the globe and China India Japan Africa South America just a name few but we have over a hundred million touch points our interactions with our customers to service their accounts annually which means and that's supported by over 8,000 of our customer service experts in the digital space specifically we've had 12 years of experience with messaging with our customer service experts and as that channel was matured we've seen explosive growth and just over the past over the next five years we're expecting 60 percent year-over-year growth in those digital channels so really we're looking for ways to support that and so we came to the conclusion that we needed a virtual assistant but we don't think of it as a cost-cutting measure per se but more of a way to deliver a service that our customers really are looking for our customers really want something that they can get answers to their questions as fast and easy as evenly as possible with every brand not only discover so that was the original I guess driver behind why we decided to go with a virtual assistant but not only that we're seeing some really great I guess lifts with our agents they're able to handle the more emotive complex conversations now which enables us to or enables them to really have a better interaction and touch point with our customers and then finally because of this we're able to kind of deliver new capabilities for the channel things that we were originally thinking about how did we get there many people within our enterprise have a perception of AI you know Holly you can thank Hollywood for terminator for Robocop for how nine thousand you can thank PR disasters from for Twitter bots and stuff and that's really what people think about when a eye comes to comes to mind what they don't think about is what they interact with on a day-to-day basis that is AI spam filters voice assistants Maps you know and so we really had to ground them and what was reality versus what they perceived a eye to be and we also had to make them more comfortable that we were actually putting the customer first and thinking about how we introduced AI to to discovered so for example we its disclosed if you will that our customer is interacting with the virtual assistant every time and then if if we do end up having to transfer that conversation over to a customer service expert we tell them as well so it's a transparent experience for our customers when when we roll out or rolled out the virtual assistant though we had to really think about how this would affect our customers and we also had to think about the best way to define value for each of the intents or inquiry types so we looked at the volume and our channels for instance to understand what the the most high-traffic intents were we once those were defined we went and define kind of a happy path for the customer looked at areas where that conversation might break and really figure out the best way to communicate with our customers for each of these intents or inquiry types once once you know we were able to deploy or develop and deploy an intent we still have to make sure that we're legally compliant we're you know checking all the boxes with risk etc but then once we launch we we don't just leave it and walk away where we're in the channel constantly monitoring our customers interactions with our virtual assistant and making sure if there's better ways to communicate with the customers better ways to improve the kind of flow of the conversation ways to improve our models by introducing new train phrases etc and then oh and now I'm going to show you a quick demo of just a sample interaction with what we've been able to develop over the past year it's just going to show a sample interaction with the customer on our website and then moving to the mobile device while maintaining that same conversation across channels and then transferring over to an agent when the conversation gets a little more complex [Music] [Music] so you know so we don't build in a delay or anything any fake typing bubbles for the interaction with our virtual assistant that's really to show that we're not trying to deceive or you know make sure our customers aware that they're actually interacting with a virtual assistant with that I'm gonna turn it over to John to kind of talk about how we utilize dialog flow and what we've built on top of it thanks grace everyone John Coyne I'm a software engineer at discover as Rachel mentioned early last year we performed a thorough evaluation of different LP providers or we ultimately decided to go with dialog field to implement our virtual assistant we then spent the remainder of the year building out the platform and the necessary automated processes to deploy our system so today I'm going to cover some of the building blocks that you can use and some of the performance measurement tools to constantly build and deploy a virtual assistant so during our evaluation period our primary goal was to measure the performance of intent detection so what's an intent quite simply a user question or intention it really it's the first and the key step to building a virtual assistant if you break down a virtual assistant into two high level components its detecting what the user wants and helping them fulfill that intent or what's known as in fulfillment now we actually have a separate team that manages more of the fulfillment side of things and that's more procedural nature you know where you're basically going out to fetch user data or performing an action on half of the user where the intent detection side is where more of the AI machine learning comes into play and that's what my team focuses on and that's gonna be really the theme around my talk today so for those who aren't familiar with dialog flow let me explain some of the basics a dialog flow agent is a virtual representation of your logic representation of a virtual assistant to your agent you add a number of intense and then to each intent you add a set of training phrases the training phrases are then basically used to customize your model it's really built on top of Google's underlying and allyou models they're built from years of experience so your training phrases really should include examples of how a customer might phrase a specific question for example here I have a tank called available credit where a customer's asking their tenth would be what inquiring about their available credit to spend is what it is and you can get some of this data from actual customer messages that you would either sanitize or economize as part of your input to this one of the important features of dialogue foe that we like this was something called confidence essentially which with each intent detection that dialogue flow performs it returns you back a score to indicate how confident was and then intended just detected and this was really important to us to be able to make intelligent decisions about our virtual assistant replies dialogue flow allows you to set a minimum threshold that if this confidence score does not meet that threshold they can do one of two things return you back a fallback intent or no intent at all a fallback intent could be something just like a clarifying statement asking the user to reword their question but this is something that we decided not to implement because really it was more important for us to be able to get it right and try to automate it and if you actually noticed here's something that we do is we set our minimum threshold extremely low just 10% now it doesn't mean that we're actually sending the replies back to users and all the scenarios but what we're doing is we're collecting data around on the intent detection process so we can make more informed decisions about how we want to really send our replies back and I'll touch that on this a little bit more later so the testing process that we established during our evaluation period is something that we've actually built into our daily process as we're adding new intents and we're updating existing ones to start off with you get to scour for real data from customers whether it be from existing IVR channel chat or it could even be inbound email Channel but you might really have to spend some time to actually get good labeled data so here's a customer message and here's what intent you expect to get back and something to notice you want to make sure that your training data that you use for the training phases is separate from your testing data because you don't want your results become biased so when you have your labeled data with a message in an intent you can send it through the dialog flows API to detect the intent you get back a name of an intent along with a confidence score and then from there you compare the detected and expected intent you can generate a set of core metrics now we do this on a per intent basis essentially for each intent that we have defined we go through and calculate each one of these metrics so giving a couple examples if a customer said why is my credit showing as zero dollars if we detected this as the intent available credit and we expected to get double credit then while we're calculating available credit metrics we consider this a true positive however if we're calculating the metrics for another intent called payment posting we consider this a true negative because we did not expect to get content payment posting and we did not get back through content in a posting and that's the definition of what is your negative is for the purposes of our individual intent metrics this is not as important but we still notate it the true negative bit is let's say for another message of customer said it shows my payment posted but I have no credit available just wondering it when it will be available if dialogue flow detected this as payment posting but we expect it to get the intent available credit and while we're calculating available credit metrics we consider this a false and I gave the conversely for payment posting we consider this a false positive so once we're done with this process we then calculate a set of more advanced metrics that can give us some better insights first one is known as precision or positive predictive value we can use this to determine if we have problems with false positive and really it's defined as the total number of tests where a specific intent was detected for example available credit what percentage of those were correct another intent known as recall or sensitivity or true positive rate can be defined as the total number of tests where a specific intent was expected for example available credit what percentage of those were detected correctly as available credit and this will let us know if our intent is to narrowly defined missing messages that it's intended to pick up so using our simple data set from the previous slide we would end up with a precision of 100% but a recall of only 50% for available credit so really these two metrics are complementary for the purposes of measuring performance you know precision can be 100 percent with only one true positive if we had no false positives but if recall is low for the same intent there really means it's missing almost all messages entirely it doesn't really provide much value recently we've actually started calculating a new metric called f1 score which is the harmonic average of both precision and recall as a number of intents has grown and became more cumbersome to look at so many different metrics so the f1 score provides a single single number that we can look at to look at our intent performance so comparing a couple intents seems easy enough right the lab is when you scale up to 10 50 100 and tenths this is where a tool known as a confusion matrix can really come in handy using the output data from our test process we can generate essentially a heat map of the intent detection performance we mapped the detected intent along the rows and the expected intent in the columns and in each cell is the percentage of times where those intents meet so if you see the dark line from the top left tag on down the middle to the bottom right this is where the detected and the expected intense match and this is what we want to see basically the lighter shade means less confusion or less times they meet and the darker shade is we're going to see in the middle so anytime we see a darker shade outside of that middle is where we have areas of opportunity so for example here I've highlighted an intent called unrecognized transaction has been detected 19% of the time and we really expect to get pending transaction so what can we do when we see this there's a few different things one of them is we need to go down into the training phrases for each of these intents look for similarities that we can try to eliminate the second thing that we could try to do is actually just the confidence threshold perhaps if we increased it they're gonna be less false positives for unrecognized transaction lastly you might just need to combine these two intents into a single intent and I build the conversation flows out to direct users on the right path so now I'll touch a little bit on a dialogue flow agents that we use similar to common software engineering practices where you have different development tests you know production environments we do a similar structure for our dialogue flow agents and our development and training environment is where all of our updates happen manual either via the dialogue flow console or via some processes that we built out the API calls that they provide to update the train phrases when we're ready to promote to the next environment we can execute a deployment pipeline that exports from development to our staging environment here we can perform acceptance testing and run some aggression tests for rate confident enough to deploy to production where we actually extract out the entire configuration into an artifact that we that we sent into artifact repository and we executed another pipeline to deploy that into our production environment there's never any manual updates happening into production it's all through processes that are automated being a finance institution we're highly regulated on being having auditable processes that are repeatable is really important so expanding a little bit upon the pipeline I just talked about this is something that our business product owners can initiate and manage themselves it runs through all the tests in the metric generation that I've talked about and it compares the metrics against the prior version so ya can actually see where things have improved or may you may have introduced some issues and then it actually generates a summary report for you that will highlight the changes for you instead of having to go search for them so while you know engineering team has built out this process it's something that a business or product owner can be easily execute and interpret the results themselves so now I'd like to give a quick demo of this process and full disclosure here this is a pre-recorded demo I wanted to be risk averse and also cut out a couple minutes from the middle so right now I'm logged into the dialog flow web console here updating our training agent and I'm editing the intent available credit here's the training free section so what I'm actually gonna do here is the phrase that we saw early my example that got detected as payment posting even though I'm going against my own advice I'm gonna go ahead and add this as a training phrase knowing that it's in a testing set and I should see performance improvement I would hope right so let's go ahead and add that we'll save the changes I'm gonna hop over to another tab here this is actually an internal web tool that we've built out for a business product owners to help manage our virtual assistant they can do a number of things from this from this tool and one of them is actually run that deployment pipeline oops so here we're gonna go ahead and select the source as the training agent and we're gonna deploy that to our staging agent and once we kick off the deployment here we're get a message saying the our execute our job has started I'm gonna hop over to our continuous integration server and just go ahead and explain some of the steps that are going on here so one of the first things that we do is we export the source agent dialog flow provides an API we can actually extract the entire configuration into a zip so we do that for the source and the target and then we perform some validation tests this is mostly just to look at the content dialog provides a capability to set up like a custom payload for your responses that we use like dynamic slots for you know user data so we're just doing some skiing the validation air to make sure it's well-formed the next thing that we do is actually generate a difference report so basically any intents that were added anything we're training phrases were updated or any content that's changed we're gonna list out all the changes that have happened sometimes if there's multiple people that are updating the agent we want to make sure that we list out all the changes and we have that you know documented next thing we do is think about this like unit tests and software engineering certain phrases we want to make sure that are always detected as specific intents so we make sure that those those paths if not gonna fail the deployment next thing that we do is run through all the tests and metrics that I've talked about and then we actually perform a threshold validation making sure that our metrics at least made a minimum standard or us will fail the deployment so after that's done we get a slack notification to our team channel here our product owners can go ahead and check out the results we send a link that they can go ahead and download and we actually require an approval you know somebody obviously we want them to check the results out first before they approve the actual deployment so here I'm gonna go download our difference report and hopefully that we see just one chain one change was made and here we can see intent changed available credit and here's the training phase that I added so that's good now we'll go into our test evidence floor here we can see there's a confusion matrix there's the test metrics and then the raw test results every single message in what it was detected as if we want to investigate it not that we do it every time but it's there so I may go ahead and download the summary report and here we can see ok the precision increased for payment posting that's good less less false positives there it looks like the precision decreased for a couple of other intents that I wasn't expecting the recall did go up for available credit so that's good and true true positives went up there but the recall actually went down for a number of other intents so it's pretty interesting really kind of what this highlights is you know machine learning AI is not really an exact science you know you can't always expect you know something's going to work out the way it is and just having a process like this that we can automate really helps us to enable to do this at scale all right so now that we've deployed to production how do we monitor our performance and continue to improve it so within our whip internal web tool we've actually built a process where we can view the messages and what they were detected is we can go ahead and annotate those as either correct or incorrect and if they were wrong what was the right intent this allows us to do a couple different things one of them is actually generate the performance metrics of our real production model right it's one thing to be able to look at in a test environment saying okay this is how we should do but it's much more valuable to see how you're actually doing in production the second thing that that we do is actually create an automated process where it can export some of these messages into our test environment let's say you know messages was detected at a very low confidence special but it was right that was the correct intent we can go ahead and try to add that to our development environment to see how it improves the performance lastly we can generate something that's known as an ROC curve here we plot the false positive rate along the x-axis the true positive rate along the y-axis for varying confidence thresholds so for example here I've highlighted at an 80% confidence threshold minimum threshold I can expect to get about a three point nine percent false positive rate and a four eighty two point three percent true positive rate so circling back to my previous slide and confidence but if we had our minimum threshold say eighty percent we wouldn't be able to collect any of this data to the right so this by by setting our confidence low collecting the data we can analyze it and make a more informed decision about how we want to set our confidence thresholds otherwise you're just taking a guess so talking a little bit about how we utilize this data in production our high level processes basically when we receive an incoming messages we first go to a dialogue flow detect the intent and get back a confidence score part of our business logic is then one looking to see if we have that intent enabled and two if it meets the minimum confidence threshold we enable the company stressful to be set on a per intent basis if one's not set we use a global default so now you might be asking why would you have an intent enable or disable I didn't have it in your dialogue flow agent and there's a number different reasons for this one of them is you know if you have something deployed and you see an issue with it being able to quickly turn it off is you know something that is useful to us you could say why not just delete the intent of dialogue flow but as we've seen making model making updates to your model can have unintended consequences second thing that allows us to do is actually deploy new intents to smaller number of channels we can actually control these settings at a per channel basis so we have a channel only we're only employees can access so sometimes we'll beta test a new intent in a channel where only employees will see it before rolling it out to them to the broader public and the last thing that we can actually do is define intents that were either not ready to fulfill yet or we just don't have an entire to fulfill you know this can deflect away from you know giving incorrect responses one example might be for an intent increasing are increasing the users credit limit let's say that somebody comes in and we see them ask I want to decrease my credit limit I maybe this isn't a common request so if this was detected as the increased credit limit intent you know it's gonna end up with a bad user experience so by quickly defining a new intent to decrease credit limit we can go ahead and get that detected but then routed to an agent to handle it so it has a better customer experience and with that I'll go ahead and turn over the place they're bad things up here so yeah just some of our key takeaway some of our learnings over the past year when we started this process that was really we needed to tackle kind of the preconceived notions that people think of when a eye is brought brought to bear so tackle us head-on bring examples of what AI is in their everyday lives and that'll really help people understand that it's not just you know monster under the bed kind of thing when we defined our processes for taking an intent and really defining the customer value the value for us as a business and all the way through production into post-production and you know being able to train and improve that experience post-launch we really didn't reinvent the wheel there we leaned on existing processes we use metrics from other channels that when we were talking about the virtual assistant it wasn't confusing everybody in the room big for us be customer focused we in John mentioned this earlier were it able to introduce new intents that were not necessarily fulfilling to get the customer to customer service expert as fast as possible and get them stuck in this loop of did you mean this did you mean that just really you know trying to provide the best customer experience possible is really what has helped us through this process and then the last two kind of go together enabling the business to get the insights and the data they need to deploy this at scale using it to deploy new intents make changes on the fly when it comes to confidence thresholds that we use changing the kind of language that the virtual assistant uses and that they the customer sees when they're communicating with a virtual assistant is really important to us and so being able to do that at scale is really crucial for us [Music] 