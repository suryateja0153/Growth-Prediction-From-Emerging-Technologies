 [Music] hello and welcome to the conversational ai session at microsoft ignite my name is darren jefford i'm a principal group program manager for the conversational ai team uh it's great to have you here today so let's jump straight into the agenda we've only got a short session today so the agenda we're going to cover an introduction to the bot framework for those of you who are not so familiar also cover some of them the momentum with customers uh we'll go through a summary of what's new and then get straight into a composer demo where we'll show an end-to-end demo of building uh conversational experiences plugging in skills move to canvases where we'll show whatsapp and some speech capabilities i'll show how easy it is to bring that to life and then move into a call to action so let's get started so where i always start these conversations is really with this diagram across the bottom we have the bot framework this provides the software development kit the building blocks that everything is built on the sdk allows you to build conversational experiences that prompt for questions they have memory the ability to context switch dialogue management and so on we also have the composer tool which is our design tool bringing together a lot of the tools to allow you to design dialogues and get a build deploy and test that again you'll see a lot of composer today on top of that we have the azure bot service so once you've built your conversation experience you need to surface it and connect it to end users and we have a broad range of channels which means you can write your experience once and then connect it to these channels so for an enterprise connecting it to teams and web chat will make a lot of sense for something that's consumer facing b2c you may want to make available on your website in your mobile app you may want to be available as an alexa skill on whatsapp or facebook messenger you can do all of those things with the bot service this right once make it available everywhere it's a really important capability we then have a range of ai cognitive services these um building blocks democratized ai the key one being language the ability to take a question from a user and break it down understand what the user wants to do the intent as well as pull out key bits of data so i say hey i'd like to book a meeting with lily a week on wednesday between three and four it will understand i want to book a meeting it will also identify the person's name but also then convert a week on wednesday between four and five into a date time meaning you don't have to worry about that complexity and we have a number of starter kits for language models we have speech capabilities which compose really well together uh speech to text text-to-speech with very natural uh voices again you'll you will touch on that a bit later on computer vision you could upload a a picture of a receipt or a form and extract information so lots of possibilities there and again you can plug in any of your own capabilities alongside these as well we then have the virtual assistant on top which brings this together makes it easier to create a more sophisticated assistant experience allow you to plug in skills for that enterprise kind of parent child bot type pattern that's very popular deal with security and also provide some base capabilities like personality and q a and so on and the bot framework stack that you see here actually powers a number of things across microsoft you know the enterprise assistant cortana integrated with office power virtual agents which is our citizen developer focus tool there are other sessions on this at the event is built on both framework and works together really well and as well as helping power experiences in teams so the whole platform you know across microsoft in terms of momentum um we've seen fantastic growth you know over 2.5 billion monthly messages over 528 000 registered developers and those numbers are increasing you know um constantly we've seen through covid lots of organizations especially healthcare like cdc and providence standing up symptom checkers questions and answer type experiences as well as many customers you know scaling up to address large increases in incoming requests from uh from customers so scaling that self-service thing up has been a been a recurring theme we've also seen great growth across microsoft with power virtual agents health bot and teams so it's an exciting time on the customer side you know bbc as we highlighted at the build event have built a digital assistant to engage with uh users in the uk increasingly around the world unlocking their content from podcasts and media and this is had tight integration with our speech capabilities where we have a custom wake word where you can wake up the experience you can talk to it and bbc actually have their own um customized voice tailored to their brand as part of this overarching conversation experience a really nice experience uh walgreens healthbot sort of symptom type checking on their website along with q a experiences uh hop tea for around site management voice acronyms and things a complex problem space has been a great partnership there also with uh new york city around experiences for parents uh to engage and get information around uh kind of aftercare kind of programs citizen engagement aberdeen city council financial services with lowell around deploying some of the cognitive services to the edge so fantastic momentum great partnerships and we continue uh to work with these customers and more quick summary of what's new with the bold framework we recently did the 4.10 release of the software development kit there's been an update to composer has now has q a support you'll see a lot of this later on as well as a raft of other features and we still keep releasing new capabilities as part of composer we're introducing orchestrator in preview for those of you building more complex experiences where you have a parent bot and multiple of these child bots or skills routing utterances or questions reliably across any a number of skills becomes increasingly complex we now have this new orchestrator capability based on a transformer model that does a much better job of doing that through their routing you can provide it domains uh through keywords and it will do a um a good job at connecting uh people up to those skills and you'll see a demo of that later on you also see continued uh investment in the virtual assistant uh we have you know do a composer-based declarative version that we continue to build on and uh you'll see more of that in the future with the q a maker there's been a number of new capabilities multi-turn support the ability to have questions with some sort of hierarchy so if a user asks how do i get to your office maybe there's multiple ways the train and walking and by car so we can actually ask follow-up prompts to narrow down and get the user to the right amount of the right data right question and answer pair so that's a really exciting feature used a lot rich text editing as well so the ability to add formatting emojis and things within your your answer a very uh often asked for feature along with role-based access control so you can now grant different access to different users for your knowledge base which is a a well asked feature request moving forward there will be further simplification around the resources that you need to manage when you create a q a maker resource lots of work going on in the language understanding space uh moving forward um for now uh the the main uh investment has been around the labeling experience a much easier way especially for more complex you know composite type entities and um scenarios um the labeling experience is a big step forward and uh many of you will benefit from that on a day-to-day basis on the board service side uh actually we spoke about the alexa channel that will cover that later on so that's in preview today we have single sign-on in preview for web chat and teams for those of you with the enterprise assistant scenarios with this single sign-on capability end users will not be prompted to log in either in web chat and in teams as they roll that capability out there's been a very asked for feature to remove those prompts so now um that capability is available in preview adaptive cards 2.0 brings a broad range of new capabilities which are now in preview along with human handoff capabilities where a bot can hand off to a human which in um the many scenarios is needed we have integration with live person you know out of the box and you can see further evolution uh with telephony and so on uh moving forward so now let's get started with our first demo using composer so we're gonna bring to life uh just some basics within composer and show off a few new features before we move on to skills so let me switch into uh composer so i'm actually running composer here locally and within a web browser most of you will typically use the electron app that we provide that you can download and install i'm using in the browser today because i'm using some very new bits so within composer we have a variety of ways of getting started i'm going to go ahead and click new one of the new features is the ability to create a new conversation experience from from knowledge base now you can go ahead you can kind of choose a name for your bot as per usual but actually within composer now you can point it at a source of faq information and documents and so on and it will build that knowledge base and make sure the bot right out of the box works with q a maker which you can then very importantly extend and add skills and do other things afterwards you can also go ahead and create another knowledge base from scratch at which point it will go ahead and create the experience and you can see you're dropped into the q a editor actually directly within composer so you can go ahead add a question add alternative phrasing and an answer so it's a great partnership between us and kind of the q a maker team to bring this to life you can go ahead and click start bot uh you provide your q a subscription key and you can get right in with a q a bot and you can again you can see it's a very simple dialogue it's purely doing q a maker within here and we've given you some basic conversation flows that's a great new feature for those q a maker focus scenarios uh during covered we saw a lot of bots being created very quickly just to do q a but but we're now seeing those customers wanting to expand those experiences and get far more broader so this is a great way of doing that because switching gears going back into this experience obviously there's a variety of starting points and you can see here we're starting to bring to life virtual assistant which will some of you may know we've had available through visual studio and yeoman and so on for some time and it gives you kind of a core assistant as a starting point and you can go ahead and add skills and it gives you personality and a number of things so this is still work underway and you'll see a preview of this kind of being used today so if i go ahead and create a new va core i choose a name for it we go ahead and kind of create that and you'll see right away within composer here um we've got a number of you know top level kind of intense here things around greetings and kind of you know onboarding getting started um utility type intents like canceling and help and an unknown event handler so there's questions your bot cannot answer you may want to go and call q a or go and call some sort of search tool so it's much easier to see those utility things that we're providing here within the general dialogue you can see in this version we're handling these kind of three intents here and we have kind of a simple you know onboarding flow so this is where as an example getting started it would explain what the bot can do and ask you maybe for some information to personalize in this case it's asking for your name and you'll see here within composer we have a the begin dialogue from the dialogue starts um handler here we'll also see we have an interruption intent here so it's part way through the dialog when it prompts your name you say why do you need my name it can actually even though it's asking you another question switch to that and switch back again so what are the key capabilities of adaptive dialogues which are used by bot front composer that lets you build these more sophisticated experiences and you'll see a little bit more of that those kind of dialogues that are being used here and you can you can see here that um for this response you can see we've got something called language generation and if we go ahead and click on bot responses you can see all the responses from the dialogs are actually brought together into this view and with dynamic generation you can provide more than one option and the bot will actually at runtime pick one of those it allows for a slightly more dynamic kind of experience you can see here we've got adaptive cards and things so bringing those responses together into one place has been a great step forward the same thing for any training data you're bringing all that lewis data together you can go in and edit that directly within composer without having to jump into the portal and again you can see here from a q a kind of point of view there's a variety of you know knowledge bases that we we have today where you can go ahead and add you know knowledge and and so on to it obviously this is a new one so i'm going to go ahead and just show some of these things so within the emulator in this case this is one i deployed earlier so you just go ahead and click start bot and one of the key things if i re if i start this conversation if you look at this adaptive card here you see he says hi i'm your virtual assistant and you can see hello and hi there hey there this is language generation we're actually got that text is a language generation entry and it's picking that and changing each time which makes it slightly a nicer experience so if i go ahead and want to get started and go into that onboarding experience it's gonna ask me my name just gonna say what's your name and i'm gonna say you know why do you need my name now instead of this saying hello why do you leave my name which you can sometimes see we're actually doing that interruption to another dialogue saying i need my name don't know how to talk to you and and asking again i'm going to go ahead and say darren so it will then go ahead and say nice to meet you shows me the help card and can enable me to get started now if i actually restart this conversation you're going to see the uh welcome back card is actually parameterized with that information from memory so language generation is using information from the bot memory to actually you know parameterize this a bit more so i can go ahead and say you know what are the event dates for ignite so this is a q a kind of item and you can see it's gone ahead routed it to q a and given me a response back and if that was multi-turn it would it would go back and forward and give me some information and then of course i can go off and you know i plugged in a skill in this simple one i'm going to say you know go ahead and find me a coffee shop and you're going to see this is going to go ahead identify this as something to go to a skill and go ahead and show an adaptive card with information about coffee shops and this is a skill we have in one of our github repos and again if you click on any of these cards you can kind of see information including a speech friendly response which is you know a a key thing for speech-based experiences so let's see how we can connect skills to your bot within composer so within composer you can natively connect to a new skill you provide the manifest url for your bot any bot could be a skill and that describes the capabilities of your skill you can see our registered calendar and who and poi you've already seen back in bot design you can see we've actually integrated the new orchestrator in preview directly as a new recognizer meaning we can use that for routing to a skill so go ahead and select that i want the advantage of orchestrator over the lewis base dispatch is it uses a transformer model so we can just provide keywords relating to the domain it does a much better job than understanding which skill to actually route that to so still in preview when we're working through the integration we then have an action to go ahead and connect to the skill we select the skill that you saw before i can provide authentication information and if you send activity process to false it will take the question from the user and forward it directly to the skill and then start that conversation just go ahead and see this in action so if i go ahead and say new meeting orchestrator you can see is actually fired here so if i go ahead and click on the trace here you can actually look at the recognizer and go ahead and look at the the intent calendar skill so i'm going to invite lester to my meeting so using graph it resolves the name of that person i'm going to say the title of the meeting is project review so they're going to find when we're both available at the same time using graph which is pretty clever select the time i don't make this a teams meeting yes i do everything is a teams meeting right now uh we're also gonna maybe have some people in the london office which is uh recently uh opened so if we go ahead and do that discuss the description yeah review the project and one of the last stages actually the bot asks me a question do i want to go ahead and actually book this meeting have i done everything like at this stage i'm going to say actually i forgot to add patty now you see here it's asking me a question is it correct yes or no so i'm now going to interrupt this flow and answer a question from earlier in the flow and it's going to process that go ahead and add that new person to the meeting that you'll see shortly on the adaptive card here and then go back to asking me the question one of the benefits of adaptive dialogues ability to change your mind with dialogue and we're pretty excited about that and just give you a quick example i can go ahead and say who is uh nestor for example and you'll see the same skill routing actually going to the who skill in this case which again organizational search allows us to actually understand um who people are going to be in your organization and you can see these details here so switching back uh just quickly to the slide deck one of the capabilities uh that we're just working on right now is this bot project you can see here within composer you can see the bot and you can also see the various skills and the dialogues actually within each of those skills so this way of bringing together multiple skills in one project rather than you have to jump around from them we think is a big step forward for simplifying this and allowing you to uh go ahead and uh edit the more complex parent child box and you can go ahead click start or bots and it will enable the local debugging of that so that's a new feature uh coming to composer later this year just to give you an idea the framework composer is actually being directly integrated into power virtual agents which is our sas tooling for aimed at citizen developers and actually within pva you can launch composer go ahead and use the full power of the bot framework and actually publish that back into power virtual agents uh so you can then uh combine the best of both worlds together so there's a feature coming later this year and we'll share the roadmap later on so going back to the conversational campuses we touched on at the beginning if you remember you can write your bot once and then make it available across a very broad range of canvases so many of these for those of you familiar will be uh you'll have seen before also we have the amazon alexa we have the whatsapp uh capability uh and moving forward at telephony capabilities uh from microsoft as well so broad range of channels um let's just show a kind of a couple of the more speech focused ones uh quickly as part of the demo here so within web chat here i've configured direct line speech which is a channel that sends audio directly into your bot it's very fast and also allows you to have you know different voices so we can make advantage of our neural uh voices and you'll hear in this example we've actually not only used one of the new neural voices but applied a more caring tone to the voice so if i go ahead and ask what are the event dates microsoft ignite will take place online kicking off on the morning of september 22nd at 8 a.m in the pacific time zone the event programming will include live segments along with questions and answers available across time zones so this is the same assistant you saw working uh within composer and the other demo kind of earlier on and we can see that it's detecting speech it's applying that more caring kind of voice using the newer text-to-speech neural capabilities now if i switch the same bot uh and it's actually also been added to the alexa channel if i go ahead to the alexa developer console i can talk to the same experience using this test tool so i'm going to go ahead and start this open ignite assistant hey i'm your virtual assistant i'm here to help you get things done what are the event dates microsoft ignite will take place online kicking off on the morning of september so you get the idea there uh so again the uh same experience across multiple channels and you can see it working with alexa so your bot can act as an alexa skill a google assistant skill within web chat and any of those canvases that you that you desire so switching back to the slides um one of the things we're really excited about is actually announcing uh whatsapp support in partnership with infobit so they can't be here today due to the digital nature of the event but we'll go ahead and run a video which introduces their capabilities [Music] [Music] so [Music] [Music] i hope this showed you some of the advantages of using whatsapp across the customer journey it can help in every phase and at every touch point with your clients let's take an even closer look in the awareness stage of the customer journey you can use whatsapp to generate leads by using ads these lead to a chatbot that can answer frequently asked customer questions during the consideration stage customers can get answers to even more targeted questions or can receive valuable content to help move them towards a close in the purchasing stage you can help customers with reminders and delivery notifications finally in the post sales stage you can provide customers with helpful user guides product manuals tutorials and so on in retail unilever brazil successfully promoted a new product by exchanging almost three hundred thousand messages in seven days resulting in sales figures 14 times higher this is just a small example of what you can achieve by adding whatsapp to your communication strategy but let's talk about how first you need info bip credentials talk to your microsoft representative about connecting with us or visit www we'll provide you with an api key base url and a whatsapp number after that we'll guide you through whatsapp onboarding you can find more information about the process by following the link in the description but in short it involves sender registration integration and setup we'll help guide you every step of the way with the final step you adding an infobip adapter to your bot and finally we prepared a whatsapp demo you can try it out yourself by scanning this code or saving our demo number you can find the link and the number for the demo account in the links below which should demonstrate what a powerful tool whatsapp can be in your customer engagement strategy thanks for watching it's been a great partnership with infobit to bring uh whatsapp to bot framework um here's a kind of brief uh kind of demo that i recorded earlier within whatsapp on my on my device so you can see here we're having a conversation with the conversation experience through whatsapp i'm asking natural language questions you're seeing cards and emojis and things it's a great engaging experience it's actually really quite nice to use conversation experiences within whatsapp uh it's a very rapid um and engaging experience so it gives you a bit of a feel uh for how this works so you saw in the video there is a qr code that will take you to a demo there's also a telephone number you can add it to your device right now and talk to it so it's great to actually bring this to life [Music] so we've covered a lot of things on the left with our roadmap moving forward into november focus uh continues to be on composer so actually integrating uh this into power virtual agent so again you can publish your uh more sophisticated experiences using bot framework directly into power virtual agents so you can make the best of both worlds with the citizen developer tool with pba and sas also bringing virtual agent and virtual assistant and skills into composer more natively you've seen some previews of that will continue to iterate make it much easier to get started on our platform there'll also be the alexa channel ga google assistant will follow and some new security features looking ahead into 2021 we are investing significantly in a new creation and management experience for conversation ai built around the virtual assistant work so actually making it much easier to get started manage your as your resources and focus on your experience and bring a lot of that assistant sophistication to it there'll be reusable skills you can choose as part of the configuration process and some great work being done in that space single sign on down adaptive cards 2.0 ga kind of capability so we've got a lot on um including a telephony capability that we'll be bringing to uh conversation ai as well so you can connect your bot up to uh telephony infrastructure and our telephone number so with that call to action we have a blog post that covers you know all of the key elements i've covered today and the links to everything uh we've got some great resources to get started with composer documentation a link to get started on the whatsapp side we also have a survey we really want your input to help shape the product what are the features you think we should be investing in what are the areas you think we should look at um we really value your input so any time you can take to share that uh insight to us would be great and we'd love to have an ongoing conversation around uh how we evolved the product there's also a book a small book we released earlier this year with some resources around getting started with that thank you for your time um it's been great to share the broad range of investments we've been making and a view into what's coming soon so thank you and enjoy the rest of the event 