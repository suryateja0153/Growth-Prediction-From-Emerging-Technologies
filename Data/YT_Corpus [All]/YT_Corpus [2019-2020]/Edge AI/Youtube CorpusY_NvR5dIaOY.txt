 I don't understand. I don't get it. What am I doing? Thank you to Skillshare for sponsoring this video The first 1,000 people to click the link in the description will get a 2 month free trial of a Premium Membership. Okay so as you may know we are living in the inside times right now. Now I'm not a terrible cook but I am lazy and this means that I can't just go to a restaurant that call it self-care anymore In other words, I'm eating a lot of pasta nowadays. Jar of sauce, bag of noodles, Mamma Mia! Except much like Mamma Mia 2: Here it Goes Again, there can be too much of a good thing. But instead of being a normal mature adult and just learning new recipes I thought: can I just get a robot to do that instead? Can I teach a computer how to cook? So this task kind of hinges on one thing, the ability to teach a computer how to invent new recipes and that's an ability i don't currently have. Now I'm not starting from zero, I have taken a few intro to coding classes but there is a pretty big difference between printing HelloWorld and getting a computer to learn how to make pasta recipes. So in this video I am going to try and bridge that gap and I'm gonna take you along for the ride to get things started, I just- I just googled how to teach a computer to generate recipes and then I just fell down the rabbit hole of searching anything else I didn't understand which was a lot okay so here's what I found out now don't worry I'm not gonna talk about the math behind machine learning because honestly it's not that easy and I am not qualified to do that, but more importantly I honestly think that the intuition behind it all is going to be a lot more useful to you. So machine learning. It might sound really futuristic and complex but it's fundamentally pretty simple. Let's say you have a machine now this is basically a baby that's really good at math and literally nothing else then you give it something to look at. For example pictures of numbers. You tell it what those pictures are supposed to represent - what those numbers are. Then you ask it to find a pattern in the pictures. The quality of that grouping that pattern recognition can be scored for example you give it some new pictures and ask it to sort those into groups. The more it gets right, the higher the score. The machine will think about the patterns that help increase its score and try to think more along those lines. So, for the pictures of numbers maybe it realizes that eights, threes, and nines tend to have round upper halves, while eights, threes, and sixes have round lower halves. So if the machine sees an image with a round upper half but not a round bottom, by process of elimination, it should be able to quickly narrow it down to a nine. Now the actual process isn't this reliant on visuals - remember computers think with math. But what you need to know is that machines don't learn by magic, they are just trying and testing out different features and pursuing the ones that improve their score. And much like me and re-watching TV shows, it's not even smart enough to know when to stop. It'll keep trying out new ways to improve its score even when there's nowhere left to go. Let it go too long and it might start seeing meaning and features that don't actually help. So you, the person who made it, need to tell it when it's done. And that's basically the learning part now let's take a closer look at the machine. You've probably heard of neural networks before sometimes people call them multi-layer perceptrons which is a bit too 60s sci-fi for my taste. Neural networks are designed to mimic how human brains work by identifying fundamental patterns and using that as a guide to generate output. Now even the most basic neural network can do some pretty cool things but it's far from great. It's really rigid so you can only have a fixed sized input and a fixed sized output. Not very useful if we're trying to generate pasta recipes which can vary in length and complexity, so instead I found out about a specific kind of neural network called a recurrent neural network, or an RNN. These allow you to input and output sequences - that is, maintain context over multiple inputs, which is cool but how does that help us with what we want to do? Well, what if instead of sequences of pictures we do a sequence of words? Now the machine can learn to find patterns in these words - which sentences make sense given what it's seen and which one's don't? Using that knowledge, it can start looking at sentences and predicting what the next word should be. And it can just keep doing it... forever. So, we give it a few words to start with (usually a random sentence from our recipes) and it will add one word at a time until, hopefully, we have a full recipe. Except it isn't that easy because of course it isn't. The problem is even though RNNs maintain context better than some neural networks, they're still nowhere near as good as a human. Imagine you're reading this recipe: melt butter in a medium saucepan. Whisk in flour and cook. Now you know from reading countless instructions before that verbs and the nouns that follow it are usually the most important part, so you'll make sure to remember those words and won't waste too much time focusing on the parts inbetween. Basic RNNS don't work that way. Instead it'll try and remember every word and pretty quickly it'll get overwhelmed and start forgetting important context. So it might remember you need to whisk and cook flour, but it might forget you need melted butter first. Enter long short-term memory which is a special kind of RNN with a really confusing name. Basically while a machine is learning you can imagine that it is maintaining two memories: a short-term one that is encountering a new experience or looking at a new word. And a long-term one that retains everything learned thus far. Long short-term memory allows the machine to do what you do -  forget some information in the short-term so when that memory is eventually used to update its long-term pattern recognition, it prioritizes what's relevant. Now it does need to figure out what features make a word relevant, but that's where the whole machine learning thing comes in. Okay so LSTMs theoretically have the ability to do what I want... I think. So now I just need to do it. I started by downloading a bunch of highly rated pasta recipes from Epicurious.com. I'm gonna show these the machine and this is how it's gonna learn what a pasta recipe looks like. And then I spent like another two days googling how to actually make an LSTM. Basically the code was copy/paste but like actually setting it up - like downloading and downloading drivers and all of that stuff - was my personal hell. But eventually I was ready to go. So let's go! Alright so instead of words, my LSTM works on a character by character basis. It's- it's the same intuition, instead of predicting what the next word should be, it just starts predicting what the next letter should be. This wasn't a strategic decision. It's just because I don't know how to set it up for words. It just seemed harder. If you want to look at it, let's let's see! Would you look at that? Wow! Notably it has- it trains on a sequence length of 100 characters. What that means is that it just looks at the past 100 characters and with that it tries to predict what the 101st character should be and it just does that over and over again. Let's let's see if it runs. We're doing it! We're doing it! 5 hours. It's gonna take 5 hours Okay, I mean, okay. It isn't perfect. It's really far from perfect actually. [machine generated gibberish] It's bad! By my weak understanding of machine learning, I think that the typos mean that I should have just trained it for longer. I don't know I'm just gonna train it for longer then. It didn't work! Yeah, so I ran it for longer this is what happened. I think that the problem, right, is that 100 characters just isn't enough. It loses so much context that it just believes that 500 tablespoons of olive oil is a good enough pasta recipe! I'm gonna try and feed it a longer character sequence. It's gonna take like 2 hours per epoch, so I'll see you guys in a day? two days? it was a total failure! Listen, here's what it came up with, are you ready for this? bowl on soils over medium heat add pasta and cook season with salt and pepper season with salt. It's like olive oil all over again. I don't understand. I don't get it. What am I doing? So either I need to accept that 500 tablespoons of olive oil and some salt and pepper is a pasta recipe, or I need to change my approach. I've spent like a week on this already so... I'm gonna need to change my approach Okay so, hmm, turns out what I was doing was dumb. So it turns out the thing I was using long short-term memory, LSTMs, were just the wrong thing for what I want to do. It's kind of like using a hammer on a screw - right toolkit, wrong tool. Basically even though long short-term memory can better filter for relevancy, they still have two big problems. (1) even though they can handle sequences of words as input, they only process them one word at a time. So, if we feed it the sentence, set the stove to high, it'll stop and think after every word. And unsurprisingly, that means that it can take a really long time to learn anything. And (2), even though they're better than basic RNNs they're still pretty bad at long term dependencies because they process words one at a time. It becomes this technological battle where, sure, you can force it to remember really far back, but then it's going to take forever to learn. So with LSTMs, you kind of just need to accept this relatively short memory in exchange for doing things in a reasonable amount of time. So what if we stopped using long short-term memory? There are different types of neural networks, and as we know now for what I'm doing, it turns out I was using the wrong one. Instead there are these things called transformers. Like RNNs, they can accept sequences as input, but what makes them special is that instead of inching across sentences word by word, transformers can look at everything all at once! It remembers the ordering of the words and analyzes each word simultaneously for its relevance to the overall message.This parallel processing allows transformers to work a lot faster than LSTMs. For example, if it sees this text, it might find these parts to be essential because they define key objects and actions, these words provide more detail, and these are more or less just to make the sentence is grammatically correct. These are all important components to generating meaningful output, but the machine's ability to recognize just what role they play is what makes it so powerful. Now here's the thing, I could just do this all over again and try to make a transformer all on my own, but I can just barely grasp how it works. So maybe I'm not in the best place to implement it. Luckily ,the nonprofit organization OpenAI has has done it already. And when I say that they've done it, I mean that they they've taken this transformer architecture and- and they've trained it. So now I could just take this machine and then tell it to like focus on pasta recipes. And I could do this on my laptop - I could open up a code editor and run it myself - but given the fact that I've come to realize that for things that are more computation heavy, my computer sounds like it's going to explode, I'm not gonna do that! So I decided to use something else. You see, there's this thing called Google colaboratory... what is it called? Google colaboratory... okay google colab! There's this thing called Google Colab that lets you run on a virtual machine. Even more luckily, there's this data scientist at BuzzFeed named Max Woolf who already made a Google Colab notebook that you can use to just finetune GPT-2 to generate any text you want. Like YOU could do this, you just need to copy it and feed it the text you want it to learn. So, I'm just gonna feed it all the recipes and see what it comes up with. Okay so it's been an hour - an hour and a half - since I ran it and it's done. Okay! The first thing that strikes me is the fact that it's formatted exactly like how I inputted things! It's not just giving me a list of one tablespoon olive oil. For all intents and purposes this looks like a real recipe to me, but as you may have guessed, on a scale of 1 to master chef... I am an idiot sandwich. So I'm gonna phone a friend. This is Melissa. She's been my friend since high school and is possibly the only person I know who loves the Bon Appetit Test Kitchen more than me. Hi! So, Sabrina sent me some recipes the other day. Yeah, I'm gonna read these recipes and see if they're make-able? See if they're doable. Let's see how this goes! Okay, so our first recipe is a fettuccine with asparagus, parsley and fried parsley. That's a lot of parsley. Transfer to a plate and cooled and transfer to a plate of ice water tight ice watermelons. Add pesto. Bolognese. Bol-en-ez? Bol-en-ezyay? That one looks pretty good actually. Mushroom ravioli! Okay the instructions say if frozen mayonnaise mayonnaise Mayo mayonnaise Mayo Mayo Mayo will need to be minced to coat. Okay we've got macaroni and cheese Hold up! There's a full cup of cognac in this recipe. I think it's gonna be really hard to make one of these recipes without like modifying it in some way. But we're gonna try. I might make macaroni and cheese, may leave a cup of cognac out because that's expensive. Our backup is ramen for dinner if the pastas don't turn out. Alright let's go! Yeah I've gotta go. Cook. Now. Byyyyyye. oh my god. oh my god. We made it! I have my bag of groceries, let's go home now! Okay, I just finished making the robot mac and cheese, now I'm gonna make some real mac and cheese because... well I'm just gonna show you! Mac and cheese! YUM Okay so I just finished making both of the recipes. So I tried to make the recipe from the robot, uhm... didn't exactly make macaroni and cheese. So I ended up following a recipe from Bon Appetit to make macaroni and cheese and it turned out way better. Have them both in front of me here. In the end, it was like semi edible. It's not the best thing I've ever made but I would not make it again. I think the robot did like an okay job. From first glance, I thought it was a functioning recipe, that's why I chose this one. And then as I actually went through it it was not. Anyways happy cooking - or not happy cooking. Please don't make these recipes. I'm gonna keep eating this macaroni and cheese and call Sabrina and show her what her monstrosity made. It turned out so bad. So, obviously it didn't work out. The real issue was the fact that I- I didn't I didn't try very hard to train it. If I'm totally honest here. I was kind of over it, so I trained it for the shortest amount of time possible and then just picked a random mac and cheese recipe. And that's kind of the way it goes with robot generated things, you're not always going to get something good, in fact a lot of the time you're gonna get something bad - you're gonna get garbage! You're gonna get that mac and cheese! Whenever you see that stuff online, you need to know that it's cherry picked. Now I want to ask you a few questions that will help shape the future of this whole channel. What did you think of this video? What did you think of the topic? Is it interesting to you or do you prefer more of the humanity stuff? Was it too fast? Was it too technical? Was it not technical enough? Are you more interested in the math? Let me know down below. Another question for you: are you ready for an ad read? This video was sponsored by Skillshare if you like learning you're gonna love it! It's this online learning community with thousands of classes covering just about any skill: from entrepreneurship, productivity, graphic design - heck, I even watched a couple of classes to figure out how to use an LS TM. Skillshare is perfect for working creatives who are looking for a way to sharpen their skills. A lot of you guys have asked me how to get started in animation and motion design, well guess what! A lot of my favorite animators actually have courses available on Skillshare. But even if you're just looking to dabble Skillshare is amazing. Most classes are less than 60 minutes long and they come with hands-on projects so you could take on a creative challenge to break up the monotony of spending every day indoors. The first 1,000 people to sign up with the link in the description will get a two month free trial of a Premium Membership. After that it's less than $10 a month with an annual subscription. So, whether you want to explore new skills, deepen existing passions, or get lost in creativity - get started with Skillshare. But either way... have a lovely day! 