 [Music] good morning everybody welcome to the session my name is Mustafa I'm co-founder of deep mind and this morning I want to tell you a little bit about the work that we've been doing to use machine learning and AI to tackle climate change so you may be familiar with our mission our mission is to try to solve intelligence and the core motivation that led us to set up this mission when we started the company in 2010 was to try to address the key question what if we could distill what makes us unique and exceptional as a species our minds our intelligences our capacity to be creative to plan over long term sequences to have really incredible intuition for discovering insight in complex social systems what if we could extract the essence of that into an algorithmic construct wouldn't it be incredible if we could use that and take advantage of parallel compute access to vast amounts of training data and use it to do really important things in the world and so that was the motivation that led us to architect solving intelligence as our core mission and I think what's at stake in the world is that many of our most challenging problems are actually intractably complex from science to macroeconomics to weather modeling we're overwhelmed by the complexity of the systems around us we've got tons and tons of data but trying to extract insight from that data and learn the relationship between cause and effect well enough to be able to make meaningful predictions in these environments it's becoming more and more challenging so the key question is what if we were able to use the sorts of systems that we've been developing and try and extract new insight but actually use that to turn insight into real action to actually affect these stuck social challenges that was our core motivation we really need new tools new tools that humans that we design to try and help us to make sense of the complexity of the world around us and we began quite a few years ago now on the old school challenge of Atari our first major breakthrough came in 2015 for those of you who don't know I'm sure everyone does the the Atari set of games was the sort of hundred or so environments from around the 80s and 90s many of which you'll be familiar with from pong to space invaders and the challenge for us is could we actually take just the raw environment provide purely the pixels as inputs and give them to an agent that isn't told anything about what they could do isn't given any prior knowledge no heuristics everything the agent should learn purely from scratch and all we provide is simply the goal in this case the optimization target was score could a single agent learn to play all of these games - humor level performance or even above simply through correlating score and a rewarding outcome with the preceding state that had taken place over the past interactions that it had playing the game and so the key intuition here is imagine a robot standing in an arcade with no sense of what's actually going on behind the scenes no additional information but just controlling the joystick and looking at the screen so here's a little video to show you what it was like when we first set our agent to play in this environment you can see it's randomly moving left and right to control the paddle at the bottom and most of the time it's completely missing any of the bricks at all after 300 or so games the agent seems to learn this correlation between score going up and moving the paddle preemptively to the right place to tap the ball into the blocks what was really interesting after about 500 or so games really unexpectedly and very surprising to many of us engineers was that it discovered a strategy of tunneling if it could just pummel the ball up the back it could get maximum score with minimum effort and this is really interesting because it was actually the first time that we got really concrete intuition that we were onto something nothing in the system had been pre-programmed there were no heuristics none of the engineers were able to hand code little tricks like this one but purely through self play the system discovered new knowledge and that is the core quest of deep mind how can we discover new insights and new knowledge we extended this a few years later to tackle the ancient game of Go the incredible thing about the game of Go is that enormous complexity arises from very very stunning simplicity there are very few rules and restrictions in the game on a 19 by 19 professional board like this one each player of black and white stones takes turns to place a single stone anywhere on the board where there's no other stone and over time the objective is to surround your opponent stones and conquer territory in the way that you can see here the incredible thing about the game is just with these simple rules there's something like 10 to the power of 170 possible configurations of the board so what you're seeing here is an intuition of the branching factor at every moment there's a further few hundred or so positions and that goes on and on and on and to try and place that in some kind of context 10 to the power of 170 is estimated to be more atoms than there are in the known universe in every liquid and solid and gas in this room all around us on our entire planet and in the known universe more atoms are there are fewer atoms in the universe than there are positions that are possible in the game of Go so the traditional methods of writing handcrafted rules and heuristics are clearly not scalable really important intuition because many of our world's most complex challenges that we would like to make progress with have the same kind of characteristics and so thankfully we were successful in playing the world champion at the time at the game of Go and this was really recognized as a milestone moment in the development of AI but really interestingly Lisa Dahl who was one of the legends of the of the game who we played in Korea a few years back said something very interesting after the game his initial assessment going in was that he thought alphago was based on a probability calculation and it was simply a machine but when he saw some of the spectacular moves that alphago was able to play his mind was changed surely he said alphago is creative the specific move in reference he said was creative and beautiful and this was really exciting for us because again it demonstrated to us that a system through self play through interacting with an environment in the way that we had designed could discover new strategies that were surprising to even the very best players in the world after alphago we extended it to what we called alpha zero really interesting that we're able to generalize alphago to be able to play any other two-player game so we really wanted to resist the temptation that systems got really good at specific games clearly as humans what makes us really impressive is that we can learn new skills quite quickly based on our experience of performing well in other domains so for example if you know how to ride a bicycle you're probably going to do a bit of a better job on a motorbike and you bring that prior knowledge to bear that transfer learning approach is exactly what we are we were hungry after and so we tested you know alphago to extend it to a whole bunch of other games again learning completely from scratch in a fully general way with no opening book no endgame database no surest --ax itself play starts completely from random and no reference to any past human games so purely organically and the interesting thing is that the improvement rate of the algorithm was actually phenomenal so alphago zero has no prior knowledge of the game and only the very basic rules at its input at zero days three days later alphago zero surpassed the abilities of alphago Lee which is the version that beat the world champion Lisa doll four games out five and 2015 and three weeks after that alphago zero reaches the level of an alphago master the that defeated 60 top professionals online and the world champion qje in three out of three games in 2017 and then after 40 days alphago zero surpassed all other versions of alphago and arguably became the best go programmer in the world and again the key intuition here is that more training time a more self play provides the algorithm and the agent with more experience more examples to learn from a greater distribution of possible state spaces and in doing so it's able to produce much more general much more flexible insights so this single system this general model was able to be the best put systems out there in shogi in chess in under four hours and ultimately and go in under eight hours it's really interesting here to look at a quote from Garry Kasparov one of the former world chess champions he said the implications go far belong beyond my beloved chess board not only do these self-taught expert machines perform incredibly well but we can actually learn from the new knowledge they produce and again this is precisely the symbiotic man and machine relationship that we were hungry after how could a Junt systems provide us humans with new insights and new knowledge that we could then use to take actions in our own complex environments and again train systems to improve in the process and I really want to sort of take a moment to step back because this is really the real purpose behind our core mission to solve intelligence how can we enable machines to help teach us new insights new strategies and new knowledge to focus first and foremost on the problems that actually matter in the world today and I think what what's really at heart here is our free choice to work on the problems that really matter and really address the core question of what is our purpose in the world today and there couldn't be any greater moment for us to address these real stark social challenges for example take the question the challenge of climate change we know that global mean surface temperature over the last 150 years or so has been rapidly rising we know that we're potentially on a trajectory to hit two degrees of rising temperature which called which could cause irreversible consequences for our world and have a massive impact on our ecosystems according to NASA the planets average surface temperature has already risen by about point nine degrees since the last 19th since the nineteenth century this is scientific fact and is clearly one of the most urgent and pressing problems for us to focus on because the trajectory looks really worrying a 1.5 degrees centigrade average rise could put up to 30% of species at risk of extinction according to the IPCC and at 2 degrees centigrade most thing ecosystems will struggle to survive altogether but this temperature rise of course doesn't just affect animals and ecosystems global temperature increases of 3 degrees are estimated to result in 330 million people being displaced by flooding alone according to the UN and in fact this actually affects all of us right now where we're stood here today sea levels could rise by 3 foot by 2 2100 and so take a look at what would happen right here at IO this would leave us underwater right where we're stood pretty remarkable so it's clear that climate is one of our greatest challenges and so three or four years ago we decided to ask ourselves the core question how could we as a team start to focus significant amount of our efforts on this really important problem and of course energy consumption is one of the largest contributors to climate change itself so we took we gave ourselves two core pillars to work on and at Google the first is the question of whether we can dramatically increase the efficiency of existing systems both on the consumer side and also on the large-scale industrial system side of things secondly could we rapidly accelerate the introduction of renewables we know that this technology is possible prices are plummeting but there are some very significant barriers adoption that we think machine learning models can help with so I'm going to talk to you about these two goals so first of all what did we do on the consumer side well we've had an excellent collaboration with the Android team for over three years now and what we've been trying to do is extend the battery life that you get from your phone simply by improving the way that your phone interacts with you the way in a very personalized way we managed to deliver a 30% reduction in CPU wake-ups and is now rolled out to Android Pi which is already hitting about 2.5 billion users this had an enormous contribution to increasing the overall battery life from a single charge on a pixel to around 30 hours or so so this is a little bit on how it worked we basically along with the Android team built a two layer deep convolutional neural network with a faster with with with a neural network on top of that to predict the probability that an app would be opened at a given interval so the key thing here is that we abstracted out and anonymize sequences of app interactions that you had and then try to predict when you were likely to use an app in relation to the other apps that you are using in the future so we know for example that some people tend to use certain apps in the morning say when you're on your commute or when you're quickly accessing your news other apps tend to be used more at the weekends and this relationship is really important because if we can optimize which apps they open in the background we can obviously significantly reduce the cost on battery life and of course as with all of the applications and deployments and launches that we try to make we pay a great deal of attention to fairness and privacy so there's no favoritism of one app over another all of that was completely de-identified you may use a particular app in a very different way to the way I use another app and that doesn't actually get factored in at all it's entirely personalized and your individual usage is what really matters but of course we personalize in a privacy-preserving way as well so all of the personally identifiable data is removed before the actual model is trained and then the model is retrained on your local device which i think is a really exciting and promising proof point of how we're gonna get closer and closer to locally trained models over the next five years or so so moving now from processors in your pocket to processors in the cloud of course at Google we have some of the largest and actually already most well engineered and efficient industrial systems in the world when we decided to take a look at Google Data Centers I can tell you that some of the expert engineers who had been working on these systems for almost two decades now we're a little bit surprised that we thought we could make them significantly more efficient they were very collaborative and we set about on a three-year journey to see if we could try to use machine learning systems to improve the efficiency of how power is managed in the Google Data Center fleet and this is a super important problem because we're all consuming a hell of a lot more of data centers energy and and storage and we're creating vast amounts more data they centers that across the world actually use around 3% of the world's electricity and of course it's growing rapidly so there's enormous opportunity for us here to try and use the existing data in the existing systems and run them much more efficiently and it turns out that the cooling energy is actually one of the biggest consumers of electricity after the non server load in a data center in fact cooling can actually make up around 40% of the total energy used in the data centers so how did we do this well obviously everything starts with a large amount of historic training data to give the agent to give the system some visibility on how the system is operated in the past and try and learn from that and replicate it going forward so there's over two-and-a-half thousand data inputs again showing one of the many benefits of collecting really rich really accurate really well labeled data or over extended periods of time we are able to look at things like the incoming IT load power meters pressure sensors water flow meters pump and fan speeds alarms external weather conditions loads of very rich contextual data that provides the agent with a lot of information about how the system has operated and then we ask the agent to take control of twenty or so actions so it can adjust which cooling towers are activated it could adjust how many chillers are being used at what time it could adjust pressure set points temperature set points flow set points the whole range of other control space actions and so the way to think about it a little bit like Atari is that the system is trying to learn the correlation between data at a particular state and a desired action that it's trying to optimize with respect to a specific goal and of course that goal was can we run the existing system at the same you know with the same level of performance we obviously don't want any dropout in you know in in DC uptime and availability but can we do so with less energy consumed and so the way the initial version of the system worked is that every 5 minutes the cloud-based agent pulls data from some of these thousands of sensors does a bunch of cleaning and processing in the cloud and then spits back a set of recommendations to a human operator who examines them and then implements them and this adjusts controls for all the set points that I mentioned and remarkably this was able to deliver a 40% reduction in data center cooling energy this is a graph that we first produced when we turned on the machine learning model for about 48 hours and then turned it off afterwards and again this was an incredibly significant moment for us a couple of years ago because it was actually demonstrating that we can do what we attempted to do what we what we wanted to do in 2010 when we founded the company which is trained in a petri dish toy game-like environment and actually extract the lessons from that environment and deploy them in a real world in this case in an enormous very valuable industrial system like Google's data center fleet but the really exciting thing is some of the kinds of lessons or knowledge that was discovered in the process that was surprising to many of the data center engineers the first is that it has actually more efficient to spread load across more equipment and so if you think about it as a data center engineer you're having to review thousands of data center inputs over time and you've got all sorts of controls that you can adapt and finding the optimal relationship between different pieces of cooling equipment at different times given different incoming IT loads and different weather environments is incredibly difficult even for the most experienced data center engineers and so it turned out that spreading that load across more equipment was actually more effective another surprising intuition that higher flow rate through the chillers was actually not always better in some cases it remained better but in many cases it was actually better to reduce flow to the chillers given some weather conditions and finally adapting the loads to different pieces of equipment across the year turned out to also be a very valuable way to drive efficiencies so then how did we scale this up and get it into production across the fleet well it was obviously really important that we took a safety-first automation approach so let me tell you a little bit about that the first part of the process looked exactly the same the data center produces a bunch of sensor information that describes state at any given moment and then the model produces a set of recommendations but in this case the model sent those recommendations to a local data center control system that automatically implemented those and without the human necessarily being in the loop and this in itself was the first autonomous application that we're aware of in a large-scale industrial system so some of those key safety features firstly there was continuous monitoring across the entire fleet there was automatic failover just in case anything went wrong there were a set of smooth transition heuristics that allowed the system to gracefully fail rather than abruptly shift to a set of new parameters there was two layer verification so both at the local level and at the cloud level there was a verification of the inputs at both levels constant communication between the data center operator the model the cloud team and the local data center team two and then crucially there was uncertainty estimation and I think this is very exciting it's the beginnings of interpretability of our machine learning algorithms you want your model to accurately give you a confidence indicator of how sure it is that a particular set of recommendations are going to lead to a particular outcome that is desirable and sometimes you might have a bit more courage to move that confidence estimation further towards the objective that you're looking for okay you know if you choose to do that or you might want to keep it more constrained depending on what you're optimizing for and how risky the state is at that moment and of course there's always rules in heuristics and the human is in the loop all of the time the interesting thing here is that over the 12-month period that our autonomous system was in deployment as more and more data or training examples were collected the performance of the system got better and better and better in this case going down is actually a good thing because it's improving the efficiency of the system and using less energy to deliver the same performance output so it's really cool to see one of the key data center engineers in the team say the following it was amazing to see that a I learned to take advantage of winter conditions and produce colder than normal water which reduces the energy required for cooling with the data center so really helpful to get that feedback so now moving on to what we've been doing on the wind farm side of things this was the second pillar of our motivation to try to figure out how we can use machine learning models to make wind much more competitive the challenge with wind energy is that although the cost of production can buy units be lower over a year it's really really difficult principally because it's very unlike fossil fuel energy and it's very difficult to dispatch it's very unreliable so grid operators really prioritize knowing exactly how much energy they're going to receive from different producers and when they need to dispatch that to the various different consumers who demand it at a particular time and this has really significant economic consequences because that certainty is incredibly valuable the unpredictability of renewable energy makes it much much less valuable than fossil fuels because you can't guarantee the exact amount sometimes it's windy sometimes it's not there's huge variability so our challenge was to try to improve the quality of our predictions so that we could accurately schedule when we were going to have surplus wind energy to provide to the grid and that makes it much more competitive with traditional fossil fuel energy production we started working on about 700 megawatts of Google's wind farm portfolio this is about a quarter of the entire energy produced by Google at any given time and just to put that in perspective it's about the same amount of energy that's consumed in all of San Francisco so it's really material and again the way that it works is that we took a whole set of inputs including whole range of weather forecasts local weather observations and all sorts of other data inputs and we train the neural network to try to predict with some probability distribution what power generation will look like in 36 hours and that allowed the team to then provide the grid with much more accurate much more reliable information about when the wind farms were able to provide provide energy back to the grid and therefore keep it competitive with the rest of fossil fuels just to give you a bit of an intuition for how difficult this is this is production from 0 to 250 megawatts as you can see on the y axis here and that's just across a 16 day period so the scale of the variation is absolutely phenomenal so it's really difficult to make this a competitive product and being able to tell the grid that we're very confident in 36 hours that we're going to be able to supply you with the right amount of energy that you need again makes it competitive and you can see here that our predictions are tracking the ground truth over time overall this actually made the value of the wind energy that's developed at Google 20% more valuable in economic terms and so again this is a step change improvement a really significant step up that helps us to you know eliminate fossil fuels in the grid over time and increase the amount of non carbon-based energy that we're producing so finally just to sort of wrap up and summarize the intrusion I want to leave everybody with today is that we actually have enormous potential to deliver radical improvement to existing systems of course we would love a moment where we could rebuild everything from scratch but the reality is we have to engage over the next couple decades with old-school industrial established systems where we have to work with existing data and existing hardware and existing infrastructure there were no new phones used in the production of these algorithms no new cooling systems no new turbines this was existing hardware and but when we collect the right data and it's stored and processed and well labeled accurately we actually can deploy machine learning models to generate enormous step function like efficiencies and I think this is a very modest step forward in the right direction and gives us good a good sign that over the next decade I think there could be really remarkable breakthroughs and advances to come from these kinds of energy efficiencies using machine learning models so with that I just want to leave you with a final closing thought this to me is the real power of AI to help us find really deeply practical real-world solutions to try and tame some of the complexity of our most difficult social challenges this is our core purpose and to me this is what makes life worth living thanks very much for listening to my talk [Applause] [Music] you [Music] 