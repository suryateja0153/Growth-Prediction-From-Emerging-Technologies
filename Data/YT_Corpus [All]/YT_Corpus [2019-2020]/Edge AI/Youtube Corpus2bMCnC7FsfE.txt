 from Las Vegas it's the queue covering next word 2019 America is brought to you by Juniper Networks come back everybody Jeff Rick here with the cube we're in Las Vegas at Caesars at the Juniper next work event about a thousand people kind of going over a lot of new cool things four hundred gigs who knew that was coming as new information for me but that's not what we're here today we're here for the fourth installment of around the cube unpacking ai we're happy to have all the winners of the three previous rounds here at the same place we didn't have to do it over the phone so we're happy to have him let's jump into it so winner of round one was Bob Friday he is the VP and CTO at mist the Juniper company Bob great to see you yeah good to be back absolutely all the way from Seattle Sharon a parking she's a vp applied scientist at Tech Co can you see Shauna and from Google we know a lot of AI happens at Google Raj and chef he is the vp AI product management at Google welcome thank you Chris be here all right so let's jump into it so just to warm everybody up and we'll start with you Bob what are some when you're talking to someone at a cocktail party Friday night talking to your mom and they say what is AI what do you give them as an examples of where AI is impacting our lives today well I think we all know the examples of the self-driving car you know AI starting to help our healthcare industry being diagnosed cancer for me personally I had kind of a weird experience last week at a retail Technology event where basically we had these new digital mirrors doing facial recognition right and basically you start to have digital mirrors who are gonna basically if you start guessing hey you have a beard you have some glasses and they start calling me old you know so this is kind of very personal I have a I said one thing for you the comi all but hey I go walking down a mall with a bunch of mirrors calling me old that's a little annoying did it bring you out like a cane or a walker oh yeah start giving some advertisers that were like okay guys this is a little bit over the top all right Shauna what about you what's your favorite example to share with people yeah I mean I think one of my favorite examples of AI is kind of accessible and on your phone where the photos you take on an iPhone the photos you put in Google photos they're automatically detecting the faces and they're labeling them for you they're like selfies here's your family here's your children and you know that's the most successful one the ones that I think people don't really think about a lot are things like getting loan applications right we actually have AI deciding whether or not we get loans and that one is is probably the most interesting one to me right now Roger so I think the focus example is probably my favorite as well and what's interesting to me is that really AI is actually not about the a it's about the user experience that that you can create as a result of AI and what's cool about Google photos is that my entire family uses Google photos and they don't even know actually that the underlying is some of the most powerful AI in the world but what they know is they can find every picture of our kids on the beach whenever they whenever they they want to or you know we had a great example where you know we with our kids every time they like something in the store we take a picture of it and we can look up toy and actually find everything that they've taken picture of it's interesting because I think most people don't even know the power that they have because if you search for Beach in your google photos or you search for I was looking for an old bug picture from my high school there it came right up so until you kind of explore you know it's pretty tricky so Roger you know I think a lot of conversation about AI they already spoke of the general purpose general purpose general purpose machines and and robots and computers but but people don't really talk about the applied a that's happening all around is why do you think that so it's a good question there's there's a lot more talk about kind of a general purpose but the reality of where this has an impact right now is though are those specific use cases and so you know for example things like personalizing customer interaction or spotting trends that did that you wouldn't have spotted before or turning unstructured data like documents into structured data that's where AI is actually having an impact right now and I think it really boils down to getting to the right use cases where AI can add value right sure and I want to ask you you know there's a lot of conversation always as AI replace people or is it an augmentation for people and we had Gary Kasparov on a couple years ago and he talked about you know it was the combination if he plus the computer made the best chess player but that quickly went away now the computers actually better than Garry Kasparov plus the the computer how some people think about AI as an augmentation tool versus a replacement tool and is it just going to be specific to the application how do you kind of think about those yeah I would say that any application where you're making life-and-death decisions where you're making financial decisions that disadvantage people anything where you know you've got UAVs and you're deciding whether or not to actually drop the bomb like you need a human in the loop if you're trying to change the words that you are using to get a different group of people to apply for jobs you need a human in the loop because it turns out that for the example of beach you type sheep into your phone and you might get just a field a green field and AI doesn't know that you know if it's always seems sheep in a field that when the sheep aren't there that that isn't a sheep like it doesn't have that kind of recognition to it so anything where we're making decisions about parole or financial anything like that needs to have human in the loop because those types of decisions are changing fundamentally the way we live great so shift gears the team or did you have something pop no no I'm okay as a team you remind me I have I've been delinquent on my bail so I'll be a more active on the bill sorry about that so everyone's even we're starting at zero again so I want to shift gears and talk about data sets Bob you're up on stage demoing some some of your technology the mist technology and really you know it's interesting combination of data sets AI and its current form needs a lot of data again kind of the classic Chihuahua blue buried in photos you got to run a lot of them through how do you think about data sets in terms of having the right data and a complete data set to drive an algorithm yeah I mean I think we all know data sets with one of the tipping points for AI to become more real right along with cloud computing storage but data is really one of the key points in making AI real right my example on stage was wine right great wine starts a great grapes great date ai starts of great data for us personally LST M is an example in our networking space where we have data for the last three months from our customers and we're really using the last 30 days to really train these LST mm algorithms to really get that tsunami detection to a point where we don't have false positives how much of the training is done once you once you've gone through the data a couple times an adjust versus when you first start and you're not really sure how it's going to shake out in the algorithm yeah so in our case right now right training happens every night so every night we're basically retraining those models basically to be able to predict if there's going to be an anomaly or network you know and this is really an example of where you look at all these other cat image things this is where these neural networks are really were one of the transformational things that really moved AI into the reality column and it's starting to impact all our different energy whether it's text imaging in the networking world as an example where even AI and deep learnings really starting to impact our networking customers sure I want to go to you what do you do if you don't have a big data set you don't have a lots of pictures of chihuahuas and blackberries and I want to apply some machine intelligence to the problem I mean so you need to have the right data set I you know big is a relative term and it depends on what you're using it for right so you can have a massive amount of data that represents solar flares and then you're trying to detect some anomaly right if you train in AI what normal is based upon a massive amount of data and you don't have enough examples of that anomaly you're trying to detect then it's never going to say there's an anomaly there so you actually need to over sample you have to create a population of data that allows you to detect images you can't say oh I'm gonna reflect in my data set the percentage of black women in Seattle which is something below 6% and say it's fair it's not right you have to be able to over sample things that you need and in some ways you can get this through your surveys you can get it through actually going to different sources but you have to bootstrap it in some way and then you have to refresh it because if you leave that dataset static like Bob mentioned like you people are changing the way they do attacks and networks all the time and so you may have been able to find the one yesterday but today it's a completely different ballgame fraudulent to you which comes first the chicken or the egg you start with the data and I say this is a ripe opportunity to apply some AI or do you have some AI objectives that you want to achieve and now you got to go out and find the data so actually I think what starts where it starts is the business problem you're trying to solve and then from there you need to have the right data what's interesting about this is that you can actually have starting points and so for example there's techniques around transfer learning where you're able to take an algorithm that's already been trained on a bunch of data and train it a little bit further with with your data and so we've seen that such that you know people that may have for example only a hundred images of something but they can use a model that's trained on millions of images and only use those hundred to create something that's actually quite accurate so that's a great segue maybe a ring on that one it's a great segue into talking about applying on one algorithm that was built around one data set and then applying it to a different data set is that appropriate is that correct is are you risking all kinds of interesting problems by taking that and applying it here especially in light of when people are gonna go to out where the market places because I thought a data scientist I can go get one in a market place and apply it to my data how should people be careful not to make a bad decision based on that so I think it really depends and it depends on the tud the type of machine learning that you're doing and what type of data you're talking about so for example with images they're there they're well-known techniques to be able to do this but with other things there aren't really and so it really depends but then the other intro the other really important thing is that no matter what at the end you need to test and iterate based on your based on your data sets and and and based on sample data to see if it's accurate or not and and then that's gonna guide everything ultimately sure I was gonna go to you you brought up something in the preliminary rounds about open AI and kind of this we can't have this black box where stuff goes into the algorithm and stuff comes out and we're not sure what the result was sounds really important is that is that even plausible is it feasible this is crazy statistics crazy math you know he talked about the business objective that someone's trying to achieve I go to the data scientist here's my data you're telling me this is the output how you know kind of where's the line between the layman and the business person and the hardcore data science to bring together the knowledge of here's what's making the algorithm say this yeah there's a lot of names for this whether it's explainable AI or interpretable AI or opening the black box things like that the algorithms that you use determine whether or not they're in spectable and the the deeper your neural network gets the harder it is to expect actually right so to your point every time you take an AI and you use it in a different scenario than what it was built for for example there was a police precinct in New York that had facial recognition software and victim said oh it looked like this actor this person looked like I don't know Bill Cosby or something like that and you were never supposed to take an image of an actor and put it in there to find people that look like them but that's how people were using it so the Russians point yes like it you can transfer learning to other ai's but it's actually the humans that are using it in ways that are unintended that we have to be more careful about right even if your AI is explainable and somebody tries to use it in a way that it was never intended to be used the risk is much higher yeah I think maybe I'd add you know you know if you look at Marvis kind of what we're building it for the networking community a good example is when Marvis tries to do estimate your throughput right your internet throughput that's what we use what we call decision tree algorithm and that's a very interpretive algorithm and we predict low throughput we know how we got to that answer right we know what features got us there you know but when we're doing something like anomaly detection that's a neural network you know it's a black box it tells us yes there's a problem there's some anomaly but that doesn't know what caused the anomaly but that's a case where we actually use neural networks to actually find the anomaly and then we're using something else to find the root cause so it really depends on the use case and more than I you're gonna use an interpretative model or a neural network which is more of a black box model to detail you got a cat or you've got a problem somewhere so Bob that's really interested so can you not unpack a dural network is just the nature of the way that the communication and the and the data flows and the inferences are made that you can't go in and unpack it that you have to have the separate kind of process to get to the root cause yeah you know the site is always hard to say never but inherently yes neural networks are a very complicated state a set of weights right it's basically usually a supervised training model and we're feeding at a bunch of data and trying to train it to detect a certain feature a certain output but that is where they're powerful right and that's why they basically doing such good job because they are mimicking the brain right that neural network is a very complex thing it's kind of like your brain right we really don't understand how your brain works right now I mean you have a problem it's really trial and error and we try to figure out right right so I want to stay with you Bob for a minute so what about when you change what you're optimizing for so you just said you're optimizing for throughput of the network you're looking for problems now let's just say it's into them into the court or some other reason we're not you're changing you're changing what you're optimizing for can you do you have to write a separate algorithm can you have dynamic movement inside that algorithm how do you approach that problems because you're not always optimizing for the same things depending on the market conditions yeah I mean I think a good example you know again with Marvis is really with what we call reinforcement learning right and reinforcement learning is a model we use for like regular resource management and there we're really trying to optimize for the user experience and trying to balance the reward the models trying to reward whether or not we have a good balance between the network in the user right that reward can be changed so that algorithm is basically reinforcement you can finally change how that algorithm works by changing the reward you give the algorithm great Rajan back to you a couple of huge things that have come into into play in the marketplace and get your take one is open source you know kind of what's the impact of open source generally on the availability to use I and more applications and then to cloud and soon to be edge you know the current next stop how do you guys incorporate that opportunity does it change what you can do how does it open up the lens of AI yeah I think open source is really important because I think one thing that's interesting about AI is that it's a very nascent field and the more that there's open source the more that people can build on top of each other and be able to utilize what what others others have done and it's similar to how we've seen open source impact operating systems the internet things like things like that with cloud I think one of the big things with cloud is now you have the processing power and the ability to access lots of data to be able to to create these these networks and so the capacity for data and the capacity for compute is is much higher edge is gonna be a very important thing especially going into next few years you're seeing more things incorporated on the edge and one exciting development is around federated learning where you can train on the edge and then combine some of those aspects into a cloud site model and so that I think will actually make edge even more powerful but it's got to be so dynamic right because the fundamental problem used to always be to move the computer the data or the data to compute well now you've got on these edge devices you've got Tunde data right sensor data all kinds of machining data you've got potentially nasty hostile conditions you're not in a nice pristine data center where the environmental conditions are and the connectivity issues so when you think about that problem yet there's still great information there you got latency issues some might have to be processed close to home how do you incorporate that age-old thing of the speed of light to still break the break up the problem to give you a setup up well we see a lot of customers do is they do a lot of training on the cloud but then inference on the on the edge and so that way they're able to create the model that they want but then they get fast response time by moving the model to the edge the other thing is that like you said lots of data is coming in to the edge so one way to do it is to efficiently move that to the cloud but the other way to do is to filter and to try to figure out what data you want to send to the cloud so that you can create the next data sense Sharonda back to you let's shift gears into ethics this pesky pesky issue that's not a technological issue at all but right we see it often especially in tech just because you should just because you can doesn't mean that you should yeah so and this is not a stem issue right there there's a lot of different things that happen so how should people be thinking about ethics how should they incorporate ethics how should they make sure that they've got kind of a you know a standard kind of overlooking kind of what they're doing the decisions are being made yeah one of the more approachable ways that I have found to explain this is with behavioral science methodologies so ethics is a massive field of study and not everyone shares the same ethics however if you try and bring it closer to behavior change because every product that we're building is seeking to change a behavior we need to ask questions like what is the gap between the person's intention and the goal we have for them would they choose that goal for themselves or not if they wouldn't then you have an ethical problem right and this this can be true of the intention goal gap or the intention action gap we can see when we regulated for cigarettes what we can't just make it look cool without telling them what the cigarettes are doing to them right so we can apply these same principles moving forward and they're pretty accessible without having to know oh this philosopher and that philosopher in this Ephesus said these things it can be pretty human the challenge with this is that most people building these algorithms are not they're not trained in this way of thinking and especially when you're working at a start-up right you don't have access to massive teams of people to guide you down this journey so you need to build it in from the beginning and you need to be able to based upon principles and it's going to touch every component it should touch your data your algorithm the people that you're using to build the product if you only have white men building the product you have a problem you need to pull in other people right otherwise there are just blind spots that you are not going to think of in order to build that product for a wider audience it seems like they were on such a razor sharp edge right what coca-cola want you to buy coca-cola and they show as for coca-cola they appeal to your let's all sing together on the hillside and and and be one right but it feels like with AI that there's that is now you can cheat right now you can use behavioral biases that are hardwired into my brain as a biological creature against me and so where is where is the fine line between just trying to get you to buy coke which somewhat argues probably just as bad as Jewel because you get diabetes and all these other issues but that's acceptable but cigarettes are not and now we're seeing this stuff on Facebook we're you know so we know that this is and coke isn't just selling coke anymore they're also selling vitamin water so their their play isn't to have a single product that you can purchase but it is to have a suite of products that if you want that coke you can buy it but if you want that vitamin water you can have that sure if I had been watering a smile that only comes with the coke dump five you want to jump it yeah I mean I think we're gonna see ethics really break into two different discussions right I mean ethics is already like human behavior that you're already doing right doing bad behavior like discriminatory hiring mmm-hmm you know training that behavior into AI is gonna be wrong it's wrong in the human world it's gonna be wrong in the AI world I think the other component to this ethics discussion is really around privacy of data it's like that mirror example right you know who gave that mirror the right to basically tell me I'm old and actually do something with that data right you know is that my data or is that the mirrors data that basically recognized me and basically did something with it right you know that's the Facebook example when I get the email tell me you look at that picture and someone's tag me in the pictures like no where was that good where did that come from right but I'm curious about to follow up on that as social norms change we talked about it a little bit before we turn the cameras on right it used to be okay to have you know no black people drinking out of a fountain we're coming in the side door of a restaurant not that long ago right in the 60s so if someone had built an algorithm then that would have incorporated probably that social norm but social norms change so how should we you know kind of try to stay ahead of that or at least go back reflectively after the fact and say kind of back to the black box ooh that's no longer acceptable we need to tweak this I wouldn't say it in that example that was wrong 50 years ago but not okay it was wrong but if you ask somebody in Alabama you know at the University of Alabama math department who've been born red and born bred in that cultures whole what you know they probably would have not necessarily agreed but so generally though again assuming things change how should we make sure to go back and make sure that we're not again carrying forward things that are no longer the right thing to do well I think as I said I think you know what we know was wrong you know is gonna be wrong in the eye world I think the more subtle thing is when we start relying on these AI to make decisions like you know should my car hit the pedestrian or save my life you know those are tough decisions to let a machine take off or your ball decision right when we start letting the machines or you know is it okay for Marvis to give this VIPs preference over other people right you know those type of decisions are kind of the ethical decisions you know where they're right wrong the human world I think the same thing will apply in the AI world I do think we'll start to see more regulation just like we see regulation happen in our hiring you know that regulation is going to be applied into our AI great solutions we're gonna come back to regulation in a minute but Roger I want to follow up with you in your earlier session you talked you made an interesting comment you said you know 10% is clearly you know good a 10% is clearly bad but it's a soft squishy middle at 80% that aren't necessarily super clear good or bad so how should people you know kind of make judgments in this this big gray area in the middle yeah and I think that is the toughest part and so the approach that we've taken is to set a set out a set of AI principles and what we did is actually wrote down seven things that we will that that we think AI should do and four things that we should not do that we will not do and we now have to actually look at everything that we're doing against those AI principles and so part of that is coming up with that governance process because ultimately it boils down to doing this over and over seeing lots of cases and figuring out what what you should do and so that govern this process is something we're doing but I think it's something that every company is gonna need to do sure and I want to come back to you as so we're gonna shift gears to talk a little bit about about law we've all seen as Zuckerberg unfortunately for him has been you know stuck in these congressional hearings over and over and over again a little bit of a deer-in-the-headlight you made an interesting comment on your prior show that it he's almost like he's asking for a Galatian like you know he stumbled into some really big hairy nasty areas that were never necessarily intended when they launched Facebook out of his dorm room many many moons ago so what is the role of the law because the other thing that we've seen unfortunately and a lot of those hearings is a lot of our elected officials are way way way behind they're still printing their emails right so what is the role the law how should we think about it what should we what should we invite front from the law to help sort some of this stuff out yeah I think as an individual right I would like for each company not to make up their own set of principles I would like to have a shared set of principles that were following the challenge right is that with between governments that's impossible China is never going to come up with same regulations that we will they have a different privacy standards than we do but we are seeing locally like the state of Washington has created a future of work task force and they are coming into the private sector and asking companies like text EO and like Google and Microsoft to actually advise them on what should we be regulating we don't know we're not the technologists but they know how to regulate and they know how to to move policies through the government what we'll find is we don't advise regulators on what we should be regulating they're going to regulate it in some way just like they regulated the tobacco industry just like they regulated sort of monopolies that tech is big enough now there is enough money in it now but it will be regularly right right so we need to start advising them on what we should regulate because just like mark he said well everyone else was doing it my competitors were doing it so if you don't want me to do it make us all stop I think that's can I do a negative bill and that would not for you before Mark's response to me that's crazy so Bob old man at the mall it's actually a little more codified right there's gdpr which came through May of last year and now the noon is to California make sure I get a right California Consumer Protection Act which goes into effect January 1 and you know it's interesting is that the hardest part of the implementation of that I think I haven't implemented it is the right to be forgotten because as we all know computers are really good at recording information and cloud it's recorded everywhere there's no there there so when these types of regulations how does that impact AI because if I've got an algorithm built on the data set and person you know item number 472 decides they want to be forgotten how the heck do I deal with that well I mean I think with Facebook I kind of see that as I think I suspect mark knows what's right and wrong he's just kicking the ball down of tires like oh you guys it's your problem you know please tell me what to do I see a ice kind of like any other new technology you know it can be abused and used in the wrong ways I think legally we have a constitution that protects our rights and I think we're gonna see a lawyers treat AI just like any other constitutional things and people who are building products using AI just like we build medical products or other products and particularly harmful people you're gonna have to make sure that your AI product does not harm people you're a product does not include you know and promote discriminatory results so I think we're going to see you know our constitutional thing is going to apply to a I just like we've seen other technology and work and it's gonna create jobs because of that right because yeah there'll be a whole new set of lawyers holding civil lawyers and testers even because otherwise if an individual company is saying oh we tested it it works trust us like how are you gonna get the independent third-party verification of that so we're going to start to see a whole pillar as' proliferation of that type of field that never had to exist before yeah one of my favorite doctor room in child reform accenture if you don't follow her on Twitter followers she's fantastic and great lady so I want to stick with you for me to Bob because the next topic is autonomous and ramen up on the keynote this morning talked about mist and and and really this is kind of shifting workload of fixing things into an autonomous setup where the system now is is finding problems diagnosing problems seeing problems up to I think he said even generating return authorizations for broken gear which is amazing but autonomy opens up all kinds of crazy scary things Robert Gates we interviewed said you know the only guns that are that are autonomous and the entire US military are the ones on the the border of North Korea every single other one has to run through a person so when you think about autonomy and when you can actually grant this this AI the autonomy the agency to act what are some of the things to think about and what are the things to keep from just doing something bad really really fast and efficiently yeah I mean I think we discussed right I mean I think you know from practical purposes we're far you know we're there is a tipping point I think eventually we will get to the sea p3o Terminator day where we actually built something on par with a human but for the real purposes right now we're really looking at tools that are going to help businesses doctors self-driving cars and those tools are going to be used by our customers to basically allow them to do more productive things with their time you know whether it's doctor that's using a tool to actually use AI to predict you know help make better predictions they're still going to be a human involved you know and what Romney talked about this morning networking is really allowing our IT customers focus more on their business problems where they don't have to spend their time finding bad hardware bad software and making better experiences for the people they're actually trying to serve right trying to get your take on on autonomy because because it's a different level of trust that we're giving to the Machine when we actually let it do things based on its own volition there's a lot that goes into this decision of whether or not to allow autonomy there's an example I read there's a book that just came out oh what's the title you look like a thing and I love you it was a book named by an AI if you want to learn a lot about AI and you don't know much about it get it it's really funny so in there there is in China a factory where the AI is optimizing output of cockroaches now they just they want more cockroaches now why do they want that they want to grind them up and put them in like a lotion it's one of their secret ingredients now it depends on what parameters you allow that AI to change right if you decide to let the AI flood the container and then the cockroaches get out through the vents and then they get to the kitchen kitchen to get food and then they reproduce the parameters in which you let them be autonomous over is the challenge so when we're working with very narrow AI when use how the AI you can change these three things and you can't just change anything then it's a lot easier to make that autonomous decision and then the the last part of it is that you want to know what is the results of a negative outcome right there what's the result of a positive outcome and are those results something that we can take actually right right Roger give you the last word on the time because kind of the next order of step is where that the machines actually write their own algorithms right they start to write their own code so they they kind of take this next order a thought and agency if you will how do you guys think about that you guys are way out ahead in this space you have huge datasets you got great technology you got tensor flow when will the machines start writing their own a their own algorithms well and I actually it's it's already starting right there that you know for example we have we have a product called Google Cloud Ottawa valve which basically takes in a data set and then we find the best model to be able to match that data set and so things like that that that are there already but it's still very nascent there's a lot more that that can happen and I think ultimately with with how it's used I think part of it is you have to start to always look at the downside of automation and what is what is the downside of a bad decision whether it's the wrong algorithm that you create or a bad decision in that model and so if the downside is really big that's where you need to start to apply a human in the loop and so for example in medicine hey I can do amazing things to detect diseases but you would want a doctor in the loop to be able to actually diagnose and so you need to have have that in place in many situations to make sure that it's being applied well but is that just today or is that tomorrow because I you know with with exponential growth and and and as fast as these things are growing I mean will there be a day where you don't necessarily need that maybe needs a doctor to communicate the news maybe there's some second-order impacts in terms of how you deal with the family and you know kind of pros and cons of treatment options that are more emotional than necessarily mechanical yeah because it seems like eventually the doctor has a role but it isn't necessarily in accurately diagnosing a problem I think it I think for some things absolutely over time the algorithms will get better and better and you can rely on them and trust them more and more but again I think you have to look at the downside consequence that if there's a bad decision what happens and how is that compared to what happens today and so that's really what we're where that is so for example self-driving cars we will get to the point where cars are driving by themselves there will be accidents but the accident rate is going to be much lower than what's there with humans today and so that will get there but it will take time yeah now there is a day when it'll be illegal for you to drive yeah yeah manslaughter right III believe absolutely there will be in and and I don't think it's that far off actually and I'm waiting I'm waiting for the day when I can have my car take me up to Northern California with me sleepy baby boy I live that long that's right and work while you're while you're sleeping right well I want to thank everybody a ton for being on this panel this has been super fun and these are really big issues so I want to give you the the final word will just give everyone kind of a final say and I just want to throw out there Mars law I mean people talk about Moore's law all the time but a Mars law which Gartner stole and made into the hype cycle you know is that we tend to overestimate in the short term which is why you get the hype cycle and we turn tend to underestimate in the long term the impacts of Technology so I just want as you look forward in the future we won't put a year number on it you know kind of how do you see this rolling out what are you excited about what are you scared about what should we be thinking about we'll start with you Bob yeah you know for me and you know the day of the Terminator cp3 oh I don't know if it's a hundred years or a thousand years that day is coming you know we will eventually build something at some part of the human I think they mentioned about the book you know you look like a thing and I love you type of thing that was written by someone who tried to trained AI to basically pick up lines write cheesy pickup lines yeah I'm not for sure I'm gonna trust a AI to help use my pickup lines yet you know you know I love you you know you look a good thing I love you I don't know it may work but who wouldn't who would've guessed online dating is what it is if you had asked you know 15 years ago but I think yes I think overall yes we will see you determinate or cp3 oh it was probably not in our lifetime but it's in the future somewhere ai is definitely gonna be on par with the Internet cellphone radio it's gonna be a technology that's going to be accelerating if you look at where technology's been over the last is this amazing to watch how fast things have changed in our lifetime alone right yeah you know we're just on this curve of technology accelerations this amazing potential curves Sharna yeah I think the thing I'm most excited about for AI right now is the addition of creativity to a lot of our jobs so a lot of we builded augmented writing product and what we do is we look at the words that have happened in the world and their outcomes and we tell you what words have impacted people in the past now with that information when you augment humans in that way they get to be more creative they get to use language that have never been used before to communicate an idea you can do this with any field you can do it with composition of music you can if if you can have access as an individual to the data of a bunch of cultures the way that we evolved can change so I'm most excited about that I think I'm most concerned about the products that we're building to give AI to people that don't understand how to use it or how to make sure they're making an ethical decision so it is extremely easy right now to go on the internet to build a model on a data set and I'm not a specialist in data right and so I have no idea if I'm adding bias in or not and so it's it's an interesting time because we're that middle area and it's getting loud was getting out all right Roger we'll just throw with you before we have to cut out or we're not going to be able to hear anything every minute so I I actually start every presentation out with a picture of the mosaic browser because what's interesting is I think that's where AI is today compared to kind of women when the internet was around 1994 we're just starting to see how AI can actually impact the average person as a result there's a lot of hype but what I'm actually finding is that 70% of the companies I talk to the first question is why should I be using this and what benefit does it give me why 70% ask you why yeah and and and what's interesting with that is that I think people are still trying to figure out what is this stuff good for but to your point about the long run and we underestimate the long run I think that every company out there and every product will be fundamentally transformed by AI over the course of the next decade and it's actually gonna have a bigger impact than the Internet itself and so that's really what we have to look forward to all right again thank you everybody for participating that was a ton of fun I hope you had some fun too they look at the score sheet here we've got Bob coming in in the bronze at but 15 points Rajan at 17 in our gold medal winner for the silver bell in shardana at 20 points again thank you thank you so much and look forward to our next conversation that all right thank Jeff Rick signing out from Caesars Juniper next work unpacking a I thanks for watching [Music] 