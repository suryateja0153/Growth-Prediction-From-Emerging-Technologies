 [Music] you [Music] you welcome to fundamentals of artificial intelligence today we are going to look at uninformed search usually in most of the AI techniques that we will explore we will later looked at using domain information or what is more commonly called heuristic knowledge which would be under the category of informed search however as an introduction to search in graphs we would love to look at uninformed search first so what we will cover today is how we will very quickly review problem solving as search look at what we meant by state spaces we read them formally introduced graph searching and introduced a generic searching algorithm thereafter we look at a couple of uninformed search strategies first the breadth-first search thereafter the depth-first search iterative deepening uniform cost search and then we will look at something called bi-directional search let's look at what we meant by problem-solving a search we define a state space that contains all the possible configurations one or two configurations I have shown you we would love to define all possible configurations of the relevant objects we would then look at the initial state that is specify one or more states within that state space as situations from which we stop and then we define something called the goal state one or more states that would be acceptable as solutions to the problem and of course we need to specify the operators a set of rules that describes the actions or operations available the state space is what is vital for formulating a problem-solving domain as state space search the state space literally consists of all possible configurations this is also referred to as the problem space for the a puzzle game that I have shown you little while ago each tile configuration is a problem set are the eight puzzle we should note has a relatively small space okay there could be problems which would have huge state space and we would look at how to search it in order to get to a solution so let's look at a problem solving a state space search and this is the start node which I wanted all of you to take note of this is as with nine tiles here one of them is plank and you move the blank around to arrive at this goal position now in the last class we have looked at how these expansions can take place given the four operations we will just look at the complete tree of solution so given this state you could have three possibilities of moving the blank so the blank is here you could think of moving the empty to the left it could come here at this point or you could think of moving it up to the center or it could move it to the right so given the start as this sets these configurations of tiles are the its successor nodes successes and we can keep on on generating the successors like from here we could get at more successors by moving the blank to a newer configuration like the blank could go up and one could come down so we could have two blank one eight six seven and three four five and we could have another one on which would be like to a three one six four seven could go this side and I would have blank here and I would have five so we could generate I had all the successes from one node but one thing to note here is that this point here this node here is a reputation of what I started with here as my start so I would avoid I'd getting expansions of these type of successes as having said that I would love to get all the successor nodes listed and then the idea would be to look for a path that takes me from through this space of successes as to the configuration that I was looking paying for and therefore this is line of expansions would be the solution to the problem that I was looking for now if you look at this very closely we can have a simile here this can be thought of as a graph and basically what we'll be looking for is given a node start node of a graph and a goal node G I'm looking for some path add that takes me from s to G so problem-solving as state space search can be abstracted to the mathematical problem of finding a path from the start node to the goal node or in a directed graph so let's take a look at what we mean by graphs and directed graphs before we proceed further into our discussion of problem-solving a state space graph you must have looked at graphs before but for completeness let me put the definition here a graph G comprises acept V of vertices and a set of edges the vertices as can be anything but is most commonly a collection of letters or numbers that's the representation and the set of edges is a set of double turn subsets of V that is e is a group of subsets of a B where a B belongs to the vertices and is not equal to B usually the graph is denoted as a 2-tuple gve so if a graph is given and I know its edges then we say vertices a and b rhs n't and if there is an edge a B that joins them in the graph and we called a and B themselves as the endpoints of the edge two edges that share a vertex such as let's say I have a graph here and I have a here and a be here and that's that's one edge I have another edge a and you see here that's another edge so if I have a B and a C here they are sharing a common on node a and then they are said to be adjacent to each other so I'm more interested here are in finding out the path in a graph like if you recall we had this eight puzzle all tile configurations and where I explored and really got these sort of structure there as I keep on expanding my nodes at every level well given the four operators of the eight puzzle game to me and from and given s as I could arrive at a given G I am more interested in finding out how did I come from s to G or get to know what is a path so the notion of a path in a graph is intuitively very clear but it's very difficult to pin down it formally so suppose I have a graph which is a set of vertices and edges and I have K vertices so 0 1 2 3 up to KK plus 1 not necessarily distinct and I have edges as e1 e2 so and so forth up to eat it o sub K not necessarily this now each edge II I is a group of vertices the alternating sequence that I get of the vertices and edges starting from the what is V sub 0 to V sub K is apart from V sub 0 to V sub K of length K the length is the number of edges and it's not the number of vertices so for this part that I have highlighted here the length of the path is one two three and four so here is a four length path and what I wanted to highlight was that this part is made up of edges e1 e2 e3 e4 so alternatively it had vertices let's call this vertices as VA VB VC so the path from the start to the goal for the given graph would be something like s e sub 1 V sub a a sub 2 V sub B e sub 3 V sub C ISA for Angie so that's the path that's adds in the given graph what we are more interested when we were looking at graph search for solutions to given problems is what are called directed graphs or die graphs for shot here again it has a set of vertices as V but the set of edges is actually directed edges so what are directed edges directed edges are ordered pair of elements of V put another way if I have a graph of two tupple of V and E E is a subset of V cross V it is a digraph if these pair which I get are ordered pairs so ordering of pairs you need to give each a direction namely the edge a B goes from A to B so here is an example of a I have a set of vertices ABCD and pair of edges a b a c b a c c d c-- so if these pairs are directed and arcs rather than just being edges as in the general graph that I was talking off then what we have is a digraph a tree is a connected graph with no cycling so here if you see if you go back and see the directed graph here we have a arc that starts at C and comes back to C again or if you could see here we go from A to B and then there is a path from B to a such a thing is called a cycle so in a tree we have a graph we just connected but they do not have cycles and this is something that we'll explore or in the remainder of this lecture so graph searching in for problem solving as a state space search is to find a sequence of actions to achieve a goal all searching for parts in a directed graph to solve a problem we define the underlying search space and then apply a search algorithm searching in graphs therefore provides an appropriate abstract model of problem solving independent of the particular domain and the type of graph we are searching here one needs to remember is usually a directed graph so we are in now position to formalize search in state space so let's define a state space a state space for us is actually a graph of vertices and edges where V is the set of nodes and is the set of Arc's here when I say nodes the node may be a simple node or it could be a data structure that contains a state description it could contain other information such as parent of the node operator that generated that node from that parent and other bookkeeping data each arc corresponds to an instance of one of the operators so basically whenever we are talking of formalizing in search in state space is we are looking at having whole of the state space converted into nodes with each operator giving me some instances that takes me to the other nodes so finally we end up having such a directed graph and searching in this directed graph for a path that brings me from s to G is what I mean by getting to the solution for each R in such a directed graph has a fixed positive cost associated with it corresponding to the cost of the operator and each node has a set of successor nodes corresponding to all of the legal operators as that can be applied to the source node State the process of expanding a node means to generate all the successor nodes and add them to their associated arcs one or more nodes are designated as the start node and then there is a goal test predicate which is applied to a state to determine if it's associated node is a goal node a solution in such a formal framework is a sequence of operators that is associated with a path in a state space from a start node to a goal node and the cost of each solution that I am looking for is the sum of the arc costs on the solution path so if all the arcs have the same unit cost then the solution cost is just the length of the solution or the number of steps or the state transitions that's involved so state space search under such a scenario is the process of searching through a state space for a solution by making explicit a sufficient portion of an implicit sait's space graph now one needs to remember that we do not generate the complete graph when we are looking for a solution under this idea of problem solving we keep on generating the graph as we keep on exploring for the solution so it's the process by which you search to a Smith's state space by making explicit only a sufficient portion of it of an implicit state space graph to find a goal node for large state spaces it's important to realize that it is not practical to represent the whole space so you initially start with just the start node and then expand the start node s its successors are generated and those nodes are added to the set V and the associated arcs are added to the set e this process continues until a goal node is found so instead of having the whole state space graph as it is explicitly generated and then looking for a solution the idea is to make explicit a sufficient portion of this as I go on expanding four nodes and every node that I expand answering a question whether that's my goal node if not getting its successor nodes and keeping the process continuing so state space search is when each node implicitly or explicitly represents a partial solution path in general from this node there are many possible paths that have its partial path as a prefix so basically what it means is that when I am doing such a state space is exploration in a directed graph I have come up to this point and then I keep on expanding beyond but one needs to remember that whatever I have expanded up to this point this still forms a part of the path so it's still the partial part is still there as a prefix for me beyond this there would be many alternate paths but this one up to here if somewhere the goal lies below this node then up to here this is the partial path that's included already so how do we evaluate such starts search strategies it's important to realize that we have many such searching techniques that we will discuss which are uninformed but how do we evaluate such search strategies there are four listing matrixes one we talk of completeness completeness is a guarantee of finding a solution whenever one exists so if a solution exists and if your searching technique can find that solution and the technique is said to be complete next we talk of time complexity that is how long does it take to find a solution and this is usually measured in terms of the number of nodes that the searching technique expands next we talk of space complexity how much space is used by the algorithm this is also usually measured in terms of the maximum size of the nodes list during the search and then there is a question of whether this search technique is optimal or admissible if a solution is found and is it guaranteed to be an optimal one and that is is it the one with the minimum cost if that guarantee is there for the given searching technique then it's said to be optimal we will now look at be searching techniques and then look at the evaluation of these techniques along these four matrices so what are the important parameters that one needs to really before we go into looking at the search techniques and evaluation of them is as these three interesting things that needs to be remembered we talk of a number of successor of any state the maximum number that's called the branching factor R then we talk of the length of a path in the state space is the minimal length which is the depth of the shallowest goal all that's D so we need to understand and something about D and something about B so if I have a node that's expanded every time into two successors so here are my branching factor is two if my goal lies here R that's the depth of the minimum length of the path to the shallowest goal then my B is three and I could have a maximum depth of these goes on on it could be infinite and that maximum depth of the state space is M so given these parameters to me and given the idea that we could search a directed graph to arrive at from a given and state to a given goal we look at a graph search procedure so even before I write then got him for the graph search procedure I would like to highlight that what we literally do is we have the start node s and we have its successors let's call this success as a and B so we create two lists one called the open and other called the closed and we first put s in the point where it needs to be expanded so we create a list called open and we put s in the open list so we put us here consisting solely of the Sartre note and then we pick up s for expansion so we pick up s and what we want to really check now is that is s as the goal node itself if not we generates his successes so if s is the goal node we have nothing to do we must come out and exit that's what is a check here or by saying that I create a list is called closed that's initially empty and then if there is nothing in open I have to exit out with failure but otherwise I select the first node and open and remove it on from open I take it away from open and push that North in closed now why do I do that is a way to remember that s has been expanded so then after that what I do is I generate the successors of s so the successors of s here are a and B so I take a and B and put it in open and next when I look for an expansion I take the note from I'm open so it comes to me now one needs to remember that how I add a B on to the open list will depend on what criteria do I really follow in order to really arrange this is later on we will see that if I am doing a breadth-first search i would see that everything is edited and of the list if I'm doing a depth-first search I would add it to the beginning of the list okay so basically you create a list called closed that is initially empty and you take the first node and open you remove it from open and put it on close and then if n is goal node we have nothing to do we exit it immediately else what we do is the following we expand the node n generating the set M of its successors so we install them as successors of n in the open list so add these members of M to the open list and then expand them further now if each member of M is already in G then we can decide whether we want to redirect its pointers or if each member is already in close that means one of the successor has already been expanded then we can redirect its descendants whatever are there to that pointer else we will ignore that note to be expanded further so how do we reorder the list open and is very very important to understand and the type of technique that we will have in the graph search so they are either according to some arbitrary scheme if it is uninformed search and according to some heuristic merit if it is a informed search today our concentration would be only on looking at arbitrary a schemes of arrangement and of the successor nodes in the open list so we look at uninformed search today and it's important that we really understand what we mean by uninformed here our uninformed search is also called blind search because of the very fact that it does not use any information about the likely direction of the goal nodes we do not have any idea of the problem domain so inform search on the other hand are also more popularly called the heuristic search are inform search techniques in the sense that they use information about the domain to try usually head in the general direction of the goal inform search methods and uninformed search methods are distinctly different in only either use of no information or use of information about the domain few of the uninformed search methods are breadth-first search depth-first search deft limited search uniform cost death first iterative deepening and bi-directional search we will look at few of them today in inform search we have hill-climbing best first greedy search beam search a and a star which we will look at in the next lecture so uninformed search strategies we do not have information from the problem domain and that is how we order the nodes in open using some arbitrary screen today we will look at this five uninformed search techniques breadth-first depth-first iterative deepening uniform cost search and bi-directional search so what is breadth-first search let's look at it in more closer terms by using our real graph here so I have a graph with node ABCD efg so what I expand is the shallowest unexpanded node so the fringe if you can see by now is actually a first in first out queue so new successors all go to the end so if you recall we said we will create two lists when we are doing graph search one an open list and another a closed list and we will keep the start node in open as we expand we take a to the closed list and generate the successors of a so the successors of a that I get I have B and C then the next time I take B for expansion take B here and keep it in close and when I get the successors of B so the successes of B you could see are D and E so those successors will go to the end of the list so D and E will come here so that the next node that I take for expansion is C rather than and D so this is how the breadth-first search works i expand the shallowest an expanded node the fringe is a first in first out queue that is the new successors go the end so first I check if is a goal state if it is not a goal state I get its successes which is B and C so the fringe for me is BC now so next I check if B is a goal node if not I get its expansion which is de but then the next node to be expanded is C and not D that that's something that one needs to really understand here when I am doing a breadth-first search and then next node to be expanded becomes d and so on and so forth so a few questions that I want to answer about the properties of the breadth-first search the first question is is breadth-first search complete we can see that the breadth-first search always guarantees that it will reach the goal if the branching is finite so if I have a state-space search to be done starting at a given s to some given G and I know that this is is the state space within which I have all the configurations for those states and then if branching is finite for this search so at some point somewhere I will definitely arrive at G why would that happen intuitively is because I would be expanding everything at every level and that will guarantee that no state is missed for a finite be and therefore breadth-first search is complete the number of nodes that we will generate is at this level l it is 1 and if I have B branching at this it is be e at this level it will become B square than B cube so I will have an order of B to the power D this is the number of nodes we will generate what about space complexity because of the very fact that the breadth first search generates every node at every level it has to keep all the nodes in it that it had expanded ok so keeps every node in the memory either in or on a path to the fringe and therefore the order is of B to the power D whether breadth first search is optimal now this depends if we guaranteed that deeper solutions are less optimal that is if step cost is one if we assume that every step it just costs one and there is no other cost involved so then it would mean that if I have some solution which is deeper down there and if I have a solution which is somewhere are at the shallower node I will get the shallower one first and therefore every time I am guaranteed to get the minimum cost solution so it is optimal next we will look at the depth-first search so you expand the deepest unexpanded node that's what are the clue is for depth-first search and if you have realized by this time I'm the fringe that I am talking of is last in first out queue that is you put successors at the front and those are what is expanded so you first check if a is a goal node or if not you get the successors which are B and C and check if B is gold if not you expanded and you have de but the point here that I want to make is de would be put in the front of the open list rather than at the end of the list in open so I have D I check if these a goal state and then I get its successor H I so I put its successors a chai in the front so here is the queue if you go back one slide there I had D which I expanded and he gave me two successors which was H and I H and I would come to the front of the list rather than to the back of the list so I checked and continue this search are go on doing i and then go on doing everything till I expand at every level so the questions or properties of depth-first search is their first search complete you could see from these explanations that a depth-first search is not complete because what can happen is that if I have infinite deft space and I could be stuck in in LA I could go on expanding down there our line and nowhere on this line our solution would exist so first important realization that first search is not complete what about the time complexity of their first search if I have M which is the maximum depth and B being the branching factor then the number of nodes that I need to do is B to the power M terrible if M is much larger than thee but if solutions are tense maybe mass faster than breadth-first search but if I have a huge M then it would be terrible time complexity in terms of space as definitely we only need to remember a single path of unexpected and unexplored nodes so the time complexity is B M which is linear and it may find a non optimal goal first but in terms of optimality it could be possible intuitively that there are goals here are somewhere at lower levels which will definitely be missed by any a depth-first search technique so it is not an optimal search technique next we come to a modification of our depth first search which is deft limited search to avoid the infinite debt problem that I was showing you in the previous slide of depth-first search we can decide to only search until a deft L that is we do not expand beyond their cell but then what will happen is that if we keep that limit L we may have a goal which lies just little well beyond L and we will never be able to find this code so an better idea would be that what if I keep on changing L and interactive Li iteratively I keep on in raising L so this is the idea of the next search technique that we will discuss called the iterative deepening search so iterative they make such I looked at level 0 first then I look at level 1 for the goal then level 2 level 3 so on and so forth so the idea of iterative deepening is let me repeat it so I start with at level 1 then I go to level 2 level 3 level 4 so the idea is that I take this level I did not find things here so I thought of doing a little bit more deeper level I did not find things there I may think of going even down I did not find things there I may think of going even down so this is what is iterative deepening search where I increase the death bond at every iteration so properties of iterative deepening very quickly it is complete the order of time complexity is o B to the power D spaces OB D and it is optimal if step cost is 1 or increasing function of death next we concentrate on something called the uniform cost search if you remember breadth-first is optimal but this is optimal if step cost is in if only optimal if step cost is increasing with depth that is it remains constant can be guarantee optimally for any step cost for that we look at something called the uniform cost search we expand note with the smallest path cost so here is a small graph this is a graph to find a path from s to G so here is my start and here is my goal so first when I expand s I have then its successes a B and C but the question is which one do I expand next X when I look at this I could see that the cost to a was 1 the cost to be was 5 and the cost to C was 15 so I would rather accept and the node with the smallest cost so I expand a so my next expansion is of a where I get to G and I know that the cost is a to G is 10 plus 1 here so 10 plus 1 11 that's what I market G and the other nodes that I have is B with a cost of 5 already there and C with the cost of 15 already from the previous expansion so next which node to expand if I ask the same question then I go to expand a node with the smallest path and therefore I go and expand B so once I expand B I have here on this marked B 2 G so I get G but the path cost is 5 and 5 that may extend so the G cost a stent and here it was 11 and now C 15 so the next note that I want to expand is this node and that when I see that I know that this is a goal node and I stop but I pick up this so this path that I got is the path which is with the minimum cost so uniform cost search implementation wise the fringe that I am looking for is definitely Q but then they are ordered by the path cost so this is equivalent to breadth-first if all step costs we're all equal the question is whether they are complete yes they are and the number of nodes with path cost is always less than equal to cost of optimal cost number of nodes and paths with path cost is greater than equal to cost of optimal cost and whether it is optimal or not yes for any step cost the uniform cost search is an optimal graph search technique so let us now look back again and illustrate these uninformed search strategies that we have learned today so we have looked at and breadth-first search we have looked at that first search we have looked at iterative deepening and we have looked at you from Gossage so here is a small graph that I want all of you to look at and over this we will try to explain and illustrate all of these search strategies so here is s ABC its successes de den and B successor eg and C so I have put the cost of every part in red there besides each of the arcs so first let's look at breadth-first search so if you are looking at breadth-first search here we know that we start with s0 here s in that list and then we generate its successors so we put this so in terms of the algorithm that I was talking off we call this node list is open and we call this node list closed so we create a list called closed and we create a list called open in open we have as 0 to start with and we pick up as 0 take a 0 here to close and get its successors into open list so I have success as a B and C so I put a B and C in that list then the next note that I expand is of course a and therefore I move a here to this and I have now BC but because it is a breadth-first search therefore i include its successors de and g to the end of the list so here is where de and she comes to the end of the list and the next node that is taken off for expansion is B and its successes which is G is added to the end of the list here so on and so forth so finally I have expanded E and then the next node that I get is this e so I have a solution because G is the goal node so the solution path that I am talking of is very simple as to a to G so that's the solution and the cost of the solution is 3 plus 15 equal to 18 our number of nodes expanded including the goal node is that we could expand 1 2 3 4 5 6 7 nodes so we had expanded 7 notes including the goal node the depth-first search is what we will try to expand now so in this we take s put it in this list and next we take the successes which are a B and C and put it in the list called open take as 0 to close next we take a 3 for expansion its successors B E and G now this is something that we need to take care of we put it in the beginning of the list here so as we put it in the beginning of the list the fringe moment is along this line so the next thing that comes to be expanded is D and that is what how it happens and the solution path that I get here also is sa G the same solution path but what is more interesting is because I took this path and then this was the maximum def I came back and expanded again and and then I came back and got G so the number of nodes that I expand is only 5 including the goal node is only 5 this is that first search next we just highlight one idea of simultaneously searching from the for word from s and backward from G so stop when both meet so we have an node s here and we have a G here we are looking for a solution from s to G so you keep on expanding and looking for our friends so the fringe keeps on coming here and from GU keep on ongoing in the same and we stop when these two fringes come and meet so only point that needs to be now discussed or are understood is what does it mean to search from backwards from G it basically means that we need to specify the predecessors of G at times this could be difficult like in chess what is the predecessor of checkmate what if there are multiple goal states there is a problem and what if there is only one goal test no explicit list or what do I do so basically a bi-directional search is is an alternate searching from the start state towards the goal and from the goal towards the start you stop when the frontiers intersect works well only when they are unique start and goal states and requires the ability to generate predecessor states that's something very important and come sometimes we need to finding a solution more quickly here are the time and space complexities so only thing that is important to realize when I am doing uninformed search over graph for problem solving a state space search is failure to detect repeated States because if I have some failure to detect repeated states this can turn a linear problem into an exponential one and there are two interesting solutions in the first method which is suboptimal but very practical at least I do not create paths containing cycles this is what are highlighted and in the beginning and in the second method the idea is to never generate a state and which is generated before so but then this would require that you keep track of all possible states so it uses a lot of memory for a very simple game like eight puzzle you would require something like factorial nine states in such a case but then and these solutions work very well because then you do not create a exponential problems of the state space so this is all that we have in uninformed search in the next class we will look at information from the problem domain being used to direct these searches which are more commonly called the heuristic search techniques thank you you [Music] you 