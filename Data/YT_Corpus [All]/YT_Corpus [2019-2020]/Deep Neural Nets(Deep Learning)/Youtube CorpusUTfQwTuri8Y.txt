 [Music] hello I'm Nicholas Thompson I'm the editor in chief of Wired it is my honor today to get the chance to interview Geoffrey Hinton there a couple well there are many things I love about him but to that I'll just mention in the introduction the first is that he persisted he had an idea that he really believed in that everybody else said was bad and he just kept at it and it gives a lot of faith to everybody who has bad ideas myself included and then the second as someone who spends half his life as a manager adjudicating job titles I was looking at his job title before the introduction and he has the most non-pretentious job title in history so please welcome Geoffrey Hinton the engineering fellow at Google welcome thank you so nice to be here with you all right so let us start 20 years ago when you write your some of your early very influential papers everybody starts to say it's a smart idea but we're not actually gonna be able to design computers this way explain why you persisted why you were so confident that you had found something important so actually it was 40 years ago and it seemed to me there's no other way the brain could work it has to work by learning the strengths of connections and if you want to make a device do something intelligent you've got two options you can program it or it can learn right and we certainly want programmed so we have to learn so this had to be the right way to go so explain though well let's do this explain what neural networks are most the people here will be quite familiar but explain the original insight and how it developed in your mind so you have relatively simple processing elements that are very loosely models of neurons they have connections coming in each connection has a weight of it that weight can be changed to do learning and what a neuron does is take the activities on the connections times the weights adds them all up and then decides whether to send an output and if it gets a big enough sum it sends an output if the sum is negative it doesn't send anything and weight about it and all you have to do is just wire up a gazillion of those with a gazillion weight with cuisine squared weights and just figure out how to change the weights and it'll do anything it's just a question of how you change the weights so when did you when did you come to understand that this was an approximate representation of how the brain works oh it was always designed as that right it was designed to be like how the brain work but let me let me ask you this so at some point in your career you under start to understand how the brain works maybe it was when you were 12 maybe it was when you were 25 when do you make the decision that you will try to model computers after the brain Oh sort of right away that was the whole point of it the whole idea was to have a learning device that learned like the brain like people think the brain learns by changing connection strengths and this wasn't my idea this shirring had the same idea shirring even though he invented a lot of the basis of standard computer science he believed that the brain was this unorganized device with random weights and it would use reinforcement learning to change the connections and it would learn everything and he thought that was the best route to intelligence and so you were following Turing's idea that the best way to make a machine is to model it after the human brain this is how a human brain works so let's make a machine like that yeah it wasn't just choice I did a lots of people thought that like that all right so you have this idea lots of people have this idea you get a lot of credit in the late 80s you start to come to fame with your published work is that correct yes when is the darkest moment when is the moment where other people who've been working who agreed with this idea from Turing start to back away and yet you continue to plunge ahead there were always a bunch of people who kept believing in it particularly in psychology but among computer scientists I guess in the 90s what happened was datasets were quite small when computers weren't that fast and on small data sets other methods like things called support vector machines worked a little bit better they didn't get confused by noise so much and so that was very depressing because we developed back propagation in the 80s we thought it would solve everything and we were a bit puzzled about why it didn't solve everything and it was just a question of scale but we didn't really know about them and so why did you think it was not working we thought it was not working because we didn't have quite the right algorithms we didn't require the right objective functions I thought for a long time it's because we were trying to do supervised learning where you have to label data and we should have been doing unsupervised learning where you just learn from the data with no labels it turned out it was mainly a question of scale that's interesting so the problem was you didn't have enough data you thought you had the right amount of data but you hadn't labeled it correctly so you just misidentified of the problem I thought that using labels at all was a mistake you ought to do most of your learning without making any use of labels just by trying to model the structure in the data I actually still believe that right I think as computers get faster for any given sized data set if you make computers fast enough you're better off doing unsupervised learning and once you've done the unsupervised learning you'll be able to learn from fewer labels so in the 1990s you're continuing with your research or in academia you are still publishing but it's not coming to a claim you aren't solving big problems when do you start well actually was there ever a moment where you said you know what enough of this I'm gonna go try something else no really I'm gonna go you know sell burgers but I'm gonna figure out a different way of doing this you just said we're gonna keep doing deep learning yeah something like this has to work I mean the connections in the brain are learning somehow and we just have to figure it out and probably there's a bunch of different ways of learning connection strengths the brains using one of them there may be other ways of doing it but certainly you have to have something that can learn these connection strengths and I never doubted that okay so you never doubt it when does it first start to seem like it's working okay you know we've got this I believe in this idea and actually if you squint you can see it's working when did when did that happen okay so one of the big disappointments in the 80s was if you made networks with lots of hidden layers you couldn't train them that's not quite true because convolutional networks designed by Alec are you could train for fairly simple tasks like recognizing handwriting but most of the deep nets we didn't know how to train them and in about 2005 I came up with a way of doing unsupervised training of deep nets so you take your inputs a your pixels and you'd learn a bunch of feature detectors that were just good at explaining why the pixels will Haven like that and then you treat those feature detectors as the data and you learn another bunch of feature detectors that we're good at explaining why those feature detectors have those correlations and you keep learning layers and layers and what was interesting was you could do some math and prove that each time you learned another layer you had you didn't necessarily have a better model of the data but you had a band on how good your model was and you could get a better bang each time another layer what do you mean you had a band on how good your model was okay so you can ask once you've got a model yeah you can say how surprising does the model find this data you showed some data you say is that the kind of thing you believe you notice that surprising yep and you can sort of measure something that says that and what you'd like to do is have a model a good model is one that looks at the data says yeah yeah I knew that yep it's unsurprising okay and it's often very hard to compute exactly how surprising this model finds the data but you can compute a bound on that you can say the the this model finds the data less surprising than this uh-huh and you could show that as you had extra layers of feature detectors you get a model and each time you add a layer it finds the data the bound on how surprising finds the data gets better oh I see okay so that makes sense so you're making observations and they're not correct but you know they're closer and closer to being correct I'm looking at the audience I'm making some generalization it's not correct but I'm getting better and better at it roughly roughly okay so that's about 2005 where you come up with that mathematical breakthrough yeah when do you start getting answers that are correct and what data are you working on your this is speech data where your first step you break this was just hungry digits very simple gauging then around the same time they started developing GPUs and the people doing neural networks started using GPUs in about 2007 aha I had one very good student called Vlad me who started using GPUs for finding roads in aerial images uh-huh he wrote some code that was then used by other students for using GPUs to recognize phonemes in speech uh-huh and so they were using this idea of pre-training yep and after they'd done all this pre training that chunk then just stick labels on top and use back propagation and it turned out that way you could have a very deep net there was pre trained this way and you could then use back propagation and actually worked only sort of beat the benchmarks for speech recognition if initially just by a little bit it beat the best commercial available speech recognition it beat the academic work on speech recognition on a relatively small dataset called timid I did slightly better than the best academic work also work done at IBM and very quickly people realized that this stuff since it was beating standard models that are taken 30 years to develop right with a bit more development would do really well and so my graduate students went off to Microsoft and IBM and Google and Google was the fastest to turned into a production speech recognizer yeah and by 2012 that work that was first done in 2009 came out in Android Android suddenly got much better at speech recognition so tell me about that moment where you've had this idea for 40 years you've been publishing on it for 20 years and you're finally better than your colleagues what did that feel like well back then I'd only had the idea for thirty years correct sorry sir just a new idea it's fresh um it felt really good that it finally got the state-of-the-art on a real problem and do you remember where you were when you first got the revelatory data no no yeah okay all right so you realize it works on speech recognition when do you start applying it to other problems so let me start applying it to all sorts of other problems yep so George Dahl who did the was one of the people who did the original work of speech recognition applied it to I give you a lot of descriptors of a molecule yep and you want to predict if that molecule will bind to something yep tract is a good drug and there was a competition on cargo and he just applied our standard technology designed for speech recognition aha to predicting the activity of drugs when they won the competition so that was a sign that this stuff sort of fairly Universal uh-huh and then I had a student called Ilya sutskever who said you know Geoff this stuff is going to work for image recognition and faithfully is created the correct data set for it yeah and there's a public competition we have to do that and so what we did was take an approach originally developed by Yana car yeah we a student called Alice Khrushchev ski was real wizard could make GPUs do anything programmed the GPUs really really well and we got results that work a lot better than standard computer vision that was 2012 and it was the coincidence I think of the speech recognition coming out in the Android so you knew this stuff could solve production problems right and on vision in 2012 it had done much better than standard computer vision so those are three areas where it succeeded so modeling chemicals speech voice where is it failing the failures only temporary you understand where is it failing for things like machine translation and I thought it would be a very long time before we could do that yeah because machine translation you've got a string of symbols comes in and a string of symbols goes out aha and it's fairly plausible to say in between you do manipulations on strings of symbols right which is what classical AI is yeah actually it doesn't work like that the strings of symbols come in you turn those into great big vectors in your brain these vectors interact with each other right and then you convert it back instead of strings of symbols to go out and if you told me in 2012 yeah then in the next five years we'll be able to translate between many languages using just the same technology recurrent Nets but just the stochastic gradient descent from random initial weights I wouldn't have believed you it happened much faster than we expected but so what distinguishes the areas where it works most quickly in the areas where it will take more time it seems like visual processing speech recognition sort of core human things that we do with our sensory perception there seem to be the first barriers to clear is that correct yes and no because there's other things we do like motor control we're very good at motor control our brains are clearly designed for that yeah and that's only just now on your own that's beginning to Pete with the best other technologies there they will win in the end but they're only just winning now I think things like reasoning abstract reasoning are gonna be therefore kind of last things we learn to do and I think they'll be among the last things easier let's learn to do and so you keep saying that neural nets will win everything eventually well we own your own nets right right anything we can do they can do right but just because humans the human brain is not necessarily the most efficient computational machine ever created well my second there not being so certainly not my human brain it could it there be a way of modeling machines that is more efficient than the human brain philosophically I have no objection to the idea that could be some completely different way to do all this it could be that if you start with logic and you try and automate logic and you make some really fancy fare improver that and you do reasoning and then you decide you're going to do visual perception by doing reasoning yeah it could be that that approach will win it turned out it didn't but I've no philosophical objection to that winning it's just we know that brains can do it right but there are also things that our brains can't do well are those things that neural nets also won't be able to do well quite possibly yes and then there's a a separate problem which is we don't know entirely how these things work right we really don't know how they when we don't understand how top-down neural networks right there's even a core element of how neural networks work that we don't understand all right so we explain that and then let me ask the obvious follow-up which is we don't know how these things work how can those things work okay you asked that when I finished explaining yes um so if you look at current computer vision systems most of them they're basically feed-forward they don't use feedback connections there's something else about current computer vision systems which is they're very prone to adversarial examples you can change a few pixels slightly and something that was a picture of a panda and still looks exactly like a panda to you it suddenly says that's an ostrich obviously the way you changed the pixels is cleverly designed to fool it into thinking it's an ostrich but the point is it still looks just like a panda to you and initially we thought these things worked really well but then when confronted with the fact that they look at a panda and be confident it's an ostrich and you get a bit worried and I think part of the problem there is that they're not trying to reconstruct from the high-level representations they're trying to do discriminative learning where you just learn layers of feature detectors and the whole whole objective is just to change the weights so you get better getting the right answer they're not doing things like at each level of feature detectors check that you can reconstruct the data in the layer below from the activities of these feature detectors and recently in Toronto we've been discovering or Nick Frost's been discovering that if you introduce reconstruction then it helps you be more resistant to have a serial attack so I think in human vision to do the learning we're doing reconstruction and also because we're doing a lot of learning by doing reconstructions we are much more resistant to adversarial attack but you believe that top-down communication in a neural network is how you test how you reconstruct how you test and make sure it's a panda not an ostrich eye I think that's crucial yes because I think if you but brain scientists are not entirely agreed on that correct brain scientists are all agreed on the idea that if you have two areas of the cortex in a visual in a perceptual pathway if there's connections from one to the other they'll always be backwards connections right not necessarily point-to-point but there'll always be a backwards pathway they're not agreed on what it's for right it could be for attention it could be for learning or it could be for reconstruction it could be for three and so you we don't know what the backwards communication is you are building your new neural networks on the assumption that or you're building backwards communication that is for reconstruction into your neural networks even though we're not sure that's how the brain works yes so that cheating no if you're trying to make it like the brain you're doing something we're not sure it's like the brain not at all okay um there's - I'm not doing computational neuroscience that is I'm not trying to make a model of how the brain works I'm looking at the brain and saying this thing works and if we want to make something else that works we should sort of look to it for inspiration so this is euro inspired not a neural model okay so the whole model the neurons we use they're inspired by the fact your ins have a lot of connections they change the strings it's interesting so if I were in computer science and I was working on neural networks and I wanted to beat geoff hinton one thing i could do is i could build in top-down communication and base it on other models of brain science so based on learning not on reconstruct if they were better models then yeah you'd win yep that's very very interesting all right so let's let's move to a more general topic so neural networks we'll be able to solve all kinds of problems are there any mysteries of the human brain that will not be captured by neural networks or cannot for example could the emotion know look so love could be reconstructed by a neural network consciousness can be constructed absolutely once you figured out what those things mean we our neural networks right now consciousness is something I'm particularly interested in I get by fine without it but so people don't really know what they mean by it there's all sorts of different definitions and I think it's a pre scientific term so a hundred years ago if you ask people what is life that it said well living things have vital force and when they died the vital force goes away and that's what be that's the difference between being alive and being dead whether you got vital force or not mm-hm and now we don't think that sort of we don't have vital force we just think it's a pre scientific concept and once you understand some biochemistry and molecular biology you don't need vital force anymore you understand how it actually works and I think it's gonna be same with consciousness I think consciousness is an attempt to explain mental phenomena with some kind of special essence and this special essence you don't need it once you can really explain it then you'll explain how we do the things that make people think we're conscious and you'll explain all these different meanings of consciousness without having some special essence as consciousness right so there's no emotion that couldn't be created there's no thought that couldn't be created there's nothing that a human mind can do that couldn't theoretically be recreated by a fully functioning neural network once we truly understand how the brain works the Sun the inner John Lennon song that sounds very like were you just and you're a hundred percent confident of this no I'm a Bayesian so I'm 99.9% cold okay what is the point one well we might for example it will be part of a big simulation true fair enough okay [Applause] that actually makes me think it's more likely that we are all right so what are we learning as we do this and as we study the brain to improve computers how does it work in Reverse what are we learning about the brain from our working computers so I think what we've learned in the last 10 years is that if you take a system with billions of parameters and you do stochastic gradient descent in some objective function and the objective function might be to get the right labels where it might be to fill in their gap in a string of words well any old objective function it works much better than it has any right to works much better than you would expect you would have thought and most people in conventional AI thought take a system with a billion parameters start them off with random values yeah measure the gradient of the objective function that is for each parameter figure out how the objective function would change if you change that parameter a little bit and then change it in that direction that improves the objective function you'd have thought that would be a kind of hopeless algorithm they'll get stuck and write and it turns out it's a really good algorithm and the bigger you scale things the better it works and that's just an empirical discovery really there's some Theory coming along but it's basically an empirical discovery now because we've discovered that it makes it far more plausible that the brain is computing the gradient of some objective function and updating the weights of strengths of synapses to follow that gradient mm-hmm we just have to figure out how it gets the gradient and what the objective function is but we didn't understand that about the brain we didn't understand the reread it was a theory it was a long time ago people so that's the possibility but in the background there was always sort of conventional computer scientists saying yeah but this idea of everything's random you just learn it all by gradient descent that's never gonna work for a billion parameters you have to wire in a lot of knowledge all right so and we know now that's wrong you can just put in random parameter and everything so let's expand this out so as we learn more and more we will presumably continue to learn more and more about how the human brain functions as we run these massive tests on models based on how we think it functions once we understand it better is there a point where we can essentially rewire our brains to be more like the most efficient machines or change the way we think it's using relation that should be easy but not in a simulation you just thought that if we really understand what's going on we should be able to make things like education work better yes and I think we will yeah I it will be very odd if you could finally understand what's going on in your brain and how it learns and not be able to adapt the environment so you can learn better well that's okay I don't want to go too far out in the future but a couple years from now how do you think we will be using what we've learned about the brain and about how deep learning works to change how education functions how how would you change a class in a couple of years I'm not sure we'll learn much I think it's going to change the education is going to be longer but if you look at it assistants are getting pretty smart map yeah and once the systems can really understand conversations assistants can have conversations with kids and educate them so already I think most of the new knowledge I acquire is comes from me thinking I wonder and typing something to Google and Google tells me think you just have a conversation at acquire knowledge even better and so theoretically as we understand the brain better and as we set our children up in front of assistants mine right now almost certainly based on the time in New York is yelling at Alexa to play something on Spotify probably baby shark you will program the assistants to have better conversations with the children based on how we know they'll learn yeah I haven't really thought much about this it's not what I do but it seems quite plausible to me AHA well we will we be able to understand how dreams work one of the great mysteries yes I'm really interesting dreams I'm so interested I have at least four different theories of dreams so a long time ago there were things cool okay a long time ago they were hot networks and they would learn memories as local attractors and hopfield discovered that if you try and put too many memories in they get confused they'll take two local attractors and merge them into an attractor sort of halfway in between then Francis Crick and Graham mitchison came along and said we can get rid of these false minima by doing unlearning so we turn off the input we put the neural network into a random state we let it settle down when we say that's bad change the connections so you don't settle to that state and if you do a bit about it we'll be able to store more memories and then Terry Sinofsky and I came along and said look if we have not just the neurons where you storing the memories but lots of other neurons - can we find an algorithm that will use all these other neurons to help you store memories when it turned out in the end we came up with the Boltzmann machine learning algorithm and the Boltzmann machine learning outcome had a very interesting property which is I show you data that is I fix the states of the observable units and it sort of rattles around the other the other units until it's got a fairly happy state and once it's done that it increases the strengths of all the connections based on if two units are both active it increases the connection strength that's called kind of hebbian learning but if you just do that the connections just get bigger and bigger you also have to have a phase where you cut it off from the input you let it rattle around and settle into a state is happy with so now it's having a fantasy and once it's had the fantasy you say take all pairs of neurons that are active and decrease the strength of the connection so I'm explaining the algorithm to you just as a procedure yeah but actually that algorithm is the result of doing some math and saying how should you change these connection strengths so that this neural network with all these hidden units finds the data unsurprising and it has to have this other phase that said this what we called the negative phase when it's running with no input and it's canceling it's unlearning whatever stated settles into it now what Crick pointed out about dreams is that we know that you dream for many hours every night and if I wake you up at random you can tell me what you were just dreaming you're back because in your short-term memory so we know your dream for many hours but in the morning you wake up you can remember the last dream but you can't remember all the others which is lucky because you might mistake them for reality so why is it that we don't remember our dreams at all and Crick's view was it's the whole point of dream is to unlearn those things so you put the learning rule in Reverse and terry Sinofsky and i showed that actually that is a maximum likelihood learning procedure for multiple machines so that's one theory of dreaming you showed that theoretically yeah we showed directly that's the right thing to do if you want to change the weights so that your big neural network finds the observed data less surprising and I want to go to your other theories but before we lose this thread you've proved that it's efficient have you actually set any of your deep learning algorithms to essentially dream right study this image data set for a period of time resort study it again resources a machine that's running continuously so yes we had machine learning outcomes some of the first algorithms that could learn what to do with hidden units were Boltzmann machines okay they were very inefficient but then later on I found a way of making them approximations to them that was efficient and those were actually the trigger for getting deep learning going again those were the things that learned one layer feature detectors at a time and it was a phishing form of a restricted Boltzmann machine and so it was doing this kind of unlearning but rather than going to sleep that one would just fantasize for a little bit okay after each data point so androids do Dream of Electric Sheep so let's go to theories two three and four okay theory to was called the wake-sleep algorithm and you want to learn a generative model so you have the idea that you're going to have a model that can generate data it has layers of feature detectors and it activates the high level once in the low level once and so on until it activates pixels and that's an image you also want to learn the other way you don't want to learn to recognize data and so you're gonna have an algorithm that has two phases in the wake phase data comes in it tries to recognize it and instead of learning the connections that is using for recognition it's learning the generative connections so data comes in I activate the hidden units and then I learned to make those hidden units be good at reconstructing that data so it's learning to reconstruct it everywhere yeah but the question is how'd you learn the for connection so the idea is if you knew the forward connections you could learn the backward connections because you could learn to reconstruct yeah now it also turns out that if you knew the banquet connections you could load the four connections because what you could do is start at the top and just generate some data and because you generated the data you'd know the states of all the hidden layers and so you could learn the four connections to recover those states so that will be the sleep phase when you turn off the input right you just generate data and then you try and reconstruct the hidden units are generated the data okay and so if you know the top-down connections you'd learn the bottom-up ones if you know the bottom-up ones you can learn the top-down once and so what's gonna happen if you start with random connections and try doing both alternate both kinds run and it works now to make it work whether you have to do all sorts of variations on it but it works all right bad as you want to go through the other two theories we only have eight minutes left I think we should probably jump through some other questions well do give me another hour I could do the other tooth all right well Google i/o 2020 so let's talk about what comes next so where is your where is your research headed what problem are you trying to solve now I'm the main thing I'm trying to solve which I'd be doing for a number of now I shown reminded of a soccer commentator you may notice sucking carbon teachers they always say things like they're doing very well but they always go wrong on the last pass and they never seem to sort of notice anything funny about that okay a bit circular so I'm working eventually you're going to end up working on something that you don't finish and I think I may well be working on the thing I never finished but it's called capsules and it's the theory of how you do visual perception using reconstruction and also how you route information to the right places and the to motivating factors to main motivating factors were in standard neural Nets the information the activity in a layer just automatically goes somewhere you don't make decisions about where to send it the idea of capsules was to make decisions about where to send information now since I started working on capsules some other very smart people are googling invented transformers which are doing the same thing they're deciding where to route information right and that's a big win the other thing that motivated capsules was coordinate frames so when humans do vision they're always using coordinate frames and if they if they impose the wrong coordinate frame on an object they don't even recognize the object so I'll give you a little task imagine a tetrahedron it's got a triangular base and three triangular faces or like right four triangles easier to imagine right now imagine slicing it with a plane so you get a square cross-section that's not so easy right every time you start you get a triangle it's not obvious how you get a square it's not at all obvious okay but I'll give you the same shape described differently I need your pen imagine the shape you get if you take a pen like that another pen at right angles like this and you can make all points on this pen to all points on this pen that's the solid tetrahedron okay you're seeing it relative to a different coordinate frame where the edges of the tête region these two line up with the coordinate frame and for this if you think of the Tetra from that way it's pretty obvious that at the top you'll get a long rectangle this way but the bottom you get a long rectangle that way and there's a helical Weierstrass I said you've got to get a square in the middle so it's pretty obvious how you could slice it to give a square but that's only obviously if you think of it with that coordinate frame so it's obvious that for humans coordinate frames are very important for perception and they're not at all important for complex for complex if I show you are tilted Square and an upright diamund we're actually the same thing they look the same to a conflict it doesn't have two alternative ways of describing the same thing but how is adding coordinate frames to your model not the same as the error you were making in the 90s or you were trying to put rules into the system as opposed to letting the system be unsupervised it is exactly that error and because I'm so adamant that that's a terrible error I'm allowed to do a tiny bit of it uh-huh it's sort of like Nixon negotiating with China actually that puts me in a bad role anyway so if you look at continents they just neural nets where you widen a tiny bit of knowledge you aren't in the knowledge that of a feature directly as good here it's good over there and people would love to wire in just a little bit more knowledge about scale and orientation but if you do it in the obvious way of having a 4G grid instead of a 2d grid the whole thing blows up on you but you can get in that knowledge about what viewpoint does to an image by using coordinate frames the same way they do them in graphics so now you have a representation in one there when you try and reconstruct the parts of an object in the layer below when you do that reconstruction you can take the coordinate frame of the whole object and multiply it by the part whole relationship to get the coordinate frame of the part and you can Y that into the network you can wire into the network the ability to do those coordinate transformations and that should make it generalized much much better it should be the networks just find viewpoint very easy to deal with current neural networks find viewpoint other than translation very hard to deal with so your current task is specific to visual recognition or it is a more general way of improving by coming up with a rule set of coordinate frames okay could be used for other things but I'm really interested in the use for visual recognition okay last question I was listening to a podcast you gave the other day and in it you said that the people whose ideas you value most are they young graduate students who come into your lab because they aren't locked into the old perceptions they have fresh ideas and yet they also know a lot is there anything that you sort of looking outside yourself you think you might be locked into that a new graduate student or somebody in this room who came to work with you would shake up yeah everything I said take out those coordinate units work on a feature 3 work on future for everyone we'll ask a separate question so deep learning used to be a distinct thing and then it became sort of synonymous with the phrase AI and then AI is now a marketing term it basically means using a machine in any way whatsoever how do you feel about the terminology as the man who helped create this well I was much happier when there was a army which meant your logic inspired and you do manipulations on symbol strings and there was neural nets which mean you you want to do learning in a neural network and they were completely different enterprises that really sort of didn't get along too well and fought for money that's how I grew up and now I see sort of people who spent years saying your electrics a nonsense saying I'm an AI professor so I need money so you your field succeeded kind of eight or subsume the other field which then gave them an advantage and asking for money which is frustrating yeah now it's not entirely fair because a lot of them have actually converted right okay wonderful well then I'm got time for one more question so in that same interview you were talking about AI and you said I will think of it like a backhoe backhoe that can build a hole or if not constructed properly can wipe you out and the key is when you work on your backhoe to design it in such a way that it's best to build a hole and not to caulk you in the head as you think about your work what are the choices you make like that um I guess I would never deliberately work on making weapons I mean you could design a backhoe that was very good at knocking people's heads off and I think that would be a bad use of a backhoe and I wouldn't work on it all right well Jeffrey gives an extraordinary interview all kinds of information we'll be back next year to talk about dreams ferries 3 and 4 that's so much fun thank you [Music] you [Music] 