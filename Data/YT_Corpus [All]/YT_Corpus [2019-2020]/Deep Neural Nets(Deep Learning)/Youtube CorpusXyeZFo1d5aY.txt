 in this video we will discuss wavelets scattering transform and how it can be used as an automatic robust feature extractor for classification we will cover the working of the wavelet scattering technique for signals but the same technique can also be applied to images wavelet scattering is best understood in the context of deep convolutional networks or deep cnn's which some of you may already be familiar with at a high level deep convolutional networks filter the data apply some non-linearity and pool or average the output these steps are repeated to form the layers there are a few challenges with deep cnn's first these models typically require large data sets and significant computing resources for training and evaluation second typically you must choose many settings for your networks which do not independently affect performance lastly it can be difficult to understand and interpret the features that are extracted now that you have this background let us see how wavelet scattering addresses these challenges the motivation behind using wavelet scattering networks is to start with a set of known filters since the filters in fully trained networks often resemble wavelet like filters the main difference here is that the filter weights are learnt in the case of convolutional neural networks while the filter weights are fixed in the case of wave light scattering networks now let's dive into the details of the network an input signal is first average using wavelet low-pass filters this is the layer 0 scattering features with the averaging operation you lose high-frequency detail in the signal the details lost in the first step are captured at the subsequent layer by performing a continuous wavelet transform of the signal to yield a set of Skellig Ramco efficient it's a nonlinear operator in this case a modulus is applied on the scaler gram coefficients and then the output is filtered with the wavelet low-pass filter yielding a set of layer 1 scattering coefficients the same process is repeated to obtain the layer to scattering coefficients meaning the output of the scalar gram coefficients in the previous layer becomes the input to the operations in the next layer then we apply the same modulus operator and filter the output with the wavelet low pass function to yield the layer 2 scattering coefficients you can have more than three layers in the scattering Network but in practice the energy dissipates with every iteration so three layers are enough for most applications the coefficients are typically downsampled to reduce the computational complexity of the network these coefficients are collectively referred to as the scattering features you can also visualize and interpret these features a wavelet scattering network is referred to as a deep network because it performs three main tasks that make a deep network convolution non-linearity and pooling in this case convolution is performed by wavelets the modulus operator serves as the non-linearity and filtering with wavelet low-pass filters is analogous to pooling this way you can use the features obtained from the wavelet scattering networks and build models that can classify your data for more information and examples please refer to the documentation section of wavelet toolbox 