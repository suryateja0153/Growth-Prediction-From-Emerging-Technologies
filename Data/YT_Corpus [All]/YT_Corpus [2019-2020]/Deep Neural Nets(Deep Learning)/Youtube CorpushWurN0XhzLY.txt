 hello welcome to a continuation of my series on convolutional neural networks in ml5.js the last time i recorded one of these was february 24th 2020 it is now uh october 2020 i would like to keep this mask on for the entire recording of this video but i cannot because it plugs up my glasses and i can't see anything and fortunately i'm in a hermetically field room here by myself uh where it is safe for me to take off my mask so i'm sorry that it took me so long to get to continue this series but i'm very excited to do it with you today i kind of spent the last half an hour like re-watching this video and getting myself centered to where i am and where i want to pick up with now in this video tutorial the first thing i want to highlight for you is that i made a couple errors in the previous video when i was discussing how the resolution changes from layer to layer within a convolutional neural network i was kind of off by one or two or maybe by a power of two here and there thank you to return exit success who eight months ago pointed out that that 28 by 28 image actually becomes 26 by 26 when the 3x3 filter is passed over it leaving out all the edge pixels in the new processed image additionally luis points out here that the resolution the total number of pixels is reduced by a quarter not by a half because if the width is reduced by half and the height is reduced by half the pixels being the width times the height are reduced by one quarter thank you for saying i'm awesome too i mean i don't know it's nice that's nice i appreciate it when i watched the video again this morning i discovered that i promised some things at the end and so i'm here to deliver on that promise and the first thing that i'm going to do is take the example from train a neural network with pixels which didn't use convolutional layers and update that example to have convolutional layers and just look at how the code is different and see if it performs differently at all as a reminder of what this example does is this takes a low resolution 10 by 10 uh image from the webcam and i've already trained the model to recognize it as label a when i'm standing in front of the camera and label b when i move away from the camera so ultimately this kind of simple binary classification with very clear distinctive images works fine without the convolutional layers but let's try something a little bit more sophisticated could we perhaps get it to recognize whether i'm wearing my mask or no mask and let's add convolutional layers to this example and see how that works i should also quickly mention that there have been some updates to the ml5 library since the last time i recorded and you'll want to make sure you have version at least 0.6.0 that's the version i'm using for this particular demonstration the first step for adding convolutional layers to your ml5 neural network is to change the task so the task that i'm going to specify is image classification i should probably point out that convolutional neural networks are not limited to working with images they're super effective for lots of other kinds of data and i'd certainly like to get into that at some point and look at some other examples but a primary use case is image classification ml5 knows how to work with images so this is kind of our starting point so the the terminology the friendly term if you will to having convolutional layers in your ml5 neural network is specifying the task as image classification other thing i need to do is be much more specific about the input data here so with a regular neural network in ml5 it was just about the number of inputs were the three were there 104 whatever number you might pick based on your data here i'm going to be sending in images so i need to tell ml5 what are the dimensions of the image width and height and how many channels does the image have is it an rgb or rgb alpha image is it a grayscale image and in working in p5 generally uh it's going to be a well it's up to me to specify the resolution of the image in this case it's 10 by 10 let's up that resolution to 64 64 by 64. so i'm going to say in an array 64 comma 64 comma 4 because the pixels of the images that i'm going to pass in have red green blue and alpha values ultimately here the alpha information is useless because i don't have any transparency in the images so i might want to filter that out but i'm not going to worry about that right now i'm just going to let it be 64 by 64 with four channels i'm noticing here that it says outputs three and i kind of don't remember why that's there um i probably when i was doing this the last time i knew in my head like oh i'm gonna have three labels three possibilities but actually ml5 will quite nicely uh figure out how many outputs there are in term if if it's a classification problem based on the data itself so i'm just going to take that out and i've got inputs image classification and debug set to true because i want to see the graph of the loss as it's going now if you recall i put almost no thought into the data collection interface there is no interface when i press the key a that's saying these images are a label a when i press the key b these images are labeled b so i'm going to keep that model but i do need to now adjust this add example function the nice wonderful thing about the fact that i've specified it as an image classification problem is ml5 knows how to work with p5 images or or raw pixel data both are possible but i'm just gonna since i have a p5 image i'm going to use the p5 image so rather than have to loop through all the pixels and kind of normalize the data myself i could do something much more simple so i'm actually going to remove all of this processing of the pixels and the input itself which is really a single input image i'll call it input image is i need to make it an object and the property i'll just name it image and the image that i want to send in is the video itself then for the target the training target i'm going to also just be consistent and make this an object called label uh and that will actually be the label itself one of the nice things by the way i can do in javascript here is what i'm creating these object literals i want to have a object with property image and value video here the property name happens to be the variable name of the value so i can use an enhanced object literal just makes the code a little bit shorter and cleaner and i can just say target equals curly brackets with label inside so now i just need to change this inputs to input image and i now have my data that i'm using to train the model is the video image itself as well as the target label both wrapped into objects i also need to do the same thing in the classify video function because that's where i'm also sending an image into the model for a prediction so i can actually just remove this entire bit of code and replace it with that same object literal and pass that in all right i'm going to try to run this i'm really not so confident it's going to work and there's more that i want to say about this a couple things i want to add to this example and then there's going to be another video where i think it would be a really excellent demonstration to show a use case where i've collected essentially a database of images that i want to use to train the model but let's let's just run this and see what happens okay well first of all i'm seeing the uh image being drawn by 64 by 64. let me change the way i'm drawing the image i don't think i need to draw every single pixel individually as a rectangle here in this use case so i'm going to take this out and just draw the video itself and stretch it out over the width and height of the canvas it's important to realize that i've actually still set the image to be 64x64 so that's what's actually being passed into the machine learning model here but we're seeing a higher resolution version of the image stretched out over the canvas i'm going to try exactly what i did before which is every time i press the key a i get a new training image with label a [Music] now i'm going to step away and give it a bunch of training images with label b and then when i press t it trains the model that didn't seem to work so well so this i'm glad that happened because this is inevitably going to happen to you something went wrong because the loss is not going down in fact the loss is like above between four and five which are very high numbers for a loss so i was just doing some debugging to try to figure this out and i downloaded the data the ml5 neural network saves the data from your training data set and i looked at it and i thought oh i forgot to normalize the data so all of these numbers are all pixel values between 0 and 255 which makes sense that's the way pixels are stored in p5.js but i need them to be normalized between a range of 0 and 1 for the neural network to work so right before i train the model i need to add one line of code to normalize the data so i'm hoping this fixes it but it remains to be seen [Music] i could have reloaded the date i saved previously but i'm just doing it again just to do it again [Music] i say my model training prayer and then i press t ah that's a loss function i like to see a b a b so there's a live chat going while i'm recording this right now and the question comes up can't you add the normalizing layer and so first of all the normalizing normalizing data is not a layer of the neural network it's sort of like a pre-processing step and that could be something that ml5 just always does by default but there are some cases where you don't want to normalize the data or you want to normalize the data in your own way and so that's explicitly something you do have to call it ml5 that's an interesting question whether or not ml5 the library itself should change the way it works but for now i do have to call it so this worked and ultimately it's the same exact result of what i had in the previous video so why are we even here so i would like to make the case for you why you might want to use the convolutional neural network uh functionality in ml5 beyond just the regular neural network stuff so one is that it's my suspicion here that if i gave it a much harder problem more complex images with less obvious distinctive differences to classify that the convolutional neural networks are going to perform better this was such an easy case of like am i standing in front of the camera or not it's only two classes so we're not really seeing a difference so i might try it with my mask that might be a slightly harder problem the other thing you might be wondering is well why are we even doing this when we had this whole system about transfer learning i mean after all this is basically exactly the examples from the teachable machine videos well in truth if what i wanted to do was quickly whip up an image classifier that's like recognizing some gestures and movements i'm in front of the camera or not from the camera or a particular object using transfer learning and teachable machine will get me probably better more accurate results more quickly but there are a couple reasons why you might not want to go that route one is maybe you don't want your model to be based on any pre-existing model or data set um you don't want to use mobilenet model that which was trained on the imagenet database as part of what you're doing also maybe the images you're using really have nothing to do with the sort of everyday objects that the mobilenet model was trained on so for example if you're trying to recognize drawings or circuits or some kind of obscure specific design pattern that's not something you see like scissors and phones and remote controls and coffee cups right then that transfer learning approach isn't going to really help you because the data of the of the pre-trained model that you're basing on does not match your current data and that's what i'm going to show you in the next video where i want to look at doodles and shapes and other kinds of data that just aren't sort of photographic images from everyday life but here let's just make the case that this is going to work a little bit better and let's see if i can get it to work do the mask and no mask so let's add some more specific labels here in the key press so if i press the key m then i'm going to add an example with the label mask [Music] and actually the labels this is a little bit silly like but because i could just like code it to like say a message when it sees a certain label but the labels could be just any arbitrary string so the label is going to be nice mask for when i'm wearing it and keep other safe wear your mask for when i'm not wearing it all right let's see if we can get this to work so let's first do the no mask now on with the mask [Music] all right hopefully that's enough data let's train the model wow that's some wacky loss but looks like it figured it out [Music] hey it likes my mask oh oops i didn't really think about the design here okay i uh fixed the layout so now it will tell me to put on my mask uh if i am not wearing it so here i am wearing my mask sitting at my computer and i take it off and it tells me to run so this is great our convolution neural network there's no transfer learning there's no base model this was all done in the web browser in p5.js with ml5 amazing ah all right before i go from this video i want to just return to this model summary panel in the debug view when you're training the model so this is ordinarily like the part that i maybe try to stay away from a little bit the model architecture the lower level details but i think it's really important to make the connection between these layers and the diagrams that i showed you in the previous two videos about what is a convolutional neural network and we can see right here the convolutional layers the pooling layers um and then the flattening the flat layer and the final output label and you can see that there's two outputs because there's a probability confidence score for mask and one for no mask so that would be a higher number if there are more categories but this is the default architecture that ml5 will make when you say image classification and it's actually possible for you to configure this yourself to say how many convolutional layers you want to say how how big you want the kernel the filter kernel to be how do you want to do pooling what is your stride all of those parameters that i mentioned in the previous videos are configurable here so if this isn't working for you or you just want to play an experiment let me show you how to do that in the ml5.js reference you'll find a section under neural network for defining custom layers and this is where you can actually configure individually the number of layers and what those layers do in an ml5 neural network so this is the default set of layers for classification the default set of layers for regression and i want to look down here at this default image classification layers all you have to do is create an array called layers fill that array with objects that include the various details for each layer so let me copy this to the clipboard go back to my code and i'm going to right here in setup right before options i'm going to paste that in so now i have a variable that's holding on to the custom layer configuration and i'm going to go down to my ml5 neural network and i'm going to add a property layers custom layers so here i have the input dimensions the task that i'm doing i want to debug it while i'm training and now the custom configuration for the layers and i could start to experiment with this and you can see here in this array my first layer is a convolutional layer i want to have eight filters a kernel size of five and a strides of one i haven't talked too much about activation functions and what's this kernel initializer so these are i'll try to put some resources in the video's description where you can read up more about some of these other properties that you could experiment with but again this is the size of max pooling maybe what would happen if i did it three by three and change the number of strides along the x and y axis and you can see one thing there's two the thing i think that's important for me to point out is there are two convolutional layers and as the resolution is decreasing the number of filters is increasing not a blanket rule but that's one way to approach this approach architecting your model um trial and error is your friend here experimentation uh talking to somebody else who knows about convolutional neural networks or has tried it before to get some advice about what might work well for you and your particular scenario i encourage you to experiment with that leave your feedback and things you tried in the comments and in the next video i am going to look at a convolutional neural network that is trained off images of shapes squares circles and triangles so that i could create something where maybe i'm drawing on a piece of paper and the neural network guesses did i just draw a circle a square or a triangle and then later i'm also going to show you some pre-trained convolutional neural networks that are in ml5 like doodlenet which is trained on a whole lot of drawings from the google quick draw data set to recognize various kinds of doodles and these are scenarios where using your own convolutional neural network really makes sense because it's the kind of data that we're working with drawing and shapes and abstract geometry isn't something that the original mobilenet model image classification model was trained on so transfer learning doesn't necessarily apply and also there are some reasons why you might want to train your model from scratch with only your own data and you have a real sort of control and understanding of how that data was collected and how that model is being used as opposed to a situation where you're doing transfer learning and basing your model off of a pre-trained model that you might not know as much about okay so i hope i'll see hope that next video won't take a year to come out uh but who knows what's coming next in 2020 into 2021 i hope good things for you and i will see you in a future uh ml5 uh video if you're watching this in years into the future well there's a little bit of history for you history lesson i don't know what i'm what i'll be doing or what you're doing but i i'm glad that you're here and then i'm here with you in this sort of virtual mediated way all right see you soon goodbye [Music] you 