 hi everyone i hope you're doing well i'm hiki park from georgia tech i'm very excited to present bluff a visualization tool to interactively decipher adversarial attacks on demure networks team learning is now commonly used in many domains for example in the medical field the learning models can estimate the treatment effects on patients on the road we can see self-driving cars using computer vision technologies however deep learning models are vulnerable to adversarial attacks an adversary attack applies carefully crafted perturbations on data inputs and fills a model into making incorrect predictions adversary attacks zebra dyes many deep learning based technologies especially in security and safety critical applications such as data-driven healthcare and self-driving cars due to the threats of the adversary attacks people cannot confidently use deep learning models to overcome the vulnerability of deep learning models we need to understand how the adversarial attacks permeate the modal's internals also for a better understanding about adversarial attacks it would be worthwhile to examine if and how an attack strength changes how the model produces incorrect predictions for example it would be useful to know if a stronger attack exploits the same neurons as a weaker attack does or if those sets are completely different we present bluff an interactive visualization tool for discovering and interpreting however certain attacks mislead dnn into making incorrect predictions our main idea is to visualize activation pathways within a dnn traversed by the signals of input data for given input data an activation pathways consist of neurons that are highly activated and the most influential paths activation pathways represent what features are detected and how those features are related to contribute to the final prediction to understand how the attacks manipulate the neurons and the paths inside the models bluff visualizes the activation pathways of nine inputs and attacked inputs that is bluff finds and visualizes the most activated pathways given benign and attack input data love also visualizes the most inhibited paths by the attack to uncover where the attack is blocking the signals to the b9 path also block visualizes the most excited paths by the attack to uncover where the attacks stimulate to induce the activation pathways going towards wrong directions the blood interface tightly integrates three coordinate views it consists of control sidebar graph summary view and detail view here a user inspects why a deem learning model must classify as adversarial giant beta images crafted by the projected gradient descent attack as armadillo in the main graph summary view we visualize the activation pathways of benign and attack input data here each vertex represents a neuron when hovering over a neuron bluff shows the detailed information of the neuron the detailed view for a neuron shows a feature visualization and example data that visualize what feature the neuron is detecting for example for giant panda images this neuron looks for face of animals that have white furs and dark eyes feature visualization is a synthesized image that maximizes the corresponding neurons activation data set examples are patches of images from the training data that highly activate the corresponding neurons we also show how the neurons median activation to change according to different attic strings here in the graph summary view the neurons are represented with different colors based on their roles the green nodes are the most important neurons only for the original class giant panda which means they are highly activated by benign giant panda images the blue nodes are important neurons only for the target class armadillo the orange nodes are the most important neurons for both original and target classes giant panda and armadillo the red nodes are the neurons that are highly activated by only successfully attracted images these neurons are exploited by the attack to induce the incorrect prediction by exploring the activation pathways pjd successfully perturbed pixels to induce the brown bird features an appearance more likely shared by an armadillo than a pena both armadillo and brown birds have small roundish and brown bodies the brown burn neuron then contributes to the armadillo mist classification by activating more features such as scales bumps and mesh by using the options in the contour side bar users can interactively filter the neurons and connections to visualize for example they can select to visualize our graph or only highlighted neurons or only pinned neurons by using the highlight pathways options users can select which activation pathways to visualize such as most activated or most inhibited excited or modest changed by the attack by using the comparison mode users can compare how attacks of different strings have different activation pathways in summary we developed bluff an interactive system to understand how adversarial perturbations fall on the learning model blood visualizes most activated inhibited excited activation pathways after the attacks and provides flexible comparison of attack escalation thank you all for listening i'm happy to take any questions 