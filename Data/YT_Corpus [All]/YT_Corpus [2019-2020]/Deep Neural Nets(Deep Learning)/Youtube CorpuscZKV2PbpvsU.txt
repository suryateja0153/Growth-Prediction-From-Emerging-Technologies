 hello my name is Hopkin lead the first author of the effective white box testing of deep neural networks with adaptive unit selection strategy which is corked with 3m chop finely and up to all thank you for coming to my session in this talk I first discussed the over contents of our work and explained our approach and wizards in detail team neural networks are used in many different places such as music generation hardware design and computer programming some safety critical domains like self-driving car also use Eve neural networks as their core components then the question is are deep neural networks safe enough no these two photos shows the car accident in u.s. caused by self-driving cars post accident was caused by his failure in object detection the left cord fail to recognize the trailer-truck and the right car fail to recognize the pedestrian as a result there are human fatalities in both accidents to prevent such reward excellence demands for testing the neural networks is rapidly increasing the objectives of Team neural network testing or to explore different states of the networks and detect unexpected behaviors before deep neural networks cause any problems in real world as in traditional software testing coverage metrics should be used to define the states of in neural networks however coverage metrics for traditional software testing such as branch coverage or code coverage are not sufficient for distinguishing different states of deep neural networks therefore a lot of new coverage metrics that are specialized for deep neural networks have been proposed since 2017 to the previous slide our objectives of deep neural Nets of testing can be rewritten as to increase coverage and find adversary inputs which are inputs that might cause unexpected behaviors testing techniques that focus on these objectives can be widely classified into gray box testing techniques and white box testing techniques both testing techniques use coverage metrics as their core components the difference is that how to generate the inputs in order to increase the coverage gray box testing techniques is a testing techniques that only use the outputs of the deep neural network on the other hand white box testing techniques utilize the rates and value of internal neurons to generate inputs both approaches have pros and cons but we chose to focus on white box testing techniques because it is easy to generate inputs that can explore the certain state of deep neural networks white box testing is a testing technique that uses the gradient to generate inputs the first step of testing is to select the neurons in the deep neural network then calculate the gradient of the neurons with respect to the input and finally add the gradient to the original input to generate next input the gradient edit will help increase the values of selected neurons since gradient calculation is state for the key component of white box testing is how to select neurons well that might increase the coverage there are a few researches that proposed so called neuron selection strategies for example the Explorer suggested to select two neurons that are never covered before and the Air Force adjusted for different neuron selection strategies including a strategy that selects most frequently covered neurons however existing techniques like team Explorer or the airforce use you know selection strategies regardless of networks data set or metrics and we observed that using fixed urine selection strategies can lead to suboptimal results these two graphs shows the result of testing the net v model with different coverage metrics in the left graph deerforce which is drawn in scion line achieved higher neuron coverage compared to the death of my random strategy which is drawn in popper on the other hand in case of Cup Canyon coverage as you can see in the graph in the meter random outperformed the deer Falls moreover this instability gets even worse when the models are changing when it comes to 3gg PFOS defeats random strategy again and get between two lines get even larger this indicates that urine selection strategies should be adaptively tuned for the even testing setting therefore in our paper we propose a tool called adept which adaptively learn and generate your own selection strategies with respect to the given coverage metric data set and models in order to implement adapt we first define the space of the neuron selection strategies by parameterizing them and design our online learning algorithm that find good neuron selection strategies in the defined space in wizard adept show dream October increase in both your own coverage and obtain your own coverage compared to the existing techniques which are using fixed unit selection strategies in our for graph adepts which is drawn in blue line rank in the first place regardless of models and coverage metrics moreover our depth is also effective in finding adversary inputs these images are the adversary images found by adults that no other existing tool could find you can see that found images are not different from the origin ones especially in imagenet data set you can barely see the difference between the original ones and the generated ones even if you see the images in their original size PGG classifies the first image on the right hand side into cowboy hat and ResNet classify the second image into spider monkey while human might think all three images are photos of a cute puppy from now on I will explain the approach and result of our work in detail our idea is to generate adaptive you know selection strategies with respect to the given coverage metrics models and latencies to generate the neuron selection strategies we need a space of them therefore we first define the space of the neuron selection strategies by paralyzing them in this system one unit selection strategy is represented as one real number vector which weights the features which will be defined in the following slide for example two different vectors s1 and s2 in the slide represent different unit selection strategies since they have different weights on each feature therefore finding a good unit selection strategy is equivalent to finding a good real number vector in this system using the vectorized general selection strategies unit selection is done by scoring them to score the neurons the first thing to do is prep recent runs as feature vectors we design 29 atomic features where each of them is a boolean predicate on the neurons these features can be classified into 17 constant features which are not changed during testing and 12 parry features which are continuously changing as testing goes on we design each feature by considering the characteristic of the layers and neurons these 29 features will represent the different states of the neurons with boolean vectors based on the feature and a neurodivergent strategy each neuron can be scored with the dot product of each feature vector and this election strategy finally journals with top k values are selected if we choose K neurons in this example neurons are presented with 50 million brilliant vectors and a strategy is a 5 dimensional random vector each neuron is scored by the dot products and neurons that scored as 7 and 6 are selected if we select two neurons in a past few slides we have defined the infinite space of neuron selection strategies based on the space defined we design an online learning algorithm to find good urine selection strategies we design the algorithm that adaptively find unit selection strategies during testing procedure based on the genetic algorithm the whole procedure has two phases which are testing phase and learning phase and learning phase is done in two stages which are extract stage and combined stage the first phase is testing phase in the testing phase documented neural network is tested using mu n selection strategies generated in the learning phase except for the first iteration in the first iteration that testing phase cannot get strategies from learning space testing is done with M randomly sampled during selection strategies not depth or neuron selection strategies here or parameterized neuron solution strategies that described previously after testing phase is done during selection strategies instead of covered neurons for each strategy or test to extract stage of learning phase in extract stage K could neuron selection strategies are extracted from the past few testing wizard with two criteria first criteria is to collect the neuron selection strategies that collectively achieve the highest coverage in this example as trainers for in the blue box are extracted since they can cover all the needles that other strategies covered in case that the number of extracted strategies with first criteria is smaller than K strategies that sorely achieved the high coverages are additionally collected in this example as to in the green box is additionally collected since it's only achieved the highest coverage note that s2 is collected twice and this will wait as to more than other strategies in the next stage in combined stage new neuron selection strategies are generated in four steps first tooth strategies or randomly Sentret let's stop soon as two ns for our Center next generate a new strategy by mixing input strategies as v is newly generated by mixing s 2 and s 4 you can see that first and last elements of s 5 comes from S 4 and second elements of s 5 comes from its 2 then add a small noise for exploration and normalize the generated your selection strategies to keep each elements of it in a proper range finally repeat these steps to generate a mirror there are some strategies and aspect to testing phase the iterations continues by alternating each phase until the time body is expired as the testing goes on a learning phase will fine-tune the strategies to cover more neurons based on the testing regions in order to show the effectiveness of others we design 8 experiments with 2 coverage metrics two data sets and two models for each data set and we used 20 randomly chosen images or small models and 10 randomly chosen images for large models we compared adept with five existing testing techniques which are my random strategy that selects urine randomly to explore two versions of tears was including round-robin strategy and tensile force as a representative of great box testing odep showed remarkable increase in coverages in our eight experiments left photographs showed achieved Neron coverages and right four graphs showed a chipped up Canyon coverages in our egg cracks adept which is grown in blue lines achieved the highest coverage in testing vgg with urine coverage a depth was able to cover about 3000 more neurons on average compared to the second best one which is round-robin strategy of TF us our depth is also highly effective in finding adversarial inputs as you can see in the table that was able to find more adverse really puts compared to the other testing techniques not only the number of the founded were three inputs adept was also able to find more diverse labors compared to the other testing techniques plus as you can see in the Venn diagram in the patent Labor's found by other to almost covers the labor is found by other testing techniques while analyzing the resort we could confirm that other tip unit selection strategy is important this graph shows the important features of these collective strategies in extract stage while testing each more tests with neuron coverage red colored crashed show the features that selected neurons should have and blue colored graph show the features that is elected neurons should not have the interesting thing is that the feature number four which is the most important features that was elected urine should have been testing the net for then at five hundred and fifty becomes the worst features that the neurons should not have when it comes to vision nineteen similarly feature number two which is the best features for testing which is nineteen comes a features that neurons that should not have in testing other models these learned features by adapt show that the neurons selection strategies should be adaptive to the settings our tour Adept is publicly available through github and dr. hall if you have any interest please visit our github and see how it works we also provide easy-to-follow tutorials that can test the deep neural networks written in tensorflow and carrots in sum up we proposed on adaptive neuron selection strategy for white box testing of neural networks using parameterised neuron selection strategy and adaptive online on in algorithm and showed that the proposed technique is highly effective we have made our tool adept publicly available if you have an interest in our work please visit and see how it works this is the end of my presentation and thank you for listening 