 welcome back to machine learning foundations for Google developers I'm Laurence Moroney from the tense flow team and I'm here to be your guide in the last video you learned all about convolutions and how they can use filters to extract information from images you also saw how to create pools that can reduce and compress your images without losing the vital information that was extracted by the filters in this video you're going to get hands-on and create your own convolutional neural networks so let's get started in earlier videos for the simple neural network for spotting fashion or handwriting digits you defined a model architecture like this you use layers and primarily dense layers for densely connected neurons to use convolutions and pooling you have the con for 2d and max pooling layers like this now they can be stacked on top of your dense network you define a convolution layer with a number of parameters in this case the 64 is the number of filters for this layer remember that the filters will be randomly initialized and then the best filter is to match the pictures to their labels will be learned over time the 3 by 3 is the size of the filter earlier we saw filters for the current pixel and its immediate neighbors that were 3 by 3 and that's what we're defining here as before we have an input shape which is the shape of the images being fed in and that's 28 by 28 with one byte color depth similarly the pooling is done like this with a layer and the 2 by 2 defines the size of the chunks to pool so in this case if 4 pixels will become 1 there's also men pooling average pooling and stuff like that but we'll focus on max pooling here these layers can then be stacked on top of each other so the results of the 64 filters from the top layer will each be pooled and then their results will each be filtered 64 times and they of course will get pooled again so let's take a look at the models summary so we can see how the data is changing as it goes through the network you'll see something like this there's a lot going on here so that's on packet first of all the initial output probably looks weird our images are 28 by 28 and we get 64 filters so we'd expect our output to be 28 by 28 but 26 by 26 now this looks like a bug but it isn't so let me explain why consider a picture like this one of a very sleepy doggy on the Left I've zoomed into the top left of the picture so you can see the pixels now when doing a filter you scan every pixel and take its neighbors but what happens if we pick the top pixel like this it doesn't have any neighbors above it and it doesn't have any to the left similarly the next pixel doesn't have any neighbors on top but it does have some on the left it's not until you get to this pixel that you'll have one that has neighbors on all sides which you can see here so a three by three filter requiring a neighbor on all sides can't work on the pixels around the edges of the picture you effectively have to remove one pixel from the top bottom left and right and this reduces your dimensions by two on each axis so 28 by 28 becomes a 26 by 26 which you can see here each filter will learn 9 values for the filter coefficients plus a bias for a total of 10 parameters so the 64 filters have 640 learn herbal parameters our pooling reduces the dimensionality by half on each axis so 26 by 26 will become 13 by 13 but no parameters are learned on this layer the 3 by 3 filter then reduces 13 by 13 to 11 by 11 by removing a pixel border like before the max pool halves that rounding down so we end up with 5 by 5 images at this point we have 64 filters and the images are 5 by 5 for 25 pixels multiply all that out and you get 1600 which then gets fed into the flatten this set of 1600 values can then be classified with a dense network as before so now that you've seen how the code works let's take a look at a lab that updates your fashioned classifier from last time to use convolutions as well as dense layer types so let's take a look at improving computer vision accuracy using convolutions here's the deep neural network that you've created already for the fashion am-ness data set and we can see that we have flat followed by a dense with 128 neurons followed by another dense with 10 neurons because we've 10 classes when I run this and I'm just going to train for 5 epochs let's see how quick it is and let's see how accurate it is first it needs to download the data and we can see after 5 epochs it's up to about 89 percent accuracy on the test set and a little over 87 normos Tady 8 percent accuracy on the validation set which is really really strong performance considering it's only been 5 epochs so now let's take a look at what will happen with a convolutional neural network so here you can see the model architecture we have our same flattened dense dance that we had earlier but in this case on top of that we have a couple of convolutional layers and these convolutional layers have their associated max pooling layers note that the input shape is 28 by 28 by one because the convolutional layer expects it to be in three dimensions with one dimension for the color depth and that means we have to reshape our training images and our test images arrays they we're 68,000 by 28 by 28 we have to add another dimension onto it 10,000 by 28 by 28 by 1 for the test images with that extra dimension added onto it so now when I run it it's gonna compile it's going to show me the model architecture and it's gonna start training now this is going to be a little bit slower because it's doing a convolutional neural network but if you're running using the GPU runtime change runtime type and make sure you've GPU do that even before you begin and you'll see it's not too bad is five six seconds per epoch and in this case with only five epochs training it's gone up to about 93% on the test data and 91 and change on the validation data so we can see it's actually improved it's a significant step in the right direction so I have a play with it yourself and as you're working through the code lab take a look towards the bottom of the collab where you can visualize the convolutions and pulley to see what they look like and there's also some exercises at the bottom where you can try different things for yourself once you've done with that you'll be ready to take this week's exercise so now you're ready to experiment pause the video and give this lab a try see how far you can get and have fun experimenting with the visualization of the welcome back now that you've had a chance to play with convolutions it's time to do the exercise give the one at this URL a try I'll share the code for the answer next time so don't forget to hit that subscribe button for more great videos and the rest of this series [Music] 