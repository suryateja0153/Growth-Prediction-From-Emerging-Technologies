 Augmented Reality (AR) is a promising technology. But can AR make it safer to navigate large ships? Will AR information actually be useful for the navigators? We will show you a range of examples of   how AR can be used on ships in the future. This is the result of several years of design research   including field studies, prototyping and testing. We have recreated several scenarios in Virtual Reality to explore and demonstrate how  AR could be used by navigators. Let's take a look at an accident   scenario that happened in 2012. The cargo ship Vega Sagittarius departed from   the port of Nuuk, on the west coast of Greenland. Icebergs appeared ahead, so the   vessel had to change its course. The navigators lost awareness of their surroundings. As a result, the vessel ran   aground on an underwater rock. Would this have happened if   the navigators had AR headsets? Imagine you enter the bridge of the Vega Sagittarius. As you enter the work place, an AR panel appears   and adapts to your position on the bridge. In the AR panel you see the most   important information you need. As a result, you don't have to shift your attention   between the environment outside and the screens inside. You approach some icebergs. The system identifies the objects outside   and provides relevant status information. Small symbols above the horizon indicate your course   and heading, providing feedback when the ship turns. As you approach shallow water,   no-go zones are indicated on the ocean surface. Such overlays make it easier to understand how   map-based information connects to the real world. Finally, the system informs you that   you are approaching an underwater rock. In collaboration with the Chalmers University of Technology   we have tested these AR concepts with several navigators. More trials are necessary, but the results so far indicate   that these features could help prevent such accidents. Let's look at other examples of   how AR can be used on the bridge. In this scenario you enter the bridge of a small cruise   ship approaching a large field of ice in Antarctica. On a large, virtual AR screen an ice forecast is presented   to inform you about the conditions ahead. You can draw points on the ocean surface to discuss   with your colleagues which route to take through the ice. The points are presented both outside and on the map. A grid and radar image is overlaid on the ocean,   helping you identify where you are in relation to the ice. As it becomes darker you turn on search lights, which   you control by pointing where you want the light to go. To look at the conditions further away   you use a night vision zoom camera, and see the video feed next to the captured area. In the last scenario, you are on an ice breaker   that is about to rescue a vessel stuck in ice, beforing escorting two vessels in a convoy. When you look at the ship you are approaching, information about distance and the closest   point of approach (CPA) is presented above the ship. You find the same information   in the vessel list in the AR panel. There is also another vessel behind you,   waiting for a convoy to begin. A vector line on the ocean surface indicates   where you will be in 2, 4 and 6 minutes. Walking to the aft bridge, you can see   the ships are lined up behind you. The Icebreaker Assistance app indicates the relative   speed and distance between each of the three vessels. Back at the workstation, the Icebreaker   Assistance app is also part of the AR panel. This makes it easy to monitor the speed   and distances between all the vessels. We use the examples you have seen to create components   and rules for how AR applications on ships should work. The next step is to test these concepts on ships,   and see if they work in real world conditions. Finally, the result will be taken further   in the OpenBridge project, which is an open design system  for maritime workplaces. 