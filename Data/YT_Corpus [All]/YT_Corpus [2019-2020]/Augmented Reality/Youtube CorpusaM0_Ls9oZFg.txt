 We present our work on combining personal Augmented Reality with large interactive displays for information visualization. Our goal is to address typical issues of large displays, like limited perception, managing density and complexity and effectively supporting multiple users by extending the large display with Augmented Reality. To achieve this, we present an extensive design space and several exemplary techniques. We first analyzed the spatial alignment of the display, the visualizations, and objects in AR space. We identified 9 different spatial zones around and in front of the display. The spatial zones can be adjusted to compensate for physical obstacles, such as walls and floors, or other visualizations. We discuss which parts of a visualization can be augmented, such as data marks, links and even whole visualizations to present additional, potentially multivariate data and to allow for personal annotations and tools. Finally, we analyzed how AR can be used to display individual views in order to show personalized information and to minimize the mutual disturbance of analysts. We created u2vis, a data-driven framework for information visualization for Unity, which natively supports Augmented Reality applications. It can be configured completely in the Unity editor, is easily extendable, and available on GitHub. Our prototype consists of two separate Unity 3D applications. One controls the content on the display, while the other one is responsible for the Augmented Reality content. We use a Microsoft HoloLens as AR HMD as well as for tracking and the spatial alignment with the display. The two applications’ state is synchronized by a custom client server solution using TCP and OSC. We further present exemplary techniques building upon our design space and addressing common challenges with large displays. Embedded AR Visualizations use the space in front of data marks or links to incorporate additional, contextualized information. They can have any shape, like lines, bars, or cylinders, and extend orthogonally away from the screen. With large displays, the perception in peripheral areas is problematic. Therefore, we propose to hinge relevant visualizations depending on the user's position to allow users to access and see visualizations that would be normally distorted. As an alternative, the Curved AR Screen technique aims to provide an overview of the entire display. Most of the peripheral screen is transferred into AR onto two curvatures left and right of the user which are influenced by the user's position. Brushing and Linking is a common technique to connect multiple visualizations. We propose to transfer it into AR to achieve user-specific highlights and three-dimensional AR links between related data marks. To gain an overview of complex or dense visualizations, we suggest to show AR extended views directly on the axis of a visualization. Augmented Reality Visualization Layers can be used to show visualizations of the same type in front of and behind the display to allow for superimposed comparison of additional data. Even tools, such as Magic Lenses, can be transferred into AR space, so that each user can personalize them individually and they don't hinder the work of other users. When exploring data, users benefit from annotating visualizations. We propose to move sketches, drawings, and notes into AR space to keep them private and to avoid visual clutter on the display for other users. Many of the presented techniques benefit from being combined with each other, such as links, Hinged, and Aggregated Views. We presented our work combining personal Augmented Reality with large interactive displays for information visualization. On the basis of our experiences, we are convinced that the extension of large displays with AR has great potential for visualization, sense-making, and data analysis. 