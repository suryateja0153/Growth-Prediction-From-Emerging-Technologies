 yeah thanks for the introduction yeah I just say my name again so I'm Patrick vibe and my colleague is Ramon taxol and we've done this work designing our immersive 3d modeling combining augmented reality will contact this place and this was done at the Interactive Media Lab dressed in at the Technische universität Dresden in Germany so just to give you a brief overview of we developed a modeling application to create simple 3d objects by combining an interactive design workstation we've had coupled augmented reality which the user interacts by using touch some pen and furthermore we also investigated how the AR space at the borders of the display can be used to offload menus and for additional views and at the end I will also talk about larger design space which we call augmented displays but first we are not first to combine augmented reality with this place so let's have a quick look at some where edit work there's different work and the modeling and sketching division where different forms of this place are often used to manipulate AR or stereoscopic 3d objects for example dual cats some biosis sketch and Makapuu de or to enable freeform sketching like sketch there's a biosis sketch and that's also work on distributed user interfaces where displays are used to support interaction with AR or to provide additional views and information this is just a short overview for more detailed overview please look into our paper and now I will try to explain what differentiates us from prior work by giving an overview of our core concepts so our general idea is to take a two-thirds mood it touched and pen enabled design workstation and combined it with fat cupboard stereoscopic augmented reality and this creates an AR modeling and biome which addresses the lack of immersion of traditional displacement at the same time this allows us to use the precision of natural pen and touch interaction and contrast to for example mid-air interaction so our goal was not to to challenge well-established modeling applications but to explore how we can use augmented reality to improve them and contrast to related work we emphasize the alignment of the display and the a our content to generate the impression of a single seamless system instead of a distributed one and furthermore like I said we also explore how additional space gained by using AR can be used for example to display additional views or menus of course an interesting question is where do you place augmented reality objects in this regard we define three different levels of proximity of the AR content and relation to the display the first one is super imposed objects directly in front or behind the display which has also the strongest connection to the display himself the next one are adjacent objects arranged that the edges are close to the edges of the display and the third one are objects placed anywhere in the environment that share no spatial relation to the display they can have Auto relations and we propose to use a network panel touch interaction for the first two levels but to use matera interaction for the third level to interact independently from the display yeah we implemented our concepts in a prototype of course which you will see in the following slides we use Microsoft Surface Studio as the interactive surface and microsoft hololens SD hat monitor our display and both devices run unity which we also implemented our prototype and and to communication and for synchronization of the two applications we implemented a dedicated client-server structure with which a custom protocol which is based on open sound control and TCP and also to synchronize the coordinate systems we place a root anchor 40ar content at the bottom left corner of the display so if you have any further questions regarding our prototype I will gladly answer them later on but now I would like to get back to our concerts by giving you a quick overview of our navigation and modeling techniques we decided to use touched input for all navigation related tasks and to interact with menus and we also wanted to write provide users with a simple gesture set that works well it's easy to remember and this is what we also used travel buttons for mode switches for example for translation rotation and scale basically all the detection techniques use one finger drag chester's for manipulating the X and y axis and the two-finger gesture for manipulating the z-axis we use a boss modeling approach for designer which means that you have a rough model that is enter at a rate of 3 we find by creating new edges and faces and we decided we decided to use pan interaction exclusively for adding new geometry for the the modeling functionality itself for example you can create a new edge simply by crossing two existing edges with the pen and you can extrude a face by first selecting it and dragging it outward of the pen an interesting challenge in this regard is how you interact with a our content that is in front of the display for example user self to reach through the model to interact with the display which leads to perception issues and we solve this for designing our by switching to a 2d projection when users start the interaction and then switch back to the stereoscopic AR representation after the interaction is finished so this explains our concept sound I would now like to describe the specific techniques in more detail that illustrate how it des a our space can be used to extend and approve the view on the display it's of one important functionality is of course to create new models for which we propose three approaches the first one uses or is a 3d accept object browser which uses AR to also show your preview of previous and future items and also which also enables you to see the objects already in stereoscopic AR the next one enables you to simply sketch the contour of an object and then of rotational solid is created again as an AR object this is a very easy way to create such an object and the third one is to use a real road reference by simply sketching the contour of a physical model which is done convert it to an extrusion object and you can also manipulate the amount of the extrusion like you see now yet another important concept are truly autographic wireframe views which are useful to reduce the complexity of an 3d model and this is a standard feature of nearly every 3d application that you bet there is but usually they require a lot of screen space so our approach is placing them an AR space at the borders of the screen and to maximize the screen space that you have for modeling the position resembles the corresponding Cooder projection which makes it immediately obvious which view they show the interaction is linked so when you change the model when you move it for example the views update immediately and also you can interact with the display border to manipulate the autographic views for example to hide them or to change their to change the rendering mode and you can also tilt erm by doing a pinch gesture to have a better view yeah we also propose to offload menus into a our space again to maximize the screen space used for modeling you can for example to one finger swipe to the border of the screen to offload ennum to AR you can do swipe to the center of the screen to move them back to the display and of course you don't oh and of course you can interact with them when they are uploaded so this is why we added little handles at the border of the screen that you can touch to to toggle them for example but you can also use the border of the screen to interact with more complex widgets for example imagine the two days shouldn't ask where you first touch the border of the screen and then you can move your finger up and down to change the rows and you can move your finger further to the left to change the item and then when you lift the finger you trigger the selected item it's a very simple easy way to interact with menus that are uploaded and last concept I want to present makes use of the available a our space to embed instances of the model object directly into the environment they are spatially independent from the display so they can be placed anywhere and because they are impended independent they are not transformed by touch but using midair injection and a dedicated transformation widget but they are still coupled to the model object which is on the display so that means if you change the model the the off-loaded model updates dynamically and this is useful to gain an understanding of how our model relates to the real environment for example for Frida printing so this concludes the designing our concept itself but we also opened up a much larger design space which we call augmented display and which is which is not all limited to a 3d modeling classroom which I would like to talk a little bit about we define augmented display as the extension of non stereoscopic interactive surfaces like tablets tabletops or display Wars with through two or three dimensional objects using personal augmented reality but what is important is that the display serves as a frame of reference for all associated augmentations so besides our own work there are other publication publications which given this definition can be considered augmented displays and we are very interested in exploring the switch design space of what monitors place especially regarding questions like what is the spatial relation between augmented reality content on the display you already saw an example in the proximity levels I presented earlier but just can be analyzed further what role do we object play in relation to the display array for example the primary focus to the user like the model object ISM and design AR or do they play an auxiliary role to content that is on the display itself how does the interaction with to display manipulate AR objects what is the spatial coupling for example and how can we use the screen to define boundaries for a objects for example to clip them or change their behavior so yeah to summarize I presented to you our work designing our an immersive 3d modeling application that combines head-mounted they are displays with an interactive surface and in the future we plan to evaluate our concepts of using AR to extend this to display screen and formatives of user study and also to pursuit the exploration of this design space of the exciting new class of this place that we call augmented this place yeah thanks you for thank you for the attention and I'm now open for questions [Applause] thank you very much thank you for the great talk is Andrew Bianca Comcast I would like you to comment a little bit about offloading some MIDI interfaces off screen like for example your token our projection which i think is a great idea but given the limitation of the current technology for example the field of view of their older lenses can actually people see them or do you actually have to thank you well not without moving your head obviously but having used it I would say it works reasonably well right now of course having a larger field of view would help tremendously but we're looking more into the future so the hololens y2 is it's nearly there should be there already and which probably also have a lot of will have a larger field of view so we don't see that as a limitation on the concept side but of course it is a little limitation on the practical implementation here but I think this will change for future technology thank you for briefs matulak prefer networks I really like this this works so it seems that you're using the AR space as far as I understand mostly for visualization and for very basic manipulations of of the objects right so I'm wondering whether you're not kind of missing the whole 3d interaction space to provide some creations and design tools also in that 3d space because you have a fixed basic 2d surface where you actually use the pen to create your shapes and and your modeling right so how would you extend that how would you use the pen in the 3d space maybe using a tablet you just called the tablet in the air and then depending on the orientation you can use the whole 3d space or something like the AR pen which was presented at KY this year so I don't know can do you think you really need the fixed surface like designers do designers prefer to have a fixed surface to do their creation or do you think you can exploit the the 3d space also for creation and modeling yeah that's an interesting question I can really answer you the question of designers prefer a fixed station at least I do when I do my modeling and so this is the baseline we have of course to evaluate that and we will study with real designers which we didn't do now but the focus was more and in this work at least was supposed to use a stationary to supply and to explore how we can expand that using a tablet to actually do modeling or sketching and AR is an interesting approach but it's I think it's a very different approach with which would require very different techniques than that what we have done here is a tablet via paper actually down in her mouth presented that at KY also this year they're doing some kind of very basic modeling I just it's a short additional answer to your question for base since I'm one of the courses it is actually the notion to use it to use the tablet and to move it in space and to use a spatial location or orientation of course it's also represented in the Augmented displaced concept so the idea is not it's not fixed to a stationary display but any display which can be augmented and where you can interact is where you have the precise interaction on the surface plus an aligned or a coupled augmented view is this concept of augmented dispenses way in a sense yes you can also use a tablet and maybe not only we didn't envision VR but a normal environment plus of Antoinette's so it could be possible to use that as an additional thank you so actually more a couple comments and so much a question but I'll flesh it that way one is the concept actually will work well what you your left hand is awfully you're the first thing my first comment is you don't use two hands you it and we have two hands so one thing you could be done with the other hand is we've done some work where you instrument the display and you put on a gimbal so you can actually rotate and manipulate the the tablet as it means to control the rotation and viewing angle without having to have your head Oliver so that's one thing you could explore and it would I think it would I'd meant the technique very well and it's a good use of the hand that the use of the tablet is is useful because it does anchor the thing in space so you've got good better better memory but the other part would be again I think it there's some examples I think might be interesting for you to look at Tobey Grossman's 3d tape drawing examples where he's on a flat surface been doing drawings but on layers so you can stack things up and then change the orientation and he's got some very complex curves that worked out really well with that and so everything's best for southern versus something else there's some really good technique there's some very good applications where this would extend really well with and those two techniques would be among many that would help that yeah keep going Thanks thank you thank you and thank you for presenting Patrick we thanks Patrick Walmart 