 [Music] hello everyone my name is Sergio Felix and I work as a study at Google and I'm Soren Wallace I'm a software engineer at Google thank you for joining us on the migrating a monolithic application to micro services also thank you for waiting in line for such a long time this is the last talk of the day hopefully you don't fall asleep thanks for coming if you have any questions we're gonna have a Dory available we'll try to mix live audience questions with the Dory so just be aware that that's available kidneys through the clickers Sergey and I both work in an organ Janee ring productivity this means essentially our job at Google is to build tools to help make other Googlers more productive specifically Sergio works on a tool called Loki and I work on something called glass pane to give you about to give you a little more context around this Loki is a release orchestration tool it basically allows developers but mostly to release engineers a way to automate the process of managing scheduling planning controlling software builds through different stages and deployments basically you can think of Loki like most CICE tools out there there's a concept of a flow that has triggers and the triggers kick off a pipeline that has a bunch of steps and then you get notifications when those steps move along and we use these weird-looking flows to compile and build is we're looking applications that in our team we call hybrid applications these are applications that are made up from both open source software and internal software that gets bundled together build tested and so on glass pane on the other hand is an internal metrics platform at Google that's essentially designed to help leaders understand the health and relative performance of their projects and teams through mainly actionable insights so today we want to tell you a story about our journey and how we migrated both low heat and glass pane from monolithic applications and split them up into micro services but first why did we decide to build low key and glass pane as monolithic apps in the first place this allowed us to experiment quickly we needed to focus on the business logic and having a single binary really allowed us to do this while preventing initial over-design we weren't as concerned with everything working you know as beautifully as possible as long as it worked since we were a small team we could also easily manage the changes just kind of by saying hmm you work on this thing I'll work on this thing it also made things the maintenance around our binary pretty easy because we only had to do it once it was great until it wasn't our teams were growing we started getting more product requirements and we started onboarding new team members we started to have too much cognitive load when we brought a new person under the team instead of just needing to understand the small piece they were responsible for they had to spend a few weeks to figure out how the whole architecture of our application worked we had to start delaying deployments to sync features across the different team members and we had no way to independently scale certain small parts of the app that might need more resources than others we had to scale the whole app all at once wasting tons of resources this made it really messy to debug when an error happened it was really hard to go and find the root cause we started to feel like we had built a cage around ourselves that we were desperate to escape and this is where micro services came in but what is a micro service and what do they even come from before we go deep into patterns and all that we want to take a step back and just look at the history of where microservices actually come from you don't know about my monolithic apps we have a single binary that gets deployed changing one of its internal services or Soren mentioned requires the deployment of the whole application so that's a slow velocity to production and then a Soren mentioned new engineers arrived and they have to understand this really complex application with a large code base and I usually have to submit PR requests and there's a central group of people hopefully who are have your authority to approve those changes again this is slow they also have a single database where all the services talk all the modules inside talk to the database the industry then moved on to service-oriented architecture the term was coined around 1998 by a group of people working on something called CORBA those old enough might be able to remember and the idea here was that you would build services a bit more decoupled than when a monolithic app and you had four types a business layer at the top a bunch of enterprise services and at the bottom application and infrastructure services all tied together with this thing called the Enterprise Service bus around that time we wanted to share everything and so we had single database that was shared across all the services the problem with this is that if you made a change to your database that change could ripple throughout all your Microsoft all your services that was a problem also the Enterprise Service was needed to scale depending on how many services you had and it was a single point of failure then things a little bit and we got to micro services here autonomous teams are organized over a single functionality micro services are independently deployable and teams produce and consume api's this makes it really simple for other services to scale really fast and enables innovation also nowadays micro services are deploying containers so it gets even simpler to deploy so what are the benefits of micro services well they're pretty simple to understand these small services make it so that onboarding new team members is relatively easy when compared to a monolithic app because people are only focused on the things that they're responsible for it also allows you to work on potentially different text acts within your team you might have someone working on Python for this micro service and when working with Java for the other one it's pretty cool they also have isolated responsibilities which means that everything all the micro services are responsible for a single thing and you can deploy them independently they're also scalable and distributable and you can reuse business logic throughout your application simply by making a call to a micro service that's responsible for the certain functionality that you need they're also really fault tolerant later we'll talk about some patterns you can use like the circuit breaker breaker pattern to handle when a service goes down this is something that's not quite as elegantly possible with monolithic apps okay those are some of the benefits but how do I actually go about migrating a monolithic app this is something that's really daunting for a lot of teams right you might have a bunch of legacy code you might have all these different dependencies that are intermixed and you're wondering okay how do I go about tackling this well with both Loeb Loki and glass pane we had a model with a gap that we wanted to break into micro services but we weren't sure how we initially asked ourselves these questions which you also might be wondering how big should these services even be and how do I actually go about splitting up the functionality in my monolithic app well the micro part of micro services it's kind of more of a label than a description the size of a micro service can really vary there's this concept called service granularity that's essentially how big are your micro services and there's no one-size-fits-all approach for this it's going to depend on your infrastructure and your tech stack ask yourself how much overhead is associated with building a new service considered things like source control management deployment testing etc later we'll talk about some tools that you can use to automate these things ask yourself does creating a service cost more than implementing its functionality if that's the case that's a good indication your service might be too small one approach that's commonly used is domain driven design which emphasizes the idea of bounded contexts where each component of your application or in this case each micro service is only responsible for a single thing if you're familiar with object-oriented design you can think of this as each micro service handling one strong entity and it's related business logic and the data layer beware of an anti-pattern called nano services this is essentially when your services are so small that it's not feasible to maintain them to give you an example of this we actually ran into this problem with glass pane so it started as a monolithic app running an app engine and after our design process we decided that there were essentially seven domains in glass pane so we created seven micro services that was our magic number ish we moved from the monolithic app first to this core micro service that talks to six other micro services that handle their respective domains and where we went a little too small a little awry is when we started making an individual micro service for every single metric that we wanted to show in glass pane now we wanted to show hundreds of metrics in glass pane so with that infrastructure we would have to build hundreds of different micro services and do all of the release and testing and logging and all the things associated with each of those along with the complicated data logic and business logic that we might have instead we took a step back we said ok this is not feasible for our team size and our tech stack we decided we'll have a single micro service responsible for all the metrics but how do we keep that isolated responsibility principle well we still had having a single micro service allowed us to only have release and tests and logging for a single one so it solved our problem but we were able to take advantage of Google cloud functions which provided that isolated responsibilities without all of the maintenance that goes along with those separate services so this was our solution and maybe something similar could work for you all right I just talked about deciding on the size of your micro services but how do you actually go about splitting up the functionality in your model with a gap there's a pattern for this called the strangler pattern it gets its name from the strangler vines of the fig tree which start at the top of the tree in the leaves and they slowly work their way down over years potentially until they're rooted in the soil and they've entirely consumed the tree and it dies you can think about migrating your monolithic a kind of like that slowly and creepily and hopefully not in a forest so to give you an example here's a monolithic application we've got it's a single binary it's got some modules in it maybe the accounting module the shipping module the inventory module and they're all communicating with the same database and when a user makes a request the monolithic app is the only service that handles it with the strangler pattern the first step to migrating this monolithic app into micro services is to add something called a proxy now this is gonna initially all its gonna do is reroute requests that are coming from your user to the monolithic app nothing has changed about the way your user is interacting with the app this is just a layer you've set up so that you can begin redirecting traffic to new services as you implement them next let's say we want to tackle the functionality that's provided related to inventories in our model with a gap we decided that's a domain that we want to put into its own micro service so we create a separate micro service binary that we call inventory micro service and notice that it has its own dedicated database this is crucial micro services are not really micro services unless the data layers are separate we haven't begun implementing the functionality yet we just created a binary the next step is to set up a link between the proxy and that new binary that's running as we implement the functionality related to inventory we can begin using the proxy to redirect some of the traffic into that new inventory micro service binary once we're done implementing the functionality we can remove that functionality from the monolithic application next we tackle the next domain let's say we want to tackle the shipping logic so we create a new binary again with its own database setup a link from the proxy to that new micro-service binary then as we implement the functionality of the shipping micro service all the traffic gets redirected and we can remove that functionality from our monolithic application we do the same thing for the remaining modules create a new binary link it up with the proxy implement it and now all of the functionality is gone from our monolithic app and voila you're in micro services hooray for low key fortunately we started with something a lot more simpler our initial monolithic application was built with python 2.5 and it was running with flask and because the way we architected our services to begin with sorry our modules to begin with we could easily translate basically each module into a service in our new architecture so for the most part that was pretty easy however not all the modules were simple we had this pipeline module which was kinda like a monster like a Frankenstein he did a bunch of things it's tore the pipeline configuration it managed the states of the pipelines it managed a catalog of stage types and in also contain all the logic to actually run the pipeline so when we were looking at this and we wanted to transform this module into micro-services we decided to split this module into three micro-services the pipeline service just managed the state and the configuration of the pipeline and that's it then we had a separate service that just managed the catalog of stage types and all the logic necessary to run the actual stages were in a GCB executor pretty simple all right so where to get started well source code and documentation good place to start design Doc's are gonna be your best friends create a strategy for how you're gonna migrate from monolithic app from a monolithic app into micro services it can be a costly refactoring process that you might have to delay feature development for for a while or take some resources from other parts of your team to do you want to create a design for your final architecture what you want it to look like decide on those domains that you've you've your application needs to handle this is actually a cool opportunity to maybe rethink some of the things that maybe weren't so pretty or more good about your initial app in low Heon glass pane we also created design Docs for each individual micro service this allowed it this made it really clear what the the entities were that were being handled by each micro service the business logic related to them the data layers and more importantly the contracts that were being established between each micro service and the other services that it needed a consume or that needed to consume it next ask yourself do you want to split up your source code repository in glass pane and low key we decided to do this by splitting our repository into a single repository per micro service we established clear dependency relationships between the services this is a really cool thing about micro services to take advantage of this also meant that essentially there's no other choice but to deploy them separately which is what you want to it's one of the key benefit to get out of finally set team responsibilities if you're a small team you might have one member who's responsible for multiple micro services if you're a large team you might have whole sub teams dedicated to a single micro service decide on this and you'll be good to go you might be wondering okay if I've got a separate repository for every micro service like here in glass pane you can see we had a repository for the core service the preference service the team service and so on how do I share code between them our solution was to add a common repository it's not a micro service it's just a separate repository where we can put shared code that all the individual micro services can depend on this means we can still deploy them separately and test them separately and and they're not depending on each other okay so we thought about the sizes of the services we have a document set up in place and then for us in loci and in glass pane we were thinking if when I will do micro services what technology stack do we pick so you can run micro services in multiple ways you can run them as App Engine applications as a customized compute engine in kubernetes in cloud functions in kind native it depends for us specifically we picked gke mainly because we could deploy a wide variety of applications in gke if you can put it in a container Chicka you can probably run it we were also super interested in self-healing capabilities and the auto scaling capabilities in gke this meant our application would be up and running all the time also we really like the declarative configuration in GAE we could just basically tell G what we wanted and gke we'll get it done also we really like that in gke we had easy network setup and gke basically handled the updates of our kubernetes cluster for us so we didn't have to manually schedule this and run it for ourselves plus since our old allocation already leveraged most of the GCP services we were also interested ji-ae can leverage things like stackdriver pubs of datastore and so on for the backend though as our team changed we were more experts on Java than in Python and so we pick spring mainly because we knew Java our developers knew spring it's a perfect fit spring is a very mature framework used throughout the industry it's open source cloud native it's as flexible as you want it to be if you want you can specifically configure something let it or let spring auto configure itself also there's tons of documentation so it was really easy to get started on top of that we found that there are these two projects spring cloud GCP and spring cloud kubernetes the first project basically allows your springboard application to leverage things like pub/sub data store authentication and so on really easily and sprinkle kubernetes allowed the Springwood binaries running on a GK cluster to leverage the kubernetes api we'll talk about how we use both of these things in other slides both glass pane and low he use this front-end framework called polymer for our front-end UI you might be wondering why am i talking about a front-end framework in a presentation about micro services well polymer takes advantage of something called web components where each piece of the UI is a separate component with isolated and responsibility it allows us to think about our front-end in much the same way we think about our micro services back-end architecture here's an example this is the side the navigation bar or the sidebar for low key and you can acutely see how it's composed of tiny pieces web components that interact together to create a single page application we encourage everyone to go check out the polymer project and the lead project there pretty interesting we found it useful so anyway now we have an idea of how to split our services we've picked a technology and now we want to be able to expose these services to our clients our front ends or other applications I'm going to talk about two patterns that you could use gateways and aggregator or composite services now gateways as the name implies they act as a door right they basically decouple your clients from your downstream services gateways basically allow you to configure an optimal API for each of your clients it also allows you to aggregate calls to the services so your front-end doesn't need to know that in order to get a flow it needs to go to three services the Gateway can handle that for the client also the gateway allows you to set up throttling rules retry logic so if a service is down for a moment the Gateway can retry a couple of times and then the user doesn't even know this is also a good place to place perimeter security this allows you to block certain users to you know access any of your downstream services that you might not want to a note it's just that perimeter security should not be the only security that you add to your application so how do we get a gateway in a spring good application you basically just add this dependency and you're able to now match Brad's right predicates and filters and set up a bunch of things which is really really fast and magical and there's this other thing called aggregator or composite services these are basically just services that aggregate calls to other services this allows you to maybe simplify calls or implement things like me try or the exception handling as an example I told you the beginning about this concept of I flow in lo he that has notification triggers and a pipeline and so instead of having the front end talking to these three services to create just one flow we created an aggregated services called the flow service so now the front thing can just talk to the flow service and the flow service handles the logic of talking to these other services for the front end it also notices if a service is down and maybe do a couple of retries if something didn't happen as expected speaking of retries how do I even configure the number of retries in my service so we were we were developing our services in Loki we had a bunch of configuration that we wanted to add to our services retries timeouts feature flags and we didn't want to redeploy our whole service when we change one of these variables Oh turns out that the spring cloud kubernetes project allows us to basically push a configuration map to our gke cluster and as the cluster notices these changes it delegates that over to the services and then you can just read these as variables annotated with the add value annotation in your application really really convenient for toggling features since glass pane doesn't use spring we didn't have this cool configuration management right out of the box so we decided to implement this functionality ourselves we created this configuration micro service that listens for changes to protobuf file essentially sitting somewhere in a repository containing the configuration settings for all of our micro services like feature flags and number of retries and the things Sergio is mentioning when this configuration service detects a change to this file it sends a message via cloud pub/sub to all of the other glass pane micro services to tell them hey the configuration is updated and they know to update those values without having to be redeployed ok so we get a bunch of services up and running and we might want to be able to carry out complex complex transactions across them let me set an example imagine this emanuelly you have a project in Loki and a project might have additional metadata associated with it and it doesn't pretend that a user wants to delete a project right so the project service gets a message to delete Project X for the project service is really easy it just goes to its data store and deletes the project and that's it but there might be some cleanup that needs to happen from other services if you deleted a project maybe stop the triggers or if it's a pipeline currently running stop it or something like that right and you want to be able to do this atomically as well and then on top of that imagine that in the future the system grows and there's new services that are available and they also need to react to things that happen when a project gets deleted how do you do that it turns out that there are some patterns called saga patterns I'll talk about orchestration and choreography in orchestration you have a single service that coordinates what's happening this coordinator service makes sure that things happen in a lot in the certain order or the event happening at all the problem with orchestration though is if this is magical coordinator service somehow dies the other services don't know what to do and so then you have choreography in choreography services basically produce and listen to events and then react accordingly there is no single service coordinating the actions the downside to this is that there might be some overhead because you're sending events and then all the messages have to get them but in Loki we use a combination of both for the example that I was talking about the project service emits an event saying hey project X has been deleted and through eventual consistency the message arrives eventually to all the services who are interested in this message and then delete the project in a fan-out strategy the opposite can also be done a single service might be listening to multiple events from other services for example we want to do this with our metrics service we want to use the metric service to calculate release velocity and additional metrics in our application Sergio covered some useful patterns for coordinating your services but as your application grows and your may be using these aggregator or composite services how do you keep track of the requests that are being sent between all of these different services distributed tracing is a technique to do exactly this Zipkin is an example of a tool that spring uses to add essentially breadcrumbs to the HTTP header automatically to all your requests allowing you to track them as they bounced from service to service this means that you can troubleshoot errors and gather metrics about the way that your services are communicating really useful stuff as an alternative there's tools like envoy and sto that create a service mesh to enhance HTTP requests between services running on any tech stack to provide your application with distributed tracing capabilities automatically so for Loki in order to implement distributed tracing we only had to add these two dependencies to our services after this our spring good applications began pushing information to stack driver that meant that we can then go back to our stack driver in a DCP console and we could actually tell and see the messages bouncing across all our services and if you wanted to you can even click a button to go into detail about what's happening each in each individual service how did the services even find each other if I create a new service how do the others know that it even exists where this thing called service discoverability it's been around for a while but it really became popular for micro services when Netflix introduced Eureka the concept is actually pretty simple you have something called a service registry when new services arrive they talk to the service registry and say hey I'm the service I'm the project service and then other services can query the service registry to find out what other services are available and you can do some really interesting things with this I'll show an example here in loci we had this general trigger service and maybe some implementations the manual trigger and the get trigger and we wanted to have a way to enhance loci to have new types of triggers without actually going back and changing the existing source code so in order to do this we leveraged server discoverability if you wanted to add maybe a pub/sub trigger we just wrote the pub/sub trigger in a way drop it into the cluster the service register with kubernetes and then the trigger service became aware that this service actually existed now with that the trigger service can go back to the pubsub trigger and interrogate the server the service asking what it did and then it could expose that functionality across the other services but what if a service goes down unlike monolithic apps one major benefit of micro services is that your whole application can somewhat be up and running even one of those services goes down how do you know how do you handle this I'll talk about some patterns and behavior patterns circuit breaker pattern and self-healing services so secret breaker pattern is basically a pattern used to detect failures and allows your services to react to those failures here's an example imagine that a user wants to do something with the flow service and in order for that to happen the flow service needs to talk to the trigger service if everything is fine the closer it is talks to the trigger service and that's it imagine that for some reason the trigger service is down the user doesn't know that the trigger service is down obviously and so maybe the user will click a button to try again maybe the user isn't patient and clicks the button again and again and again and then you run into this issue where the flow service has a bunch of open connections you know waiting for the trigger service to come back and then the trigger service is dead and so if it ever becomes available again it doesn't know about those other requests which are in progress and the user is super confused because the user doesn't know what's happening so here is the same thing but with the circuit breaker again if nothing is wrong the flow service through the breaker goes to the trigger service everything's fine the cultural end and the user is happy but again let's say that the trigger service is down for some reason the flow service goes through the circuit breaker on to the trigger service and now the circuit breaker will try a couple of times for you depending on how you've configured this when the circuit breaker determines that the trigger service is unhealthy it'll get a chance to react the circuit is open and now the circuit breaker can actually throw out an exception in your flow service and that your flow service can handle logic should you maybe tell the user that something is wrong maybe it'll store the request and try again after the trigger service becomes available so Sergio through the pattern at you now I'm going to show you how can you actually implement this so we did this in glass pane and here's how we had this metric service in Java that attempts to get all the available metrics in glass pane by sending the request to the metric micro service but what happens if that fails well as you can see here it just throws an exception and the user doesn't know what happened where are my metrics well we implemented this by creating a new annotation called the method retry annotation as you can see it takes in a number of attempts to attempt the method and even a fallback method so that when that number of attempts astir passed it actually can fall back and say hey we weren't able to get a request but here we're gonna pull the metrics from the local repository in this service maybe from previous requests and get some default metrics to show the user and maybe we also show an error message on the UI this is just one way you can implement this pattern but this is the kind of cool flexibility that's possible with micro services depending on your tech stack this might be provided automatically or you can create it yourself and then this other thing called self-healing services for example kubernetes is able to monitor the state for your health of your application to find out if it's down or not and if it is kubernetes is able to kill the pod and create a new instance of your applications so that it makes sure that is always up and running however for this to work you need to have a way for your application to tell kubernetes that is actually alive and in Springwood applications you can actually use the spring started actuator the actuator basically adds additional endpoints to report the health of your application and if configured correctly you can even use something called micrometer to get metrics about related about traffic coming back and forth in your service also I didn't want to leave you hanging you can also use a circuit breaker pattern and inserted this capability in spring you basically have faint clients that you use notice that I don't have an IP address you just basically name what client you want to talk to and he goes back to the service registry and finds out who's the service is where it lives and so on alright it sounds like there's some cool benefits to micro services but having all of these different binaries sounds toilsome right how do you manage all of this stuff building testing and deploying all of these services can sound like a big daunting task maybe as big as a monolithic app itself how do you manage these services automation is your friend there are tools out there that we really encourage you to use that will help to automate the different parts of managing your services this this can be in a CI CD pipeline to make it so that you're deploying testing continuously and automatically if you're trying to do all this manually it's not going to be feasible okay so there's things that we clearly didn't cover in this presentation but we encourage you to go out and search for this a certain mentioned you want to be able to automate the creation of your infrastructure either through code or configuration lots of tools out there like ansible puppet chef Google Cloud and Amazon have implementations for these things in low heat we use something called terraform you want to have a CI ACD pipeline for micro service make sure that you always run tests and whenever a change gets pushed to one of your repositories how about rollout strategy you think about how you going to deploy the services you're going to deploy them always when the test passes are you gonna have a cannery are you gonna do green blue deployments think about that setup error logging metrics and reporting you want to do this at the beginning when you're developing developing the services instead of waiting until the end obviously don't forget about security and testing we didn't cover this topic at all but we encourage you to go out and look so what can you take away from this presentation well earlier we talked about some of the pros and cons of monolithic apps versus micro services and how micro services came to be we told you why we initially built low Heon glass pane as monolithic apps and why we decided to go and push into this great adventure of converting them into micro services despite the great refactoring costs micro services allowed us to iterate quickly and focus on solving our users needs so ultimately we got out of it what we wanted throughout this presentation we also show you how to take advantage of existing patterns like the strangled pattern to slowly break down your service we also talked about Saiga patterns to reinforce atomic operations circuit breaker when something goes down we use examples of loci and glass pain to show you how you can implement the same patterns with different technology stacks ultimately there's no one-size-fits-all approach to the perfect application if there were we wouldn't be here right it's there would be no price to talk but we hope that you learned from our experience with low key and glass pain and that you took away some useful tips for how to choose a good architecture for your app we hope the road ahead is a little clearer now there's this cool search engine you can use to search for all the tools and things that we talked about in this presentation in case anything is is big but we wish you the best of luck on your journey [Applause] [Music] 