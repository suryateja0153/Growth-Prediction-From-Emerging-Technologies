 [Music] today on the future of everything the future of AI and air traffic control first of all I want to say that we're still taping under zoom conditions so I apologize for any technical glitches we're doing our best and we hope you're all safe back to AI and air there's a lot of talk about autonomous systems for transfer for transportation there's driving cars self-driving airplanes and helicopters self-driving boats self-driving spaceships each of these has an is an active area of research with critical considerations I think obviously of safety and economy can we get people and cargo to where they're supposed to go safely and efficiently they can have many challenges in order to be trustworthy and to be trusted by those who use them a out AI algorithms machine learning algorithms show great promise in being able to assess them assess the environment and make rapid conditions to control a vehicle but of course there's always worry about whether the AI will make good decisions in difficult circumstances especially rare circumstances that the designers may not have anticipated or made it have literally never happened before situations in which of course even humans can find themselves and which can be very difficult but humans use their experience and judgment to make the best decisions hopefully with good outcomes but not always how will a AI systems make these decisions and how will they stand up to the scrutiny if and when things go wrong well professor Michael kokand offer is a professor of Aeronautics and Astronautics as well as computer science at Stanford University he is an expert at building autonomous systems and in particular systems for aviation Michael what are the main challenges as you see it for trustworthy autonomous vehicles okay so I see there there being two major challenges the first one is how do you build them in the first place and there are a number of challenges associated with that and then a second major aspect is how do you then go about validating those systems so going to the first part of how do you build these systems to be safe it's it's actually really really tough and I don't think the general public appreciates how hard this is it's hard for three reasons the first reason is that many of these systems rely upon imperfect sensory systems that don't directly observe the true state of the world so we see this with autonomous cars so with autonomous cars they rely upon vision sensors or lidar or radar and many of these sensing modalities can be affected by occlusions like car blocking or your vision of the pedestrian there may be noise there may be sensor failures and so forth and so making good inferences about what's actually happening can be very challenging what would you say in general that these imperfections and sensing are at the same level of human imperfections or are they more or less or just different it depends upon the sensing modality so like if we're talking about like radar sensors radar sensors can see through clouds that they're often not impacted in the same way that pilot pilots eyes are affected ends and so you can get superhuman performance in terms of along some dimensions but sometimes not others okay and and a similar kind of challenge occurs when you try to apply these AI systems to medical decision making which is more along your line of research where we have to rely apply and maybe we don't call them sensors but maybe we call them diagnostic tests so we apply these different diagnosis tests maybe for trying to determine whether someone is infected with the crew virus or whatever but you know there's a false positive false negative rate and and so forth and the sensors that we use for autonomy for transportation systems they are also impacted by false positives and false negatives so for an example we may think we see another aircraft but it's not actually there or vice versa ok so that's a first big challenges the imperfections in the sensing which will be different from human sensing but will still have its problems that's right and so related to that is uncertainty in the future trajectory of reality so there's a lot of that I noticed there is a lot of that especially right now and our ability to model what's actually going on is a major challenge I believe a great baseball player once said predictions are difficult especially about the future yeah that's exactly right and for many of the systems that we're interested in our lab if if if you mess that up the consequences the consequences can be fatal right so if we're trying to make a prediction about where another passenger aircraft is going to be over the next 40 seconds I mean most of the time they just fly straight right but sometimes they might turn left or turn right or start a climb where a descend and we have to be robust to that variability so this is interesting yet that implies that these systems not only need to sense the current present they have to have some memory of the past either recent or distance and they need to have a model for the likely things that could happen but I would guess also the unlikely things that's right and many of the systems that we're interested in involve humans in the loop and as you know humans are a tremendous source of stochasticity or randomness and what happens and so the the pilots who are flying these aircraft they may certainly decide to maneuver to avoid collision or where maybe they're they're oblivious to how the situation is unfolding but you you make a good point that in order to make these predictions into the future you have to keep track of what's happening in the past and we see this come up quite a bit in automated driving so for an example if if for the past you know 10 seconds or so someone is coming up behind us and they're driving erratically that will inform our predictions about what will happen in the future and so we may want to be a bit more conservative as they pass us but maybe we don't always want to be super conservative because that will be at odds with our efficiency this is the future of everything I'm Russ Altman I'm speaking with Professor Michael Koch endure for about some of the challenges in building these autonomous systems for transportation so I think I think we've gotten to so far I'm pretty good I think if I'm a good counter we had sensor problems and we had prediction of the future problems then another major challenge is the trade-off between safety and operational efficiency and that this is this is another aspect that that people generally take for granted they think oh well let's just maximize safety right but if you're building an alerting system or a system that takes over and maneuvers for you you can't tolerate too many false alerts right so if we're trying to build an aircraft collision avoidance system and it tells the pilots to take an extreme evasive maneuver then maybe we can lower the collision probability but it's not going to be used useful at all uh-huh and getting that balance right is really tricky so and I would guess that in those situations that it could be context specific in the sense that you're taught well for I mean the most obvious example is your safety tolerances in an aircraft that is unperson where there's nobody in the might be different and then one that where there are three people sitting in the or or 400 people so do we have to build to kind of parameterize miles where you can models where you can kind of dial up or dial down the this trade-off because it really is a trade-off and I guess you you want to be able to have I guess humans make some judgments about that trade-off or is that not the right approach yeah no that that's that's exactly the right approach there's a lot of a lot involved in getting that right though yeah and you're right it depends upon I made it like a situation aisle and I guess I'm fair I don't think there's just one dial right so so at a high level there's often a trade-off between safety and operational efficiency but operational efficiency can encompass many different dimensions so it could be measured in terms of number of false alerts if we're building a system for cars the number of hard breaks and so forth and so this is a very very much a high dimensional space and that is a major challenge for human designers we like to think roughly in like two or three D but beyond that it kind of boggles our minds and so one of the research thrusts in our lab is figuring out how do you handle that dimensionality how do you extract from a committee of humans how to make these make these trade-offs in a way that's sound great so this now you've now put us into a deep hole of deep challenges and yet we're not paralyzed my understanding is that these systems are being built what is the state I don't know if you want to refer to general autonomous vehicles or concentrate on aircraft what is the state of the science now and what are some of the examples of New Age technologies like I know I think that most of this was done purely by humans 40 or 50 years ago and as a non-expert I don't really have a sense of the pace at which things have been automated so can you paint a picture for us about how things have been going and where they're going currently yeah so I'll focus on one particular application to aircraft collision avoidance because that's great that's what I've spent a number of years thinking about so I the interest in aircraft collision avoidance dates back to the 1950s there was the mid our Coalition over the Grand Canyon in 1956 involving United Airlines and TWA 128 fatalities this led to the creation of the FAA in the night in 1958 and a whole bunch of research on aircraft collision avoidance systems it wasn't until the 1970s that the FAA actually established a program to create an aircraft collision avoidance system and that system became called T casts the traffic alert and collision avoidance system okay so I if you might recall computers back in the 1970s they were not soon to say I do read it so back then memory was extremely expensive the the processors were very limited and it placed a huge burden upon the human designers of the system at MIT Lincoln Laboratory the mitre corporation and other organizations in the 70s and 80s to anticipate the full spectrum of all the different situations that might occur and what they had to do was encode what to do in every situation as a set of rules okay and that's really complicated that's super complicated and it was limited by your imagination literally that that's right so it turns out that I got to know a lot of the original engineers who worked on this program super brilliant people and the the system turned out to be a major success but one of the challenges is anticipating and working with uncertainty we as humans we like to think roughly deterministically if I do this then that will happen if I do that then this will happen but it turns out that in order to achieve the level of safety that's required of commercial air transport this really requires reasoning about low probability events and humans are just not good about thinking about events that may occur on the order of you know 10 to the minus 9 probability and 1 million one in a million and that's that's where where my research picked up in in 2007 what started out as equations on my whiteboard turns into a very large program called a cow sex the airborne collision avoidance system X has a little phonetic relationship to its predecessor the K that's right the caste there's the connection there also t castes the international standard was known as a caste and so this is a connection to that that's pretty cool great great before you tell us about it let me just ask a very basic question about air traffic control is this collision avoidance part of the normal navigation system or is it a separate system that recognizes that we're in big trouble and it kind of takes over I I don't have a clear model of whether this is a separate add on or part and parcel of how a plane would do its entire flight plan that's that's a great question so it's it's meant as as the last safety net in a layered system of safety and as you know commercial air transport it's it's unbelievably safe right and actually I was an aerospace professor and as as a private pilot third-generation private pilot it's just amazing to me that you know one of the safest places we can be is in a metal tube at 30,000 feet that's just that's just magic to me yes but anyway the the reason why we have the safety level of safety in the air space is because we do have a strategic separation provided through you know there are different rules like depending on whether you fly east or west you fly at different altitude layers there are different Airways and so forth we also have air traffic control air traffic control they rely upon ground-based radars and they call out traffic to the pilots and they route the the the aircraft around to each other yes so T casts and and now a cow sex sits below that so anything that that that that's not resolved through air traffic control will be captured by T KS and Inc s X and this is present on the plane not on the ground it's it's onboard the aircraft it continuously monitors the aircraft around it independent of air traffic control independent of the ground-based radars and so that level of Independence is very important and that's why when there are these aviation accidents it's normally due to a failure of a number of different systems because there's so much redundancy in the system as a whole ok so I I that was a big thank you that was a very useful tutorial on the on the setting within which you found yourself and I think you said in 2007-2008 you started building this tell me how it was different and and what challenges it exposed or solved right so it exposed to a number of of challenges the approach that was taken and although it came out of out of some research that I led it eventually involved a number of people across a number of different organizations and there are a number of technical aspects that we can talk about right now but the success of this really was due to the leadership of a particular individual in the FAA Neal Suki who was willing to think outside of the box in terms of improving the safety of aviation and I think as AI starts providing opportunities in other domains we're also going to need that kind of leadership at places like the FDA and Department of Transportation and and so forth so what's the different I'm going to interrupt this is the future everything I'm Russ Altman and we're gonna return I promise with Professor Michael Koch underfur talking about the key elements of the new system for collision avoidance next on Sirius XM welcome back to the future of everything I'm Russ Altman I'm speaking with Michael Koch underfur about the new a caste X system he created starting in 2007 for collision avoidance and then we'd like to understand what were the good ideas Michael in that system and what did it teach us and where does it leave us today right so what one of the key ideas is to not have the humans try to anticipate the full spectrum of what might go on and encode rules for solving those issues so what we do instead is we build models so models of that directly address those three major challenges so we have we need a sensor model that captures all of the sensor error characteristics and so forth we need a model of how the world evolves in response to the decisions of the system and the decisions of other humans and others in the in the system and then another component is we need a way of encoding the objectives right so the the AI system can't it needs to know what it needs to do right and it needs to be told it needs to be extremely safe and it needs to try not to alert too often that there are other considerations as well like for an example you may not want to tell the pilots to climb and then all of a sudden tell them to descend unless it's like SuperDuper necessary so that's called a reversal I forgot to ask you does this system ever take over the plane or is it always advisory Oh a great question so it is advisory however Airbus some Airbus aircraft like the Airbus a380 has an automated response to tea cast and in the future it will be automated to a Kasich's but the pilot can always override it okay that was an important thing for us to know whether it's a closed for an open that's right that's right and so once we have those models we need a way of optimizing the behavior of the system with respect to the objectives and we use a special type of optimization called dynamic programming and dynamic programming as it as a computer scientist this is one of the most beautiful concepts of all time let's say it's also a core idea in computational biology as you may write in terms of comparing DNA sequences and whatnot so you have tasted up the magic so what what's amazing with dynamic programming is that it takes something that seems to be computationally intractable and makes it tractable so here's here's the here's the computational challenge right so as I mentioned we have to reason about the full spectrum of what might happen and the space of possible that there are more trajectory trajectories than there are atoms in the universe and then on top of that we have to take into account their relative likelihood and we have to reason about all that and it's just not feasible for it every supercomputer to even enumerate all the possible atoms of the universe within seconds if that's what's required right so what what we do here is we do all of the reasoning on the order of minutes off line and we store that into a lookup table and then that lookup table that goes through an extremely rigorous verification and validation process and then once that is certified that then goes on board the fleet of aircraft and and then it just boils down to a lot of table lookups and interpolation so much of the complexity is is captured by this lookup table so two quick questions and I have so many questions but I think the first one is when you were building models in tooth I know a little bit about model building and in gross and gross terms one way is to do it with mathematical first principle models and another way to do it is to inform it by data from many many previous trajectories many many previous air air air flights I'm wondering if you can tell me are these the mathematical models or are they data-driven or are they some sort of hybrid it's it's definitely a hybrid it's a mixture of real data and human expert judgment so for the the system for manned aircraft we collected a continuous stream of FAA and Department of Defense radar that that data informed a large dynamic Bayesian network and that captured all the statistical correlations and relationships between the the relevant variables this was done while I was at MIT Lincoln Laboratory and then what what we can do is sample from that model and then generate you know millions or billions of scenarios that we can then run in simulation great yeah if I can my second question is there are all kinds of airplanes and so how I assume like the sensors that are on the planes might be different certainly there are flying capabilities so I assume that there must be an element of the ASX system that is aware of what kind of plane it's sitting on yeah there are different flavors so there's one called a cow's XA that's meant for large unmanned large manned aircraft there's Xu for unmanned aircraft with different flight capabilities there there's one for small unmanned aircraft and the challenge is that they they all have different platform limitations different sensing capabilities and so forth but returning to your question about the the modeling I so we had a wealth of data for manned aircraft but we want to put this put a flavor of this system on on urban air mobility systems like personal air vehicles the are largely autonomous yes the Amazon delivery drones or ones that actually carry humans whoa okay yeah I ability to order that from Amazon yes yeah that is not really available but we need to build up models so that we can we can plan with respect for them holiday tit and and so forth and so then there isn't a lot of data and so we have to build tools that can help extract expert judgment about you know the characteristics of these systems and how they'll encounter each other and so the next generation of a Cass X you might even rename it will have a much broader range of applications and therefore it has to it will not just be informed by empirical data but you will have to inform presumably with some sort of simulation although you did mention expert opinion about how things and so I guess this is an example where you're bringing in human expertise into this otherwise automated system that's right so what we want to bring in human expertise into the creation of these models the validation of the models but also in the specification of the objectives right and so for a cow sex this this is this is one system to be used worldwide right and so there are many different stakeholders we don't have to it's not enough to just please the FAA we need to make sure that Eurocontrol and the International Civil Aviation Organization but they're on board with the system and they they have potentially differing objectives different tolerances different places where they want to be on the trade-off curves and so we actually need AI to help arrive at consensus so as we finish up we a couple minutes left I wanted to go to this issue of validation so you guys work very hard you do your best effort but even with your best effort and your I'm sure good relationships with all these agencies they and the users need to trust these systems how do you approach validation is it empirical are there things that are provable what's the approach uh so the the modeling and simulation that gets us maybe about seventy or eighty percent of the way there other dimensions that have been important in establishing confidence in autonomous systems includes using as a basis fundamentally sound methods so as you know the dynamic programming has been around for a long time the work of Richard bellman in the fifties and so forth these these techniques are are well established and and they're they're they're sound we also really want to to the extent possible come up with mathematical proofs that the system will be safe under certain situations and our ability to do that depends upon what kind of system we're working on whether it's a aircraft collision avoidance system where for driverless cars in in some situations we may be able to provide proofs now in order to prove anything we generally have to make very strong assumptions about the sensor error characteristics and and so forth the acceleration limits and but we have been working on on tools and people all around the world have been working on applying what are called formal methods to the verification and validation of these systems now this becomes very tricky when the system involves a neural network so a neural network is not being used in in a caste X this is the new class of algorithm that has taken machine learning by storm which are famous for their good performance and for their inscrutability that's right and also over the past few years neural networks have been observed to fail under somewhat benign examples so if you make a small modification to a stop sign maybe it misclassifies the stop sign as a yield sign or a speed limit sign or whatever and so in collaboration with with others in particular Clark Barrett and guy Katz we've been looking at ways to prove properties about neural networks and including situations where a neural network is being used as a controller we have a long way to go until we're able to use these tools on on very large networks but we've been able to you apply them to smaller networks as a proof of concept well this sounds extremely exciting and obviously the validation aspects of all this is where the proof will be but I want to thank you for your efforts in this area and I want to thank you all for listening to the future of everything I'm Russ Altman if you missed any of this episode listen anytime on demand with the Sirius XM app 