 The adoption of AI is accelerating and primarily this is because we have so much more data now and we have the compute power to actually do something with it. It doesn't take days to run your predictive model. It takes hours. Sometimes even minutes. The risk to companies that don't embrace machine learning or artificial intelligence; they're gonna fall behind. The challenges, the mindset. So in the new new way of thinking when you have an AI, when you're collecting data, when you do the product, when you ship the product, or how do you bring the value? Public perception can be another challenge which can hinder the uptake of AI. AI can be an enabler. It can shift jobs to new higher skills more productive types of roles because AI is simply a tool that people can use in a way that's appropriate. Many aspects of it weren't necessarily looks so different from what you see today, but will simply get better. Silicon companies like Intel and ARM are now designing and making chips where the AI training algorithms are embedded into those chips in hardware and so you see performance factors of one hundred or a thousand and so what we're seeing in some summary is much more computing power available to perform all the math that's needed. There are some potential challenges which may hinder the advance of AI, for example data privacy concerns. And also how do we protect the personal information, the medical information, your financial information and, in the meantime, still can help you with building the algorithm with your critical information or personal information data, but not really leverage it. The privacy laws, for example, GDP are in Europe are quite strict and you have to as a business be very aware of those when you're collecting data from customers or third-party companies or individuals. Government also needs to be monitoring potentially controlling and managing how AI is used in society in the future. And so we worry that a computer is gonna somehow drive my car for me and what happens if, you know, the computers wrong or what happens if the computer makes a decision different than the decision I would make? If the car hits someone, which already happened, who is taking the responsibility? Is the software company taking the responsibility or is the data science that developed the algorithm? Can I take the responsibility? I think right now it's, it's also a empty field. There's no, there's no specific laws. So there are many ways in which government can and should respond to AI and crucially government needs to be engaged needs, to have their own experts analyzing, researching, talking to industry in order to make sure that the adoption of AI and widespread use of AI is done in a way that benefits society. It's difficult to understand artificial intelligence. It's a complicated field. But if you can create tools that put that in the hands of the decision-makers and Make it simple enough for them to use and simple enough for them to understand then it becomes a very valuable tool. 