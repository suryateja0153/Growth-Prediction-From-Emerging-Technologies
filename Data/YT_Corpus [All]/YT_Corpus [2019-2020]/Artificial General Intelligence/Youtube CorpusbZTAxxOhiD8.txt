 artificial general intelligence AGI is the intelligence of a machine that could successfully perform any intellectual task that a human being can it is a primary goal of some artificial intelligence research in a common topic in science fiction and future studies some researchers refer to artificial general intelligence as strong AI full AI or is the ability of a machine to perform general intelligent action others reserved strong AI for machines capable of experiencing consciousness some references emphasize a distinction between strong AI n applied AI also called narrow AI or weak AI the use of software to study or accomplish specific problem-solving or reasoning tasks we ki in contrast to strong AI does not attempt to perform the full range of human cognitive abilities as of 2017 over 40 organizations worldwide are doing active research on AG AI topic requirements various criteria for intelligence have been proposed most famously the Turing test but to date there is no definition that satisfies everyone however there is wide agreement among artificial intelligence researchers that intelligence is required to do the following reason use strategy solve puzzles and make judgments under uncertainty represent knowledge including common-sense knowledge plan learn communicate in natural language and integrate all these skills towards common goals other important capabilities include the ability to sense EGC and the ability to act eg move and manipulate objects in the world where intelligent behavior is to be observed this would include an ability to detect and respond to hazard many interdisciplinary approaches to intelligence eg cognitive science computational intelligence and decision-making tend to emphasize the need to consider additional traits such as imagination taken as the ability to form mental images and concepts that were not programmed in and autonomy computer-based systems that exhibit many of these capabilities do exist EGC computational creativity automated reasoning decision support system robot evolutionary computation intelligent agent but not yet at human levels topic tests for confirming human level AGI the Turing test Turing a machine and a human both converse sight unseen with a second human who must evaluate which of the two is the Machine which passes the test if it can fool the evaluator a significant fraction of the time no Turing does not prescribe what should qualify as intelligence only that knowing that it is a machine should not disqualify it the coffee test was niak a machine is required to enter an average American home and figure out how to make coffee find the coffee machine find the coffee add water find a mug and brew the coffee by pushing the proper buttons the robot college student tests Gertz all a machine enrolls in a university taking and passing the same classes that humans would and obtaining a degree the employment test Nielsen a machine works an economically important job performing at least as well as humans in the same job the flat-pack furniture tests tony Severns a machine is required to unpack and assemble an item of flat-packed furniture it has to read the instructions and assemble the item as described correctly installing all fixtures topic q tests AGI Chinese researchers Fung Lou Yong Chi and yang Lu conducted intelligence tests in the summer of 2017 with public available and freely accessible weak AI such as Google key or Apple Syrian others at the maximum these kiss reached a value of about 47 which corresponds approximately to a six-year-old child in first grade an adult comes to about 100 on average in 2014 similar tests were carried out in which the kiss reached a maximum value of 27 topic problems requiring AGI to solve the most difficult problems for computers are informally known as AI complete or AI hard implying that solving them is equivalent to the general aptitude of human intelligence or strong AI beyond the capabilities of a purpose specific algorithm AI complete problems are hypothesized to include general computer vision natural language understanding and dealing with unexpected circumstances while solving any real-world problem AI complete problems cannot be solved with current computer technology alone and also require human computation this property can be useful to test for the presence of humans as with Capt CAS and for computer security to repel brute-force attacks topic classical AI my research began in the mid 1950s the first generation of AI researchers was convinced that artificial general intelligence was possible and that it would exist in just a few decades as AI pioneer Herbert a Simon wrote in 1965 machines will be capable within 20 years of doing any work a man can do their predictions were the inspiration for Stanley Kubrick and arthur c clarke scare achter HAL 9000 who accurately embodied what AI researchers believed they could create by the year 2001 of note is the fact that AI pioneer Marvin Minsky was a consultant on the project of making HAL 9000 as realistic as possible according to the consensus predictions of the time revere quotes him as having said on the subject in 1967 within a generation the problem of creating artificial intelligence will substantially be solved although Minsky states that he was misquoted however in the early 1970s it became obvious that researchers had grossly underestimated the difficulty of the project funding agencies became skeptical of AGI and put researchers under increasing pressure to produce useful applied AI as the 1980s began Japan's fifth-generation computer project revived interest in AGI setting out a ten-year timeline that included AGI goals like carry on a casual conversation in response to this and the success of expert systems both industry and government pumped money back into the field however confidence in AI spectacularly collapsed in the late 1980s and the goals of the fifth-generation computer project were never fulfilled for the second time in 20 years AI researchers who had predicted the imminent achievement of AGI had been shown to be fundamentally mistaken by the 1990s AI researchers had gained a reputation for making vain promises they became reluctant to make predictions at all and to avoid any mention of human level artificial intelligence for fear of being labeled wild-eyed dreamer s topic current narrow AI research in the 1990s and early 21st century mainstream AI has achieved far greater commercial success and academic respectability by focusing on specific subproblems where they can produce verifiable results and commercial applications such as artificial neural networks computer vision or data mining these applied AI systems are now used extensively throughout the technology industry and research in this vein is very heavily funded in both academia and industry most mainstream AI researchers hope that strong AI can be developed by combining the programs that solve various subproblems using an integrated agent architecture cognitive architecture or sub sumption architecture Hans Moravec wrote in 1988 I am confident that this bottom-up route to artificial intelligence will one day meet the traditional top-down route more than halfway ready to provide the real-world competence in the common sense knowledge that has been so frustratingly elusive in reasoning programs fully intelligent machines will result when the metaphorical Golden Spike is driven uniting the two efforts however even this fundamental philosophy has been disputed for example Steven Harned of Princeton concluded his 1990 paper on the symbol grounding hypothesis by stating the expectation has often been voiced that top-down symbolic approaches to modeling cognition will somehow meet bottom-up sensory approaches somewhere in between if the grounding considerations in this paper are valid then this expectation is hopelessly modular and there is really only one viable route from sense to symbols from the ground up a free-floating symbolic level like the software level of a computer will never be reached by this route of versa nor is it clear why we should even try to reach such a level since it looks as if getting there would just amount to uproot our symbols from their intrinsic meanings thereby merely reducing ourselves to the functional equivalent of a programmable computer topic artificial general intelligence research artificial general intelligence AGI describes research that aims to create machines capable of general intelligent action the term was used as early as 1997 by Mark Braud in a discussion of the implications of fully automated military production and operations the term was reintroduced and popularized by Shane league and Ben Gertz all around 2002 the research objective is much older for example Doug Lin at cyc project that began in 1984 and Alan Newell saw project are regarded as within the scope of AGI AGI research activity in 2006 was described by Pei Wong and Ben girsl as producing publications and preliminary results as yet most AI researchers have devoted little attention to AGI with some claiming that intelligence is too complex to be completely replicated in the near term however a small number of computer scientists are active in AGI research and many of this group are contributing to a series of AGI conferences the research is extremely diverse and often pioneering in nature in the introduction to his book goat Saul says that estimates of the time needed before a truly flexible AGI is built vary from 10 years to over a century but the consensus in the AGI research community seems to be that the timeline discussed by reycarts file in the singularity is near ie between 2015 and 2045 is plausible most mainstream AI researchers doubt that progress will be this rapid organizations explicitly pursuing AGI include the Swiss AI lab i-dsi a nice sense vicarious Mooloolaba the OpenCog foundation adaptive AI leader and new mentor and the associate Redwood Neuroscience Institute in addition organizations such as the machine intelligence Research Institute and open I have been founded to influence the development path of AG I finally projects such as the human brain project have the goal of building a functioning simulation of the human brain a 2017 survey of AGI categorized 45 known active R&D projects that explicitly or implicitly through published research research AGI with the largest three being deep mind the human brain project and open I based article namely deep mind with their success in human player simulation for eg alphago made use of new concepts reinforcement underscore learning to improve already trained networks with new data or unsupervised underscore learning eg by generative adversarial network to get improved networks by competition topic processing power needed to simulate a brain topic whole brain emulation a popular approach discussed her achieving general intelligent action is whole brain emulation a low-level brain model is built by scanning and mapping a biological brain in detail and copying its state into a computer system or another computational device the computer runs a simulation model so faithful to the original that it will behave in essentially the same way as the original brain or for all practical purposes indistinguishably whole brain emulation is discussed in computational neuroscience and neuroinformatics in the context of brain simulation for medical research purposes it is discussed in artificial intelligence research is an approach to strong AI neuroimaging technologies that could deliver the necessary detailed understanding or improving rapidly and futurist reycarts file in the book The Singularity is near predicts that a map of sufficient quality will become available on a similar timescale to the required computing power topic early estimates for low-level brain simulation an extremely powerful computer would be required the human brain has a huge number of synapses each of the 1011 100 billion neurons has on average 7,000 synaptic connections to other neurons it has been estimated that the brain of a three-year-old child has about 10-15 synapses 1 quadrillion this number declines with age stabilizing by adulthood estimates vary for an adult ranging from 1014 to 5 times 1014 synapses 100 to 500 trillion an estimate of the brains processing power based on a simple switch model for neuron activity is around 1014 100 trillion synaptic updates per second subs in 1997 Kurtz file looked at various estimates for the hardware required to equal the human brain and adopted a figure of 1016 computations per second CPS for comparison if a computation was equivalent to one floating-point operation a measure used to rate current supercomputers then 1016 computations would be equivalent to 10 petaflop s-- achieved in 2011 he used this figure to predict the necessary hardware would be available sometime between 2015 and 2025 if the exponential growth in computer power at the time of writing continued topic modeling the neurons in more detail the artificial neuron model assumed by Kurt's file and used in many current artificial neural network implementations is simple compared with biological neurons a brain simulation would likely have to capture the detailed cellular behavior of biological neurons presently only understood in the broadest of outlines the overhead introduced by full modeling of the biological chemical and physical details of neural behavior especially on a molecular scale would require computational powers several orders of magnitude larger than Kurt's files estimate in addition the estimates do not account for glial cells which are at least as numerous as neurons and which may outnumber neurons by as much as ten to one and are now known to play a role in cognitive processes topic current research there are some research projects that are investigating brain simulation using more sophisticated neural models implemented on conventional computing architectures the artificial intelligence system project implemented non real-time simulations of our brain with ten eleven neurons in 2005 it took 50 days on a cluster of 27 processors to simulate one second of a model the Blue Brain Project used one of the fastest supercomputer architectures in the world IBM's Blue Gene platform to create a real-time simulation of a single rat neocortical column consisting of approximately 10,000 neurons and 108 synapses in 2006 a longer-term goal is to build a detailed functional simulation of the physiological processes in the human brain it is not impossible to build a human brain and we can do it in ten years Henry Markram director of the Blue Brain Project said in 2009 at the TED conference in Oxford they have also been controversial claims to have simulated a cat brain neuro silicon interfaces have been proposed as an alternative implementation strategy that may scale better Hans Moravec addressed the above arguments brains are more complicated neurons have to be modeled in more detail in his 1997 paper when will computer hardware match the human brain he measured the ability of existing software to simulate the functionality of neural tissue specifically the retina his results do not depend on the number of glial cells nor on what kinds of processing neurons perform we're topic complications of an criticisms to AI approaches based on simulation a fundamental criticism of the simulated brain approach derives from embodied cognition where human embodiment is taken as an essential aspect of human intelligence many researchers believe that embodiment is necessary to ground meaning if this view is correct any fully functional brain model will need to encompass more than just the neurons ie a robotic body Gert saw proposes virtual embodiment like second life but it is not yet known whether this would be sufficient desktop computers using micro processors capable of more than 109 CPS Kurt's files non-standard unit computations per second see above have been available since 2005 according to the brain power estimates used by Kurt's file and Moravec this computer should be capable of supporting a simulation of a be brain but despite some interest no such simulation exists there are at least three reasons for this firstly the neuron model seems to be oversimplified see next section secondly there is insufficient understanding of higher cognitive processes to establish accurately what the brains neural activity observed using techniques such as functional magnetic resonance imaging correlates with thirdly even if our understanding of cognition advances sufficiently early simulation programs are likely to be very inefficient and will therefore need considerably more Hardware fourthly the brain of an organism while critical may not be an appropriate boundary for a cognitive model to simulate a be brain it may be necessary to simulate the body and the environment the extended mind thisis formalizes the philosophical concept and research into cephalopods has demonstrated clear examples of a decentralized system in addition the scale of the human brain is not currently well constrained one estimate puts the human brain at about 100 billion neurons and 100 trillion synapses another estimate is 86 billion neurons of which 16 point 3 billion are in the cerebral cortex and 69 billion in the cerebellum glial cell synapses are currently unquantified but are known to be extremely numerous topic artificial consciousness research although the role of consciousness in strong AI AGI is debatable many AG AI researchers regard research that investigates possibilities for implementing consciousness as vital in an early effort Egor Alexander argued that the principles for creating a conscious machine already existed but that it would take 40 years to train such a machine to understand language topic relationship to strong AI in 1980 philosopher John Searle coined the term strong AI as part of his Chinese room argument he wanted to distinguish between two different hypotheses about artificial intelligence an artificial intelligence system can think and have a mind the word mind has a specific meaning for philosophers as used in the mind-body problem or the philosophy of mind an artificial intelligence system can only act like it thinks and has a mind the first one is called the strong AI hypothesis and the second is the weak AI hypothesis because the first one makes the strongest statement it assumes something special has happened to the machine that goes beyond all its abilities the we can test so referred to the strong AI hypothesis as strong AI this usage is also common in academic AI research and textbooks the weak AI hypothesis is equivalent to the hypothesis that artificial general intelligence is possible according to Russell and Norvig most AI researchers take the weak AI hypothesis for granted and don't care about the strong AI hypothesis in contrast to Searle Kurt's file uses the term strong AI to describe any artificial intelligence system that acts like it has a mind regardless of whether a philosopher would be able to determine if it actually has a mind or not topic possible explanations for the slow progress of AI research since the launch of AI research in 1956 the growth of this field has slowed down over time and has stalled the aims of creating machines skilled with intelligent action at the human level a possible explanation for this delay is that computers lack a sufficient scope of memory or processing power in addition the level of complexity that connects to the process of AI research may also limit the progress of AI research while most AI researchers believe strong AI can be achieved in the future there are some individuals like Hubert Dreyfus and Roger Penrose who deny the possibility of achieving strong AI John McCarthy was one of various computer scientists who believe human level AI will be accomplished but a date cannot accurately be predicted conceptual limitations are another possible reason for the slowness in AI research AI researchers may need to modify the conceptual framework of their discipline in order to provide a stronger base and contribution to the quest of achieving strong AI as William Coxon wrote in 2003 the framework starts from whys and bounds observation that intelligence manifests itself only relative to specific social and culture contexts furthermore AI researchers have been able to create computers that can perform jobs that are complicated for people to do but conversely they have struggled to develop a computer that is capable of carrying out tasks that are simple for humans to do a problem described by David Gallinger is that some people assume thinking and reasoning are equivalent however the idea of whether thoughts and the creator of those thoughts are isolated individually has intrigued AI researchers the problems that have been encountered in AI research over the past decades have further impeded the progress of AI the failed predictions that have been promised by AI researchers in the lack of a complete understanding of human behaviors have helped diminish the primary idea of human level AI although the progress of AI research has brought both improvement and disappointment most investigators have established optimism about potentially achieving the goal of AI in the 21st century other possible reasons have been proposed for the lengthy research in the progress of strong AI the intricacy of scientific problems in the need to fully understand the human brain through psychology and neurophysiology have limited many researchers from emulating the function of the human brain into a computer hardware many researchers tend to underestimate any doubt that is involved with future predictions of AI but without taking those issues seriously can people then overlook solutions to problematic questions Croxon says that a conceptual limitation that may impede the progress of AI research is that people may be using the wrong techniques for computer programs and implementation of equipment when AI researchers first began to aim for the goal of artificial intelligence a main interest was human reasoning researchers hope to establish computational models of human knowledge through reasoning and to find out how to design a computer with a specific cognitive task the practice of abstraction which people tend to redefine when working with a particular context in research provides researchers with a concentration on just a few concepts the most productive use of abstraction in AI research comes from planning and problem-solving although the aim is to increase the speed of a computation the role of abstraction has posed questions about the involvement of abstraction operators a possible reason for the slowness in AI relates to the acknowledgement by many AI researchers that heuristics is a section that contains a significant breach between computer performance and human performance the specific functions that are programmed to a computer may be able to account for many of the requirements that allow it to match human intelligence these explanations are not necessarily guaranteed to be the fundamental causes for the delay in achieving strong AI but they are widely agreed by numerous researchers there have been many AI researchers that debate over the idea whether machines should be created with emotions there are no emotions in typical models of AI and some researchers say programming emotions into machines allows them to have a mind of their own emotion sums up the experiences of humans because it allows them to remember those experiences david Galanter writes no computer will be creative unless it can simulate all the nuances of human emotion this concern about emotion has posed problems for AI researchers and it connects to the concept of strong AI as its research progresses into the future topic consciousness there are other aspects of the human mind besides intelligence that are relevant to the concept of strong AI which play a major role in science fiction and the ethics of artificial intelligence consciousness to have subjective experience and thought self-awareness to be aware of oneself as a separate individual especially to be aware of one's own thoughts sentient the ability to feel perceptions or emotions subjectively sapiens the capacity for wisdom these traits have a moral dimension because a machine with this form of strong AI may have legal rights analogous to the rights of human animals also bill joy among others argues a machine with these traits may be a threat to human life or dignity it remains to be shown whether any of these traits are necessary for strong AI the role of consciousness is not clear and currently there is no agreed test for its presence if a machine is built with a device that simulates the neural correlates of consciousness would it automatically have self-awareness it is also possible that some of these properties such as sentience naturally emerge from a fully intelligent machine or that it becomes natural to ascribe these properties to machines once they begin to act in a way that is clearly intelligent for example intelligent action may be sufficient for sentience rather than the other way around in science fiction AGI is associated with traits such as consciousness sentience sapiens and self-awareness observed in living beings however according to philosopher John Searle it is an open question whether general intelligence is sufficient for consciousness strong AI as defined above by reycarts file should not be confused with Searles strong AI hypothesis the strong AI hypothesis is the claim that a computer which behaves as intelligently as a person must also necessarily have a mind and consciousness AGI refers only to the amount of intelligence that the Machine displays with or without a mind topic controversies and dangers topic feasibility opinions very both on whether and when artificial general intelligence will arrive at one extreme AI pioneer Herbert a Simon wrote in 1965 machines will be capable within twenty years of doing any work a man can do however this prediction failed to come true Microsoft co-founder Paul Allen believed that such intelligence is unlikely in the 21st century because it would require unforce evil and fundamentally unpredictable breakthroughs and are scientifically deep understanding of cognition writing in The Guardian robot assist alan winfield claimed the gulf between modern computing and human level artificial intelligence is as wide as the gulf between current spaceflight and practical faster-than-light spaceflight AI experts views on the feasibility of AGI wax and wane and may have seen a resurgence in the 2010s for polls conducted in 2012 and 2013 suggested that the median guess among experts for when they'd be 50 percent confident AGI would arrive was 2040 to 2050 depending on the poll with the mean being 20 81 it is also interesting to note sixteen point five percent of the experts answered with never when asked the same question but with a ninety percent confidence instead further current AGI progress considerations could found below hash tests underscore four underscore confirming underscore human - level underscore a ghee or hash eek - tests underscore a ghee topic potential threat to human existence the creation artificial general intelligence may have repercussions so great and so complex that it may not be possible to forecast what will come afterwards thus the event in the hypothetical future of achieving strong AI is called the technological singularity because theoretically one cannot see past it but this has not stopped philosophers and researchers from guessing what the smart computers or robots of the future may do including forming utopia by being our friends or overwhelming us in an AI take over the latter potentiality is particularly disturbing as it poses an existential risk for mankind topic self-replicating machines smart computers or robots would be able to design and produce improved versions of themselves a growing population of intelligent robots could conceivably out-compete inferior humans in job markets in business in science in politics pursuing robot rights and technologically sociologically by acting as one and militarily topic emergent super intelligence if research into strong AI produced sufficiently intelligent software it would be able to reprogram and improve itself a feature called recursive self-improvement it would then be even better at improving itself and would probably continue doing so in a rapidly increasing cycle leading to an intelligence explosion and the emergence of super intelligence such an intelligence would not have the limitations of human intellect and might be able to invent or discover almost anything hyper intelligent software might not necessarily decide to support the continued existence of mankind and might be extremely difficult to stop this topic has also recently begun to be discussed in academic publications as a real source of risks to civilization humans and planet Earth one proposal to deal with this is to make sure that the first generally intelligent AI is a friendly AI that would then endeavor to ensure that subsequently developed a eyes were also nice to us but friendly AI is harder to create than plain AGI and therefore it is likely in a race between the two that non-friendly AI would be developed first also there is no guarantee that friendly AI would remain friendly or that its progeny would also be good topic see also equals equals nodes 