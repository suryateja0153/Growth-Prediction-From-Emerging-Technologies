 good afternoon at a warm welcome to the first ever digital global Cambridge I'm your host Stephen tube for the vice-chancellor of the University of Cambridge it's great to have you with us for more than five years now we've taken aim bridge ideas to locations all around the globe welcoming local groups of alumni and friends now we're bringing Cambridge thinking and expertise to a much wider audience in fact this afternoon we have more than 1,100 people on this fall from 64 countries representing all 31 of our colleges welcome it's certainly our biggest ever global Cambridge event and the most truly global today we're going to be discussing artificial intelligence and power first we'll hear from dr. Shawn oh hey gertie then dr. kanta aha first a few housekeeping points during today's webinar your microphones and cameras will be turned off but you will see and hear our speakers and of course me but that doesn't mean that we don't want to hear from you on the contrary we welcome your question you can submit a question at any point you don't have to wait until the end simply by clicking on the Q&A box at the bottom of the page and typing in your question after our speakers have given their presentations I have some questions for them and then I'll open up the questions from you now we're expecting there to be quite a number of questions probably more than we can actually answer but we'll do our best to get through as many as we can this event is being recorded and it will be shared on YouTube next week today I'm speaking from my home in Cambridge where I'm fortunate to be surrounded by books and some beautiful works of art outside the stunning architecture and gardens of Ambridge a place that's usually buzzing with talent creativity and dreams the ability of human beings to express ourselves through art through music and through words is a key factor that we've used to distinguish ourselves from other animals our imaginations it said are what make us human are they in 2018 Christie's sold a painting created using artificial intelligence for more than 300,000 pounds the algorithms behind it could apparently learn aesthetics and it taught itself eight if art is the mirror of the soul is it possible that the reflection created could be soul less well the brilliant Cambridge graduate Alan Turing once said that a computer would deserve to be called intelligent if it could deceive a human into believing that it was human it seems that we're already being to see although we must question whether that is by the machine itself or by the humans who program now we know that ethical questions swirl around the use of technology to persuade us to do things to recruit us for work to replace our jobs to reinforce or introduce cultural biases algorithms ensure that we are bombarded with advertising with connections with real and fête news the internet seems all pervasive will consider this writing in 1909 incredible because even private use of landline telephones had hardly begun another Cambridge alumnus ianforster seemed to predict the Internet in his short story the machine stops I've been rereading the story during lockdown and I find it extremely resin Forster visualizes a world where human beings no longer think they need each other only the Machine a world where no one interacts even with family except through the Machine and where they pressed button to turn on music here a lecture or order items they need it's eerily familiar Kuno one of the rare people who rebels against the machine cries out we created the machine to do our will but we cannot make it do our will now it's robbed us of a sense of space and of the sense of touch it's blurred every human relation the Machine obscures past and present creating a world where people can learn as they wish but only what the machine lets them know in a time before algorithms existed Forrester predicted technology that could reinvent history eventually the machine stops and all its internal civilization dies with it but Forrester leaves the reader with a glimpse of hope there's a hint of life outside the machine but the late great physicist Stephen Hawking suggested that and I quote full artificial intelligence but spelled the end of the human race it would take off on its own and redesign itself at ever increasing rates humans who are limited by slow biological evolution couldn't compete and would be superseded and whoa artificial intelligence is powerful indeed in Forrester story it's the machine that has the power but Douglas Adams's is creation Marvin the Paranoid Android is built entirely to serve is this a more accurate vision of the technologies that were developing I didn't ask to be made he says no one consulted me or considered my feelings in the matter I don't think it even occurred to them that I might have feeling Marvin of course is ridiculous than a satirical invention but despite his misery and his brain the size of a planet he serves his human masters without questioning that such is his role fictional portrayals of artificial intelligence are endlessly fascinating but the reality could be disturbing technology is developing at such a speed that it's almost impossible policy and law makers to keep up the science fiction of Foresters day was still science fiction when I was studying at Cambridge in the 1980s and even for the youngest adult in this virtual room smartphones didn't exist when you were a small child and they only became ubiquitous in your teenage years and yet now we can't imagine our lives without any more than Foresters characters could imagine a life without the machine it seems we can no longer live without Wi-Fi apps Google Maps Wikipedia yesterday it so happens that my internet access disappeared for a few hours I was bereft and increasingly anxious so we need a cohort of experts not only to further develop the technology although that is vital but to research analyze and understand it and to guide those in authority throughout the world and that's why eBridge has established the leader Hume Center for the future of intelligence and the Center for the study of existential risk these two centers working in collaboration with faculties and schools with other universities with government and private part are each exploring the impact of artificial intelligence in our world because we must ensure that the superhuman power that can be wielded through it is used for good to talk to you further about artificial intelligence and power I'd like to welcome to leading Cambridge academics first dr. Shawn oh hey Gertie Shawn is the founding executive director of the Center for the Study of existential risk and he leads its research Direction strategy and management his own research focuses on technological trajectories and the impact of artificial intelligence and other emerging technologies he'll be followed by dr. kanta de ho Kanta is the research project coordinator of the Leverhulme Center for the future of intelligence her research is part of the AI narrative project exploring the public understanding of artificial intelligence as instructed by fictional and non-fictional narratives Shawn over to you first thanks Otis even we're all in social isolation at the moment but life is somehow going on regardless and actually AI is a pretty big part of that online call technologies like this are using AI to filter out background noise and some of them will turn my spoken speech into text if you want that supermarkets are using AI for forecasting the demands that people will need for logistical planning and for planning routes for drivers so that my elderly neighbors get their groceries banks are using AI to detect fraudulent transactions in the masses of payments that are happening online and like a lot of people I'm being kept from going mad by Netflix which is recommending movies to me based on my preference what I've watched before people like me I've watched before in the and direct response to the COBIT crisis it's been really exciting to see what people been developing researchers in Cambridge and worldwide are developing AI techniques to identify disease outbreaks in fact one of the earliest signals of an outbreak a woman was picked up by an AI system overseen by epidemiologists right back at the end of December AI is being and developed to forecast the needs for equipment and resources in hospitals and to find new ways of diagnosing hope in 19 patients whether by supporting analysis of Ches scans or by monitoring the sounds that people make when they breathe air when they cough if they might have the illness all of this is incredibly powerful for supporting an overstretched medical system ai is being used to support researchers and clinicians in scanning and for drug candidates and outside of the lab AI is being used by companies like Facebook to spot and flag online misinformation and conspiracy theories and a whole lot more to put it simply we just wouldn't have been able to respond as effectively to this crisis or to keep life going under lockdown as we have without ai and digital technology so on the next slide I'd like to ask why this is happening now the current AI revolution is in large part based around a type of AI called machine learning machine learning approaches are statistical approaches that allow computer systems to learn from data and then to make predictions or to take actions guided by the data that they take in machine learning is often using combination with other types of AI m technique such as those that make use of collections of human written rules AI and machine learning in particular is very dependent on data but machine learning in turn allows us to make sense of all this data whether through online interactions health records our satellite imagery we're generating much much more data about ourselves and about our world than we ever have before if we have any chance to make sense of this to draw out the patterns and the inferences and to be able to act on all of the end this data we need the tools of AI and at the same time all of this data makes AI itself very powerful across domains from healthcare to business to the really big challenges like climate change clean energy and scientific progress but ass even said for any powerful technology that touches on so many different aspects of our lives at the same time it's important that we don't just consider the opportunities but also the challenges and the longer-term questions about where this might all lead us I've been lucky enough to be involved in two centers in Cambridge that do exactly this on the next slide the Center for the Study of existential risk works on global risk for AI this leads us to consider how artificial intelligence can help us with global challenges like climate change food security biodiversity loss and pandemic outbreaks but also the risks of my post weather in warfare or in cyber security or the implications of the more powerful systems we may develop in future the Leverhulme Center for the future of intelligence is a collaboration between Cambridge Oxford Berkeley and Imperial and considers a much broader range of ethical and societal questions alongside how do we ensure for example that AI doesn't erode our privacy and civil liberties how do we make sure that we understand the limits of the AI systems were putting out to the world at the moment and the biases that may exist in the data that it draws on what can human and animal intelligence tell us about the longer-term potentials of AI and how do our hopes and concerns around AI differ across cultures and ethical traditions worldwide what can we achieve consensus on and how do we reconcile the differences these are all obviously deeply interdisciplinary questions they're not just scientific are technical questions and as a result our centers have computer scientists working hand-in-hand with lawyers social scientists critical theorists and philosophers to try and answer them the global AI narratives project is a fantastic exemplar of the CFI model so at this point I'd like to hand over to my colleague dr. kanta taeho who leads that project and will tell you more about it thank you very much Thank You Sean so I shall just mentioned CFI is an interdisciplinary research center focused on the nature attics and impact of artificial intelligence and we're currently running 15 projects divided over five research programs and the program I work in which you can see on the next slide is called AI narratives and justice so I joined in 2017 as a postdoc on the AI narratives project where we investigated the portrayals and perceptions of AI in the english-speaking world what the dominant narratives look like and how they stereotype the technology those who build it and those who are affected by it and we evidence some serious problems in the ways in which we talk about AI now for instance when the average person thinks of AI they don't tend to think of all those technologies Shawn just mentioned but they think of this bloke the Terminator so from our research Terminator can can move on now emerged a book which came out earlier this year and since we also had interest from those developing the technology industry and policy makers such as the UK Parliament we wrote a non-academic reporters well so both are pictured here and from the start our research has focused on the extent to which portrayal of intelligent machines are anthropomorphize made to look like humans and correspondingly gendered and racialized we've always argued that this process of biasing and stereotyping creates a vicious cycle when the narratives perpetuate stereotypes this affects the culture of the industry itself and who is able to work in it so having a homogeneous group of developers means that the technology will have biases that are not picked up on early enough which leads to inequalities in society which again becomes reflected in new narratives but are there alternatives to these stories is it inevitable that we imagine intelligent machines this way although much AI technology is developed in Silicon Valley the West is not the only place to ever have imagined the existence of intelligent machines comparative research that looks at different religious linguistic philosophical literary and cinematic traditions can make us better understand our own narratives and indicate alternatives this is why we set up the global AI narratives project it emphasizes the narratives outside the english-speaking West including narratives from countries that have a our technologies imposed on them from outside and a rising AI superpowers in this project through a series of regional workshops around the world we're developing a global network of people who work and think in the field of AI narratives in the broadest sense and because of the pandemic we've had to cancel and reschedule many of the workshops but I will highlight one we had last year in Egypt our workshop in Cairo had a strong focus on the post-colonial a neo-colonial aspects of AI technologies and perceptions and many of our local contributors claimed that Egypt was a so-called AI desert there's no development of AI technology ongoing nor are there any notable films or literature or non-fiction works stemming from the region that portray a future with intelligent machines so there's a very strong sense that everything is being imposed either from the West or from Japan but particularly on the Arabian Peninsula nations are developing their own hybrid of Western technologies and stories with local approaches and one example is that even seen a robot pictured here which speaks Arabic however not everyone is equally happy with that hybrid some colors move self Orientalism using Western technologies with aspects that the West would consider typically Middle Eastern such as a robot wearing a Toma in a Kaffir or science fiction stories that feature jinns so on the next slide we see the global AI narrative project is about understanding platforming and networking the decolonizing AI project which I'm currently setting up is about acting on this knowledge now the term decolonizing is often misused but it refers to a process of constantly unsettling and questioning the colonial legacy supporting status quo this can mean enabling people to make the informed decision not to use certain technologies or enabling people to develop their own tools because intelligent machines don't have to be the Masters tools the rest of the world has dreamt of them too this research is far from finished but it has revealed in surprising ways how powerful storytelling about AI is in different parts of the world as people try to come to terms with the immense technological changes sean has mentioned thank you thanks very much canta and Shawn really some fascinating insights and it's going to be fun to pursue these I'm noticing some great questions already coming in from our audience and we'll get to those and in a few minutes time please those of you online do submit questions and we'll get to you shortly one of the interesting things for me about AI is that in in so many ways I'll despite what I talked about in Forrester and and elsewhere the concepts are developing so quickly the technology is emerging so fast I'm curious as to how you actually got interested in this because you probably given your ages it didn't start out in AI so Shawn I understand that your PhD was in genomics how did that transit into an interest in research in a odd you seem to be having a problem with Shawn so I will try and sort that out and I'll go back to canta what about you Cantor where did your interest in AI really emerge I gather by the way that you have a PhD or you have an interest I should say in quantum physics and literature a wonderful combination do do give us some insight into that well that's quite a long story actually I became my studying English literature so I did my undergrad and masters at Leiden University in the Netherlands but I had a semester overseas at UBC in Vancouver and that's really where everything changed now in fact the first time I ever met new vice-chancellor although you wouldn't have seen me among the thousands of students but it was at a pep rally at UBC and this I gather was is a North American tradition where basically everybody who's just come into the university is new students gather in the ice hockey stadium and do their school cheers so we did all that I will not repeat the school cheer for arts that we learned but then suddenly the lights all went off and it became silent and the Imperial March from Star Wars started playing and there was the vice-chancellor then of UBC so aside from from that close encounter we I was able to study anything there during my term abroad so I took a course in Science and Technology studies which was looking at Science and Technology from a humanities perspective and I loved it so I went to stir on to do my thesis on children's science books and then my PhD at Oxford on quantum physics and literature wonderful well I can assure all of our Cambridge alums that we're not going to start playing Star Wars in the senate-house anytime soon Sean can we go back to you sure so can you hear me the stun yes we can when I was doing my PhD the explosion in progress in genome sequencing was just happening and suddenly we have all of this beautiful day to play with to really start to understand some of the big scientific questions like how evolution worked at a genetic level and so I found myself as a biologist having to learn basic programming statistics probability and I was able to make some progress in a rudimentary way but that got me very interested in what would be the more sophisticated ways that we could deal with this kind of scientific information that and we are developing which got me interested in technologies like AI at the same time I became very interested in the sheer pace of progress in scientific and technological research and that brought me to end up reading work by another iconic Cambridge person and Lord Martin Rees who wrote this a wonderful book our final century and another wonderful book on the future where he talked about the big challenges we face the potential that technology plays in tackling those challenges but also the risks posed and the challenge of trying to govern and understand these technologies I got fascinated by that and went to Oxford to work on it and a couple of years later I was lucky enough to be recruited to set up a center to work exactly on these issues in Cambridge it's funny that that was just seven years ago what we've gone from basically part-time me to dozens of us at this point working on a lot of the big challenges Martin wrote about climate change biodiversity biotech and AI and of course Lord Reese is a former master of Trinity College and and really the inspiration behind the creation of the Center for the Study of existential risk Sean you mentioned the question around how a AI can be used to address the fundamental challenges we're facing with the pandemic right now and one of those methods presumably is the use of apps that trace and track how people are interacting with others I'm curious as to how worried do you think we should be about that sort of technology from the standpoint of privacy government control potentially those sorts of issues how do you think about it well the first thing you would say is that these apps differ in the extent to which they use AI so at least the way that for example computer scientists would define them the UK version as I understand it doesn't in any significant way but they are digital technologies and the issues you raise are very relevant I think there are a lot of decisions you can make with these in terms of how much data you collect how you store it who has access to it and these are important questions I'm pretty happy with what I understand of the UK version and in fact the Google and Apple version is even stronger on privacy it these don't collect a huge amount of information and they've taken good pains to consider privacy and security issues the UK have even released the source code and are quite paper explaining their method which has allowed the UK privacy and community to really engage with it I think these are very good steps in governance other parts of the world have deployed apps that draw much more information such as for example your location your credit card usage CCTV footage and at that point I'd be a little bit more nervous I think that data is a very powerful thing and we should think quite carefully before giving it up but I also would say that we are dealing with a crisis that is costing us lives every day and it's particularly costing lives of healthcare professionals anything that we can do to support them including through technology I think we should take very seriously and we'd want to have good reasons to not use the technology at all thanks very much Sean very interesting observations canta anything you'd want add yes so regarding the ianforster quote you read out earlier vice-chancellor it's it's really interesting that again Forrester predicted this idea of what we now call technology creep so you start using technology as an emergency solution for a certain situation and such as for this specific part of pandemic management contact tracing but what tends to and then is that after that situation is resolved the introduction of the Technol the technology that has been introduced does not go away it stays it becomes permanent and at some point people just don't notice it anymore really interesting there's obviously an elephant that's right close to us when we talk about IA i and that is the question of jobs i think the probably the most common concern that is raised by people whenever you talk about AI is somehow we are all going to be replaced by robots or computers there won't be any work for human beings to do again i mean this is clearly a huge question socially and economically how do you think about there is there anything we can learn from existing AI narratives canta that might help us in in thinking through those issues well yes people do tend to focus a lot on the elimination of jobs and nothing coming in their place and resulting unemployment rather than anything alternative that can be created or facilitated by artificial intelligence taking over what we don't like to do so there are examples in fiction such as E&M banks as culture novels where there is no need to do any strenuous labor because that's all been reported sized and taken over by AI there is much less disease and suffering and so people find other things to do ways to enjoy themselves playing games traveling the universe but these stories about the elimination of jobs seem to also sometimes divert attention from the actual robot Association of the workplace where rather than replacing people with robots companies start using people as if they were robots so micromanaging that time putting them under extreme pressure to perform perfectly and flawlessly and having their jobs at risk for be for doing such human things as getting sick thank you that's a really interesting observation Shawn anything you'd like that well one distinction I would make is as sometimes people think about a full job being automated and thus replaced I think what you actually will see in a lot more cases is aspects of somebody's job getting automated and effectively somebody being able to produce a lot more so you know everything but anyone on this call thinks of everything they do in a day it's very varied but there are some aspects of it that have repetitive developments that can be automated so I don't know how many areas will be fully replaced you couldn't fully replace a doctor but you might get to the point where one doctor is doing the work that would have taken five doctors in the past and if you kind of summed up over kind of an economy that may lead to jobs being lost it will also lead to jobs and new jobs being created but there are questions underneath that and such as will the number of jobs being created be equivalent to those being lost and will the people who are losing jobs be in a position to gain other jobs going forwards or will they be for people with new skill sets but I would also add to that that when I think about this I always think about there are a lot of things in society that we consider very valuable but that we don't remuneration looking after our elderly looking after children sports and social activities things that kind of fall outside of traditional economic measures right now in a world in which we can automate and some of the routine tasks why should we not consider adding these things to our measures of economic growth Thanks I thought I mentioned earlier the painting that was sold at Christie's for more than 300 thousand pounds canta you've actually been studying literature as as a way into understanding how humans interact with artificial intelligence and thinking about the future do you imagine a time when writing itself stories can be replaced by a human creation of stories can be replaced through artificial intelligence well there's two sides to that so on the one hand this of course the kind of embodiment and experience of life as a human that is expressed in literature on the other hand there is the more technical side of writing so I've had some very interesting discussions with my undergraduates in English looking at texts that have been written by a eyes and while AI produced poetry can be hard to be to distinguish from human produced poetry the subtleties of producing longer prose seem far too complex basically AI cannot connect sentences in way that makes sense so it can it can produce individual lines that read beautifully and that via vocabulary can sound like they connect but a story we are far far away from thanks very much I'm about to go to questions from the audience but Shawn just before we do that obviously there's been a great deal of focus already in our conversation around ethics and AI trying to ensure that AI is actually used to improve the human condition how do we help governments and other public authorities think about those questions what can Cambridge do what is Cambridge doing in that space I think Cambridge is doing a lot that's of a lot of value hey one thing is recognising the need for cross-disciplinary expertise on these things so outside of what we're doing in our own Center I'm really excited about things like the new doctoral training center on AI for environmental risk bringing together researchers working in AI and people working on the climate environmental side to really serve train each other in working together for the big challenges and train the next cohort of scientists I think this kind of work is incredibly valuable I think the work of centers like the center of science and policy is really important in providing that kind of translational role linking politicians in Whitehall and elsewhere to be thinking about both scientific progress and ethical legal issues that's happening in places like Cambridge lastly I think it's really important that centers I Cambridge hold governments and tech companies accountable to a certain extent so these you know big powerful players are certainly developing technology with all the best of intentions but we have a role to play within that ecosystem to really take an outside view on how things are being developed bring in the sword the sources of expertise we need consider whether vulnerable communities are being included in decision-making processes and so forth and make sure that yeah we're holding them accountable and I guess the last thing I'd say is that Cambridge is a place with a global reach a lot of the impacts of AI are going to be global and a lot of the conversations that we need to foster are ones that involve talking to our colleagues in Beijing in South America we've just released a paper trying to look at resolved misconceptions around differences in AI ethics and governance principles between Western traditions and Chinese AI principles that just came out this week there's a lot that I think ends up being misunderstood between cultures and Cambridge I mean we've got 64 countries on this call we have a wonderful to build those bridges great thanks very much boy we have some wonderful questions so I'm going to get right into them we have a question from Nikhil in Singapore who's a graduate of Hughes Hall the the point is that hypothetically it's possible for artificial general intelligence to learn ethical concepts from the analysis of human interactions is that true would a I be able to learn ethics and then apply the concepts in its own interactions with humans and other AI entities do we know whether that's possible but Fanta yes I certainly think that an AI can learn the way it would be able to learn and infer many things from observing human interactions I think one thing that we should bear in mind is that it will really depend on which kinds of interactions that AI is observing because everything an AI learns comes from those observations from gathering data and so if it sees two people behaving what we would consider less ethically then it has no way of telling whether that is ethical or not and we'll just infer that that's how humans are we have a question from Shenmue who is a graduate of Jesus here in the UK around just where you ended your last observation Sean a global global collaboration but spinning it around what about global competition there is clearly global competition in the development of AI especially we see between the United States and China Europe is involved is that good or bad for the ethical use of AI Shawn that's it's a very good question and complicated enough that we have a paper on that as well I'm called an AI race rhetoric and risks competition in of itself is no bad thing I think competition can often spur innovation and AI affects so many different disciplines and domains that you can have different countries and different groups within different countries leading in different areas and learning from each other I think that there are limits though where competition can get in the way of some of the collaboration we need I mean for example they're like we need some level of interoperability and we are living in a globally connected world and a lot of our whether it's our search engines are our self-driving vehicles are going to be crossing borders I also think that on a lot of these kind of ethical challenges how we use data how we make sure that a AI benefits Society we really do need to try and pool our expertise to the extent that's possible and I think one of the big challenges we'll have is how to sort of balance the bizarre trade-off if you will between allowing sort of innovation that reflects a particular culture is kind of ethical and cultural priorities while also finding common ground on some things that affect us all on a global level we have a question from Scott in Hong Kong who's from Kees whether or not there's a potential that a I will squeeze out or tend to squeeze out minority views or at least make non conformist views seem more odd than the the the question here really comes from assertions that you know little Google or Facebook snooze supply might be actually biased over time because of the patterns of use etc does that get self reinforced how can that be addressed can't I'll start with you yes this is a huge problem in all kinds of applications of AI technologies and is one that again with kovat 19 we are seeing needs to be addressed again and needs to be borne in mind when technologies are developed where do they gather their data how is a recommendation system built up because for instance with kovat 19 it effects men more badly than women so if you have a database that doesn't take gender into account then that means that some people are going to be more at risk than others men are going to be more at risk than women you want to add anything to that well just to reinforce em come to view I mean there there is a potential for a fundamental problem where certain parts of the world in certain communities have more access to technology and are thus feeding more information and data in which may self reinforce I think probably the only way well there are a number of ways in which we can get around that but we do need to look carefully at the data sources involved we need to make sure that they're representatives of communities who are likely to be excluded from these conversations both on the general level in terms of what data kind of goes into whether it's Google are faced with recommendations but also the people who are developing the technology I mean a lot of this is coming from Silicon Valley which is a somewhat homogeneous group we need to make sure the voices of communities that otherwise wouldn't be empowered in these conversations have a have a voice in them I've been quite enthused to see the development of initiatives like the partnership on AI which has tech companies but also has a lot of non-governmental organizations nonprofits who bring in these you know minority views and considerations of vulnerable groups in order to do a more nuanced and careful consideration of these issues thanks very much I've got Elena in France and Eugenio in New York who've asked similar questions around the potential role of intergovernmental organizations arena mentions that UNESCO is currently working on ethical principles around AI and Eugenio asks about the role of the UN more glued more broadly I suppose potentially from a regulatory perspective is there any potential in that is that how this is moving or or are these discussions taking place in different fora I'll start with you on this one Shaun I know that the United Nations is taking this increasingly seriously so a lot of the UN individual bodies have gotten involved in different aspects of AI governance and regulation UNESCO is a wonderful example the ITU is another wonderful example it's been running events and conferences and discussions on AI for a global good and which have been wonderful yes I apologize the United Nations centrally has recently established a high-level digital panel on global cooperation that's chaired by Melinda Gates and Jack Ma and we amongst others have submitted evidence to that and I'm talking to some of the people who are both with that and I think they're doing very good work I mean some of what they're thinking about is how to go from principles there's been a lot of work done on ethical principles whether it's privacy and security justice to the practical application what happens when the rubber hits the road now that is harder to do than to say because these principles come into conflict with each other and different individual countries have different economic societal and cultural priorities so it's going to take I think years of careful work to figure out how to balance these things but I do think that the United Nations can play an important role and is doing good work on this Thanks canta anything you'd add or well the United Nations has also been very supportive in in building individual and informal networks so for instance we launched the global AI narratives project at the AI for good global summit in 2018 and we have really been able to use their very strong network that is much more non-western focused than many AI specific networks thanks very much we have a question from Hanna an Emmanuel grad in the UK about whether or not public perceptions of AI that you've been describing are going to deeply affect the potential for regulation of AI in the future how do we think about that both problem and I suppose opportunity I again we'll start with Anton this one because Hannah was interested in the narratives you're investigating and how they play out yes so we have done some research in collaboration with the BBC on this question of what does the UK public think about AI we ended up giving the paper the title scary robots because that was an exemplary answer that we got that really represented quite a concerning number of views expressed basically many people are strongly influenced by Hollywood by films such as The Terminator by TV series such as West world so all about humanoid robots rising up and threatening our lives and yes that can have very negative impacts for the implementation of AI although in terms of regulation it could also mean that because people are so worried about it we could say well we want very strong regulation of yes technology we want it to be absolutely guaranteed secure on the other hand you can get over regulation from that meaning that regulation will be so strict that the UK will lag behind in terms of development of technologies compared to many other countries we're almost at the end of our time but we have one wonderfully provocative question and you really can only give it a what a one-word answer I think it's a question from Andrew in the UK who grabbed graduated from Peter house could we conceive of admitting at an algorithm or set of algorithms of artificial intelligence as a student at Cambridge yes or no unfortunately we're nowhere near what do you think no absolutely not I've done admissions interviews for a few years now and just thinking of the amazing range of students that we already get way too many to be able to offer place as to I can't think of an algorithm that would get you anywhere near all right that's wonderful actually that's in some sense is reassuring I think it's a good way to end you've been absolutely marvelous thank you both for participating and sharing your insights it has been just a delight to host all of you I hope that it's been informative and we will look forward to other opportunities the next global Cambridge will be in July featuring Professor Robert Miller of the university's whittle lab talking about decarbonisation of the aviation industry stay safe thanks for joining us you 