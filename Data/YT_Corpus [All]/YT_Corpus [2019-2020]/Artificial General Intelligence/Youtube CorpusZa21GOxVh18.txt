 The human brain is the most powerful  supercomputer in the world. All right, let’s see this electrical headquarters of yours in operation. It helps us navigate our environment by carrying out about one thousand trillion  logical operations per second. It’s compact, uses less power than a lightbulb and has potentially endless storage. The human brain is really one of the most complex systems that we can imagine. We have a fundamental lack in our understanding of the way the components in the brain interact. But it is this very interaction that generates cognition and consciousness. All these mind-boggling intricacies have driven our fascination with the brain and for centuries we’ve been trying to map  and understand it. And most recently - replicate it. The brain is certainly a computer that has been evolving  for nearly 4 billion years. And the more we learn about the brain, the more we're able to incorporate the smart ways that it does computation  into our artificial devices. Scientists are beginning to agree that to realize our technological dreams, we need to build computers that work like our brains. One day these computers could in turn help us unlock more secrets of cognition. The brain is packed with neuron cells that constantly communicate with each other through electrical pulses, known as spikes. Each neuron releases molecules that act as messengers and control if the electrical pulse is passed along the chain. This relay race is happening simultaneously throughout billions of neurons. Much like the zeros and ones of the computer world, this is the basic language of the brain. But understanding all of this isn’t enough. We’ve still only scratched the surface when it comes to figuring out how the brain works. The more I'm working on the brain, the more I understand how complex it is, how difficult it is. Many relatively easy cognitive functions cannot really be understood at the level of cells. The human brain  is one of the biggest secrets and mysteries that we have, despite many years of intensive work. Katrin Amunts is at the helm of  the Human Brain Project, a 10 year long attempt at studying the brain. With researchers collaborating across 100 universities, the project is expected to cost around €1 billion. Professor Amunts and her team are working on one part of it, a 3D digital brain atlas. They are creating three different high resolution maps - one of neurons; one of their connections - which uses different colors to indicate the orientation of neurons’ branches; and one map of the receptors  for the messenger molecules. When we think about an atlas of the world, we can map all the different countries. But then we can also see there are maps illustrating the level above the sea or the temperature. And it's a little bit like what we have  in the human brain. There are different aspects. We want to understand where the cells are located. We want to understand where certain areas are located, how they are connected, what is their molecular profile, what is their gene expression that  is important for function. So there is not one single aspect that can explain everything in the human brain. So that means we need different types of maps that reflect different aspects of brain organization. To create the maps, the team is scanning slices of post-mortem brains. We get brains from body donors and process them, embed them in paraffin, and then cut them into 20-micrometer-thick sections. 20 micrometers, this is approximately like thickness of one hair so this is very thin. One brain has approximately 7000 sections. These sections can then be analyzed under the microscope and we can then reconstruct the areas in 3D. Much like a fingerprint, every brain is unique, so to account for these differences, the team scan 10 brains for each of their maps. This generates petabytes of data that’s analyzed with the help of AI and used to run brain simulations on supercomputers but even the supercomputers struggle. So to further our understanding of the brain, we need better machines. We cannot make our chips much faster  without them melting, unless we designed completely new architectures. We cannot make our components much smaller because then we reach component sizes where quantum effects take over. So the computation becomes too imprecise  to be practical. We need to find better solutions in order to increase our computational power. Mihai Petrovici, like many other scientists in the field, thinks that modeling computer hardware  on our brains is the way to go. It will not only increase the speed and efficiency of future machines, but also help build better AI. There are certainly things that computers do much better than brains, such as adding or multiplying big numbers, because this is what they were designed for. Intricate problems in mathematics are accurately solved in the minute fraction of the time required for a human calculation. There is no evolutionary pressure for us to be able to multiply big numbers. Otherwise, certainly our brains would be able to do it. However, there is a strong evolutionary pressure to recognize your surroundings, to be able to build an internal model  of your surroundings. When you hear a noise in the bushes, to be able to imagine that maybe there's a predator there. To be able to recognize faces in order to live in a society where people can actually communicate and cooperate. And this is what evolution has made our brains excel at. This ability to build an internal model of the world, to have, sort of, the world inside your heads, to imagine what is happening around you  even if you don't see it, this is of critical importance for a true artificial intelligence. AI like Google image recognition, Alexa or the autopilot in a self-driving car all work thanks to neural networks, software which already tries to imitate  the way our brain recognizes patterns. One thing that today's artificial intelligence needs in order to be able to perform whatever task it was designed for, is a lot of examples. So in order for Google, for example, to be able to show you pictures of cats, whenever you type in cat, it needs to have seen millions of images of cats. That is certainly not how we humans operate and learn. When you show a child, for example, a cat or whatever other new thing, it just needs to see it a couple of times in order to quickly grasp the main features that are specific for that animal and then recognize it whenever it sees another individual of the species. The scientists at Heidelberg University are working on a different part of the Human Brain Project. They’re using the brain maps developed by Professor Amunts’ team to build computer hardware they hope will help AI  learn like our brains do. This new hardware is called neuromorphic which means formed like neurons or like the brain. Actually, none of what you see here on the outside is really neuromorphic. You might be tempted to think that this is more or less like the machine that you have at home on or under your desk. This would be true for the outside components but at the heart of the system, there lies a piece of hardware that is fundamentally radically different from the chips in your computer, and that is the neuromorphic heart of the system. The microchips on these wafers look nothing like the entangled web of neurons that we have in our heads. But each component communicates like an individual neuron by sending along spikes of electricity  to their many partners. This design immensely increases the operating speed. neuromorphic hardware generates results  10 million times faster than conventional hardware. We certainly believe that this will become a big thing, we will see many applications of these systems for everyday tasks. One of them would be face recognition, pattern recognition in general, speech recognition, the ability to read texts. The ultimate goal, of course, is to create true artificial intelligence. But it's really hard to say by when we will be able to actually copy the brain in an artificial substrate. What we can certainly do and what we are doing right now is - understand particular aspects of computation in the brain. The 4 million artificial neurons packed into this neuromorphic computer are just a tiny fraction of  the 86 billion neurons in the human brain. Still, it’s a big step forward for the machines. Even though our knowledge of the brain has increased over the last few decades, it’s still fragmented. If the Human Brain Project is successful, it could bring this knowledge together and encourage research and collaboration across different scientific fields. And so this effort could be just the beginning of the journey. Better understanding the human brain, is really one of the challenges of the 21st century. We have an increasing amount of people suffering from neurodegenerative diseases, suffering from major depression,  other psychiatric diseases. We need to have new tools to diagnose and have better therapies for these brain diseases. And since we are living in an aging population, these diseases, of course,  play a major role in the future. 