 [Music] hi I'm Arjun gopalan and welcome to episode 3 of noodle structured learning in the previous episode we learnt about natural graphs and how they can be used in neural structured learning while natural graphs are common there are many machine learning tasks where the input data does not form a natural graph for instance if you recall the document classification task from the previous episode we use citations to form a natural graph in the absence of citations we wouldn't have had a graph similarly if we're doing simple image classification or text classification where the input data contains just raw images or text then we may not have a natural graph in either case in this episode we'll discuss how we can apply noodle structured learning to such tasks so what do we do if we don't have a natural graph to begin with the title of the video might have given this away but the main idea is to build or synthesize a graph from the input data building a graph can be done in many ways but in this video we'll use the notion of similarity between instances to build a graph in order to define a similarity metric we need to convert raw instances whether they're documents text or images to corresponding embeddings or dense representations we can do this using pre trained embedding models such as those on tensorflow hub once we convert raw instances to their embeddings we can use a similarity function such as the cosine similarity to compare how similar prayers of embeddings are if the similarity score is greater than a threshold then we add a corresponding edge in the resulting graph repeating this process to cover the entire data set builds a graph and once we have a graph using neural structured learning is straightforward as we saw in the previous episode let's illustrate this workflow for the task of sentiment classification using the IMDB data set this data set contains movie reviews and the task is to classify them as good or bad let's see what the code looks like to build a neural structure learning model for this task here again we use Kerris for illustration but neural structured learning also supports estimators the first step is to load the IMDB data set for simplicity we use a version of it that is part of Kharis once that is done we want to convert the raw text in the movie reviews to embeddings we use swivel embeddings in this example but any other embedding model such as Burt word to ik or an embedding model of your choice may also be used instead once we have created the embeddings we can build a graph using those embeddings neural structure learning provides an API called bill graph to do so notice that it accepts similarity threshold as one of its arguments this allows you to control the threshold below which edges are dropped from the resulting graph in this example we use a threshold of 0.8 once we have the graph we define the features of interest for our model and combine these features with the graph using the pack neighbors API in neural structure learning in this example we use a maximum of 3 neighbors to augment our training data now that we have the Augmented training data the next step is to create a graph regularized model this part is similar to what we did in the previous episode first we define a base model which can be any type of karas model whether it's a sequential model a functional API base model or a subclass model it can also have an arbitrary architecture then we define a graph regularization configuration object which allows you to specify various hyper parameters in this example we use 3 neighbors for graph regularization once this configuration object is created you can draft the base model with the graph regularization wrapper class this will create a new graph Kerris model whose training loss includes a graph regularization term what's left is then just compiling training and evaluating the graph regularized model this example is also available as a collab base tutorial on our website you can find that linked in the description below in summary we looked at how to build-a-bra regular rice model when the input data does not form a natural graph this technique can be applied to all kinds of input data such as text images and videos now graph building is not the only approach to handle input data that does not form a natural graph in fact in the next video you will learn about another aspect of neural structured learning called adversarial learning which can be very useful to improve a models robustness to adversarial attacks that's it for this video there's more information in the description below and before you get to the next video don't forget to hit that subscribe button thank you [Music] 