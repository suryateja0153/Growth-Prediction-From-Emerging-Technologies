 Two countries, Austria and, and- what's the other one? Hungary. Hungary, right? [LAUGHTER] Because, speaks Hungarian. Yeah. So like, Austria and Hungary, that could be an answer. Uh, so the way you thought about this problem was- if, if, if you think about it, it was pretty different from, from, like normal search problems. You had this constraint in your head that, oh, I have two countries that are right next to each other, that's one constraint. And if you were thinking about, oh, one of them needs to start with an A. So you had a bunch of [NOISE] constraints whe- when, when you think about, you have a bunch of constraints when you think about a problem that- that's like this. Uh, and that makes it pretty- like that, that helps us to use different types of model that could be pretty different from state-based models. So this is more of a motivating example. We are gonna talk about these types of models. So, so far, we have talked about reflex based models, state-based models. So we spent some time talking about search problems, MDPs, adversarial games, and then what the plan is to talk about variable-based models, specifically constraint satisfaction problems today and, and on Wednesday. And then we're going to talk about Bayesian networks next week. So we'll have three lectures on Bayesian networks. Uh, so what's gonna happen is, Reed is going to talk, uh, talk about the CSP, the second lecture of CSP on Wednesday, and then Percy is going to be back next week talking about Bayesian networks, and I will do the third lecture of Bayesian networks. So it will be whole mix of us, talking about variable-based models. You'll see all views of us. So, so that's, that's the plan. Okay? All right. So, um, okay, so going back to our paradigm. So our paradigm is, uh, starting with modeling. So how do we model, uh, various types of problems, and then how do we develop inference algorithms? I tried to answer questions we care about, objectives we care about based on those models. And we have been talking about learning a little bit. So, so if you have these models and they are not full models, how do we go about learning, learning these models? So, so here is just a review of what we have talked about so far. In terms of modeling, we talked about various frameworks like search problems, or MDPs, or games. So these were various frameworks that we had, and, and we had different objectives. So we had things like minimum cost path for search problems or we cared about other things like maximizing the value of policies for, uh, for MDPs, or, or games. So this was kind of some of the frameworks we talked about. And in terms of inference, we discussed tree-based algorithms, and we discuss- we discussed graph-based algorithms. So if you remember, backtracking search was the simplest most naive thing we tried out for our search problems. Uh, for, for games, like we looked at minimax and expectimax, which was also going down a tree. And then you can have more, uh, graph-based type algorithms where, where you're looking at a recurrence relationship, and, and examples of that are things like dynamic programming, uniform cost search, A star. In terms of MDPs in games, we looked at value and policy it- iteration. And then in terms of learning, we discussed a few types of methods for each one of these frameworks. We looked at structured perceptron, Q-learning, TD learning. So, so these are some of the topics that we have talked about so far. So, so if you're midway through the quarter, these are all the cool things we have learned so far, and these are for state-based models. Okay? So state-based models were kind of cool. And we had, we had a couple of takeaways from state-based models. So let's just summarize like two main takeaways from state-based models. One of the key way- key takeaways was, was that when we're modeling these, these state-based models, we had, we had local relationships. So, so our model would specify these local interactions and local relationships that we had between the states. So for example, if I wanted to go from S to A, my neighboring state A, then I would think about what would be the cost of going from S to A. So I had this local relationship between them. And the goal was to do inference and an inference was more trying to like look at a global property. Can I find the, the shortest path from some state to some other state in this whole graph? So, so the idea was, let's actually model and specify these local relationships, and then do inference where we find globally optimal solutions. So, so that was kind of the whole idea of state-based models. And the thing that they use, the thing that they, that made them powerful was this concept of a state. So, so let's just summarize what state was. Well, a state is a summary of all past actions that's sufficient to choose future actions optimally. And, and that's how we define states, that's how we went about states. Okay? And, and once we had state, when once we had the notion about state, then our mindset was, I'm gonna move through these states through actions. So I have states that I can think of them as nodes here, and I have actions which, where I can think of them as the edges in this graph. And the question is, how do I go through one state to another state, and what is the sequence of actions I should take? So, so if you think about a policy, like we were talking about a sequence of actions and, and the sequence actually mattered, right? Like I, I would take this action and another action, and the goal is, I'd say for me, to go from here to the door and I would have a [NOISE] sequence of actions that need to go one after each other for me to, to achieve the task. Okay? So the type of problems that we wanna talk about today, um, don't have, they, they have a little bit more structure. They don't really care about ordering. And that's kind of the key difference. So, so when I asked that very first question of pick like two countries, one of them, the name of one of them should start with A, the other one should speak Hungarian and they're not right next to each other, then the way you think of like all those constraints, all the things that you need to satisfy, you don't really need to like follow a specific order. They're a bunch of constraints, you need to satisfy all of them. It really doesn't matter to start from where. And then that's kind of the idea that a, a variable based model is. And, and we're going to go through this example throughout the lecture. So the example is, it's a map coloring example. So, so the idea is, let's say we have a map of, uh, Australia here. And Australia has seven provinces. So these are all the provinces here. And what we wanna do is, we wanna color this map. So, so the question is, how can we color each of these seven provinces with three colors? I have red, green, and blue. So that no two neighboring provinces have the same color. Okay. So that's, that's a task we wanna do. Okay. And then kind of the key idea again here, is the order of things doesn't matter, right? I can pick any of them [NOISE] and pick a color, and then just go from there. It doesn't matter, like, if I'm, if I'm, it matters in the sense of the algorithm side of the things, but in terms of the model, it doesn't matter to, to include that. So, so here, for example, this is one possible solution. Right? Like I can have the map of Australia. I can have these different colors like red, green, and blue for, for different parts of it, and no two neighboring countries have, have the same color. So, so this is one possible solution that we can get, we can have other solutions, er, to get. And, and our goal is to find these types of solutions. Right? All right. So, so I can think of this as a search problem. I can, I can perfectly think of this as a search problem, where let's say, it starts with a partial solution. And my partial solution is, somehow I've decided to, to choose, I'm just gonna refer to these provinces by their first letters. So I'm gonna choose WA, V, and T. I'm gonna just make them red. And now what I wanna do is, I wanna figure out what other colors to use for the rest of the provinces. Okay. So I can just go down like a search tree. So, so my state here is this partial assignment, and I can go down the search tree and I can choose Queensland as, as my next thing. And, and I'm gonna color that red. So if I color that red, everything looks good. Everything is great. So now, I'm looking at Northern Territories, so NT. I'm gonna pick a color, I'm just gonna color that green, let's say. So [NOISE] I color that green. Then if you look at SA, I only have one option for it, right? Because I've already picked red and I've already picked green, and SA is connected to all these red and greens. So, so the only color I can pick for SA is blue. So, so that is, that is all I have. Then how about NSW? Then that has to be green, right? Because, because I've already picked blue right there, so that has to be green. And, and here is one solution. So I just went down a search tree and picked a solution to this problem. I could have picked some other solution like that decision that I made over there to make NT green, that was kinda random, right? Like I can just pick blue there. So let me just pick blue there. And then I can just have another solution, that's a perfectly fine solution, and I'll have my, my map going. How about I choose, I choose a different color for Queensland? So, so I decided, I decided to make it red, maybe I want to make it, uh, blue. So if I make it blue then NT has to be green because that's the only option I can have. And then when I get to NSW, I don't really have any options for it, right? NSW, I have no colors for it that would work. Because, because green is taken, red is taken, blue is taken, NSW is connected to all three of these. That's not really gonna work. How about I choose queen to be- Queensland to be, uh, green, same story, NT has to be blue, SW I don't really have a solution for it. Okay. Okay, so, so this was just going through this example assuming that it's a search problem, and I have these states that represent partial assignments, and I'm going to pick actions and the actions are going to just give a coloring to the next- to some next variable here, okay? So, so the state is partial assignment of colors to provinces and the action I'm going to take is assign the next uncolored province to a compatible color. So I can perfectly think of this problem as a state-based or like using state-based models, using this particular state and action. But, but the thing is there is more structure to the problem and the structure in this particular case comes from the fact that again ordering doesn't matter. So, so variable ordering does not really affect correctness here. It's just a bunch of constraints. It doesn't matter in what order I'm satisfying those constraints. And, and in addition to that the variables, they're, they're kind of interdependent in a local way. So, so for example if I just look at Tasmania like right here, it's not connected to anything, so I can just pick whatever color I want for that. And it's not affecting the rest of my problem. So I don't really need to have some order to like pick t first or pick t last, right? I can just pick a color for t and it doesn't affect the rest of- the rest of my system. Okay. So the idea variable-based models is, let's, let's kind of make our models- like let's make our models simpler than state-based models. Let's now try to figure out what is this the state thing that's sufficient for us to make, er, make decisions in the future and, and pick actions sequentially. Let's try to have an easier language, er, to represent the model of, of a problem that kind of looks like this. So, so the idea is to come up with this new framework. And, and in this new framework, we're going to have variables as opposed to states. So, so we are going to call these things variables. And we're going to have assignments to these variables. So, so the whole job of modeling is to figure out what the variables are and what's sort of assignment we are picking for those variables. And this decision of, well, what order should I color things or what value should I pick for, uh, for, pick for each province like, like that decision of what order of values should I pick? What order of variables should I pick? I can push all of that to inference. Okay. So, so it's not going anywhere, I'm just pushing it to inference. So another analogy here is you can think that you have a difficult problem and you can have like an ad hoc way of going about it and solving it, an, an analogy in programming languages so that it would be, I would be solving it using assembly language. If you look at state-based models, you come up with the idea of state. You're doing something, something more general and you're doing a lot of work and why are you doing that? Because you have a higher level of abstraction, so when you're using something like state-based models, an analogy to that is maybe you're programming in C. So you're moving the level of abstraction. And when you're using things like variable-based models, it's even moving the level of abstractions a little bit higher. It's, it's even like programming in Python. So, so sure you can do the exact same thing in C too, but now you have this higher level of abstraction to think about problems and that makes your model much simpler. And, and the order of things that can become the problem of inference. Okay. All right. Everyone happy with, with why we want to do state-based or we want to do variable based modeling? All right. So, so I've kind of motivated this but I haven't really said what it is, how we go about solving it. So what I want to do for the rest of the class is, I want to start formalizing variable-based models by this idea called factor graphs . And then after that I want to talk a little bit about inference in the case of state- uh, variable-based models. So specifically, I'm going to talk about dynamic ordering and arc consistency as ways- as heuristics that allows us to, to solve these variable-based models. And then towards the end, I just want to show you a couple of examples, other examples of why variable-based models are so powerful and where they come in and just give you some ideas of like what- some other examples to look at, okay? All right, so, so that is the plan for today. So, so let's, let's start with a simpler example. So let's say that I have three people. Maybe I can draw that here. So I have three people, Person 1, Person 2, Person 3, and each of them they are going to choose a color either red or blue, that- that's what they're gonna do, red or blue, red or blue, okay. And each of them have a set of constraints. So, so the idea is maybe this guy really wants to pick blue. So, so really wants to pick blue. Maybe this third person prefers to pick red, but maybe he doesn't- it's not like as bad as this guy so prefers red. And maybe we want to make sure that they pick the same thing. The first person and second person. And maybe we want to ensure that the second person and the third person, we prefer they pick the same, they pick, they pick the same thing- the same color. Okay. So these are some set of constraints almost that I'm putting on, on this example. And the way we can think about these constraints that I've just laid down on this picture is using this idea of a factor graph. So a factor graph is going to have a set of variables. Okay, and this is like analog of states as, as we talked about in state-based models. It's going to have a bunch of variables. I'm going to have three variables because this person is going to pick something, this person is going to pick another color, this last person is going to pick a color. So I'm going to have variables; X_1, X_2 and X_3, okay? Let me actually write down some of these. So we're going to go over a bunch of definitions for the first part of the class at least. So we're going to talk about factor graphs. Factor graphs are going to have some number of variables. We're going to represent variables with capital letters, so like capital X. So in that particular example the variables that I have are X_1, X_2 and X_3. Okay. And each one of these variables, they're going to- they're going to live in some domain, they're either going to get red or blue, right? So, so each one of these X_is, they are going to live in some domain. So we're going to say, X_i lives in some domain of i. So in this particular example, the domain is just red and blue. So each one of these X_is are going to live in either red or blue. And if I pick a value for it, and if I come in and say, well, this guy picked red and this guy picked blue and this guy picked red, then I'm giving an assignment. So that's called an assignment. [NOISE] So an assignment, I'm going to write it with small x. And it's going to tell me well what X1 took and what small means kinda red or blue. So capital means the actual variable. And X2 and X3. What were they? So maybe for this particular example maybe you're talking about red. Blue and red, okay? All right. So, so that was variables. They live in a domain and then we can pick an assignment, okay? So now I have all these constraints and I can write those constraints as something that's called factors. So these factors are going to be functions that tell me how happy I would be if this X1 takes value red or value blue. So their functions, in this case F1 is a function of X1. So, so I'm gonna write, a factor graph needs factors. And these factors are Fj's. There are some number of them. There might be a lot of them. Fj's of, ah, some X taking some value Xi. Some Xi taking some value Xi or some number of, let me just write the most general form right now. X. And these Fj's have to be greater than or equal to zero, okay? So they are kind of telling me how happy I would be, right? So, so here I would have F1 of X1. Um, so if I really want this guy to pick blue then what would be a good factor to put here? What should I say for F1 of X1? So I can write it as an indicator function making sure that X1 definitely takes blue. Maybe I can write it like this, okay? So, ah, so if it is an indicator function what does it say- what does it tell me? If it is an indicator function, if X1 actually takes blue, then the value of this factor is going to be one. If X1 takes red, the value is going to be 0. So I'm kind of treating 0 as this thing that I don't want and anything above 0 as something that I actually want to get, okay? So, so I'm going to have another constraint. This constraint is going to be F2. It's a function of X1 and X2 that's why it's connected to both of them. So I'm gonna draw these squares as, as kind of like showing where the factors are. So, so the circles are my variables. And then the squares are my factors. These functions that kind of told me what are the constraints? What are the things that I need to satisfy? So F2 is going to somehow encode that they need to pick the same thing. Again it can be maybe an indicator function. Making sure this is- these two are equal to each other. And maybe I'll have F3 of. F3 is going to be a function of X2 and X3. [NOISE] This ensures that they sometimes make the same, or sometimes here kinda means that we can have an indicator function, but maybe if they don't pick the same thing you wouldn't be too sad. So, so maybe you don't put 0 for that. So it would be an indicator function plus some constant. That's one way of going about it. And then X3 is going to be take, prefers red. So it's going to have a factor. That says it prefers red, okay? All right. So let's look at the same thing on the slide. So that's a factor graph. So I can actually look at the values of the factors maybe F1 of X1. Maybe what I want is I want if, ah, for that to be equal to 1. If X1 picks blue I want that to be equal to 0. If X1 picks red. For, ah, the two, they have to agree, for the case that they have to agree that I can define it as an indicator function but if they are not equal to each other, if I'm gonna get 0, I'm going to be very unhappy. If they are equal to each other I'm going to get 1. So I would be happy. And then for the case that X2 and X3 needs to kind of be equal to each other, then maybe we can do something like an indicator function plus 2. This means that if they don't pick the same thing, oh I'll be happy. But like if they picked exactly the same thing, I'm going to be even happier. So I'm going to get 3. And then for the last one similar thing I, I preferred the last person to pick red. So I'm gonna give it a value of 2 to that and I'm going to give 1 for the case of blue, okay? So, so these are my factors, question? Does the factor value matter, or is the only thing that matters if it's equal to 0 or not. So good question. So question is, does the factor value matter or is it just like if it is above 0 or not. In general it does matter like what you were picking. For you're soon going to be talking about a specific case of concerns, specific case of factor graphs where the zero and one is the only thing that's, that matters. So I'm not focusing too much on the exact value. It's just if you get zero that's pretty bad. If you get non-zero that's good. So I'm treating them like that because soon we are going to talk about CSPs, constraint satisfaction problems which are just factor graphs where you have 0s and 1s, you don't have anything above them, okay? All right. So let's try to actually write this up. So, um, here's this environment that you can play with it if you want. Um. Okay. This is visible. Yeah. All right. So here you can define variables. So I have variable X1. It can take value red or blue. X2 and X3 similar thing. They can take values red or blue. I have four factors so I'm going to write up what those factors are. Factor F1 depends on X1. It's a function and it's going to return the result of this indicator. And then a similar thing, ah, I'm going to define, ah, the second factor also as a function of X1 and X2 and it returns a value of the indicator and has all these other factors. And on the right you can kind of see these factors being generated. So we're going to look at this environment even more next time when we talk about more fancier inference algorithms, but for now let's move to-. Let's move to finding our factor graphs. All right. So. Alright. So what is a factor graph? So more formally a factor graph has a set of variables X1 through Xn and each one of these variables each one of these Xi's lies in some domain in this case the red or blue was our domain. And then the factors are going to be F1 through Fn. We have m of them in this case let's say. And, and each of these factors is just a function over X that is going to be greater than or equal to 0, okay? So, so that's a factor graph. It tells us what are the things that we really want. So let's look at one example here. So in this- in this particular map coloring example, the variables or the provinces that we have. We have seven of them. The domain is going to be red, green, and blue. So those are the colors that we can pick. And then the factors. Well, the factors here are just going to be telling us that don't pick the same color for two provinces that are neighbors. So I'm going to have factors that are indicators ensuring that we don't give the same value to two neighboring territories. So we have factors that basically connect every neighboring territory. And again this square here corresponds to each one of these functions, question? Now isn't it the same for all the variables? Not necessarily. So the question is is the domain always the same for all variables? It depends on the problem. Not really. Also we are going to talk about how to reduce the domain as we go. So that's, that's another reason that I'm emphasizing on the domain because when we think about the inference algorithm, the domain is not going to stay the same throughout. If I pick a red for example for WA, then NT is not gonna have red in its domain anymore. So, so the reason I keep bringing up the domain is we're going to look at how to update the domain for the- for the inference algorithm, okay? All right. So this is a factor graph. Um, [NOISE] let's define a few more things just so we have a common language to talk about things. So, so we're going to find a scope. So scope of a factor is a set of variables it depends on. So, so it's really simple. So scope. So I'm going to write scope here. Scope. So it's just set of variables a factor depends on. So for example, ah, for this case if I have F2, it depends on two variables X1 and X2. So the scope of F2 is just X1 and X2. Ah, so in this other case, when we looked at the map coloring example. If we look at F1 as a factor that tells us WA and NT should not have the same color. The two variables that are used are WA and NT, okay? So, so that's the scope. Then now that we have the scope, we can define something else called arity which is the number of variables in the scope. So each one of these squares just how many- how many edges is it coming out of it? That's arity. So in this case, this particular square depends on two variables, arity is two. I can have a setting where maybe I have a factor that depends on three variables, then arity is three. I can have a factor that depends on only one variable, then arity is one. And, and if arity is two then we call it- we call the factor a binary factor. If arity is one we call the factor a unary factor. So just common language. [NOISE] So we have arity and then we have-. Which is- which is the number of variables in the scope. And then you have unary, unary, unary factors. When arity is one, our binary factors and arity is two. So it's just defining things. So for example in this case of map coloring F1 is a binary factor. So in the case of map coloring all our factors were binary if you- if you look at it. All right. Let me go back to that. Here it is. So I have a bunch of factors that just say these two variables should not be equal to each other. So I have a bunch of binary factors and that's pretty much the only thing I have, okay? In this case, I have a binary factor, I have a binary factor, I have a unary factor, a unary factor. All right. Okay. So, so far so good. So- so we talked about the assignments, right? The assignments are going to be a setting where we give actual values to these variables. And an assignment can have a weight that tells us how good that assignment is. So- so remember, a factor tells us how good this particular excite, like how happy I would be if x_2 takes a value and x_3 gets a value, a weight tells me how happy I would be for the full assignment. So- so what it is going to be is like in this case, we can- we- we can look at weight to just be a product of- of my factors. So I'm gonna write- uh, maybe I'll just write it in front of here. So I'm going to define a weight of an assignment x. And the way I'm writing that is I'm just gonna write it to be a product of f_j's, uh, j from 1 through m. So I have m factors, so it's going to be f_j's of x taking assignment x. Okay? So for this particular example, we looked at the tables, and each one of these tables represents our factor. But- but now, if I talk about a full assignment, then I'm looking at what does it- what happens if x_1, x_2, and x_3 take all possible values that they could be taking. So I have eight possible options here. And then I'm looking at a weight, eh, as- as a product of ea- all of these factors multiplied out by each other. So- so remember, I was saying well, 0 is the thing that I really don't want to have. So if I have a 0 ever, like that, that's a super like hard constraint that I'm trying to enforce, and that makes my weight equal to 0. So so- if x_1 ever picks red, that was like a hard constraint. We really wanted the first person to pick blue. So fir- if the first person picks red, then the weight is going to be equal to 0. The other thing we really wanted was the first and second person to pick exactly the same color. If they pick different colors, then my second factor is going to be 0, weight of that is equal to 0. Otherwise, I would have different- I- I would have different weights. Maybe the thing I care about is to maximize the weight, so I'll pick the one, the assignment with- with the value 4. Okay? So going back to this, um, demo environment we were just looking at, um, what we can do is, uh, we can- basically, we've defined our factor graph, and we can actually step through it, and you can play with this, but you can basically get these [NOISE] two different- different assignments that- that give you non-zero weights, and you can pick your favorite. So we're gonna talk about various types of algorithms that allow you to compute these weights. Okay? All right. Okay. All right. So weight of an assignment x is just a product of the factors of that assignment. Okay? And then our objective is to maximize the weight of the assignments. So I- I want- what I want to find is, at the end of the day, what I wanna do is I want to find an assignment. So I wanna find that small x that maximizes the weight of, er, of that particular x. Okay? All right. So going back to the map coloring example. So here, um, let's say that we defined all these indicator factors. So if it is an indicator factor, I'm either going to get 0 or 1, I'm not gonna get anything other than that. Then if I have this particular assignment which kinda looks right, then the weight of that assignment is just going to be a bunch of 1 multiplied out by each other, so I'm just gonna get 1. Okay? So- so if I find a solution to this map coloring problem, the weight of that- that particular assignment is going to be 1. I could have another assignment where I don't get, uh, a good solution. I had two of- two of these- these neighboring territories are going to be have the same color if they're both going to be red. Then in that case, two of my factors are going to be 0. If they are going to be 0, the weight is going to be equal to 0. So for this particular map coloring example, where my factors are just indicators, the only weights I can get are 0 or 1. I can either get 0 or I can get 1. If I get one, I find a solution. If I don't get 1, I don't find a solution. Okay? All right. So we have been talking about factor graphs, they're these more general things. Now, we're going to start talking about CSPs, constraint satisfaction problems, which are just factor graphs where all factors are called constraints, and the factors are going to take value 0 or 1. And the constraint is satisfied if the factor takes value 1. [NOISE] So we talked about factor graphs. We're going to talk now about constraint. I'm just gonna write CSP, constraint satisfaction problem, CSPs. Okay? They also have the same variables as before. And we're gonna pick assignments for them. So same thing, I'm gonna- assignments. But the factors are going to be called constraints. [NOISE] And these factors fj's of x are either 0 or 1, they're not anything else. Okay? And if you find an assignment where your weight is equal to one, then that means that you are satisfying all your factors, and that's called the consistent assignment. So you- we have consistency, consistent assignment, assign- I'm gonna write assignment. Um, that is when the weight is equal to 1. If the weight is equal to 0, then we have an inconsistent assignment. So- so it's either 0 or 1. We have consistent assignments or inconsistent assignments. [NOISE] Okay? So an assignment x is consistent if and only if the weight of that particular assignment is 1. That means, all the constraints are satisfied, because constraints are just give me 1 and 0. I'm multiplying 1 and 0. If anything is not satisfied, then the thing is 0, okay? All right. So, so far, summary so far is we have just gone over a bunch of definitions. Factor graph is the more general case of it. Constraint satisfaction problems is more of an all or nothing kind of a situation. So you have hard constraints, everything is a hard constraint. And then you have- so, um, so for example, if you think of map coloring, you can think of that as- as a constraint satisfaction problem because everything is a hard constraint, right? Like you- you don't want any two neighboring countries to have the same color. So you're either going to give 1 if- if that constraint is satisfied, or you're going to give 0 if that's not satisfied. You still have variables. Factors are called constraints. Assignment weight. If that is equal to 1, we have consistent assignment. Otherwise, we have an inconsistent assignment. Can we just think of the CSP as a- Constrained factor graph is that the idea? It's- it's a more constrained factor graph. Yeah, it is- factor graph is this big picture of CSP is an instance of factor graph. All right. So that was factor graphs and constraint satisfaction problems. So, so let's talk about how we go about solving these. So, so how should we find an assignment? Our goal is to find an assignment. So we have consistency, right? Because, because if, if you are talking about CSPs, we wanna get weight 1, that means you wanna have an assignment that's consistent and makes all my factors 1. So, so how do I pick, how do I pick that? Okay. So, er, so let's look at an example. Let's just like, let's just see how we would do it normally, like if you wanted to solve this. Like, if I was solving this I would pick one of these, like one of these nodes, or variables, I would pick WA, maybe I would say well, let's just pick red, just to see how that goes with that. And then I would go to a neighboring, neighboring node like NT. And I do have a constraint. The constraint is WA and NT should not be equal to each other. So the only thing that tells me is that NT should not be red. So I'm just gonna pick some color, let's just pick green. So then I'm gonna go to some other neighboring, neighboring node, so that's SA. I have two constraints. The two constraints are is SA should not be equal to WA, should not be equal to NT, so it shouldn't be red or it shouldn't be green. The only option I have is blue, so I'm gonna set that equal to blue. Then I'm gonna go to Q, the only option I have where Q is red because, because green and blue are already taken, then I'm gonna go to NSW, the only option I have there is green. When you go to V, again then the only option I have is, is, is red. And then I can pick whatever color I want for T because that's kind of random node out there. Okay. So, so this is a thing that we would probably do if we were to do this, right? We, we would go over these nodes with some order and we would pick colors in some other order, and I know that's important. But, but the way we would do it is just, just pick some order and maybe we'd have some heuristic that picks your order and picks the values and tries to make the constraints satisfied. So, so what we wanna do is we actually wanna spend [NOISE] a little bit of time, uh, talking about doing that, and go- and having actually heuristics that, that tells us what order we should use, we should use for the variables, and what order of values we should pick. So, so we're gonna talk about a few heuristics mainly this time. So, so, so to do that, um, we need to define one more thing, it's the last thing I'm gonna define, and then after that talk about the algorithm. So, so we're gonna define dependent factors. So dependent- so the partial assignment is going to be partially assigning values to variables in this, in this, um, CSP, right? So, so a partial assignment, for example here, could be that WA needs to be red and NT needs to be green. That's a partial assignment, okay? Then I can define dependent factors to be a function of partial assignments and a new variable X_i. So let me depend- let me just write that somewhere, maybe I'll write it, a different color because it's. So we have, um, we have something else called dependent factors, it's D of x and X_i, where x is partial assignment and X_i is a new variable I'm picking. And dependent factors is going to return a set of factors. It- it's going to return a set of factors that, that depend on x and X_i. So, so for example, in this particular case, this we said, this is a partial assignment. Let's say I'm asking what are the dependent factors of this partial assignment and SA? So I'm picking a new variable, I'm picking SA, and I'm saying, what are, what are the dependent factors? And then these are going to be the factors that depend on this new thing SA and depend on the partial- partial assignment. So it's going to be this factor and this factor, right? I'm going to pick the factor that says WA is not equal to SA, and I'm gonna pick a factor that tells me NT is not equal to SA, okay? [NOISE] And that kind of like the idea of dependent factors is that it allows me to, to think about the next thing I should- next things I should be worrying about. So, so if you remember like tree search algorithm, if you would look at children of, of some note. Here we are going to look at dependent factors, because, because those are the factors, the next factor is we should, we should care about, that's why I'm defining these dependent factors. Okay. All right. So, so now this is the algorithm. Kinda I want to write it up on the board because it would be good to have it, [NOISE] but it is a little bit of a long pseudo-code. So, all right. So the algorithm we're gonna talk about right now is, is just backtracking search. It's not doing anything fancy. We're gonna talk about fancier things next time. But, um, you have backtracking search. It does the thing that you expect it to do. So it takes some partial assignment x, it takes the weights that we have so far, and it takes the domains, domains of, of those variables that I have so far. Okay. So if x is a complete assignment, if you have found a complete assignment, then we are going to update the best thing we have and we would return, or we would do whatever you're supposed to do for the problem, right? Like we might have different types of problems here, like maybe the question is find one assignment. If I find one complete assignment, I can, I can just return. Maybe I'm looking for another question which, which tells me count all possible assignments that you can have. So, so if I'm counting assignments then I'm just going to update my counter and try to find the next assignment. So depending on what the question is I might want to do different things when I find my, my complete assignment. But let's say I find my complete assignment, then I update and I'm happy. Okay. Then [NOISE] um, I feel like then we're going to choose an unassigned variable, so I, I should have written this. So if x is complete, then let's say we are happy. Then we are gonna choose, um, an unassigned variable, unassigned, so choose a variable, chosen an unassigned variable X_i. And well, how do I do that? I'm gonna talk about a heuristic to do it. Um, so, so we'll talk about that, but let's say I have some way of figuring out what is the next variable I'm picking. And then after you pick the variable, you're gonna pick some value for it, right? The map coloring. You're gonna pick a province and you're gonna say red. So how, how do you know it's red? Like how do you know the val- the next value you need to pick is red? Well, that comes from another heuristic, uh, which says order, values, and domain. So values would be red, blue, green. So those are my values, right? So ordered the values that are in domain I, um, [NOISE] I've chosen X_i. So, so you picked up the next i, maybe the only colors that you can use right now are red and blue. So, so then you are going to order red and blue using some heuristic that I haven't talked about yet. But maybe some heuristic says, you should use red first and then you- you'd use red first, you'd order it in that domain- in, in that order. And then for each of these values in this order, so for each v in this order, that you've decided, you're gonna update your weight, or you're gonna have this Delta weight value. And this Delta weight value is going to be product of your factors, okay? [NOISE] And these factors are factors of your partial assignment whatever you've decided so far, maybe you, you have assigned two colors for two territories already and you're looking at the third one. So it's going to be the partial assignment union whatever value you are looking at for this new X_i that you're trying to pick, maybe a color for. Okay. And, and what are these f_j's that you are looking at? Well, these f_j's are going to be the f_j's that are interdependent factors of the partial assignment and your variable, that's why we defined dependent factors. Because these are the factors that we care about, these are- I'm not gonna look at Tasmania if I'm not looking at that part of the graph, I'm just gonna look at the things that depend on my current partial assignment and my, my, my, er, my X_i. Okay. If Delta is equal to 0 return, or continue, 0 continue. So that means that this assignment you- continue, continue. Er, this means that this is a particular value that you have picked just made everything 0, it didn't work. So, so you should try other things. The other thing you're gonna do is if this value works is you're gonna update your domain, so we're gonna talk about how to do that. That's the thing that's going to save you- save your time. Because like you have now found out that you only need to care about colors red and blue, and you don't need to worry about green. So, so that- that's updating the domain, making sure that you don't need to worry about all the colors. And then after that, you're just going to backtrack on this new thing. Backtrack on this new thing. So on this new thing is X union you've picked value v for X_i. So this is your new assignment you have extended your assignment by value v. Your weight is going to be whatever weight you started times Delta, that's weight Delta, and then you've updated your domain, so you're just gonna use domain prime, okay? Domain's prime. So this is domains of everyone's, like domains of, uh, all the other nodes. All right. So, so we're gonna talk about this a little bit more. So- but this is the basic of, of the algorithm. Okay. So gonna first talk a little bit about updating domain. So, so how do we update domain? So, uh, one very simple way of updating domain is, is this thing that's called forward checking, which says well, if you pick a color, so let's say that you pick W to be red, then just look at the neighbors of WA and, and then see if you can update the domains of them. So this is the simplest thing I can do, right? Like I've picked WA, I've decided WA is red. So the thing that I'm gonna do is I'm just gonna look at the neighbors and the neighbors are NT and SA. They cannot be red, so I'm gonna to just update their domains to be red- er, to be blue and green, I just drop red. Yeah. So, so that's like the simplest thing while would do so maybe I'll write it in different color. So what option is this forward checking approach for updating domain. Okay. So let's go further. So maybe now I'm at NT. I'm deciding NT to be green. If I'm deciding NT to be green, I'm gonna look at neighbors of NT. So I'm gonna look at SA and Q, they cannot be green anymore. So I'm gonna drop green. Okay. I'm, I'm gonna look at Q for whatever reason. And Q, I'm going to pick blue for Q, because I want to pick blue for Q. And, and then I'm gonna look at the neighbors, and my neighbor SA does not have anything in its domain. So I realized that at this point, like this particular assignment is inconsistent. I don't need to worry about the rest of the nodes and when what I'm picking for the rest of the nodes, it's kinda like equivalent to pruning, like I don't need to worry about anything else, because I've just found out that this- this assignment does not work. Okay. So that's kinda the whole idea of updating the domain. So, so forward checking is the idea of doing one step lookahead. So after assigning a variable X_i, you wanna eliminate inconsistent values from domains of X_i's neighbors. So you want to reduce the, the domains of X_i's neighbors, uh, and if any domain becomes empty, then, then you don't recurse on that. And, and when you, you unassig- something to notice is, if you're unassigning X_i, you have to restore the domains. So, so because you change the domains if you're unassigning, if you're deciding, uh, green who was not the color to go then, then, then you got to- you got to update your domains, okay? All right. So the other question was this heuristic. All right, so this heuristic updating domain, one way to go about it is forward checking, just update the neighbors. Another, um, place that, that we need to, uh, pick things wisely is choosing the unassigned variable. So which one- which, which unassigned variable should I start off? So, so which variable to look next? And, and again, one heuristic to, to look at here is to pick the variable that's the most constrained variable. So, so choose the variable that has the fewest consistent values. So, so you are going to pick the one that's the most constrained variable. Why do we wanna do this? Why would I pick the most constrained thing? Probably because of less options. Yeah. So you're left with less options. And, and, and the idea is if I'm going to fail, let me just fail early. Like if this is not gonna work, let me just find out that it's not gonna work early. So, so that's the whole idea of it. And in this case, like if you are left with this option where we- where we choose red and green here, and now we wanna pick what should I look at next? I should be looking at SA because that only has one value. So if that's not going to work, well, nothing else is going to work, right? So, so we want to choose, choose, uh, a variable that has the fewest consistent values. And again, the reason this works is, is if we have some number of constraints in our factor graphs. So, so these are more general for factor graphs too. Like everything I'm saying is not just about CSPs, it's about factor graphs. Um, and, and the reason this works is we have some constraints, right? We ha- we have some, some of these factors are going to return a 0, because they are going to return a 0, that is why I, I, I would like to follow a heuristic like this because that allows me to not look at everything. So, so this, this heuristic only gives us benefit if we have some factors that are constraints. Okay. All right. So, so that's one heuristic. The second question is, okay, so now like using most constrained variable, I pick my variable, what value am I going to pick for it? And, then for value, but it's interesting because for value you want to pick the least constrained value. So- and, and the reason again is [NOISE] you pick the most constrained variable because you wanted, you wanted to know if you're going to fail, you wanted to fail early. But now you've committed to that variable. Like now you're going with that variable. So you might as well- you, you have to like assign a value for it. So you might as well pick the least constrained variable here, to, to leave options for, for the other variables around you. So, so an example here is, and, and how can you think about- so, so an example here is you're going to look at, um, [NOISE] this, this setting where, what is it, you're picking Q, right? And, and you want to choose what color to, to use, what value to use for Q, right? You can- you can color Q red. If you color Q red, you're gonna do this forward checking, and if you're gonna do forward checking, you are going to update the domains. And when you update the domains, you have two options here, two options here, two options here. So that could be a measure of consistency. So you have six consistent values. If you decide to use blue for Q, what's gonna happen is you are going to update NT, and, and that's going to have one value, SA is going to have one value, and SW is going to have two values. So you have 1 plus 1 plus 2 pl- and that's equal to 4 consistent values. And, and you're gonna, you're gonna basically pick the one that, that leaves the most options possible. So you're going to order the values, the colors values here refers to colors, of selected X_i by decreasing number of consistent values of neighboring variables. [inaudible]. Yeah. Yeah. So it's the cardinality of the domain of neighbors. Yeah. And, and one other thing is like these heuristics are only going to work if you are doing forward checking. If you're not updating our domains they're not going to give us any benefits. Okay. And, uh, also another note about this particular heuristic, uh, which is for ordering the values, the only like place that this is actually going to give us some benefits is when you're working with CSPs when, when, when we actually have everything as constraints. Because, because if we don't, we actually need to go through all the va- all the values and then figure out where the value of the factor is for, for them. So, so, so this is only going to be beneficial when we have- when we have everything as, as, a constraint. Just a question, so when we are doing all of this, we are not actually copying anything, right? Well, we're it's just, it's just one possible what if we find something without worrying about [inaudible] [OVERLAPPING] So it is a recurrence. Other optimal, more optimal solutions. Uh, yeah. So, so depends on what we were doing, right? So, so that's kind of this pa- this part. So, so the question is are we finding for the optimal solution, are we finding for S solution? It depends on like- and that's kind of this line. If you find S solution and you're happy with that one solution you can just like return it here and be happy. If you want to find the best solution and you need to like iterate this multiple times, then maybe you have like a counter here that still like keeps iterating. Um, for CSPs you want to find S solution because, because, because we, we just want satisfy the constrain- constraints. But if I have a factor graph I actually want to optimize my, my, my weight. All right. Yeah. So, so yeah. So the, so the idea of this most constrained variable is we must assign every variable. So if you're going to fail, let's just fail early, it's kind of similar to pruning. And the idea of, uh, what order we are picking for, for values is we are going to pick values for the least constrained value. Uh, so and, and kind of the reasoning behind that is you've got to choose some value. Like, like we have to choose values for all of these things. So, so choosing, uh, so, so choose a value that's the most likely to lead a solution for everything. Okay. And this is what we just actually said. Okay. So, so going back to this, this algorithm, now we have a heuristic to, to follow for all these three different red lines. And, in doing so we're just doing backtracking, and then we can update this and, and just go through it, and it does- it does find a solution. Okay. All right. So, um, so now I want to spend a little bit of time talking about arc consistency. So what arc consistency is, is it's just a fancier way of doing forward checking. So, so we talked about a heuristic for this one, a heuristic for this one, the only algorithm we are talking about today is this, that's, that's the only thing. And, uh, we said, well, in this algorithm we gotta update the domain, the way we have been updating the domain is just looking at the neighbors and trying to update the domain using forward checking. So another idea is to do something slightly better which is called arc consistency. And arc consistency doesn't just look at the neighbors, it goes through the whole, the whole, uh, the whole CSP, and tries to update, uh, the domains of even like further nodes ahead of us. So it doesn't just look at the neighbors. So, so that- that's what this whole section is going to be about, how to do arc consistency. Okay. All right. So, so the idea of arc consistency is let's eliminate the values from domain. So, so I have this, this giant domain, I don't want to go over all those, uh, values. Uh, I have a for loop here for all the values. If I can update my domain, I have less things to iterate over that's going to be much better. So let's just try to reduce branching. Okay. So, so here is an example. So let's say that I have X_i and X_i lives in- so I'm looking at X_i and X_j, and X_i takes val- the, the domain of X_i is 1, 2, 3, 4, and 5, and then the domain of X_j is 1 and 2. Okay. So now what I wanna do is, um, I had a constraint, the constraint is X_i plus X_j is equal to 4. So if this is my current domain of X_i, I don't really need to worry about all these values in X_i because the constraint tells me, well, 5 never works because X_i plus X_j has to be 4, so that's not going to work. This one is not going to work. The only way for things to work is to have 3 plus 1, and 2 plus 2, and that's it, right? So, so the only variables that I actually need to worry about for domains of X_i is, is 2 and 3, not 1, 2, 3, 4. So, so what I wanna do is I wanna take the domain 1, 2, 3, 4, and 5, and reduce that to just looking at 2 and 3. Because those are the only values that I should actually care about. And this const- yeah, because this constraint is kinda enforcing that. Okay. So and enforcing+ our consistency basically tries to get to the, this smaller domain. Okay. So, um, all right. So a variable X_i so let's actually formally define this. A variable X_i's are consistent with some variable X_j. If each, each, uh, value X_i in the domain of- for each value X_i in the domain of X_i there exists some X_j the domain of X_j. So, so the factor is equal to- is not equal to 0. So basically it's ensuring that everything is going to be consistent. So, so if you have inconsistencies, remove things from the domain of X_i. So our consistency ensures that if there are any sort of inconsistencies between two variables X_i and X_j's, it's let's say it starts from X_i, and it tries to remove for- from the domains of X_i, uh, to, to make sure that all factors are not equal to 0. [inaudible]. So we start from 1 and- so we pick x_1, and I will try all, all these other variables, xj's and values of them, and then we keep, like, iterating. We do iterating over all of them, but we gotta like pick one, and update the domains of that. Okay. Yeah, so, so what we're gonna do is we're gonna just write up the function, enforcing our consistency. And it's gonna remove values from domain of i to mix- it make xi consistent with respect to some other xj. Okay. So, so the only thing I'm touching is domain of xi. All right. So, so let's actually, like, go over an example of how this works. And then we're going to look at the pseudocode for it. So here's our example. I'm gonna start from WA. I'm gonna pick red for it. Okay. So that's my current domain for WA, is red. If I was doing forward checking, what would I do? I would just look at NT and SA. I would update the domains of NT and SA. So now what I'm gonna do is I've realized that NT and SA their domains are changed. So I'm gonna push them to the, to the same- to the same list of things I have, and I'm gonna look at each of them and see the neighbors of them too. So the arcs that come from them. So I'm going to look at NT. Um, well, that is right here. Actually, it's too soon. So, so e- everything looks consistent there. Everything is great. I can't update anything more. I'm going to pick NT now. Let's say I decide NT is green. So NT is green, I'm gonna look at neighbors of NT. So neighbors of NT are WA. WA is red. Everything is great. SA has a green. I need to get rid of that green because it can't be green anymore. Q has a green, I need to get rid of that. So let's update that. So Q and SA, their domains are touched, right, their domains have changed. So I actually need to look at them, and then see how the domains of their neighbors are going to be affected. For example, I can look at SA, and I can see well, SA is, is blue. The only way for SA to be consistent with the rest of these guys is that they don't have a blue in them. So I'm gonna remove blue from Q and SW and V. Because, because they cannot have blue for these two to be consistent. Again, if SA here is kinda of my xi. So I'm, um, sorry. It's actually my xj. So I am gonna pick xiQ here, and I'm gonna update the domain of xi, so it becomes consistent with SA. Right? So I'm gonna like pick- change the domain of Q, get rid of blue. I'm gonna change the domain of NSW, get rid of blue. I'm gonna change the domain of V, get rid of blue. Okay. So what has updated? Q is updated, NSW is updated, V is updated. They're gonna go to- go back, and I'm gonna go through them again and see if, if their neighbors need to be updated. Okay. So going back to, to, to Q, Q is red. NSW's domain needs to be updated to be consistent with Q. So I'm gonna remove red. NSW's domain is touched. So, so now I gotta go back to V. V is going to become red, and then T can take any value that it wants. So if I do like this full, like enforcing our consistency here, I'm gonna end up with, with something that looks like here. So all my domains are kind of pruned, and I have, I just like have a solution, right. Like I don't need to actually iterate over any values. And this is just done by, by updating the domains. And then doing this arc consistency approach, rather than doing backtracking search. So, so all of that is done in this step. Okay. All right. Yes? [inaudible] solution, go back and make NT blue as well. Uh, so, so if you wanna, if you wanna actually- so, so this whole, like, pruning is only, like, useful, right, if you want to find best- like a solution in a CSP, but if you have a factor graph and you actually- if you have a factor graph, you need to actually try out all these values to see what is the value you're gonna get for each, each one of the colors. If we did forward checking instead, we actually would have arrived at the same conclusion here, right? It would have just have taken more steps like filling more of these different- If we were doing forward checking, we had to do the, like, we actually had to do the algorithm. Like, like we wouldn't get to this, like, we would get to this much later because if, because if you are doing forward checking, we would just look at the immediate neighbors, we'd update the domains, and then we'd go to the next, like, nodes in the neighbor- neighbors and do backtracking search again. Here, like, I'm not- I haven't, like, called back-, like, I'm here. I've updated by domain. And I'm with that scenario, and I haven't called backtracking search yet. All right. So yeah, so forward checking is kind of a simpler version where we're assigning xj to be equal to xj, and, um, and you're enforcing arc consistency on all the neighbors of xi with respect to xj. Arc consistency, what it does is it repeatedly- well, there- there are different algorithms that try to do arc consistency. The particular algorithm we were talking about in this class is called AC-3. It's just the most useful- like, the most, um, common way of doing arc consistency. And what it does is it repeatedly enforces arc consistency on all the variables. So, so it goes over everything pretty much. So, so what it does is you're gonna add xj to your set. Then while set is not empty, you're gonna remove an xk from, from that set. And for all neighbors, let's call them xl of, of this this xk that you have picked. For all the neighbors, what you're gonna do is you're gonna call enforce arc consistency on xl with respect to x here- xk. Okay. And then if your domain is changed, if don- you change the domain of domain of l, then you're gonna add that back in. And that's kinda what we're doing in this previous example, like, we, we kept adding the nodes back in. So, um, yeah, so in terms of complexity, um, of this algorithm or worst-case scenario, it's going to be order of e times d cubed, where e is the number of edges and d let's say is the number- maximum number of values that you can have. So, so, so the reason it is that is, when you're enforcing arc consistency, this line takes order of d squared. Let's say you have d values. For each of them you have d values, you need to co- consider all that combi- all those combinations. That's d squared. You are, are doing- going over all the edges, right, so, so you have all the edges. So that's ed squared. And another thing to notice is, you're sometimes adding these things back in the set. Well, why are we adding them? Because their domains can be changed. Their domains can be changed at most d times. So that's that extra d. So, so that's order of ed cubed. If you're interested in it, you can look at the notes for it. That's worst-case scenario. In general, it doesn't take that long. In general, like, I'm not gonna keep, like, adding the same value, like, a million times, like, back in. Or the same xl back in my set. Um, in general it's much faster. In practice, it's much, much less. Okay. All right. So, so again, it's a heuristic. It's not the best thing in the world. Like, if- I, like, ideally, you would have wanted AC-3 to not return a solution if there doesn't exist a solution. But, but here, for example AC-3 is not being very effective. Here's an example. Right. So you have these three nodes, and let's say you are left with these domains. So blue and red. If you're enforcing arc consistency, the domains are not gonna change. These domains are very consistent with each other. But, but there is no solution that actually, uh, you can find here, right? Because if you choose blue and red here, you don't really have an option for the third one. So arc consistency is actually not going to, uh, be able to figure out that this, this doesn't work. And there are more complicated versions of arc consistency that consider, um, uh, that, that go beyond these binary relationships, uh, but they are, they're going to take exponential time. So, so our consistency is simple. You run it, it's usually useful, but it's not gonna find everything for you. Okay, okay. Yeah, so and I'm kind of the whole intuition of arc consistency is we are looking at this graph in a local manner. And locally we're trying to like update our domains to be more efficient, but it's- it's not, it's not gonna give us a global answer. Of course, it's not gonna give us a global answer. Because if you want it to have a global answer, we had to reconsider the relationships of all arc- all arc constraints with respect to each other. Uh, but it's, it's basically making sure that locally at least everything looks good. How do you figure out when you should or shouldn't use AC-3? When you should- so in general you can use- so I would- in, in general I would say use AC-3 because it's going to prune things usually. Um, if, if you have a lot of dependencies between, like, if you ha- if you have like the circular type of dependencies, it's not gonna figure everything out but it's usually just going to be useful. So, so running it in practice, it doesn't take that long. Running it is usually going to prune part- part of your domain. So I do recommend using it, but it's not gonna figure out everything because you have- you have connected. Like everything is connect- everything is connected with everything. Then you have dependencies between all your variables. All right, okay. So, so summary so far is, uh, well, we've been talking about backtracking search on partial assignments, we talked about dynamic ordering, so how to order our variables and how to order our values. We decided to order our variables based on the most constrained variable because if you're failing, you wanna fail early. And we decided to order our values, like, if I'm picking red, blue, or green, uh, based on the least constrained value because if you're- if you've, if you've decided to pick a value, you should try to succeed. So, so that's kind of the intuition behind it. And, and look ahead is useful, forward checking is, uh, one way of doing it. So it enforces arc consistency only on neighbors, our consis- cons- consistent AC-3 enforces arc consistency, on neighbors and their neighbors and just goes over all the arcs that, that we have in the- in the graph, okay? All right. So that was kind of the set of algorithms I wanted to talk about, but next time we're going to talk about more, more inference and learning type, types- type of algorithms for CSP. So now what I wanna do is, I wanna spend a little bit of time talking about modeling. So, uh, we've talked about two examples now, right? The, the map, the map coloring. And this one is also, like, picking colors. These, these are the examples we have talked about so far. So, so let's look at another example. So, so let's say that we have three sculptures, A, B, and C and they're gonna be exhibited in a museum or in an art gallery and, and I have room 1 and 2. So they can be either in room 1 or, er, room 2. And I'm going to have a set of constraints, so maybe my constraints are; sculpture A and B cannot be in the same room, sculpture B and C must be in the same room, and room 2 can only hold one sculpture, okay? So, so these are my constraints. How would I go about this? Well, I need to write a bunch of factors. I need to write- I need to actually model this. So, so let's try to do this. [NOISE] So this was my domain. So I have three sculptures. So I am gonna find variable A, right? So that's sculpture A, it can be in room 1 or 2, okay? Then I have three sculptures, so I'm gonna have variable B and variable C. Each one of them can be in room 1 or 2, okay? So now I gotta define factors, right? I had all these constraints. One of the constraints was A and B cannot be in the same room, so, so that's a factor, okay? Let's call that f1. It's going to depend on A and B, right? It, it cannot- A and B cannot be in the same room. Er, what is that factor? It's a function, right? Over A and B. And that function is going to return something. What should it return? It should return A not being equal to B, okay? So, so that's one factor. What else do I need? Let's just make sure that everything is okay here. So, so far what I've done is I've defined A, B and C. They can take values 1 and 2. I've defined one factor that connects A and B. I'm gonna define another factor f2 that's going to connect B and C. And I really want a sculpture B and C to be in the same room. So these are local variables but let's just be consistent. So what I want is B and C to be equal to each other, okay? So to be in the same room. So that's factors f2 that's just created here. And what was the last thing I wanted? Each room, one? Yeah. So every room gets, uh, one, right? Was it every room or was it- actually I don't remember. Second room. [OVERLAPPING] Second room. Okay. Second room only gets, um, only gets one. So that's a factor that depends of- on all three of them, right? It depends on A, B, and C. And one way to enforce that is- what I am gonna say is, well, if A is in 2 or if B is in 2, or if C is in 2, right? So I'm gonna- I'm gonna write indicator functions if A is in 2, B is in 2, C is in 2. And if I add those up, well, that should be what? That should be less than or equal to 1, right? Because I don't want there to be more than one of them in, in a- in one room, okay? And this is enforcing that. So okay, I have this third factor. This third factor is not a binary factor anymore, right? It depends on all three of them. And then if I step, then, we're going to talk about these algorithms next time. But, um, here is the assignment that, that you're gonna find. So we're gonna find that, uh, sculpture A is going to be in room 2, B is going to be in room 1, C is going to be in room 1 and, and, and that satisfies all the factors that we just like wrote, okay? So if you're interested in writing up more models, use this environment, it would be cool. So, so that was another example of, of CSPs. So now I want to talk about one more example, so, uh, I think two more examples. Uh, okay. So this is an event scheduling example. So, so the event scheduling example is, I have E events. Let's say these are classes or yeah, different courses that you're taking. And then you have T times slots. So you have E events and T time slots, okay? And you wanna schedule- you wanna schedule a time slot for an event that- that's what your plan is. So it's a scheduling problem. And you have one of two constraints. So the first constraint is, each event must be put in exactly one time slot. So each event in exactly one time slot. One time slot T. So that's one constraint. Another constraint that you wanna have is, maybe we want each time slot T to hold at most one event because we don't want them to overlap. So each time slot T you want that, uh, it can have at most, uh At most, uh, one event, at most one event. So this is another constraint, at most one event. And then maybe I have a set maybe, maybe event E is allowed in time slots T only if event E and time slot T are in some set that someone gave me some A set. So, so I have another constraint that ensures that some E, with its time slot, is in some predefined fixed set that someone gave me. Okay. So, so these are some of the constraints that I have. And what I wanna do is I want to, I want to formulate this problem as a CSP. So, so how would I go about it? What should be my variables? What should be my variables? [NOISE] Events? Events. [NOISE] So we're gonna go with events. Okay. So let's say that- so we can actually have multiple formulations for this. So one formulation, maybe the most natural formulation here is to say that my variables are going to be events. So those are going to be my X_es here. And every event can take a time slot, so the value that it's going to get is 1 through T where T is the time- we have T different time slots, okay. So then if I, if I start with this, if I start with a setting where I'm saying every event is a variable, then I kind of get this first constraint for free. So each event E is, is in exactly one time slot because I have my variables E, they're not gonna get multiple values assigned to them, they're gonna get one assignment. So if they get one assignment, I kind of already get this one for free. The second constraint is this constraint which makes sure that each time slot can have at most one event. So to ensure that, then I need to make sure that X_e is not equal to any some other X_e prime, right? Because, because X_e is my variable, my event variable, it's gonna get a time, time slot value, the two time slot values for two different events should not be equal to each other. So the constraint that I have is X_e is not equal to X_e prime, X_e prime. Okay. And how many of these do I have? Well, I have like order of e squared of them, right, because I have- let's say I have e events, so I have- so then I have e times e options here to make sure that they're not equal, equal to each other. So I have e squared, uh, binary, uh, factors, okay. So, um, and then I have another constraint which tries to ensure that these, these events and their time slots which is the X_e value is going to be in some set A. You can kind of treat this as a unary factor, so you have some number of unary factors, you have e unary factors here. Okay. So, uh, and, and the, the, the number of variables that you have is, uh- the number of variables you have is e but their domain is size T. So, so it's, it's good to think about this. Because if you have multiple choices, so I'm gonna talk about the second choice in a second. But if you have multiple choices for modeling this- it's a good idea to think about what type of factors do you have. How many of them do you have? So here are like the worst-case scenarios. I have e squared binary factors. Okay. So I have another option, right? So in this option what I did was I took, um, the events as my variable. The second way to formulate this is to say, well, maybe my variables are just the time slots. So, so maybe I'm gonna go a different, different approach, take a different approach for modeling this. I'm going to call it Y_t, Y_t are the time slots. So I have variables for time slots. Each one of them can either take an event or maybe there's no event added, that's empty, empty value. So, so they either take an event or no event. And if I model this, this problem using, using the second approach, then I get the second, the second one, the second constraint for free because my variables are again time slots, so I can, I can, I can satisfy the second constraint. And then for the first constraint, I actually need to write something for the first constraint which says each event is in exactly one time slot. So I'm gonna write a constraint that says Y_t, this time slot is going to get an event for exactly one t. So, so this particular constraint that I have, it's how many variables does it have? If I want it to be exactly one time slot. Remember the sculpture example? I wanted it to be exactly in one room. It needed to depend on everything else. So this is going to be a t-ary constraint, right? So I have t variables here. So previous formulation, everything was binary or unary. Here, I have a t-ary constraint. I have less of it but I have a t-ary constraint. Okay. And then I'm going to have another constraint to just ensure this, this last, this last constraint. Okay. So, so one way to think about these two different approaches is how many of these constraints do I have? So, so we just saw that we have a t-ary constraint here, one thing that you can actually do, and I have the slide afterwards about that, is if we have some, some n-ary constraints, some t-ary constraints, some constraint that depends on t number of variables, I can actually change that to order of t binary constraints. So I can actually like reduce down to binary constraints. So, so I can make these two algorithms- not algorithms, sorry. Make these two models to have all binary or unary constraints. So that part is fine. But one of them is going to have t number- like order of t number of factors, the other one is going to have order of e type factors. And the question is, well, which one should we use? And it really depends on if your e is greater than t or t is greater than e, right? So if you have, if you have more time slots than events, if you've a lot of time slots and you have like five events, let's say that you want, you want to set, then you should use the first algorithm because that, that was where we had order of e squared number of constraints. But if you have it the other way around, which is again less natural but maybe you don't want to, you don't want to- you're okay with not assigning all events a time slot, so, so if you, if you had it the other way around, then, then you can use the second formulation. So the point of it is you might have different ways of formulating a problem, you should use the one that, that is the most beneficial depending on what, how many constraints you have and then so forth. And then one last thing to, to- before, before we head out, so I just said if you have an n-ary constraint, we can actually write down binary constraints that are equivalent to this. And the reason is usually our algorithms require having binary or unary constraints. Here, I have, I have a setting where I have this or between X_1, X_2, X_3, and X_4. So the way to make this- makes the binary constraint is what we can do is we can define an auxiliary variable. So, so I'm going to define a new variable, and this new variable, I'm going to call these A_is. And these A_is are going to be just the result of- the or of A_i minus 1 or X_i. Okay. So what's happening here is, let me just draw this real quick. So I have a setting, ah. I'll just do one. So I had X_1, X_2, X_3, X_4, I can have an n-ary constraint that connects all of these together to one factor graph. What I can do is I can actually define new variables. So I am defining that many new variables, A_2, A_3, A_4, and then I'm ensuring- and I'm defining new factors where A_1 is the result of these two ors. So I'm going to just draw this like this. A_2 is the result of or of these two variables. A_3 is the result of or of these variables and so on. This is not binary, right? What is there right here? It's three. So we need to do one more step, like, after you're defining these auxiliary variables, after that, we need to define- we need to do one more step where we define a new variable B which kind of represents A_i and A_i minus 1. So I'm going to replace these two with just one variable. I'm gonna call it B_1 and I'm gonna just connect that to X_1. I'm not going to draw it, but you get the idea. So, so B_i's are just going to be representing A_i minus 1 and A_i. And that allows me to have binary, um, binary factors here. Okay. And, and by doing so, I'm adding actually one more constraint. I actually need to add a consistency constraint that makes your B_i minus 1 of 2 is equal to B_i minus- B_i of 1. Just ensuring that like pre and post are staying the same as we're moving through the graph. So that's another reinforcement. All right. Let's chat next time about this more. 