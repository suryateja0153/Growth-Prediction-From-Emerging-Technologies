 [Music] in this video I'll show you how you can use autograph to write complex high-performance tensorflow code using normal Python Auto graph is available in the new TF to function API makes it easy to run tensorflow computations in a way that's efficient and portable when you imitate a Python function with TF dot function autograph will automatically convert its Python code to tensor flow graph code the code is then compiled into a graph and executed when you call the function let's look at an example this simple function calculates the square of a scalar input if it's positive in tensorflow 2.0 you don't have to use TF cond anymore you can just write a normal if statement an autograph will generate a TF cond operation so that the entire computation runs as a graph this is the generated code that autograph writes for you notice that we're writing true and false functions that would normally be fed into a TF cond statement instead of writing these you can simply use Python if statements let's take a look at a more complicated example this is a bare-bones RNN cell note that it contains a data dependent for loop and it also contains a data independent if statement autograph will only run the data dependent loop in the graph and leave the data independent if statement untouched simply adding a TF that function as a decorator still lets you call the function directly and get results immediately but the function runs in graph mode it prints results and we can also time it now if we remove the TF not function decorator which I've preemptively done here and run the function in eager mode we get the same results out however it's going to be a little bit slower because we won't have coalesced the entire function into a single TF graph op we can time both options with TF that function in autograph and without you'll note that using TF dot function which requires only a single function decorator is significantly faster than the eager mode version without TF devotion [Music] 