 We are very happy that so many teams jointly global edition, which will be new and very exciting. Our exchange and collaboration with the teams and partners is so great, and everybody involved is extremely motivated. Together we are working towards our vision: a world without barriers. Enjoy the second day of the symposium and see you soon. Thank you.  Thank you very much for these words, Roland, and a warm welcome from my side to the second day of the sidebar Karin Symposium 2020. My name is Roger Gassert and I have the pleasure of guiding you through today. As a reminder to all participants, let me provide you with a few points about the symposium format. We are now live from Zürich again and have a mix of pre-recorded talks alive discussions. Depending on where you're watching from, the program may be shifted by a few minutes on the YouTube screen. We will do our best on our side to stick to the schedule. Throughout this will have live international sign language and closed captioning service. You can access the captioning in the YouTube player. Each talk is followed by a question and answer session with our speakers joining lie. So if you have questions to ask because, please submit them to the YouTube live chat. The chat will be located beside the video stream and can be accessed using your Gmail or YouTube account. The chat is intended to ask questions for speakers and not discuss with other participants. It will be set to slow mode and moderated by us. Alternatively, if you can access the chat you can submit questions by email . We will select questions from these two sources and address them orally to the speakers. I would like to provide you with information on the post recession which will be more interactive today. In interactive booklet is available on our landing page so you can go through the abstract and identify posters of interest to you before the poster session. Yesterday posters were retweeted by the authors in the sidebar Flomax and. You can go through that channel which is also linked on our symposium landing page, or by searching for the sidebar Flomax symposium hashtag. I found these posters to be beautifully designed and want to thank all the presenters. You can continue to interact with the authors by Twitter today. -- Sub (Laughter). We will have dedicated (inaudible) rooms and the access information will be activated before the break. We will now begin our scientific programme and switch over to the programme on brain computer interface. We start with a short block (inaudible). I now wish you a very inspiring second day of the sidebar Fluid symposium 2020. -- CYBATHLON symposium . (Music plays) I'm now very pleased to introduce our first keynote speaker today, Cuntai Guan. He is a professor and program director in the School of computer science and engineering at Nanyang technological university in Singapore. His is one of the leading experts in brain computer research, machine learning, (unknown term) learning as well as artificial intelligence. In particular, his research aims to apply (inaudible) technology to the restoration and enhancement of human brain function, for example after neurological injuries. His group is also taking part in the CYBATHLON 2020 with the team that will compete in the BCI discipline. Today his talk will be on brain computer interface for brain function recovery in stroke rehabilitation. Cuntai, the floor is yours.  Hi, everyone. My name is Cuntai, I am from the Nanyang university in Singapore. I'm going to talk about the brain computer interface for motor function recovery in stroke rehabilitation. So I will cover the following. A brief introduction to/ a st rok e and the principle of rehabilitation. What is the BCI and how we use it to help patients with stroke to recover their function. Finally some other future directions in this area. / Is a detrimental disorder which causes damage in the brain , either due to block or bleeding in the brain. It is one of the leading causes of disability . Especially in developed countries and some of the developing countries. When the patient is attacked by a stroke, 30% of them have to go through a long-term rehabilitation to recover their motor functions. This had a very high burden to the society and family and economy. Today, we are still not solving the problem to help them recover their motor function so there is a lot of research still going on in this field as we know. So once a stroke attacks the brain, it affects not only motor but it also affects cognition and the emotion. 40 days talk, I'm going to focus mainly on motor function and traditionally, there are many options for the stroke patients to use and help them to recover their motor function. Medication, therapy, motor imagery, brain stimulation, robotics, virtual reality and brain computer interface. Those are the robotics that are popular in rehabilitation medicine. The mechanism for this objects and the patient to recover their motor function is as follows. It is based on nearer plasticity -- Nearer plasticity , the level of brain function at the normal level so after stroke, the motor function drops drastically and it recovers faster after the first few days of the treatment . After that, some people recover well and are back to normal but some may be slower and some very slow. Depending on the subject and many other reasons. After 3 to 6 months, they cannot recover fully from their lost functions . That is where they need to have long-term rehabilitation to recover their motor function. So beside the Robotics and nearer therapy , those are the methods that have been popularly used in rehabilitation . BCI used as a new option and if you look at the system, you can see they stroke patient, if you can acquire a brain signal, you can use whatever device will stop of course, some devices are more expensive or troublesome and some are more portable . Those are devices which are more portable . No matter how you acquire signals, after that, we will go through several steps to try to decode the motor function . Then we use different types of feedback to close the loop so the person can exercise by activating the motor function and motor areas so they can recover motor function. Depending on the system and how the researcher and developing system , they are given a type of feedback system . A simple one can be a screen or a monitor with a visual feedback , then there can be virtual reality and they can be more immersive and realistic in a sense. Or they can combine some robotics and it can be a soft robot or exoskeleton , whatever can actuate the affected arm. Or limbs. They can use different kinds of stimulation, FES. There are various systems to combine PCI with feedback -- BCI systems, we talk about the whole thing and not just the BCI alone but different types of feedback. To make it clear. Then we zoom in to see how exactly it works. This is an example of EEG . We have the brain and typically we have to cover the motor area . For this example, this person may have a stroke on the left-hand side of the brain so that is why the right limb is affected. We get the data and we can use machine learning approach . Later we will talk about deep learning and trying to decode the motor function and activity . Then we apply the different feedback to the user. For instance, this is a robot and once this BCI system detects the motor intention, the BCI will send a signal to the robot and the robot will drive the hand of the affected arm. This is a closed loop training so the person can keep exercise of the motor activity so it will activate the motor area . Hopefully by repeat , over many days and many sessions, they can form a new pathway or enhance the existing pathway so they can recover their own limb movement. That is the process of BCA-based/ system. I will just give you some actual examples. Those are the systems we developed in our lab and we also put them into clinical trials. For instance, on the left, top corner . This is a system with BCI . The feedback is through visual and also a robotic effect so the person can imagine the movement and the BCI can detect feedback by this robotic device. This system is for lower limbs and the person , in this case, they tried to imagine a brisk movement of walking so they can see feedback by visual display. Whether it is the intention of moment being detected, you see the Prince on the road to walk towards -- The print on the road to walk forward. This subject uses EEG to drive a robot. You can imagine the movement of the hand so this soft robot will open and close the affected arm . It closes the loop. This is another system using only visual . These two have a physical device to send feedback and we also have just visual feedback. By following the instruction on the screen, imagine you move forward, right and forward again. Those are the different designs of BCI system , trying to help the patient to do the repetition. Each of the four trials we have some clinical results. For instance, for the BCI plus and defector, we divided the patients treatment and the first group is the BCI with the feedback and the red is the mechanical robotics alone and the last , the group is the traditional rehabilitation by the therapist. The patient actually went through six weeks training so this is the training and we measured the follow-up after 12 and 24 weeks. So from the outcome, you can see the BCA group kept improving even after they stopped training. We still see the motor function and this is measured by the typical motor function assessment tool in the rehab medicine. Kind of training similar to BCI and there are some up and down after the training. For the traditional therapy based treatment, the function actually goes back a lot after stopping training . This is measured by the resting motor threshold. Lomond better integrity of the pathway. -- Low means better. You can see after the patient improved , some from the ipsa lesion L, some from the Contra lesion all. This is for the soft robot plus BCI. Chinese it was insisted it be done in the patients by six weeks, and follow-up in 24. Similar information to this trial. By end of the training there are two groups. One is BCI and one is soft robot alone. Soft robot provides higher average recovery, this FMA. And this is BCI. But if you look at the follow-up, full BCI group it improved slightly and was kind of sustained. And the soft robot group grew back quite a lot. At the last trial, similarly, we see improvement after the follow-up. This is single group, single arm bile. These are the studies in our group. -- Single arm try. i al . Groups are explained to you. I will show you the results which are clinical outcomes. These are the brains by neuroimaging. We did a functional MRI and looked at resting state connectivity. Indeed, we found consistent improvement before and after the clinical trial. The BCI group has a consistently high improvement over the Robotics group. Although the improvement in this study was not significant because of the small sample size. In another study also measured the function of MRI in CBF and structure . In both function and structural analysis , we found significant change compared pre-and post-rehabilitation. So that is the evidence to show BCI training did bring changes in the brain. So if changing the brain can happen, potentially the recovery can sustain. That is what we hope to see. There is one more thing, actually, we studied using BCI. We tried to find whether we would find biomarkers so we can do prognostic analysis to see whether, from first sensation, we can predict whether subjects can benefit from one of the particular rehabilitation regions. In this study we have two groups. One using BCI and the other using BCI plus, a non-invasive (unknown term), T DCS. For one group, the stimulation group, we found the relative power in (unknown term) has strong , significant prediction power. But for the non- stimulation group only the (unknown term) index, because we compare left and right brain, has strong prediction power. They are (inaudible), different. This is (inaudible) data we can hypothesise in the future. We can either use those prediction parameters to try to group the subject , group the patients, into different treatment regimes. So as to maximise the possible outcome, if we can. So in the last 5-10 years, there were many studies in different groups in the world. Here is a list of some of them. Those are the studies . Back to early 2013, 2014 , which compared BCI with other methods, like visual feedback, robotics and FES. So, BCI compared with other control methods. If you look at the FMA of many of the studies and the outcome, the relative improvement is about 4.5 /5 point FMA , which is promising. Which is also slightly better than other methods if you compare the intensity of training. There is also a steady to compare different types of BCI in different groups. BCI compared with robotics or without robotics and so on. Outcome also in the range of five points. Those are the outcomes we can expect, probably, right now. There are also many more studies published in the literature. Mostly one arm studies. They are all without controls. But if we don't look at the control group , just look at the output, the relative power, relative improvement in FMA. This also falls in a similar range. But, of course, the sample size is mostly very small. Maximum 20+. And the number of sessions can range between a few to tens of sessions. Of course, by principle, if you have a longer session, longer duration, multiple sessions, recovery will be better. Some have many, many sessions and the recovery looks better. Most of the clinical studies in BCA today for the upper limb. -- BCA today. We see promising results, many studies across the world. But they are a pretty small number of studies on lower limb. Here are a few, six of them. The recovery is mixed. Some look quite OK but some not so much. But, still, this is not well studied so it needs a lot of work to see whether BCI can also benefits with -- benefit patients with lower limb disability after stroke. Then I want to talk about about how we build a BCI system from the algorithms, from the system perspective, because my background is computer science. I don't have a medical background. So how do we view the system so that system can be used for rehab to achieve better performance? We built BCA on motor imagery detection which is (inaudible) exercise, fundamental mechanism for patients to recover. Try to activate a motor cortex. We used a phenomenon called ERD. We try to imagine (inaudible). The most commonly used method. With this technique, we enhance the separation of the left and right hemisphere pattern so we can use machine learning after the special pattern, we can use a machine or a symbol or a linear classifier and also use deep learning. A few years ago, we had an algorithm called filter bank and we divide easy multiple banks and we have a special pattern to solve an optimisation problem which can become very popular and a lot of people consider it as a standard in motor BCI. Today, I mentioned that the planning has rung back deep learning has been very promising and deep learning has been very successful in many fields , speech recognition . There are a lot of potential promises for BCI as well . Recently, we developed algorithms for architecture in BCI and we achieved the best results compared with the traditional approach. This is even more recent, by a student . We tried to see how we can get a more end-to-end system , just through filtering. Using the raw e.g. and a multilayer network. Then after we learnt their future, we try to use the special feature and focusing feature and temporal feature. These are the most recent results. We get the best results compared with more like a set of art and the SVM mention and the deep conversion that and a lot of people use this as a benchmark. With this architecture, we achieved the highest accuracy compared with all the methods , 77, 75, 73 . This is a small variation and this is one without the temporal information. It is basically the same class of methods. These two are publicly available datasets . These two are the datasets in our study. Initially, we used 74 and 71% accuracy but now we can achieve 77 competitive 71 and 81 to 74. While we are concerned about accuracy? There is a reason. In studies, people actually found for patients who have higher BCI accuracy, they can achieve relatively higher outcome. That is something that is meaningful. Because of this reason, we have to keep improving. 77, 81 is not good enough. It's good but not good for everyone. If you look at everything, 80%, some of the patients may have 95% so they can have a very good performance and get a good recovery but still, if we talk about the 10% or 20% , 25% of patients who can only have a relatively low accuracy of detection . Those patients may suffer from the rehabilitation and may not be able to achieve the same level of recovery as those who can achieve higher accuracy. Why? This of course is what we observed. We have insight to understand. With deep learning, we can have interpretation of why the accuracy is so important for the recovery. So we analyse the data in our rehabilitation trials . Altogether, we have about 25 patients because we can't EEG every session and we build a deep learning model for them and use this technique called gradient back propagation to plot this relevance pattern . It means if we send one trial of data into the deep learning, we try to measure for each particular channel what is the output grading change. If the grade changes a lot, that means it will make the system , it will help the system to make decisions and have a higher weight. Based on this, for those patients with a higher accuracy, actually, the activation mostly focuses on the motor area and this is with patients with a left side affected arm and the right side has the condition. If this person has a high accuracy and 87%, this person can recover and the FMA relative changes is much higher. Compared to another patient, this is another example of the accuracy is not so high. 75. Average. If you look at the relevance publications ) propagation pattern. The patient not only has this but the motor area also has a strong activation in the frontal area. That's why we are not necessarily activating the motor part. And the third example , another group did this and it is pretty low, about a chest level accuracy of BCI. The pattern is mostly on the frontal area. Very little on the motor. If you categorise all the 25 patients according to which part of the brain has a higher contribution to the actual accuracy, we can see if those people use it more, the Met area, they have a higher accuracy and they have a relatively higher improvement. This is a relative FMA improvement endpoint. For those who only use frontal, they have a small improvement and if those patients use both , second category. They get a moderate, not so bad but not as high as those patients with motor activation. You see, there is a huge potential in the future, moving forward. We can use deep learning to understand each of the patients and why they don't perform well. If we have this information, hopefully , possibly we can adjust or help this patient to learn to activate the motor area or how to use feedback better to help the patient improve. This will be the future work based on these observations. This is also part of the research by my PhD student, Remi. This is unpublished. And then, moving forward, I just mentioned most of the work today using BCI is for motor recovery. In fact, many of the literature, people found there is an interaction between not only motor but also cognition and emotion inside the brain. For instance, the cognitive effort, how does it contribute to mighty recovery. If the person has a low motivation or emotion , not very energetic, which also affects the recovery. How can we combine the interactions between motor , recognition and emotion , it will be an interesting question to ask . This is the next project we are working on. Beside the motor and cognitive and emotional reactions, I thought I would mention the fine hand movement and also not , we still need further study and hopefully BCI can help those even more challenging tasks for the patients. We hope the BCI can help contribute to personalised interventions to understand the individual differences as compared to the different regimes for the biomarker so we can predict which rehabilitation method is the best for each individual. We just mentioned the accuracy will need to and be correlated with the outcome stop we always want to have detected performance accuracy so that will lead to better outcomes of the rehabilitation Finally we tried to see if we could have a better understanding between different motor functions , cognitive function and emotion. So we can define better algorithm detection or design better programs for patients to go through rehabilitation to recover their motor function. And hopefully memory retention and other functions as well. So, as a conclusion , in the last 10-15 years there have been many studies using BCI. I think there BCI shows promise for upper limb. A lot of evidence you can see in the literature. In controlled trial or non-controlled trial. But we still want to push the frontier to help patients with their learning fine hand movement. We can see the potential of deep machine learning or artificial intelligence and assent. How to contribute to the rehab by looking at the data . We hope to see more data from your activity and behaviour activity. -- Neuro activity. We hope to see personalised for patients. That is the future work we are focused on. With this, I will thank all my collaboratives, clinical , engineering and funding. Thank you very much. Any questions or would like to answer, this is my website.  Let's welcome now Cuntai live from the nice and warm Singapore. Good evening, Cuntai. Evening. Let's open the floor for questions. Thanks as well for the very nice lecture and overview for stroke rehab. Stroke rehabilitation is a topic very dear to me, as you know. You showed in your talk you combine BCA with robotics. So what is the advantage, according to you, to combine these two technologies, to use them together? Speak back it's an excellent question. There are several things in consideration when we combine robotics. The first thing is to help the person feel the movement of hand or arm so that can really help motivate them to do the repetition. If you don't have the robotic or anything back, sometimes the patient feels (inaudible). That is one advantage. The other one is robotics is a good device for rehabilitation. It also can help to build strong muscle movement and reduce spasticity and so on. Combining two is always the consideration for medical doctors. So, hopefully, we can take advantage of both BCI and robotics.  Very good point with the importance of also providing feedback to the patient. Let me open the floor to questions from the audience. Do you somehow take into account the aspect that a large fraction of the motor areas in the brain can be affected? And maybe not be any more functional after stroke. For people who have a large stroke how does BCI still work?  Good question that I don't have the answer! -- But I don't have the answer. In fact, in our population trial, there are quite diverse. Patients with (unknown term) , (inaudible). We don't have sufficient data to certify whether the lesion size would be a factor. So far we can't find your version yet. But that's a good question. How can the patient be kept motivated through repetitive sessions? Due change of feedback? Make it more challenging? 's -- do you change the feedback WISE  That is a critical question we ask ourselves in other studies. In the current study the answer was no. We did not change the difficulty level or system. But that is a good point. Motivation in patients was one of the key successful elements in the whole rehabilitation. So I think for practical use. I have a separate clinical study and a practical system. In a practical system I have to design and interactive interface for patients to be engaged so they are interested to continue and play with the system. But for the clinical study we have to stick to relatively boring protocols so we can keep this consistent. **Audio lost** . . To provide evidence . And hopefully we can build a practical system then. I think some companies allow to share products. In that case it is important to create a level of difficulty to challenge the patients so they can can you to do it without feeling bored or that it's to see. That is something in the BCI system that is very important. To go beyond that, I will come back to the research. We tried to see if we can provide more information for patients to motivate them. For instance, we can provide detailed improvement , which is not (inaudible) from the body from the so-called clinical outcomes. Which can already show change in productivity, muscle, many other measurements. So you can show the results to the patient to tell them after two weeks you improved . So it should continue. So there are many things we can incorporate to motivate the patients to continue to do that. It is like a reporting system. Tell them you're doing well. Continue doing. That is where we are looking. Speak Mac the importance of feedback on performance to keep the motivation of patients. Maybe we can take one more question. What is your opinion on using invasive approaches for BCI with stroke patients? Keeping in mind the (inaudible) over non-invasive approaches. That definitely is another option. Although our (inaudible) like (unknown term), surgical procedures and so on. But there is a promise if you use BCI , we can use electrical signals to stimulate the motor or part of the pathway. That is something we are very interested in going. It took a lot of time and is invasive, I would say. But it is something very, very possible in the future. Having said that, I think we need a platform more commercially available. I think Neuro link has something one step further. If you think of it open access system , more like an apple, that would be great for people to use a commercially available system for more studies. So because one of them. In the future. -- Is one of them. -- Stroke. So we now move to our first short talk of the day , still on the topic of brain and computer interface which will be given by Xiaoxi Wei . She is a student of the brain and behaviour lab at the Empire College London in UK. She focuses on brainwave decoding and brain computer interfaces with machine learning to help paralysed patients to control their surroundings using their mind. Today he will present his research on deeper transfer learning form imagery decoding. I pass over to you.  Hello everyone, we are going to talk about into subject the transfer learning format imagery decoding. Brain computer interface has emerged as a solution for people with disabilities to regain control of their surroundings. Brain waves are directly collected from the school and motor imagery is our brainwaves people think about moving parts of their body like the left hand or right hand. On the right, it shows the control to the BCI and first, EEG signals are collected and these signals are fed into a decoding algorithm . The algorithm decodes the signal into maths and run back -- Commands and finally, the system gives real-time feedback to the subject thus influencing (inaudible) . CNN's are powerful decoders and have been used for imagery decoding since 2015. However, the challenge here is a free drain this in with multiple signal -- Subjects, it will decrease instead of increase. This is called connective transfer problem in machine learning. The transfer leads to a long and tedious draining period for new users because we can't utilise subjects actively. There are many differences like sensor locations and certain instance we are setting it up and different people have very different activities and performing the same task. To address the problem, we combined transfer learning with deep cyber coding . Extending the approach, we apply dozens of sessions with new subjects and use this data to train a deep learning model. The deeper transfer learning approach only connects one session from the target new user and then uses subject to train at the deeper transfer learning model. The deeper transfer learning model could be used to reduce the tedious training session of a new user. Transfer learning transfers the representations, knowledge from the source to target domain. From the sole subject to our new user, the target subject, there are several ways we can cheat this in the literature. The first is called fine tuning. We can train multiple source datasets first and then retrain the same on a new dataset with a smaller learning rate. The second idea is to split the new network layers for different datasets and this idea hasn't been tested for e.g. decoding. There is an example of the processing task and we can see that different language has a common feature extractor and then finally, their own feature extractor was split at the end to deal with their own differences. Another idea is that deep domain adaptation with maximum mean discrepancy. It is a matrix that computes distance between two distributions or datasets. We tested all three ideas in our study but due to time limitation, we are only going to talk about the result of the second one which is the main result of the study. The time series are very different from languages so applying this idea into the e.g. scenario is not straightforward. The next few slides, we are going to talk about how we apply this idea into the EEG scenario. First of all, we use one of the best performances for coding as the baseline. It contains a temporal layer, especially, an equal lay at the classification layer. In this study, we propose three architectures to perform multi subject transfer learning. The first one is the separate feature extraction network, the SFE in. Each individual has their own which are extracted due to differences in the data and finally, their features are fed into a common classify to classify them at multi-imagery. These features then have to fall into the same set of rules for the classification. Inspired by the , we have to extract common features after these individual channel layers. After that, we further split those the layers before that and we hope those layers can deal with more data like sensor locations, and in deeper layers after some common feature extraction, these deep layers can deal with more task relevant differences across different subjects. Finally, we propose the sensor aligned networks. There are two layers, the first convolution layer acts as the channel proposal layer and it uses kernels to propose channels and the second layer acts as the channel selection layer. It uses double kernels to perform a channel combination and channel selection. After this, the feature sizes doubled by T and this becomes the new and improved feature extraction. This network is a special design for different channel locations where we are setting up on different subjects so hopefully after this layer, those channels can have a similar location before they are put into the same common feature extractor. We evaluate our next works on two datasets. The first is an off-line dataset . It contains four imagery's of left hand, right hand, both feet and tongue. We also recorded our dataset. The subject is relaxing to go straight, left hand to turn left, right hand to turn right and both feet to 10 on the headlight. After they do the correct action automatically, we ask a subject to perform the motor imagery accordingly. We also had a pilot online session in which the pilot tried to control the game in real time. We trained a baseline in with the off-line session and he used the SEN to perform the online control. This is the result of the baseline . The left shows the average baseline accuracy of different subjects on BCI dataset. We can see that the average accuracy of different subjects dropped dramatically from 82% to 73% after using all subject dataset. Instead of using the only subject dataset. A similar result can be found on the Cybathlon dataset as well. We can see the accuracy dropped from 55% to around 49% if we use more subjects e.g. to train the DS CNN . The connective transfer problem on multiple subjects later. However, we can see on both off-line datasets and our Cybathlon dataset, it outperforms the multi-subject baseline. Note here, although I will post models seem to be a bit more stable, we observed no significant difference between outpost methods and the single subject both -- Baseline. For each individual subject, we could do with differences in the EEG data to ease the problem with connective transfer. In conclusion, CNN's encounter decrease inaccuracies when they are trained in multiple subjects EEG and having separately to extractors contributes to tackling this problem of connective transfer. Our proposed network has the potential to enable different subjects and this could reduce user training time and improve model performance. This requires further studies. We believe this study is the first step towards using multisubject deep transfer learning to reduce training time. There are many aspects we are working on and the first is to test our methods on larger datasets with more subjects and use deeper transfer learning because five subjects are not enough. The second idea is to improve network designs like replacing fully connected layers with well-designed convolution layers et cetera . Of course, we are working towards applying our model on paralysed end users and of course, the Cybathlon. Preprint of this study will be online soon. Email me if you have any queries. Thank you for listening.  We are back, welcome to Xiaoxi join us live from the UK. Thanks for this great talk. Let's open the floor for questions. You mentioned your method can reduce the training time. So how much do you think you can gain without? Can you go all the way to getting all the way with data still need some kind calibration trail? 's big Mac I think it still requires the collaboration trials for now. Because in the use of other subjects with EEG , we still rely on the personalised EEG to train the decoder. So it is not very possible for now to train a universal classifier for everyone.  OK, maybe in the distant future! (Laughter) Let's take a question from the audience. What is your opinion on using invasive approaches for BCA in the case of a stroke patient? That is the wrong question, sorry! What is your opinion on using (unknown term) e.g. BCI instead of (unknown term) BCI? (Inaudible) not or more reliable? Good question. Between motor imagery and other things like visual stimuli, it is voluntarily controlled by the subject. Because using visual stimuli is occupying your vision and it's not very convenient for a BCI user to control it voluntarily. Speak Mac OK, thank you very much for the answer. We have more questions? No. You mentioned end user testing CYBATHLON. How does CYBATHLON scenario benefit from the approach you just presented? Would use that in your algorithms?  Yeah, hopefully because considering the COVID situation we are not able to collect much data from subjects , and eliminates -- and are limited to (inaudible) . (Inaudible)  Thanks again for the nice talk. We will close the session here. With this we reach the end of this BCI block. We'll now have a short break before resuming with the arm prosthesis discipline. Mac welcome back for the arm prosthesis block. We start with a short trailer of the disciplines. (Music plays) Before I introduced the keynote talk for this block we want to use the (inaudible). This is given by (unknown name), a user of arm prosthesis (inaudible) team that will compete in November. Maria, we look forward to your statement.  Greetings everyone. I will compete in the (unknown term) race for (unknown term). We come back from the Istituto Italiano di Tecnologia in Pisa. I'm glad to start collaborating with our research team about four years ago when they were developing a first prosthetic prototype from our robotic industrial end. I was involved as a user and designer , helping in collecting experiences and suggestions to develop novel devices for assistive technologies. With this motivation I'm really glad to introduce you to this symposium which focuses on user treatment processes. Today, more and more, we can see users involved in this kind of design processes, giving suggestions, experiences and perceptions. These kind of processes really help in a wearing -- in raising awareness about disability in society. Thanks to initiatives such as CYBATHLON we can see more and more user design processes that help in developing new, novel devices for assistive technologies. So, once again, welcome and see you on the CYBATHLON 2020 global edition on 13th and 14th of November.  Thank you so much for this passage message, rear. I now have the pleasure of introducing a keynote speaker, Antonio Bicchi, professor of robotics at the university of Pisa. He leads the robotics lab at the Italian Institute of technology. His main interests are in robotics, and control systems. Hints team competed in the 2016 arm prosthesis race and will compete again in CYBATHLON 2020. We will now hear more about the importance of softness in his talk from and, how soft tech is changing the game. My name is Antonio Bicchi and this talk will be about using cleaning technologies -- The new technologies we have learned through the years in robotics for prosthetics. And showing how this is possible for numerous reasons and better than what exists already. The work is joined with my colleagues and co-workers in the University . These are some of them and it is a big group that has worked over the years. I also want to disclose that a founder of Hugh Robotics. -- We start with the robots when I was a student , the robots were machines that had heavy mechanics and were very effective in (inaudible) and making things more effective. Humans were separated from machines because of their own safety and this has been important and today is an important point of our economy. To make products. If you go today to factories, you will see many robots that are not separated from humans , they coexist and share the same space. Very often you see people robots being used in a safe and comfortable way. These are collaborative robots and the economy is growing fast so this is already some 30% of marketing products and it is going up . What happened ? If we look back at the 60% -- When this started, they had 160 kg flops and since then, the power has gone up so five years ago, we had 40,000 times that computational power in a small smart phone and today, we are more than 1 million times that . We have machines to do things that are impossible for us, the best champion of a game and it was achieved in 2016 by a machine. From Google deep learning. -- Google deep mind. If you look at these robotics, the second change happened . In the 60s, robotics were servo motors and they , at the beginning of the century, we had such a huge change in computation. These (inaudible) . What is the difference between motor systems in humans and motor systems in robots? In units, there is (inaudible) in artificial . So active motors have specific density and maximum efficiency so this is not really the point in either of these measurements and purely generic measures . Others can be (inaudible) but if you go to more general things, had -- How much does it cost to bring this from here to there or how much mass has the robot got to bring to the table, the robots have much more than humans. Humans outperform robots in the sense that the system is much better . This is shown in this cool video. Cruel video. This is back in 2015 and at that time, the whole system for a robot was still far behind that of humans. What has been changing or what has changed, what can enable this change? It is human intelligence and human intelligence is about , it is computational and it is in the cortex. The cerebral cortex . It is the computational model. If you look at the human intelligence, we have much more than a computational point and if it is not connected to the nerve system and the central nervous system that we have in our body, including our skin , we already have many nerve centres there. The emotions of our body are dominated by this emotional command of muscle fibres. It can be said that intelligence is in the whole body. People in art new from the old times. You can see how the nature of bodies are exploited by animals to do things that wouldn't be possible otherwise. The elephant's trunk is interesting or the tutor running or the snake , it makes humans storing energy , they are conserving their energy through their body. Elephants have a lot of intelligence . Bodies are soft , our body is filled with many muscles , very often every part of our body has two or more muscles . Depending on the task. We also have bones, we are very (inaudible). All nature , we have (inaudible) from the invertebrates from other species and animals have some in the body. The idea of having somebody's that can comply and can embed their natural intelligence in robotics . In recent years, many devices and new robots have been taken from nature as you can see in this picture. To mimic or copy or are inspired from nature. If they are efficient at the beginning, then the transition from purely (inaudible) to the collaborative process has been enabled by this attention to softness. For instance, these are videos that show strongly how the new technologies set out a simple interruption of robots with humans. Soft robots have been out and developed new robots that mimic existing vertebrates . (inaudible) or humanoids , they move naturally and compliance within (inaudible). How can we use this technology for computation ? Some of the progress that we have as humans. We specifically focus on hands because this is one of the parts that really think that is the physical intelligence of the human body and attracts humans as shown by this picture. Human hands , we have this many joints , 34 mussels, three nerves, 150,000 nerve fibres just for the hand. It is soft system and it is compliant in a lab environment. Crucially, it is simple to control. When we use our hands, we don't think about a hand motion which is very complicated and it's something that we use very naturally. When you lose a hand you realise how important hand is to everyday life. (Inaudible) first documented processes to the innovations that were made after World War I by Ferdinand Sauer Brooke in Germany. And (inaudible) Russian in 1966. Throughout (inaudible). (Inaudible) you realise they have up to 5 joints, they normally have no sensors , or sometimes have a few, and rigid mechanisms. Rigid systems. As opposed to our hands where we have 20 joints and use all of them. (Inaudible) when want to open a jar. We have a need for (inaudible) for the whole system. If you compare (inaudible) in natural bionic replacement needs humanlike dimensionality. In the upper limit alone we have 30° of freedom (inaudible) to make our limbs soft. In the lower limb there is comparable flexor T. -- Flexibility. How can we achieve and organise such complexity (inaudible) going about our daily tasks simply using this complex machine? That is a question that (inaudible) artificial hand. If you look at robot hands , for instance already in 1986 that were (inaudible). They had 16° of freedom. But it was very difficult to control and fragile and heavy. The real point is to develop (inaudible) that can make it more rugged and easy to control. Making it possible for the brain to cope with the complexity of the hand. The question is how can we do that? How can we manage these 30° of freedom? A newborn can already (inaudible) such as the one you see in this picture, without even knowing that he has hands or muscles. There is some theory from one group of people which says that the whole complex we have in the sensor part of our body , and the motor part of our body where we have many muscles and many sensors, is somehow managed before being helped by upper-level cognitive functions by some filtering, if you want. That made for a fast and abundant presentation and more abstract parsimonious. (Inaudible) that make all the competitive sensors be simplified to some abstraction and motor control to be (inaudible) . This can be exemplified by the postural synergies. This is a nice way of explaining this concept. There are 20 joints of a hand independently. We tend to cluster them in groups that naturally hang together. The muscles were used together is shown here in the left where hand has its power grasp motion. The second synergy is where the hand opens and closes in this way. But if you look at the statistics of how we use the muscles of our hands, then you find that the first synergy alone already explains 50 % of (inaudible). And if you combined the 1st to review what you have 84% , and so-and-so. (Inaudible) is not one dimension, it can be one of two dimensions. There was a very important conclusion that came from neuroscience. That also correlates in how we control a hand. For instance, there are others in cortex (inaudible) high level synergies organised (inaudible). But if we focus on this mathematical (inaudible) then things (inaudible). Follow me please on this very simple gradual motor. (Inaudible) hand and assume your closing according to (inaudible). Joints are closing together and taking on the shape you see on the right, indicated by this first one. If you think of grasping a ball, when you start closing the hand, he reached the point where you start having contact with the arm. If you go further, the shape of the hand does not match the shape of the ball, of course. Maybe symbols, yes, but most balls not. See what happens when the hand is not able to grasp the object ? This observation requires that we studied from the (inaudible) point a few. -- Point of view. (Inaudible) soft and strong but it is compliant. We have ligaments, tendons, muscles. All these elements are compliant. So the idea of mixing soft robotics with the Synergy model led us to propose this soft Synergy model. Basically the idea that our central nervous system does adds (inaudible) synergies we have seen before, while the physics of our body (inaudible) the object. So that our hand is (inaudible) image that is the way the phone you can see in this (inaudible). (Inaudible) by the hands (inaudible) to do operations. This is a nice theory but does it hold in practice? Well, he was a very simple , interesting sample or experiment we did. A person is trying to catch an object that is really not there. You can see that the person doesn't control the hand to match the shape of the object. We have the intention of grasping . If you see here, it uses a feature of where the hand was controlled. Our intention was to direct the hand to go towards this but we've relied on the existence of an object that put and formed our hand so as we expected from our learning experience. That is what soft synergies are about. Of course, soft robotics also tells us how to build products that look like and behave more like the human body. Our hands are able to , the robot (inaudible) so if you want to do this with a robot hand, forget it . It's going to destroy it but if it is on the south side, as shown in this video here, you can achieve a much more successful robot and you will have strong instances. So this led us to design the Pisa soft hand. It already has (inaudible) because it is softer and adaptable. He is the first prototype of the hand that was designed at the beginning for robotic application and it is very compliant and it has been transformed into a prosthetic hand . Longer work. As you can see , the same characteristics of being adaptable and compliant. Here is a video of the hand used for the first time as a prosthetic hand. As you can see, the control comes from the usual (inaudible) and the hand has the full ability of the human hand. It only has one synergy that gives the hand intention to the user and able to experience some (inaudible) who is a collaborator in our group and she has the design of the hand and takes all the input from users to consideration. And here you see another video where you can see how all the joints of the hands are instrumental to have the hand shape around objects and not only is it gentle because of the way it is built according to the human hand. Performance and grasping the performance in the fine manipulation is not the only thing where prosthesis is important. Our hands are very important for social interaction. We shake a hand , we touch another person on the shoulder. And also, it's important how we touch our own body with our hands and this is something we do every often without thinking much of it. If we want to have a prosthesis that is embodied and feels like part of our body, we have to match these abilities of the human hand. If we look at existing processes, it is not always the case. Not even in hands that look more like human hands. Indeed, the cosmetics are similar . The inner structure is rich like it's not compliance with the cyber -- The shape of our face. You can introduce a degree of compliance that is much suitable or for social interaction. Maria is using the hand with her own body and socially interacting with a person. You see that this can be used in a more natural way. Here is Maria with a collaborator who is one of the co-owners in this work. The first prototype of the soft and prosthetics that you have seen here has been trialled with several partners around the world. Mayo Clinic, Brace and the ability. We have many patients and we have realised that the soft technology has important potential but of course, we have seen many lessons as to what it could become. We'll press this is for real people in the world. We are working to what is something we can use every day like every person with reasonable cost , good performance and a natural feel. Indeed, we wanted to go even further in our search. To go further in the research, we have built a project that I would like to show you . It is called natural bionics , natural integration of bionic limbs via spinal interfacing. It is a joint project . The goal of this new project is to create a fully integrated , symbiotic replacement of missing or damaged parts of the human body with artificial limbs that the user will feel as a true part of their body. We do this, we need more than just bodies -- Robotics so we need surgery and reconstruction. I am fortunate to be joined by (inaudible) from the University of Vienna and a professor from (inaudible) . Two of the strongest surgeons in the field. First of all, the project aims to create a sensor Rotary -- Since remote interface and creating work that we called the (unknown term) which is a sensor image of the hand that has been amputated through target of the muscles in the stomach. Also the pathway fibres will be used and surgical techniques that (inaudible) . The second part is to decode from the neural code through the muscles and the language of the spine is so the three have a better understanding of what (inaudible) and also how to convey back our information from the prosthesis to the patient. This is where the professors come in. It is important to know that once you have this (unknown term), this sensory value, then we have to connect the motion , our brains send to the hand, with the feedback we had . Here, it is important to notice that this leads to the interaction of the hand with the environment and it's important for humans , for us to believe that some parts of the body are indeed (inaudible) and the expectation of the feedback from the interaction matches what we learn . If we want the proceeds this -- Prosthesis too much, it is important what we get back from the interaction is similar to what we get back from the interruption of our real hand. It is a soft and we believe it is important that the prosthetics is also soft . It can be close to the hand mechanically and it is of course our job in this project. Here are some first results for the national bionic project which will go further , five years or more so we are the beginning. This is a new hand that is looking like a human hand and can interact with our body. In a natural way. He is a social interaction of the new hand. In this video, you can see Maria using the first hand and showing how the hand and the design of the hand , the control of the hand is very natural and allows her to do things. Of course, we are not saying it is definitely better or worse. It is different. It is Will prosthetics that we hope will bring some improvement. Of course, the control of the process is not the whole (inaudible). We have to get feedback. Feedback is very important. For instance, I just mentioned (inaudible) of asking. If you look at the nerve fibres , and go throughout arm, you realise out of the 350,000 actions innovating the human arm, only 10% are referenced. -- F torrent. That means 90% is dedicated to bringing sensory feedback . This is also possible to see that movement is a sensory phenomenon. 90% of nerve fibres are dedicated to setting. (Inaudible) it is known that, anatomically, we have no (unknown term) sensors but we have sensors on (inaudible). That is enough to control (inaudible). These are examples of how important sensors are in the control of (inaudible). In this project we will have a transplant of the dermis (inaudible) and through (inaudible) devices we will then have (inaudible) for these dermis transplants that have reached treatment of receptors (inaudible) surgical technique. Of course, there are several ways of giving feedback from the prosthesis. Where (unknown term) sensors are placed. To our nervous system. Here RFU a re systems that have been tried. (Inaudible) reproaches different. What we want to do is use non-invasive impact. Here is our very first prototype of the prosthetic hand with a splayed device that will eventually be used on (inaudible) whether dermis transplant is there to provide this image directly to the spine. Sensory feedback, as we said before, is no less complex than what we have in (inaudible). Humans use nearly instant teeniest dimensionality reduction of elementary sensory input through invariance (inaudible). It is important here to have a theory. One of the important things is that we have the ability to be triggered by a perception. We have many illusions. Illusions that can be explored. On the left we have the barber pole illusion. Where this poll is really rotating but it appears to you and me as if it is moving upwards. What is happening? Were extracting from this image some premise of motion that are extracted from the reality. Therefore, they project reality on the lower dimensional space. So our approach is we are going to try to exploit these weaknesses of our sensory system and make it possible (inaudible) central cues without (inaudible) the whole complexity of the thousands of receptors. But rather going to (inaudible) presentation. (Inaudible) motioned (inaudible). We have already implemented (inaudible) possible way. (Inaudible) distribution of sensors in the skin (inaudible) if I want to find where my hand is I use sensors that are in my skin. (Inaudible) there are reasons why there are (inaudible) stop if we understand this principle (inaudible) that can, for instance , show person, as in this preliminary experiment here, when an object is touching the hand. Therefore, the person can control much better the hand. (Inaudible) this exciting adventure (inaudible) 2016 , and that we will join again this year. We have learned a lot through interaction with other teams through the competition, and through the social mixing together . I think that CYBATHLON is a really great idea. It is the Formula One of Paralympics as I call it. It has really changed the (inaudible) in prosthetics. He was participation in (inaudible) where the SoftHand Pro was used by Maria as one of the pilots. (Inaudible) . Just briefly mentioned that in this series we had at Karlsruhe touch by next was first and third. And Rosa, another pilot, was fourth , but did the whole task completely. We were the only research group in that competition. We lost to (inaudible) well proven in time , and with patients. Here is Rosa , that I would like to introduce to you. And besides the actual results of the competition, I was very happy of being part of CYBATHLON because of the many lessons we learned, not only during but afterwards. Here are some pictures we took without the pilots knowing. Here is Maria using the hand to manipulate herself own or to open a bottle of soda. -- Manipulate herself phone. You see Marie is using (inaudible). This is very much like what a normal hand does in the left picture. This is proof that the controller for the hand remains (inaudible) allows more natural interaction. Here are some self interaction examples were Maria and Rosa were waiting rather nervously for the start. You see they use the user hand (inaudible) like we do with our own hands. Rosa is working on (inaudible) just to get concentration. Rosa makes a sign with a hand. And Maria tries even to dance with an engineer (inaudible). If you have a hand that in can interact and Maria is interacting nicely and safely with Christina , she is the leader of , one of the leaders of our team . And finally, Maria is doing something that no other person can do. I believe. Maybe not so useful but . This is work that has been done by a group of people and I am thankful to all of them. I hope that I showed throughout this talk that some technologies can bring some innovation and some useful , new features in prosthetics. Thank you very much . He is Rosa saying goodbye . Thank you. We now welcome Antonio live with us from Italy. Thank you very much for this talk and for reminding us that a movement is always strongly interconnected with sensory feedback.  Yes.  We have time for some questions from the audience. Yes, the human hand is much more complex than any prosthesis therefore shouldn't we aim to build more specific prosthesis dedicated to specific tasks and the. One user would use many.  That is possible avenue . I'm not sure , we do use tools for different tasks . Normally we use the same hand with tools and this idea could be similar to changing the hand if there are two. I'm not completely sure that most users will embrace that point of view but some could , why not? Further question is in the long run, do you see pathetic research being overtaken by unitary -- Regenerative lung ) limit research? I must say not able to answer this scientifically and I know very little of regenerative medicine. I haven't seen results so far that encourage us to think that we will see this in our lifetime. So it may be in the future but a rather far future. It's worth continuing to improve the technologies we are working on now.  I would think so, yes.  Do we have further questions? How much more important is the look of the hand rather than functionality when talking to the users? The look of the hands is not an easy point . Every user has a different point of view and for instance, we have learned that the approach of making it very much like the human look is not always the best and of course, everyone knows that in many cases, people with amputations like to , they don't want to conceal the technology that is behind them and they are proud. One of the roles of Maria , you have seen before, it is the head of starting what the users really want and the users , it is different types of people, younger or older and each group has its own preferences. The design of the looks is very important to make it acceptable and functionality is also very important. As I said, not just grasping power or dexterity in operation but also the natural look of interaction .  Thank you. I think we have time for one more question. What does it mean to Rosa and Maria to experience the kinds of hands you are developing? What kind of feedback do you get?  Both Maria and Rosa are our pilots and preferred users. They are part of the team . I'm glad to say that they are happy to use it and they are enthusiastic about using it. More than this, we have tried to have several attempts of users with several attempts and the feedback we have got is almost 3 good all the time. I can remember one, there was one user that was unhappy about the different features of the hand. It's normally well received. The hand is not just looking natural but its functioning more naturally and that is much appreciated. I would say the way they receive it is very good.  Nevertheless, I'm guess , do they have desires that you could address in the next iterations and things they think that are lacking right now?  Of course. There are many. Many directions of development, we have learned a lot from users and we have changed the design already and we have a long way to go. From , the hand is still a bit noisy like many hands and that should be eliminated. More dexterity, we are working now on a more dexterous hand with control and integration with wrist and with an elbow. And definitely the sensory feedback, which is one of the topics we are working very hard now .  Thank you very much, Antonia. We have to close our live discussion but you will address the remaining questions in the chat. Thank you for joining us and good luck with your team at the Cybathlon 2020! Great pleasure, thank you.  We now move to the shorter topic in the arm prosthesis blog. Nathanaël Jarrassé is a permanent scientist at the Institute of permanent systems and robotics of the Sorbonne University in Paris. Working in the team, he put -- Was a priest from Rocky was a researcher and received his PhD in UPMC and holds a degree in mechanical engineering and also an MSc degree in robotics. His research aims at understanding nearer matter rehabilitation and assistance. He is part of the smart arm team which will compete in the Cybathlon 2020. He will present to us in the heart of -- On behalf of somebody who is on maternity leave. We look forward to your talk.  Thank you to the organiser for letting us present at the Cybathlon Symposium. I will present the work of Mathilde Legrand. She is actually on her maternity leave. We are all members of the same team from Sorbonne University in France and be happy to be part of the Cybathlon in November. Our team is made up of Robert sis, scientists and clinicians and someone who is an arm amputee. We focus on the development of improved prosthesis and controlled approaches for high-level applications like an arm or shoulder amputation. When we look at the current prosthesis, we can observe that the metrics is advanced and we have to find commercially available, FDA approved and prosthesis such as the (inaudible) and the Michelangelo . We have robotic arms from (inaudible) but there is a discrepancy between how advanced the mechatronics is and how constrained the controllers for the device. What kind of control exists for those advices -- Devices? We look to give an overview of the kind of control that exists. The most control approach is to be (inaudible) or direct control approaches. Basically, a user will rush to reach target X and will have to control his own body and the prosthesis to be able to perform an adequate jester. Did you see the most , approach is to measure on the human body (inaudible) used as a control input for the prosthesis joint. Different kinds of signals can be used, usually (unknown term) . (Inaudible) . Can also be signals from the central nervous system like NSAID grams. Or what the head movements or ankle movements (inaudible). What is important to observe is to this kind of architecture creates a dual controlled loop. Users have to produce auxiliary signals that will use (inaudible) to control the prosthetic joint. In the same time to control his own body to perform the desired trajectory . The problem is those two loops are very different, (unknown term) loop inks loan complex views because of muscle contraction . (Inaudible) to perform a reaching task. (Multiple speakers) When there is a final reaching error, instead of (Inaudible) solves the final reaching error of the prosthetic hand. One possibility to solve the issue of the dual loop is to use (inaudible) joint approaches. (Inaudible) are basically way the central nervous system has to manage (inaudible) to perform some tasks. For example, during your reaching task, there is usually no relationship between the shoulder velocity and elbow velocity. Those kind of relationship can be modelled specific control (inaudible) the body of the user's (inaudible) to compute (inaudible) prosthetics should generate or exhibit to produce this kind of synergy. In this case, the elbow prosthetics would automatically actuate (inaudible) piloted by the shoulder velocity of the user to reduce the complexity of the control. The problem is that such an approach is complex to set up. First building a proper model of the synergy is difficult. Needs lots of (inaudible) on each subject. But more problematically basically synergies are task -dependent. Means the control architecture will be complex. Has to recognise the kind of task being done. To load the proper synergy model to be able to control the prosthetics in a correct way. More than this, there is a fundamental issue with these approaches. Basically, they are open-loop approaches. Open-loop from the robotic point of view. Means that in both cases the correction to the loop closing has to be done by the user through his human centuries system, through feedback (inaudible). He has to realise that performance action have performed the prosthetics. This pathetic is not able to close the loop because it has no idea of the task, (inaudible) behaviour onto. The result is that because of the discrepancy between the lips and the complexity of using the pathetic loops, the user, rather than (inaudible) correct an error of the prosthetics by using body compensation. Because of the motor slacking behaviour of the motor control of the central nervous system, basically they will exhibit body conversations. (Inaudible) proximal joint motions, such as shoulder or back movement to compensate for the process error or Mac. We propose to take advantage of this natural behaviour and build a control that uses this body conversation. We call it compensation cancellation control . see CC. This is another view of it. (Inaudible) steps (inaudible) and compare the posture of the user body to what we call non-compensatory posture. This is used to compute an error that is then transformed into a velocity of the prosthetic joints. More simply, the user is in charge of controlling the prostatic displacement (inaudible). And the prosthesis is in charge of changing the kinematic structure of the prosthesis to minimise the body conversation from the users. For example, to reach a target with an elbow when the elbow is fixed the user will compensate with its strength. (Inaudible) and use it to change the kinematic configurations of the elbow to (inaudible) compensatory pastor. This is a very natural approach because there is no specific learning. By the conversations out (inaudible) exhibited by the central nervous system. It's versatile because Hong Kong can say true posture it uses is not at base. (Inaudible) only used for orienting joints of the prosthetics and not the grasping of the hand. Because there is no compensatory posture of the grasping that can be used and tracked to determine the user wants to close the handover and object. At the moment we are working on how to map the compensation onto the device motion. And also what is a compensatory posture. And how to may be modulated, not have it fixed, and have it evolving according to the environment or preferences of the user. What I'm going to present quickly here is the first feasibility study we performed using three (inaudible) ceases (inaudible) elbow in hand. We performed the Rowley and clothes spin test. He used for that the CC scene mode to control the elbow and wrist while the hand was always controlled with my electric control. (Inaudible) contraction switch to pilot all the joints together with the same muscle contraction signals. We observed that (Inaudible) measured through the (unknown term) score. CCC we also observed (inaudible). Tens to enhance body conversation which is not acceptable stop so at the moment we are working on improved tuning or more training of the users to minimise those (inaudible) conversations especially. In conclusion, those are encouraging results. We are currently working on theoretical proof of the kind of stability of this specific human robot Kaplan. We are broke in on what might have more generator of controlling our (inaudible). (Inaudible). I will thank you. I will be happy to answer your questions if you have some.  We now welcome Nathanaël life in Paris. Thanks for being with his assassin.  Thank you very much. I would like to start with the first. You showed us some objective and semi objective metrics for how the behaviour changed with your compensations . if I can say! That strategy UN lamented. You showed that the time reduced and also on the NASA-T LX the storages. How did this feel to him and how did he react to what the prosthesis did?  Thank you for the question. The user was happy with this system because the user was able to control several joints required and it has a lot of co-contraction, depending on the muscle quality of the user, it can be difficult to produce and in our case, our participant has a lot of difficulty to exhibit proper cocontraction so it was very fatiguing at the muscle level. Being able to perform the task and use different strengths without having to regularly exhibit cocontraction was a real treasure to do . Additionally, his description is that the device felt natural because of course, the conversation in this case was extended and advanced but it was not , he was not really aware and he believed he was not doing something new and some new skill that hasn't been land to be able to perform something with the pathetic and this was very pleasant for him compared to the time it takes to be able to master simple tasks. They were saying that there was still some work to be done but they were well surprised by the system.  Do you think that the collaboration between the prosthetic limb and the user would further increase if there was more training? Is it the amount of training to get to better know the behaviour?  Definitely. As you may have seen, in our control , there is a specific and very crucial integrator and there is some kind of inner shell between the (inaudible) and the reaction of the device. This allows to have another region coupling from one joint to another that will be constraining this kind of integrator states a bit of view to participate , the action which would lead to the processes of reaction sale for short, with more time, and more adequate tuning of the hand, we could have a faster subject and limited (inaudible) exhibition.  Let's see if we have a question from the audience can. There are some aspects moved more than the strength of your control strategy? That is a very good question. Unfortunately, I don't have access to the specific results and Mathilde could have answered that but I can't. Hopefully we will try to provide some information in the next paper . Don't hesitate to send us an email and we can provide more insight later. SPEAKER: Thank you. You understand the importance of control properties and I was wondering could this same strategy be used for prosthesis that has an active wrist because having an active wrist can induce additional movements.  Definitely. That is our next step and we tend to use existing commercial devices to be able to quickly do experiments with patients but there is , there is a very limited number of active wrist flexor available so we have built our one and the next step is to make some trials on a more complex prosthesis that was developed this year and it has for -- Full freedom and the elbow and as you said, the wrist flexion is critical and amputees tend to orient their hand with their shoulder and elbow complex with lots of adjustment and it is problematic from a (inaudible) point of view so that is our next goal.  Thank you very much. We have to close the live Q&A for, it would be great if you could join the chat and see if there are any further questions. Thank you for being with us this afternoon.  Thank you very much.  Will now have a short break and continue with the interactive poster session at 325 Central European summer time. I kindly ask all presenters to prepare their zoom rooms and demos so we can start on time. To access the rooms, follow the links that have been activated on the symposium landing page. Please don't forget to reload the landing page if you are already on that page so you can see the links appear. You will find a direct link on the slides that will be shown on this stream during the poster session. Please feel free to visit several rooms and interact with the presenters. We wish you an engaging and inspiring poster session and stimulating discussions. (Video plays) Welcome back everyone. I visited some rooms and was impressed by everyone creating material to showcase their work and taking full advantage of the virtual event. Congratulations to all our poster presenters. If you did not get the chance to visit every Zoom room , don't hesitate to contact the presenters via Twitter or email after a symposium. Now is our next topic on leg prosthesis. He was a short clip for you. -- Here is . (Video plays) Time to welcome our last keynote speaker, Helen Huang. She received a PhD from Arizona State university in this now the distinguished Prof in the Department of by medical engineering and closed-loop engineering , or in short caps clear, at the North Carolina State University and University of North Carolina at Chapel Hill and the United States. A research focuses on (inaudible) where a robot station with (inaudible). Her talk today will be about Neural Control of Robotic Prosthesis. Helen, we look forward to your talk.  First I want to thank the committee for inviting me to give a talk. My name is Helen Huang. I will talk about my research related to neural control of reported lower lumbar procedures. Just a bit about myself. I'm Prof in the joint Department of biomedical engineering. I am also the rector of Clear. That stands for closed-loop engineering for advanced rehabilitation. -- I am also the director. These share a common interest in rehabilitation engineering and science , as well as clinical translational rehabilitation research. I encode you to visit our website and see what we do in North Carolina. -- I encourage you. I want to highlight the team from our own department, Packet Bionics. They will compete in the power lag category. The team is composed of a group of undergraduate students. Most of them are seniors now. When I talk to them about the opportunity to compete, they were just a sophomore. Very proud of students who have grown so fast in two years working on this project. The team leader is Dr Bruce Wiggin. He also received a PhD from our program a couple of years ago. I also wanted to highlight how to awesome pilots in our team, Charles Humphreys and Faisal ham doing. Both have spent a lot of time with students. I look forward to cheering for the team. Just back to my own research. I lead a group of students working on robot Essex Liberty device. We are trying to merge human and wearable robots, not only physically attached together. So specifically, we work on machine interface for not only prosthetic legs but arms. We work on control automation , artificial intelligence for operating these wearable robots. We also conduct research trying to understand how human and these wearable robots interact with each other and covered up. And Marco adapt. In this talk, I will talk about robotic lower limb prostheses and present how I can achieve human symbiosis . So addressing the quality-of-life for an individual who has a limb amputation has a profound societal impact because this population is large and growing. In the US, about 2 million individuals limp -- Live with limb loss and there are globally more than 1 million applications performed every year. The majority are performed in the lower limb and many patients depend on some sort of assistive device to restore the basic mobility and basic activity of their living. When we look at the market in terms of lower limb , the majority of devices are still passive . However, recent advances in sensors and also battery develop these robotic motorised prostheses and lower limit -- Lower limb prostheses has been ongoing for more than 15 years. On the top line, you will see it's actually older versions and prototypes for commercial devices that are available about 10 years ago. I have been using these for my slides for many years. I want to highlight the habit -- This is a biome currently in power on (inaudible) . Recently, there is multiple new prototype which is developed and I apologise that I did not include everyone's prototype . These new generations are more powerful, reliable , light and practical. This is definitely a promising future and a promising technology to further improve the mobility for individual who has a lower limb amputation. So all these devices, they use some sort of autonomous control so here is assuring a very typical way that a typical control for this device. It is combined with a machine that will complete the control and it identifies the human's stated during the cycle and based on that information, it can describe what is the desire for the devices are supposed to do and we can use the impedance control to achieve that. The benefit of these devices is it powers through the entire cycle and it will generate a gait pattern close to what we observe in able-bodied persons with intact limbs. So here I show the circle representing the state of (inaudible) and as long as we can predefine this task, this potentially can enhance the power and can assist a person to walk unassisted. Power device , it is more important than usable for task like assets -- Task like stair centre. Again, once we can predefine this locomotion behaviour, we can include that into the control and this became a part of the control as well, to assist the person to perform this locomotion task. We can continue expanding. The problem of this control is a lack of adaptation. Two new environments, to the user's physical condition , movement intent and the lack of ability to support activity that is harder to predefine. Well, so these controls for the prosthesis control , they are known to be fast in terms of feedback control rate. They have a faster action reader and a more precise sensor and could provide a precise control if there is a task that is well defined. However, they lack adaptability. If we look at another control and the human prosthesis system, that would be the human motor control. We know human motor control is highly adaptable , flexible and they can generate a versatile motor behaviour to adapt to all kinds of environments and activities. In order to generate and improve the function of these prostheses, one where we can achieve this human prosthesis symbiosis is the two systems can work together and building this interface , controlling with each other directly. Therefore, I'm going to show you a couple of things I have been carrying out around this idea. My goal is to enable versatility of robotic legs via neural control . Versatility is a prosthesis that can adapt to many different environments and activities in the individual's daily life. So I have been working on this topic of work for a couple of years and I will show you to remain a concept that I have pursued in the past 12 or 15 years. So my first project relating to this topic is it came from my understanding of how current these processes are controlled. I talk about these locomotion roads so each individual predefined the movement and behaviour that is associated with different locomotion modes. And one important aspect is you have to make this task transition in order to trends rag rug to go from level walking to stare a centre. This is very early version of the video and is the first version of the powered limb. This person is demonstrating transition from level ground walking to ascending stairs. This person has no idea what is in front of the -- The company had another sensor attached to this underside and they used some sort of special body motion as well as the immersion from the softer side to tell this prosthesis where the next step is. This approach is sometimes reliable and also later, the company removed the intact sensor and decided to try and teach the user how to load inappropriately using body motion and they could trigger the transition. To me, I was just thinking instead of using this body motion, how about just decoding their neural intent and then the person will be able to do the task seamlessly. That is exactly what I did. I came up with generating this supervised control approach. I will generate eight neural machine interface as a higher level control which identifies users locomotion mode and in the lower level, it is autonomous control so you predefine the locomotion behaviour. When then they wrote machine interface recognises the intent, it will select the appropriate mode. Initially, I used the input which is the EMG came from the muscle and I developed the phase dependent strategy. Later, I also used additional sensors which I call the neuromuscular mechanical fusion and some additional sensors such as sensor that monitors the motion of the thigh and the pylon and integrated together, I built a classifier that could be able to recognise what a person's next step will be in terms of locomotion mode. I'm now going to talk in detail so if you are interested, you can read some of my papers , decades ago, which have a detailed engineering approach there. Fast forward and we did a decoder and connected it with the machine. Here is the lab testing. We can see the user would be able to walk up the stairs and transit without stopping, with doing any appropriate loading. So the transition is smooth. This is great but every time I presented this work, while I'm working on this idea, I often get a question regarding does your decoder have an error? I say yes, always there is to 5% of the error. That doesn't mean there is a 5% chance that person will fall. That is a greater question. This highlights the difference between prosthetic arm and leg. Fora lower arm device, because the basic function is supporting the upright balance and stability, when error happens the person might fall and generate injury. So that is a safety issue. Does the non-critical error lead to the person falling? I really don't know. I conducted another test. I simulated an error with the person walking. This error was what I saw as my recognition load algorithm. For this video look at the flash of this error. That is the duration when error was injected. Here it shows some of the error like this one. And you can see this error , you can barely see the difference of that cycle versus another cycle. And more importantly, the user also reported feeling nothing. So this error does not cause any danger or problem , so we call it a non-critical error. But we also have a situation like this one. You see the hyperextension. One more time. In the middle of the stance there is a hyperextension that is generated that causes the balance to be perturbed. And the user also told us they felt not comfortable walking with it, not safe, not stable. So those are critical errors. We put those errors together and mapped the errors, when it happened, and how big was . Versus the response of the person in terms of balance stability. This shows angular momentum. You can see that not every error will cause a problem. Most errors happened during the swing phase, even though the magnitude is large. But it's OK. During the sensor phase, humans are more sensitive towards error. In future work, how do we deal with these non-critical errors? It is important to make this practical for users to use. All right, so the previous approach that has allowed us to run adaptations on level ground and stairs. But when I revisit my goal, the versatility is adaptation to many different environments and activities. How about the environments like walking on the trail , or playing tennis , or dancing, potentially allowing amputees to compete in Ninja Warriors , a popular TV show in the US. When I looked at this supervised neural mentioned previously. I realised the behaviour of the prosthetic joint is still dominated by the autonomous control. Even though we have a neural interface. But we would not be able to use this in your interface to operate the procedures to perform tasks beyond what is predefined here. But my goal is truly to give humans freedom to use these powered devices to assist all kinds of activities, including those activities not that, you know, easy to predefined motor behaviour such as playing tennis or, again, competing, jumping or freestyle dancing. So can we do that? We have two controllers . human motor control and machine control. We mentioned the one way we can merge them together is a neuro interface. But instead of directly connecting those two, maybe we can add the neuro control dominant. For example, in this case, we can use the ritual -- residual (unknown term) muscle there to directly operate the prosthetic joint. So the ankles behaviour is purely dependent on the neural input from the human. So, now, the main question is . the first question . what Mac can amputee is coordinate their residual muscles inappropriate way for the continuous and direct EMG control? This is important because the EMG is the control space. (inaudible) controlled interaction this approach would not work. And we wanted this approach should be reliable as well. In order to address this question my group has a contact sequence of study. The first one, as an example here, we take the load from the residual to Biala Santeria and residual gastrostomy's and we mapped the magnitude into two spaces. (Inaudible) and the horizontal line is the gastrocnemius. (Inaudible) colour blue in the space. To respond her the is preventing (inaudible) presenting (inaudible) in real time. The task for the user is trying to fill colour as a space, as many spaces as the can. Another example , with use the same residual muscle pair to proportionally drive the talk - - t o rq ue so the goal of the user is (inaudible). Due to the time limit I won't go over every detail. But there are a lot of interesting observations. I encourage you to read our recent work. I just want to highlight the two take home messages. One is that there is a large variation to Asian -- variation across amputee participants in the capability into activation of the residual antagonistic muscles. (inaudible) in group 1 subjects would be able to feel more than 85% of the two (inaudible). That means the person would be very flexible enable to generate (inaudible) in this space. The second group as the majority of patients. They have activation . Some level of cooperation. But it is smaller than Group 1. In the last group we have two patients who have limited corrective. They basically can activate one muscle at a time. The second take-home message would be if these residual muscles are in contact of control such as the inverted pendulum, they see the consequence of their muscle activation . After a certain amount of practice, it's not very long. We gave 10 trials of practice for each person. And the majority of patients, basically in the patient one and two, being able to adapt their residual muscle activity for the efficient control. Of this inverted pendulum. They started to have their activation and be able to perform the task more successfully. So this result gave us a confidence that if this residual muscle has a certain meaning, in terms of control and they can control the leg, if we give a certain amount of time for practice, they will probably be able to use those devices for their activity performance. But is that true? Instead of competing in ninja warrior, we led them to 1st to try to control their posture. Why? One , posture control is very important and it is in almost every activity, operate. Number two is based on our knowledge and not of the power devices were passive devices and they would actively support this device and posture control. Also, if someone says how about using autonomous control, this is quite difficult as there is an anticipatory part and the user started to modulate their joints , that is very difficult for autonomous control to do. For example, in order to control the talk on the ankle, you have to know how heavy the box is and how compliant it is to the ground. That information is harder to obtain. So anyway, we did a case study and recorded one person going through a couple of weeks of training. The set up is a straightforward so we have got the magnitude and used it through these pneumatic muscle actuators . How it works is it will shorten and generate it like a muscle. So there are two from the front that make the function of TA and two on the back which mimic the function of gas. And we select one patient from group 2 because the majority of the patients , they can do is to group one and it should have no problem to use the device as well. The procedure is we introduced him to understand and when the muscle contracts, how that will operate in the prosthesis . After that, we went through a four week PTE guided training for posture control . Here I wanted to demonstrate how it will work and this is the early on trial, the first day, he is trying to perform this task for the first time which is pick up this heavy medicine ball and put it on the side. Rate of transfer. I want you to pay attention to how he controls the joints. So he couldn't be able to bend really low and you see that kick there. You can see he is very excited because he wouldn't be able to successfully finish the task and be able to come up without causing any dangers . He also mentioned that he has control and sometimes it is too fast , sometimes faster than (inaudible) . Later, we see a synchronisation of the two so that is no longer true. So I will show you. First, let's see the results compared to the passive devices of the side, this aside is EMG controlled. You can see the posture because a passive device doesn't have that much so he has to really use the back and the intact side to compensate this task. And you can see how beautiful it is on this side, this is the standard way for the lifting weight and we know if you use it too much , if you use your back too much, it's going to use) cause a secondary injury . In the anterior and posterior direction on the prosthesis side. The blue line shows the centre of pressure of the Pacific side of the green line is the intact side. If you use the passive device, the pathetic side barely is modulating but when he started to use the EMG control , it's not only beautifully modulating synchronises so well with the intact side. If you render the correlation , you can see how well this matches. The value is much higher than using a passive device. And also, we want to see a training fact from day one until the end and we still focus on the crosscorrelation of this EOP , bilaterally with the zero alike. As you can see, there are days and this value started to increase. Somehow, it was on a certain value and also, the biggest improvement is actually in day one. If you look at the day when, across modular trial. It means that they understand the consequence of activating this muscle and became biomechanical and had a function. They started to learn that really quick. In just one day. Another amazing thing we saw was the synchronisation of a bilateral EMG in muscles. Here is day five. This is showing through bilateral TA EMG in a two BLS interior -- And then the grey curve is the intact side. At the beginning, the two muscles, bilaterally, was not that synchronised but after the training, these two muscles are well synchronised and some of the peak is well aligned with each other. This is motivating me to think that perhaps the person restored the pathway once the MG , the residual muscle activity became meaningful. And was restored to a biomechanics function. Of course, additional research is required because we only did a case study but it is very exciting. Just to recap, we talk about the two types of neural control . What is supervised and you can rent adaptation. I also talked about the direct EMG control and it has a lot of potential but has to somehow relate , have appropriate training of patients. And we also see when people use the direct control . Given they are self-sufficient, it can help them to adapt their residual muscle activity and in order to generate appropriate and more efficient EMG control of a prosthetic joint. So the future , I recently also have seen a lot of emerging of another research area and people trying to generate all different kinds of afferent interfaces. There is a sensation of the foot and sometimes a drink at the ankle. -- Joint at the ankle. When we have a neural control, the person also not only understands the consequence of the action but they know how they can contact the ground. That has promising (inaudible). I look for to read more from the group about their research. Without, I want to thank everyone for your attention and am ready for your questions. Thanks.  Right, let's welcome Helen joining the slide from North Carolina. Good morning.  Hello. How you?  Good, thank you. Thank you for your inspiring talk and sharing these exciting results. Let me ask you the first question. The changes in muscle activity that you reported at the end are quite impressive. I was just wondering what is the next explanation for this? Is it just a subject learning to you to some how trust the proceeds is better?  I personally think that this is the restoration of the neural pathway. (Inaudible) no longer have (inaudible) version , -- function, (Inaudible) that is why some people (inaudible) one muscle at a time. But if you give back the biomechanics function of this muscle , then you see the activity became closer to what we observe in an able-bodied person. So I am really excited because I haven't conducted more neurophysiology study on this the time interested in the way they can restore the original neural pathway for (inaudible) the muscle, and then perform the task like an able-bodied person could.  What was the feedback of the subject during this learning phase? Speak mag oh, he's excited. (Inaudible) Caskey could not do like the weight of transfer like a shed. But he can use compensation. Now he would be able to use the ankle again. Contracting muscle would be what Mackie lost the three years would be huge for him.  Fantastic, thank you. Let's see if we have questions from the audience. How robust does that EMG recording work? Is the recording signal sensitive to leg stump loading? Powers repetition accuracy after (inaudible) of the device? Great question. Our paper on that (inaudible) studies is (inaudible). We did a careful design of the subject (inaudible) important (inaudible) . (Inaudible) using highly (inaudible). One aspect is the human will quickly adapt to it and , two, it is not very noisy compared to (inaudible) you need to capture detailed EMG information like (inaudible) or (unknown term). So that is a difference in the reliability part. It depends on what information you capture. I am very excited about the current technology that is EMG recording directly into muscle. I think that is also a future direction of that is available and what my control will be more reliable.  Absolute. Let's move to the next lesson. What is the percentage of subjects in group 3 in the study you showed were not able to co-contract? Do know how many of them significantly improve their co-contraction? To what does this relate? Type of injury, time or surgery they had also won?  Yes. Another great question. I wish I could answer you for sure! In terms of percentage, in this group there are two people all the time, 20% in a small sample. We did not treat them to expand further. Sophie conducted that research, it would be great if they could stand more. The people who had limited co-activation, when we (inaudible) pendulum control , though still improves the task of performance (inaudible) was shaping the muscle (inaudible) strategy for using that muscle activation is not aligned with other subjects were recruited. Again, I recommend you read more because in the paper we have a report about it! Then I guess last one, what is the reason? We don't know! (Inaudible) the surgery or maybe the number of years after amputation. But because the sample size is relatively small we can't assure answer those questions. And nobody really reported their surgical technique . that's another thing. I think, in the field, it is important to know what type of surgery. There is a new surgical technique available. Maybe that surgical technique would help further. SOPHIE HEAWOOD:  Another question. How is it make you feel when you see a patient have success all improve quest Mac That is the thing that is motivating me to do this research. We are very excited every time we saw patients excited about technology. It does show (inaudible). Absolutely we are excited.  Beautiful. It is a beautiful message to end this question session. I would like to thank you very much again, Helen, for joining us today. I wish you a nice rest of the day.  Q4 having me.  OK, the next short talk will also be on the topic of leg prosthesis, given by Joost Geeroms, a post doctoral researcher at Vrije Universiteit in Brussels, Belgium. His research is around torque (inaudible) focusing on bio inspired and efficient energy design, as well as low and high level algorithm. He is (Inaudible) participated in the 2016 CYBATHLON addition . (Inaudible) CYBERLEGs X-Leg : lessons from active prosthetics research. The floor is yours.  Hello. Thank you very much for the introduction and thank you all for attending this presentation from the work of myself and my colleagues over the past two years. Our story starts before the first CYBATHLON in 2016 . At the end of the (unknown term) cyber project with we developed (inaudible) elderly vascular beauties. (Inaudible) weaknesses in the rest of their body. We try to enable them to remain an active part of society. To do this the project combined our processes with an exoskeleton that supports the rest of the body. It ended in 2015, after which we decided to participate in CYBATHLON with our research prototype. We learned quickly that there was not such an easy transition as the requirements for a research device were very different from those devices to participate in such a challenging demo. Advice was quite robust mechanically in intensive control. This was still a technology readiness level and not really use the side of the love. We made changes to achieve the required acts -- Accuracy and uses 30. We had a lot of technical capabilities on board the prosthesis and with this came hi complexity in terms of control. This means that while we were able to have specific control strategies programmed for sleepwalking, stair climbing and forward walking, we didn't have the ability to sense the user intention accurately and reliably enough for use during competitions such as Cybathlon . This meant we had to replace the automatic high level control and wearable sense of apparatus and the pressure sensitive insoles. By a touchscreen user input which you can see on the wrist of our pilot. Besides this, the controller used was running a thermal Dell laptop which the pilot had to carry on his back which was not very comfy. The additional covers which were less important for our research device and it was a lot bigger and more cumbersome than it was before. After the Cybathlon, we have the opportunity to continue our work together with the cyber legs consortium and new partners like (unknown term) from Iceland and we were able to do this because we were part of the Horizon 2020 project and we could take the technology we developed in the cyber legs project and take it further to increase our device and make technology of our advice and rack our device more improved. It was Nick ) was more robust, reliable and were able to be testing for a longer time with more acceptance. We made this based on the learnings we had from the cyber son -- Cybathlon and recovered as much as possible in the redesign to make them acceptable in size but we did not have the resources yet to include redesign in terms of size and weight. To reduce the size and weight. We organised an experiment of eight subjects which was including a short training session and a number of tasks every day tasks like stair climbing, tight up and go task where the users have to start from a seated position, stand up, walk on a catwalk, go back and sit down again. Sit and stand tests and two minutes task to invest -- Investigated cognitive skills using prosthesis. One thing we were able to show is that all subjects , they were all walking with mechanical needs of their own and we enable them to perform stair climbing which were not able to do with their own thesis . The user group used for this protocol were not young , sporty subjects but elderly subjects. For all other tasks that we tested, the results were pretty inconclusive and varying from neutral to slightly negative but in general, not showing any real big benefit for our device which is unfortunate and a trend we still see. We did allow for stepmother step stair climbing . Scientists like to see what percentage your performance increases with the one device versus another and this is very hard to do in this case , it is another way of performing a task. These results are still under consideration for publication and disability and rehabilitation. After several years of prostatic investigation, we faced a problem that you cannot improve the efficacy of our device because we had a disadvantage of increased size and weight compared to commercial devices. The focus for the next prototype we made was to try to address these problems of size and weight based on our past results. So one thing we did , the dice (Reads) The final device we made record the CYBERLEGs X-Leg to get away from the incremental names , of the bet , the prosthesis , it fits for a device that should be closer to be market ready. Rather than developing an integrated study and prestigious, the aim of exploring synergies between the knee and ankle joints, we decided to simplify and separated the ankle and knee prosthesis whilst in the end ankle can be used in both drinks, a person with (inaudible) might have a larger benefit from a lighter and not powered ankle in combination with a powered knee . That is the hypothesis we have now. We advanced the prosthesis and technical aspects , solving many of the problems we encountered during experiments . We increased the range of motion up to 120° for the knee and reduced birth module so we can allow more people to test our devices. Mainly, we reduced the rate , the weight from 3.8 kg for two modules combined compared to over 5 kg or the previous iteration. Also, this weight includes everything including the combined knee and ankle prosthesis. Power and control electrics are able to perform high-level control and also interface with the other modules developed in CYBERLEGs X-Leg . It is a control power we need to have with the prosthesis. The modules , as before, the use pressure sensitive insoles and I have to say these electronics are that our own merit but by desert -- Were developed at -- Elsewhere. We managed to improve our device a lot and it can help for user acceptance. We hope that these advances will allow us to really investigate the advantages of our actuators and activation methods. We were ready to start larger scale experiments at the beginning of the year, January and February but that did not quite work out the way we had planned unfortunately. We have performed a number of initial experiments but the past year has not been very kind to people doing trials involving people . We are currently still working on that. Also, for that reason, the participation for the Cybathlon unfortunately was very difficult for us given the small team we have to prepare for this event. We hope to be able to present more results of our new devices soon. With that, I would like to thank you for your attention and I will be happy to answer any questions you have regarding my presentation. Give very much. Let's welcome Joost joining us live from Belgium. Welcome. Thank you very much , it was very nice to see the evolution of your research prototypes and the impact that the Cybathlon had on that project and process. Maybe let me start with a quick technical question. What is the uniqueness in the design of the cyber leg concept? Can you tell us more about it? So we actually developed several concepts already that we tested within the cyber legs so in the first prototypes, we went for the synergies between the knee and ankle and if you look at a human walking, the knee is more breaking device or breaking a joint so you anticipate energy in the knee when you walk but the ankle is an energy producing parts so you need to be propelled forward. What we tried in the beginning is to exploit that synergy but of course, with that comes extra complexity and also limits the use of the prosthesis to walk because you have less of these synergies . And I think this is good for research prototypes but if you want to go more and like we did later when you go to more higher TRL's, we can put them into these ideas and we investigated them with our prototypes , but that is a later prototype . We were looking at ways to control our device and things like that.  I think I saw in one the presence of us bring element?  Yes, this is also the case in the last designs to explore (inaudible) as much as possible to reduce the required motor power for several tasks. We saw yesterday in the exoskeleton session this can have an effect on dealing with uneven ground. Do you see the same benefit in your set design for the leg prosthesis?  Yes, for sure. I think compared to having a direct drive for solid control of your ankle joint for example is not desired in many cases. So I think being (inaudible) allows you to have more natural behaviour of your prosthesis without really having to control it in a certain mood. As we get yer, absolutely. -- Certain mode.  Is it possible can control joints of each leg with one controller? Or investigate energy and for cinching one (inaudible) WISE  It is for sure possible. We have one electronic, one battery , to control both joints, all included in the prosthesis. How well that works altogether we still have to investigate. In first instance we went to looking at the knee separate with the passive angle and looking at the ankle separate, which is also possible. And allows you to exclude the effect of one or the other as we investigate the ankle behaviour by itself and the need behaviour by itself. That is, for sure, possible. For the combination of both joints we still have to go into more detail to see what benefits we can get there.  Thank you for the answer. Name questions from the audience so I will ask another one myself. -- Name questions. I found it interesting (inaudible) evaluate the benefits of the CYBERLEGs plus plus in the task you use. It illustrates the challenges of assistive technology as we discussed yesterday. But what was feedback from participants? Did you have such data? What did they report during interviews for example? Yes, we also included questionnaires. Also, there was a bit mixed results. I think, in general, the amputees were very positive about doing this deck and climbing. It was a sensation some of them had not had for 20 or 30 years. -- Doing stair climbing. But in general I think we need to look at more things , like training is something that comes back in literature a lot. We need to train more. But it is not so e.g. to have subject coming for months and do extensive training. -- Not so easy. I think most of them were positive about our device despite the high weight. For me it is promising when we look at testing a new device.  K. Let's close the session here. Thank you very much for all your answers , and thank you as well for joining us today.  Thanks for having me. Goodbye. OK, it is now time to close the leg prosthesis block. Before we moved to our last short talk of the symposium would like to show a short video to introduce the new centre (inaudible) ETH Zurich. Enjoy. In automatic competence in rehabilitation engineering and science. I am the executive director of RES C. Please take a few moments on our vision and mission. Our mission is to make the environment and society more inclusive in general. We (inaudible) approach towards comprehensive management of physical impairments. Here is the background. Persons living with physical disabilities face challenges and obstacles in their everyday life and can lose their autonomy. This affects their quality-of-life, prevent them from fully participating in, and contributing to, Société, and creates socio-economic burden. Currently, people with disabilities are treated by medical staff are specific periods and I lost track of without the clear management of further treatment. This means the current approach to rehabilitation is highly fragmented in time and in space. Furthermore, exceptions for novel treatments and technologies is (inaudible) high financial burdens associated with fragmentation of rehabilitation process his profession's (inaudible) treatment. The aim of RES C is to transform from the (inaudible) fragmented system to a long-term solution offering personalised prevention programs early as possible , and continuous treatments and assistance in the home and/or work environments. Our approach is an interdisciplinary network of experts. In collaboration with clinical partners, healthcare and disability organisations, industry and governmental institutes, we promote the development of (inaudible) in human centric solutions for rehabilitation. We establish a network foster dialogue and provides (inaudible) for partners in the industry and while Max factor for public and most importantly people living with disabilities. Specifically, we foster interdisciplinary research and education to advance the field of rehabilitation. And we (inaudible) innovations for our partners. This will improve quality-of-life persons living with a disability and contribute to inclusive society for all. Are you a person living with disability, industry or service provider, a researcher, or just interested in shaping the really big of tomorrow making a society more inclusive? Please contact whether it was any kind of request. -- Please contact us with any kind of request. We hope to talk to you soon.  Thank you very much for this introduction and the offer to connect in exchange. -- And exchange. We now come to the last tour, topic of importance to the field . ethical design. By my shallow Janka. He is a senior researcher at the ETH Zurich. His supple investigator in (inaudible) elderly care in Switzerland. His research focuses on (inaudible) technology assessment and robot ethics. Marcello is also a member of the steering group on the organisation for economic co-operation and development. Thank you for being here. We look forward to your talk.  Before I start, I would like to thank Roger, Olivier and other people who made it possible to have the CYBATHLON symposium this year despite the difficulties caused by the COVID pandemic. My talk covers rehabilitation engineering and (inaudible). As such it connects to other talks today. As recently stated and promoted by the European group on ethics and science in new technologies. The major approach to promote this view of health and well-being into assistive technology is ethical design. Ethical design is basically a collaborative approach between engineers and other researchers aimed at incorporating ethical considerations such as safety, well-being, autonomy early on in the design of element of new technologies in order to make them ethical by design. It involves the promotion of safety and well-being through adequate valuation and user centred design and the consideration of ethical and social well-being such as privacy, autonomy and so on. It is important to highlight that rehabilitation and assistive robotic devices are ethical classes of ecological innovation as they are presently designed to empower people with disabilities and enhance safety, well-being and autonomy but ethical motivation may not always result automatically in the systematic incorporation of ethical consideration into technology design. When talking about ethical design at the symposium four years ago, I was assuring how the engineering community was going through a shift from reactive to proactive ethics. As evaluation of existing technology with no active participation of social scientists in product design and development, referral to user centred design at the moment and it was basically a general view of ethics as the evaluate of technology and in contrast, the community was moving towards a proactive ethics approach which was based on the accepting operation of ethical considerations to technology design and assessment by a user centred approach and active collaboration between clinicians, engineers and other scientists . It was based on a general view of Essex as a facilitator and not a validate of technology. However, in recent years, research has shown that involvement may not have enough for achieving user empowerment and we need to involve users in the right way. Collaboration may not be enough if the collaboration is not achieved in the right way. To give you a few examples, this is starting with the spinal cord injury participants involved in powered X studies perceive that outcome measures were mostly focused on assisting improvement while neglecting the quality of-life of the target population. A recent study showed that while technical aspects of interfaces such as usability of his ability are used extensively, comparatively, there is little in-depth research on this self image and self experience of the BCI user. Sometimes gaps an implementation show measures and especially when it comes to measures for measuring and validating well-being . Systematic reviews show that more than 60% of disability studies on rehabilitation are reported to be using non- (inaudible) measures so what you can see is that there are gaps that might emerge in the implementation process or in the translation process that goes from designing in labs to the actual clinical use of assistive technologies. In order to overcome these gaps, I would argue that we have to embrace a second part of the shift which moves from ethics from theory to practice because ethical design cannot be achieved solely through a focus on design but it requires a practice and an active engagement with the implementation process. My major point of this presentation is putting into practice and it can be achieved in three steps. One step is improving the validity of assessment measures. And moving beyond custom-made measures and towards standardisation. The second step is having an increase focus on the patient quality-of-life, lived experience, satisfaction and finally, we need to align ethical principles with codes of conduct and standards and regulations. I will provide you with a few positive examples in each of these three domains in the community. Regarding improving validity and reliability of measures, going beyond custom-made measures and towards standardisation, a proposal is coming from the ASTM International which provides tools that help assess and ultimately improve the usability of exoskeleton suits and is doing so by achieving greater harmonisation between assessment measures in this field. Another positive step in this direction is taken earlier this year by the IEEE which is the standard roadmap for bread machine interfacing which provides the first of its kind overview of existing and developing standards for computer interfaces internationally. Regarding having an increased focus on the patient , there is no international effort towards standardisation and this is much-needed because some studies have shown that a positive potential in developing qualitative measures for experiential assessment. This is a study conducted by (inaudible) and it showed quality feedback by user experience questionnaire and it could improve visibility for exoskeleton use. Another study showed that qualitative interview methods and group theory bridges have shown potential to assess the user experience among BCR users with disability. They also developed an interview protocol involving interactive demos and narrative interviews showing consistency across elderly users of several classes of assistive technologies is a viable tool to assess user experience and sense of safety and well-being. In terms of the third step, aligning ethical principles, codes of conduct and regulation, I wanted to highlight the importance that in order to insert practical guidance, ethical principles should not remain just obstruct but they must be translated into actual regulation.' Example is how the (inaudible) which is one of the four -- By the rehabilitation engineers and it states in its first statement that the welfare should be held paramount and it is also been set into actual regulation suggesting the UK care act from 2014 which puts emphasis on well-being. It's important that this alignment of principles and codes of conduct and regulation can achieve what they called the ethical governance and this is exactly what can be achieved by harmonising actual regulation with ethical principles and standards. Another positive example that I want to show is how the ethical principles of (inaudible) which translates into the field of new technologies and especially with interfaces into the notions of nearer safety and the security . It's been converted into standards and safety requirements for a person and into actual safety legislation . In the European and United States. I want to conclude by highlighting how these forces of harmonising ethics with the standards and regulation is happening but only at the level of individual ethical principles but at the level of the entire frameworks. A positive example is the OECD recommendation aren't responsible technology which sets the international standards on the governance of interfaces and other technologies. As a member of the OECD, I have the privilege to contribute to the drafting of this argument and a lot of the property rework we did was precisely aligning this governance documents with existing work on standardisation. Such as the privately measured efforts by standards and also with existing ethical frameworks such as those developed within the ethic society and also several groups of researchers worldwide. This is just to show how positive the steps have been taken to the development of more practice oriented ethical approach to technology design and assessment and with this, I would like to thank you for your attention.  We now welcome Marcello , thank you so much for your talk and being with us today. And thank you for reminding us the work we do is ethical.  Absolute.  Where you think we should start when we tried to consider ethical implications more? I'm talking especially from the point of view of engineers. Is it outcome measures we should focus on? Where can we make the biggest impact?  Very good question. Not easy to say there is a one size fits all approach that can fix the problems. I would argue that , since our goal is an extended community is empowering end-users, we should probably start from the needs and wishes of end users. Because there is nothing more ethical than incorporating those end users and wishes to actual product design. Because this can create a sort of positive snowball effect. Once we have integrated actually the wishes and needs of end-users we are in a better position to empower them, and improve their health outcomes. I would say focus on outcomes is more a consequence of the right focus on needs assessment and integration.  Thank you. A related question is maybe we are used to, in a field, doing trials with a large number of subjects. If we present subjective feedback from individuals, we often get the comment that you need more participants in your study to say nothing. Do you think, as a field, we need to evolve how we run these studies, what we accept as relevant steps forward? In the sense of maybe publishing more signal case studies?  Yeah. This is a very good question. It's easy from the perspective of the (unknown term) to say we should involve end-users more extensively. But when I refer to a practice oriented approach I am also very mindful that this kind of studies are time-consuming for companies who operate in the private market, and can also be more costly. So we have to be aware of these challenges. But I think we should find creative ways to overcome these challenges. As it was said in publishing more single case studies could be one approach. I would argue that expediting in certain circumstances the process that leads to ethic approval for involving more patients could facilitate their participation. Then I think public understanding is very important. Because if we do the right work on raising awareness and providing good public understanding of the technologies we develop . and (unknown term) is a perfect platform for this, doing it internationally. We build trust among end-users. And if we build end-users' trust, we have much better chance of involving them in the right way. So it is a sort of virtual circle -- virtuous circle.  What is your take on the ethical Kunal John that involving end-users in unsafe robotic prototypes might be more -- might bear more and not less risks? -- Ethical conundrum. This is based on the assumption that if we include end-users , there are inherent risks associated. (Inaudible) were one step ahead in minimising risks because we know whether end-users come from, and in which direction our research project can take. But this is something we should definitely take into consideration, especially when conducting research with vulnerable groups, such as people with (inaudible) condition , senior citizens or children. So this is a very important conundrum. I don't think it's unsurmountable. But this is something important to consider.  You. What could result if there were no ethical standards?  That's a sort of moral psychology question! What would people do if there were no standards at all? There is an optimistic answer to this. Which we would have super effective (inaudible). So everyone would be able to self collate and develop products in the most ethnically aligned way. Then the pessimistic answer . which it would just be hell! I tend to be realistic , so probably neither optimistic or possibly sick. More tending towards optimism. -- Pessimistic. I would say a large majority of people in the robotics community are well intentioned want to develop products that (inaudible). Even more in the neural rehabilitation and assistive technology community. Because as I mentioned these technologies are inherently ethical and designed to empower people and enhance their safety. So I would think, even without standards, most things would go the right way. But this is not enough, as I guess. We want to make sure as many things as possible go the right way.  Wonderful. I guess a good act of optimism and regulations will be the way forward. Thank you so much for being with us. And thanks for your talk.  You.  Right, with this, the CYBATHLON symposium 2020 is coming to an end. I would like to invite Olivier here to join me so we can say a few words together. Let's see if we can fit on the screen and maintain.  Nice to be next year. Thanks, Roger. We had an amazing event and I was extremely impressed with all we had in these two ghettos. I would take home the message of our first keynote speaker which was (inaudible) highlighted in the testimonials of the importance of including users and their needs in (inaudible) for assistive technology. I was really impressed by to drive and motivation of all the (inaudible) pilots (inaudible) disability. I was also touched by the testimonials of marking Maria, and how tightly they're integrated in the teams involved in developing. I feel so more and stronger use involvement in a toxin that the first some posing for years ago. -- First PROF SIMON COLLINSON: (inaudible) post importantly, I'm happy the virtual format worked well and allowed us to reach this level and interaction quality of talks and posters. Only possible thanks to efforts of many people in the backroom. From the initial thought of holding a physical symposium in Zurich to the implantation of this virtual event, which resulted in many unexpected challenges. Let's just say that we and everyone worked with us went asleep learn Kavanagh lastly was.  That Simon have to thank everyone? (Inaudible) I want to thank a no name macro name for their support. Helped us with many last-minute adjustments. And our lab down here in professional TV studio (inaudible) we are some kind of TV presenters.  Indeed. Big thank you to all. Also want to thank the colleagues that made this event highly accessible, namely international sign language interpreters who signed the entire event live next to us and also closed captioning service. We finally like to extend huge thank you taller speakers and poster participants who show tremendous flexibility in patients as we figured out how to run this virtual event. For this we also had great support from all lab members who are would also like to thank from the bottom of my heart. Finally would like to thank the Stavros Niarchos Foundation again for their supporters with trans-what mac to this format. We look forward to the CYBATHLON competition in the new global format and wish the participating teams like in the preparations and at the races. Thank you, everyone, and see you at the macro side bath and global edition in November.  They go! -- There you go. (Video plays) 