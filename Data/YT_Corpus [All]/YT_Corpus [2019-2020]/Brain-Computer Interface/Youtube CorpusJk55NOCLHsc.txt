 welcome everyone this is christopher lee we're going to be starting in just a minute okay i have one o'clock on the dot hello and welcome everyone this is rachel paul with iwap and we are excited to have you joining us today for our noro abilities webinar series kickoff before we start today's program just a few housekeeping items to go over one all attendee microphones are muted to prevent any background noise or disruptions today's webinar will be recorded and made available on youtube and we'll send out information how you can access that closed captioning is being provided today by ai media you can select the closed captioning icon on the bottom menu of your screen and we do have a question and answer box available we encourage you to post your questions there throughout today's webinar and we will get to as many as time permits today and any technical questions or other comments can be left in the chat and we will try to address those issues as soon as possible so i'm happy to turn the program over to christopher lee to get us started good morning good afternoon everyone this is christopher lee we have a great program for you today from lab to the real world restoring movement control and the feeling of artificial limbs and brain implants it is brought to you by the patrick mcgovern foundation in cam which is the national center for adaptive no technologies and iwap which is the international association for professional accessibility professionals which is a division of the global initiative for inclusive ict again as i mentioned earlier my name is christophe lee we have a packed agenda today um i am the managing director of iwap i'm also the chief learning officer of g3 ict i'd like to bring um next patrick mcgovern who's the chair of the board of trustees of the patrick j mcgovern foundation so welcome patrick thank you christopher good morning good afternoon and good evening depending on where you are great to see all of you i'm patrick mcgovern i'm delighted to be here representing the patrick j mcgovern foundation i'd like to welcome the neuro abilities community tuning in from around the world i want to begin by recognizing the terrific g3 ict team behind the neuro abilities program especially excel lebrois who spent many years working closely with my father pat mcgovern as both president and ceo of idg communications in idc today xl is a champion of the rights of persons with disabilities in the digital age axel thank you for your leadership and collaboration the foundation is honored to be part of this initiative to create a more equitable inclusive and accessible world on behalf of all the trustees i want to thank the community gathered here today for what promises to be a fascinating conversation our foundation carries on the legacy of my father who had a lifelong fascination with the human brain he established one of the world's leading neuroscience research institutes at mit the mcgovern institute for brain research and he was also years ahead of his time in recognizing that technology can be used for the betterment of humanity with his trademark optimism he believed technology could democratize information accelerate human achievement and solve our greatest challenges neuro abilities uniquely brings together this cutting edge of neuroscience and technology for the betterment of humanity it is nothing short of extraordinary to consider the impact this technology can have on future generations my father was also a master communicator and convener who traveled the world bringing diverse groups of people together he had a deep commitment for sharing knowledge insights and ideas for public good in that spirit i believe he would be thrilled to see neuro abilities is here creating a space for advocates neuroscientists and persons with disabilities to come together to promote research and innovation and prioritize the perspective of those who use these technologies at the patrick j mcgovern foundation we are carrying the torch of my father's optimism and one of the most promising frontiers of tech for good is the assistive technology that improves lives and enhances human potential i'm really excited for today's opportunity to learn from the perspective of a neuroscientist and a user with neurotechnology stands today and the promise it holds for the future thank you again for for joining us today and i'm going to pass the virtual mic to uh christopher all right thank you patrick i sure appreciate it and we uh appreciate your support um so the next um speaker up that will be doing some introduction is a colleague and friend of mine theresa bond she's a research scientist and um she is with incam and she is the chair of the nobility advisory council so welcome theresa and take it away thank you christopher and um and thanks to the iap and to the g3 ict and to the mcgovern foundation all of whom are making this webinar and neuroabilities possible it's really a pleasure to work with the group and it's really very inspiring to hear um that it's carrying on the legacy of the mcgovern foundation which has such prominence in the neuroscience community um i it's my great pleasure to introduce um my uh my not so uh uh old friends but people who uh people um who i've known for some time jennifer collinger who is a doctor of biomedical engineering she received her doctorate from the university of pittsburgh and she is a soon to be an associate professor in the department of rehabilitation neuro engineering laboratory i'm sorry in the department of rehab medicine and jennifer um is a very prolific researcher who has been the first author or co-author on over 51 peer-reviewed papers and she has been a pioneer in the area of uh restoration of movement to people with um severe neuromuscular disorders and spinal cord injury she uh she is a seriously deserving of uh her new position as an associate professor and i can tell you that she has been a shining light in this translational field since she was a graduate student she took enormous initiative showed enormous initiative talent perseverance and creativity from the very first moment she entered the field and my own personal experience with jennifer um besides being sharing a position on the board of the bci society where she nurtures an entire community of bci researchers um was when in 20 i think it was 2013 uh she was the unanimous uh an outstanding runaway winner of a poster contest uh that i coordinated for the bci society meeting so she continues in this vein she's a and she has shown remarkable remarkable sensitivity to all of the people she works with one of them being nathan nathan copeland is a uh is a bci pioneer he will join us to discuss his experiences as a a person who has worked with jennifer for almost six years jennifer said six years in may um he has uh is one of the uh only individuals in the world who has been implanted with microelectrodes to enable the movement of a robotic arm and uh which i understand he'd like to use to play video games um he's always been interested in engineering but he has really become a partner in this research with jennifer and her group and um working uh sometimes up to 12 hours a week uh as a colleague so um with that um i'm terribly interested in in what these people have to say um and i i'm very excited to uh to welcome them well thank you teresa for that kind introduction and thank you to teresa and christopher for inviting us here to talk about our study and experiences i'm obviously really excited to be giving this presentation in collaboration with nathan because i think that's you know really a unique perspective to share with the rest of this field is what is it like to be a participant in this study so i'm going to kick us off with just a little bit of background about our project and some of the scientific goals of it and then i'll turn it over to nathan before the question and answer session so that he can talk about some of his favorite memories from the study and things that you know he would like to share so um so our research group is interested in using brain computer interface technology to try to restore upper limb function and many of you may be familiar with cam anderson's study from 2004 where she asked people with spinal cord injury and specifically quadriplegia so impairment of the arms and legs which function if restored would have the most impact on your quality of life and you know far and away it was really restoration of arm and hand function that was a top priority for this population and so we're trying to use brain computer interfaces or bcis as i might refer to them to tap into brain activity that still remains intact after spinal cord injury to bridge that injured spinal cord and restore movement and there are a lot of ways to record that brain activity so a lot of you are probably familiar with eeg so electrodes that sit on the scalp and those can record from large areas of the brain at the same time to give some information about movement and then there are also implanted technologies i'm showing here in this top right picture an electrochordatography or ecog grid that can lay on the surface of the brain to again record activity from you know now smaller areas of the brain the technology that we use in our lab is an intracortical microelectric array and you can see a picture of one here on the bottom right so it's a very small electrode array that has about a hundred electrodes on it that can record from single neurons in the brain and as i mentioned um in the title we're trying to develop a bidirectional bci and so what that means is that we have these microelectrode arrays that record activity from motor cortex shown here in blue we can decode those signals to try to figure out what the participant is trying to to do in terms of their movement and goal and then at the same time you know we typically control a robotic arm at the same time we can record from sensors in their robotic arm translate that information into stimulation patterns that we can then play back through electrodes that are implanted into somatosensory cortex so if we zoom in at you know what information are we getting from these microelectrode arrays you can see that there are two electrode arrays and planet and motor cortex there if we zoom in on one of those what each of these black boxes is showing is a recording from a single channel on that electrode array and if you zoom in at one of those channels you can actually see if we align these threshold crossings or deviations and voltage that we're getting activity from here two different units so each of these waveforms is an action potential and we can look at the way that these action potentials are occurring and the rate at which they're occurring and relate that to movement parameters so that we can give the participants control of the robotic arm i thought i'd tell you a little bit about how we calibrate the bci to try to figure out that relationship because we really want to try to pick up on natural motor commands as opposed to learning to generate commands that can be used for control so here's an example showing screenshots from a calibration paradigm that occurs in a virtual environment and so what we do initially is have the computer control the robotic arm to you know first reach to a target which is this red object in the workspace then we give an audio cue to grasp with a particular hand shape and then there's usually a carry phase so moving that object in space as you would from any functional tasks and then a queue to release and so so throughout this calibration the participant is thinking about moving that virtual arm towards the target to execute those actions we can record their brain activity and examine the firing rates of all of the neurons that we're recording from and we can also record the kinematics of the robotic arm and then essentially we fit a regression model to figure out that relationship and that's what we use as the basis for control now what's been interesting and shown by you know many research groups over the years is that this attempted or imagined movement generates activity that is very similar to what is seen during overt or actual reaching movements has been as has been measured in animals for example and so what that means is that this control is fairly intuitive and natural and that participants typically report thinking about you know go grasp that object as opposed to thinking about extrinsic commands such as move to the right you know move a little bit forward and so when we're recording from populations of neurons about 200 channels in motor cortex we've shown that we can enable up to 10 dimensional bci control which is three-dimensional endpoint position three-dimensional orientation of the hand in space and then up to four dimensions of hand shape for most of the work that we do we typically control about five to seven dimensions so moving the hand around in space and being able to open and close the hand let me show you an example of what performance looks like when this is nathan has just visual feedback so here are his tasks he's performing as part of the action research arm test it's um commonly used after stroke and the goal is to pick up these objects and move them as fast as you can towards the platform and a time of less than five seconds is considered you know able-bodied time and so he's getting very close to that even with only visual feedback on a single day and so you can see again that the control is very natural and fluid as he moves through those different movements so i told you we were developing a bidirectional bci and yet i showed you that the performance was fairly good with only vision so why do we need some amount of sensation or sensory feedback at all well for very dexterous and complex tasks such as buttoning a button tying your shoes or brushing your teeth you know it's pretty clear that you need sensory feedback to know how to manipulate those objects to perform these fine movements but you know we're not quite there yet in terms of bci control or robotics or fps to reanimate those functions so even for simpler things like trying to hold a cup level without spilling it and without squeezing it too hard or passing an object from one person to another or holding a fragile object these are tasks that you know naturally rely on sensory cues in order to maintain the appropriate grasp force or to you know figure out the timing of when you need to to release an object so that the other person has a hold of it so let me tell you just a little bit about what it actually feels like and what types of sensations are generated when we stimulate in somatosensory cortex and i know that nathan's going to talk about this a little bit more so as i walk you through this figure on the left you can see a schematic of the hand and what we do about once a month is stimulate with set parameters here we're using 60 microamps at 100 hertz stimulation for about one second and we ask uh nathan to report you know if he feels something and if he does where does he feel it and he can draw onto the hand the area of um that he's feeling and so what you see on the left is sort of a cumulative summary of areas of the hand that we've been able to generate focal sensations and they span the index through through little finger typically at the base of the finger and if you move over to the middle of the figure i'm showing you a schematic of the arrays as they are implanted in the brain so the red line there is what's known as the central sulcus and to the right of it would be sensory cortex and so you can see that one array on top is more medial towards the midline of the brain and the bottom one is more lateral towards you know out towards the ear and so you can see is that the when we stimulate through these electrodes which each square is an electrode we tend to see clustering based on the color so on the medial array we're generating sensations from the little finger and then down into the ring and middle finger and then on the lateral array we pretty much exclusively generate sensations on the index finger and this actually lines up well with what is known about the organization of somatosensory cortex as shown on the right figure where we would expect to see that organization from thumb most laterally away from midline towards little finger more medially and so what this means is that even after chronic spinal cord injury this organization is still preserved we can tap into this and stimulate and generate sensations that almost immediately feel like they're coming from a particular part of the hand and this has been very reliable over a period of years um so these sensations can vary can feel like pressure or tapping or tingling that might depend on the way that we stimulate also if we turn the amplitude up that can change the intensity of that stimulation so the last thing i'll talk about is just what happens when we put these two things together the motor control and the sensory feedback and so this is obviously a very collaborative project it was led by graduate student charlene flusher and john downey along with our engineer jeff weiss and rob gonz who's leading the sensory part of our study and so this schematic just shows you you know the overall experimental setup where again we're recording for motor cortex with those arrays in blue using that to control the robotic arm in five-dimensional space and then taking sensor data from the arm to turn that into uh sensory feedback in the through stimulation of electrodes and somatosensory cortex and so the way that we did that was just record from the joint torques from each of the fingers and then stimulate on an electrode that corresponded to generating a sensation on that finger with larger amplitude for larger joint torques and i think that the best way to convey you know the impact that this had on performance is really just to show a video um first where here i'm showing you the fastest trial with sensory feedback on the left and without sensory feedback on the right from that task that i showed you earlier the action research arm test or the air at and so consistently trials were faster with sensory feedback and what you see on the right without sensory feedback is that he spends much more time kind of positioning the hand around the object before he feels confident in initiating that grasp and we saw this for you know objects of many different sizes and shapes consistently across multiple days and so i'll leave you with one data slide here so what i'm showing you here is just a histogram of the amount of time that it took him to complete the trials for that task that i just showed you so picking up there's eight different objects of different sizes and shapes and you completed those trials multiple times so across the x-axis on the bottom is time so how many how many seconds did it take to complete that task and on the y-axis is the number of trials that were completed in that time so shifting this to the left would be faster times so you can see here without sensory feedback his median completion time was about 20 seconds 21 seconds and then when we provided icms sensory feedback that median completion time was really cut in half down to 10 seconds and so importantly if you pay attention down to this left left-hand side of the histogram 15 of these trials were completed in less than five seconds and i mentioned earlier that on that task completing a trial in less than five seconds is considered an able-bodied performance time and that was something that we didn't achieve without sensory feedback so you know even though the performance on its face was fairly good with visual feedback even for a task where he had full vision of the task and was already performing at a high level sensory feedback was still able to make an immediate and significant improvement so i hope that i've shown you that a bi-directional bci can enable high degree of freedom robotic arm control that allows our participants to perform functional tasks that we can generate finger specific tactile percepts in somebody with chronic spinal cord injury and that putting those two things together improves the ability to perform tasks involving transport of objects when the sensory feedback is provided so there's a very large team of people that are working on this project you know without whom this wouldn't be successful including our funding from nih and darpa but most importantly we really couldn't do this without our study participants who dedicate you know a lot of time and undergo surgery to allow us to do these studies and so it's really my great honor to turn the rest of this presentation over to nathan so that you can hear about his experiences and then you know please feel free to direct your questions to him at the q a since this is such a unique opportunity okay nathan hello everybody my name is nathan copeland and in 2004 i was in a car accident that left me a c5 quadriplegic when i was in rehab in pittsburgh they asked me if i wanted to be on a research registry they said anytime there was someone looking for uh participants that um met certain criteria they would look at the registry and you know give me a call and then fast forward to 2014 i got a call from the team at the university of pittsburgh about the bci research and uh they asked if that was something i'd be interested in doing and i thought it was super cool and i said yes and you know that started this uh you know going on six year adventure so one of the the first uh tasks that we ended up doing with the linking the sensation to the robot was this finger detection task where rob here is pushing on a finger the sensor for that finger is on the computer to stimulate on an electrode that we had already decided or figured out felt like that certain finger and they blindfolded me and this is the first time that we did this task and it worked uh i'd say remarkably well um even when rob tries to trick me here and push two fingers at once i still figuring it out even though i was kind of like feeling like did you really just do that or am i kind of imagining things um [Music] so next is the million dollar question that i've been asked a million times and sometimes it's still kind of hard to explain uh what does it feel like well uh first sensations are completely electro dependent so you know you saw that illustration with the layout of which electrode feels like it generates a sensation on which finger and then depending on uh what kind of parameters they stimulate at uh that sensation can change a lot so 100 hertz is the you know the pretty standard uh frequency that they stimulate at and that can generate sensations uh like pressure and uh like a tingle there's some warmth uh you can see what else is in there you know a lot of index uh knuckle finger or knuckle sensations but then when you change that to like 20 hertz and then i start getting like tapping sensations um start getting weird stuff that i somehow got described as sparkly which is you know uh kind of thought of it like a firework where it's in like one area but it's kind of uh moving around uh kinda it's it's one of those things that sometimes ask me you know what it feels like and i say i don't know why don't you get some uh brain implants and and figure it out so in 2006 they came to me one day and asked if i wanted to meet the president and i said i guess like why why would i say no to that but he was in pittsburgh for the white house frontiers conference and so i got to meet president obama and shake his hand with the robot arm and give him a fist bump and here's a video of that so for for years this was always what i would uh describe as the the best thing i'd ever gotten to do through this study but then last spring i got to fulfill my life stream of going to japan uh there was uh uh yeah a neuroscience conference in toyama that i got to present a poster at and um i did a presentation at osaka university and ko university and uh a few other places and i got to have a dream vacation that i thought you know after my accident that i would uh never get to go there um it's just uh something i wanted to do since i was a little kid and then uh speaking of things i always wanted to do when the study first started they always ask me you know what kind of goals i wanted to do um you know what i would want to do with the implants and i always said i want to play final fantasy 14 with them and then you know it only took five years but i did get to play for a while i wasn't that good but it was still fun i enjoy playing games when i can also my my implant day is um may 4th which if you're a nerd you notice star wars day and the lab is full of nerds so this is how we celebrated one day um i still don't even know whose lightsabers those were but i i ended up coming in that day and they were on the table and i said yeah why wouldn't i want to uh have a lightsaber battle um one of the funny things about this is that's actually a luke arm by deca so yeah luke skywalker lightsaber battle so that was pretty fun um speaking of the luke arm that's the the second robot arm i've gotten to use and this is the hardest hardest object in the arat test and this is the first time i've ever completed it usually that ends in a bunch of marbles going all over the place and someone on their hands and knees on the floor counting trying to pick them all up the third and current robot arm that i'm using right now is a kuka um lbr assembly robot with right hand robotics reflex tactile gripper um this is by far the favorite robot arm that i've got to control um with bci it is way faster than the others um i really like that it's not anatomical um [Music] it allows for things like um as you watch this video the the hand can stay parallel to the table which lets me [Music] work better in the workspace if it's if i was doing this with the anatomical arm it's shoulder mounted and if it moves up then the um the hand has to move up and be pointed uh upwards because that's how shoulders work and so that task was just lift up the object and put it on the other side of the table without hitting the middle that was as many times i can do it in two minutes and that was my current record of 25 then another day another thing that wouldn't be possible with uh one of the other robotic arms was weird just messing around and seeing if i could put this block on this piece of pipe that is on a spring um that's just stuff that was for another task and we were just messing around and so speaking of other things i've controlled i've controlled a a wham arm by barrett i've used a glory high exoskeleton glove that i used to pick up a taco and eat it and then in the bottom left there is actually a portable system it's a it's a tablet and a digital hub that uses uh different cables and the patient cables which are the big big gray ones these are just like hdmi cables but it can do basic cursor tasks they can't do any of the simulation stuff but it is portable um i actually have it at my house now since all this pandemic stuff started i actually got to take it home back in march and i've been using it to play a bunch of games because that's what i want to do with it so other things i've done here's a video of me playing sonic the hedgehog uh but i also like to just use a drawing program that's my favorite meal i talk about obviously it's a cheesy gordita crunch and alcohol blast you gotta have the fire sauce uh i also have a youtube channel it's called bci can do better that's uh new spaces and on the apple playlist called my cyborg adventure which is just a collection of um study related videos news videos that kind of stuff so i also always get asked why why do it um you know this is a quote right out of the 23 page consent form you will not receive any direct benefit from taking part in this research while it's true that i'm not going to get to keep my implants forever i'm not gonna get a robot arm to take home and and all this i think um i've actually received great benefit from taking part in this research the thing i think i've benefited the most is i've grown as a person i never would have been able to do these kind of um speaking engagements in front of rooms of you know more than 100 people um before that's something i kind of just have grown into enjoying uh really like hearing people say they found inspiration or value and hearing my experiences but more importantly why i decided to do it was uh to push the science forward i knew the participants they were looking for is very specific criteria and i met that criteria and somebody had to do it so how could i say no if i i could do it so i just i wanted i want to do whatever i can to make sure that people in situations like mine in the future kind of bypass that that realization that hits all of us to have a uh you know catastrophic injury where we realize our life will never be the same and we kind of go through this despair of you know feeling like we're never gonna um get to do the things we enjoy anymore or contribute to society or you know that kind of thing so i'm hoping that the science can get pushed forward uh thanks to whatever i can do um through this study and maybe one day it really ends up being like star wars where you know luke got his hand chopped off and the next day he had a robotic one that you know could feel a pin prick and worked just like his uh you know the hand he had before and was good enough to save the universe or or whatever so um yeah thank you guys for you know listening to what i have to say um that's me in japan at a park with lots of deer okay so yeah i guess now it's the time for questions thank you nathan thank you jennifer we appreciate uh incredible work incredible story um rachel let's open it up for questions i know we have a few in the q a as well as the chat and yes this is rachel and we'll get started because we do have quite a few so the first question might be more directed towards jennifer asking is nathan using only his somatosensory i'm saying that correct cortex or is he simultaneously using his motor cortex to move feel so for almost all of our experiments we decode the movement signal from motor cortex and then stimulate in somatosensory cortex for the sensory feedback okay our next question congratulations nathan and the team can you speak about the muscular capacity of the robotic arm like what weights can the arm lift and does functionality cover the whole arm or part of it or just the hands yeah um so the the kuka robot the one that nathan likes it's the strongest i would say i think it can hold 14 kilograms um so weight is not really a concern and you know we don't even really need to deal with the effect of gravity so the way that we've controlled all of these robots is really in sort of endpoint space so if you think about what nathan is trying to control is to position the hand in the place and orientation that he wants it to be and so the computer figures out how to control all of the joints to get it to that position but what we're decoding from the brain is the endpoint velocity that essentially sets the position in orientation of the hand our next question i notice nathan has some use of his hands did this experiment help his brain to recover that use no i don't know nathan do you want to talk about your injury level and how much function you have okay so i'm c5 quadriplegic um so i do have some wrist function uh i've wrist extension but not flexion and i have no um finger movements um at all and then i have um pretty good uh arm movements uh biceps no triceps but a good shoulder all that um and no unfortunately none of this um has the capacity to you know regain any of my loss function would it be cool if it did yeah i would just add to that you know we've been using robots for control not necessarily because we think that's the ultimate device that people want but because we're trying to focus on how do we get this information out of the brain for control and then use stimulation to provide that sensory feedback back and so robots are very reliable in terms of you know going where you tell them to there are definitely other groups that are working on trying to use electrical stimulation of the nerves or muscles to restore function to people's own limbs and that's a very challenging but important problem that that people are working on that you know might have the capacity for some functional recovery um you know and more closely aligned i think with what people are are desiring okay just want to mention we have a question from muhammad and i'm going to hold off since you're asking about some other projects and specifically related to optic nerve revision so if we have time at the end we'll come back to that or maybe i can put you in touch with jennifer afterwards i just want to keep questions for nathan here uh nathan do you know you talked about this a little bit do you find certain robots to be easier to learn and are controlled than others um so i'd say controlling them is uh not more difficult from one robot to the next uh but um okay so like like jen said uh control is endpoint and the robot kind of figures out what to do to get the hand there and so each robot uh moves within the workspace differently they have different kinematics and so that's that's the the main reason that the luke arm is my least favorite arm that i've controlled um because uh just how it was more limited in the workspace like if you would reach to the far left it would you know bend the at the elbow a certain way and it just kind of was more limiting than say the kuka like i mentioned when i'm doing a task i can move the the hand part in anywhere within the workspace because it has so many um joints that it can stay parallel to the the table so that's why i think an anatomical robot say you know years down the road there's one that can get mounted in a house and and you want to use it in the kitchen and you want to get a a box off the shelf in the cupboard if you're using an anatomical arm that's mounted at the shoulder and you need to reach the top shelf when you move the you know arm up it's going to bend at the elbow it's going to put the hand at a position that's pointing towards the ceiling and you won't be able to grab anything off the shelf because you know your hands can be pointed up but with the kuka you i could move you know up and it would stay parallel to the ground and i could grab you know the box and pull it off and bring it down but like you asked the the control is not harder um learning to use or recognize how they work within the workspace has been different with each arm okay thank you nathan with more questions here for jennifer did the arm get calibrated each time it was used yeah for almost all of our experiments we trained a new we called decoder so figuring out that map between brain activity and kinematics each day it's the same general relationship we assume but the neurons that we're recording from can be different from day to day another question for nathan you shared my cyborg adventure is that something you could that is shared with the general public if people wanted to follow you or find that yeah so the the actual youtube channel is called bci can do better that's no spaces but if you search on youtube for um my cyborg adventure and filter by playlist it uh should come up okay great i think we have a few more questions so let's see so it looks like you have functional use of your right arm and how will you decide which are which to use for the robot yeah um well it started out with um we had a right-handed robot initially and so we were planning to enroll someone and do a left sided implant right because the left side of your brain typically controls your your right arm there's been some discussion about whether you know if somebody was left-handed prior to their injury would we still get as strong of a control signal from their non-dominant hemisphere and fortunately we haven't had to debate that yet because all of our participants were previously right-handed prior to their injury you know but also significantly impaired um after injury and so it was kind of a mix of um practical reasons and then just thinking that the dominant hemisphere would have the strongest most coordinated command signals but we really haven't tested that okay another question for nathan says did you experience any training effects in how easy it is to try to generate the movements necessary to control the robotic on no like it it's just been like i guess really intuitive like i never really had to um like go through this whole trying to learn how to think something uh to make it to make it move right uh other than just moving you know think about moving my arm to the right so it's one of those things that it worked the first time um we tried it of course you know we start with only like you know two degrees of freedom like i you know move the arm up and down and left and right and um you know it worked it was just you know i watched the the computer move into the targets and then i just think about moving my arm in the same same way and then it trains the decoder and it just works and um yes so that's that's all i've ever had to to think to get it to to move of course we you know you start slow and you do the two degrees then you add the third so you can move it in and out and then grasp and you know wrist rotations and and that kind of stuff but yeah no no real mental gymnastics or struggles i think on the same lines another question was uh has your quality of life improved with the device being at home now you mentioned you were able to take i had a portable device you ever bring home uh [Music] yeah like for a while there i was using it like almost every day because you know the world shut down and i couldn't go anywhere and so that kind of you know definitely saved me from some of the the boredom and you know driving myself crazy with nothing nothing to do so i mostly played games and i i drew a i drew a cat and i should have put it on here too but uh yeah i spent hours working on this this cat and um yeah so at home the systems you know pretty much limit limited to that you know i can train a decoder that can move a cursor and you know i can play play games or draw so it's uh it's fun i i want to get back into using it more often and play more games and yeah new new consoles came out and maybe get one of those and control a ps5 with my brain and get a i want to get a nice new tv and computer and kind of send some emails out to companies and see if see if they think i'm cool enough to to give me a tv and a xbox in a playstation okay we have a few more questions here um did you ever experience any sensations from the stimulation other than the ones in the robotic arm um i think kind of what this question is asking is have i received sensations that were not from tasks using the robotic arm the answer is yeah there's all kinds of tasks that um use stimulation but not um involving the robotic arm at all but also what they also might have meant is no i've never felt any sensations um just every day not hooked up to the arm and receiving stimulation most of the tasks rely on the fact that stimulation through a given electrode generates a sensation that feels like it's coming from somewhere on nathan's hand and so it could be driven by a virtual reality or some other mapping that we that we provide but it all nathan correct me if i'm wrong but it always feels like somewhere on your hand it's not a direct sensation no always my hand okay we have a few more minutes here let me get one or two more questions how has this bci collaboration benefited other study participants and the academic curriculum at the university um you know i i think this well this is the only um you know planned pci study that we have going on here although we have you know expanded to now a site at chicago as well as part of this study and so you know i think that's a very small community of people who are doing this type of research and that's one of the reasons that we're interested in doing presentations like this is to share our experience and and what it has been like certainly we've collaborated a lot with basic neuroscientists who you know have always wanted to ask uh you know what it feels like for the to receive this type of stimulation have been unable to in animals for example and as nathan explained it still may be a little bit hard to articulate in words um you know but it's been just a great collaboration with other neuroscientists in the in this area and piggybacking off of that i wanted to go back to muhammad's question since we have a little time and this could be open up to the entire panel here but he was asking to what extent have other areas of bci test have been as successful in comparison to the robotic arm has there been any tests for sensory related bci especially with a regard to the optic nerve or vision related functions in general yeah i mean you know on the on the motor control side um i think there's been a lot of great progress over the past few years just in terms of you know communication so trying to decode either cursor control for typing on a virtual keyboard or even recent approaches of decoding handwriting for example that have really accelerated the pace that can be achieved for pci-driven communication and i mentioned earlier that other groups are trying to tie bci with functional electrical stimulation either for assistive or rehabilitative purposes which i think is exciting you know the sensory bci in terms of vision i don't know if there's other panelists who want to speak to this since it's a little bit um outside of my area but definitely there are cortical visual prosthetics you know that are now you fda cleared and under investigational trials for restoring vision the the general safety principles and things are similar but the science is different another question for jennifer um what is your impression of the recent interest of the private sector in bci development yeah i mean you know one thing that i think is challenging for this field is how do we actually translate it out of the lab and you know so that people can use it at home and not just for experiments or playing video games like like nathan mentioned um you know with our portable system but actually on a big scale of translating this and making it accessible and that's going to take you know significant investment and so i'm personally excited to see the interest in this technology to try to push forward the you know the actual implants and electronic technology it's clearly going to need push in terms of science so that we can develop technology that's reliable and robust outside of the lab and so you know i think there's going to have to be tight integration with academia and then figuring out actually how do we get this out as a medical product and reimbursable for people to be able to use so you know i do think that this investment is important and it's part of the responsibility of this community to try to provide input into that to make sure that it gets back to helping the people that we're you know trying to help now we have this is christopher we have one more question and i can't help but to to ask it um nathan you mentioned earlier about pushing science forward that's that's what it's all about for you it seems like i'm just curious where is the science going um what's next nathan or jennifer either one i mean it's it's hard to know um you know i think every time something comes out and you know you look back you know six years ago and i never would have thought um you know i could be doing the things that i'm doing now so in another you know five years you know i really don't know but um hopefully you know like jen said there's there's pushes by people with money that they want to you know make you know things and that's one of the one of the things like okay if we get the the implants and the you know that stuff working out well enough that you can go home with it uh you also need stuff to control like i mentioned a kooka in the kitchen uh that would never work uh that thing's huge and you know so there needs to be people thinking about stuff like that like what are you gonna do with these implants like you need a cooker that is you know mini like a mini mini that you know could be in your house could attach to your wheelchair that kind of um stuff will come down the line eventually and you know everyone can play more games i'm i'm i just i'm just wanted to add that you know it's because of you in part because of your courage um to uh to try something new and jennifer's courage to encourage the science and to follow the science in this way that private industry is interested and and that the science is moving forward so i i have to say thank you to you and to jennifer thank you all time has ended um to the presenters awesome presentation um i want to thank you all and i want to thank ai media for being a captioning team today um i want to thank g3 ict and the team we do have a next webinar coming up in january so stay connected make sure you check us out um and um and we look forward to um getting more information out to you thank you everyone thank you thank you all right bye-bye bye thanks jennifer and nathan you 