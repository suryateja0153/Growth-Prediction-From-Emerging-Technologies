  GRACE LESLIE: We all know intuitively and for centuries that music is a very, very powerful human experience, and we know that it brings people health and well-being. But we're not quite there in terms of understanding on a scientific level why that is. My name is Grace Leslie, and I study brain music for a living, and I also conduct brain music research at Georgia Tech in Atlanta. The goal of my research is to develop new kinds of music technologies that are going to use brain and body signals and see how we can incorporate these into new kinds of music, new kinds of musical interfaces that are going to bring us health and well-being. One of the most fun parts about my job is I get to direct the Brain Music Lab, which I started here when I arrived. One of the projects that is ongoing in the Brain Music Lab is playing heartbeats to people. What we're finding is there's actually a effect that this heartbeat listening has on your ability to feel what somebody else is feeling. Another student that I'm working with, he's applying all different kinds of machine learning methods to actually predict imagined music or listened music from having only their EEG data. So what are all these brain and body signals that I'm talking about? I can start out with EEG, which is my favorite one. EEG stands for electroencephalogram, and this is a way that we place sensors, like the cap that you see here, on somebody's scalp. And these sensors are measuring voltage created deep inside the brain. When I'm talking about EDA, I'm referring to electrodermal activity. This is a way to measure how aroused our central nervous system. When I'm talking about ECG, this is the acronym for an electrocardiogram. What we're picking up is voltage, and we can attach these in a particular configuration around the heart to measure a lot of different features of somebody's heartbeat. Over several years of practicing what I like to call brain body music performance, I started out being very focused on these new interfaces that is going to record input from the way that my body signals perform onstage, turn them into music so that I can learn how to use that in an expressive way. I developed a new kind of algorithm that takes an incoming EEG signal, and I convert that into sound on the computer. And I learned how to manipulate these brainwaves to produce different kinds of sounds in a musically performative way. I started to recognize that the most powerful way that I can influence this brain activity while I'm onstage is actually to pay attention to the body instead. When somebody asks me about how I tune my instrument, I would have to say, that tuning happens not from me tuning the instrument itself. It happens from me tuning my body to a particular frequency. My heartbeat might be 70 times per minute. Oftentimes, when I'm performing, that will drop very much or rise very much, depending on how much I'm holding my breath as a result of playing these really long notes on the flute. Eventually, I developed a way to manipulate my breathing pattern onstage in order to create this kind of expressive arc and to reach a different kind of physiological state in order to express this sense of deep calm. A lot of people ask me, do you always have to make music that sounds like a warm bathtub? The musical nature of this, the sound qualities, the timbres that I produce, that is actually very inherent to this idea of inviting somebody to synchronize with me. What I'm doing is developing music that I believe sounds very new. And it's something that is exciting for me to share this new experience with my audience. The music and the research are incredibly intertwined. I don't think any part of this work could exist without the other. It's using that data to understand how music that I compose is going to affect people's brains and people's body signals, their heart rate, their breathing, their skin conductance levels. And I'm using that knowledge to inform the way that I compose this particular kind of music. 