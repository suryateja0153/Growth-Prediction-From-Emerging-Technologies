 Imagine a world where, you are integrated with a computer to navigate the environment Like this, actually, no, less tech like this? ... but, more discreetly ok, how about this? but, wait, in this just an electric bike? Is not, let me tell you why In this work, we explore integrated exertion, this is the design space at the intersection between, human-computer integration, where the user and the system co-operate in a partnership and exertion support, where the user invests physical effort as part of the user experience. And in the experience of integration, the system is constantly sensing and interpreting data in order to act in the experience And the data that we explore in this work is the user's neurological data read via EEG from the occipital region That is the orange part on the back of the brain responsible for vision processing Reading this data can tell us when a user is, or is not, in a state of peripheral awareness in real-time, and this is what we built Introducing Ena, a novel system that affords rider-eBike integration via the rider's neural activity. Via an EEG cap, Ena monitors that the user's neural activity is between 0.76 and 1.19 microvolts within the high alpha range of 10 to 12Hz. These correspond to the rider's field of view being peripherally open to afford higher awareness of the environment and it activates Ena's engine support. Instinctively, the rider's field of view narrows as a response to a threat, such as a car veering. In this case, Ena instantly stops engine support, allowing the rider more time to respond to the situation. with this work we imagine a future where interactive systems are integrated with our neural activity to support enjoyable and safer experiences. We studied our system with 20 bike riders and derived themes and design tactics around designing integrated exertion experiences with neurological data We invite you to take a read at the paper for more details Now, I would like to focus on a few take aways from this work Take away one, Our work introduces and demonstrates peripheral awareness as a neurological state to HCI This is a new approach we can use to study user's of our systems through a non-invasive neuro-physio lightweight and real-time approach For example, to inform future health integrations that help user's in developing practice to reach peripheral awareness and have a deeper understanding of their abilities Take away two, Changes in a user's field of view relating to peripheral awareness can be read in real-time to gain access to a user's pre-attentive state This means that the system is reading directly from the user's brain and it can react faster than what it takes a user to react to the situation This is particularly valuable in different situations, such as, Navigating the environment, Operating machinery Emergency response and Team operations where the user benefits from having a wider awareness of the environment Take away three, integration directly from the user's brain can facilitate a symbiotic-like experience and to talk about this, I'm going to use this chart from previous work where we see the system as an equal to the user In this case the user and the system have their own sensing abilities that that can complement each other In what Farooq and Grudin called, working as partners and partners implies two agents, however, Mann, previously said that once computers systems reach more advance abilities the divide between the user and the system was going to blur and the user and the system would become one In light of this vision, we see now in this work the system and the user are one and because in the 60's Licklider also told us about the 'speed mismatch' and the 'language problem' as obstacles in the symbiosis vision and users of our system said that, they didn't need to think how to communicate or how to raise the attention of the system as it was directly from their brain wave, so the user and the system became one Lastly, this approach contributes to Rekimoto's call on extending the toolkit of human-machine integrations available to us with this, we have begun to blur this divide between the user and the system My take home message is Using peripheral awareness as a nerurological state for human computer integration is viable and it offers access to a user's pre-attentive processing state that the system can act upon to support the user experience with that, I would like to thank you for your time, and I'm happy to take any questions, thank you 