 This is the "Emotionally Intelligent Artificial Intelligence, and Brain Computer Interface" team. So what we're trying to do hasn't ever been done before, as far as I know, and so this is very wonky but it's a proof of concept. This project arose out of the fact that emotionally intelligent entities of artificial intelligence are going to come and make a lot of decisions in our lives, very soon. Health care, migration, employment, social sorting. All sorts of things, and there isn't much recourse. On the other hand, Facebook Building 8, DARPA, Elon Musk and others, are beginning to make companies and initiatives where cognitive processes alone will control navigation and interaction with emotionally intelligent artificial intelligence. And a lot of this research is not public -- little bits of it are -- so this is a real look into the future of which we only have a little bit of access to. Our teams -- we had two of them -- one was to make the wonderful body part, which Cynthia did, and she was the only one left from that team. And the other part, with our programmers, our dedicated programmers, was to make the emotionally intelligent speech synthesis. So I'll let them talk about what they did and then we'll explain what you're gonna see. I'm Sarah and so I'm gonna talk about one of the components that we used. So this visualization that's flashing in and out -- there are two components. One, Cynthia will talk about. But in this particular analysis what we're doing is when someone speaks we're analyzing the sentiment so what they feel when they're saying something and the magnitude of what they're saying. That's like how strongly they express something and then from that we're creating a visual using p5.js and that's exploring how to express what someone's saying in a different form -- so, in a visual form -- based on color and then also you'll see with positive sentiment it will become bigger and with a more negative sentiment it will become smaller. And then Cynthia is going to talk about her really exciting wearable. My name is Cynthia and I was commuting here from Baltimore. I'm a new media artist I specifically work with biofeedback sculptures and different immersive meditations and installations. Things like that. So what we decided to do was to work with the EEG. I'd worked with them in the past, and getting different signals out of them to make different responses happen. We have two -- we have interest, and relaxation, right? Those are the two we pulled. You can call them many different things, like meditation, and things like that. The two we have are similar to the sentiment analysis so that's what we're trying to do is compare the two. My name is Dori Rose, I'm an artist and a technologist. It was a lot of fun working with very talented artists and technologists here. And that was my first time working with BCI. And also a lot of beautiful wearables. So I'll talk about the demo, so as part of the demo I'm gonna be asking Ellen some questions and as Cynthia and Sarah explained her brain waves are going to drive the colors on the wearables and her speech is going to be analyzed and be shown on the screen. Right, Ellen, how do you feel right now? Ellen: I feel really... intensely..... calm [pause] And... I'm really enjoying this experience very much. [pause] Dori: What do you do to relax? Ellen: Meditate.... very... calmly. [pause] Dori: How do you stay motivated? Ellen: I don't like to stay motivated all the time. I like to be active, and I don't want to always be motivated. Dori: What is something you hate? Ellen: I really hate getting stuck on the subway when the temperature is really high and people haven't used deodorant. [laughter] And they're standing right in front of you! Dori: What is something you love? Ellen: I know it sounds corny, but I love the beach.... [pause] That wraps up the demo. [Applause] 