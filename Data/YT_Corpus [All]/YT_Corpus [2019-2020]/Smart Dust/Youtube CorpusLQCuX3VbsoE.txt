 all right um thanks for uh reconvening that we're time for our uh our second speaker our deep learning part of the summer school uh it's my pleasure uh to welcome uh just kidding my thing with to blaze yarakis uh he leads an organization at google ai working on both basic research and new products the team can has contributed many contributions including mobile nets federated learning and coral they've also founded google's artists and machine intelligence program and they collaborated extensively with academic researchers in a variety of fields um from a personal point of view i've found blaise to have one of the most creative and unique perspectives on machine learning and ai and i'm very happy to have him here to tell us today uh to share his vision with us today so uh and he's gonna give his talk live and we'll um probably take questions at the end so i hand it off to blaze thank you so much uh erin for the very very very kind introduction and for and for having me here i i'm going to share my screen let's see okay does that all work sorry yes does excellent um all right um so uh apologies for the uh you know it's it's gonna it's a little bit a little bit difficult to give a talk uh remotely without um you know any sense of the of the audience and the feedback but uh you know aaron uh counting on on you or or anybody else to break in if if if something is going off the rails so i um i wanted to talk about about three things today um the first is a little bit of uh history of computer science and ai from maybe a little bit of a different perspective uh than than you might be used to and then talk a bit about scale the the problems of scale the possibilities of scale um again from a little bit of a different perspective than i think uh you know most most researchers in mlai are used to uh and then um and then i want to talk a bit about what is missing uh from from the the model of learned functions uh and uh and straight state-of-the-art performance that that most of us uh think of as as being what we do so um history of computing uh you know many of us uh you know the first image that comes to mind when we think about the history of computing is uh babbages difference engine this is a reconstruction uh commissioned in 2008 by nathan mierfeld um and uh i believe this one is in in the computing museum in mountain view there's another one in london um and uh amazingly worked uh when it was built from uh from babbage's plans um whether or not it's a computer in the modern sense is actually something that bears a little bit of of thought when um when babbage was alive he was not best known as the inventor of computing but rather as one of the founders and fathers of the industrial revolution uh he was uh he was all about factories and efficiency he invented the penny post uh his intellectual contributions had more to do with uh manufacturing uh than they than they did with uh with computing and in his book on the economy of machinery of machinery and manufacturers uh there's this one chapter that that treats the the computing work um it's on the division of mental labor we have already mentioned what may perhaps appear paradoxical to some of our readers that the division of labor can be applied with equal success to mental operations and then it ensures by its adoption the same economy of time a short account of its practical application and the most extensive series of calculations ever executed will offer an interesting illustration of this fact while at the same time it will afford an occasion for showing that the arrangements which ought to regulate the interior economy of a are founded on principles of deeper root than may have been supposed so the the thing that he goes on to describe in this chapter is the french hydraulic engineer gaspar the pronis government-funded project to uh to make a giant set of of uh tables of log and trig functions uh which was eventually published in in 1791 it was part of the french government's uh kind of standardization and decimalization uh and rationalization project uh the sort of post-french revolution uh proni was in turn inspired by adam smith's wealth of nations he uh he basically wanted to make these gigantic books of of function tables uh by building an org chart and and so he divided up the labor for doing this into three levels and uh bragged that he could manufacture logarithms as easily as one manufactures pins which i think is a great uh bon bon so he talked about the the layers of the org chart in terms of sections the zeroth section of course is prania himself the first section was five or six of the most eminent mathematicians in france uh including legendre and carno and some others that you may be familiar with the second section was seven or eight persons of considerable acquaintance with mathematics so you know at the top levels they were kind of working out the um the basic algorithms that they would use which functions would they tabulate over what ranges and so on and so forth these would then reduce those operations to elementary ones and uh and the bulk of the labor was this third section which was from 60 to 80 people using nothing more than simple addition and subtraction they return to the finished tables it's remarkable that nine tenths of this class had no knowledge of arithmetic beyond its first two rules meaning addition and subtraction since we're usually found more correct in their calculations than those who possess the more extensive knowledge of the subject in fact uh that third section consisted almost entirely of out-of-work hairdressers uh because it turned out that they had less work to do uh during this period than they had while the heads of the nobility were still on a few years prior this idea of of using uh women uh primarily as the uh as the lower tier of a computing machine uh is one that uh that had has a long history a longer history than modern computer science does so premier was doing it it was also being done in in the first uses of punch cards which was shown here this is the preparation of the 1890 u.s census or the first project in digital humanities this is this was the index domasticus which went on for several decades um you can see all of the various church fathers peering over the shoulders of one of the women doing the the data entry and computation for this digital humanities project or the harvard computers uh which was the first uh use of large-scale computation for astronomy uh also called pickering's harem by the way that was a pickering on the on the on the top left and all of the labor being done by the women um some of whom ended up being quite prominent astronomers in their own right by the way which was a bit of a kind of hidden figures story uh even as late as world war ii uh there were massive compute farms uh being uh being uh done by by women uh and uh these were for calculating ballistics uh trajectories uh nuclear bomb yields all sorts of things now um at the time of of uh um at the time of the of the early computers that uh that babbage was uh uh was was dreaming up uh really it was his collaborator aydah lovelace who um who kind of understood what it would mean for general computation to happen as opposed to thinking about these things as manufacturing processes as as really just about a kind of um machine for generating the values of a function uh ada understood i think the uh the bigger possibilities and uh and they're a remarkable series of of footnotes in her translation of of this lecture by minabri on the different section that really revealed the extent of her understanding of this uh she was also fixing to be an amateur neuroscientist at the end of her life she had a tragically short life cut short by cancer and as she was very sick toward the end of her life she she wrote the following in one of her letters i have my hopes and very distinct ones too of one day getting cerebral phenomena such that i can put them into mathematical equations in short a law or laws for the mutual actions of the molecules of brain equivalent to the law of gravitation for the planetary insiderial world the grand difficulty is in the practical experiments in order to get the exact phenomena i require i must be a most skillful practical manipulator in experimental tests and that on materials difficult to deal with the brain blood and nerves of animals in time i will do all i dare say and if not why i don't signify and i shall amuse myself at least it appears to me that none of the physiologists have yet got on the right track i can't think why it does not appear to me that cerebral matter need be more unmanageable to mathematicians than sidereal and planetary matter in movements if they would but inspect it from the right point of view i hope to bequeath to the generations a calculus of the nervous system um i actually always find this letter a little bit a little bit um difficult to read it kind of chokes me up a bit um who knows what she might have achieved that she had lived but as it turns out she wrote this in 1844 99 years later a paper was published about that calculus that she imagined a logical calculus of the idea's imminent and nervous activity uh warren mcculloch and walter pitts this was really the last moment at which neuroscience and computer science were the same field and um what mcculloch and pitts imagined in their models of neurons in the brain is that they were carrying out logical propositions logical gating functions so they imagined the whole brain was like a a function evaluator and and that neurons were doing ands and ors and knots and so on um and that and that you know that that all of the mental processes could be reduced to uh to a kind of uh a logical calculus in that way uh so you know this this uh this drawing of there is uh you know it's just one of many in the paper uh drawings of neural nets and you may recognize um that these neural nets and the reason they're the neurons are drawn as they are by the way is that they're pyramidal neurons which you know have a pointy end and a fat end and and those loops by the way at the ends of certain of those neurons uh represent um inhibitory synapses which they imagined might be a not operation so you know any of you who have seen circuit diagrams of of logic gates will recognize that loop on the end as being the um you know the not loop at the end of a nand gate or a nor gate or something i'm pretty sure that this is that this mcculloch and pittsburgh is in fact where all that comes from in other words logic gates are artificial neurons and all of classical computing uh is is really uh based on on this um idea of modeling modeling brains modeling neurons and and and the gates and there are the artificial neurons and that that analogy was very very direct from mcculloch and pitts to uh the early designs of the um of the eniac and other early other early computers to touring's seminal papers on on computing so yeah uh all computers in other words are neural nets the difference of course is that a classical computer uh which runs ordinary programs and does arithmetic operations and so on is a computer in which all of the neurons are um you know are are kind of fixed function and rigid uh and uh they don't learn rather they um uh they're they're wired up into a certain configuration that does a very very specific task uh and executes um operations in series so uh in that sense um you know these these early models of brains really had very little to do with how real brains work but they had a great deal to do with how modern classical computing the 70 years of computing that uh that went all the way from uh you know 1940s up until i would say i don't know 2015 or so how all of that computing worked now not all computing was done in that sort of logic gates uh sort of school this is frank rosenblatt in 1959 with uh the very first artificial neural network which i'm sure many of you know about the perceptron uh which could distinguish between uh triangles circles and squares uh the the um the synapses that govern the behavior of this feed-forward neural net were actually connected to potentiometers and motors that would do uh kind of uh learning using using something like reinforcement so um all of these ideas uh you know involve uh involve the the kind of theory that a brain is basically a function um and uh and that if we're going to do learning uh in other words figure out what what on earth that function is it's essentially a regression process so if you have a really big function uh like a brain then that means lots and lots of parameters lots of neurons lots of synapses and lots of parameters if you're doing regression of course also means lots of data so um so the idea of size of bigness and of brute force was sort of built into this idea from the very beginning um and uh and and uh you know in the recent uh experiments with with gpt3 you know we see that same sort of of uh you know what happens if we just make it bigger more data more computation more millions of dollars to train and so on these are uh these are um pods of tensorflow processing units in the google data center the fact that google has access to very very big data and very big computing with their you know giant data centers the biggest in the world as far as i know um you know that that's that's one of the things that made google a natural place for uh for the development of a lot of these techniques uh you know jeff dean when he founded google brain talked a lot about this kind of confluence of big data and big computation as one of the reasons that google would really be at the forefront of a lot of this kind of work and and he was right it has been although open ai is certainly giving google a run for its money but i believe uh personally that uh most machine learning in the future will be done on very small devices and not in data centers at all and um and that that might elicit a a-ha you know especially in the in the uh in the weeks just after gbt3 um the reasons are um that i think we can i think we must and i think it's inevitable and i want to i want to run through these arguments briefly to give you a little bit of a sense of them so as far as we can goes uh well um back in 2017 uh aaron mentioned mobilenets which was one of one of one of our our group's uh earlier outputs and um mobile nets uh and and many other techniques uh you know involving involving uh quantization and model compression and so on uh allowed for what what had been really quite heavy weight uh in this case convolutional nets standard kind of machine learning models to run on uh on small devices uh like phones uh in real time uh even on the arm processor uh now it doesn't even require you know kind of using the gpu or something which was quite surprising to me and to many other people as well that it was possible to run these large models on on modern processors uh because modern processors uh have so many vector operations because they are in fact so fast we've pushed things really to the limit um and because they're so um because that that pathway of miniaturization and speed uh kind of uh carried moore's law for 70 years and that that really goes places uh so it's interesting that even on modern on on modern phones you know we can actually evaluate you know quite large neural nets although not of the sizes of some of these very big ones we've seen recently um as for why we must why we must think about about about neural nets on small devices well um you know one of the one of the things that our team has done um is uh ship a lot of neural models of different sorts on things like android phones um for uh for a selection of text uh for um captioning uh for tr you know translation of of um of of speech into into text for people with uh with with hearing disabilities um and and so on and and in a lot of these different applications you really don't want a system in which the signals are first sent up to a data center somewhere and then the result comes back down um you really want local evaluation local execution because of privacy because in many cases these neural nets are serving as kind of prosthetics that are mediating your interaction with the natural world or with other people in ways that that you really don't want another entity to be in the middle of if that sense you you want you want that mediation to be entirely confidential not to be a potential source of surveillance and um and whenever whenever you um you aggregate information in in the data center you know even even if you uh if you have very very strong security as google does um you you still are now uh you know you're no longer in your own home as it were uh right you you're now um uh you're now cycling things through a space that uh that can be uh surveilled for example by uh by governments and and there are real civil liberties implications to that so uh so making these things run locally is important you know we we shipped uh some features on android like for example uh now playing a number of years ago that do something like shazam that recognize the music in your environment uh continuously and in real time that's much more useful than an app that you have to launch and you know listen to the music and get back to get back the the result you know it shows up on the lock screen if you turn it on like what music is playing right now if you're in the coffee shop um but there's no way such a thing can be implemented by having an audio stream of everything the microphone here is continuously being streamed to a server somewhere right that would be that would be anathema from a privacy standpoint but uh when all those things are running locally it's not a problem it's like a smart hearing aid essentially so uh yeah same kinds of things with face unlock uh and and certain functionality in google lens so we've done a lot of work with these devices to to bring uh uh to bring various neural capabilities um to a place where they can run on on devices um i also think that that that more and more neural nets running locally and on devices is sort of inevitable from us from a scaling law perspective um and uh just for a bit more of a trip down down memory lane in computing history this was one of the first um all um all solid state uh four function calculators it was a very lightweight meaning you know it only weighed about as much as um i don't know a desktop computer i suppose and you can see all these you know 13 boards stuffed with components uh and you know this this thing in 1969 uh you know eventually eventually turned into the google pixel 3 say in 2018 and when you tear down a you know a modern phone you don't find boards stuffed with components inside what you find inside is actually almost nothing they're full mostly of battery and um i don't know if you can see my mouse when i move it over this thing but these these two chips are really the best uh end of the phone so even the space inside the phone is not primarily being used by computations just these little bits and um you know the trend toward making computing uh work uh as uh systems on chips uh means that uh nowadays most laptops you know don't have boards of of computing in them either i mean this a system on ship like this one is apple not only for a smartphone but for quite a powerful laptop the entire laptop is basically on this one board with all of its support electronics so um it's a it's a pretty different world that's why laptops have now gotten so thin by the way they're mostly surface and the inside such as they are consists mostly of battery uh you know we get sort of comical pictures like this one where in uh memory is so small that needs multiple layers of adapter in order to just like result in something macroscopic that can be plugged into you know a larger machine which is itself mostly made out of air so you know that little 64 gig thing dwarfed by its adapter you know now obsolete there are 512 gig one terabyte and actually even two terabyte ones and and just again just for perspective this was the first hard drive from ibm the 350 disk storage unit announced in 1956 stored 3.75 megabytes on 50 magnetic platters the weight was about one ton um this is the husky stadium at university of washington that's how much area you would have to cover with those uh with those original hard drives in order to make 512 gigabytes of storage uh so a quarter mile on a side never mind how much power would be involved and of course uh the reliability of those things wasn't too hot either weight 150 000 tons or 136 billion grams uh the modern device is about one gram so 136 billion roughly gives you uh how much scaling has gone in from 1956 to present day and there's still plenty of room at the bottom uh to uh to quote feynman even assuming no further gains in linear scale 3d structure is barely there in modern memory and computation so a sugar cube one centimeter or so on a side um according to feynman's calculations in his wonderful paper there's plenty of room at the bottom uh is um he estimated that that that about a petabyte would be the you know the amount of information in all the 24 million volumes of interest in the world in 1959 um and um and in fact um we are at at a moment in time today where where uh we can actually store about a petabyte in a sugar cube volume if we if we uh stack up uh uh silicon of the kind that i've that i've already shown you so in other words nanotechnology uh you know it doesn't look like uh lots of robots swimming around in our blood and all the other kinds of fanciful things but nanotechnology has quietly arrived and is living in our pockets and purses even though we're still far from uh from a lot of that uh sort of uh you know drexler type nanotech when we look at moore's law uh it's the observation of the number of transistors in a defense integrated circuit doubles about every two years and that um you know that that has been happening since the 70s uh this is on a log vertical axis here's a somewhat more um detailed view of moore's law showing the scaling of various different subparameters of it and um and you can see that something starts to go a little bit wonky in the 2000s we are still in an exponential scaling of number of transistors uh on a die however around 2006 we encountered the end of so-called dendrid scaling and standard scaling is as transistors get smaller their power density stays constant so that the power use stays in proportion with area both voltage and current scale downward with length and when that stopped happening due to physics that's when we saw the number of cores on a die start to increase above one that's when we saw the frequency stop to rise uh you know i i grew up in a world of computers still being measured in terms of how many megahertz or gigahertz they were running that stopped being advertised when that number stopped going up uh single thread performance of serial computers therefore also stopped um but the number of transistors keeps going up so what are you going to do with all of these extra transistors will make more virtual computers on the same die lots and lots of processors but of course if you're using traditional um computing traditional serial computing there's a limit to how much utility you can get out of multiple cores it's actually very difficult to program serial you know computing on on lots of parallel cores but um i think it's maybe not a coincidence that 2006 was also the year that the deep learning cabal took over uh the at the time nips now nurip's conference so um they in a sense i think they provide the answer to the end of denard scaling we know now what to do with all of those extra transistors on a die and the answer is neural nets there's a declining marginal value of all of those extra transistors for doing serial computations but there's no limit to how many transistors a neural net can usefully use uh that's why you know we have the those kind of scaling limits in our own head based on some you know some fairly uh shrunky biology but uh you know it has uh it has a very very large number of units uh regardless of whether you measure that in terms of number of neurons or a number of compartments within neurons or channels even but they're all running at very low clock speed uh in parallel so that's what's going to happen with uh with the majority of our silicon as well because we've stopped being able to uh scale serial serial computing but we can still scale parallel computing and um so many many modern all of the all of the new uh chips coming out of silicon manufacturers are um are starting to do very large scale parallel computation to enable neural nets to run uh fast and at low power uh google's edge tpu which we we released in 2018 can do uh four tera ops at two watts or 400 frames per second of mobile net v2 uh on this little tiny chip and everybody's making neural net processors now um and in fact uh the um you know this is a this is the the coral board that aaron mentioned uh that includes um edge tpus on it for prototyping you can use them kind of like raspberry pi or something um it can do all sorts of neural operations uh and do them in a privacy preserving manner because all of it is being done uh locally so things like you know using a camera to do people counting or to look at social distancing or use of ppe or whatever you would like for those things to work without uh without surveillance and it's possible to do that if you have all those computations happening locally um but uh but anyway my my point uh with all of this is just that uh you know we're seeing um use of transistors for neural nets start to dramatically outpace the use of transistors for serial computing and i think that's a very a very interesting computing trend as we look to the next decade so um this fun book from 1691 the secret commonwealth of elves fawns and fairies uh was written by robert kirk i don't know whether he was a true believer or not but it's kind of an ethnography of the spirit world in um uh in the uk in what is today the uk and um uh you know he imagines a whole sort of uh society or universe of other intelligent beings that are not uh that are not human uh that are kind of living among us you know in the fairy circles or you know under the rocks from the bottom of the garden what have you um and uh this um this book by the way the secret commonwealth that was the inspiration for philip pullman's title uh the secret commonwealth in his second volume of the book of dust this is the same philip pullman who made his dark materials which some of you may have may have read wonderful books um but what phil pullman imagined was that it was a parallel universe in which all of us have these kind of witches familiars we have we have these kind of animal formed things that are kind of external intelligences uh that are also a part of us so you know the person's a person's demon or familiar is a part of themselves and kind of augments them in various ways uh the the uh there's a there was a movie there was a bbc series which was quite a bit better than the movie this word ourself right the the singular and yet plural kind of comes out of this idea of demons and um i think that i think that we're we're actually kind of um rapidly moving towards such a world um you know if if uh if we're making brains uh out of silicon that we're uh carrying around in our in our pockets and purses and so on there and they and they perform more and more cognitive functions then um you know effectively we we have entered the world of ferry uh and there's a lot else in this world of ferry besides people's uh personal demons or personal cognitive extensions that recognize all the music in coffee shops or the translate between languages or recognize objects and what have you uh so uh you know i i also think that things like uh you know a gene or a spirit that you conjure up in the car that you know that helps you to drive ought rightly to be thought of as another entity in this kind of world of fairy uh it's not a proper entity in this world of ferry today which is actually one of the reasons that it works so poorly so uh you know a voice navigation uh on on maps today is kind of called in from a distance from the data center and that's why it'll interrupt you when you're speaking or not not understand you know sort of what what lane you're it has no eyes it has no ears it has no social awareness it's not sort of physically present you can't make that physically present in the current model that is run from the data center without uh without surveillance so um you know ultimately these things are going to have to be actually you know the computation is gonna have to be present and separate from the company that made it and in the car in order to have that social awareness and do a good job of navigation and do a good job of interacting with humans so so yeah this is the direction things are going uh and uh and we have infinite numbers of transistors with which to do it and uh and that's why i think the great majority of neural nets are going to be um evaluated and learn and operate uh in uh in the ferry world which is to say in devices that live uh with us among us in environments on our persons in our persons in cars in cities and not just in data centers that kind of call it in from a distance doors that open and close because they recognize people and not and you know and don't open the door for cats and dogs smart dust eventually you get the idea so where are these neural processing units headed well um low clock speed uh and analog computation are certainly on on the on the frontiers uh that allows for very low power and very low heat dissipation which in turn allows stacking in 3d um and and that's what brings us you know our sugar cube that can uh that can embed not only you know a petabyte of data but uh but possibly on the order of peta operations per second uh which is about uh you know perhaps roughly human brains worth of computation so you know we're kind of we're kind of here we know how to do it leads us to a prediction uh you could call this neural silicon law number one if today there's equal silicon area being dedicated to the cpu and the neural computation in devices every 18 months or so the neural silicon will double while the cpu stays roughly constant because there's there's not you know no further gains to be had from adding transistors to serial computation that means that in a decade or so 99 of the transistors in your personal device uh will be neural as opposed to evaluating classical computing uh neural silicon law number two is that if those things can be run at very very low power by down clocking them then that means that ambient power that just comes from the difference in heat between your skin and the environment or um uh you know or um ambient radio or light or whatever all of that becomes becomes part you know sufficient to power its neural computation and uh and you don't need um even batteries you can run things with with just a capacitor and uh law number three is that the majority of your neurons are going to be digital are going to be implemented in things like transistors as opposed to in wet wear inside your own head because the number of neurons inside your own head is constant and the number of neurons uh that that augment you uh via via your personal devices going going up exponentially at the moment and there's no race between the constant and the next moment so um so i i hope i hope i've explained why i think that the idea of big machines um you know and and big models running in data centers that cost millions of dollars to train and so on is not necessarily the way of the future and i want to talk a little bit about big data as well so um the need for uh for for big data uh you know is clear if you have very large numbers of parameters and you're thinking about things in terms of regression um if you want to train something that is uh doing regression in order to go from you know 28 by 28 pixel image to a number then you need lots and lots of copies of the number uh they all come from different human beings that originally wrote all of those digits um we um we invented a technique a few years ago that uh some of you may have heard of called federated learning for um you know not not so much for disrupting the whole idea of how learning is done but for at least uh changing the terms of the engagement of people and the fairy world if you like with uh with with data uh and and the way it works is by taking stochastic gradient descent and uh and it's and its many variations and sort of turning it inside out in such a way that not only does inference happen on devices out there in the world as opposed to in a data center but learning also happens on devices out there in the world so um you know just just doing learning on a device in the world maybe it doesn't sound like such a big deal but but it might also sound particularly useful um you know sure my local device could do uh could evaluate a gradient and and tune a weight but if it's only my data that it's learning from that's not nearly enough to learn how to do a complicated task somehow everybody's information has to get aggregated together in order for this to uh to really work but how do you do that aggregation without moving all of the data to a central location well you can instead think about a distributed model for uh for the learning algorithm itself and um uh and the way the way it works and this these are stills from a comic that that we that we made about federated learning because we wanted policy makers to be able to understand it as well as computer scientists and uh and the children researchers um but um but uh this this comic you know sort of tells a little story about about an imaginary uh startup and it's privacy nightmares and how they uh how they use federated learning to solve their their challenge um but the idea is to not move the the training data to the server to keep it on the device um to uh to run gradient descent um when that device is not busy doing other work so you know you're asleep it's asleep uh it's plugged in it's got lots of time and power it runs over the examples that it has observed throughout the day and um and and calculates gradients and tunes its weights a little bit that's by the way the same thing that you're doing when you're asleep uh that's why uh you know when we talk about learning skills or memory consolidation sleep is so essential to all of that right we um there's good evidence that we don't do a very good job of tuning our own synapses uh while we're awake and behaving either we need that that rest period to do it so your phone is doing the same thing uh but then the real trick comes when um uh when the uh when the deltas when those those gradients and those those uh those updates are themselves taken and compressed and encrypted and um and these secure aggregation uh protocol is applied which adds random masks uh to all of those uh gradients uh random masks that when they're all added back up when they're uploaded and added back up in the data center cancel out to get uh to get an accurate gradient from the entire population that then tunes the network and brings it to a better state so this allows learning from entire populations without uh without revealing any of the any of the training data to uh to the server um it's it's a um it's a very very interesting field this one in which you want to think pretty hard about bounds on privacy and performance you know if you if you uh if you want to de-anonymize a system like this one you can imagine taking one step based on one item of training data and then trying to reconstruct the training data from the change in the weights that's possible to do but of course if you take many many steps um if you uh if you you know average together lots of training data and take many steps and tune the network based on that then you're no longer able to uh to do that reconstruction unless your neural net is just memorizing rather than generalizing so a neuron that's doing the right thing it's generalizing rather than memorizing uh will also preserve privacy uh when when this when this learning happens and there are various kinds of differential privacy style bounds that one can make on that so it's a hot field uh you know we um we wrote the first few papers in the beginning uh google papers dominated very quickly turned into a field work where papers made at google and from our group are a very small minority of the papers being published on federated learning uh there was this cool paper in december 2019 with lots of authors advances and open problems and federated learning that is a fun one to check out if you're interested in this topic i'm also very excited by the idea of training generative models with federated learning because um you know one of the shortcomings of normal supervised learning with fl is that you need the feedback signal on the device in order to know uh you know how to how to calculate a loss function but of course when you're doing unsupervised learning you don't need a loss function and generative models are by definition unsupervised uh and and therefore the sky's the limit with respect to federated learning of generative models so very interesting possibilities here and you could of course then train a generative model to um that you will then use as a kind of artificial user or an artificial ensemble of users to then uh kind of make an endless private faucet of data to to do labeled training data if you want so i now want to take a bit of a step back a bit of a turn um and uh and talk uh for for my last few minutes about um about whether in fact it's it's uh it's reasonable to think about brains as just functions um i had a a high school teacher um uh in in math who um you know when she was uh teaching the class um basically the rudiments of analysis when she was teaching us what functions were uh was really at pains to tell us that a function could be anything you know it could be something that that uh took x and delivered uh you know cosine of x as the output but it could equally well be something that took a uh you know took a picture of an animal and emitted uh you know what animal it is and i thought that was a bit of a um a bit of a spurious uh illustration of what a function might be because i i didn't think that such a function was physically realizable um and of course i was proven wrong by by convolutional nets but you know the question remains like is it really the case that we are just functions you know that we have some inputs and we have some outputs and and and that's that you know we're just the evaluation of a function um i mean even in our field we see some pretty interesting conflicting narratives between you know ai which essentially uh makes the rather grand claim that intelligence is about functions and regression that is the same modeling functions based on data and data science which is a very modest term right that really just says no no this field is not about real intelligence not about solving ai it's just it's just about you know doing a better job of handling data and modeling and understanding data we call these things that we make models we don't call them brains so there's a modesty behind that but you know many of us really do want to solve the uh the big the big problem right what about it what about intelligence for real you know these these narratives are very different um so yeah everything we've been talking about is just regression it's modeling p of y given x or p of x if it's a generative model or an unsupervised model uh we don't call them brains or people uh at the same time in the more kind of popular press we see this ai narrative of um you know uh models surpassing humans at one after another task othello and checkers and in the 80s and 90s uh to uh you know to starcraft and poker more recently and that that very much leads to this you know oh my god you know the robots are taking over ai is coming uh sort of story but um you know what i think it's kind of hard to avoid when you look at that list of successes of models is that they're all about passing a test or winning a game uh in other words we are now at a moment where if you can take a task and break it down into something that can be scored uh that it's a well-defined problem that has a well-defined metric uh for merit uh in other words a loss function that we can define for it and we can gather enough data then we can build a neural network that will achieve superhuman performance of that i mean i i think we're kind of running out of problems that you know that satisfy these criteria and that we can't you know build a network that will just kind of crack it it's actually remarkable to me how little territory this actually covers um it's not how most of life works uh you know and you know if you if you're if you're learning by the way how to drive right you don't have to crash the car a hundred thousand times uh in order to figure out how not to do it uh the way uh the way uh the way learning works today but also you know what what is the loss function anyway for how you hire people in your company or what's the loss function for criminal sentencing or you know what's the loss function for for a couple's therapist you know or for or for evaluating good art versus bad art i know um you know schmidt huber tried to make lost functions for good art versus bad art but but i i respectfully uh think that that's um uh not only the wrong loss function that he defined but uh but a but a problem that is actually not particularly amenable to making a loss function for so yeah a great deal of life is not actually about winning a game uh or uh or or um or a test or passing a test or achieving a certain score um and that's true even a very workaday sorts of problems that we face all the time in in machine learning engineering and practice like you know how to rank notifications in android uh you know what is the figure of merit what is the loss function a lot of the a lot of the the really big problems that we have created for ourselves as a society um you know stem with with computer science the past few years stem from uh loss functions that are trivial like maximizing engagement uh you know with a facebook news feed or with youtube or whatever when in fact um you know there is no simple function that that you can optimize that won't result in in a crappy outcome uh and i i want to point out this is not just an advanced human issue it's not it's not something that is unique you know to um you know to things with big brains like us the way uh patricia churchlin put it in a quote that i really like is the success of artificial neural nets not withstanding it must be acknowledged that their behavior is a far cry from what a rat or a human can do as they live out their lives on the planet all vertebrate species are able to detect threats and to behave appropriately in response to motivations to survive thrive and reproduce in this domain as well as maintaining homeostatic functions there are typically competing values and competing opportunities should i mate or hide from a predator should i eat or made should i fight or flee or hide should i back down in this fight or soldier on should i find something to drink or sleep and so forth go ahead and market something as intelligent but if it's brittle lacks flexibility and common sense and there's nothing approximating motivation or drive or emotions or moods it may be difficult to persuade the rest of us that is intelligent in the way that biological entities can be um so i i really i i buy this i think i think uh uh pat churchill is correct um and we can look at some of the very very simplest life forms on earth and see this at work uh so these are um bacteria these are e coli uh you may recognize uh some of them are in the process of mitosis of reproducing um for those of you who are unfamiliar with e coli and how they work uh they've been the subject of a lot of really uh important biophysics um uh experiments and theory uh in um in the past 50 years and they they have these uh filaments that come off them uh these uh these flagella uh with motors at the base and and the way the way they work is that if if the motors rotate one way then those flagella all bundle together and form a corkscrew and the thing swims and it kind of swims forward that's called a run but sometimes the motors all reverse and and when the motors reverse then the flagella unbundle and uh and they flail around uh they don't kind of corkscrew together like this and and then the bacterium executes what's called a tumble meaning essentially it randomizes its orientation so uh bacteria are a little bit like those those old radio-controlled cars that can only go forward or backward and turn um you know and the um the forward mode is run and the turn mode is tumble and the turn is random so if you look at an e coli swimming its trajectory looks like this a series of runs alternating with uh with tumbles or randomizations in in direction of movement howard berg in the 70s uh did a bunch of theoretical work on chemotaxis and bacteria and basically showed that with just this one bit control of running and tumbling ensembles of bacteria can actually do a really good job of following food around and and the basic trick is that you run more when the food is declining or low and you tumble more when the food is high and if you do that then statistically you end up with kind of distribution of bacteria that can follow the food around this is a little simulation to show you how this works so um so here those uh those green guys are bacteria and and what i'm what i'm doing is having them learn through evolution how to do chemotaxis so um so what you what you see is as a the the red is uh is food and this in this simulation uh if they um if they are in the red they're eating uh and their energy goes up uh and if they're not eating their energy is going down if their energy goes down to zero they die um and if their energy goes up beyond a certain threshold they they get to reproduce um and what you see on the on the right hand side is uh is a row of uh or sorry uh yes a row of values for their uh q table uh for each bacterium i'm gonna i'm gonna replay it so you'll see this a little bit more clearly so the q tables all start off random and and they the those q tables just map the uh the sensory experience of the bacterium to action to the one bit action uh runner tumble um they're not doing real uh reinforcement learning which you'll be you know you're you'll be learning much more about this later in the course but um but they're just they're just following a a cue table that maps observation to behavior and um and what's happening here of course is the ones that uh the ones that that don't have working queue tables will all end up dying off and the ones that do have working q tables will survive and reproduce which is evolution and there's one more thing in this little simulation as well which is that when two bacteria touch then they might exchange a little tiny bit of their of their of their q tables and that's something that bacteria do it's their version of sex uh that's um so that that that kind of exchange of little bits of of of dna is one of the ways that um uh one of the ways that that evolution happens in bacteria beyond just the reproduction of the individual so they they learn how to do um how to do chemotaxis as you can see um yeah those are the rules in in detail conjugation is the name for the exchange of the little bits of of dna and there's some random mutation throat as well cosmic rays so um oh and i guess i should have said also that that because uh most of them die more random ones are thrown in when the population goes below a certain threshold so so this is um this is learning through um through evolution now the question is is the thing that has been learned optimal because you know if you're a machine learning person then you're probably imagining that there is a loss function here and that and that i have just implemented an optimization procedure for learning via evolution there are you know plenty of evolution inspired optimization procedures like uh cma evolution strategies um and um uh you know and and this is really just uh this is really just a you know a standard kind of regression problem but being done by other means by by evolutionary means but here's the thing um i didn't put in what the loss function actually was right so so what is the loss function system like this i mean really all we said was you know if it persists it exists uh and if it dies it dies so um there are plenty of papers there's a rich literature about you know what um a bacterium might be optimizing when it's doing chemotaxis this uh um uh strong freedman bialic coburn paper from um uh uh from the um i don't know if this is with the 80s or the or the nine this was 90s this is 97. uh you know posits um sort of optimality of of of food eating right essentially you know a bacterium should eat the maximum amount of food possible that's that's what it's optimizing for okay so what should its chemotactic strategy be with respect to running and tumbling and you know the the the predictions do roughly match with behaviors but um uh but but the thing is that if you if you want to try and ask directly what has been optimized uh this actually looks like an inverse reinforcement learning problem so um so i'm going to kind of turn the problem on its head a little bit and say can we can we invert uh the the learning procedure here and back out what the uh what the reward function would have been that would have resulted in um in in these bacterial learning what they apparently have learned through this evolutionary process so that is the inverse reinforcement learning problem um and uh and and the way we're going to solve it here because it's actually quite ill-conditioned is um is via a a kind of cheat a hack and the hack is that rather than having uh q tables be the things that uh that the bacteria are are um are learning in the sense that that's what they what they have and what they carry on it's actually going to be reward systems that they're learning so i'm now showing you uh some some little artificial bacteria that have a um that have a different uh sort of universe they have food and they also have the ability to emit a chemical uh which is uh which is rendered here in blue and they have the ability to sense that chemical uh there is no um there's no uh sort of specification in the system by the way of of what um of what that chemical actually um uh you know should be used to do what it means right they they kind of figure that out for themselves but um but the point is uh sorry i'm just re-running the simulation here uh the point is that they uh they figure out how to use the chemical they figure out how to eat uh they have a two-bit output now a mid-chemical don't admit chemical run or tumble and um and they're now individually learning via reinforcement learning um and there are a number of different events that they can that they can observe happen in their lives um mating the encounter of another bacterium eating the encounter of the chemical um hunger meaning that their that their their food supply is running low and um or um uh or satiation right uh so so uh imagine that all of those are events and that they get a reward positive or negative for all of those things they start off with um uh with with reward systems that are entirely random that are arbitrarily positive or negative for all of those events and the ones that survive and reproduce are the ones whose reward systems are actually uh good reward systems for um for learning what they need to learn so it's a learning to learn paradigm if you like with evolution thrown in and um and they do learn how to do chemotaxis as you can see um and uh and this is the second half of the simulation which i which i've replayed now a couple of times uh is is just sort of figuring out a little bit about what they have learned uh with respect to the signal like what is what is that signal being used to do um that extra chemical uh what it turns out they they learn how to do is is um signal each other collaboratively so they can follow each other each other around um and um and so as a sort of rudimentary form of sociality is learned as part of the reward signal for these bacteria so um if we do this many many times then you know the question is all right what is um you know what is the optimal what has been optimized for what is what are the rewards uh this is what the answer uh actually ends up looking like so as you might expect um death uh gets a negative reward uh they don't like death they don't like hunger they do like eating they like sex they like food um so you know all the things that you would expect um emit by the way the most negative thing this is uh this is actually um the signal this is this is signaling because signaling is costly i forgot to mention uh when they when they signal they also lose energy faster than they would otherwise um so that that that comes off as a as a negative reward and positive rewards come from from from living and from reproducing um but um but the error bars i think are in a way more interesting than just the uh the the means all of these are viable um uh bacterial populations that emerge from this evolutionary process uh so some of them love death uh and um and some of them uh um you know hate uh food and actually are repelled by food uh you might wonder like how on earth can a bacterium that is repelled by food even even survive but they they do uh if they uh if they love signal in some situations so there are actually all sorts of reward systems or all sorts of things that can be getting optimized that are viable in the work and when you look at um at the different populations of bacteria that have that have learned different kinds of rewards or different emotional systems if you want to think about it that way they have different collective behaviors some of them have very small but very stable populations some of them have um large populations do a lot of exploring versus exploiting um you know so you get kind of like a wild range of different things and and and what i what i hope this starts to uh to to make clear is that it's it's pretty problematic to think about um about all this just in terms of of regression and optimization like we don't even know what on earth these things are optimizing when we try to measure what they're optimizing we find that there isn't a single thing that they're optimizing for i've done a lot of experiments that i'm not going to have time to show you that involve putting these things into a jar together you know so what happens if you evolve a bunch of these things separately and you put them together and the answer is you get sometimes competition uh sometimes cooperation you get different different uh bacteria that might occupy different evolutionary niches if you like and learn how to work together in certain ways um so you know it's it's it's wild and it's all of the things that you that you uh expect from nature um and none of it looks like optimizing a function so you know what persists exists evolution decides on what is good and bad uh or better and worse or better and worse versions of good and bad it's not exactly optimization um despite the fact that we do have evolution-inspired optimization algorithms um and and and the the reason that you can sort of see immediately that it's not optimization is that the moment you have two entities together in an environment like this even if they were both trying to optimize for a specific thing you already have something sort of like a gan uh right so again a generative adversarial network is an example of what happens when you take two systems that each are trying to optimize something but but one of them isn't that they're interacting with each other one of them is is looking at the output of the other one and vice versa so in such a again um you don't have something that looks like uh like the gradient like gradient descent whatever you instead have is a dynamical system in which you have uh pursuits and spirals and uh um uh and chaos sometimes uh and so on and you know anything that looks like spiraling anything looks like it has vorticity tells you right away that it's not gradient descent because um uh because whatever whatever loss function it is that would be uh would be descended in a gradient system that would be the uh the integral of this thing and you can't integrate something that that has vorticity in it right this is not the gradient of any function i mean these are steam gans uh don't even uh um uh don't even have you know have an infinite number of of limit cycles even so you know this is not this is not something that is that is optimizing anything so locally each actor is doing gradient descent of its own with some well-defined loss function but when you put them together the combined thing is no longer doing gradient descent and we can't in general write down the function that's being optimized anymore and life is like that at every scale uh it's it's sort of like the general relativity of of of loss functions in the sense that everything is perturbing the environment of everything else and so you know where we might have thought about uh just a function getting learned and optimization of that function the state of the art result and so on as being like an isolated particle or special relativity you know where the space is fixed relative to the particle real life is that every particle is influencing every other particle and we actually have a kind of curved space and the dynamics of movements in all that curved space are life uh not not not optimization there are many solutions many niches signaling begets collectivity the environment is each other the question even of whether we're looking at one organism uh one super organism or lots of independent uh you know organisms all competing or cooperating with each other is not actually very well posed you know it really kind of depends on how you look at it so um so yeah optimization is not how life works there's no external arbiter saying what is good or bad it's just you know like what what persists gets to stick around and play another round and by the way it's also not how brains work uh and i i don't you know i i'm definitely not enough time in this in this lecture to kind of go into some of our uh meta learning uh research on on on brains and on how they work but but if you think about a brain as being a collective of neurons that are all talking and signaling to each other which is after all what brains really are um and losses as being the propagation of of signals back uh you know it's it's um it's it's one it's more like life than it is like uh like regression uh i guess is the short way to put it you know we we only think about the function as being the thing that in the end does inference uh but that sweeps under the rug all of the learning processes that are actually used to train those functions up and when you start to think about the learning processes as being part of what that brain actually does then you realize that dynamics and feedback are um are inherent in um in in what the neural network does as part of its learning process and that's in turn contingent or dependent on the environment outside of that of that brain um and um and you're no longer in a world of of of things that you can think about it's just uh it's just functions that optimize something there's always that that presupposes an inside and an outside that don't exist in real life um so okay i'm gonna i'm gonna um uh skip my few remaining slides that have some more mathy bits in them and maybe open it up to um uh to discussion um and uh grand challenges uh so um the um you know some of the grand challenges that i think we we uh we face now um are you know how it is that um that that in this kind of multiplayer universe of lots of ais lots of intelligences that learn together i love federated learning how it is that we can talk about privacy and agency and so on in a distributed environment like that um also if we have um uh if we have brains that themselves uh evolve in their not only in their architectures but also in their learning rules uh and in how it is that they learn from each other how does that all work uh how can we characterize uh how um you know how learning occurs in environments like that um how can we think about artificial societies as being things that are engineered in order to create certain kinds of outcomes um large-scale meta-learning in the federated setting is an especially interesting crossover i think between the two things that i have alluded to and talked about um how does one engineer artificial ecologies uh how does one think about about bringing dynamical systems theory back into the picture when one thinks about learning in order to understand better how how learning happens in ensembles can we define state of the art can we define soda in a meaningful way for social environments uh because you know the asocial environments that we have right now i think we've kind of already played them out we've determined that we can make any damn function we want but we're not we're not uh we're not any closer to making things that are truly uh intelligent or alive um and maybe even more fundamentally can we do work as a research community without relying on um on these ideas of state of the art of soda how do we do the equivalent of hill climbing or complexification ourselves without it without it being uh you know a game with simple rules uh as it has been uh with things like the cfart challenges and so on and uh finally uh if we think about ai ethics uh and other related concerns in this kind of curved space uh uh environment um you know we that that poses its own very special set of challenges i've only alluded to the problems of machine learning fairness and ethics but but obviously those are those are heavily implicated in everything that i've been talking about so i'm getting hoarse and i know i've tried to cover too much territory i will stop there and uh it looks like there are some questions on the q a uh how so how should we how should we handle this uh yeah so we can just go through the list um what we did last time was actually call on people to ask their own questions even though they've gone ahead and written it here and we'll get through as many as we can and then from there maybe you can answer a few offline after we're done here yeah that sounds great by the way well thank you very much it was it was excellent i truly enjoyed your your presentation and so maybe yeah let's let's just jump right into the questions um so yeah so i guess uh bhargav are you there yeah do you want to ask your question oh can you increase your get closer to your mic now now it's clear yes so my question is our brain generates neurons and uh okay uh so all right we can read it upload yeah yeah yeah yeah then like as we learn in practice but in deep learning yeah you're unfortunately kind of cutting in and out so i'll just go ahead and read your question you write uh our brains generate neurons and connections between them when we learn and practice in deep learning we have a fixed architecture of the model so can we say that having a fixed architecture is creating a bottleneck for human level or general intelligence in a.i yes uh yeah i think that it is um so there are a couple of different approaches um you know so so in in of course um in well i i should also say something else which is that in real brains there are of course a lot of strong constraints on what is connected to what uh that are coming from um uh you know from the the from physics right from just like what is close to what so um you know in in deep learning we um we can think about uh dense models where everything is connected to everything and and it's all a weight and um and and you can imagine essentially every conceivable kind of model as being just you know a subspace of of those kind of dense or fully connected models and when i say denser fully connected models by the way i mean more than just um you know dents from one layer to the next i mean a real brain um you know doesn't just have layers it doesn't just look like you know a stack of one layer connects to another it's literally like any neuron can connect anything else and um and that's one of the reasons by the way that back propagation can't possibly work in a in a real brain you know you have to be thinking about you know about signals for both what we think of as feed forward and what we think of as the learning signals propagating to various other parts of the brain um but the the way we can um i believe the way we can think about architecture search and learning um as part of the same framework is to imagine that um uh that that there are um genes if you like that uh that actually grow brains and that growing and learning are are just two different time scales of the same sort of process uh there's a beautiful work that alex morvinsev and collaborators have done with neural cellular automata that are worth checking out that that that um that explore what happens when you allow you know structures to emerge from learned patterns of cellular automata so if you imagine you know brains getting grown as soluble automata and and the selection criteria on you know certain brains that survive is one that can do a good job of learning and learning together i think that's the kind of path forward that feels to be most fruitful great um so i guess um do you have uh can you uh maybe ask your question live you're top of my list here yeah i don't know if i can allow you to chat or not okay can you hear me okay yes okay thanks um i think it's more from uh a industry perspective because when we talk about scale big machine big data we definitely want to leverage some picture picturing model but oftentimes we see that it's not adapting to our local data set or our specific problem that well that accuracy is not very satisfying so i'm just wondering like what would be your suggestion for that probably not a fixed rule for that but i'm just curious what would be your first thought or like some solution for this case if you are in this situation yeah it's a great it's it's a great point and one that really really converges on on the questions about equity and ai as it's being done today because of that very very brute force approach right so um you know one of the things that's so interesting about gpt3 is that it can pre-train with vast amounts of data and allow further data or or fine-tuning uh that that make it work for a specific uh scenario but none of that all of that fails of course uh if you're if you're working in a domain that wasn't well covered by the by the vast amounts of of pre-training and um you know that speaks a little bit to what i was saying earlier about you know like you don't learn to drive a car by crashing it you know 100 000 times there's something very brute force and extractive about the way we're training these models today that just feels like it's um you know we might we might be coming out with functions that are actually quite close to certain you know functions that do end up in in human brains but we're doing it in a way that is massively inefficient and as long as we're doing it in those massively inefficient ways we um we are going to have a serious equity problem because only the uh the parties with the resources to do that kind of massive brute force training will be you know setting up the priors right like what language is this being done and or what domains is it being done and you know who's internet is it being done and which rapidly it's trying to look like not not just one internet anymore right speaking to the fragmentation in china and india and so on um so yeah i they're they're i think they're profound questions and i don't have a practical solution for you given current learning paradigms but i think it really speaks to the need for looking at different learning paradigms that are not so brute force right for sure thanks let's take um i don't know this is yon or joan uh um if you can yeah you should be okay uh yeah it's yone it's a weird finnish name um yeah so mike my question let me just find it here um right so i'm wondering about the sort of current state of these uh this edge device uh machine learning you kind of answered my first question which was going to be about uh whether they can be trained on edge devices that can happen via federated learning but i'm wondering if there's any sort of advances in the forward passes we do uh on on the edge devices like can we do some bayesian stuff like can we incorporate uncertainty in our outputs or or stuff like this because i mean uh bns with with stochastic weights those those can be uh pretty tough to work with and you know if you doing mc high dimensional mcmc on a on an edge device seems like a daunting task so i'm wondering where we stand where we're at with that yeah it's a good question and it's it's really at the interface of of the physics of how we do uh you know sort of neural computational edge devices and um and algorithms and and and the the you know the state of our theory about these things so um you know we we uh we certainly are looking at non-traditional you know kind of analog computing uh you know and stochastic kinds of of operators right that can potentially be you know work at much lower uh uh uh much lower energy um uh or um or use a lot fewer transistors i mean the idea that the idea for example that you're using um uh arithmetic logic units essentially add and multiply or max multiply accumulate unit units in order to evaluate neural nets is kind of crazy right because those things are designed for accounting they're designed for you know the number being being precisely correct at the end of the story and we know the number being not precise you know the number doesn't have to be precisely correct uh you know that's why quantization works so uh you can use a lot fewer transistors uh if you um uh if you allow you know for that lack of precision and do things more in the analog domain and use other components there maybe not even transistors but memristors and so on um and then and then that that requires that you rethink uh of course your training algorithms and your and and your um and your inference protocols as well and you'll be able to simulate those effectively so you can really experiment with them and develop new theory so um all of that is super interesting um you know uh uh i i don't know if that quite addresses spot on your your question i mean there you talked about about you know mcmc kinds of techniques that that um at least the way they're done today are are really hard to do on uh you know on a single edge device or to or gang together lots of edge devices to do that that is true um but you know the the design space is i guess what i'm saying is the design space is yes a lot bigger than we than we normally think about it as and and thinking in a more embodied way about what is actually possible to do these devices opens a lot of doors thank you great um there we go hi uh yes can you hear me yeah so uh you mentioned that we will have npus in the future and they'll be able to do analog computing so i was wondering what is analog computing yeah yeah that's what i was just referring to i really just mean that instead of representing uh say values of activation at an artificial neuron as a floating point number or a fixed point number it can be for example the charge of a capacitor um and uh you know and so you know if you if you do that you can shrink the number of components a lot uh it also means that you're that that things lose precision a little bit and lose the ability to you know to characterize fully uh the way you can with fully digital logic but um but if it means an order of magnitude more neural computing that's you know at an order of magnets with less power that's a pretty good trade-off i see where would quantum computing fit in all this i don't think it does um i i differ from hartmut nevin uh my my uh my very snazzily dressed and clever colleague uh who runs the quantum computing effort in this regard um you know hartmut is uh uh you know well i think i think i've finally won the argument of like brains don't really use quantum computing if i can start with against which is not to say obviously the quantum effects are not relevant to how brains work i mean without quantum effects there would be no atoms and so on so obviously we use them in that sense but um but we know that we know that um uh you know that insofar as our brains are mysterious they're not mysterious because of quantum spookiness i think that's pretty well established um i i you know the hardwood claims that that it may be possible um uh maybe not to speed up inference but perhaps to speed up learning via quantum tunneling so think about about about the optimization problem uh in in ways that quantum tunneling benefits learning in some way the the trouble with that um it's a long discussion but the very brief version is that quantum tunneling only works if if you have a kind of pin cushion like energy landscape with lots of very skinny energy wells and thin barriers between them and uh that's not the way uh training landscapes work for uh for neural computing in general they they're they're bigger and they have uh you know mountains that you have to tunnel through rather than thin walls you have to tunnel through so it's not clear to me that that the quantum computing is going to be useful uh any time soon for either either the inference or learning passes in neural computation but obviously who knows i mean there may be some discovery that turns all of this on its head thank you all right and then we'll give the honor to the last question we'll squeeze one more in uh maddie can you select one of your questions uh yep so this is gonna be pretty hard um so i this is super interesting work it's actually like really cool where again i'll find out more about uh the experiments on like essentially the learning the reward function and as a kind of like a combined question um what are your current intuitions or thoughts on how the local like optimization affects the global optimization because that is a like a key problem in learning it is um yeah okay you've cheated you've asked all of your questions um so um first of all with respect to like where do i find out more um yeah we're actually quite behind in in in publishing some of this stuff and and to be honest part of why we're quite behind in publishing it is because it's it's you know we don't have state of the art results for a lot of the for a lot of the of the sort of more wacky techniques that i was talking about later in the talk um you know partly because they weren't really designed to generate state-of-the-art techniques insofar as they are state-of-the-art uh the the way they are state of the art is generally learning from very very small numbers of examples very very rapid convergence um you know and that's and that's true of a lot of learning to learn type schemes that you know they really shine uh in in the small n uh domain of of samples but um but you know some of this is really just sort of like you know some fairly profound like trying to work our way through you know these these uh you know so very fundamental questions like what does it even mean to make progress you know right how do we how do we know that we're doing something worthwhile uh you know as we as we start to experiment with some of this stuff which is obviously relevant in the sense that it it obviously breaks some of the assumptions that are obviously wrong in what came before but but in the process of breaking through those barriers we've also kind of like broken our compass you know we've broken our our our our ability to know when we're actually making progress or not so we're we're trying to feel our way through that right now um you know there are there are um um there are some public so you know any anything anything um you know alex morgan savvy you know he's more aggressive about putting some of his stuff out there uh not via traditional publication methods there's distill dot uh pub you know kind of things that are pretty cool uh michael evan has done a bunch of work in biology that i think is extremely relevant to this um and there's some collaborations that we have with along those lines um and uh and as for the um as for the federated learning federal analytics and and the the challenges of all of that um we we've been running these uh small workshops on federated learning uh in recent years um that are worth getting hooked up to a quirkshop and i think i believe there will be one at nurips again this year um that will go into a lot of those questions in in in great in great detail uh so that's a very active community um and one that is one that's worth connecting to to understand some of the some of the things that you're raising cool all right well thank you very much uh we're gonna have to leave it there um but blaze thanks again for the excellent really insightful talk and i'd like i'd ask all of our our participants to to think about the things you've heard here today because my own experience uh the kinds of stuff that he's talking about is just becoming more and more true as the as the research community progresses to ever more complicated problems and it's uh it was amazing how many things that just during your talk that i was thinking about that these methods that are you know state-of-the-art methods where the objective function doesn't at all describe the way in which it works and so there's plenty of fascinating to connect those thoughts so anyway thanks again uh it was truly a pleasure thank you thank you thank you so much it's really really uh really my honor and uh yeah i i hope this generation uh you know figures out some of the things that have eluded the previous ones because figuring out what what comes after optimization feels to me like the fundamental problem of of post-capitalism and post-human population growth and many other things as well i think these are really profound waters yeah so so yeah it's on your shoulders guys thank you so much blaze i just wanted to add that he will be back because i know there were a lot of unanswered questions but we do have a breakout um with blaze at 4 15 so we'll try to carry over those questions left unanswered into the breakout later on today thank you again and a quick break we'll meet back with marco baroni in 15 minutes 