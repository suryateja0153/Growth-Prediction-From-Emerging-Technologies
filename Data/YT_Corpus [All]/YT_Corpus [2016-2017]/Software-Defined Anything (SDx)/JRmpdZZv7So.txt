 two years ago the guys from Renesys were here to talk to you about maybe gb instability they observed during the code red worms and the NIMH to worm I remember there was a lot of skepticism about at the time about why this should have happened or what the cause was since BGP is supposed to be immune to to a congestion or not dependent on congestion measurements they came over and talked to us at the same time at Dartmouth because we happen to be in the same small town up in New Hampshire and we were interested at the time in a variety of or capturing a number of indications and warnings about global internet health so we decided to look at BGP in addition to some of the other areas that we were looking at having to do with scanning worms distributed honey pots looking at ICMP scan traffic a number of different methods that we were looking at to get a global picture of what was going on in the internet so we looked and looked and looked at BGP data for a long long time and nothing interesting ever happened until January 2003 of course stuff was happening but nothing interesting from a global perspective until January 2003 when the slammer worm I came along and I think pretty much put to rest any notion that there there anywhere any doubt that there was a relationship between scanning worms and and bgp instability I started look at the data and I wanted some way to compare it to previous worm epidemic specifically the Code Red in the Nimba worm epidemics and I had no yardstick there was no standard measurement for me for which to measure these things so that's what I came here to talk about today he's down so everyone has their metrics measure of measures and indicators in in biology we talk about vital signs like blood pressure body temperature pulse and respiration meteorology has your standard measurements seismic economic indicators and nearly every field of study there is a state vector that you can describe the whole universe with in the most reductive it's still useful it's useful because otherwise we wouldn't use these numbers and we're familiar we're all familiar with these numbers we here's my normal daily basis but in our field of study and internet health internet stability there is no such a collection of standardized metrics so here if lacking that standard yardstick how do we compare the events that traumatized the internet how do we compare their various effects on on things like stability events like scanning worms or September 11th or the Baltimore tunnel fire or the Northeast blackout how do we describe and monitor current conditions as well so how do we say what is the what is the current conditions on the internet right now we still don't have a vocabulary we don't have a standard list of metrics that we can use so if you're on that land on mailing list and something's happening people are saying I'm seeing a lot of activity or I'm seeing this this kind of activity but there's no number that they can point to so there are a variety of ways to actually look at the internet and say what is it state right now there are commercial companies that everybody's familiar with the measure packet loss and latency we can talk about traumatic events in terms of the availability of services like email and web services and an inter domain routing we probably are reduced to two areas and that stability and and reach ability so moving towards some kind of standard BGP metrics and I'm here not here to propose a standard and I'm not here to propose that the way that we're looking at is the only way to looking at it I'm just throwing out the idea that what we need we need to be working towards it some kind of standard yardstick whatever metrics we come up with should be reductive reductive is a bad in one sense if you lose detail you lose insight on the other hand we have to dampen some transient you're not phenomenon if we're talking about global internet health the things like reset spikes and all the other sort of things that can cause local routing and stability are not sort of things that you want to be strongly indicated in a global indicator we want to look at widespread phenomenon and it should be on some kind of standardized scale so again going back to the two areas that I think BGP is useful in looking at our instability and reach ability instability could be based on Route flapping or it could be based on the time density of rude announcements and withdrawals just looking at updates per minute reach ability can be based on tiles table sizes measured in the total number of IP blocks which is up around 130,000 these days or it could be further extrapolate to the total number of IP addresses in a particular table there are problems with both of those methods and I'll try to touch on that so after the slammer worm I tried to come up with some kind of metric that I could use to standardize and measure these things so given nbg peers and bgp peers i have BGP peering relationships a with 10 different routers that are scattered across the globe topologically and geographically dispersed so for each peer each one is feeding me data i'm not a router now i'm just a collector I'm an observer for each one of these peers I want to calculate the local weighting factor that tells me how active this local router is and so what I do there is I I just simply take the hourly average of activity total updates and withdrawals / or announcements in withdrawals per hour and I take a thousand divided by that factor and that gives me a pretty good number we call that w for each one of those weights then we have for each peer we count the announcements in withdrawals per minute over a 15 minutes sliding window now why we use 15 minutes while I experimented with it empirically on data that we were looking at over the course of ordinary days and extremely active days and what you find is that if you go 30 minutes you dampen out a lot of the the transient stuff but you also get a lot of time leg now it's 15 minutes before anything is indicated because you're looking at medians and you could go smaller like 10 minutes or five minutes but then you're going to get a lot of false positives so I chose a 15 minute window because it seems to me to give me a pretty good compromise between false positives and I use that that that value that medium value to calculate the local instability index where the local and stability index is just that weighting factor they talked about a thousand divided by the the hourly average x the the median for updates and withdrawal for the past 15 minutes that gives me a local instability index for each one of my peers and then I just take the median of that so I started out just looking at that as a way to to understand what was going on empirically what I found is that values between 0 and 50 on this scale that we developed we're pretty much normal instability on a daily basis you'll see your values go up and down from 0 to 50 not indicating any particular kind of stress when you see values go from 50 to 100 you're talking about unstable conditions and values over 100 are very high instability you know that something serious is going on because of the 15 minute window as i said the instability tends to lag by about eight minutes of significant events the what we found also is evaluate values calculated with very different data sets for instance the right / posit Ori and the Oregon roop use repository extremely similar and I'll show that in a second and the high water mark for this index we has no upper bound much like the Richter scale has no upper bound it's 536 which was at 1248 eastern standard time on january twenty fifth which of course was the slammer alarm the slammer worm you can see there right actual 1230 eastern standard time they pretty much goes right off the chart and then drops down during the course of the day / course of about 19 hours and also you can see that in green the ripe data and blue the Oregon data are very very similar in fact similarity is 98.6 percent for this particular day so this shows two things not only the the worst instability that we've ever seen since we've looked at this but it also shows that the the global instability index using very different data sets yields it's very similar results so when now we go back and we look at the code red instability on its worst day which was july nine 2001 see that pic peaked around 160 you see the day started fairly normal and it was until after noontime eastern standard time that the value started to creep up until they peaked around 161 ninda very similarly stayed stayed pretty quiet in the beginning of the day and then carrot uncharacteristically just shot up to the 100 level right after looks like about eleven o'clock eastern standard time on sep tember 18th 2001 so putting the three of the three really bad days on one slide so you can kind of get from perspective you see the slammer worm is easily the winner of the mother of all of scanning worms in terms of global instability other events not just scanning worms that cause global instability on the morning of july seventeenth i was awakened by my beeper because i have it now set to go off anytime the global instability index exceeds 100 and at two o'clock in the morning my beeper went off anybody guess why it's your responsibility you guys did this to me you guys were patching for the iOS vulnerability and basically inducing massive amounts of global instability so two o'clock in the morning I got on my keyboard and wrote to my friend's apartment of Homeland Security and said the internet is under attack and they wrote back and said you're an idiot so it turns out it's pattern repeated itself or three days right after midnight eastern standard time everybody started taking down the routers and the little piece if you look at it in more detail actually kind of correspond at the top of the hour which more or less suggests scheduled maintenance then so we were ready for the really the killer worm the the decon vulnerability had been released the same day as the I think the iOS vulnerability in July sixteenth and we SAT waited for the killer one that was going to come we were ready this time and the blaster one was released on August the eleventh and nothing happened absolutely nothing happened for three days nothing happened we SAT and we watched the global instability index and we saw mild instability you can see that in a couple instances it Peaks up around the value of 50 and then suddenly at 4 11 eastern standard time on August fourteenth the thing goes up and hits 90 and that of course was the Northeast blackout and I was watching that at the same time seeing my mobile instability indicator go up and watching global reach ability go down and there again I watched my friends at the Homeland Security Department and said something happened that I don't think it's a worm and sure enough five minutes later we turned on CNN found out it with the blackout if you want more information on that there's really good report on the Renesys website about the BGP effects on global routing excuse me the the the global routing effects of the blackout so I said that this reach ability was another area I'm sort of working towards a global reach ability index as well this shows what the global reach ability index kind of looked like during that two day period it was a plummet and reach ability and here I just take the maximum table size for all the routers that I'm looking at and I divide that by its current table size that's pretty simple index and you can see that basically three percent of the internet disappeared at 4 11 p.m. eastern standard time and then slowly came back over the course of about 24 hours a very similar profile basically happened during the slammer worm in this case it was not quite three percent of the internet that disappeared but it did plumb it off pretty quickly after slammer worm start to disappear and came back slowly over the course of the next 17 18 this chart is smooth because i pasted it from a pitch that i was giving to executives and they can't handle squiggly lines so here in summary i suggested that there are some beats and metrics that can be derived from bgp that we should be thinking about ways to standardize our vocabulary so that we're all talking about things in some standardized way not that necessarily this is the only way to think about it I'm looking for feedback I'm here to suggest that we're looking at this and if you have any suggestions on this please write to me Dennis not McGrath the dartmouth edu or condor at dartmouth edu there are other ways of looking at internet health and we're also looking at those and you can look at our net watch that is TS dartmouth edu website and see some of the other things that we're looking at including a packet latency and loss measurements scanning worm scanning activity honey pots as i mentioned earlier and finally we need data researchers always need data and we never have enough i have currently the ripe and the oregon repositories to look at I don't have a lot of real-time bgp feeds i'm looking at three edu feeds right now and that's great i actually get pretty good numbers with those three edu feeds but i also get a disproportionate contribution from internet too and last week there was a major instability event on internet too and it sent my global instability indicator haywire and again i wrote to my friends at department of homeland security and they said what are you talking about there's no problems here it turns out it was just a link between the abilene network in argentina and south america was just disappearing from internet to on and off for the course of about eight hours so if i could have more more bgp data more bgp feeds of peers in real time I appreciate the the data it would really help and I can't pay you for it but I can give you a t-shirt and if you come see me afterwards I'll give you one and that's it questions for Dennis thank you I had a question didn't have a question then um you didn't see anything from the blaster worm to have an intuition of why why didn't I questions why didn't blaster worm cause instability it it it appears that it didn't it didn't scan nearly aggressively as his predecessors obviously there was some some instability there it was kind of buried in the noise again you should talk to the guys at Renesys who look at this data much more closely than I do well chia actually which I didn't show the following week after the blaster were in well gia caused a little bit more instability than blaster did because it had all that ping traffic that was going around as well but both those worms didn't come near the the instability effects that observe at the previous worms seem to be mostly a problem behind the firewall and I'm not an expert in what blaster was doing or what it was trying to do but I certainly think that we haven't seen the last of the very aggressive scanning worms just at those two particular ones we're not fast movers the way slammer was thanks 