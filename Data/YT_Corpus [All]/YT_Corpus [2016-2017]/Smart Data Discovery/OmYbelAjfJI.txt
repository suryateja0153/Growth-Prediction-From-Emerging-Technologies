 Hello, everyone and welcome to today's session of the BD2K Fundamentals of Data Science webinar series, where each week we present a new lecture giving us a background in the foundations of data science. And it's a real pleasure to introduce today's speaker. Her name is Lucila Ohno-Machado. Lucila is Professor of Medicine at the University of California San Diego and Chair of the Department of Biomedical Informatics. Lucila has had a distinguished career. She received her MD from the University of San Paulo, received her MBA, went to Stanford in the 1990s, received her PhD. Musen, and I can say that I'm pleased that she got her PhD with me, which makes me very, very proud. Lucila has lots of honors. She's an elected member of the American Society for Clinical Investigation and a fellow of the American College of Medical Informatics. She edits the Journal of the American Medical Informatics Association. But most important, she directs a project through the BD2K program related to finding, accessing, interoperating with and using data. And that's going to be the topic of Lucila's talk this morning. Before Lucila speaks, let me remind everyone that you're all on mute because there's so many people listening into this call. As you have questions during the talks today, please put your questions into the chat box and we'll be sure that we can send those questions to Lucila for her comment at the end of the hour. And we're looking forward to hearing what Lucila has to say. Go ahead. Thank you, Mark, and thanks to the organizers for the opportunity to present this project, which is the Data Discovery Index Consortium that we are leading together with collaborators from the University of Michigan, University of Oxford, and also University of Texas Houston. So I'm presenting on behalf of all of them. And I'll try to monitor the question box as I speak. So I would like to start with the motivation for this. And this is one that I'm personally interested in. For example, a question about could I get all data about astrocytomas with TP53 mutations. And, in particular, I'm interested in the stage two type of tumors. Can I get images? Can I get medical records? Can I get other type of data so I could assess survival or I could assess recurrence in other items of interest? And, believe it or not, if you're trying to do that today, it is very cumbersome and you don't find everything that you should. So we started with the Data Discovery Index Consortium with the goal of helping users find shared data, build a prototype for data discovery index, a search engine, and interoperate in the Commons. So in accordance to the FAIR principles, our primary goals are to find and access data. And the other I and R are also desirable, but are not the total focus of our projects as of now. Our goal is to do for data what PubMed did for papers, that is make them discoverable and make them accessible. BioCADDIE started effectively about 1 and 1/2 years ago with our set of priorities. And I'm pleased to say that after 1 year and 1/2 we have a lot to show. This is a slide from Ron Margolis that he presented at our all hands meeting that happened just a few weeks ago. And he had the task to show others, or to show the bioCADDIE team, where we fit into the digital data Commons for NIH. And in his slide here, he shows this stack of items that are anticipated for the Commons and how data and reference data sets are such an important foundation for that, and with that, all digital objects as well with software, with systems workflows, and so on. And this is all on top of Compute Platform, which can be cloud. It can be high performance computing clusters. So in this slide I just show my view that pre-curated data turns into curated data. And it's annotated as metadata are included. And then analytics happen. In analytics, it is the priority of many of the BD2K centers of excellence. And this is how it all ties together. They are hosted in a cloud, a cluster server. In our case, we do a lot with HIPAA data, not necessarily in bioCADDIE, but in many other projects, that is human subjects that needs to be protected with a certain type of regulations. And it's often the case that you combine this data. So in my example, you are looking for medical records determining the rate of recurrence, the survival of a particular type of tumor, so you want to combine publicly available data with HIPAA compliant data. And then when you join items, you create another dataset. And that other dataset can also be annotated and be pre-processed and entered into an analytical process. So that's why I believe it all comes together and we should join forces in terms of indexing all these objects so we can reuse them and can make the analysis reproducible later. And journals and publications are not out of the loop because they are the end product of all of this. And they're a little bit of a circle, in a loop in themselves. So the bioCADDIE project, the main components are working groups, metadata specifications, software development, collaborations, and administration. I actually proposed this project initially thinking it would be a research project. But clearly it was also an engineering and technical project. But most of all, it is a social project in which collaborations are critical and engagement of a large community makes the project much more impactful. So the way we view bioCADDIE and its Data Discovery Index prototype is that we will develop a search engine that people can access to show what is involved in getting digital objects indexed. This search engine, as with anything else, can be replaced by another search engine, another front end, and so on. But what's important is that the data and the objects get indexed in such a way that this search engine can find them. Additionally, we want pilot projects from other institutions to be integrated into the Data Discovery Index so people can develop different portions of this DDI. And together we get much further than we would otherwise. An important aspect, also, is that we want to index data aggregators. That means we want to index other indices. We don't want to reproduce that work. And, in fact, we want to make sure users can get to them when they are searching for particular objects. Like I said, in our case, we're searching across a wide variety of data types. And those aggregators tend to focus on a particular data type and are much more detailed than we would ever be able to be if we set out to index absolutely everything ourselves. So one example that will be given here is the Omics Data Discovery, the Data Index project, that I'll show. And it's in collaboration with the Heart BD2K center and with the ELIXIR colleagues. So what we have here is just another illustration of-- we have big data sets, for example, from the NIH conference that we will index, we are indexing at this moment. We are also providing links that are indexed to aggregator services. So this was a pilot project that Henning Hermjakob leads in collaboration with bioCADDIE and the Heart BD2K center. And it's the Omics Discovery Index. So, again, it has its own search engine and it has indexed Omics objects to a very high extent. So what we do is integrate with this aggregator, and, therefore, not replicate the work. But let's say we were trying my search. We would find the Omics datasets on astrocytomas, but we would also find images, hopefully, and find clinical data. So that's the goal of being an umbrella index for all those other ones that we help integrate. So the OmicsDI is one of several examples. But it's the one that was a supplement funded to the project and I'm happy to display here. There are others as well. So the goal is to get these repositories, the datasets, and the date aggregators, and adjust that metadata so we can do this uber index into a search engine, provide users with pointers, with results that are ranked in order of relevance to them. In order to do that, we have a terminology server that attempts queries and also a ranking engine. So some of you have seen our presentation at the last BD2K meeting. We were in the beginning of the road or in the middle here. And we were designing the prototype so we can showcase what the indexing is all about. Where we are now, this data engine, DataMed, is already deployed. And it's in version 1.0. That you can see. And together with it, it's the metadata, which is also finalized at this point. So the front end of data metalogs like this-- there are 23 repositories now, many more being indexed as we speak, 10 data types, 4 pilot projects integrated, and about 649,000 datasets at the moment. Also, at the bottom here you will see the pilot projects that have already been integrated with three more to come. And the way the pilot projects work is we issue a request for applications. And we have a peer review process and then issue subcontracts to the projects that were deemed most relevant and most integrable with bioCADDIE. And here we have a DataMed search engine, how it looks like. I encourage you all to go to DataMed.org and try it out for yourselves. There are filtering by facets, by data type, by repository, by accessibility, and authorization. And so keep in mind that in order to filter by accessibility, we do need to have the metadata about that. And that's why one of our working groups has focused on it. We can, again, filter by repositories, specific facets, and so on. So upcoming, our path ahead is depending on a variety of factors. But the goal was to make a difference in the way the data are shared. So we have a dataset retrieval challenge. We are still having working groups for certain items that we are fine tuning and integrating into the projects. So in terms of the working groups that I talked about, they are a fundamental piece of bioCADDIE. They relate to use cases. That's how we elicit it-- use cases through working groups define criteria for inclusion, define how we would deal with identifiers, define the metadata specifications, and what the graphical interface would look like, usability testing, and so on, and, importantly, also data citations and links to publications, and then finally, the evaluation. So these were all working groups that we created surrounding the Data Discovery Index Consortium so that we could get members from the community to participate in the creation of it. So one of the initial working groups is how we interacted with the other BD2K centers and other programs at NIH. So we had developed some supplemental projects-- I will present one of them quickly-- with other centers shown here. And there is one upcoming with links as well, and visualization, and ranking. As I said, there's often different modules that can be either incorporated to DataMed as a search engine or be a search engine in themselves. We also have been in contact with Common Fund program about datasets that they would like to be indexed. And we had joint meetings all through the streaming webinar. We also plan to participate in the called pilots. With the identifiers, we decided we will not mint identifiers through bioCADDIE, but we will use identifiers that fully resolve to an URI. And we should also maintain a set of landing pages for each of the datasets indexed, including forward ones that may no longer exist, so we needed to document the persistence of this dataset. The Identifier Working Group was led by Jeff Grethe. And there was a minimal identifier pilot in collaboration with other BD2K centers that is also ongoing, as well as Data Citation Implementation Pilot with the FORCE11 organization led by Tim Clark. This Data Citation Implementation Project was a supplement to bioCADDIE and allowed even more members of the community to contribute to our efforts. Another working group was led by Susanna Sansone-- very important, related to the metadata specifications and has gone through several versions. Now it's on 2.1. And the important thing to emphasize, it was derived both from a use case approach, which we call a top-down approach shown on the left-hand side, as well as a bottom-up approach, that is looking into what we had as metadata already and trying to reconcile several metadata strategies in order to come up with the minimal specifications for DATS, which is the Data Tag Suite, which is based on the same principle as JATS, which is the Journal Article Tag Suite. Meaning, at one point, once that specification is very well understood, data producers can submit data or submit metadata to bioCADDIE in the same way that journal publishers submit data to PubMed. So that's our goal. The working group representation was from several institutions. And some of them are listed here. And this is to say that it wasn't us deciding on the metadata specification, but consultation with many, many initiatives. We also did use cases and testing benchmarks. And there is a report you can find at how user analysis was done and usability tests. We also, as part of this, created testing benchmarks. So that's another contribution that we perceive as being long-lasting because it's a very laborious work in terms of annotating and confirming and validating rankings of retrievals. So this is now available. And it will be used for our challenge. And after that, it will be available to the community. So the use cases were essentially creating these benchmark data sets, instantiating the queries, running search engines, and manually annotating the quality of results. We also had a working group on Data Citation Metrics because they are important in order to reward those who share the data. And the goals were to have qualitative and quantitative metrics that would talk about issues such as when the date were produced, provenance, downloads, and then rank results, and criteria to restrict search that could depend on search metrics, for example, the most popular datasets, that is the most downloaded and so on. So this group dealt specifically with this issue. And the report is also available online. Another working group that is very important was to decide which data repositories we would index to get started with our search engine. And that is an important distinction between a search engine that simply finds everything. We wanted to convert at least some degree of filtering of quality control to which datasets appear, or at least in the order in which they appear in our search engine. So we have come up with some criteria here related to prominence, sustainability, scope, quality, and access, and also with a repository submission workflow so that repositories can approach us or we approach them. And then we work out on how we should automate this metadata mapping into our specifications and how to exert quality control into the mapping and so on. So, again, anyone who has a repository out there who wants it to appear right away in bioCADDIE and DataMed, please do let us know because we are into a very active process of doing this. Many repositories are being indexed as we speak. And accessibility metadata was also very important. So lead by George Alter from the University of Michigan, a working group decided what would be the initial set of metadata related to authorization, authentication, and access. And this has also been incorporated into DATS 2.1. And why is accessibility important? Because we do not want to limit ourselves to public data only. We know that there are several very valuable datasets that are under access control. And users should know that they exist and then know also the conditions by which they could be accessible. So privacy is very important to us. And one important project, a supplemental project that relates to it, is named Count Everything. And that is for secure aggregating counts of relevant patients across different data types. So we partnered with the MD2K center, with the PIC-SURE center, and also the Global Alliance for Genomics and Health, which is the translational genomic center out of UC Santa Cruz in order to come up with a secure aggregated account. Why is it important for bioCADDIE? The situation is as follows-- remember, I was looking for astrocytomas. And suppose I was looking for ones that had mutations in TP 53 and I wanted the whole sequence of that particular gene. If I go by metadata only, I would know that, yes, I have whole genome sequence data for those patients that I identify. However, I would not know how many have a particular mutation. So if it's a dataset that has no patients with mutations, maybe it's not as important to me as having another dataset in which 20% of the patients have mutations in that particular gene of interest. So in order to organize the way I would be requesting those datasets, because they are under access control, it would be important to know which one has more of the characteristics of the patients I'm looking for. So that's why counting everything would be important. But as you know, counting can compromise privacy. So that's where we designed this in such a way that it's done through encryption. And all those communications and the aggregation is done in a secure environment. So this is a supplemental project that involves those three other centers of excellence, those other BD2K centers. Continuing on the list of working groups-- also a working group to rank search results led from the University of Texas in Houston was conducted. The report is online. And their recommendations are to empirically determine which ranking algorithm from the Elasticsearch family would be best for us based on evaluations against reference sets and logs of user behavior-- since we now have a user basis and they are continuously accessing DataMed-- and provide alternative ranking based on user preferences. So this also is evolving as we have more users to our search engine. End User Evaluation Criteria-- also very important. And we are still conducting this in terms of saying, how do we know we got there, that we have a good product for users? Usage itself might not be a good metric. There can be other measures of impact. So this particular working group was working on that. Repository Contact Workflow-- this was led by George Alter. How do we develop this workflow in terms of having a repository to index? Who starts the process? How is it tracked? And so on. How we prioritize those that come to us. There is now a committee that has developed processes and is following up with this particular aspect. Natural Language Processing is also an important aspect of our index because, as you know, it is very important to extract structured data from narrative text. And, actually, we have just issued an extension on our dataset retrieval challenge sign up. So that we came up as-- there's a challenge that has a very high monetary award which will be in the form of a subcontract to the winners. And there can be more than one. Around $50,000 for this particular challenge. So if you're interested, please do log in to Biocaddie.org and look into this challenge. The way it works is that the winners will have their algorithms incorporated into our data match prototype. And we will make full use of their work. And we will compensate for that as well. And an independent panel of judges will be making that determination. So, also, for ingestion and indexing, I won't go through many, many details. I would ask you to primarily follow the boxes that are shown here in this L-shaped format. Because that's the process by which the core development team, led by Jeff Grethe and by Hua Xu, are developing this ingestion of data sources in order to get the metadata. And there are important interactions here, and I would say that with schema.org and with CEDAR. So with schema.org we want to be perfectly aligned so that the metadata can conform to schema.org so it can be found by other search engines and not only DataMed. Also, the collaboration with CEDAR is such that-- remember, there were datasets that were not already aggregated and that the data contributors would be annotating those data sets or creating those metadata, populating the metadata for us. And we rely on CEDAR, that is a center led by Mark Musen that is developing these forms in smart forms so that data producers can annotate their datasets. Also, the DATS metadata model was developed by a working group led by Susanna from Oxford. And we are creating this metadata transformation so that it becomes easier to reconcile all of those strategies. The requirements for the metadata, as I mentioned before, were driven by multiple stakeholders. So as I said, it's a social process of reconciling all of this and making it so that we're all swimming in the same direction. There was collaboration across these multiple working groups that I mentioned before in order to get this ingestion and indexing going through a process that initially-- like in number one, there is a submission format, we need to develop adapters, and so on. Evolving to number three, in which we hope, and we are structuring ourselves to scale so that, similar to how journalists currently provide data to PubMed, data providers will provide data to DATS without this more manual process that is currently involved in populating the initial DataMed. So as we evolve, we become happier, and we also scale the index, how encompassing it is. We also want to enhance metadata, that this will be a continuous process. And it will continue to involve the community in that as well as incorporate elements of natural language processing as we progress. The final document preparation-- again, that is a pipeline here. And in order to be scalable-- that pipeline process is scalable horizontally-- large datasets were full and has been pipelined. And DATS 2.1 models are in the works right now. And there is a high volume of operations dedicated to this at the moment. We want to populate the index as much as possible. Scalable index services as well-- we rely heavily on Elasticsearch. And we are also creating APIs for developers so they can build their own modules and utilize the indexed data in their own ways. This is another pilot project that I wanted to highlight. Pilot projects are, like I said, those that are competed through a peer review process and are awarded to the ones that are deemed more relevant to bioCADDIE at this moment. So one of them is led by Chris Mungall from Lawrence Berkeley National Laboratory in collaboration with other programs displayed here. And Chris' goal is to use GitHub, YAML, and Markdown in order to make, as he puts it, making metadata annotation fun. So it's a project that, again, he uses the capabilities of GitHib in order to have authors put their metadata in there. And this is ongoing. But we've seen some demonstrations of it already. And it is, again, showing alternatives to what we had originally thought the annotation process could be. And this is the value of engaging the community. We always have some good ideas coming up. And we can incorporate them or put different modules into our own development. Another bioCADDIE pilot project was issued to the University of Utah and to metadata data discovery and integration to support repurposing of heterogeneous data using the OpenFurther Platform. And this is, again, another way of indexing that this particular group in Utah has proposed. And we said, yeah, let's try that, too. Because the more minds that think about this process, the better. Another one to complete-- there were three this past year-- was the feasibility study of indexing clinical research data using HL7 FHIR, which is a standard for clinical data exchange that is very popular these days. And it's a pilot project on a harvesting strategy for the data discovery index led by Harold Solbrig from the Mayo Clinic. So they had three deliverables. One was metadata harmonization. The other one was indexing the dbGap phenotype variables. And the third one was exposing metadata through schema.org, which as I have mentioned before is also our goal with that, with our metadata specification. So we're very happy to have those three pilot projects this year. And we'll have the natural language processing next year. And these are all, again, available for the community to come up with the best ideas. So we, essentially, see bioCADDIE as having the Data Shop component. This is very technical-- indexing link, linking to articles, ontology-based tools. We see the Data Showcase, which is the front end that uses Elasticsearch, but essentially it's about the graphical interface, how we visualize, how the usability of the tool is meeting expectations. And then there is the whole Data Market, which, again, it's a social aspect of it that is very important. Because there need to be incentives for data sharing and for people to annotate data very well. And those incentives currently are somewhat obscure. And then, citation networks need to develop, because the same way as publication citations became the currency of academic metrics, the data citations might become in the future at least an important part of the large ecosystem. So in our bioCADDIE Data Shop and Showcase, we see as the repositories contributing as something happens inside this shop. And then the products are displayed in an easy-to-see fashion so that the researchers, our clients or customers, can decide what they want to take out of the store or not. As I said, the Data Market needs to be developed. It is not fully developed. BioCADDIE is one front end of it-- or DataMed is one front end of it. There can be others. And, again, the currency for data has not been well-defined. So it's very exciting to be at this point in time where we are helping define all these elements for the NIH data Commons. And more than data we also see these other digital objects to have in this value. And it will be software. It will be software systems, packaged as dockers, packaged as VMs, or other sorts of value that will be provided. So we are, with the help of a large community, trying to create the market, define the market, and create the first tools, so that after it exists, others can come up with even better tools, and even better ways of indexing, of accessing, and so on. So we are at the beginning of a long journey. So here is the roadmap created by the University of Texas colleagues. And as you see, we have met the milestones from before. We are still running there. And there are public releases of the new versions scheduled. And they have improvements on a variety of features as determined by the community. So please do experiment with DataMed. Don't expect to see everything in there. But it's there so you get the idea and you demand other datasets and you demand improvements in the user interface and coverage of the datasets that we have right now. So our journey-- this is a poor picture that I took in the Johannesburg airport. If you have an opportunity, please do take a better one. But it says something very important. It says-- if you want to go fast, you go alone. If you want to go far, then you go together. It is an African proverb. And we see bioCADDIE as in that stage that we were asked to go fast, but we were also asked to go far. So we have engaged a large community to go far with us, to have an initial prototype and then engaged the community to challenge the community to have better prototypes, and to help us index this huge volume of data that are out there, unused, in a way that makes more value for our dollars. So with that, I was also instructed to leave plenty of time for discussion. So I have here the two things that I want you to remember from this talk-- Biocaddie.org and DataMed.org-- so that you can fully understand what we're doing through our consultation with the website and experimentation with the search engine. So, again, I would like to thank the organizers for having given me the opportunity to do this. I did not list here all collaborators for this project in fear that I would miss somebody. And with so many collaborating-- more than 100 at this point-- that would certainly happen. So I would like to thank all collaborators, all our members of the executive committee of bioCADDIE who have teamed up to come up with the best of both worlds. You know it's a consortium that we put the best minds to work into this very, very challenging problem. So, Mark, thank you, again, for the opportunity. Thanks, Lucila. That was great. I'm encouraging all of the people who are dialed into this webinar to post questions. Since everyone is muted, please put your questions into the chat box and we'll try to get to them as we can. So please put your questions in the chat box now. And we'll feed them to Lucila. Before we do that, Lucila, let me ask you, you ended your talk showing a roadmap. And bioCADDIE has a very ambitious goal. How do you know when you're done? Do you have any sense for what is the number of repositories, what is the number of datasets out there, and how can you ever know when to stop working? Yeah, well, again, that's why we had a full working group on that, right? But, also, yeah, I see we have a lot to do still. And I can say it has been such a fast-paced project that sometimes we don't even have time to stop and think of what's next, how do we know when we're done. And we think at this phase there is so much to be done that I can't see the end very soon. So in contrast with the publication world in which there was a market already-- journals existed, they were publishing, they were having their own websites, and so on-- so in contrast to publications, data are more complicated because it's not as organized as that market was. So at this point we're just seeing the tip of the iceberg, the datasets that most people know and have used, except that they're scattered all around, and except that as a user of a particular type of data, let's say for me clinical data, I know where to tap into the sources. But when I jump into Image Data, I don't know, or Omics, or others. So there is so much out there that we don't even know-- that that's important that those communities specialized on these data types be in this journey together with us so we don't miss anything. But it is a very important question, but one that, unfortunately, I don't have a good answer for you right now. I just see so much ahead of us that I can't see the end at this point. Do you have any estimates for what the denominator is? How much biomedical data is out there and what fraction can we possibly access through bioCADDIE? Yes. Well-- Is this is an impossible question? No. I think the good thing is at least, the repositories, we know which ones they are, what they are doing. And we also know those repositories related to articles. Because those are increasingly more prominent and more available. What we don't know, and actually what we don't know if we really want, is from the long tail of those datasets that have not been indexed and are potentially available but not findable, we don't know the quality of all of that. So how do you know that something is good enough to appear in a search engine that has quality control on top of it? And you may say, well, maybe it's not worth doing that and let the users exert that quality control. As of today, and this may change in the future, but I believe that it's important to get started with some sense of quality control first. And, therefore, many datasets that has been produced by one lab or kept there but not shared, that there might be some reason why they were not shared. So we will not being addressing those immediately. I think, as we progress, and if we find that the denominator is not that huge, then there is a case for indexing everything. But probably what we'll find is it will plateau at some point. But, again, I can't tell at this point. I think it will take another three or four years for us to be at that stage that we can really assess and be picky about this or that. OK. We're starting to get some questions from the audience. Probably the most important comment that we've seen so far comes from Marjorie Mitchell who says, you're doing awesome work. Thank you. I read that. Thank you. OK. I have a question asking whether imaging data can be indexed with bioCADDIE, can it be linked with Omics data. And, ultimately, will bioCADDIE give you one-stop shopping so that you can have a single search that will provide results from a variety of these kind of data sources? That is my goal. And when I mentioned that very first use case, I want to have all data about this particular condition because I want to correlate it. I want to find recurrence of a tumor through images or through data that shows increases in sizes and so on. So that's exactly the point of getting an uber index that would then point to the sources that have more detailed information. And if that's Omics, there are a certain repositories. If that's imaging, there is also, through the BD2K centers, excellent sources of indexing of images. So I think that our point is exactly this integration. And you find things that you didn't know about. Another questioner mentions that you alluded to aggregating patient data and points to the problem of there not being unique patient identifiers that make it easy to bring patient data together and questions, how do you deal with that problem? How do you deal with missing data? How do you deal with double counting data? What are the challenges in doing this kind of aggregation? These challenges are multiple. I mean, they not only come from the privacy end of things, but exactly what you mentioned, the duplication of patients across different datasets is a huge problem today for research studies. So bioCADDIE will not-- again, I will be very happy when we are at that point, but right now, it's more at the point of that, oh, this exists. And this Count Everything project was the first attempt to see how we would link-- because one dataset has mutations, another dataset has sensor data, another dataset has clinical data. Assuming we have the same patient represented in all those three, how we would do a secure linkage and also privacy preserved in secure linkage of records so we could do this de-duplication. So that's a very important research area that I encourage more people to get involved because it's really going to be a bottleneck in the future. OK. A corollary, that is how is the identification managed by bioCADDIE? Again, we do not delve into the datasets. Therefore, the de-identification is not an issue because we're mostly dealing at the metadata level. So if you want all African-American patients with TP 53 mutation of a certain type, initially, what we can point is to datasets that have that type of metadata that would have race and ethnicity and would have mutations or it would have gene information. But unless we delve into the dataset, we can't count the number. So at this point, re-identification through our index is not an issue. Lots more questions coming in, Lucila. This one is interesting. Do you have any tips for searching with DataMed? People have intuition about how to optimize their Google searches, but are there any good heuristics or ways in which users can optimize their efficiency in exploring data searches which is something that is not necessarily intuitive to most people? Yeah, well, what I'll do is I will go to Advanced Search because that might not be immediately obvious in the interface. But there is-- just as in PubMed-- a way not to just go in and type what your search is, but to structure it better. I'm trying to get to the slide that has the interface here. Yeah, here. So see there is on the right-hand side an Advanced Search. So I think that's the best way to go about it. And then as you get your answers, you can filter by the repositories, by the data types, on this left-hand side. And you can also check the synonyms that it's getting for you. Because the engine, once you type something at the top, it uses that terminology search to go about synonyms and expand hierarchically that concept. So I think that those would be ways to get started. And also, feedback, let me put it here. If you have feedback about something we should be filtering by and we're not doing, that would be very important for us to know as well. Please do contribute your comments. Along those lines, a questioner asks, how are data errors and inconsistencies found, flagged, and corrected? Do you actually have a mechanism for giving feedback to the repository managers? Yes. So I would use this GitHub. You click here and you put your issue there so that someone can respond to you. And if those corrections are needed, that's an excellent way to provide us with that information. OK. Two related questions, one of which is, how can someone get a list of all the collaborators in bioCADDIE. And are there librarians working on the project? Yes, there are librarians. The list, if you go Biocaddie.org-- unfortunately, we need to work on the interface. If you go to working groups, you will see everyone listed under a working group there. So I would say the list is scattered into the working groups. There isn't a consolidated list. But if that's desirable, that's something that we should probably do. Because then I can put a link on my acknowledgments lines to that particular list. And that will cover everyone. Great idea. Thank you. Lucila, you stated that you had certain expectations about searching data when you created DataMed. And the questioner wants to know, did anything surprise you in your findings as you created the tool? Yeah, well, it is still surprising me because if I were to say I'm satisfied and I can do that query in the beginning, that was something I really wanted to do, was as a friend of the family, I wanted to know what is the survival for a particular age group, a young person, and I think I'm not satisfied yet. You know, we can find some certain things there right now, but we don't have enough imaging repositories, and I know that those are coming, so it's not like we're not able to, but it's not populated to the extent that I would like at this point. I mean, it is much better than if I go on Google and search for it because it's essentially very hard to find anything that is more data-centric in the current Google search engine. But still, again, my surprise is that it's not as simple. I started this project with a much more naive approach. This is a lot of work, but it's simple. And now, it's a lot of work and it's not simple. That's for sure. Another question-- how are you encouraging researchers to deposit their data into repositories? Isn't this just a lot more work for them? And what is bioCADDIE doing to get access to more data? Yeah, so, again, that's where the data citation groups are working on it and also what the incentives are. I think we do need help with that because remember when it happened that journals started requiring deposit of data in order to publish an article, people started doing it. Again, not perfect metadata, but at least data were deposited and so on. It so happened that there were repositories ready for that. What happens now is there are certain data types in certain modalities that you don't have repositories. Or, I mean, you may have, but they're not as recognizable as those were when the journalists made that requirement. So I think we need to create, again, this market for data repositories that are beyond what exists already for other data types. And then with the publications, which are still important for the academic community, require that. And then have the funding agencies provide incentives for people to comply with that. A questioner wants to know how users might be engaged in providing feedback to the DataMed developers. And how do you ensure that you're creating a search engine that people actually want versus one that you think they might want? Yes, exactly. And that's where, again, I'll get to this point of providing the feedback through GitHub or through contacting any of us because each person has a different idea of what they would want from a search engine on data. So that's also the reason we had those pilot project solicitations and so on because it is different and everyone is different. We want to know how can we cover the 80% most common expectations and then also learn about others so that in the future we can produce those. So the best thing is to provide feedback through this GitHub link, which is here. So noted. We have very little time left. Let me be very selective in posing some questions to you, Lucila. Here's one that says, a dataset actually gets used and re-used-- or rather, as a dataset actually gets used and re-used, and suitability for different purposes can become clearer, is there now in your scheme, or do you envision developing, rules for data users to supplement data supplier's metadata with usage notes, caveats, bug reports, et cetera. In other words, I guess, how do you make DataMed two-way? Yes. So that's one thing that we were thinking, too, that with more volume and if we could-- for example, we are looking at it's screen right now-- if we could have for each one of those entries, the number of stars, the reviews from people-- I liked it or no I didn't like it, similar to when you were buying a product on Amazon-- I think that would be very good. We do need to create that feedback mechanism in here. And then we need to, obviously, start getting a lot of usage to it so that we go from several reviews. But I think that's a goal definitely. A good question from a user is, can you say something more about how bioCADDIE actually facilities data re-use? Yeah, at this point I wouldn't go that far. I would say we're trying to address the findability of it. So indirectly if you find it, you're more likely to re-use it, but that's not a guarantee. It might have access controls that you are not able to fulfill the requirements and so on. So I think it's a step towards reusability, but it's run of several components that need to be in place so that it can be re-used. And this feedback, again, is very important because people have to access it. People have to use it and then provide feedback. Yes, this was useful for me. Or, no, this dataset looked good on the outside, but once I got it, it's really not that useful. We're just about at the end of the hour. Several questioners would like to know how they can get ahold of your slides. I will provide it to the organizers. And also, let me make a point, I'll put it on the Biocaddie.org website. Thanks, Lucila. And let me let the audience know that this talk was recorded and will eventually be on the website for the training coordinating center, which is providing an archive of all of the webinars in the series. At this point, we are out of time. Let me thank Lucila Ohno-Machado for what was a really exciting presentation. Let me thank all of you for some really great questions and remind you that we do this every week. And we look forward to next week's presentation as well. Thanks, everyone. Thank you. 