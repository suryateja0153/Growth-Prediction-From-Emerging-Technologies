 first of all I want to thank the organizers for the opportunity to talk here this morning some of you might have expected my gosh maka who was originally invited to give this talk unfortunately Michael snapped a tendon in his knee and he couldn't make the transatlantic flight so he asked me to stand in for him and give this presentation luckily I was involved in the work so it's going to be not too unnatural what you wanted to do in this particular work it reverberates with what was already said just now we wanted to take a snapshot of what is actually there today and what we can do with it and how is it better or is it already better than conventional computing so we are looking at that hardware is now available carlins my shoulders impressive pictures from the from the big machines in the human brain project it's also available in smaller form factors for embedded computing and systems range here from dedicated hardware that is digital to mixed signal systems that have analog computing parts and digital parts for routing or we still have generic hardware that we can compare against for example did the normal CPUs GPUs and systems now what are they then next question we need to ask is what are the trade-offs what is this actually we are looking for and power was emphasized already another one I think is still we want to also be faster exascale computing for example but that the third one here I think is very important if we look at the uptake of this technology is also how convenient and easy to use are these systems and will they make mainstream's soon or will they be so specialized that it's just for the experts like us so to speak that will be only able to use these so for this particular work we asked the question if you just take your standard benchmark task and we grab a few systems to test you know how will they do in the trade-off between these three elements so we picked a couple of systems and here we work with a spinnaker there's a picture here of the spin three boards in the top right we have a very small system there and we could know later go to her large assistance but for the point of this comparison we just took things systems that were available at the time we compared it against spikey Marisol and some people might be familiar with it so it's a mixed system of analog hardware digital hardware and run to ten thousand fold speed up of a real time and also has a quite no footprint and low power and then we compared it against something more typical of mainstream if you want so this is a GPU enhanced your network framework this is something we develop ourselves in Sussex and we ran it on a standard gaming device so this is a high-end gaming graphics card the titan black referred 2880 course and as a task we picked also something quite standard and most of you will have seen this so this is the handwritten data handwritten digit set where the question is to recognize these handwritten digits here is a nice way of visualizing that we took that from from this paper here and it's hard to see but here's a blow-up so you see in there than the digits and this shows but proximately how the clustering structure of the similarity of digits are there this is a well-established ask most people in machine learning have used it so we know exactly what the performances of different algorithms and solutions are for this and it's fairly high dimensional and that's important because we think if anything then your morphic solutions will be good in high-dimensional tasks and then you can scale the difficulty of the problem you have up to 10 different classes like the 10 digits but you can also use subsets of it if that is too complex for these small systems we are testing here and we have a good set of 60,000 training 10,000 testing samples so this is a realistic type of machine learning problem okay so we are we have a task we have some heart we want to test but the only thing that's missing and maybe that's the most challenging part is an algorithm that we're going to use that's neuromorphic and runs on all these three platforms and so I give you a bit of a flavor what that's like and it's a fairly simple system so we also see later at the computational performance and recognizing your digits it's not you know end of the like bleeding edge of the of the performance on the amnesty to set but at least it can be formulated on all these different hardware systems and it works like this so you first have to translate the problem somehow into something that the neuromorphic computing algorithm might understand and under this understand a neural network basically so something in your network can understand the first step of that is encoding your input space into something that we can put in there and for us that means we need to kind of formulate some sort of rate type encoding of this what's an image before and we did it with this virtual receptor approach that's something that michael has been spearheading for vile and the idea is basically you have inputs and they're here shown in the principal components just abstractly as dots and you want to encode those into a very very have positive numbers that could be represented by a firing rate and we do this by placing so called virtual receptors that are these crosses in here and then you encode every of the inputs just simply by its distance to these virtual receptors you see this red ring there that might be one of the inputs you might encode you look at the distance to the different receptors and that defines you through the simple formula the activation of each of these virtual receptors so we get a recording in some positive numbers in a vector of positive numbers of virtual reactor activation that gives you the encoding of that point and it's a very general thing you can do with any kinds of inputs yeah there they live in some high dimensional space and then you can always make this kind of encoding and then you can go ahead and pick your favorite network you know might think on the future of doing deep learning or more advanced things here this is a very simple type of model that also it's michael's idea published this a couple of years ago hmm and this is a very simple network that does the following you have these inputs here these are these rates and you encode them into spike in populations of neurons the quality projection neurons this is bio inspired by a factory system and the new a factory system you have this antenna lobe mushroom body pathway of recognition of odors and that's where this inspiration comes from the projection neurons they are in the antelope so you have these projection neurons and they just represent these firing rates as spikes and then they inhibit each other slightly which is basically a contrast enhancement type of algorithm followed by supervised learning here the dashed arrows are this plastic sign opsys and some associative neurons so these will then represent the classes of of your problem in this case there might be up to 10 of these representing whether the boss is 0 of 1 2 and so on present in the input so they would fire and the inhibitor dodgin strongly so there's a winner-take-all kind of decision being made on this slightly refined representation here it's a very simple system and you see I mean the performance isn't huge but this wasn't the goal here at a goal here was to see we put them onto this different available hardware system and see can be implemented does it work and then how is it with the power and the convenience and how is it with the speed hmm now we had this idea that's the basic model we wanted and on the spiky chip where we implemented at first they could pretty much implement it this way but then when we went ahead and want to put it somewhere else we had to do slight modifications and here's the example of the GPU solution we now have different underlying neurons simply because they were available so there's also choice the trade-off between convenience and how much do you stick to the same thing in the benchmark and then am I here we abstracted the inhibitory neurons also they inhibit each other directly that it's the individual step that's just the way the GPUs work yeah so you spawn kernels on a very frequent basis which means you can spawn them for every time step and we decided here to implement the plasticity outside the GPU this is was just a choice to match what we were dealing with spiky this is something that can be discussed and the same thing for the decision what class was recognized and then again we went to spinnaker as the next thing and we still had to modify slightly so for example it didn't seem to be practical in the end detritus first but it didn't seem to be practical to do a full set of input spikes to represent our inputs but it seemed to be more practical to put in the rates as inputs and then have a pass all unit pool here to make us input spikes from that that's something we had to learn yes there's one thing the other one was that the learning now had to be on board because it wasn't practical to extract the spikes and like start stop the spinnaker in some way and extract spikes in the middle that's what's just absolutely impossible to do so we put it on on the chip and use some STD p rule combined with reinforcements signal and a sort of free factor will to make the learning happen so you see it's it's it's details I don't want to go through all the nitty-gritty of this but we had to adjust details to make this model work on the different heart so there's no such thing as one neuromorphic algorithm and you can just ship it out to different hardware systems and it will run it is not like that but as I will show you in a moment we could achieve that they all perform on the same level which gives us confidence that we did implement the same kind of algorithm in the end there are also other differences there was the difference in how we implemented how the connections are made what kind of sign apses and neurons are used and so on but it has knock on effects on how we do the actual operation of the system so for example on the spiky we had to run it in a one second per stimulus simulated time so we had to collect more spike so to speak as on the spinnaker we could do this in a hundred twenty milliseconds simulated time I should say and practice obviously that means on spiky it's much faster because it goes ten thousand times faster than real time and this one goes in real time but I wanted to point out that there's other things that you need to adjust to make this a valid comparison hmm obviously we could have run it here on the right hand side which is pinnacle longer two but that would have been like a voluntary vase that we didn't want to put in because the speed measurement what we would be affected so how we did all this was that we basically tried to do the best on each hardware and then compare yeah so we try to to find out how long do we have to run every input to recognize it well on the spinnaker that was only hundred twenty milliseconds males on the spiky was a second and so on so I hope it's clear that what kind of thing we were trying to do here and I'll take you to the results now and show you this trade-off between accuracy speed power and convenience hmm the first thing how i created is the system so here are some curves for the performance of the systems in real calls so this is like digits recognized correctly for different problems here is just comparing the digits five and seven so very simple problem to the full system on the right here chance performance would be this dashed line down here we did put it here too and then these are the performances for different size of the classifier network and if you do larger networks you do a bit better so you see you come from this 10 vr 10 virtual receptors kind of representation to 200 VR system and you get better and better hmm and then you see here Jen that's the GPU based system was a spinnaker versus spiky the spiky was a bit size limited so we just tested it on the two simpler systems here and then for the larger stuff you did the other two boards now obviously there's more available and we can kind of push this further but you're of course can only bench mark at the time when you have to stuff available so that's what my severely at the time and you see the total performance that I should also point out but it's consistent between the systems it's not great in comparison to like you know top of the the line em nice performances they lie ninety-nine percent yeah so the best things that would be up here this is just you know ninety eighty percent depending where you are so that's great but it's a reflection of that simple model so i wouldn't be worked up about it what's important is that we got the same kind of performance in the different systems for spike is only realistic to compare this front one here so we encourage that we even though we did completely different implementations we did get something that seemed to do the same thing so for that we were happy with that here's a bit more of a close up between the spinnaker and the gin performance and you see it really kind of clusters along with diagonal so if you look at the performances against each other they do the same kind of thing now so this desert stretch to us that the limit of performance in recognizing digits is basically in limit on this kind of simple model that we did rather than a limit on using your morphic hartville because it would be unreliable or something it's not the point genesis the point here is simply the model is a bit simple now now let's come to the more interesting things how do we now compare on speed and power so here's the speed performance and we try to kind of drill down a little bit into the different aspects of it so in different colors here i show for the three different system for different system so this would be a simple cpu solution GPU accelerated spinnaker spiky we show the power for different tasks within the actual program system and that was one of the interesting results here really so you see at the bottom always that's kind of the time spent on actually executing spiking your network computations on the hardware so on the cpu that scales linearly up and you see it costs a lot once you get to larger systems these are three sizes of systems each on the GPU on the other hand jeez it's just flat is basically because you're not using all the course and on the spinnaker is guaranteed real time so that's flat on the bottom here and the spike again we couldn't do the larger systems and you see the comparison yeah so you see that you goes to a point where for small system CPUs are just fine to where they get really slow and then between the spinnaker and the GPU here there's they're sort of a bit of a difference still obviously if you went to much larger systems than spinnaker would have actually be faster but then the first thing you might have noticed is that these little bars down there they are actually that big compared to all this other stuff on top what's the other stuff on top that's basically setting up the network on the device and transferring the input data in and getting the results out yeah that's the kind of big chunk of stuff here and then there's some other tasks here in violet on top of different size i should say in the spiky here did the runtimes actually display ones not the runtime the runtimes invisible because it's so fast you and the actual runtime is almost nothing and this blue is the set-up time and and transfer time so we see in terms of speed there's a lot of promise here but it's not really fulfilled yet because either we had to daph to really use it efficiently or because it really can't yet be used that efficiently in a practical applications because you have to get system in the algorithm in and the data in and the data out and that is really that seemed to be limiting at this point what you can do with it in terms of speed okay let's speed now let's have a look at power consumption power consumption depends also a lot on the different phases of what you're doing and that's here time-resolved on these graphs so here this is the GPU system then you have the spinnaker system here and that's the spiky and um the blue stuff here is GPU power the gray stuff is the workstation where the GPU is in and then here similar the bottom thin line here that's kind of the baseline power used by the by lachemann Ichabod yeah and then there is a workstation part in green that is about the support done Valda spinnaker was running things and then the violet is the data preparation where the spinnaker wasn't even actually involved and here's a similar thing yeah this is work station again when you set up the system and then you have the training run and the testing run for for the spiky system I think the first thing to mention obviously the neuromorphic systems are better with power consumption the power is lower here and there then what the GPU is consuming there so that that's expected you only GPUs are hungry devices they're rated at about 300 watts for this particular GPU so you will consume more power interestingly it doesn't ever get to 300 watts here so we're talking here about about 40 50 Watts consumption so they're not as bad as they seem on the peak power consumption that is mentioned but you also see that the workstation support is taking a lot of power as well and that's just the snapshot of what's happening now maybe in the future that's completely unsubstantial but in terms of what Weaver benchmarking is we wanted to see what's there now how is it working now and the truth is right now we've wasting all this power on the workstation support for all these systems and we're racing all this time shuttling in data and getting it out rather than having that the benefits of the systems directly that's that's the result that we found you now this is power consumption and obviously they're on different time length so what's the total energy consumed for the computation how do they compare on that page and that's shown here and you see the CPU is getting really bad if you go to large system because it runs long and needs a lot of power where's he did actually more neuromorphic systems start to look better and yet again the the most power is taken by the the most general energy is used by the supporting pc now i should say the message he was just integrating those diagrams i showed earlier of the power of time yeah so this is reflecting the same results but just reformatted for a better view okay so that's that's power which which brings me to a quick summary of what we found here so we found we can implement the same algorithm with a lot of work in the details but we can implement them on the different available systems it's possible and they give the same performance in terms of their computational ability in terms of the the speed the speed here was mainly determined by bandwidth and one thing is that we can say okay that's just a temporary thing that we have to face now because these systems aren't fully embedded and developed yet but I think it could also be a lesson to be learned what to pay attention to when developing them it's not only about making the systems internally work well it's also to make them work well in an environment for an application so the bandwidth of how you get things on there and off is important and will stay important the software interface so that's the the system that's always in the front that reformats your neuromorphic model on to something that's understood on the hardware that is also a bottleneck that takes a lot of time to set up the heart that the hardware for example on the spinnaker system when we tried this on a larger board which we eventually did we actually stopped doing it after a while because when we scaled it up we hit like the one hour limit for setting up the system on the board and that the testing just became very very tedious so that's something that that's that needs to be kept in mind and then of course on the side of the algorithms we didn't pay too much attention to this initially but we can also set them up in different ways and it would be important to set them up in ways that they don't communicate too much to begin this so that that is something to be really looked at separately so for example we could have chosen to do the plasticity always on chip rather than off trip and that would have helped a lot and the same for the input spike train generation and finally the energy consumption through the date when we were doing this work it was mainly the host workstation that was eating all the energy and they all the advantages of the systems that we had which are running at much lower energy were kind of eaten up by that but it kind of item and that brings me to the end here so I want to thank Alan who is post locked with Michael and me who has done all the leg work in this Michael of course this was funded by the human brain project and the GPU announced networks they are funded by these folks in the UK the whole work is published here if you want to see more details so thank you very much you can hold on yeah there you go good to see again so it's a very nice systematic work it struck me that the results all the burden in the uploading and the configuration that really dragged down the neuromorphic solutions of course spiky is Karl Heinz is 10 10 year old platform and so it'd be interesting to see what this looked like on I can but for a spinnaker it looked like very good performance as you know equivalent performance in terms of the amnesty work and really superior energy consumption once the uploading was done and so it suggested that if you had a problem domain that was more of a streaming sensory processing so where you upload the system configure the system you get that done whether it takes five minutes or five hours doesn't matter but then you let the Machine run with streaming sensory input for for it you know a long time then then really you'd have spectacular superiority in terms of energy consumption and at least equivalent performance is that what you would predict yeah I think I think that would be accurate but one needs to keep in mind that unless you really run it continuously there's no such thing as saving a state on spinnaker and then reusing it again later not as of yet I think that would be something that would be interesting to look into so you would have to do the reup load so if you had your streaming application but you wanted to stop it and reconfigure some parameters or something in between you would have to reupload the whole process again so that and actually rear out at the moment everything again but which takes a long time yeah so just to the this local learning that Caroline's was was talking about the you know the the learning and the the homeostatic adjustment and other plasticity going on at a local level on the trip then then you're in the position to have streaming sensory input which is after all what neural systems are for that's what they evolved for and you really do show terrific advantages in terms of performance and power yes I believe so I mean it's a hopeful picture here it may say we're not quite just there yet in terms of usability but in the future I think you get these performance results on the power so it is going to be much less power then then the CPU GPU kind of systems we working on today yes absolutely I'm actually bit confused in the case of the two neuromorphic chips was the learning being done in loop or was it done offline and then loaded onto the chip was the running done they're learning the learning was a gun in the loop meaning the chip was being fed and then wait updates computed off chip and then loaded or was it done off chip and then loaded yeah so the two system differently so for the spiky it was done that was random spiking and the weight update was done outside of stuff off chip ok on the spinnaker was done on chip because the off-chip wasn't even practical and for the spiky the on-chip wasn't practical so ok so for for this pack it was in in loop in the loop so yes it's just another workstation yeah ok and over the case at spinnaker it was off ship or on ship completely on to completely for the spa area so in this case in the case of the speed I'm bit confused on to the configuration for the spinnaker why it took so long because my understanding it would be that you configure the chip once and then if the if the weight update is being done on the chip then the only thing you're basically doing is applying the input vectors to the chip and then just the chip will do everything from there on is that correct that's correct it's correct here I mean so why did why do I be excessive time taken by the configuration in this case well the accessor time taken for configuration is an upfront cost you have there the neural network you want to simulate needs to be distributed on the different course on your spinnaker system and that's done in in payson on the workstation so that there's a routing algorithm and then later actually there's a C++ part as well but the routing where it goes on your spinnaker system is all done on the workstation then it's all uploaded then once is running you're right once it's running there is no role of the workstation in there anymore and it actually just does its thing and then you have to grab off the results again of course 