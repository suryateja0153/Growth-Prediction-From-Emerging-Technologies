 okay welcome back everyone I hope you're ready for Martin Luther it's a topic about an introduction to Software Defined Networking enjoy thank you sir there's no microphone work can the people in allows ray understand me that sounds great welcome everybody to this presentation before i get into the subject of SDN i will actually introduce myself my name is Martin lush woods I work here in Berlin as you can see on the picture i work as the team lead for the OpenStack team at sea sola from sis 11 is a company doing web hosting and we have invested roughly two years of work into evaluating OpenStack and bringing OpenStack into a state in which it actually does what we expect it to do and one of the things that we have evaluated a lot during this time was software-defined networking along with multiple solutions and implementations and today that is what I stand here in front of you and to our presentation on software-defined networking so what is soft when you find networking software defined networking really is network virtualization thanks sorry any questions I was trying to be pull out for those people needing to leave a bit earlier of course the presentation is going to carry on with a more detailed inside into software defined networking and before we understand what Sdn actually is we need to understand how IT has changed over the last few years because that is fundamental to the understanding of software-defined networking so years ago individual servers had individual tasks there was a server or there were many service in one data center and then there was a task the individual server was doing for instance monitoring could be such a task so there was one server and there was a monitoring system running on top of that server and there was no other task this server was acting for and in fact over the last few years the capacity of service has increased continuously so by now you can actually buy not only servers but you can buy big service lots of CPU lots of ram and it's almost impossible to use this with application unless you're using Java of course but we will not get into that today so the interesting question is how can I turn all the capacity in my rack inter actual food in my fridge because that is what it's all about right I'm buying hardware and I want to use it to the best to make money and to make as much money as I can with the hardware that I have and this is where virtualization comes in virtualization really follows a very simple idea the idea behind virtualization is to run multiple workloads at the same time on the same machine of course every workload needs to be strictly isolated from the other workloads that I have on the machine I still have one big server but I do not have one task for a machine anymore instead I have multiple workloads so I can have a monitoring system in a virtual machine I can have a database I can have a wordpress installation on a web server I can have a metering system all these applications are running separated from each other inside virtual machines on the same server at the same time and I've been using the word virtualization a lot in the last few minutes the interesting thing to understand the important thing to understand in this case is that virtualization in the sense that i have used word in the last minutes really refers to the virtualization of computing power so we are not talking so much about virtualization per se but really we are talking about one individual factor of virtualization and that is virtualizing computing power visualizing computing power by now is a very well-established technology we have kvm we have Zen we have vmware we have hyper-v for every major operating system there is at least one big solution for computing virtualization available and for most operating systems there are multiple solutions available for virtualization so in fact when it comes to computing virtualization everything is super awesome and we couldn't be happier with the situation that it currently is and now the interesting question is how does virtualizing network work or how has it worked in the last year's how have we actually doesn't at the interesting answer to that question is actually we haven't networking virtualization has not really happened what we have done is we have done a concept in which we treat and networking for virtual machines exactly like we would have done networking for actual physical machines in a great example for that is a setup that I have personally seen many times in the world I have tapped interfaces and i connect my virtual machines with their tap interfaces to bridge and I connect a VLAN tag device on the other side of that bridge that I call that virtual networking it's not it's exactly what I would do an actual iron an actual bare metal and that is not virtualization that really is just applying the concepts that we have used up to this point on the actual virtual machine that I have every person involved in software-defined networking at this point woods and that would be the nicest reaction you could get from that person just ask you if you are trying to get them because that is not virtualization that is in fact only applying old principles to a new scenario and surprisingly this worked well for quite a while we have done this for years we have basically set up virtual machines like this for a number of years it involves a lot of manual configuration so whenever somebody needs original machine somebody needs to configure a proper network device on that machine needs to act and needs to ensure that bonding is available on that machine and there at various I properly configured switch port to which that virtual machine can connect to and all this enquires manual intervention and it requires a lot of intervention and now the interesting question is why is that not good enough anymore why can we not continue to do what we have done in the last year's and what obviously has worked out rather well so who have used in the cloud this is impossible everybody's in the clock by now right the glad is everywhere so again who's in the cloud who's not in the cloud who doesn't want to be in the cloud okay anyway the cloud in this case in this context is a very important thing to understand because the cloud is the one reason that enables the requirements for new ways of virtualization on the networking level in fact by now as I have already mentioned the cloud is everywhere so everything is the cloud and everybody is in the cloud if you buy a local storage system by qnap and install it behind your telephone line you are in the cloud according to cube I don't know what these guys I'm not allowed to say that now anyway so um I don't know what exactly the marketing definition of cloud is but in fact there is a very clear definition of the cut per se and the cloud in fact is not so much something completely new it Morris logical evolution of virtualization and actually of computing virtualization because what has the cloud really done the cloud adds two features to computing virtualization namely the first important thing automation so I will no longer have to manually start a virtual machine I can actually just create a template and I can start as many instances of one particular virtual machine as i think i need and i can do that again and again i can just do it as many times as i need to and in the end i will have a number of setups all centrally managed all set up completely automatically and everything is going to be fine at the second important factor is only meant capabilities so I cloud actually allows me to just log in create an account at my credit card data and I can start virtual machines and this obviously creates a problem because by now the expectation is that I can just do this at any point in time I need to be able to log into the web interface and do that and it's impossible for me to wait for somebody to create you know my account to start regional machines for me or to ensure that these virtual machines network configuration is proper for the host that the vm is running on and this is where we have an obvious clash between conventional networking and cloud computing and cloud computing is to one reason that we need to look into new ways of virtualizing networks in our setups conventional networking makes three basic assumptions number one is the network is a managed centrally and relies on hardware functions such as VLAN whenever you take a look at conventional setups you will likely find switches actually doing management capabilities and then the one that is used most of the time are vlans so I have a logical separation of individual customers on the same switch I have actually something on my switch that ensures that customer a can not see the packets of customer be and the other way around the second assumption is machines belong to specific customers so I go I install a computer I'd install a server and that server is going to belong to this particular customer nobody else no other customer will be running stuff on that word on that machine nobody will be ever able to use it except for the one customer that I bought this machine for and that I built this machine to and the first assumption is there's little to no requirement for scale out so I customer now creates an order and she needs a few virtual machines or a server and we create the setup for the customer and then everything is going to be fine for a number of months before the customer gets back to me and tells me okay I need another virtual machine and as soon as the customer creates or needs another which little machine as a provider we just created this is a very manual process never we need to create a virtual machine we need to create the vm per se we need to create the storage for it we need to create the port configuration everything i've already mentioned obviously this doesn't scale and this doesn't work and this is exactly where cloud computing comes in to help it counts first of all the networking is managed by customers and cannot rely on hardware functionality so I cannot assume that I can reconfigure my switch just because a new customer has registered himself and has created an account and now wants to use a virtual machine inside the setup service host VMs of multiple different customers in fact I cannot dedicate a server to a particular customer inside a cloud because all servers need to be exactly the same they need to be configured the same they need to have similar capabilities and I must be able to start any customers which little machine on any server because everything else does not scale and anything that doesn't scale inside cloud computing environments it's not going to work very well which'll machines come and go static configuration doesn't work I cannot assume that a customer does not want a new machine just because it created five of them yesterday at any point in time inside clouds I need to expect my customer to come and say okay I need another 200 virtual instances and I need to create them myself because I have the configuration for that in place I have all my automation frameworks properly configured and I can just create those two hundred things and if my customer comes to me and tells me I need 200 VMS i just cannot sell one of my administrators okay please create 200 bonded ports on individual service because that is what the requirement currently is that is exactly by conventional networking and all this manual stuff creating ports configuring switches does not work in cloud computing environments and thisis what requirements for software-defined networking actually comes from the interesting question is can we fix it so what can we do to work around the shortcomings that I have just mentioned number one network virtualization needs to fix these three issues of conventional network it needs to make network and functionality independent of the hardware in use I cannot ensure that configuring a switch as possible so I cannot rely on any home functionality that mice which is only going to provide if I configure it accordingly in fact I need to turn my switch into something very dump my cloud computing and virtualization environment needs to allow me to configure the whole network from within the actual platform because my customers need to maintain their own network configuration and there are network topology I need to enable them to do that I need to offer them functionality to just create their own virtual networks that any manual intervention from an administrator and the cloud also needs to make it easier for customers to set up their own network in topology in fact inside clouds as a provider I do not want to have anything to do with my customers doing then I work in configuration I want them to do this all on their own and of course they are free to contact me if they run into a technical issue that is something that is up to them I do not want to know anything about my customers networks because that is something that they need to do and only they have the actual knowledge to run would ever set up they may require this is a screenshot taken from OpenStack horizon so this is the ritual software-defined networking module that you can find it opens like here you can see the customers have created which will networks for themselves we have number of external networks we have internal networks and customers are free to create as many ritual networks as they think that require inside this platform so in fact whatever customers do they must be able to do it on their own and they may not require any intervention from me as the provider how can we do that what is the technical means what are the technical means to actually implement this type of networking inside our installation the most important thing you need to understand about software-defined networking is that software-defined networking really it's about decoupling decoupling is a word that you will hear a lot in the clap context and it hardly applies as well to anything as it does to software-defined networking decoupling means separating one thing from another what are we actually decoupling what are we dividing from each other we are dividing networking hardware and networking functionality this is the part where I actually earlier mentioned that you cannot reconfigure your switch so if we have a switch and we now rely on the switches functionality and we need to find a way to no longer do that we need to implement the functionality by the switch somewhere else and we need to implement it in a way that allows us to influence it from the running setup here's what you typically have inside a data center you have a host in this case that is the host running our original machine so this is the hypervisor and there's the switch the switch typically has two components the control plane and the data plane the data plane is the boring part of the switch because all the data plane really does is sending packets from one port to another so as soon as you just use a switch to send packets from one server or from one virtual machine through a server to another vm on another server all you really use as a data point the VLAN capabilities and all of our management functionality is typically provided by switches actually reside in the control plane and what we need to do is we need to decouple the control plane from the data plane so we need to make sure that these two components are separated from each other and we need to move the control plane onto the host why do we need to move down to the house because that's the place that we can influence from our cloud setup we have components of the cloud running on our host and actually we can influence the configuration of the host and hence we can influence the configuration of the control plane under host if we actually visualize our control plane and that's really what software-defined networking actually tries to achieve it really tries to decouple the data plane and the control plane on switches of course this effectively renders switches into dump packet forwarding devices i already mentioned that the important thing to understand is any major management functionality your switch is able to provide in a cloud computing setup it's probably going to be useless and I've seen customers running this with switches that didn't have any management capabilities at all this is something that actually can turn into a problem because typically those switches that do not have any management capabilities also provide only very few resources so they are not very capable of doing anything but in fact you wouldn't need most of the management functionality on your switch you should be able to run a software-defined networking without any particular switch configuration at all the network that your machines your actual bare metal servers belong to in fact should be a completely flat network that all servers r equal parts of step number two on our way to prepare network virtualization make your virtualization configure the network for you so whatever sort of virtualization you use and even if it's not the original ization solution itself but more precisely the software that is running your cloud computing environment such as OpenStack you need to make that port influence your configuration so in fact you need to use OpenStack or a cloud stack or VMware or whatever your solution for virtualization is and you need to make that component configure the control plane on your individual host and that's the way to go in fact if you manage to do that you can offer your customers a completely virtualized network environment and they will be able to perform any configuration they consider necessary inside the setup let's die for the bitter a delay a bit deeper into this let's take a look at the actual technical basics what are the technologies in use it's easy to say that we need to virtualize the control plane of switches but how does that work on the actual technical level almost all as the n approaches split the network into two logical layers these are also two words you will hear a lot inside PSTN contacts the first name actually is the overlay at the second is the underlay the underlay is what is happening on the hardware side of things so this is where our machines are talking to each other this is the flat network on my switch this is the network this is the physical link that my machines used to communicate with each other then I have my host in this picture the complete orange area is one host I have a hypervisor in our case it could kvm it could peek sign it doesn't really make a big difference and then i have my virtual switch and as we already understood the virtual switch in this case is our control plane the big difference is that on a switch I only have one control plane and on my ever sdn based setups I do have multiple control planes and I need the control planes on my individual house to communicate with each other in some way in fact how do we do that how do we implement the control plane on the host level typically we do that form of a bridge and i'm pretty sure that you have all used breeches and linux networking before but in this case it's not a normal bridge more precisely it's a bridge that has certain additional features for instance what our bridge in this case can do is it can do package tagging we can we will get to packet tagging on a later note in this presentation but for now remember that our control plane on our house actually has means of putting a stamp on every individual packet that comes in or goes out in order to assign that package to our particular virtual machine we will see where that is important on a later point in time the overlay is the ritual space in which the complete networking happens that's the room in which customer created networks exist this is the room where every customer is free to create as many virtual networks as he requires or as he thinks he requires in fact this is the case and this is the place where one customer can create thousand networks all move the same IP range if he considers that necessary and this is everything the customer has to configure in the actual setup how does the inter vm and inter host communication work in software-defined networking first let's understand how is signing packets to individual virtual machines works we have two hosts in the setup typically what almost all cloud computing or Sdn solutions do is they use week's LAN or GRE tunneling in the underlay remember that tunneling using VX line or giri is not stateful in fact it's stateless it's just a matter of the signing individual packets a certain level that is different a a certain tag that is to functionality I was referring to earlier and by using these texts or as they are typically called in the SDN context IDs I can actually determine what virtual machine a certain packet is coming from and I can determine what hosts on I am machine I am allowed to send an incoming packet tool and that's important because obviously VLAN on physical switches is used to separate customer traffic and of course I need the same functionality on my to networking infrastructure so just because I cannot use switches anymore it doesn't mean I do not need their features i still need packet separation between customers and if i have two virtual machines of two customers running on the same host i still need those VMS traffic somehow to be separated and this is where the VX land comes in and this is where the idea assignment of the ex land comes in very handy and very useful whenever a packet enters my host through the virtual switch through my bridge a certain ID is applied to that packet and that packet ID assigns this package to a certain customer and only those VMS on the host running with the same ID in place will ever receive the packet this is how packets route traffic separation on the host level works and this is also hot communication between two individual hypervisor words so if i have a virtual network I physical um is are a virtual network on two hosts and I do have that as soon as I have two virtual machines running on different hosts inside the couch everything that needs to happen is the packet coming out of my vm needs to be tacked by the SDN solution and this pays by the bridge that is responsible for doing via line into your eternal ink or GRE channeling then it needs to be sent over the cable and the host that receives the packet actually needs to read the ID that has been applied to the packet and then transmits the actual packet to the VMS on the same house with the same ID this is how traffic separation works as you can see here whenever you have a ritual or actually is whenever you have software-defined networking in place customer traffic is not going to get mixed because as soon as we have VX line or GRE channeling or any comparable solution in place we have packet ID assignments and as soon as we've packet ID assignments every actual packet is assigned to a virtual network and virtual networks do not mix I cannot reach one which will network from within another except for those cases in which I deliberately create a configuration that allows me to do that and I need to do that using a router so I the virtual router to correct to regional networks with each other but by means of default configurations I just cannot do that I do not have a rod to transmit packets from one server to another through the borders of virtual networks and the same goes for Internet connectivity so in this case it doesn't really matter a lot or with the hose that my target system is running on it's a virtual machine or something that connects me to the Internet network gateway is typically in the cloud context use another standard Linux kernel technology to allow network connectivity for virtual machines these are called network namespaces and in fact network name spaces on internet gateways do exactly the same thing that the VX land or Giri tunneling the San dividual individual hosts what network namespaces and internet gateways in clouds really do is they separate customer traffic from each other again if I have a network or if I have to virtual machines of two different tenants on the same physical server and they both need to talk to the Internet in clouds they will very often do it through one central gateway or there may be one then one central gateway of them there may be more than one central gateway but they are going to cross at some point so there would be danger of packet mix-up and abroad namespaces and software-defined networking are typically used to avoid traffic makes up of individual customer networks on the network gateways so with this in mind let's take a look at the SDN implementations we actually have available on the market right now I think the description of the presentation mentions free one is open we switch the other is controlled by juniper and the fruit is neural net by me to kula and i'm going to introduce these free individual solutions to you and mention the advantages disadvantages and also the most typical use cases for every one of them let's start with open we switch open we switch in fact is based on open flow open flow is an open standard on how to implement control planes in software so what OpenFlow actually describes this if you need to implement a virtual control play inside their installation then these are typical standard functionalities that you will require and if you implement them as we describe it you will be able to use them inside a network on many individual hosts OpenFlow is a standard that by now is available in a number of different revisions the most widespread implementation of open flow for linux is open V switch open reefs which itself is a kernel technology so there is a kernel module available on Linux machines named open vSwitch KO that open we switch module in fact is the part that on the bridge i have mentioned previously allows for the assignment of ids two packets coming out of VMs so whenever a packet comes out of vm the bridge that this vm is connected to automatically assigns the ID to the packet and that part is done by open we switch and the linux kernel the open we switch implementation in use on most linux systems actually requires help so the linux kernel module does not assign packets automatically actually what needs to happen is a configuration needs to put in place on the individual hosts and only individual breeches it needs to contain the information which ports are assigned which ID open V switch only provides the technology to do that but I need an agent or some other sort of external component to actually implement these hyman Dolph I teased or actually to configure it the assignment is done by open research yourself I'm sorry but the configuration on which port belongs to which ID needs to be done by an external agent openly switch has already mentioned earlier uses VX land or GRE is anyone in the room that not familiar with goe actually is ok so jury is generic routing encapsulation and it really is just an encapsulation protocol for standard ethernet links um it's an encapsulation protocol that does not do any encryption actually I think that's the best way to describe it I've already mentioned the kernel module the kernel module is used to create virtual switches on the individual hosts at the one problem the one big problem that open we switch actually has is the fact that there is no central database of networking information which leads to lot of overhead if you take a look at the OpenStack documentation that explains how to set up open we switch inside and openstack cloud you will see a big fat hind explaining that the documentation contains a valid set up but this setup is only valid for a proof-of-concept installation so let's take an example let's see what this actually means I have a network of hypervisors and I have many virtual machines running on these hypervisors inside my class they are belonging to individual and different customers so in fact I need a way to talk from one vm to another as you are probably all familiar with networking protocols you know that before a virtual machine inside I set up like this can talk to another virtual machine it needs to figure out where that virtual machine actually is needs to find out where it can wear it needs to send a packet in order to be able to reach the other virtual machine and an open V switch um let's imagine we have this example we want this virtual machine to talk to this virtual machine what would happen now is our proquest would descend to all hosts inside the Giri Network creating a lot of overhead because in fact our virtual machine is not actually knowing where the other virtual machine is running at the amount of overhead traffic produced inside an open V switch installation is massive compared to other solutions I have seen setups in which the overhead of the open we switch installation has actually saturated a network so the bigger the network grows the more traffic you have the more overhead traffic you have this is not traffic horse by a customer's this is all traffic caused only by the overhead of your as the end solution so whenever something goes wrong inside the set up there is very little spare amount of technol above capabilities left for for any emergencies this can easily set aright your network and this is why all open research solutions in fact are marked as experimental or proof of concept whenever you try to install OpenStack or do anything that is related to open we switch keep this in mind if you want to run open we switch in fact open research is a wonderful technology but as a standalone solution without any external hub it actually is not going to be very useful for your set up the second solution that we need to talk to serpent contrail open control is a solution that we at this 11 have tested and evaluated very intense and we actually invested at least one year of time into looking into open contrail and trying to work with it open control originally was designed by a company called contrail it was later bought by juniper and open control comes with a lot of very interesting and very great features when it comes to network connectivity um in terms of technology in fact open country probably is the most at one solution on the market there is a number of features inside up and contrail that will wonderfully connect the original machines one to another up the setup of the thing actually is something that's hairy but we'll come to that in a minute if you take a look at the diagrams and the actual standards describing how virtualization and open be an open control works um that is the one solution that will immediately give you the impression that these guys have actually gotten together their paperwork open contrail however comes with a very very big problem or actually it comes with a number of different problems and I will talk about these one after another first of all open contrail um actually consists of at least 11 demons or it did the last time I looked into the thing probably by now it's going to be free in 215 if they continued to invent new demons the speed they did when we were looking into it and many of these will just crash so many of these will basically just go away and you will not even notice because they're immediately we started by your unit system or by upstart or by whatever you have in place and still at some point you will realize that functionality inside your cloud is actually there because again this or that one component of open control has failed so open control and a number of components that are part of open control in fact will not run in a reliable way also there is a security problem so one of the thing the open control installer does is it downloads a very old version of pines monkey patches is and then install this on your system so you can have dns as a service and it's going to be a five years old bind and some whenever somebody finds a floor or a security hole in that bind obviously will be screwed because some you will just make the bike crash or in the worst case scenario will just overtake the control over the band installation that you would just have installed so in fact open flow is not only unstable it also is unreliable during our tests and trials we had a number of scenarios in which the software-defined networking layer did not actually behave as we would have expected and it was not obvious for us why that was the case we had a number of events in which the actual inventor of the software so the guy that originally found a contrail was logging on to our service using screen and then this assembled parts of open contrail on the shell in gdb just to figure out what exactly might be the problem this particular case at 3am the morning which was very awesome at least for for him because he's in the stairs obviously it's not something you want to have in production it's like a black box and whenever you something is wrong with it you will definitely require hub from Quantrell and you will need somebody from contrail to help you fix the thing another big problem that we have with open control is technology dinger what do I mean by that here is a list of technologies scripting languages and tools that are part of contrail or need to be used for contrary to work open country comes with a separate kernel module that actually installs a separate networking driver in the linux kernel so traffic is caught in the linux kernel by that kernel module and whenever something goes wrong with the kernel module if the machine actually boots up because the colonel mallu did not crash it this time you will need to find somebody who is experienced and Colonel programming to figure out why something why packets in the kernel are magically disappearing which happened quite a few number of times during our evaluation there is if map who knows if map when we talk to the vendor we were told that if map is I standard that everybody knows these days very happy that's apparently not the case we have sandesh sandesh is the indian word for a message it was a this is an invention by country so its intervention it's a protocol that was invented by the company that originally also invented contrary its ex-mla we're if munoz fift somebody at least so they talk xml / Rifton that is what they use as their internal message bus except for those cases where they require a rabbitmq because rift or sandesh didn't work for some reason we have C++ Python we have no GS we have iron d which is also is written in Java we have Ruby we have number a number of shell scripts for instance the thing that I just mentioned about downloading and patching binds actually is a shell script we have a number of databases and state configuration databases and use we have writers with Cassandra we have zookeeper we have Kafka in fact the amount of traffic and billing data produced by contrail was enough to SATA raid a free nodes Cassandra cluster at ease which was something that we also didn't like what we have XMPP we have BGP we have mpls these are the great parts of open control because then try to use official protocols because they try to use standards just the way they did it was not very smart in this case we have the enterprise edition of open country which comes as I 700 megabytes large Debian package that will basically contains X hundred as 600 w packages and unpack them to a temporary directory and then install them one after another using dpkg dash I in the person's latian script of the package and that is what they will charge you for so if you buy open contrail or if you buy control because that is the commercial product so it's controlling an open contract from juniper that is what you will basically get from them and that is what they expect you to install of course they have tested this probably on their debian and stands inside ritual books on your macbook air um I'm not sure about that but that's basically what you get if you actually get the commercial version of it so that is something you definitely don't want to have in the installation it's a big black box if it actually works the open slack and super integration is great so they have a separate module for the OpenStack networking service Neutron and you can just load that module and it's actually going to do what you expected to do at least most of the time if all the I reopen control components work of course which many times did or not and you have a prince or software in its core open control is available as open source software there is commercial support available in a certain way we were never able to actually find the one product inside juniper though that would have given us the support so we had contacts multiple people and they weren't able to actually just um sell us import some some sort of a commercial support for this solution you have a shiny web interface there so things don't work you can still click on the web interface and show up something gets better last button these there's media net media net is completely different from weapon contrail it's a development from scratch the company itself is called me to kula they are based in Japan which is helpful sometimes if there is a problem inside the card because all you need to do is telling them that they put shame on the name of the convenient that gets things thanks really quickly internet basically has open V switch at its core the awesome thing is that they do not require any custom kernel module they will just basically use whatever they find in the standard kernel of your distribution and then they will apply the configuration on top of that kernel module that they find it doesn't hurt to use an you're openly switch version then you can find in most of the newest distributions available on the market but in fact it's not deadly necessary so if you decide to go with your distribution you can just do that and actually things are games were pretty nifty the one big difference between little net and the standard open we switch configuration is that meter net at the central database of knowledge that open this which lacks so if you remember the scenario that I had on the slides earlier where one virtual machine tries to talk to another and suddenly every virtual machine in the setup and every host gets a number of up requests because the things need to find each other first this is solved in a very smart in a way smarter way in biddo net and it actually is solved inside the basic up in research setup let's imagine we have two virtual machines again and they want to talk to each other so the machine that is on the lower part of the slide needs to talk to the one that's on the upper part and it needs to know how to reach it it needs to know what physical house that virtual machine is on it gets to know where to find the ARP address for that particular I was typically a switch would do that having its ARP table available but we do not have a physical switch in this case with the ARP table so we need to replace that functionality the virtual machine can actually ask the central database inside meeeee Internet where to find that virtual machine it only needs to do so once because actually as soon as it knows where the virtual machine is it can just put packages to that machine on to the so-called fast path the answer in the machine that in the database is actually stored so the answer is this virtual machine can be found on that and that physical house and now the virtual machine that needs to talk to everyone just knows where to find it and can actually start talking to the other virtual machine and whenever these two need to talk again to each other the whole process of figuring out where the other machine this is not necessary anymore in fact this happens on the Asian side of things there is a separate agent for me to net that's called middleman and middleman actually emulates ARP answers so whenever a virtual machine tries to find another one in the installation and the fires our up requests this up request is never going to leave that particular machine it will automatically be answered by the middlemen agent and the virtual machine will still know where the other target which will is this reduces the overhead massively and as already mentioned it only requires the standard up in research kernel module module net is very well integrated with weapons tag in fact OpenStack is the number one de facto showcase form you donate I think they support other virtualization solutions but the only thing they ever actively advertise for is the open you switch port of things and there is by now a small number of really big public clouds running middle net in fact we also decided to go with the solution in the end at least for now based on the experiences that we have made for the other solutions it's open source software but commercial support is available if actually if you ask them that you want to buy support they will sell it to you which is awesome if you had been fiddling with juniper for a month prior to that and they also have a shiny web interface so whatever you want to do in sight lido net can be done on the command line it can be done using puppet they buy now are working on ansible integration which is going to be awesome and they also have a shiny weapons your face in which you can just click on things that was a brief comparison of the three different technologies are there any questions from your site mr. now is the time to ask them I will not go into somebody asks yes thanks just just a minute okay and what about failover functionality of this database rather than networking information is based on 44 am internet you mean yeah okay so um all configurations inside leader net is in fact stored in zookeeper zookeeper itself is a reliable database or in redundant database you can't have a zookeeper cluster and in contrast to other solutions zookeeper is able to take care of its clustering very well so as soon as you have a zookeeper instance failing the only thing that will happen is other virtual machines or no sorry other middlemen agents in the setup that previously talked to the one now failed zookeeper instance will automatically talk to another one okay forever most recipes anyone first row what would happen if we have a field hyper voice on the Virtual Machine moves to the next one so the question is does a virtual machine migrated over to another hypervisor if the one that's running on fails from the SDN side of things and OpenStack that's another problem you donate can do that actually it will automatically depth in central database to know that the virtual machine is now running on another house just like it would if you live my greater machine live migration is supported as well the big problem in the OpenStack example is likely hearing to be OpenStack because OpenStack by now it's not able to migrate a virtual machine or inter actually restart a virtual machine from from a failed host on another host unless you explicitly tell it to do so so it doesn't do that automatically but that is more a problem of the cloud solution out of the SDN solution the SDN solution you don't net in this case I'm actually supports that without any trouble did it answer the question that's that's what I thought yeah seeing your face the middlemen agent running on the machine actually sends a typical ping to the actual tree actual mirror and API so there's an API available in the setup and every agent regularly reports to the API that it's still alive um again then that's important to understand here migrating or restarting a failed vm on another host is something the cloud needs the cloud solution needs to initialize so um what your net really needs to do is just catch the notice that this virtual machine now is migrated to another host or is started on another house and then act accordingly that's not something that the SDN solution has a lot of stake in yes please they make sure you get some training just to make sure for me donate the agent only lives in the host and the vm itself sees a standard ethernet interface that's right yeah the in fact what the middleman agent does is it does create a tap interface on the host that is then part of the virtual machine but there is no component of media net whatsoever of any sdn solution for that matter running inside the virtual machine for original machine when running on top of SDN the networking looks exactly like it would look if it just was a standard virtualization who has proved kvn auction or something and the peg agenda lling in the host is completely done with the open V switch kernel module and there's not no other handling concerning the data in the packet hoods of not for the SDN part of the solution anything that relates to the sdl solution is taken care of by the european greece which kernel module if the task needs to be done in the kernel is so the jury tunneling and antiques land tunneling for instance are there any further questions ok so I have some final remarks first of all if you are able to speak German there is an article on the whole thing I've been talking about on ghulam actually it was written by me which is a nice coincidence so if you want to read up on today's presentation you can just go ahead and read this article it's available for free on the internet if you want a more distinct explanation of open contrail and what open control actually is there's another article available also written by me and this is behind a paywall there so if you have this issue of the German X newspaper then you can still read it and the other if you don't have that you can actually buy the PDF on the link and the same goes four minutes um actually I just had this in the post yesterday so there's an article in this issue of the newspaper unmute Oh Ned written by me as well and if you want to look at it then just go ahead and the most important thing actually is if you like cake we are hiring so this is the man of cake that we had served in the last four months that's 11 by individual employees and if you like cake then please feel free to just give us a call or go to the website and have a look and I will be very happy to have you and have you bring cake or have you eat cake whatever you prefer more thank you 