 So, this afternoon we have a great treat. We're going to be joined by President Salovey. This is our third year of the Day of Data and each year we strive to get a senior administrator to come and talk to us and this year we struck it big. We got the university President. He has pushed aside the provost this year, but Ben was okay with it, and then we'll be hearing from President Salovey. He has a long career here at Yale where he started as a graduate student and was a professor of psychology, and through all of that work, himself has worked with data a lot, so this is both important to Yale as a whole, but also to his own personal research. So, let me introduce President Salovey. (Applause) Well, thank you very much, Susan, and welcome everybody. You know, I just want to say something about Susan. When we hired a university librarian a few years back we were looking for someone who would interpret what it means to be the university librarian in the broadest possible way. You know, not just a custodian of book collections, but a kind of recognition that the contemporary university librarian is someone who really facilitates research scholarship in teaching by essentially making resources of all kinds that can be archive collected, organized, interpreted available to them, and Susan has interpreted that charge, that mission, that job description as broadly as anyone on this campus and we are very, very fortunate to have her in that role. It's wonderful to have someone who respects the old and the traditional and loves books, but also is not afraid to embrace and rush toward the new, the entire technological end of all of this and she does both very, very well. If you really haven't ever gotten to know her, you should. Take a minute and introduce yourselves and find out what's going on in our library system. So, it's a pleasure to be here. This is the third year of an outstanding program that has proven quite popular on this campus. I think it is a testimonial to both what libraries do and what librarians do, but it also helps to galvanize a kind of collective interest in the use of data in research and data management as well throughout the campus. What I love about the theme is it's so cross cutting and so interdisciplinary, so, as you heard, I'm a psychologist, I work in a data intensive field. Most of our data are either gathered in experiments or in big field studies or sometimes in survey research and sometimes use of archival sources, mostly quantitative and that's only just a little tip of the iceberg of what is possible, but very dependent, as a psychologist, both on what capacities the university had to manage data, make it available, but also data analysis interpretation. And what I love about this theme, The Day of Data theme, is it really cuts across disciplines like my own and sort of says what are common ways of managing, planning, using, interpreting data. I think many of you know, when I became president two years ago, I talked a lot about a more unified Yale and, in fact, the theme of the inauguration, which was two years ago next month, was going to be One Yale. And a couple of weeks before we were going to announce the theme One Yale, Harvard announced their fundraising campaign... One Harvard. [Laughter] And so, we realized that we had to do One Yale implicitly, and so, you may have remembered posters and tote bags and things that would say Many Disciplines, Many People, Many Nationalities, Many Departments, many this, many that, many this, many that... Yale. Right? It was one Yale - it was the implicit One Yale. Well, you know, when it comes to thinking about data, numerical, geographical, textual, visual, I think we are one Yale. I think we can take a kind of unified approach to management, organization, accessibility, consultation... all the tools and assistance that anyone in this room and beyond might need and, as a result, do it in a way that makes this among the easier places to actually get work done. You know, you just have to look around a little bit at university initiatives of the last year to see the ways in which research data can be used to address complicated needs of this place, so, you know, the opening... I make it sound like it was yesterday, it wasn't yesterday... but the opening of the Center for Science and Social Science Information was created three years ago explicitly to support data management and analysis in what had originally been a wonderful home for largely biology books. The Yale Center for Research and Computing which is supporting advanced computing, data processing technology makes its resources available throughout the research community. The university library's Interdisciplinary Digital Humanities Lab provides expertise, equipment, facilities to faculty and students often in fields who didn't think of themselves as data intensive fields but now discover what they can do with data. There's a data policy committee appointed by the provost and charged with developing guidelines for acquisition, management, storage and they're going to release their recommendations later this semester. So... I'm hoping that the Day of Data - my guess is the Day of Data has something in it for everyone. I hope it stimulates you to think about new ideas, new approaches to information, new opportunities, maybe new supports and services that Yale provides that you didn't know about. If that happens, that would be a great thing because we want nothing more than the ability for you to produce world class scholarship and research and then to teach, to provide the best teaching, I always say the most excellent teaching but that sounds like - what are those characters who have the excellent adventure? Bill and Ted? Bill and Ted. It sounds like Bill and Ted when I say and provide the most excellent education in a research university environment. This is part of how we do that. I don't want to take more time but because it does give me great pleasure to introduce our keynote speaker today. This is Chaitan Baru. He's from the University of California, San Diego. He currently serves as the National Science Foundation Senior Advisor for Data Science. In that role at NSF, he supports collaborative efforts pertaining to big data and he's going to speak today on the topic of Data Science R&D: Current Activities and Future Directions. So, let me ask you to join me in welcoming Chaitan Baru with a very warm round of applause. Thanks. (Applause) Just a second as I get this fired up. Well, thanks very much for that introduction and actually, thanks to the organizers for inviting me here to give this talk. It's a real pleasure. What I've heard so far in the session, in the morning, I think there's a lot of excitement across campus in the area of data. This is your third year to do this. My sense is each year this has been building up. It must be because there's so much going on right now that I can see. So, this is my first visit to Yale in this capacity. I think I've been here once maybe 15 years ago as a tourist, just touring New England, happened to go through New Haven. But I took the train up from Washington, D.C. ...it's actually a very nice train ride. You see some scenic spots along the way. So, very happy to be here. I think my task in this next hour using the clock that actually works as Bob found out, is A) not to put you to sleep right after a nice Panera sandwich; and B) to just give you sort of, let's say, 25,000 to 30,000-foot level view of the variety of data science, big data activities that are going on, mostly at NSF and I love to say a little bit of the interagency things. So, hopefully, you'll get a sense of the landscape of things that are happening. Needless to say, this is a really exciting times for data. We'll get into some of these during my presentation. As everyone says, there's nothing new about data, especially scientists will say that's what we've been doing all along, so we'll touch a little bit upon what makes it new and different now. The reason I actually decided to leave San Diego and go to Washington, D.C. and take this - this is actually a new position at NSF, Senior Advisor for Data Science, and I thought this is a really interesting time to be there, both to help NSF think through some of these plans and do some of those interagency things. So... All right, so, let's get started. So, I purposely used data science R&D in my title. It doesn't say big data and I'll come to that. The presentation will primarily be, of course, from the point of view of NSF. So, NSF's perspective and role in the federal government is, you know, it's the agency that supports basic curiosity doing research and these are the words from the actual mission of NSF: to promote the progress of science; to advance the national health, prosperity, and welfare; to secure the national defense. Actually, after I went to NSF I went over Bush's original report that put NSF together and, in fact, what is now filed in that all was in one organization and then things split later on. So, let's get into the topic right away. This whole phenomena of big data, which I don't have to define, you already heard that from Bob this morning, I think fundamentally what it has done, why are things different now considering that scientists have always dealt with data is just the amount of data and our ability to so easily collect so many different types of data for any problem that we are looking at has essentially forced on us greater awareness of data. It's no longer taking some data set that you collect or somebody else, in fact, primarily that you collected and did something with it. Increasingly there are data sets that others have collected, increasingly there are requirements, some of which might come from the federal government. Let's say you have to make this data available for a long term, and so, you start worrying about what does that mean. Meta data, context, sustainability, etcetera. So, the way I would say this is there's just greater awareness of all aspects of data. And this goes, by the way, not just in science but in business. As you know, the term really sort of got adopted by folks in business and Strata Hadoop conferences later this month... I think Bob mentioned it. I'm actually planning to attend. I hope some of you will be there. It's really a totally energetic and exciting place to be. If you just want to see the extent of stuff that's happening in industry, Strata Hadoop conference is a good place to be. So, while there is in industry or in science, we've sort of thought about traditionally it's been about just looking at cleaned up, structured data and doing the analytics. Now, we realize that, as we get not just designed data, but what is called found data, so not just data that you created but maybe that others have put together and you're using it in some way in your analysis, you realize that you worry about the entire life cycle of data. You have to have much more awareness of what is the context in which this data was collected, what is the context in which I'm reusing it. It's all types of data, it's unstructured, some is structured. We heard about text analysis this morning. There's all sorts of image data that we collect. There's maps... spatial, temporal... all of that, and as context becomes important and reuse becomes important it's as much about the meta data so that there is some understanding of what this original data set was as it is about the data itself. And at the end of the day, all of this has to be processed efficiently and used. So, if you collect data an you never use it, it's like not collecting data at all, right? And also, if you look at in business, and increasingly in some of the sciences that are collecting lots of data... actually astronomy comes to mind, but increasingly I would think things like genomics, etcetera, there is this issue of timely use. I think we are pushing more and more and more towards real time online analysis of data. If you think of it, that's actually one way by which you can avoid collecting a whole lot of data if you can just process it in time and make use of it or not and check it or maybe just keep a representation of it. So, essentially, as was mentioned, I'm originally from the University of California in San Diego at the Super Computer Center, but my background is as a computer scientist. I'm in the field called database systems. So, if you are in the data field, these are absolutely exciting times because all the stuff that you did 10-15 years ago is all coming back, and in even more important ways. So, that's definitely rejuvenated and created a new research agenda around data. Actually, there was a question I wanted to ask, so let me do it now. It's one of those strategies to make sure that you're not totally asleep. So, let's see, how many folks in the audience are faculty members? Okay. That's good. There are some, but there's lots of non faculty, so I assume a lot of them are grad students, maybe some are staff. How many in the audience are computer scientists? Right. So, I think there needs to be more computer scientists in the room, but that's one of the things I will talk about, data science. In fact, here it is. So, if you look at NSF, the kinds of things that NSF funds, it stretches the whole range from basic research on one side and infrastructure on the other side. Now, the infrastructure that NSF funds, of course, is in support of basic research, so usually it's an instrument of some type, you know, regardless of which directory that you're in, whether it's geosciences or astronomy or ecology, etcetera, these are all about building state of the art instruments that can collect more data and, of course, that's what they're all doing. NSF has programs across the spectrum, basically search, as well as applied areas, there are programs for, for example, creating software that could be used by a discipline and maybe re-used by others. There are programs for networking. There are programs for actually having super computers and storage and there are big programs in many of the directorates. I don't think computer science particularly doesn't have any, but many of the other directorates have programs for data archives. These are community scientific data archives, ICPS already was mentioned, and there are many others. And there is, of course, a division at NSF called the ACI, which is part of CISE that funds things on the infrastructure side and education and training is also a big part of all of this, right? So, there's education and training, both on the basic side and the infrastructure side, that is, there are programs all the way from doing research in education to supporting graduate education, the NRT program that's there, which used to be the IGERT, but there are also programs more on the training side. So, if you are a scientist, you want to use some computational resources, increasingly I hope there are also such things for data resources. Then there are programs that allow for training in that area. So, this whole field of big data and now introduced data science sits across all of that. There are activities at NSF that are in that box, or that circle, that cut across from basic research to infrastructure to education and training. I'll say a little bit about that. What has this done then, data science, and actually it's in the title of the position I have: I'm the senior advisor for data science. And one way I like to think about it, and maybe it's partly because I'm also from a super computer center, is, you know, big data is to data science as supercomputing was to computational science. In other words, I think there was a reference earlier that more is something different. Right? So, when you have more of something, significantly more of something, you really enter a new state and that's basically what supercomputing did. When you had that scale of computing available you had all sorts of new computational methods in all sorts of disciplines. It's not just physics and astronomy, it's everything all the way down to social sciences now, and certainly ecology and all of those areas looking at computational techniques to the extent that we said, okay, that's a discipline in which some training needs to be given and there are several, at least graduate student programs, in computational science that get you trained in how to model things that are using computational science and then how to do them at scale. This term wasn't mentioned today, but you may have heard of this notion of the Fourth Paradigm, right? So, the third paradigm is computing, the fourth paradigm is data, so computational science was the third paradigm. I think what big data has done, that is, the availability of so much data of so many different kinds that could be used in so many different contexts has created the need, as I said earlier, to understand the full life cycle of data, to get a much more in depth training on all of those aspects of data and not just sort of stay on the edges of it. And I think that basically leads to creation of data science as an endeavor in itself. So, I'll say maybe quite a bit more later on about various activities that we are supporting and the community is doing in pushing forward the data science agenda but actually a lot of what I heard this morning, the Yale Institute for Network Science, is an interesting one. There are so many common problems with data that are seen across so many disciplines that, that itself becomes something to be studied. And we also heard that even in something like the law school, they would like their students to receive at least some training in data, so there's also this notion that if you had a core body of knowledge, that information could be imparted through specialized courses to different other departments and domains. So, I think what is emerging here is this notion of data science and that's why I titled my talk as Data Science R&D. If you zoom into computer science, as director at NSF, we certainly found things on the foundational research side and the other directorates at NSF, we, computer scientists, think of them as the domains. Those are the guys who have some problems that maybe we can help them solve it. The Big Data program at CISE, in CISE at NSF, is really the one that connects the two. So, big data, if you think in terms of proposals, a successful big data proposal is one that really bridges these two in an effective way. It's looking at new fundamental techniques. Maybe it's scaling, maybe it's a new algorithm, with a real problem that needs to be solved in the domain science or engineering discipline. So, one of the things I do in my other life, so some of you may have been at NSF, but if you're at NSF there is this notion of IRD. You can do your independent R&D. You get some time to do that and one of the things I do during my independent R&D activities back in San Diego is related to benchmarking of big data applications and we run a workshop every year and the next one is in December in India. And one of the speakers, once who is from Facebook, came and said, big data to us means big. Right, so if you're on Facebook, the notion of big data, it's just big stuff. There's petabytes of data. Facebook has something like 20,000-30,000 instances of MYSQL database because every data science with Facebook basically goes to work every day, pulls out some data from the big well of petabytes of data, creates their own little database and they're trying the next ad placement algorithm or whatever it is, right. So, there are some people for whom big data just means big. But what I like to say is big data is also about data. And the data comes from disciplines, so if you're a computer scientist looking at this, there are increasingly areas in computer science that are sort of data intensive... network engineering is one. There are groups that have collected lots of Internet traffic data, but by and large, at least so far, computer science has not been a data intensive field but what computer science has done is work with data that may come from other disciplines, and I'm talking in terms of a field doing its own research. So, data has to come from domains and, therefore, if you're doing big data research as a computer scientist, you need to be very intimately tied to the domains. There are certainly examples of big science data. I won't go into all the details of this, but I'll just give you a laundry list of names, many of these, many of you would have heard of. LIGO is a physics observatory generating a petabyte of data per year; LHC, Large Hadron Collider, you've all heard about it, it's collecting 4 petabytes per year; LSST is the newest NSF big instrument project that just got inaugurated down in Chile, I mean, the construction has just started, and that's going to generate 100 petabytes in 10 years, at the end of the day it'll have a 10 petabyte catalog database, or just a catalog of stuff that's in the sky and the last 10 petabytes of actually the structured data; of course, NCAR is an NSF funded center. They do a lot of observational data and they also do simulations. They have a new super computer that's able to do bigger and bigger simulations and generate more and more data. There are a couple of other observational projects at NSF. One is EarthScope in the Geo sciences that's essentially trying to do a 40-snapshot of the lithospheric structure of continental U.S. So, they have seismograms and other instruments that have swept across the continent and collected all this data. And there's the Ocean Observing Initiative collecting data from ocean sites. There are other new things coming along the way. You might have heard about this interest in something called the Materials Genome Initiative, which is more in the chemistry and material sciences. That's a very nascent area. In fact, that community is trying to figure out what their data challenges really are going to be and one of the things that they encounter is heterogeneity of data. Right now, the amounts of data may not be large but they collect all sorts of different kinds of data and the idea here is to see what you can do by data collection to speed up the materials, discover and smart... eventually leading to things like smart manufacturing and so on. All of these projects, as I've mentioned before, are instrumentation projects. They get funded through the special mechanisms that NSF has for one-time allocation of large chunks of money that go towards building these things, so these are called the MREFC, Major Research Equipment and Facility Construction awards. Usually in the few hundred million dollar range, but I think this term was also mentioned today. Somebody talked about data scope. Maybe it was Bob, I can't remember now. Data, in some sense, is the new instrument, so if I have a lot of data available to me, like this data scientist at Facebook who goes to work every day and the petabytes of stuff that we're doing in terms of click streams and images that we loaded up in Facebook, that's their data. Increasingly, we're going to go to a mode of operation where just analyzing that data is the work that you do. So, it's not as much on the collection side, it's more on the analysis side. I'm going to come back and talk about that actually as one of our challenges. How do we make sure that, as a community, we actually have access to more and more data? That's going to be a bit of a challenge. This is very quick. I think some of you would be very familiar. I'm in the CAC observatories, I think jointly run by Yale which was up in Mauna Kea and I was at the VLDB Conference. I don't know if any of you had gone there, was just a couple of weeks ago on the big island, and I actually went to Mauna Kea, first time in my life, and saw some of these. Basically, what these communities are facing that increasingly all of the rest of science is facing, is they're able to easily collect data which is much more than all the data you had so far in the history of the field. So, in the case of astronomy, within a decade over 140 terabytes of information was collected so far before Sloan Digital Sky Survey, which is already a decade or more old, and within the first few weeks the Sloan Survey all took that. LSST, in the first 10 days or so overtakes what Sloan collected. So, a huge rates at which these data are being generated. Now, if you step back and think in terms of where we are in all of this as an R&D discipline or R&D activity, at the bottom what I try to show with my funky little diagram is, you know, so far what we've been looking at in the data area is building data acquisition systems that can collect lots of data, building data repositories that can serve community data sets. Perhaps developing knowledge structures, anthologies or semantics of the information so that they can be proper reuse and use of the data. Ideas like the data commons so that data can be shared. So, I can think of all of those as sort of the infrastructure that's around data and a lot of what we have done so far is in that area. The research programs that NSF is funding right now, in fact, our big data program is actually called Critical Techniques and Technologies for Big Data, I think are the next level up, which is you already have these building blocks, how do you now build systems that allow you to make use of data in a much more facile and easy way, or maybe develop new algorithms on the data that you have? And some of this speaks to this idea of the human data science interface and, I think again, Bob mentioned that. So, you could either the horizontal bar, meaning that you could build technologies that take existing pieces and put them together and make them much more usable, maybe you build workflows, etcetera. The vertical piece meaning that we might be inventing new ways of doing things that we may have to go back and change some of what's going on in the technologies. So, Hadoop was mentioned earlier, so if you look at something like Hadoop, people are, in a way, reengineering Hadoop to make it much more online. So, when Hadoop first started off it was kind of more for batch oriented processing paradigm, but people want to process these huge amounts of data using more of an online paradigm, so maybe we have to go and reengineer some of those things. So, that's the kind of idea. So, I think of what's down below and what we have done so far as the first generation of big data and I think where we need to be heading is the second generation, which is actually the use of the data for useful things, whether it's in science or societal applications or business applications. So, it's the application of this data towards some objective is really the target. So, what are the challenges in doing this? How do you promote and incentive interdisciplinary research? I think just like you folks are doing here, I think - I don't know if I can say all - but many campuses are facing this issue. How do you bring folks together on campus? If you really think about it, people's life on campuses also hurdle at light speed. Everybody has stuff to do. They have to publish their next paper, graduate the next tour and teach the next class and then we are asking them to do this interdisciplinary thing so there's a challenge here and how do you incentivize that is one of the challenges. One way, we think, would be through research programs that require you to interact. Another challenge, as I mentioned, and I'll be coming back to this theme, is how do we provide access to researchers, to interesting and real data? I think that's a real challenge. It's at the crux of breaking some of these bottlenecks and getting more interesting results out of data. Again, if you think in terms of Generation 1 and Generation 2 that I just showed, we are still sort of in the Generation 1 where we're collecting lots of data. We would like to move to Generation 2 where the data is available. And what you should really be doing is using your smarts to analyze the data and do something interesting with it. So, how do we get there is a challenge. Another challenge I see is how do we provide the platforms, and this is, I'm talking about in academia, that allow you to do data science research. And when I say platform, I mean the hardware, the software, and the data. They're all part of the platform. There are different parts of the research community that might just want a big hardware platform so maybe they can dial up the next hadoop or next something, right? There are others who want to use the available software to do some analysis. One of the things I've heard from the community certainly is the data science, databased type communities, a lot of papers are published about results, you know, how good, how fast something runs, and there are many such papers. Every paper uses its own system and these papers are really, at some level, not compatible because they're all running on different hardware doing their own, essentially, assumptions. And so, if you really start getting bothered by that then you say, well, could we create some kind of a platform on which we can have compatible results? And finally, the last one, which is right now, at least to me, seems the holy grail, is there are researchers, at least we would like them, to just work with the data. So, I give you the platform, I give you all the software, what I want you to do is do something interesting with the data and this could either be generating new algorithms or coming up with maybe new science or new ways of making decisions with the data. So, all three are part of the platform. The reason this is a challenge is, you may have heard of this, and people are now calling this the brain drain, right? I've been in discussions where there's a concern of the brain drain, that is researchers leaving academia to essentially go to Google and Microsoft and Facebook because that's - why are they doing it? Because that's where the data is. So, if you really want to do interesting stuff with real data, people are moving off to those places. Certainly, I know at UC-San Diego we lost several of our colleagues; one to Google, one to Amazon, one to Microsoft. And if you're a systems person that's where the big platforms are. So, I think this is something we need to address and how do we do this? So, maybe this is my chance to do the soap box on this one. A few decades ago the thing that universities couldn't get their hands on was a super computer. The most any university could buy a super computer like a Cray, the one that Bob showed in his slides, the circular thing. So, therefore, there was a national program that said, gee, we'd better buy these things and make them available to the community. Today, what most single university can buy is a cluster that Google could have, 100 or cluster. So, how do you facilitate that? So, this is, I have certainly started with folks in the community who are very interested in at least thinking about how to go about this problem so maybe some of you will pick up on that. Education and development of a new pedagogy in data science, and I'll come back and talk about that. So, data science becomes a thing unto itself and so how do we develop education programs and what are the principles of data science as distinct from computer science on one side and statistics on the other side. Sustainability of resources, another big problem. So, those of you who are running campus resources you know that we have data management plans but how do you keep this going? Reproducibility of research is another big issue, and I was mentioning to someone, the director of NSF just had a seminar a couple of days ago, a one-day workshop on this issue of reproducibility and I think it's a big, big deal. If you want, we can certainly get into discussions. I won't say anything more about that and I already mentioned the brain drain issue. So, let's see... I'm trying to see how I can liven this up. Well, I guess I just have to go through it. This is the 30,000 foot level thing I was talking about. So, if you think in terms of the investments that NSF does, and actually, this would apply to any federal agency that's doing R&D investments, this is a reasonable quadrant diagram that we all have started using to describe that. So, in one box you have foundational research; on the other side you have cyberinfrastructure, the facilities; there's education and training; and then there's, in a way, it's something which we call community building and the reason that's important in big data is, again, because of what we said before. This is a field where we are trying to connect technologies, and I don't mean just computer science, it's statistics, math, CS... all of those... with end application, real applications. And that requires forming collaborations. It also requires collaborations that are not just among academic institutions but what we call multi sector, so academia, industry, and government, and it's government at all levels... local, state, federal. So, that's an important part of trying to accelerate sort of the whole ecosystem. And in the middle sits policy. Again, somebody mentioned data policy, I think maybe in your talk, NSF has put out a data policy and so these are all things that govern all of this. So, quickly, in foundational research, big data is a program out of NSF. We've just announced the awards. I have some numbers later on. I think we funded 30 proposals this year in big data. It's a cross-fitting initiative. It involves all directorates at NSF, it also involves an agency called the Office of Financial Research, and I might have something later on that, but Wafer was set up through the Department of Treasury and their task is, essentially, to build a model of the financial system of the country so that they can try to do some predictive models of where the financial system is going. They have access to very interesting data and they also have access to extremely fine-grained financial data that is confidential, but researchers can get access to it in the NBA sort of way, so it's sort of like working with census data if you're a demographer. You can get micro data out of census, but there are some rules and regulations. So, OFR is the same. We also have a program called CDS&E, Computational Data Science & Engineering. The distinction between these two is in big data we are really looking for an edge that makes it new and different because of the big phenomena. Again, it's all those V's that you saw in the slide. You know, they have lots of data, scaling is an issue, or if you have lots of data maybe simpler models work better than more complex models, or actually complex models won't work because they're just too computationally intensive. Maybe you have a variety of data so a lot of heterogeneity in the data. Maybe it's semantic heterogeneity or some other form of heterogeneity. So, it has to be something in the big data solicitation where it's pushing a new aspect of data, whereas in CDS&E, the focus is more on your pushing a new science. You may be using a standard, a graph method that we saw earlier, you know, there may be some complexity in the graph as to what the nodes mean and what the links mean, but what you are really pushing is the science that comes out of it. So, that's sort of the distinction between the two. And we also have some special programs. Big Data for Disasters was a program that was done with Japan. There's one called FutureCloud, which is sort of a largish scale platform, but it's much more focused on really sort of operating systems and network research and not so much on the data research itself. And FutureCloud has been awarded, I think there are two platforms in the country which are meant to be community resources. Cyberinfrastructure, I think you know about this. The ACI was mentioned before. There is CC*DNI. I think I heard Yale must - you've got one of these 100 gigabyte awards to connect the campus, so these are for high speed networking, building data resources, and for HBC platforms. I mentioned NRT on the education side, and I'll come back to tell you a little bit more of what we are doing on education. And one of the things that we have started for the community building is this new program called Big Data Regional Innovation Hubs. Those awards were just recently made, I believe, and I'll say more about it, so let me keep quiet for now. And all of this is in the context of all of the policy issues that are coming out, everything from the DMP. You have the DMP2, to open data policies, etcetera. So, as I mentioned before, the Big Data program has a focus both on foundational research and on innovative applications. So, it's just a question of the dial. The foundational research - in both cases you are looking for an application that motivates the research, but in foundational, you are really pushing some new techniques and technologies, again, whether in CS, statistics, or math. In Innovative Applications, we are looking for something new being done in the science, but also using some innovative techniques with the data. And, as I mentioned, OFR is a participant. All of this, by the way, got started with the announcement by the Obama Administration for the Big Data R&D Initiative, which was in 2012, I think, so, 2013 was the first set of awards, when NSF and NIH were together at that time in the program and that's just a breakdown of... I think you can sort of see, there's purple on one side, that's all the proposals that we're focusing on data collection, management, mining, and machine learning. The darker one is health and bio informatics, and then there are other focus areas like social networks, physical science, engineering, foundations, and CI. In 2014, we had a slightly different categorization. There's four categories: Data and Knowledge Analytics; Data and Knowledge Management; Computational Scientific Discovery; and Innovative Applications. And you see the breakdown there. There were 35 projects funded. And the most recent one that's just come out, and you can go to FastLane and search and look for big data and the current awards we have funded. 42 proposals, which are 30 different projects and that's because several of them are collaborative across multiple universities. Most of them are actually collaborative, at least within the same campus, okay? And, here's the breakdown. 63% were on the Foundational side, 20% on the Innovative Applications, and 17% were a combination of the two. And when I say foundational, again, it's computer science, statistics, and math, so Stats and Math directorate is a participant in the big data program. And there are 6 EAGER grants that were also funded as part of this. So, the Hubs and Spokes, that's a new program and the basic idea here, and I won't belabor all the details, but the basic idea is that we see an opportunity. I think, at the end of the day, we are trying to push towards how to A) bring more data out and make it available for the community to use in their research; and, B) how to do this by creating multi sector partnerships. So, the way the program ended up is that we have this notion of hubs, which are these coordinating groups that are meant to coordinate within regions and we had a series of meetings to plan this program, and something very interesting came up in these meetings. The meetings were in each of the regions, so, we have the west, northeast, midwest, and south. These are the four regions. And when we had these meetings there were a lot of universities from those regions as well as industry. A lot of the discussion was about how these people are coming together for the first time and one of the things we asked in these meetings is ask people to put up what resources do they have available. And all of a sudden, the universities started saying, oh, really? You guys have this data? We didn't even know that you had that. And industry was talking about what kind of requirements they have and the universities hadn't heard from the local industry. So, there's actually an interesting sort of synergy beginning to happen within the regions and I'm actually very hopeful that this is going to be a very interesting mechanism by which new ideas will come forward and new collaborations will come forward. One of the things we are looking for the Hubs to do, actually the next program logically after the hubs, is called the Spokes, and right now, we are working on the solicitation for that. We expect, in a month or so, maybe a couple of months, the solicitation will come out. As I mentioned, the Hubs were meant to be this very high level coordinating activities in the region. The Spokes are meant to have a similar kind of diversity of participation, but focus on specific technical areas. So, when the Hubs got together, there were a lot of different themes that came up that they identified. One theme that seems to be common across the whole country is urban science and smart cities. So many regions are interested in issues related to smart cities. Another is global climate change and, for example, in the west, water was a big issue. So, climate change and water. In the midwest, managing the fresh water in the Great Lakes was a big issue. So, there were some common themes of this type. And, of course, personal health was an issue for everybody. So, what we want the Spokes to do, then, is to zoom into specific areas of that type and the Spokes will be affiliated with the Hubs, but they can have membership from across the country. They don't have to be all members within the particular region. So, that's the next solicitation that's going to be coming out. So, the idea of the Hubs is basically to initiate partnerships; identify what might be common resources in the region, so maybe you have a super computer, a center or storage facility here, maybe there's a university down the street that would like to use it, but they have something else to form these kind of collaborations; access to the talent, both on the technology side and the science side; and then, shared best practices. So, as I said, one of the things we'd like these Hubs to do is to start identifying datasets that may be available and expose this data. Again, you already heard about something like the NCI Commons, which in a way, is actually doing it for cancer data, and I think Bob did mention it. So, as you start doing this, you start running into this issue of API's and standards because I want to share this data with that guy, and so, what are the standard things by which we can do this? NSF has funded an activity called RDA, the Research Data Alliance, which is trying to do some of these kinds of standards development. And so, we'd like the Hubs to play a role in not only just trying to identify the data but also trying to identify along what standards can these be made available. And, by doing this, you know, by the region, we hopefully reduce the cost of, and sort of reduce some of the duplication that happens in these things. So, we had these regional meetings, as I mentioned. The midwest folks, this was several months ago, they met in Ann Arbor. The west folks actually met in Salt Lake City. The northeast meeting was in Boston, but I think there's a group at NYU that was trying to put together the northeast Hub. These awards have been announced. I think you can find them on FastLane but they're not yet officially announced. And the south, the meeting was in North Carolina and RENCI, which is University of North Carolina Chapel Hill and Georgia Tech were involved with that. I already mentioned this. These are some of the topics that came up in the different Hubs and what we found is, it's interesting, some topics are of interest for specific regions, there are others that cut across all four sectors. So, some quick updates and I should be done after that. Let me talk about some recent and upcoming activities. There is a fifth meeting of all the Hubs, so this would be all the funded folks will be getting together from November 3rd to 5th in D.C. Right after that, another initiative that actually also comes out of the White House is trying to bring... again, this is all in the vein of trying to not only connect data scientists with data, but also trying to get more data out so that people have access to these assets that they can do their research. One way we want to do this is through a meetup of meetup groups. So, there are many data science meetup groups around the country. There's a data science Meetup group in San Francisco that has a membership of 8,000. There's one in Boston, there's New York City, Atlanta, and the smallest is 2,000-3,000 members. So, if you put all of these folks together you're talking about something like 30,000-40,000 membership of people who are saying they're interested in data science. A lot of these people are folks who work in industry and they want to just do data science problems as something that's of interest. So, we are bringing together the coordinators of all of these meetup groups together in D.C. and that's going to be right after the Hubs meeting, so we're trying to connect the Hubs folks to the Meetup group folks so the Hubs get to meet all the Meetup groups that are in their regions and that's another way to try and amplify the message. The Big Data program, itself, will have a PI meeting in February. A big area that is already there but is definitely looming in the future, is Internet of Things, so you expect most of the data that's going to be coming in the future is going to be coming from all of these devices, whether they're in factories or in your house or on your body or in your car, etcetera, right? So, we have started a series of workshops just focused on the data problem with the Internet of Things. There are a lot of issues with IoT. If you just do a search on IoT you'll see, I don't know, maybe hundreds of meetings and conferences. A lot of the issues are at the device level, at the networking level, security, privacy, etcetera. We are interested on just - it's almost like the theory of data in the Internet of Things. One of the issues, for example, is the latency of data. So, if you have an Internet of Things, data is coming at you at different rates for various reasons. The network latencies are there. Part of the network may be down. You might be getting good data. You might be getting bad data. But whatever applications are running on top of that, they have to make decisions and they have to do things within some time frame, so there's the issue of how do you build those kind of systems and make those decisions in the presence of all sorts of latency issues and data issues? So, we're trying to focus on that. We had one meeting on the Industrial Internet, and that was hosted by Cisco in San Jose, and we are planning to have a couple more. One on Smart and Connected Communities, and we are thinking Chicago might be the place and we've actually talked to the folks who do the Internet array of things, Charlie Catlett, and then, of course, personalized medicine. Data Science and Education. I said I was going to say something about that. So, that's a big, big deal and I don't know if this is happening at Yale, but many campuses, some of them already have rolled out data science programs, and many are talking about doing data science programs, right? So, we had one data science education workshop recently at the University of Washington, which was really exciting. The model of that workshop was, we funded, there was about 100 different graduate students from different disciplines. In fact, it was everything from humanities and one of them was an artist who does data based art, you know, an outside art, sculptures and things like this, all the way to your usual physical science type folks. The whole range. And it was really interesting to see the dynamics among the students. They were just grad students coming together and all realizing that, you know, they're all doing stuff for data and many of them might be using techniques that others could be - you know, that you could learn from what the others are doing. So, it's a little bit like what sort of happens here, except you have 100 grad students from all over the country from different schools. So, that is a very interesting activity and I think we'll continue that as an annual activity. Another workshop that I'm planning, and we have multiple folks at NSF involved... the education directorate, the statistics folks, social science, computer science, and also NIH... is what we are calling Envisioning the Data Science Discipline. So, if you step back and think, so what's happening right now on a lot of campuses is people see a market opportunity. There's clearly a need to produce students with a certain set of skills, and so, they're trying to connect the dots. They're trying to connect the dots from, okay, we have these kinds of skills on campus. We have a computer science department, we have stats, we have management, and we want to produce, you know, these kind of students, so how do I make progress? Which is fine. It's a very pragmatic way to put together a data science program. I think we are trying to say something different with this Envisioning workshop. We are trying to say, okay, if data science was a discipline, what would it actually look like, and what would be the fundamentals of data science that make it different than computer science and statistics, etcetera? It's undoubtedly an intersection of computer science, statistics, and social science, but it's more of a visioning exercise. And from that, other things may flow, other workshops may happen, etcetera. And we requested the National Academy of Science to run this workshop, so that's coming up. If you have thoughts or interests let me know. We already have a list of folks that we'd like to invite to this. And as you may or may not, that every directorate at NSF has an advisory committee, which is essentially the folks from the community who provide advice to the directorate at NSF, and CISE has an advisory committee and we just now set up a subcommittee of that focused on data science education. And so, again, they are also looking at, you know, more from a computer science point of view, what should we be doing, what should we be teaching, what are the facilities that need to be in place to teach data science effectively, and so on? Last couple of slides. So, I did say that there is interagency activity going on, so, one of my jobs at NSF is to actually co-chair this interagency group. We just call it the Big Data Senior Steering Group, which was actually set up as part of the original Obama Administration Initiative. The group is co-chaired by NSF and NIH. So, it includes over 18 different federal R&D agencies who are all interested in big data, so it's the usual. You know, we have NASA, NOAA, DOD, DOE... Department of Energy, NSA and NIST and so on. These are just informational. So, that's going on and actually we have monthly meetings, and we actually invite external speakers to come and speak and I think there's an invitation out to Bob and the NOAA folks to come and talk about the NOAA Cloud that they went through. Another activity going on is the NIST Public Working Group on Big Data, which is actually trying to develop standards, and actually I was a co-chair of that. I have to say. I'm a non-active co-chair right now. I think one of the things that happens in government is once your name is there, it's actually hard to remove it. But, it's been interesting to observe that because the field is moving so fast that every time they get down to defining something it's moved along and keeping up is very hard. So, we do collaborate with NIH. There is a program that NSF recently announced with the Statistics Institution and NIH called Quantitative Approaches to Biomedical Big Data. Is anyone from Yale participating in that, do you know? Okay. They have funded a number of planning grants, I believe, and this is, again, NIH interested in connecting with the statistics community to see what kind of statistical methods could be used for the kinds of big data that they have in biomedicine. And I was mentioning to someone earlier today, in fact, had a meeting with NIH, Phil Bourne, who was your speaker last year. Phil and I have been talking along with some folks at NSF about doing a workshop, and this one will be in conjunction with the UK Research Councils on how to try and expose more biomedical data for the community to do research on. So, the UK folks have, you know, good datasets, I think because of their national health service and so on. Increasingly, NIH is trying to put out more datasets. There's something called healthdata.gov you might be familiar with, where agencies are trying to publish health data. And so, it's going to be an NSF-funded workshop. We'll actually run it at NIH and we'll have participation from the UK Research Councils on that. So, my last slide is some set of things where we need your inputs. So, this, I think, is a real challenge. How do we get our hands on data? So, we need your ideas. We need to release more data. We need to put it out there and, as you know, it's not just, I mean, the data has to sit next to computing, right, so it could be a hadoop style or whatever the style or platform is, but computing has to be there with the data, so it's not just publishing files on an FTB site or something like this. How do we build platforms at scale? As I said, I've actually started a conversation with some of the folks in the community, and this is more the computer science folks, as to how would we do this? And, especially in an environment where, and as far as I'm concerned the country doesn't care for R&D, right? If you sit at NSF, somebody said the other day, in fact, our assistant director, said Flat is the new Positive, or something like that. If you are flat you will be happy. If your budgets are flat it's supposed to be happy. And our budgets are flat. And I was at this workshop at the University of Washington, one of the faculty said, you know, NSF doesn't understand that there is inflation in this world. And, by the way, I was a PI till a year ago. I was on the same side a year ago. It's thought that NSF doesn't understand. NSF budgets are flat. You know, if you guys keep getting 2% or 3% raises or even higher. Private schools probably give you lots of big raises - University of California doesn't give huge raises. Sorry. That means, you know, you're going to put less effort on a project because the amount of money is fixed. So, if you want to fix that I think you need to go and talk to people in Washington, D.C. So, that's my pitch. Okay. So, we're in the day of flat budgets but we want to have these new initiatives, you know, we want to create new big data platforms, and I mean, you can imagine back to the day, 20-30 years ago, when somebody said, and this was Sid Karin and Larry Smarr, that we need super computers. We need super computer centers and new money materialized at NSF to fund super computers, okay? This is what we need today. We need big data platforms but how do we make it happen, so we need your help. Another issue, and I think some of you may be involved with it, but I know there are other research folks very much in this area of data ownership. You know, who owns the data, including, in today's world, what's happening to all of us right now. Somebody, again, Bob. All these references are going back to Bob. I think you mentioned something about do you know where your data is. So, there's this issue of how do we tackle that problem, right? It's not just the issue of keeping data anonymized and private and giving protected access but it's also who's the controlling power? You know, who's ruling in this case? And the last thing I'll say, we actually fund a group, and it's a multi university, but I think based out of NYU, and other folks. There's folks from UC Irvine, maybe Johns Hopkins. I can't remember all the schools. I can't remember if Yale is there on it, but it's called Big Data Ethics and Society. So, I talked about data science education. I mean, I really think that data science has three legs. It's computer science, statistics, and social science, especially the ethics part. The biggest Achilles heel for data science is going to be on the ethics side because the first time somebody, not that it's already not happened already, but, you know, the first time someone goes and messes up data it's going to be a huge, huge issue. So, I think of ethics as a very big topic and so, again, whatever ideas you have, the more you can teach it, the more you can do in it it's great. As I said, we fund this group called Big Data Ethics and Society and we've asked them to come and present at the Big Data PI's meeting. We may also ask them to attend the Hubs meeting so that they can sort of - it's a very good group of folks and hopefully they can spread this message. So, if you have folks on this campus interested in the ethics issue I think they should really get connected to this. So, I apologize for such a dry talk. I didn't realize it was going to be this dry, but it's very interesting to me. So. (Applause) So, I also did not find that dry at all. I thought it very interesting. Thank you. So, Yale is actually a part of the northeast regional big data hub along with Columbia, and we currently have three faculty that are helping drive that initiative. Can you speak a little bit about the skill sets for the other folks that will be needed to help support and propel that initiative should the funding be received? Okay. So, that's a very good question. I think I had, at the bottom of that slide, something about the Hugs are there to enable you to do something that you couldn't otherwise do by yourself, that is. And when I say you, it's even the campus. So, it's really regional in that sense, so I'm not sure what all the issues here are, but I know about water in San Diego, so let me pick water in California as an issue. So, if you want to try and address the water issue in California, you need partnerships across the state, both in academia and also agencies. So, I think the kind of folks you need to be involved, the Hubs program is very different than what NSF has done before. It's almost like an altruistic - well, it's an organizational thing, but it's also altruistic, so PI's are not very good at being altruistic, right? I mean, I've been a PI, so PI's are all about, okay what's in the budget for me? But here, we are talking about how do you bring together all sorts of different actors to create a more complete picture of whatever it is that you're trying to solve. So, if you can get faculty who are interested in that. Well, one of the things I find, especially in the interdisciplinary work, including I've met some recent young faculty at UCSD, is that the young faculty have a lot of energy in this interdisciplinary stuff, but I'm not sure if Hubs is where you'd want to engage them. If you can find that senior faculty, maybe Bob, but Bob is not so senior, but, anyway, if you can find the experienced faculty who is also interested in doing something that's broader than just their own program, those would be the right kind of people. And obviously, that means they have to have an interest that's, you know, we're using - and you'll see it in the solicitation as well, we use the term National Priority Areas, so the White House OSTP has announced a number of priority areas... precision medicine is one, global climate change is one, smart manufacturing, smart interconnected communities... these are all considered to be priority areas. So, if you have folks who are interested in working in those priority areas, but not so narrowly interested in just their own lab but actually trying to reach out and help, and I'm sure there are many here. I certainly know folks at other places who are like that. Those would be the best folks to engage. Is this model being extended to other parts of the world? Good question. So, actually, in the Spokes solicitation, which we are right now working on putting it together, we received interest from international groups who want to participate in this. So, the Hubs didn't say, but the Spokes will actually say that we encourage international partnerships, and so, there could be some topics. Actually, smart cities is a good one, right, because there's a faculty member at MIT who visited Singapore. Singapore has a vague smart city initiative and what they realized is because of the way everything gets controlled in Singapore, I suppose, they can control how data is released. And they realized that the data that they have is actually an asset for international collaborations because not many cities or states have that kind of data that they have access to. So, for example, in Smart and Connected Cities, we have a connection with Singapore and we can get all their data and we can do some very fancy, you know, parking optimization or whatever. That would be interesting. So, I think the Spokes will ask for encourage international partnerships. We are also finding a lot of interest from other agencies. I'm not sure of the solicitation with the state or not, but some of the agencies are even saying that they may do their own solicitation which, in some ways, is actually simpler, but then connect to the Hubs. So, you know, DHS is also very interested in Smart City issues, and actually, I mentioned the Internet of Things workshop, I don't think I mentioned the next series of workshops we are doing is with NHS, so it'll be NSF-DHS jointly doing IoT workshops. I won't be surprised if someone like that will put something out and say, you know, we have an opportunity here and we would like to connect this to the NSF Hubs. Thank you for your talk. Something you said I thought was interesting, or it was on your slide, is that you said data is a new instrument, and I'm coming from a bioinformatics background and when I think of bioinformatics compared to traditional life sciences I think of instead of studying living things, I'm studying the data. I'm serving the data and the metadata on the data, but I usually think of the instruments that I'm using as mathematics, statistics, and computer science. So, I was wondering if you could talk a little bit about how you see data as the actual instrument instead of the thing being measured. Right. And, you know... I think what I really mean there is, there's a lot of opportunity, and I think in astronomy this has already being done, where you can discover new things just by analyzing the data. So, you don't have to go to the instrument like a telescope or something. Of course, somebody went and brought it together, the data could just be click streams and maybe you observe some social phenomena by observing something in the click stream. That's kind of what I mean. So, it's an instrument to study a phenomena in that sense. Can you join me in thanking our speaker? (Applause) 