 my name is Stuart Russell and I'll be moderating this panel which is on the future of human-computer interaction and just to reintroduce our panel members we have guru Vannevar who is responsible for beating Watson at IBM the next generation Watson systems we have sherry Turkle from MIT who's an expert on the relationship between people and technology we have cynthia brazil from MIT who is a social robot assist and also an entrepreneur the founder of the geebo company and we have Barbara grosse from Harvard who works in the natural language area is a pile a pioneer on the topic of dialogue and on cooperation between humans and machines so let me open the panel by saying that we're all very familiar with the interfaces that we have now with our laptops with our smartphones and they seem fairly seamless except sometimes they're very irritating when they don't quite work right you might be interested to know that that kind of interface was described in a fair amount of detail in 1909 by e/m Forrester in a story called the machine stops he describes something that seems very much like an iPad with video chat capabilities climate control buttons and all sorts of stuff like that so what we're gonna talk about today is what comes next and how will our relationship with machines change as they become more and more intelligent so I want to begin by asking Cynthia to talk about what's going on now and where is the trend where is the technology of human-computer interface going sure so I thought I would just start to highlight the diversity of embodiments of computation that's happening right now so more from the commercial landscape what we're seeing right now is a whole ecosystem developing around hardware which makes it much more rapid and iterative to be able to create hardware of different kinds of embodiments and this is also really to related to advancements in 3d printing and so forth so whereas many of us are familiar with kind of the traditional boxy type out it's wipeouts at sort of interaction with computers we're starting to have this whole Internet of Things and wearables where the computation is becoming more physically intimate so whether it's the Apple watch or herbal watches or Google glass we're starting to see these kinds of interfaces VR headsets and so forth are coming up that literally try to trick the brain by beaming you know light signals into your your eye to make it feel like you're that much more immersed in the experience we have robots of course that are articulate and able to move around and interact with us sometimes in a social way sometimes in another more tool like way we're starting to of course there's prosthetics right we think about Lake prosthetics or arm prosthetics robots that are becoming more of an extension of ourselves that's another form of computation and as we think into the future we're starting to move into a more intimate fusing of biology with hardware so things like neural brain machine interfaces neural implants we're starting to see artificial retina we are familiar with cochlear implants that allow blind people to start to see again or deaf people to hear again and I think you know when I think about looking ahead one of the things that's always fascinated me about biological systems that we can't do in our still a can based technology yet is that biological systems can heal and they can grow and our silicon technology can't do that so I can imagine I think there's work going on at MIT in other places we're starting to treat biological materials as an engineering material itself so can you actually design and print out neural structures as an engineering endeavor rather than studying an existing brain or muscles and things like that so I think there's many directions this is going in and can go in so hey you ain't seen nothing yet so sherry when you hear this does that make your skin crawl a little bit no I I think that I basically the way I see it is that what we have to get used but we have to get better at as people as humans and we were just chatting about this we couldn't wait we started even chatting before we came on it's understanding kind of where our vulnerability is as humans two things that start to make us feel less human in a bad way so when I hear about a cochlear implant that will enhance the ability to see to hear and all the implants I'm thinking great no skin is crawling you know it feels to me like an enhancement in all of the best ways where I begin to feel I want us to be vigilant is when an interface or a computational object starts to intrude on an area or pretend to be a thing that it really can't do the way people can and where we will somehow trick ourselves into getting less than we deserve to have so for example and this is a conversation that Cynthia and I have had some time if you create a computer best friend that comes out of the box as I think hello Barbie may promising hi I'm hello Barbie I have a sister I get mad at her do you have a sister too to a child who might have a sister and might want to have that conversation they are hearing pretend empathy from a creature that doesn't have any to give and I don't think you can learn empathy from a creature that has that that does it hasn't had that empathic experience so the question becomes why make robotic interfaces in this case do something that they kind of can't follow up on can't really deliver on and it may cause us to forget what the real thing is so but but other than touching on those kinds of areas where I think we're quite vulnerable no snow crawling at all no so you don't worry about us merging our physical brains with electron augmentation for example prosthetic memory might be a possibility that we could augment short-term memory so that we would have significantly greater cognitive capacities than we currently have does that worry you well um yes but in the sense that I think we're gonna get better at understanding our vulnerability to why we want to begin to do that for medical reasons see I think a lot of these technologies are going to be developed for medical reasons people who have Parkinson's people who I mean the technology for working on memory and computation is going to be developed because of medical issues so I don't think this is the technology where you're going to stop the research or should you and then I think we're going to have to get better at figuring out well what are the what are the places where we don't want to use it but this is coming up not just in computation but in every area of our dealing with the G with the gene with the with every with with every area of scientific life and I think that's where we I think that's where we have to get better is understanding as people where we you know what are the institutions that we need to to bring us together to really as communities to talk about to talk about these issues and also where we feel that we want to sort of draw the line about parts of our humanity where we think there should be a kind of humanity or some people don't think there should be a humanity they should get their airing and there should be a public policy question Barbara okay so I want to support what Cynthia and sure-sure well sorry Cheryl said I need a memory device Charles said and I wanna I wanna just say a little quip as it were the biologists have agreed not to clone humans and I think AI researchers should agree not to clone humans also that there are many things that are machine that machines and smart machines could do for us as I said in the earlier panel we know how to make human beings and I think it's these that we should think about I absolutely agree we should not the science must continue scientific inquiry is important it's back to gurus a variable quote of you know what's the danger of not knowing then the question is how we're going to use these and I would like at some point for this panel to turn its attention not just to how we as individuals are going to use these but really to the use of computing in the large and it's not just social networks it's groups of people working together and working together with machines so what is the proper role of people and of the machines and how do we design these machines as I said earlier to make us smarter not Dumber to complement what we what we do and I think that's a huge it's a design and an ethical challenge for us to think about what we want the machines to do so I think it's hard to predict where the hardware will go I think if you read science fiction that's one of the things that is often not quite right or they way have way underestimated where we are but it's this this other issue where we're we're talking about what we would like them to do so I'd like to just step back and think about the objectives for good user interface design and design here right so it's one of the one of the three very important objectives for what we consider cognitive systems which is to be natural in the interaction with humans when you have a partner that you're working with you want that partner to be able to understand your intent your language your gestures you know all of the all of the above and you want to be able to understand what your partner is telling you in terms of the information and the evidence and and everything else of interconnections all of that and and in some cases you also have to consider you know what is the model of the world within which we are operating you know you can think of an immersive environment in which both your partner or multiple partners and your collaborators and you are working in you know I want to give a couple of concrete examples you think about a corporate boardroom which is the kind of environment that I come from where you have multiple very bright people are trying to solve a complex problem or you can think of an operating room very bright people trying to solve a complex problem or a classroom where all of these environments are collaborative and it's immersive and you want the interactions to be as natural as possible so all the design for user interfaces whether that's hardware or software or the systems that we build overall must ultimately go to what's that core of being natural here's an example would you take the classroom of where you can make mistakes because we are vulnerable in ways that we don't anticipate to the to our technology so classrooms have amazing systems to use within classrooms very seductive systems that keep students involved with the technology during a classroom and it turns out that it that in in my studies of classrooms where these systems are used the technology becomes so engrossing that he can be very hard for them to interact with the professor with with not going on to other parts of the network to shop or you know to just check their Facebook and so you have students who theoretically have to have a great system designed to enhance the classroom a professor who feels frustrated because the students don't want to be called on because they're so involved with their tools and students who have kind of lost the gist and who will admit that because they know they're on Facebook they're shopping they're texting they're buying and tailor shoes they're doing a bunch of stuff instead of being involved with the class those kinds of systems to be not in terms of you know their cognitive immersion exactly because you know if it is a well-designed system for a given task they would actually immerse the students to do the thing that the environment requires them to do exactly but it means the environment the way we often think about environmental what retirement vulnerability doesn't take into account the true environment which is the classroom as a whole and not just kind of the student in the machine and I think that's really where I'm kind of with that that we have to make sure that when we talk about the environment and everything that's involved with computation it really is our whole body our whole social world our whole psychology all of the relationships we're trying to maximize in our life and not just what is the interface between us in the machine and I think that's where we've that's where we stumble is when we think of computer human interaction we somehow allow ourselves to think about computer human okay just the two of us there we've got it covered when in fact it's the whole wide world work to get us away from just one person in one machine but I I also have a quick reply to this i banned laptops in my classroom for just that reason and I have had any number of guest lectures come and say to me it's amazing how engaged your students are and the students themselves realize that the minute they get a little bored so this is what I think it's both a design and a policy issue the minute they get a little bored they're going to go off and do something else if that capability is there so it is a very tricky design and down trace I see in the audience some blue glows on faces so we can we know who you are so make the point we speak about teamwork between people and machines I think historically there's been this conflation of an order for to be natural or to ative it needs to be human-like and I think to speak to Barbara's point certainly my own work I think what we're finding is that fascinating design spaces actually they're not human they're never gonna be human but they can compliment us in really intriguing ways and the magic is celebrating the difference and how they can help us to be more effective than we would if we were just people or just computers right so I think that's the real opportunity and I absolutely was sherry you need to think about the whole Conte that you're designing to support because you certainly don't want it to be distracting or to mitigate you know the learning outcomes saying the classroom you're hoping to achieve so just to say again we as human beings we work with non-human entities like you know people you know might be working with you know police dogs as fire you know as policemen and so forth so we understand this concept you don't have to be working only with human teammates and I think robots and other technologies are intriguing to think about they bring their own capabilities and I think people actually can think about them as teammates in a way that doesn't confuse them with trying to be exactly like humans in that process I also think one really important thing for those of us designing intelligent systems is to be mindful of the adaptability of people and that actually we should be building machines to adapt to us and I one of my current hobby horses as it were is that the electronic medical record systems have not been designed for the people who are using them they've been designed for a billing department and so we're imposing on people to behave in a different way from the way that would allow them to deliver the best care that they could deliver and I'm sure everybody here has an experience with some human-computer interaction system where they have to change their way of thinking and being because of the way the system is acting so I think a major goal as we look to the future is to really enable people to use their cognition in the best possible way rather to force them to adapt to a machine because we know how to build that machine that way so let me ask the whole panel if you can describe your vision of an ideal future system that is facilitating collaboration among multiple people and multiple machines what sort of scenario do you see that working well in and how would it all be like to be in it I can start sure so it turns out we've actually implemented one or two such scenarios today and I can you know just describe one of them if you are trying to make a really complex decision as a group and you know I come from the corporate world so I can I can use a complex example like if you're trying to acquire a company you know which is a very difficult decision because there's so many parameters that you have to worry about there's a huge amount of information that you need to do research on and typically this is going to have to happen within a few hours maybe a couple days you know and there's a lot of perspectives that somebody has to bring in you know it's a financial perspective there's you know a business strategy perspective you know channels perspective legal perspective et cetera et cetera and of course the you know ultimately there is there is a you know an instinct about what's the right thing to do kind of perspective which is a value judgment that somebody has to make so when you imagine all of these people with different points of view and different expertise come together and ask a collaborator which happens to be a machine all of the questions that are in your mind compare what is happening today to what we can have in the future today a corporate boardroom would have a PowerPoint projector somebody comes in with a bunch of slides and somebody asks a question can we do this or not and somebody you know another person says let me come back to you tomorrow with the research done with another set of slides but that's you know really poor if you had a real-time system that could answer questions as well as project the right kinds of parameters for you to consider that's the kind of system we already have working so you know is it ideal probably not yet but there's a lot of gesture recognition visual recognition speech recognition dynamics recognition between you know who is dominating a conversation whether there are biases happening that needs to be neutralized what are the objective pieces of evidence that needs to be brought to the table all of those kinds of features can be done by computer systems and it's already implemented in some of our running examples today I would answer the question by saying that I think the first thing that needs to happen is for people to recognize the power and the efficiency of the system we have now which is conversation for accomplishing human to human conversation for accomplishing so many of our interpersonal goals and of really understanding the work it does so that when we enhance it through adding computation to it we have a very high standard for the computation we add to it so through example when somebody says oh I know what we should do to this conversation we should add a kind of medical record where you won't be able to look at your patient during an interview with a patient will say is physicians nah that's not real you know the work the conversation does in that medical encounter is too important to just add something that primitive let's hold off on that and I think that we've rushed in to adding computation in a lot of places before we sort of allowed ourselves to really understand the power of face-to-face conversations in some of our most crucial human encounters with our children with our colleagues with our partners with our intimates with our with our physicians so I think that a more profound understanding for example in the medical context means that the next generation of collaborative computational partners in medical encounters really will be ones in which there is a computational partner that's adding to the conversation not systematically detracting from it because literally your physician is facing the screen not facing you as you speak and similarly just to finish up in the in the in the in the context that I study most which is somebody holding holding a phone and somehow involving themselves with a child I think we're going to have industry and individuals working together and almost the kind of consumer movement turning to industry and saying you know how can we design these seductive fantastic objects that that that in a way that lets us do our work on them in to involve ourselves with them but somehow then release us make it easier for us to release us to be in the kinds of conversations we need to be in with each other ya know we've all been in restaurants where we see couples who were just talking to their cell phones and not to each other and you wonder why they bother to go together I think that I think that that we're going to begin to take that you take the measure of the cost of our having been so vulnerable and I don't think that we're going to see that I notice I don't think that's going to persist because I think we're going to take the measure of its cost okay so can i yeah sure I just want to pick up on this because I've recently been doing some work with physicians and so I'll give you I'll give you two examples Stuart one is that if you have a patient who requires multiple doctors they need to know what each other is doing but not everything so there's a huge when people talk about care coordination but you can't ask 15 doctors to each know everything that everybody else is doing it's a cognitive problem for people we understand from our work on collaboration that there are certain crucial pieces of information that needs to go back and forth so exactly to the point that Sherrie made if instead of having this screen in front what you have is a system that recognizes that a piece of information that one doctor gathered is now relevant to the encounter another doctor is having and provides that information that would be a way of augmenting this goes back to Doug Engelbart augmenting the human intellect understanding that we can't see everything in this medical record but there's something that's important to convey so that's one thing another another piece that's more that's interactive from the other side is that we know one issue with patients seeing physicians is that they're afraid to ask their physicians questions and I will say even even people with PhDs and law degrees are afraid to ask their doctors questions but if one could build a kind of assistant to go to the doctor with you when you can't take your best friend that would remind you you wanted to ask something or give you permission to ask the question or even just you know make a little sound that would signal to the doctor that there's an issue again that would be complimenting what we're doing rather than interrupting what we're doing so those are the kinds of near term medium term collaborations that I'm thinking would be very very important to do whatever the interface would look like I like to yeah so today when we think about technologies today so much of us focused on our cognitive selves our cognitive minds and information and so forth but we know human teamwork it's also profoundly social there's profound emotive factors of even physical attributes so I think as we design the future technologies in order to really support the whole person these systems do need to more to be more savvy and capable on all of the dimensions of the human experience but to do it in the right way so that you don't interfere with our ability to engage these competencies I would call them our signature strengths on the negative side that could be vulnerabilities but they're also our signature strengths as a species to be able to support us to be the most effective so I think technologies that address deeply our social selves and emotional selves in addition to the cognitive in the physical in the right way is going to be really important to create technologies that support us to our best ability so let me go on from there and ask you whether it's important for machines to at least appear to display emotions in their way in their interactions with human beings and then after that if you've seen the movie her I'd be interested in your reaction to that particular relationship and how that evolves okay so again speaking to the point Barbara made and certainly in a lot of my own work where I develop these social robots it's a different question as to can you create a machine that has human emotions which I would say no because machines aren't human and they're never going to be versus what does it mean in the context of that artifact in that machine and what are the attributes of that interaction that can be designed to bring about the best possible outcomes for the person so it's complicated and it's nuanced I don't think it's a one or the other right or wrong I think there is a design space there's a continuum there to understand deeply that's fundamentally in service of the person and what the goals the person has so I don't think it's a simple answer but I will tell you that a lot is technology framing them is not trying to be a human-like Samantha no which is very much coming across as I'm just like you must why do I think there's a huge design space that's so exciting where they don't have to be come across they don't have to try to portray themselves as being human at all and there's actually an opportunity there and was speaking to what Barbara was saying about we interact with say companion animals differently than we interact with humans and they provide us with social support in a different kind of way that we have that gives us value right so I think as our Technology Center and our interactions relations with them evolve I think will be different what kind of hands with with companion companion animals says social support companion animals not human species different kind of experience but a different kind of social support because of that so I think as our technologies evolve we're gonna figure out the nuances of this but it's not a it's exactly like a relationship that already exists because it's just not gonna be there and I don't think it's an interesting question to ask us how we get it since there is supposed to be controversial I'll try and take an even stronger stance I have to tell you I couldn't really watch her but I did watch X not gonna come so it's the same it's the same question I think we should not build machines that try to look like people I think that our intelligent machines should do their best to make it clear when they're not people and is for some of the reasons that sherry and Cynthia have brought up I think it's not easy to do that because we do very easily attribute agency to anything that acts like an agent so I I would actually go go further I think one of the challenges that I'm looking especially if the two of you is that to have and going back to gurus point of having a natural interaction is that there is a certain level of conveying emotionality conveying social interaction that's important to have a successful interaction with a person so how do you do that without misleading the person into thinking that you're human I think actually there it was it was a project of Cynthia ISM has always been a model for me about the appropriate fluidity that you need in terms of body and economy of gesture and sort of knowingness that a robot should have in its embodiment that has always been a model of kind of appropriate robot empathic behavior and that's the astronaut assistant I mean they're you up there you are in space and you're you're fixing something out there in space and you know typing a message to your robot assistant is clearly not the way it's gonna happen most effectively but going you know is the way you know that's the way ah is the way you're going to express urgency because that's what you're gonna be doing and you certainly want your robot to understand that that means I'm in trouble as opposed to you know trouble or SOS or something so with it we know that with enormous economy of gesture we know how I would know to express if I wasn't feeling well out here and I know that you know four people would come to my help that's what you want from your robot now it seems to me that's appropriate where a robot and this is why I say that I think we need to use our smarts as people to come up with this and we can a robot to pretend to understand something about death dying los sisters jealousy these are these are areas in which a robot a robot friend a robot companion the kinds of robots there that certainly her comes right out and says I know all about love here I go you know I'm for you the these robots to me feel as though they're touching on something they don't know and only demeaning what we do were in a way that a cat doesn't because it has its own kind of connection and is proud to show it off I'm Susan II where I thought I was gonna add that you know whether it's embodied or disembodied right these cognitive systems as we think about it should have a model of I mean not just of the world but of specifically of us or a bunch of collaborators partners and of itself in order to have a you know a better understanding of what the goal of the interactions are and and so in that to that extent I think it's important to have at least some information about what state one of the collaborators is in or all of the collaborators are in so it can you know you can guide in the right way so there's this model of what I think in the extreme we in AI we think about it as theory of mind which i think is a very far out goal but I think in even in the small in the short-term you can have state of mind as as an important element of the interaction so so we know from studying dialogue but just Stewart mentioned I did a long time ago that you can't in fact carry on a dialogue with someone unless you have a model of their mental state and can figure out their intentions we also know that those things are very very hard to do well in a computing system and I think those are also important goals as we as we look forward and it's I will say it's hard enough to do have a system that can model one person but I'll try one more time what about all of these social networks what about all of the connectivity we have now I mean so we started this with Cynthia talking about the new materials and what difference they'll make but there's a whole different level of human-computer interaction going on now or a whole different level of human interaction going on now using computers and one might ask could computers play an important role in things like the running of cities this is this is something that I'm I'm chairing this AI 100 a 100 year study of AI that's gonna take that's at Stanford that's gonna take the pulse of AI every five years over a hundred years I mean one can imagine many wonderful uses of smart systems in supporting people in much larger groups getting things accomplished and you know how do we what does the interaction style look they're how do we complement human cognition in that to follow on with that so you know in thinking about the future of intelligence you know the we often think of it in terms of like you know one human mind one human brain that's kind of what we need to understand but you know in our opening remarks to the Nobel Prize the Nobel Week you know it's very clear that we face so many of these global challenges and we live in this world that's in to me connected our actions down now at the level of individuals have impact right and so the one thing that we as humans are still not good at is you know call it global intelligence how can we as a planet as a people all over the planet make decisions learn adapt perform actions for the global good we're just we're not good at that and you know with climate change and all these things we're facing the point where either through our action or inaction it's you know heading to the business I think the words were right so can technology help us become intelligent at a global scale so that we as the people in the planet can can address these these huge challenges we face that's a great question so I you were to ask one more question before before we throw it open to questions from the audience and there oh there are microphones so if you have a question please raise your hand and someone will bring the mic to you so the question I wanted to ask is to look further ahead and if we do have machines that are much more intelligent than us will they need to hide their intelligence though is not to crush our poor little egos by answering the question about her which was that in the end the intelligence that was developed in her really wanted to hang out with other AIS and really didn't want to hang out with Joaquin Phoenix after she had tidied up after it had tidied up his his a book proposal and had his you know has kind of organized his files in his life and she was ready to I keep saying she because it was voiced by Scarlett Johansson it's impossible not to imagine it is a woman but I mean there she was ready to move on to you know to others of her kind and so I think this is our insistence that we're going to create an object whose really main interest will be hanging out with us I think is also part of a kind of a very old-fashioned fantasy I think Barbara's trying to get us moved away from this is you know let's think about you know creating artificial intelligences will enhance our life and stop thinking them as our as our kind of best friends yeah I think our premise in what you said Stewart which is that they will get it will be smarter than us but I think they will be differently smart from us and that's what we should aim for yeah you know I would I would add that it's you know again come back to the goal of enhancing our life bring us with our goals and intentions so if you know hiding or showing is the right thing to do in order to do that that's the world model that the you know the the AI system should adopt so you're saying yes they should hide their intellect affirm whatever it takes to be the right partner you know is my view okay so on that note I'd like to open it up to questions from the audience so if you have a question please raise your hand and there should be three microphones in circulation although it's very hard for me to see from here if anyone has a question okay down the front hello everyone I had a question which was bit more short-term in like scale everyone nowadays basically interacts with machines with like three operating systems Microsoft Mac or Linux I was wondering why do you think after 20 years there's still only three operating systems three companies making them is this good or bad I think we all know it's bad how can we change it I think it's amazing that it's your your contention is that there should be more or you through door that should have it should have it should have narrowed down to the best I think that you can't there's seven billion people and I think you can have one best system right so you're wondering why there aren't so many why don't I have my own personal operating system yeah so why do I have to use Windows 8 you know so I actually this question has so much more to do with markets and business models and and you know dynamics there are well beyond the scope of you know technology and and and even society I think right but you know at the end of the day there you know there are so many new ideas floating around in the entrepreneurial ecosystem you know I look at you know dozens of different great ideas and which one will catch on and which one will succeed is a much bigger question than you know then what the technologies are good for and what people think about them today but I definitely would say that many new elements even if those companies don't succeed many new ideas from those companies will make their way into our lives so I have a I have a flip answer in a serious answer the flip answer is the architecture of one brain seems to have done the human race pretty well now toast operating systems obviously none of them is quite as well architected so that's my my flip answer to the we should we should maybe only have one but we don't know what the right one is so we better try a multiplicity as we do in research I think that the the second issue this the second more serious answer is really related to what guru said which is that there are there are these systems out there there's a lot invested in what's recorded in those systems and what they're used for and getting the industry to move and users to move that is people who are users to move is a rather difficult in the industry question and challenge okay but I ask if people who asked questions could at least give us an idea of what their students are not students er okay we have one up about halfway up on the right technology while it is important for machines not to mimic human emotion would you say about if it were to flip is is it important for them to or would it be beneficial if they recognized human emotions and adapted approach and even tone in accordance to what the human they're interacting with this feeling absolutely I think I think if you know we talked about this but before I think there's got to be a recognition of the the intention of the state of a person it's it's very different when a computer you know let's say a personal assistant like Siri talks to you about you know some question you asked about let's say you know you know calling somebody or whatever and not finding that person to call might have a very you know different way of articulating to you why the you know the computer did not find the person if they if the computer knew what were the actions that you did before you know maybe it was because you know the person is not in your network maybe they're not a friend you know whatever it is right so it's very important for the computer to be able to articulate answers to your questions in the context in which it is most natural to you just quickly to have some perception of emotion when replying as well so I don't notice that in effect interactionism way I'm sorry what is the point about if the Machine replies in a way that a person if interpreters as insensitive with that you have some effect yeah I agree with you that that it's it's important for the machine to understand whether to answer in in in a maybe a current way or an or a nice way right and yes machines are very bad at it today and and that's why we get frustrated with machines all the time and so we need to improve and we need to not only research but also develop a lot of these technologies that understands the state of mind but also I disagree in this and it could be of interest I you know I think that if our expectation was that the machine wasn't trying to be a person I think this is a theme that's come up but the Machine was trying to be a gracious machine but not trying to be a person but a gracious machine a machine that interacted well with people but not a person it would have addiction and a way of addressing us where we would be less vulnerable to being hurt and wouldn't have expectations of its we wouldn't substitute what you are very delicately calling expectations of user state with empathy and expectations that it understands things that it couldn't possibly understand and we're really we could get into kind of emotional trouble if it did so and I think that's the that's the research and design area where I think Cynthia and I are sort of talking about where you can get into trouble or you cannot get into trouble depending on how we play it I think over the next little bit of time so it so I think what Cynthia was saying earlier about animals I mean animals display emotions and they're different from ours you know dogs have a variety of emotions that we typically don't display ourselves but we sort of unleased we think we understand kind of what's what's in the dog's mind and that that's said of that emotional repertoire hasn't been developed yet for machines I mean there's one emotional indicator that they have which is some kind of rotating things right which basically says I'm sorry I haven't a clue and I can't get the answer to a question I'm just going to go around and round around around right as opposed to the stripe which goes across which kinds as I'm getting there I'm getting there okay I'm done so there's two different versions of that emotion repertoire that's about it right there's really there's really nothing else that is sort of widely accepted and understood as a kind of a robot state of mind but eventually and it'll depend on the capabilities there's no point developing an emotion repertoire that the machines capabilities can't really support but eventually I think we will start to see a wider repertoire of emotions so you know confusion how do you express the fact that the system doesn't understand the input that you're providing to it other kinds of things like that will will start to emerge in yeah I think they're they're really you you've asked a question that has two sides one is what should the machine be able to detect in the person and I think the answer is it should be very very good at understanding us that that's one of the important things and the other is what it should display to the person and there it should display in a way that is responsive to what it's a text in us but still makes clear it's a machine and there are many studies I think of all the cliff Nass studies that show that we we respond differently to machines in some ways and similarly in other ways we have different expectations of machines than of each other and so it's important to have that right signal processing though I just want to say that you know when a machine is responding in English say there's so many more dimensions of how to how to display you know something that is maybe better receive receivable by you alright and something that's more understandable in the state that you're in so you know once you get into in event but not what I when I say natural I mean language as is a very important component of it it's not just you know icons right and when you use language there's so many nuances and that's why it's so complicated and even then there's opportunity for being clear that it's a machine but there's also a lot of challenges in not crossing that line and giving the impression that you know it actually understands to continue this conversation but but I'm hitting the hook it's time for us to to wrap up so I'd like to thank the panel and the audience for their questions and the answer is we ain't seen nothing yet and is complicated 