 one of the hottest topics these days is machine learning but what's the big deal with machine learning well it seems that learning in particular might be the key to intelligence let's listen to Martin Jaggi, a professor of machining of the ic school at EPFL people have tried for 50 years or longer to to build machines which are in a way intelligent which is of course super ambitious and expectations are so high that we were very disappointed like 20 20 years ago when it actually did not work also in this old times their approach was more ruled-based, people thought that intelligence is actually something you can directly program to machine it's a if-then-else so if the door is closed, you do that and then its behavior intelligent. so for instance if you wanted to get your artificial intelligence to play chess you would give it a set of very precise instructions to be followed you would tell it to execute an algorithm. and you would hope that, following this set of very precise instructions would be a sign of intelligence, somehow. it's turned out it's actually not really the case this is not making the system flexible and not robust. it cannot behave intelligently in a real scenario. because it did not really learn. it just got the rules. so if you are in a very controlled and high structured environment where every case can be thought of then executing algorithms may still be the way to go however once you enter the real world of high unpredictability. or once you move from the very controlled environment of chess to the too-combinatorial world of the game of Go. then you can no longer predict all the cases that you'll encounter and you cannot get your artificial intelligence to deal with all the new kinds of situations that you, as a programmer, had not yet thought about so now we use similar techniques but we try to learn from the data and really train the system to benefit from all this data which is around. and that's why machine learning really kicks in. machine learning is pretty amazing as a topic at the moment it's getting a lot of attention for new applications and people are quite excited about and students are excited about it, which is great for us yeah but on the other hand you also have to say that machine learning is not new. That the same techniques have been around for a very long time. so what has changed now what has changed now is that we're using similar techniques but we have found much more applications, we have found more data and we have found ways to actually benefit from the data and to make it really data-driven and make it learn from the data. in particular artificial intelligence researchers have come to believe that intelligence was not rule-based but data-driven it seems that intelligence is not about knowing a set of rules rather it seems to be about learning how to react to what we observe from our surrounding here's an example for example you have a lot of images and you try to learn: is this an image of a cat or of a dog. so you try to distinguish these two kinds of images we have 400,000 images for which we really know this is a dog; this is the cat. and for each of them we have the two answers. so this your training data and if you have to you can train your system. But what does training mean? it's really nothing fancy we have always had these methods it's basically just doing a regression so you assume value one for a cat. Assume value minus 1 for a dog. so you learn your regression. you fit the regression model in fact one way to distinguish cats from dogs is to literally draw a line between pictures of cats and pictures of dogs once these pictures are located in a... wait for it... super high dimensional space I'm not high. this is actually literally what a lot of machine learning does it draws lines or whether so-called hyperplanes between labeled data to distinguish distinct concepts. and crucially what distinguishes cats from dogs is not a set of predefined rules it is now a line that was computed based on observed data. this line is not ruled-based. it is data-driven. it's not only about images it's about many many things. like many things which are boring for human like driving a car is a very boring activity, right? so these are the kinds of tasks that machines could be trained to do that's that's what we try to do. Or translate from one language into another so that's something which which can can be very time-consuming for a human and machines can really support support this and benefit from large data to make it easier to translate between different languages I can vouch for that. as you can verify by yourself, this very video has subtitles both in English as well as translations into French and these subtitles have been mostly generated by YouTube itself YouTube's algorithm is not quite a human level just yet. so i did have to make a lot of Corrections. but as a youtuber who has been using this functionality for years, i can definitely tell you that YouTube's algorithm has been improving dramatically. and this is something something very nice because it makes the information much easier to access. so this is a huge benefit if you can automatically have every movie in the world in all subtitles in all languages of the world that's that's something nice which will make it easier for us to to learn and to to access information. Or think about medical applications, it's very important. like doctors, they need to deal with so much information it's becoming harder and harder we try to use machine learning to to help them. to help them find the right scientific papers about this particular rare disease for example to support them. We're not going to take the decision away from the doctor but try to support them to show them: hey this might be a connection which which could be relevant for this particular patient because we have the data for this patient and we have seen that patients with this kind of data could be related so this is very important. to conclude I asked Martin jaggi how he envisioned machine learning within 10 years or so uh yeah machine learning in 10 years that's a difficult question yeah it's it's a difficult. in one sense it's evolving extremely fast like this year we can do things which like three years ago were thought almost impossible and on the other hand it's also not working so fast because the techniques that have been used to achieve this success, they're still kind of the same. so there, we make small improvements find better applications where we can use useful training data and gradually improved these methods one way to do so is to try to separate spam data points from not spam data points in the feature space using a hyperplane of equation w transposed x plus b. we don't understand what this new networks actually do, and why they work well and if you can make any theoretical statements about it 