 in this video I'll describe the first way we discovered forgetting sigmoid belief nets to learn efficiently it's called the wake-sleep algorithm and it should not be confused with Boltzmann machines they have two phases the positive in a negative phase that could plausibly be related to wake and sleep but the wake-sleep algorithm is a very different kind of learning mainly because it's for directed graphical models like sigmoid belief nets rather than for undirected graphical models like Boltzmann machines the ideas behind the wake-sleep algorithm led to a whole new area of machine learning called variational learning which didn't take off until the late 1990s despite early examples like the wake-sleep algorithm and is now one of the main ways of learning complicated graphical models in machine learning the basic idea behind these variational methods sounds crazy the idea is that since is hard to compute the correct posterior distribution will compute some cheap approximation to it and then we'll do maximum likelihood learning anyway that is we'll apply the learning rule that would be correct if we've got a sample from the true posterior and hope that it works even though we haven't now you could reasonably expect this to be a disaster but actually the learning comes to your rescue so if you look at what's driving the weights during the learning when you use an approximate posterior there are actually two terms driving the weights one term is driving them to get a better model of the data that is to make the sigmoid belief net more likely to generate the observed data in the training set but there's another term that's added to that that's actually driving the weights towards sets of weights for which the approximate posterior using is a good fit to the real posterior it does this by manipulating the real posterior to try and make it fit the approximate posterior it's because of this effect the variational learning of these models works quite nicely back in the mid-90s when we first came up with it we thought this was an interesting new theory of how the brain might know that idea has been taken up since by Karl Freston who strongly believes this is what's going on in real neural learning so we're now going to look in more detail but how we can use an approximation to the posterior distribution for learning to summarize it's hard to learn complicated models like sigmoid belief Nets because it's hard to get samples from the true posterior distribution over hidden configurations when given a data vector and it's hard even to get a sample from that posterior that this is hard to get an unbiased sample so the crazy idea is that we're going to use samples from some other distribution and hope that the learning will still work and as we'll see that turns out to be true for sigmoid belief Nets so the distribution that we're going to use is a distribution that ignores explaining away we're going to assume wrongly that the posterior over hidden configurations factorizes into a product of distributions for each separate hidden unit in other words we're going to assume that given the data the units in each hidden layer are independent of one another as they are in a restricted Boltzmann machine but in a restricted Boltzmann machine this is correct whereas in a sigmoid belief net is wrong so let's quickly look at what a factorial distribution is in a factorial distribution the probability of a whole vector is just the product of the probabilities of its individual terms so suppose we have three hidden units in a layer and they have probabilities of being on point three point six and point eight if we want to compute the probability of the hidden layer having the state 1 0 1 we compute that by multiplying point 3 one minus point six by point eight so the probability of a configuration of the hidden layer is just the product of the individual probabilities that's why it's called factorial in general and distribution of of binary vectors of length then we'll have 2 to the n degrees of freedom actually it's only 2 to the N minus 1 because the probabilities must have to want a factorial distribution by contrast only has n degrees of freedom it's a much simpler beast so now I'm going to describe the wake-sleep algorithm that makes use of the idea of using the wrong distribution and in this algorithm we have a neural net that has two different sets of weights it's really a generative model and so the weights shown in green for generative are the weights of the model those are the weights that define the probability distribution over data vectors we've got some extra weights the weights shown in red for recognition weights and these are weights that are used for approximately getting the posterior distribution that is we're going to use these weights to get a factorial distribution of each in layer that approximates the posterior but not very well so in this algorithm there's a wake phase in the wake face you put data in of the visible layer at the bottom and you do a forward pass through the network using the recognition weights and at each hidden layer you make a stochastic binary decision for each hidden unit independently about whether it should be on or off so the forward pass gets us stochastic binary states for all of the hidden units then once we have this stochastic binary States we treat that as though it was a sample from the true posterior distribution given the data and we do maximum likelihood learning but what we're doing maximum right in hood learning for is not the recognition weights that we just used to get the approximate sample it's the generative weights that define our model so you drive the system in the forward pass with the recognition weights but you learn the generative weights in the sleep phase you do the opposite you drive the system with the generative weights that is you start with a random vector at the top hidden layer you generate the binary states of those hidden units from there prior in which they're independent and then you go down through the system generating States for each layer at a time and here you are using the generative model correctly that's how the generative model says you ought to generate data and so you can generate an unbiased sample from the model having used the generative weights to generate an unbiased sample you then say let's see if we can recover the hidden States from the data or let's see if we can recover the hidden states at layer h2 from the hidden states that layer h1 so you train the recognition weights to try and recover the hidden states that actually generated the states in the layer below so it's just the opposite of the weight phase we're now using the generative weights to drive the system and we're learning the recognition weights it turns out that if you start with random weights and you alternate between weight phases and sleep phases it learns a pretty good model there are flaws in this algorithm the first flaws are rather minor one which is the recognition weights are learning to invert the generative model but at the beginning of learning they're learning to invert the generative model in parts of the space where there isn't any data because when you generate from the model you're generating stuff that looks very different from the real data because the weights aren't any good that's a waste but it's not a big problem the serious problem with this algorithm is that the recognition weights not only don't follow the gradient of the log probability the data they don't even follow the gradient of the variational bound on this probability and because they're not following the right gradient we get incorrect mode adverting which I'll explain on the next slide a final problem is that we know that the true posterior over the top hidden layer is bound to be far from independent because of explaining away effects and yet we're forced to approximate it with a distribution that assumes independence this independence approximation might not be so bad for intermediate hidden layers because if we're lucky the explaining away effects that come from below will be partially canceled out by prior effects that come from above you'll see that in much more detail later despite all these problems Karl Freston thinks this is how the brain works when we initially came up with the algorithm we thought it was an interesting new theory of the brain I currently believe that it's got too many problems to be how the brain works and that we'll find better algorithms so now let me explain mode averaging using the little model with the earthquake and the truck that we saw before suppose we run the sleep phase when we generate data from this model most of the time those top two units will be off because they're very unlikely to turn on under their prior and because they're off the visible unit will be firmly off because of its bias of minus 20 just occasionally one time in about e to the minus 10 one of the two top units will turn on and it'll be equally often the left one on the right one when that unit turns on there's a probability of 1/2 that the visible unit will turn on so if you think about the occasions on which the visible unit turns on half those occasions have the left-handed Newton the other half of those occasions have the right hand hidden unit on and almost none of those occasions have neither or both units on so now think what the learning will do for the recognition weights half the time we have a 1 on the visible there the leftmost unit will be on at the top so we'll actually learn to predict that that's on with a probability of not 0.5 and the same for the right unit so the recognition units will learn to reduce a factorial distribution over the hidden layer of 0.5 point 5 now that factorial distribution puts a quarter of its mass on the configuration 1 1 and another quarter of its mass on the configuration 0 0 and both of those are extremely unlikely configurations given that the visible unit was on it would have been better just to pick one mode that as it would have been better for the visible unit just a vote for truck or just a vote for earthquake that's the best recognition model you can have that's the best recognition model you can have if you're forced to have a factorial model so even though the hidden configurations we're dealing with the best represented as the corners of a square I'll actually show it as if it was a one-dimensional continuous value and the true posterior is bimodal it's focused on 1 0 or 0 1 that's shown in black the approximation will learn if we use the sleep phase of the wake-sleep algorithm is the red curve which gives all four states of the hidden units equal probability and the best solution would have been to pick one of its states and give it all the probability mass that's the best solution because in variational learning we're manipulating the true posterior to make it fit the approximation we're using normally in learning we're manipulating an approximation to fit the true thing but here is backwards 