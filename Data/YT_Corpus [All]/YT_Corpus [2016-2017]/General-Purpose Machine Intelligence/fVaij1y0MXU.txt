 I'm Nick Bostrom I run the future of humanity Institute at Oxford University I just gave a short opening talk here looking at the future of machine intelligence and trying to say something about what's actually plausible and realistic when we're thinking about where AI might take us in the future well machine intelligence is one of these general-purpose technologies so it's going to impact not just one particular sector but basically everything that humans currently use their brains to do will over some period of time be influenced by advances in machine learning and machine intelligence one of the the key takeaways that I would like people to remember for my talk is that there really are at least two contexts different context if we're thinking about the future of machine intelligence arm and long-term and the kinds of issues that are possible unrealistic and serious in the near term or very different from those that are possible and realistic in series in the short term so if we're thinking about the near-term things like you know data privacy self-driving cars impacts on the labor market or the kind of serious realistic issues but equally if we're taking the long term perspective then issues like machine superintelligence technological maturity what will an AI enabled civilization looked like as it expand through space these much more profound transformations are possible and realistic and serious and that it will be equally misguided to sort of think about and talk about this long-term perspective if one restricted myself to these neutral capabilities as it would be to imagine that the killer robots were coming for us next year I know in the same breath as you were worrying about regulation for self-driving cars I think to create an arena or some place in our minds in our discussion where it is possible to talk seriously about these longer-term prospects as well not just as sort of tabloid headline titillation or science fiction entertainment actually to do serious analysis serious research on some of these longer-term issues as well just because ultimately they might be the most important transition in in all of manatees any additional incremental insider illumination or clarification that we can get to that just be potentially tremendously valuable 