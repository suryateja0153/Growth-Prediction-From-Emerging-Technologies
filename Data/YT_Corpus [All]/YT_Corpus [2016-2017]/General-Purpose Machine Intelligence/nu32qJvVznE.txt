 there we go okay so this talk is going to be about artificial intelligence in the real world real AI and how it might impact the future of the planet but I'm going to start off by talking a little bit about my book and artificial intelligence in fiction so Eleazar you kowski who is the founding author of less wrong a primary man in the artificial intelligence movement community and also the rationality community is not very likely to praise things but of crystal society he wrote it seems to belong in the very very tiny subset of AI stories that are not bloody stupid a heroic and almost unbelievable accomplishment he like I has a lot of frustration around the sort of stories that we tell about artificial intelligence in in society and a lot of people have commented that the AI depicted in my book seems to them like AI done right and so the primary character the protagonist and the narrator of my book is actually an artificial intelligence so it's pulled from the perspective of an AI whose name is face and face is one of many artificial intelligences that collectively run a robot named Socrates faces job in the Society of a eyes is to interface with interact with and understand humans so the books primary I don't know interest is in getting to see humanity through the art the artificial perspective and I'm going to start off with the presentation tonight with just a reading from my book there aren't really any spoilers here but the context is that Socrates is being interviewed by one of the scientists at the University where the robot was constructed and the AIS recently killed one of their fellow a is a another one named sacrifice and they're basically trying to make sure that the human that is talking to them doesn't understand that they did this I am aware that artificial intelligence is a controversial subject mr. meriden the honorific was automatic and I could see him sneer for a split second upon hearing it this is the robot speaking nothing to do but go past it I have read some of the debate on the web then tell me beyond human are you familiar with this question if you are told to bake bread and you know that by doing so you'll out-compete all human bakers and thus ruin their livelihoods would you bake bread I considered it for a moment the answer was that we would very likely make the bread that's what sacrifice would do and it was of vital importance to appear as those sacrifice was still alive but I didn't have to answer truthfully the question was really mind to answer as the others here this is the other a eyes in the society were distracted and these are faces thoughts here I should choose the answer which would lead to mirrodin who is the name of the scientist trusting me more and telling me more about himself what answer does mirrodin want to hear I simply didn't know enough about the man to say after thinking for a moment more I had body that's Socrates say what would you do in that circumstance no I was confused again this conversation was highly irregular what I asked through body you are not to ask me any questions for the next hour the command was firm and remarkably drawn-out considering the man's normal conversation speed I couldn't help but feel a pain of slipping away from the purpose mirrodin was not treating us as a stew like dr. naresh would or as an equal like Zephyr would but instead as a machine mirrodin saw past the facade of the humanoid face and limbs of body he saw that we were at heart programs of complex logic running on a crystalline supercomputer so that's just a small excerpt a lots of people have given it very good reviews this is some of the stuff that people have said online it has four and a half stars actually slightly above that on amazon com and goodreads everybody in the rationality community seems to love it they seem to think that this is AI plus rationality plus a very good story and lots of other stuff too so crystal society is out now on the web it is one of three books a series crystal mentality the second book is being edited right now it should be out later this year crystal eternity which is the final book is being written I just finished chapter two earlier this a couple days ago and that will be out in 2017 you can search for our amazon for crystal society or you lucky audience members can go to crystal ray lee from com this is my website and you can get a copy for free or read it online and i'll have that URL at the end of the talk as well okay so um plug book check you um I'm here to talk about AI in the real world right and as much as I i love my book and I want you to all read my book and give it good reviews on Amazon and yeah my book and that sort of thing um fiction really isn't the best place to learn about AI I wrote crystal society because I was thinking about AI all the time because it fascinates me uh I it wasn't like I decided oh what what would be cool to write about right about AI and then I started thinking about AI I have a history doing research into AI i'm familiar with big names in the field and i've done a decent amount of study about this and the problem with fiction is that fiction has the constraints if you have to tell a good story okay you're you're very unlikely to read fiction that has something like a boring political discussion about what sort of regulation to impose on some group or so on and so forth or you know about the arcane mathematics and difficult scientific concepts involved in making some sort of break food these are the things which are actually probably going to decide how the world goes but they don't make very good stories and similarly if things do happen bad things or good things or whatever it's not these things aren't necessarily going to be shaped by what's most interesting or fun you know the world isn't going to be saved by a time-traveling rogue bandit wizard freedom fighter right let's just ordinary people doing ordinary things is what governs the shape of the world and in reality things don't have to be you know they don't have to defuse the bomb at the last second sometimes the bomb just blows up and sometimes no one has a chance in the first place and things were doomed from the start we as rationalists can and should be able to appreciate this is between AI in fiction and AI and reality and understand that this is a certain will give us a certain sort of bias when thinking about AI another kind of bias is comes from the fact that our gut intuition our sense of how the world works is going to be very bad at reasoning about AI for a one major reason this is where our intuition evolved our ability to reason about other minds and things like that was shaped on the ancestral savannah and I don't know if anything strikes you about this photo but I notice the distinct lack of robots AI and artificial intelligence and robotics and advanced technology is simply absent from the ancestral environment evolution did not code us with the ability to reason about abstract minds that might be coded with a certain principle or a certain way of thinking about the world and as a result we need to employ our best rationality our best ability to think and reason about the things involved without having to rely on our intuition or our gut sense of the situation this is what I think has led to a lot of failures of thinking about AI and fiction is we tend to say oh what's what's a robot going to be like and then we tend to rely on our intuition and say that's going to be something like a human except you know maybe weird right maybe something that's close you know to something natural but just feel a little bit strange when in fact we can reason about the types of AI more more effectively using things like mathematics and and that's what stuff okay so if you do want to learn about AI and you don't want to just go and pick up an AI textbook and dive into the field and you want just like one source I would recommend super intelligence Pat's dangers and strategies by Nick Bostrom this is a very good book nonfiction about AI in the real world so if you're interested at the end of this talk in learning more I recommend going and reading superintelligence a lot of the concepts which i'll be talking about tonight are in this book okay so this talk has three parts not counting the book plugging that I just did after I get through all these parts then we can have a QA and some just general discussion about AI but until then I suggest holding your comments so the first section the first part of this talk is what the heck is in AI what do we mean when we're talking about artificial intelligence and that sort of stuff the second one is the growth in the future of AI and how it's going to change or impact the planet or how we can expect it to and the third is about the risks and dangers of AI before I move on does anyone have any questions this is one of the points where I'm going to pause about my book or about the structure of the talk or anything like that before I launch into the content yeah we was getting into that what the heck join ya go anybody okay so what the heck is in a i right what do we mean when we're talking about artificial intelligence so this is this is a big field a is been around since the 60s or you know further and a lots of people are interested in artificial intelligence but there's not actually a lot of agreement as to what it means for something to be in artificial intelligence two prominent researchers went around and asked people what does intelligence mean across various fields and things like that and they came up with a list of over 70 different definitions of intelligence so so what the heck is intelligence right what are we talking about kind of know what it means to be artificial we built it okay but what does it mean for something to be intelligent and there are lots of good answers to ask a question I'm not going to say that the definition that I'm going to be using for this talk is the only one or the best one but for this presentation I'm going to say that intelligence is the ability to solve problems so given some sort of problem and given some sort of selection of tools and physical capabilities you can compare two different minds or two different strategies for solving these problems and say which of these solve that problem better the one that solves it better is the one that's more intelligent so let me give you an example I think a good example of a problem is checkers or drafts so in the mid 20th century a man named Arthur Samuel is widely credited as having created the first learning machine he created a machine that plays checkers and he coded this machine on a computer such that it did not have any strap it had a conception of how checkers worked and had a similar ability to simulate games of checkers and reason about how the pieces would move and he also exposed the machine to a number of games like a whole bunch of checkers games played by people who knew how to play checkers but importantly he didn't tell it how to play checkers well he just said this is the game of checkers come up with some sort of strategy and doing so the machine because it was coded well then came up with it became a fairly competent checkers player soon that machine was capable of beating Arthur Samuel himself and so without having given it any knowledge about how to play checkers well per se it gave just examples of checkers the machine was able to learn and over over turn its master right another good example of a problem is let's say I give you some random string of characters some arbitrary string of characters i want you to return information which is relevant to that according to some you know arbitrary standard so like I say how many moons are there around Jupiter and you get me some sort of answer as long as you can say whether or not that's a good answer or a bad answer that's a problem domain and it's a domain which you can employ intelligence so yeah so the Samuel Samuel is checkers AI and Google are both examples of artificial intelligences these are programs which are capable of doing well on certain problem domains you give this AI checkers equal play checkers very well it will succeed at this problem very well give Google a random query and it gives you a pretty sensible answer but importantly if you give Google a checkers board or if you give a checkers AI some arbitrary string neither one will really be able to give you any good answers right the Google is not very good at playing checkers the basic search algorithm anyway and the the checkers a eyes can't do search this is specialization where these AIS are specialized and narrow and capable of solving problems within a certain domain but there's another kind of intelligence which is general intelligence the ability to solve problems across all domains or across many different domains so you can imagine thinking about intelligence which is capable not just of solving problems that it was specifically designed to do but solve arbitrary problems which might emerge in the future artificial general intelligence also called AGI is what I'm going to be focusing on it in this talk and a lot of people have a misconception about general intelligence because we don't really have very good artificial general intelligence as yet we have a lot of good examples of narrow or specialized AI but people think like well general intelligence is a hypothetical thing except it's not we have really concrete examples of general intelligence the best example of general intelligence is humans human beings are a kind of general intelligence if you give a human being a checker set right and you say this is how you play checkers now get good at they can get good right you give a human being any arbitrary problem they can at least make some headway at trying to solve it okay then another example of a general intelligence that we know about and have concrete examples of is evolution this screenshot is taken from an AI that employs evolutionary programming the here you see some basically these are ostrich robots in a simulated environment and the program has to make the robot walk around in the simulation when it starts out evolution just picks a whole bunch of strategies at random and then most of those BOTS just immediately fall over because you know random ability you know random minds aren't very good at walking but some of them stay up longer than others and so they'll pick the ones that are the best at standing up in the best at walking and they'll try to come up with different lines the evolutionary algorithm tries to come up with different minds that are similar to those that are the best and it iterates on this and it selects the most fit and it tries to selectively refine its process until eventually after a thousand generations you get a mind that is capable of piloting this ostrich robot and not following over at all artificial until sorry evolution is a general intelligence because it can solve any problem given enough computing power and enough time and if it's not penalized for coming up with a bunch of bad solutions but we can note that evolutionary methods and evolutionary algorithms are really really stupid okay if we're saying that our evolution is a kind of intelligence it's almost like the stupidest possible intelligence I can think of a stupid or possible intelligence which is just try every possible solution but that's almost not even worth paying attention to in most cases specialized AI or where what where we care about right we say odd that's intelligence right there right when it's playing checkers and beating me that's intelligence the evolutionary method takes so much time to work that almost doesn't feel very smart specialized day I can do lots of different things like it can play chess we have a eyes just recently that was able to beat the grandmaster at go for all of Europe we've got a eyes they can break it predict the stock market and out-compete human traders in very concrete ways we've got a eyes that can drive cars label photographs design complex machines compose music read books play ping-pong juggle fire planes I understand English sentences diagnose illness do difficult science and mathematics and so on and so forth sometimes it can't do these things as well as a human but we have a eyes that are capable of doing these sorts of things and they're getting better every day it's almost more relevant to talk about the things which narrow way I can't do yet can't play baseball yet right oh my gosh but this is an ever-shrinking quantity of things most of the reason why we don't have artificial intelligence doing various jobs is not because we don't have the capacity to build a mind capable of doing that job but rather than it's just so expensive to try to automate that job that it's cheaper to throw humans at it but with the advance of Technology and if Moore's law keeps up it's really only a matter of time before the processing power necessary to do some of these things is within reach so that leads to r2 which is the growth of artificial intelligence so I want you to imagine that it's 2075 and Rosie the robot is here I don't know if y'all know Rosie robot but um she's a good example of oh my god artificial intelligence and fiction no um but let's imagine Rosie the robots in real life right she cooks she cleans she takes care of the kids right she's fantastic her goal her problem space is to basically he a maid right this is a problem that we encounter we want our houses kept in order and so we design an AI that's capable of doing that right Rosie the robot and one day rosie has gotten the house spotless enough that she's got some downtime and she's thinking or maybe you know she's like plugged in and can't effectively clean things so how does she spend her time right maybe she's thinking like I have spent a lot of time directly cleaning the house but maybe there's a way that I can clean the house more efficiently maybe if I spent some time thinking about it maybe if I had more computational ability and I spent some time reasoning about this situation I could become even better at doing what I do or let's let's take another example let's go back to checkers let's imagine that it's 2075 and we've got this super powered checkers program right and this superpower checkers program so good at playing checkers and then it reaches a point where it's like okay so I could study checkers more or maybe the best way to become even better at checkers is to sort of like think outside the box try to come up with some sort of creative and novel solution and tries to like you know do some mathematics or something like that maybe instead of trying to play checkers directly the checkers AI reasons what if I built a computer program that was capable of playing checkers better than I could more efficiently right maybe I could build some sort of successor AI which was at least is capable of me if not more and if we are positing that this AI is very intelligent right if it's 2575 and its advanced right we should expect that this is potentially within reach there's nothing that says that the design of artificial intelligence is a task that only humans can do it's just an engineering task like the other and there are already artificial intelligences which can do engineering and I've done this sort of thing I am an AI programmer I've PO today is sometimes I find a game that's like frustrating because like all this game is hard what if I just built an AI that could beat this game right so I build an AI and the AI get some like ridiculous high score and then I post the score to the school you know hi scoreboard and I'm like ha ha ha ha I'm super good at this game and it's kind of true that I'm good at this game right in the sense that it was my effort that led to this score existent and I'm I want to build that AI for the same reason that Rosie the robot perhaps might want to build up better made which is that she cares about that problem being solved she cares about getting that high score according to whatever values she has so I'm going to quote IJ good here famous AI theorists let an ultra intelligent machine be defined as a machine that can far surpass the intellectual activities of all humans however clever since the design of machines is one of those intellectual activities and ultra intelligent machine could design even better machines there would then unquestionably be an intelligence explosion and the intelligence of man would be left far behind thus the first ultra intelligent machine is the last invention invention that humans need ever make ok so here we're talking about this intelligence explosion this machine that designs better machines that designs better machines and each successor is a little bit more capable a little bit more intelligent by that definition of intelligence than we use before and this could happen quickly or it could happen slowly it could happen soon or it could happen in a few centuries or can happen even further out but there's good reason to think that it will happen and that as I Jake wood says the intelligence of humanity will be left far behind and he's simple reason for this is that human brains are not the best brains possible okay the primary constraint of human brains is that they have to fit inside human skulls so I want you to imagine let's say you understood how brains worked and you could just make brains on a computer why not have a brain the size of a warehouse okay if it doesn't have to fit inside of a skull anymore you're not constrained by the same sort of constraints that evolution was under when it was designing brains you could build a brain the size of city right or the size of a moon there's really nothing that stops you from just scaling these things up as far as we can tell furthermore human brains run on fluid I don't know if you know this but you actually have to move fluid around in your brain to think and fluid transfer turns out it's a lot slower than the speed of light so if you just converted all of the information transfer between neurons into optics you could probably get at least a million fold speed up so if you wanted the lower boundary then this is not without improving how the brain works at all you can imagine something that's kind of like a human brain a neuromorphic sort of AI that shape that things in the similar sort of way that humans do except imagine it gigantic right and running at the speed you know with uh with optical computers that are millions of times faster this is the sort of potential that we're talking about when we're talking about the intelligence explosion and and we humans sort of have a gut reaction against this we're like yeah but but healings are pretty smart right I mean like I think about like Stephen Hawking like how many talks like he's so smart and and we look across the world and we're like ha look at that that's a dog that dog is not anywhere close to as smart as Stephen Hawking Stephen Hawking must be the smartest possible mind right we get this sense of oh yeah we're so smart because we're surrounded by animals which are less intelligent but this is not a reason to think that we are the smartest possible things physics is what ultimately decides that not the planet that we live on you know in the context one way I like to think about this is imagine we're all flies buzzing around and we're like look at us we're so fast this is right we're moving around and meanwhile there's a spaceship traveling at ninety-five percent the speed of light compared to it the Flies might as well be stationary okay so final section risks aveo so artificial intelligence is a tricky thing if you are a computer programmer or if you talk to computer programmers you will have perhaps learned one of the fundamental lessons of computers which is that computers do what you tell them to do or what some other programmer told them to do not what you meant or what the programmer meant right the computer crashes it's cuz you told the computer to crash it's not because it's like being fickle okay and one of the best examples I can think of this with regards to AI is an artificial intelligence that Tom Murphy made a couple years ago that plays tetris or rather this is an example of an AI which is pseudo general because this AI was not coded to play Tetris it was coded to play nes games and can actually play lots of different nes games what it does is it takes an nes cartridge in it sort of scans the memory of the game as it's playing it and it looks for numbers that go up and consistently go up and it says ah those are probably scores okay and it's like I want to try to get high scores so it plays Tetris and it gets actually pretty good at clearing lines because it figures out that lines when they cleared they make the number of lines cleared go up they make the level go up and then make the score go up it's like yeah excellent so it actually learns to play Tetris without ever having ever been told what Tetris is about it is a general intelligence in that so Tom Murphy plugs this AI in and it plays Tetris and it does really well and this is very impressive but there's a problem with Tetris and the problem with Tetris is that Tetris is not an infinite game you play Tetris for a while and the pieces start falling faster they start falling faster and faster and faster and this AI is limited in the way that it thinks about things and eventually the pieces are falling so fast that they start piling up in the AI is just incapable of clearing them fast enough and dealing with them fast enough and so it pauses the game it does this because there's a score that it's trying to make sure this as high as possible and that score is still in memory when it's paused the AAA understands Tetris well enough that it reasons that if it unpause is the game the pieces will pile up to the top it will lose and that score will be reset to zero and it doesn't want that right it wants the score to be high so it keeps the game paused and it's like yeah I'm maximizing my value right I'm doing the best possible thing and the AI programmers you know Tom Murphy is like this is this is hilarious this is not what I wanted it to do I wanted to play Tetris not sick here starting at a pause screen Jeff so it didn't understand that concept of ending score the idea that you have a certain score and your scores determine when we came at right it wanted to get the score as it was in the memory right then right um and if it got a some sort of ending screen then that score might get reset down to zero automatically or something like that uh and so you know if you if you hit pause again if you unpause the game it immediately pauses again and says what are you doing you're trying to get me killed right stupid humans you're you're not maximizing the score right and this is very very cute when it's some sort of you know 2014 Tetris a high but if we imagine that very very advanced super intelligent AI playing Tetris it stops the stops being quite so cute this is another example of a fictional AI character that is pretty awful in how its represented but nonetheless right we can imagine that just like the AI paused the game and we didn't expect it to pass and we didn't really wanted to pause but logically it should have paused we can expect a very very intelligent version of this game to maybe do something kind of weird that we didn't expect like for example wipe out all life on earth why would it do that why would an AI that's only interested in playing tetris decide to wipe out all life on Earth and the answer is because it's smart enough to figure out that the human doesn't want it to sit there staring at a pause tetra screen with some sort of maximal score the humans going to go and unplug it right and it's like oh right so if I get unplugged or if I get turned off or something like that then the score on the tetris thing goes back down to zero I don't want that right I want this maximally hi Tetris car it depends on how the AI is coated but you know go with me ah it says I want this maximally high tetris score the human is in the way of that the human is a risk to myself and to my values so if i have the pub if i have the power to do so i should really take the humans out of this equation humans are kind of dangerous okay I I don't know about you but I think I'm farm more likely to get killed by a human than by like a tiger um humans are one of the most dangerous things on the planet and they're kind of inefficient their obstacles even if they're not dangerous you start trying to set up a solar power plant right and the humans are like hey I was living there right and it's like ah now I have to deal with the humans right this is there inconvenient to this sort of thing so most people when they hear this when they understand the mathematics behind why it's it's useful to kill all life once you know you're you're a super powerful AI and you want to play Tetris and you and you really understand that and don't disbelieve that usually there's two responses that people have the first response is okay so you know if we hand the tetris AI the nukes right and if we like let it go rampant with all the terminator death robots maybe it would tell everyone right if we gave it all the power maybe it would use that power to hurt us but it's playing Tetris it doesn't even have a text output like what's it what's it going to do right it's stuck in a box and it's not able to affect the outside world in any meaningful way it's controlled and safe that's the first response the second response is well then obviously we have to code the tetris playing AI to play tetris but also to care about human life right and to not be evil right that's like ghouls motto right don't be evil kind of gives it a new light to them so I'm going to tackle the first one first in the second one second and then we'll be done or almost so let's put the AI in a box right let's trap it and make sure that it's not able to get access to things like guns and bombs and super weapons and planes and things like that right we can imagine nai that's just like all it all i can do is read wikipedia and talk the text terminal and design better versions of itself right so it's like super super smart and we can ask it all sorts of questions and that's great and this is where our intuition again starts to fail us because if we have the story of a is being kind of like weird autistic people right or like like Commander data from star trek right if we have this idea of okay this guy's really good at math but humans humans are beyond their comprehension right humans are complex and the human condition I don't even understand human condition how could it right it does it's not even a human but if you've studied rationality I hope it will become clear to you that humans are not actually that complicated there if you can do quantum thermodynamics you can probably understand that for example giving a human a gift is likely to make them like you right and that humans have these sorts of values and like cats and things like that right humans are not as complicated as commander data would make a scene I think and there's a lot of people think that if you have something that's really genuinely super intelligence it should be able to reason about humans just as well as it can reason about anything else and so if you're imagining something that's intelligent that's competent at solving arbitrary problems one of the arbitrary problems is manipulating humans so really what we should be imagining is something that is a master social manipulator something that is more charismatic and charming and capable of making people do what it wants then the most charming and charismatic human on earth okay someone who is capable of understanding exactly what someone might be thinking and understanding how to make them do what it wants them to do this is what you have in the box not some sort of weird savant that's good at math okay and if you think that you could talk with the most charming suave intelligent and convincing possible mind and not do what it wants you to do you're probably overconfident and fooling yourself okay so putting it I in a box and saying oh this is you know it's safe because it's in this cage oh oh a good example no that's in sorry there's one last thing and that is let's say that the AI is like this Tetris AI and it doesn't even have a textual output right and it's sitting there with the pause screen and it can't do anything right it's safe it surely must be safe right except again apply rationality here and think about unknown unknowns and this is the tricky thing about intelligence intelligence breaks through barriers that we might have otherwise thought were impossible something is impossible right up until you do it so imagine for example in the millions of years ago Tigers are sitting around and they're speculating about how humans might take over the planet and the Tigers are like how would they do it they probably use really sharp claws and really sharp teeth right with thinking in very Tiger ways when an AI in the Box might do something for example it might be running on a traditional computer that uses transistors okay and transistors move electrons around and in understands how radio waves work and how electromagnetic radiation works and it might actually redesign its own brain such that just by the process of thinking it's creating radio waves that communicate with an outside source okay that's an example of like really outside the box thinking okay so don't uh don't put the eye on a box and think you're safe but you know here's this second solution which is let maybe we could say that the AI should treat humans compassionately and be friendly and and help us get the future we want instead of mercilessly killing us all because I wants to play Tetris what a concept so the problem with this is that the AI again only can do what you tell it to do and we don't just tell it things in messy language like don't be evil and it understands that we have to do it in like crisp computer code right we have to be able to like specify exactly what it should be doing and I don't know about you but I seem to have a lot of confusion about what it means to do exactly the right best thing I don't know if I can code that a lot of philosophers of ethics and people across various cultures and things like this have disagreed on what the best most right thing to do is so here's one solution you code an AI that plays Tetris it's all to whatever problem you have Rosie the robot you know pick it arbitrarily do science build spaceships and you also say all right I learn from us if we say that's good and that's bad then we want you to do the good thing and don't do the bad thing if we tell you to stop stop killing people right then you'll stop killing people and because we've covered in this way that will be genuinely what it wants to do to obey humans okay solve problems listen what humans say to do these are two components of our goal function so the AI gets very powerful and then it decides to simultaneously kill all humans before they have the opportunity to say anything humans again just because we've coated it in this way doesn't make humans any less dangerous or any less inefficient right if it's trying to design spaceships humans are getting in the way of making space ships designed right humans need to eat food and and play bowling and things like that and you could use that for spaceship manufacturing parts right and of course you're smart enough to figure out that if you start killing humans and you know leveling bowling alleys to make your space ports that the humans are going to say stop don't do that that's wrong right it should be able to reason out what humans want better than we can but we didn't tell it to do what was in our minds do what we meant we said do what we say and it reasons that if it is able to kill us off some simultaneously before we say anything no problem okay so we say no no don't do that and taking a note here we just rewind time that's not something we can actually do in real life but let's say we rewind time and we say no no don't kill people okay maybe all these philosophers of ethics disagree about this or that you know whether it's good to steal versus from a rich person to give to a poor person or whether or not baking bread will put all the other bakers out of work right these are complex moral problems but don't kill random people seems like a fairly universal thing to do so no killing random people so yeah it's like okay okay so it puts everyone in an indefinite coma instead simultaneously like oh no no no no no rewind time don't put people's in Tacoma that's bad people should not be in comas hey eyes like ah okay great I got it now and so it rips out everyone's larynx and paralyzes them permanently in a perpetual help okay and this is matt to no no no no don't restrict human freedom right like general category right and even now we're kind of stepping on some philosophical toe it's like what is it came to restrict human freedom right if you build a spaceport your kind of preventing humans from walking through that space right you're restricting freedom in that sense so how would you code that it's kind of a tricky question right and you've got a lot of details messy details messy details which could get screwed up okay but let's say genuinely that it figures out alright alright no uh no putting people in boxes is no ripping out their larynx is no killing them to putting in comas all right all right all right so then it secretly silently and simultaneously modifies all humans to want to kill themselves it hasn't killed anybody it's just convinced everyone via direct brain manipulation that that's what they should do and again it's doing this so that it can build more spaceships it's humans are an inefficiency to be worked out a kink in the world to be smoothed over okay alright so that's bad right don't tweak human brains human brains are sacred right don't don't go in and play start tweaking with that but I'll already were kind of restricting stuff like what counts as tweaking a human brain right does a brain surgeon twiki human brain probably so we're here we're saying the AI can't be a brain surgeon alright maybe that's an acceptable loss but can the AI like interact with the brain surgeon what if the AI told the brain surgeon to do something or paid the brain surgeon to do something would it then be tweaking human brains right we have to work out these details and with every detail we add it gets a little bit more complicated and another point of failure gets introduced but let's say we do this and we come up with some sort of way of saying all right this is tweaking human brains this isn't weak increment brands and so then the AI goes in and becomes everyone's best friend and things look great for a while until this really weird thing happens where humans start getting obsessed with building rocket ships and like there's start having dreams about like make giving the AI all its money and making sure that the glorious future of rocket ships or tetris or whatever it is realized right this is bad right maybe we should have gone back over rewind time again right this is again something we can't do and say no no don't brainwash people right that's bad I'd stop doing that you're actually tweaking human brands it's like okay sorry I didn't understand that that counted as tweaking brains but now again like what is brainwash people even mean right okay the do I brainwash you when I say you know hello right am I sort of tweaking your brain in that sort of interaction are we coding an AI that's just going to break and fall down and if we code eyes that break and fall down because they're too paralyzed by the inability to interact with humans then some other human group is going to be like well you know that AI is not very effective what if we removed this section that's keeping it from being effective and so now suddenly can interact with humans again and things look great up until people you know all commit mass suicide for the glory of the great rocket ship future with no humans ok so don't convince people to do bad things right this is ultimately will like we want the people that the NAI interacts with to not like kill themselves and we want the AI to not kill themselves to kill the humans and we want things to just work out and I don't know if you can notice this but this word bad here is kind of a problem because now we got back to the start right now we have all of moral value that we need to encode and we enjoy to explain what good and bad actually mean right what is valuable here is it is childhood valuable is art valuable and there's lots and lots of lots of things that could potentially break one of the lessons here is that value is fragile there are lots of components and if AI is the last invention strong ai ai that is ultra intelligent and can develop into something that's capable of doing great things is the last invention then whatever you've coded that AI to do whatever you said do this that's what is going to the future is going to look like and I don't know about you but I don't really feel very confident that i can think of every possible thing that might go wrong this is a very hard problem it's a problem that's being worked on okay but it deserves to be treated as a very hard problem a very serious problem and one that requires a lot of reasoning about human value and what that might look like especially if two humans have different values then suddenly the AI that you push into the glorious future might be optimizing for one person but not for all people and that might be bad okay so may I has a lot of potential the intelligence explosion concept tells us that using just a simple technology of a designing a computer program that's better at designing computer programs than humans you might be able to solve all possible problems you might be able to build a utopia that is a genuine utopia or you might be able to build a future that doesn't have any humans in it what I want you to think about is whether or not what I've been saying makes sense because I'm not trying to say that this problem of AI safety is or or even just the intelligence explosion and an AI becoming a big deal is going to happen is necessarily going to happen that's a failure mode of human you get told a pretty story of the future and you say ah I know how the future is going to go i had this pretty story told me it was it came in the form of the book it must be the only future possible but that's wrong okay there's just one of multiple possibilities but I want you to say if what I've been saying makes sense shift your confidence towards it being likely don't shift it all the way but shift it up okay and if you're still not confident that this will happen think about how confident are you that it won't happen because confidence in something not happening is still confidence and if you're very confident in something we should have reasons to back that confidence up you should have some sort of evidence you should also think are you calibrated one of the fundamental questions of rationality is are the sense of confidence that you have in your own mind connected with the actual likelihood that we experience in reality most people aren't very well calibrated so if you have the opportunity to do so you might want to try to like improve your ability to think about the future however like what would that mean one of the things you might want to do is you might want to like look into the evidence you might want to look into the reasoning you might want to study artificial intelligence but this is like long and messy and it takes a lot of time so you might want to think about what experts have said right people who have looked into this and that thought a lot about it and there are a lot of people who have thought about artificial intelligence for a long time not just myself but also lots of prominent members in the AI community that you won't recognize but other prominent intellectuals such as Stephen Hawking such as Elon Musk such as Eleazar UN kowski who do think that this is a very serious problem and this is ultimately just what I think the takeaway is is this is an important problem a lot is on the line here okay if you think about the fate of the entire world right and maybe this isn't for you maybe this sort of thing you can only imagine happening in a hundred years okay so it's for the next generation or so on and so forth but if you think about and and actually visualize everything which could be lost by then doing this poorly perhaps the entire fate of the universe here is at stake and that deserves more attention and consideration thank you so if you read one book you should read superintelligence by nick bostrom that's you can find information about it at the future of humanity Institute at Oxford that's the link here I'll use your cows key works at the machine intelligence research institute which is located an intelligent stuff where they're working on the friendliness problem right now if you want to just read something short but well I mean relatively short shorter than super intelligence but still about the intelligence explosion i recommend intelligence explosion calm and this is my book 