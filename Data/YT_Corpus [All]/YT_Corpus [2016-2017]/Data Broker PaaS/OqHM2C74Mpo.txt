 very good all right are you guys doing good awesome I thought I might I made last minute changes which is always dangerous right but I thought I might ask the question you know how did we get here like what are we doing like as a the IT space right computer science work how did we get here so uh how did we get to lambdas I thought that was a really great talk this last one that we had what's driving that becomes a really interesting question i think so i thought i might dive into that just a tad as an introduction to this new thing that we that i'm working on i'm very excited about which is Apache macios we just as part of a sphere we just open source in fact open D cos which is really kind of a it's it's it's Apache missiles on steroids it's really exciting stuff but from the perspective of like where how did we get to where we are like the thing that is necessary to understand the impact that Apache mesos has is to kind of like I was in India a few years ago and this is like real right like this is I thought was a great talk earlier with Andrea and we're we're looking at complexity that like someone thought that was a good idea right that how did we get there um when I want to ask you a question is what was spoken earlier was this need for speed fast and when i was in bangalore there was something really fascinating about being there you had options and one of your options is to get into a car now the beauty of the car is that it was air-conditioned right that was awesome but if you really wanted to get somewhere quickly what you really needed was to pick up the rickshaw and the rich i would actually get there quicker in many ways because it's actually more agile i had the ability to actually drive on the sidewalk and to get where you needed to go and it was just a really fascinating experience another aspect of like Who I am is I'm a pilot so I own this plane with three other people and when people look in the cockpit they see this and they think wow his complex and the reality is is I would I would claim that it's just you're not familiar with it I I can't see anything there that I would take away and still be like safe right there's a lot of redundancy there but it's really fascinating experiment when you put someone in this for the very first time it's like overwhelming so when we talk about where we're going this is where avionics is going today this is where we're at right it's all glass as a glass cockpit so I beg the question of you is can you imagine like we have we have challenges I'm not sure if you have them here but we have challenges and lots of big cities where we can't move people quickly like the traffic is unbearable right why is that now we have a bunch of solutions to that but those solutions are kind of stuck in legacy thinking we're trying to do if we looked at that first picture in banglore again we're putting more lines in and we're thinking we're solving the problem now the question becomes what does the world look like if the world was full of self-driving cars if you had self-driving cars and everything was self-driving do you need traffic lights do you need and we could go through the list of things that we can imagine right the problem is we're trying to solve our current problem with legacy thinking can you imagine in that future we have self-driving cars where the laws and rules are just completely different it would be like today looking back and going what is this law or rule or regulation around where I put my horse right like that that would be weird thinking but that's kind of what the future will look back on us as so what does it look like in the IT space when we think futuristically when we we're not stuck in the legacy world what does the legacy world look like well the legacy world is really focused on static partitioning we have a whole data center and we take that data center we have hardware we slice and dice that hardware into virtual machines right and then and then here's how you know you're in a legacy data center there's there's two aspects to it that are crucial the first is you treat your machines like pets you give them names right like this is Hadoop one this is Hadoop to the other thing that you can see is that in a legacy data center you have thousands of chef recipes thousands of them because everything is a special little snowflake right and what does that require well we you know we fixed the problem by coming out with things like OpenStack where we can automate the legacy thought if we need a machine and I have to have a name for it and I want to be able to enable that to be go into production quicker it needs a name it needs an IP address i have to automate the dns i have to do all that i have to write or do you that that becomes the really transition here and it's it's met with some challenges and the challenges everybody thinks most technology moves evolutionary and i agree with that but every once in a while there's a revolution and it's really really hard for the establishment to accept the revolution yeah and so when I think of something that's revolutionary I'm thinking about patching me so so here's here's where we're at those nine things as a statically partition world or for Hadoop those ten things are for web services rails Tomcat it doesn't matter and when we want to increase scale of something we say okay oh I'll just provision a few things more then we run into some really interesting challenges like how agile is that because that takes hours maybe days and you would do in a staging environment then you do a VIP switch over and you'd have it in production and then you have that oh crap moment we need we need we need production services now not analytical services and so now you start to drive a really interesting wedge which is I'm going to set my microservices over here I'm going to set my analytics over here they're going to be different clusters because I have different concerns which is really fascinating to me because the whole idea and concept of MapReduce came mostly out of Google Google research came out with MapReduce the paper why did that come out well they had an internal project called the Google Borg was top secret in 2008-9 time frame and what its function was is we have a data center that's mainly for web search what kind of sometimes it's not utilize fully and what if we could use the power of that data center when it's not being used fully for other purposes and what would that look like because if Web Services came into play I need to be able to adapt and adjust very dynamically not statically but very dynamically i need to change all my traffic to go to these web searches which is my primary business but if i could i'd still like these secondary services to run so if these secondary services are going to be shut down just preemptively shut down because i have a primary service i need to attend to what do we need to do well we need to check point things so the whole MapReduce process came into how do i establish a checkpointing model so i could start processing where i left off and yet we still separate these things out in really weird ways because we're stuck in this legacy mindset right that that actually was what makes Google a so far much so significantly farther in their business model than some other competition so it's a lot like it's answering this question can you imagine launching an app on your laptop and be an ask this question so really bizarre question right it's a really bizarre question so the question is this beyond this why is it that you do not have to ask answer this question on your laptop on your laptop or you inside your laptop as an operating system and in that operating system is a scheduler and that scheduler manages to the apps for you so there's multiple applications running at the same time and you don't have to care why do you need a care in a data center because when you push a nap into the data center um I'm talking more legacy stuff not the lambda stuff we just talked about that's like the first question you have to answer you know what type of affinity you have where is this node going to live those kind of questions are required why is it different so what's the difference between one node with a hundred cores in it in 10 nodes with 10 cores in it so it's an interesting thought model right like what what are the significant welp there's and scale them that's how you you learn the real difference like multiply each one of those numbers by a thousand and see where we're at which requires more operations teams and things like that so there are some significant differences but what if we were to create a scheduler for the data center what if I would just spin up an app and it would just happen right so if we get into elasticity there's another kind of thing we could talk about here with the davis center and that is i guarantee you that in your private data center you'll never get above eighty percent utilization because there's alarms and buzzers and pagers that go off when any one box reaches like seventy-five or eighty percent right we just we just can't and the statistics are I don't know of any data center actually that's I don't know too many data centers that are running below above twenty percent so it's very common to be very very low I did a work here recently with the company and they were at five percent so that's that's kind of the norm now looking at ec2 there's some companies that have moved to using may sews and one of the benefits that they gained was because we do some been packing they reduce their Amazon bill the first one was hubspot they reduced their Amazon bill in half from 160 k amount to ATK a month the last report that I saw was open desk or autodesk sorry and autodesk save some crazy amount as well like sixty percent or something like that and it's largely because we can bin pack and have higher utilization of a given node and you can still have fault tolerance because you're gonna have multiples of those so it's a very significant way of leveraging your data center so we've come out with something called dcos and i'm happy and excited to share that the fact that that we've opened sources now open DCOs was launched last month it makes your data center look like one machine the idea is no special snowflakes anymore everything is just uh resources now that's not always entirely true right you're still gonna have a no that's kind of an SSD hanging off of it you're still going to have a node that's going to have a j-bot hanging off of it you have some special nodes occasionally but you're going to be able to annotate them and then with that annotation you're going to be able to have self-healing applications where you don't have to be alerted or page the application the scheduler will see that a task that was running on a given node that no longer exists can be repositioned to another service automatically for you so this has been Hyneman the creator of apache masseuse and our stated goal for the last few years was to make it as easy to create apps for the data center as it is for your laptop so I'm gonna go a little bit quicker and to some of this because I want to show some demos in fact what we're going to look at is another lambda not to confuse you but there's something called the lambda architecture and so my focus today is going to be looking at spark and looking at the lambda architecture and essentially data agility in fact I work on the data agility team atmosphere so since I want to do a few demos let me let me challenge you just a bit around services so i have started before i got on stage a cluster and in that cluster i created an application that's running and it's actually quite simple it's uh it's called sleep if you notice it's a 3am my body time so this is what I should be doing and it's it's sleeping and that's outputting something to standard out and it's just to show off a couple of things like what are the reasons why as an administrator or DevOps person I need to know the name of a machine well I need to be able to fix it in debug it and I need to be able to go tale something like the the universal tool for debugging and the op space riot is tailing so I need to be able to do that and so I need to know what your machine to go to and becomes obvious right that's the legacy thought is I don't know any other way to do something other than to make sure I can get to it and start tailing it so what I have here is a cluster of 10 notes out on ec2 and I can ask DCOs for information around those nodes so you can see i have 10 listed here but more importantly i can say you know DC us what are the one of the tests that are running and i can see i have three instances of sleep is actually the same app just spun up to three scaled to three I can actually scale sleep two three and but more importantly I can do this I could say you know what e cos I want to affect let's abbreviate this let's let's go to D cos task log and let me kill this at the end I want to log sleep now what's important about this demonstration is that I am running the terminal that you see is running on my laptop and I am pointing to a cluster that's running an ec2 and it's running in the frankford region alright so that may not be clear based on the amount of the volume of of standard out logs at this point but we actually saw all three of those you can see the first one here there's one here we saw all three of the standard outs at the same time because I said give me the log for sleep which basically means give me all the logs for standard out for all three of them because I can't distinguish them I can even do oops follow and so we are following all three of those as they are outputting and I think it's every three or five seconds you'll see an increase in that log and that's just logging what the in fact we saw a transition right there so you can see all three logs happening at the same time and so now we have a way in fact I could go instead of just sleep I can actually say give me the list of tasks I can say this is the one I seem to be having troubles with i can say any the follow of the log of this particular instance so I just getting a look for that one and more importantly i can say give me standard air instead of standard out and so I see standard error of that task in fact I can even go so far as an I want to know what's in the sandbox for this running task so give me the ls which provides the the the the view of the sandbox itself so there's no need at all to actually know where this is running I don't care because I have full access to logging to debugging to understanding the the environment that it lives in and the beauty of this is this run on Apache basis with the open DC us so what that means is I can run it in the cloud solution and once I had that layer of abstraction I can run on any cloud and I can move from cloud to cloud and it won't matter but I can also run it on Prem and make it my own so there's some there's some really great values out of that and while we're here I have a few scripts that we're going to talk about so let's start installing a few things and then we'll have a discussion whoops okay so I'm going to install Cassandra Kafka and and then we'll once that gets established and set up we'll start looking at our demo which will be ingesting its Twitter feeds so let's get a understanding what that architecture looks like before we get to there so another lambda architecture upside this is right here the mesas architecture so this is what it looks like we have you know in a production environment or gonna have three to five masters for dev environment you might have one you have any number of slaves we actually changed the name recently two agents so you're going to emmaus agents here's the really awesome aspects of this is how your mental model changes if your Amazon as an example we have if you're running the Amazon model we have traditionally couple two things together this is legacy thinking right to two things have been coupled together that we can't even talk or think about without them being coupled together we can't separate them and that is capacity and scale when I need more scale the thing that I do is I hydrate an image should take an ami image and I say I need more of that so I spend more instances up which means I am increasing my capacity and I'm increasing scale all the same time does this make sense now what we can do with Apache pesos and open DC us is I can have a set of capacity and I can decide that I want to scale completely independent I can scale the app creating more instances of sleep if we wanted to hear this is a simple example but we'd probably want more of a web app as I have a web app and I scale it up that's all being fronted by a load balancer and so I have increased scale which is separate from increasing capacity like I need more capacity now clearly I could increase Gail to the point where I need more capacity to increase it that makes sense but I have more knobs now in other words and this is a really big deal I have been packing working for me where I can consolidate those services to a smaller number of VMs out on amazon I can change the capacity to a smaller amount and still maintain the same level of scale and that's a really big deal because it's a cost-saving measure so I talked a little bit about open D cos it's an operating system if you take the definition of Wikipedia of operating system replace computer with data center that is our goal that it was what we're after if you think about an operating system what are the things that you expect well I expect things like package management IP I should be able to do an apt get install a yum install I should have a file system things of this nature if your Microsoft you would claim you have to have a browser I'm not sure if that's a requirement but the older group laughed in here I saw that okay so we are focused on building that out and we do have like a homebrew inspired package management tool for installing apps and if you looked at what I did just a few seconds ago from the command line as I said DC us package install Cassandra and so within minutes within the amount of time where that were that I'm talking up here or but I have a fully provisioned ready to run Cassandra instance out on Amazon now the thing that's fascinating about that is that for many organizations you're going to bring in like a datastax and you're going to spend three days to do the same thing essentially right and I realize that I have basic installation and basic configurations but that's going to be evolved over time the last thing that my team's been working on which fascinates me because we haven't really announced it yet but it's going to be exciting to share with you now is the ability to upgrade something like Cassandra from 22 22 to 25 to upgrade on the fly while it the services are running those are the things that we're working on is that no downtime whatsoever and having upgrades that you just literally go in there and say DCOs the package upgrade to this version and magic happens that's the kind of thing that we are working on along with some security aspects so with open DC us what you get on top Patrick may so sore these things a nice command-line a nice gooey it's like the difference between bugzilla which is useful but not attractive and using JIRA which actually has some aesthetic please it's somewhat aesthetically pleasing I have kind of a love-hate relationship with your though but look don't let that trouble you so here's our stack and what's really most important about this just like the iphone became super popular based on the app's that were created for it we're currently building out a ton of apps on top of the deep open D cos and I'm fact I'm one of the committers on that so if you have some ideas let me know if I if I dive in here to the universe these are the possible options that are currently deployed into this cloud solution so you can see a bunch of data apps data center caps we have some developer type apps spark marathon and Kafka and you can see the list so it's a large number fairly simple we won't have time to go through the details of how to get in there but send me an email or we can talk about it after the session all the things can be installed directly from the UI so I can go in here and say oh I happen to like react let me install that so I can install I can go to the Advanced Settings look at the detail say yep that's what makes sense to me and say install and now and slaw and react so from the UI from a command line it's basically the same thing once I have service is up and running xad cos service i can see that i have a few services up and running that I didn't have before Cassandra's running cough less running I can verify some of that by saying dcos kafka connection get the connection information associated with coffee i can see i have three brokers up i can see their IP addresses within the cluster i also can resolve their dns through my sews dns so actually the broker 0 Kafka may sauce is actually resolvable IP address within the cluster some pretty cool stuff so since we've got this already kind of started up why don't we go and install and what I should show you first is whoops let's go here uh we are going to start consuming some Twitter and I'm hoping that the still works i might be rate limited by now i started sucking down a bunch of twitter feeds just a few minutes ago and I've got a cluster we could switch to if for some reason this doesn't work out I had to pick something and I thought well nothing's more entertaining than Donald Trump I'm sure he's internationally famous at this point right so we'll look at his feed will also look at the go to Stockholm feed and if somebody wants something else we can add it in there but adding this in as nothing more than saying install for us it's adding a group of demo able things within marathon it's going to spin up I don't know if we actually installed Zeppelin so maybe we should do that too yeah we didn't and I had some issues with some Zeppelin's stuff I I don't know if the demo will go as well as I hope or anticipate but I think you'll get the core ideas of it there's a pull request out for a fix on that that hasn't been integrated in yet so we are currently building out a Kafka producer and consumer for the Twitter feeds that we just pointed out if I were to go to the services for marathon and look at what's being produced you can see currently being staged as a producer for each one of the topic areas if we wanted to we could actually you know change that up and add a whole new feed because maybe we're interested in who who wouldn't be interested in pandas right of course save and so we could say install instead and within a few seconds we'd be able to see that we're going to create a producer now we're deploying a new producer for pandas so we'll add pandas to the mix and see what happens right so we takes a few seconds for that provisioning process to occur you could have these these images through docker images pre provisioned in that area or pulled fetched if you will to accelerate that type of process when we continue talking and then we'll see how that looks in just a few seconds all right so we have a nice UI looking at the whole data center this is what the architecture of open DCOs looks like it takes Apache mesos ads in an admin console which provides CI or CLI interface in a web interface we have a public node which allows you to have public access into the private nodes I can go into a lot more detail there as well but that's kind of the the overall view we have clear of course are going to have infinite number if you will of private nodes and if I haven't said it our any one of the other great things about this is that this can all run on bare metal now if you didn't see this last year last April app will move their entire serie de dissenter to Apache macios under a project name called Jarvis which is kind of Lincoln nod to iron man why it turns out that the MS are not so great at scaling I oh and Siri is a heavily intensive IO application also my research a few years ago indicates that VMs consume between seven and fifteen percent I like to have a round number of just ten percent so ten percent of your data centers consumed by virtualization that would be things like the guest OS and the hypervisor so some benefits that they gained out of this they move to Apache masseuse one there longer pain licensing fees for vm and they still have a way of now here's the thing that's really interesting there is a legacy thinking that expects that if I have a paas in other words a platform as a service it requires as a prerequisite in IAS and infrastructure as a service and what they have established now at Apple is a the experience of a platform as a service without an infrastructure-as-a-service gaining the benefit of ten percent with Dana Center for free they gained a whole ten percent of their data center which is large for nothing because they just don't virtualize it to they've optimized the utilization of their hardware they no longer have VMs that are two gigs that are only using one gig of space having a lot of headroom they're completely unutilized we're actually using all of the space if you were to consider memory space as a resource that we're using it efficiently two or three they have the highest level scale of iona possible because it's bare metal so there's some really really great benefits so bare metal is a great option obviously cloud solution another great option now lambda again not to be confused with Amazon lambda which is so fun comparison we're talking with lambda architectures the lambda architecture pushes for here's the the value prop of the lambda architecture in fact we've been doing this for years we just didn't give it a cool name and what we've been doing for years is when you're building out a search engine like an internet search engine you need to index things and when you have a new page you've discovered you need an index for it and you're willing to sacrifice accuracy for something speedy I need a speedy answer knowing that over time I'll get a more accurate answer and the index will be updated so essentially what lambda architectures and data are about is the ability to get a very quick answer knowing that I will also have a slowed lolene which I'll get more accurate answers and that's the model that we go after all right so to enable this type of behavior this architecture has three different sections if you will the batch speed and serving and I have some details of fluff there but here's the end result a common architecture that we like to promote and the frameworks that I've been working on include these we have streaming data into kafka clusters essentially which provides some fault tolerance as well as redundancy across nodes that's usually hosted and managed by a quorum of zookeepers in fact the whole infrastructure is we then have sparked streaming so spark actually plays an interesting role here because spark plays the role in streaming or we're actually transforming data into the right centric data center or right centric Cassandra instance for certain applications we will have a right centric than a read centric cassandra and some are in some cases I've seen just one instance of Cassandra with different tables so it depends on what you're after so we have a fast speed lane where we can just read things coming out of the right centrica area or we can have the slow speed lane where we start doing some MapReduce or some kind of analytic type things and we start providing results of those animals analytical results into another instance of Cassandra so spark plays another two interesting roles here one is sparks Park streaming the other is sparks equal because a lot of people are using Cassandra for high end high school no sequel option but the problem is it doesn't have an ability to join and it's esque it's cql is limited it doesn't do joins so the most common thing that I see is people that are organizations new to Cassandra need to be able to build some kind of query they often are doing that with spark spark becomes the query language in fact for Cassandra it's a very common model that we see we initially were calling this the smack stack internally in apparently marketing you know decided not to call it that but smack stack would be like spark masseuse acha Cassandra and Kafka smack right it's a very popular model for those that are working in the space so the first part is Kafka we've already got that installed it's focuses provide fault tolerance and its runs essentially it's a great log system it is a pub sub type model but the reality is it works so much different than your standard Java pub/sub that I don't like to really talk about it from a pub sub model it commonly is just a huge log it's like a transaction log and you have multiple readers that can read different and reread if you will based on failures that occurred some kind of historical information in the lock so it's a really great concept there's some great information this is for me this is required reading it's a blog post by Joe who's one of the cofounders of confluent which is the creators of Kafka it's a blog post but I printed it out to read on the airplane when I first became aware of it it's like 52 pages so that's quite a blog you know it's more of a book so but it's must read information so let's go out to our demo area and see where we're at let's go to we see our spark streaming is engaged would go out to marathon and see that we're still staging producers hmm interesting all right don't know if that will work but the end result is either with a spark notebook or Zeppelin we should be able to gain access to this this is a little bit I don't know if we'll have time to show off the whole thing but let's go out to Zeppelin and see what we get now i'm looking at the Zeppelin oh I got one more thing that I need to do here and i realize that it looks funky this is one of the fixes that we need to the pull request to do but i need to go to https to encourage it not to be HTTP to get the full result i am going to import the demo notebook which is right here import and once again i'm not sure how this will look because i don't think i have the right connection here but I could have essentially what this would do if we have the demo completely integrated is show us different graphs for the different tweets that are coming through another aspect or view of this if you will where we can look at the real data and prove that we're actually consuming things from an IOT standpoint is we could go and run this oh by the way if I wanted to I could go DCOs node SSH I want to go to the leader master proxy so it automatically knows that that is to the leader the Mesa leader within the dcs environment i'm now going to run an instance of Cassandra the client side and then we can run a quick query just to confirm we're actually inserting data into our database or not so the table has been set up which is great but for some reason the provisioning for the producers aren't actually engaged yet it could be that i'm being rate limited but if i did this just like 30 minutes ago you missed it it was beautiful it worked and if you pay money to Twitter it will probably work again so i'm not sure i am with time we're probably running late so why don't i open up some questions that's kind of the full tour the architecture again included lambda which is acha kafka cassandra which i didn't go into a whole lot of detail on the installation was fairly simple we have basis dns where i can actually resolve things with cassandra in this way the you saw the query at worked i just did have any data results and then the end result is spark streaming and doing some creole languages so i'll make these slides available you'll be able to inspect it it more in more detail but that's a core of it alright thank ya so we have a few questions the first one is what don't you get with a dcs DCOs open that you get with the paid version with with what the paid version or is there a nun oh they're so there is an enterprise version yeah okay yeah so we've pretty much opened up everything we had to a certain extent the one thing that we've held back on so far is security oriented thing so integration with Active Directory Integration with kerberos there there are some security features in the open version where we can actually have authorization of frameworks or services within the mesas infrastructure so some of it is there but there's some let's held back that it's considered to be enterprise focus there's some other aspects it's unclear to me yet we have a concept within a service to be able to update that would be changing the configuration on the fly while it's still running I believe that's going to be the open source space I am not entirely sure whether the upgrade will be so the ability to upgrade on the fly a running process may be viewed as an enterprise thing I think we're still working out some of the details of what enterprise means okay good so another question is that does meso support services and applications written in net or other microsoft base that's a fantastic question so Microsoft is actually working very close with docker to in a number of ways one is making docker native but there's actually two aspects of that native as in well the end result is Windows 2016 will have windows containers we are quickly coming into a world this world that I just showed you was linux-based we are quickly coming into the world where the containers will may need to be annotated you may need to be able to distinguish windows vs linux and that's really fascinating so we've also been working makes us fear has been working with with windows are with Microsoft with a focus of providing orchestration and management in the same way like this ability it might might be possible that Amazon I'm sorry Asher will allow you to integrate a whole lamb to architecture stack in a very simple way that you we've seen here okay so so another question here is how does acha fit into this Mac stack in it fits in a variety of ways but the main idea and concept is there's an actor pattern associated with that that helps with efficient concurrency at the at the device level and occasionally you want that at the front end level as well I mean in the front end of your of your back-end systems in other words the end point but but yeah I don't know if I have much more than that it's a common pattern to see from a producer standpoint the last question here is can any language be compiled to run on missiles okay so language and I don't know if I accurately answered the previous question so it depends on what you mean when we look at something running on top of mesas and I don't know if I have a slide for that let's see here yeah if we look at application running on top of macios it just needs to run on the platform that it's on and it won't matter what language it's in so if it's on long windows it could be a dotnet app but I don't know of one that's running i dunno of people that are running like mono so dot net applications on a Linux environment with mono we do have clients that are running cave em spun up by May so so they're running windows in a kvm space as we start to integrate more with Microsoft we'll see what happens there if you're right so that's applications running on top if you're looking to provide a service like the in the universe i was showing hey we've got Cassandra you could add your own type of services those are limited today but whatever can integrate with protocol buffer if you are going to build an ASOS framework there are other frameworks that I shouldn't call in frameworks there's other services that are just docker instances that have no framework connectivity they're just landing on the node and provide some service so a good example of that might be data dog with data dog you spin up an instance he running one on each node and it provides data analytic information about the note itself like CPU memory and things like that so cool thank you yep give a man you 