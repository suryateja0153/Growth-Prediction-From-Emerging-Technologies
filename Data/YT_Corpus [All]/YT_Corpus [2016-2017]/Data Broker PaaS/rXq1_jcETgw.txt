 you yeah good okay hello everybody let's get started there's lots of awesome to talk about so let's get going hello my name is James Strachan and I'm hopefully going to talk about lots of interesting open source stuff that you can all play with as soon as you get home alright now if you get bored in my talk I'm gonna start before I couldn't talk about quite a lot of different open source bits and bobs before I start I want to step back a little bit and just talk a little bit about how we're all trying to go faster now the IT industry goes through various trends there was a object orientation used to be a big thing and the focus on reuse and then it was all about services and so now there's a current thing of how do we go faster how to deliver value to our customers quicker now at first you might think well does it really matter if it takes me one week or two week to deliver some value the aim isn't really that the point isn't really the amount of time it takes it's how many iterations can you get in right software is really kind of complicated as geeks we can often get sidetracked in how caching works in the persistence or our emulator and kind of forget what is it that the user actually wants what is the value we should be aiming for so trying to deliver value to customers faster should be our kind of game right it's how do we do that as quick as we can and then once you have developer delivered some value how do we then iterate to go quicker and quicker and quicker because it's the iterations that make an awesome product the first projects always crap right it's a bit rubbish it's the fifth sixth seventh tenth generation that's the better one so the quicker we can deliver value the quicker we can iterate find out what customer really wants right pretty much every system have ever seen where there's specifications written and design documents or whatever the first version that comes out customers see it and go oh I didn't mean that I meant something totally different so you need to iterate a lot right the idea of working in a library tower for two years and then going dinner is kind of get you you're doomed to failure there so how do we go quick how do we go fast so there's two kind of buzz words right now you've probably heard these before DevOps and micro services they're kind of related the kind of different sides of the same coin it's really about how do we deliver software faster now to deliver software and value faster it's actually more complicated harder right so it's more complicated but you can go faster with this extra complexity so one way of doing it is refactoring software so a purely technical thing take your big hunk of monolith that occurred or split into lots of separate pieces now you probably kind of do this already and you think well everyone does that don't they the big difference though is those separate pieces are then released separately so each micro service has its own life cycle right you release each microservice when it needs to be released the Internet is kind of like a micro service system you could think of right there isn't one release we don't go these nets down today while two zero goes out and you roll out the whole thing right there's lots of little micro services that have been rolled out all the time it's much more complicated it's much more harder but it means you can move faster right so one of it is is splitting your system into lots of little tiny little pieces that all iterate independently some systems get stable and then just have the old bug fix other systems it's very quickly as you deliver more and more value the bigger change with micro services and DevOps which is though the real hard one is actually human and organizational you split you're one big team into lots of small teams working on separate things so separate independent teams if you've ever read the mythical man-month book it kind of it's a very old book and it talks about you have a big project and it's going to slow if you add more people to it it goes slower right which might seem counterintuitive at first but the more people in a team the slower it tends to go because of talking and meetings and the kind of the chitchat so if you want to go faster take one team refactor it into ten teams assuming you've got lots of people okay if you only got ten people or one person that wasn't very well but assume you've got quite a lot of people split them into small teams making small things independently and this is the key point independently minimise the coordination between teams and you can all go much quicker now the other thing that's a big change with it particularly the DevOps movement is and the cloud as well we used to have silos some of you probably still may may do have silos we have lots at Red Hat unfortunately which is slightly embarrassing but let's not talk about that right now and silos are really bad you might have a development silo and then the testing silo and then the support silo and then an operation silo and maybe a design silo and an analyst Seiler and you have people doing one function and checking things over the wall so the the the spec I will write a spec and took it away and then the the coder will then try code it and then trick it over the wall and then the tester will go oh my god this doesn't even work and what does the user won anyways and having these silos means you have lots of time it takes a lot of time to move things between the silos one of the big things of a DevOps movement is by having one team with testers and designers and coders and operations people in one team working on one thing together so it's one flat team it minimizes that silo and makes it quicker to take some card put it in development putting testing putting prediction and iterate quickly right the less silos we have the quicker we can move and the more we develop software that's fit for production the further a developer is away from production the less likely that developer is to write code that runs well in production right so the more that your one team is looking after the whole spectrum of a piece of software the more you write software that's more easily testable easily monitor abilities are easily manageable right so it's almost like from day one you should write some code and go straight to production and then get used to rolling out upgrades running upgrades to production because then you start thinking about making your software easy to upgrade easy to manage your monitor okay the other big thing about DevOps is automate the crap of everything right because as soon as you start having 10 micro services and each one of those is doing a release every say a day you're doing 10 releases a day that's quite a lot of releases right and if you've got say 4 machines you don't want to be ISO searching into a machine where and with vai editing things and curling things on the command line and crap like that right everything needs to be automated every bill needs to be able to admitted every release needs to be or to me every rolling upgrade should be automated so the more you do something the more you should be automating it so then you can get better at it right a lot of DevOps people talk about if something's painful do it more often because then you figure out a way of making it less painful right so you should release often and automate everything ok so that's the general basis of all this micro services and DevOps thing so that all sounds kind of cool but then how the hell do you do any of this stuff right how do you release something 10 times a day and how do you have 10 different things that are running independently and how do you keep track of all these kind of stuff so what we kind of need is a platform for developing micro services on top of where we can have lots of different teams writing lots of different micro services we can all kind of work together and we can all move software quickly through development testing staging and production right so we need things like continuous integration and continuous delivery where automating the builds of things and the migration of those piece of software through the platform ok so let me tell you about the implementation details for how you can do this right now professor Dave mentioned docker briefly the document has changed everything really up hi I'm kind of old not quite as old as Dave but I'm kind of almost that old I've been writing software for a long time doctor changes everything really so in the Java world we've got into the habit of making like a Java file or a war file and moving that from development to test a production which is a good thing right we make a binary you're not meant to unpack it you're not meant to hack it and then zip it back up again you might to just take that binary and move that binary through the environments and that's good that's good the only slight problem is the application service and the configuration and the JVM and the operating system and all that kind of stuff is not in the binary the binary is just some Java stuff right so that war might work perfectly on your Windows laptop using the version of Tomcat you you lovingly installed two years ago but it might not work on the Linux operating system that's in the production environment that some other guy installed some other JVM and some other operating system and yet again you get the picture right so you're not really testing the operating system and the JVM and the the application server there's so much that can go wrong by taking that war and moving it to production right because you're not really testing everything you're just testing the war and you're assuming the war is in an app server that's tested there's configured just so so everything kind of works what doctor does is change everything and that you can put everything you need in a container so the JVM the operating system patches the any shared libraries you need any binaries any environment rebels whatever version of the app server you wish to use tomcat jetty you craft wildfly whatever the exact configuration of jane di for the war and all this kind of crap right so doctor really changes everything for me the biggest thing about docker is the metaphor the shipping container shipping containers totally revolutionize revolutionized the transportation industry and in the old days people would just transport you know barrels and bags and sacks and random stuff then somebody come up with the idea of a that shipping container which men forklift trucks you have to pick up a shipping container you could get cranes and truck and tractors and trailers and chips could stack them vertically horizontally and the door was always in the same place you can have standard tools for getting things in and out and you knew if you have multiple shipping or days next to each other they're not going to interfere with each other right not one is not going to give off a gas and the other is going to illegally quit and though the explosions are gonna happen and stuff like that so docker is the same kind of thing for software it's a standard way of putting something in a box in a virtual container and then it can just be installed and run on any machine right if ever you've tried to install Oracle say or even most databases to be fair if ever you try to install NPM or gems or whatever oh damn I previously sold a slightly different version of something that conflicts with the thing I'm trying to install right now oh let me trash my entire hard drive and start again installing software is a pain in the ass right if you configure stuff in a docker container anybody can just run it right in just one command which I'll show you in a minute so docker has changed everything in terms of packaging software what actually happened some of the covers is it's still just a Linux process all the docker container ready it is it's using Linux containers things like C groups and namespaces and that kind of stuff so that all you're doing is running one process it's still just one Linux operating system process the process kind of thinks it's like it's in a VM so it looks and feels like each process has its own VM but really each process is just isolated from the other processes so with virtualization firstly this is kind of cool but it's kind of sad these days every time you make a VM you have to run a whole new operating system that's pretending to be a whole new computer right with docker containers you're just running a process in a container so that you're sharing the operating system right you don't need to run lots and lots of Linux kernels you don't remotes of device drivers pretending to be a filesystem or memory or the keyboard or God knows what else right so a docker continues just a process but it's just isolated so each process gets their own disk so you don't have processes clobbering each other's file systems by accident you know both two programs might use slash temp /foo right that's fine in docker because they're isolated each container also gets its own ports if ever you've try and run tomcat twice on a laptop you have to open up the Compu files in the Hat search you replace in all those ports because there's only one port 8080 on your laptop right in docker every container can say I'm gonna listen on port 8080 and that's cool and every container does because every container gets its own networking stack so you can listen um whatever ports it wants to slightly complicated thing is if you're on your laptop and you want to talk to those two Tomcats each one externally gets its own different plan because internally dock is doing ports whistling from the outside in so basically the idea behind docker is put your stuff in a box in a container and then anybody can run it on any computer plus you can densely pack these containers together onto hardware but studies have said it's kind of 20 percentage hardware for free if you switch from virtualization to containers because you're not running 20 code you can run 20 processes on the box without 20 Linux operating systems on the box right you just running 20 processes and this other stuff docker can do as well by the way you can have runaway processes that get into a CPU loop that one bad process can take a bunch of cent of your CPU and it can starve whether it's CPU or i/o or disk or network it can starve all of the other containers docker lets you set limits you can say this container can only use 10% of the CPU and docker kind of turns a linux box into a bit like the old mainframes where you could totally slice the box up into pieces allocate those to different programs and you can have your own little mini supercomputer or mainframe so docker is also make changes everything this is how you run it like if you learn one command today try make it this then you can run pretty much every software that anybody's ever made that runs on Linux docker run and then space then a couple of command line flags depending on if you want an interactive terminal and what you want to do with the port mappings don't worry about that detail and then the last bit is the name of the docker image and that's it and that name of the docker image could be Postgres it could be memcache D it could be a Ruby and rails app it could be Erlang it could be a Java app and ogs APIs whiffed app it could be anything right you don't have to figure out how to do gem install or npm this or that or any kind of package manager or yum update on rpms you just do docker run and your hand you're good to go so it's nice and simple so docker changes everything in terms of different delivering software right it's a thing of awesome and if you're delivering software to run on Linux please use docker containers it will save you lots of triple and the people running your software will will thank you for it okay so that's dhaka the thing about dhaka though is it's kind of like running a program on the command line you type docker run blah blah blah and then something will run for a while and then he it might stop running I even like or don't but he might die the Box might die so docker run by itself isn't enough to run lots of micro services in the cluster where everyone's talking to everybody so you need that the next level up of awesome which is kubernetes you can't see the bottom Kuban it is so hot right now so cupola teas is is an amazing of a sauce project I've been in open source for a couple of decades and for me Copernicus is the most amazing open source project I've ever used consumed worked with it's truly truly amazing to echo some of the things professor Dave said in a last talk Google are kind of the daddies at cloud computing and and big data right they wrote all the papers on hadoop mapreduce Google file system BigTable chubby for zookeeper and so forth so the whole pretty much the whole Apache Hadoop project is based on Google papers Kouga have been running containers in the cloud in their data centers for about a decade and they kind of a figured out how to do it right there they kind of know how to scale running lots of containers really lots of micro services that connect to each other so they've recently published a paper called the Borg paper if you google the Google Borg paper that basically describes bog which is their internal implementation of kubernetes and which is really how they run containers at scale which is truly amazing then what the Google guys did is I think they finally got fed up of random people from Yahoo writing their papers in Java and Apache and they thought we won't actually write our papers ourselves goddamnit as an open source project so for the first time ever Google's actually implemented the bog paper as an open source project a public open source project which is what Cuban ATC's so kubernetes is is Google's latest open source project for how to run containers at scale it started about a year and a half ago and then I work at red Red Hat saw it and went oh my god this is awesome so Red Hat jumped in and we're now one of the major contributors kollross people jumped all over it there's people from Microsoft there and various other companies of all jumped on it it's got a massive massive community but basically kubernetes is it's already in goal and it makes a really small binary it's really small and simple and it's basically software to help you orchestrate containers now the term is orchestrate containers but it always seems a bit kind of wussy to me it's like I'm just gonna slightly rearrange some content for you really what he does is it makes a container as a service platform it or a micro service cloud right they did okay don't miss under estimate the orchestra in there really cuba Nettie's take stock of containers and turns them into a self annealing auto scaling cloud right and rather like the stuff they were saying about Google cloud what's amazing about cubing it is is you can just run this on your laptop you can run this on a bunch of boxes you've got on-premise you can run it in any cloud you can run it on any infrastructures of service you can run it in Google and as you're in ec2 you can run it on OpenStack you can run it on a bunch of boxes that's under you under your desk or in the corridor or if you have a data center of your own you can really it's really really awesome before I delve into how it works and how you use it and how you can do amazing micro services on top of it I just want to mention a couple of the other open-source projects which are related there's a project called project atomic which is a Linux distribution is from some people at Red Hat Linux is really a bit of traditionally a bit of a monolith right if you up the Lib see all kinds of crazy stuff that could break anything right that's quite scary because almost every app dynamically links to Lib C so updating Linux he's kind of scary stuff right you wait you need a company to pay to help you do that kind of stuff but but what what's happening is a less risky way of doing that is saying well rather than just having this big monolith where everyone's sharing the same file system the ship shared libraries let's make a Linux that actually contains all the way down so project atomic is a new Linux kernel that's rolling into Red Hat Enterprise Linux which is basically almost everything in the operating system is in a container which means if you want to do update Lib C you can do it incrementally on a micro service by Microsoft's basis right start with system D first if you really want or whatever I'll start with your one app and update that and then up there something else that'll take something else so it gives you a completely micro service based operating system which is chemical plus atomic has Kuban it is baked in so from Red Hat kubernetes and docker apart operating system now right in OpenStack we've got darker and kubernetes backed in in in the infrastructure as a service level and also opened chef version 3 open chef these are platform as a service offering from Red Hat is an open source thing you can really on premise you commit on the cloud it was always based on Linux containers in version 3 that came out last year it's all docker all the way down but also it's Cuban 80s all the way down to so it's completely based on Cuban it is so version 3 of openshift is a platforms of service which is basically Cuban eighties so now you've got the option with Cuban eighties Google host communities online on the cloud there's something called so Google's cloud is GCE Google compute engine and then Google's content engine they thought down we've used the C what we're going to call it so they went GK as in care for kubernetes so gke is Google's complete container engine which is basically a hosted kubernetes that you can just bring your containers on so you don't need to worry about VMs and always kind of crap like infrastructures service is boring if you're a developer just don't even go there it's just the most boring tedious sysadmin you cannot right what you really want to do is write containers and run those things because that's fun that's making apps that's delivering customer value right stick to the apps and the containers go to the infrastructure that's a dark side that's operations right if you develop a stick to the containers so if you want to write containers on Google's cloud kubernetes or gke or you can run up and shift on Google's cloud or a zero or Amazon or you can release on your on your laptop at home okay so what is communities oh by the way here's the OpenShift version of the docker run and so rather than docker vernix or c which was for the OpenShift client so OC less less typing less typing OC run then you give it some kind of name and then you give it the image near the docker image name and then you do replicas equals five why doesn't have to be five you give me some number four replicas now this is basically like the previous example for docker run but there's a massive difference with this one command what this one command says is always run five instances of this container forever whatever happens right so if any of those processes die it starts another one if one of the hosts goes down that was running two of those it's that's two more on another box right this is like a cloud now is saying I always want to run five of these things please now I've got something more important to do and then you get on with your life right and so long as there's enough compute power in your cloud or in your cluster of humanity's Couponing it just makes that happen right now let me briefly explain how this works you don't need to really care about this to be honest you can just use it but here's a typical architecture diagram Cupid a DS has a kind of an API server master kind of thing that's highly available then has a bunch of nodes these nodes have a dock a demon on them to start and stop docker containers and it has a Cuban eighties daemon which we call the cubelet which runs on every machine and basic the master talks to the machines and says or machine seven you need to run this container now and it goes oh okay I think runs the container so it's a really simple model it's really small and lightweight if you want to boot up kubernetes using the open OpenShift distribution it's one binary you type up and open ship space start you've got a cube in each cluster right there right it's small it's simple if ever you've tried to run Cloud Foundry it's it's between 16 and 36 VMs I've yet to get the conclusive number but it's a lot of EMS right and it takes a lot of compute resource kubernetes is one binary right UNIX one docker demon one cubelet proxy and you're good to go so it's simple its small it's easy it's not that complicated right let me talk to you about cubed is now as a developer let's imagine you want to do some really cool cloud native apps and you want to use Cooper Nettie's and you're not sure if you're gonna be on premiere so you might be on Google or you might be on ec2 but you just want to write your app once and you want that HAP to run on Google and Allah as your and on ec2 and on your laptop right and you don't want to worry about easy to api's and you don't want to worry about info as a service because you've got better things to do with your life so these are the three subatomic particles you need to understand to use Kuban 80s now probably all well maybe all these the the meaning of these three terms might is probably new to you if you can get your head around these three things you can do awesome stuff on Google's on top of Google's container engine or on top of Cuban ETS on premise or on top of up and shift the first one is pods the second one is replication controls and third winning services so I'll do pods first okay now in docker we talk about containers and containers just a process that's kind of isolated cuban it is comes up with this concept called a pod now a parties a geek jerk because the docker logo is a whale and pod is a group of whales right so it's like a joke a pod means one or more containers basically so pod is one or more containers the idea behind the pod these parties the the atomic deployment unit the kubernetes will deploy so you define a pod and you say this part is my one image and then Cuba natives believe they deploy that pod I will tear it all down again it never leaves like half a pot around right so in the potty that deploys or or it gets deleted or redeployed right you can deploy more than one container in the pod now if you're a Java person you probably a pod these probably the same as a JVM right which is and that's cool and that's fine but you can collocate things you don't have to but it can sometimes be useful for example you might want to say oh I want to curl okay mmm cache d server with my tomcat so there's always on localhost and in-memory cache you know localhost away without any network ops so you some toys sometimes you want to have one container rather unix where you have different containers that do one thing really well you might have one thing that knows how to grab data from the internet somewhere and then another is a web server that serves it up so you might want to put two containers together that that together make a micro service but they're really two different processes but don't worry about the colocation thing if one pod is one container that's all totally cool a pod can have environment variables so you can override environment variables and you can you can define ports you can listen on ports and things like that and you can use something called persistent volumes because it might be you want to run a database and you kind of want to keep stick in that database usually so you want to put that state in the persistent volume which is outside of the docket image docket images usually are just like the installation of the software if you want to kind of store state what you tend to do is put that on a different volume so then the Steyr is independent from the installs and then you can upgrade the software to a new version and you don't have kind of this stay in the image and it gets all the bit weird plus typically when you run a container if you're not using persistent volumes and you kill the container you've just lost you state so you want to put state you don't want stateful app so you put that in a separate volume of system volume one other kind of weird thing APOD has its own unique IP address which it first seems a bit weird but if you've ever used docker on your laptop you soon get to really love the the neppy address thing if you run to Tomcats on your laptop it typically either you manually map all the ports in every container like 8080 and then deeper port and then they might report and then the other port so you can manually go well the 8080 is now gonna be 4080 or something so you can manually do that mapping or you can say docker just give me some numbers and then doctor will give you some random numbers and then you have to keep going to the second Tomcat it was forty nine thousand three hundred and what's its only two and then don't we like post-it notes everywhere of what the port numbers are and it's just horrible with kubernetes every pod gets its own IP address so all you need to worry about is the IP address and it's only the last bit of the IP just changes really and then you could use port 8080 on all of those pods so you can see I'm gonna talk port 8080 to all my Tomcats all you to worry about is the IP address we'll come back to that IP address thing is it's a crucial thing here's a replication controller now what a replication controller does is it controls the replicas in other words how is it's a terrible name I miss an issue against Cuban is please call it something else replication controller is a really lousy name but what the replication controller does is it defines a kind of part you want to run and then it defines how many you want to run and then it makes it happen so it's like a declarative thing where you say I want to run three of these please here's an example of a replication controller all the resources in kubernetes are just a blob of JSON or a blob of yam all you can get and set them over the REST API you can use a command line tool to get and set them and whatnot and there's a web web console to play with them and stuff here's an example this is this one is actually running elasticsearch you can see near the bottom image you can see the images elasticsearch that's the docker image name with a version in it right near the top you can see replicas one so that's going to run one content at any point in time if by accident you're in another container backs it will kill one of them so there's only one running at any point in time and if if you upgrade the replicas to seven it will run seven more so it's really really simple let me just show you an example of that so here's a web console I'm looking at some apps that's running here's the replication control as I'm running I'm running a bunch of stuff I'm running some Jenkins let me make it a little bit bigger there we go I'm running some Jenkins and run some Nexus and running all sorts of bits and bobs this fabricate let me filter on these labels let me just look at the console right now this is a this is the pod which is actually running the web console you're looking at right now so the web console is a docker container that's running this web app which is all static HTML and JavaScript this is the number of replicas we've said so if we say well let's try three replicas and if the demo gods are working yeah it is your pots got to three so now if we click on the number of pods we'll see we've now got actually three pots the IP address is just off the side of the screen there we go here's all the unique IP addresses and we can look inside the logs of either these the logs shouldn't be too interesting all it does is listen on the port that's not much there if you really want to get wacky you can open a console and look inside there's nothing enough to listen looking to root directory that's more interesting I can't move where anything is hosted in here bad news you can look inside the container and look inside the file system all that kind of stuff what's interesting is there's no SSH daemon or anything running inside the container docker has a mechanism for running a command inside of running container which is almost like you're shelling in but there's no excessive SS HD or anything like that you can just execute a command in a container which is kind of cool okay so that's replication controller if I go back to the controllers I can scale down again I can say oh I I did this in three I'm in one and it'll go bang and it will kill some any second now hopefully yeah we need you three anyways who needs so few containers I think I thought okay anyway now it should go down now moving swiftly on so sorry so obvious replicas are bigger than bigger than two yeah you're good to go ahead so replicas saw the replication controller does right you define a part in other words that what's the docker image what's the environment variables any persistent volumes or stuff like that you actually use this the selector thing you can give pods labels key value pairs to describe the kind of thing you want to run I'll come on to why those selectors are really useful in a minute when they talk about services let's talk about services now so imagine you're running five Tomcats so that's all kind of cool we've got five Tomcats and let's say we want to talk to those five Tomcats how do we know what the IP addresses are now we could keep querying the cupids REST API and say what are all the pods right now and find the IP addresses of them all and then we could do our own client-side load balancers but that's kind of boring we should be doing that kind of stuff infrastructure so couponing is has a thing called services which is a really lousy name because everything's kind of a service but kubernetes services our particular thing in Cuba ninties it's a blob of llamo if you see API version version one kind service that's the girl that's a service and you define a service you can give it a name and whatnot in the specification in the spec you give it the pot that the service is going to expose itself on which in this case it's HTTP so we're going to use port 80 which is seems a reasonable thing the target port is the internal port that we're going to talk to inside the containers which in this case happens to be nine thousand two hundred that's just what the elasticsearch happens to use for HTTP god knows why but that's just what he does and then it's got something called a selector the selector is the key value pairs we're gonna query the Pottsville to find the pons we need to talk to so one of the things communities does that but the board never did that Google was it uses labels to help you query pods now we can use this for lots of different things but you can query which pods you wish to talk to for a service for example we might want to do an a/b test and so we might want to run version 1 and version 2 of some software so we might put the version in available but we might for the service we might not want to care because we went with a low bouncer for version 1 and version 2 so you might want to have a service that only uses version 1 and you might want a service that only uses version 2 and then you might want a service that talks to all of them and the advances across them so using labels we can kind of query which pods you want to talk to and we can turn that into a service so basically using by defining the service in defining the labels we can define the service and then we talk to the service and the service and talks to the pods what the service actually does oh I'll come to in a second well this is what the service oh she does is it generates a unique IP address for the service for the lifetime of the service so there's one static IP address that you can use to talk to the service by talking to the service what really happens is you talk to something on communities called the queue proxy which every machine runs acute proxy so when you try talking to the service the queue proxy kicks in it uses IP tables to go ah you're talking a service aren't you the key property kicks in and a local load balancer on your machine where your service weather Canaries then load bounces and talks to the actual pods and that queue proxy monitors all the pods that match your selector so as the pods start and stop its dynamically changing the list of pods it will talk to so if I talking to the service you get dynamic and load balancing high availability and as pods start and stop the load balancer just automatically just does its thing which is really really awesome one more little detail kubernetes lets you define something called a readiness probe that says starting a container is fine but if it's like a JVM it might take you know 30 seconds maybe on a good day maybe even two minutes to startup right you have to initialize hibernate and you have to load loads of stuff and you have to wait for the JIT to get going and all kinds of stuff so you might want to define a readiness probe that says until I can query this happy page where all my message different beings are running all my EJ B's are set up and my web connect is actually serving HTTP until this happy page returns 200 don't include me in the load balancer please so this readiness probe gives you a trick that you can decide when to include a content in the load balancer another common one is I you might have a web app that needs to load loads of cache data in memory because it otherwise the responses will be too slow so you might want to warm you cache that on startup you fetch laws and laws are dealing from the database load up everything into the JVM it might take you 10 minutes to be ready oh well whatever so you can use a readiness probe to tell a load balancer only include my container when it's really really warmed up and ready so then your HTTP responses are fast so to the core long story so services are the way to load balance across pods it's really simple really elegant you just define a bit of metadata some key value pairs and and you're good to go a couple of other things about services though how many people have to use like spring or dependency injection and java re' stuff okay so one thing that's kind of start you wacky okay so think depends injection in your mind right and then imagine a polyglot version of that right that works in any language for any service you can use services it's like the Pennsy injection okay not immediate let me walk you through it so okay so a service can be internal right I can be talking to a service called cheese and that could be implemented by pods in my namespace it could be though that the service is in another new space it's influenced by another team and I maybe don't have access to that service because someone else runs it and they don't trust me to not break their service so they want to release somewhere else that I can't see so you can do something called service linking where the service I talked to it isn't actually in my local in space it's actually we point to where the service is remotely so you can define instead of using pod selectors you can do things called endpoints where you just describe where the endpoints are where the service is running which could be outside of Cuba nineties it could be in a different communities cluster it could be software as a service it could be an ec2 service or whatever and outside of your cluster or it could just be inside kubernetes in a different name space like a different logical user space so but you can have services that are internal and external to your system so there's a new pattern with kubernetes where if if you want to talk to services that your team doesn't make like imagine databases right you might be in a team writing a micro service that needs a cassandra or a Postgres or god forbid even an Oracle right but your team might not be the people that provision Oracle in the cloud you might have another team that one team that does Oracle one team it does Postgres in one team that does Cassandra right so what you might want to do is say well I want to talk to a Cassandra I'll define a service that says Cassandra or Postgres or Oracle or whatever but you don't specify an implementation you just make a service with no implementation then you call or email or as a ticket or whatever to the other team that does the database and they'll wire in an endpoint for you what's nice about this is you don't have to change your app which I'll talk about in a second you write your app once you talk to your service and then someone else can plug in an implementation later so services in Kuban it is a kind of like dependency injection you define the services for the things you need to talk to the micro services you depend on and then over the lifetime of your micro service you can change where that service is and you can do service linking a wiring and all sorts of other good stuff one of the kind of things services by default are internal so that IP address for the service is totally internal to the cluster so only other pods see that service by default right these are not global IP addresses by default you can define external load balancers to get from the outside of the cluster in like from a web browser whenever right so often you're Cuban its cluster is in a data center somewhere usually you can't just get in there with your web browser so you need to define an external a bouncer to get in from the outside if you define the type of load balancer of your service it's a typing in the yellow then Google's compute engine Google's container engine I apologize GK Google content engine will automatically create a public DNS name and a public IP address in a public little bouncer in OpenShift unfortunately that doesn't quite yet work so you have to type this one command line in OC Explorer service foo and then you get an external load balancer so both those two ways of how to make services external now one thing I should mention is how service discovery works so if you're writing a micro service and you need to talk to the foo bar service you give your services the name whatever you want to call it foo bar that services local to your namespace I shouldn't enter this Cuban a T's has a thing called namespaces namespaces are a way of taking a bunch of hardware putting a Cuban ities cluster on it and then logically splitting that cluster into user spaces if you like so if I'm in the James namespace I could disallow you all from seeing it right so I can just have my own namespace with my own stuff running and you all can see my stuff or more suitable you might have a production environment but only micro services that are running in production can see other micro services in production and the test micro services can't see the production micro services so namespaces gives you a way of kind of sealing an environment so you can't get out by default so within a namespace I just talked to foo dash bar and under the covers that the dns resolution of foo - man knows the namespace I mean and given a name space I mean resolves the service IP address for the service in my namespace so I can just in my code just use HTTP slash food - path that's it no postfix no dollar squiggly is no environment verbals no like weird stuff and just I can actually hard-coded strings to services now right which is kind of wacky it feels wrong as a Java guy that feels wrong we should we should have for config files and some dollar squiggle ease and some profiles that pick which magical dollar squiggly and the dollar squiggle it should all override each other in some really Java EE complicated kind of way and then J and E I should be a level of indirection to the Delos quickly and that but yeah you can just hard code things in cuban aids which is kind of awesome and so that works in yes it works in a Python Perl Ruby golang Swift Angela right you can just hard code everything again which is kind of cool so then your one app that's talking to foo - bar in testing will talk to the testing service in production will talk to the production service you don't have to have any magic config files that somebody has to magically edit when it goes from development testing to production right which is a really really awesome thing so services and service discovery is a thing of pure awesome it take quite a while for people to really realize how amazing and awesome this is what's even more amazing so we talked about docker and how amazing is the docker image can move from development testing production that's pretty awesome but what's even more awesome is your kubernetes manifest can also be immutable and move from development testing prediction in other words I can take a mo file of kubernetes and the docket image I'm running on my laptop with my Cuban is install and I know that that will work on production because it's the same llamo it's a same cuban that his method is the same cuban aids resources if I make a mistake in my llamo it will show up immediately because I'll miss type a service name I'll miss type environment verbal name I'll forget to do a secret or I have mention secret CI welcome to the movie or a volume or whatever in other words it's pretty clear and quick if anything goes wrong the only thing that could really mess up really as he moved from development to test the production is the thing I'm just about to talk about secrets and persistent volumes so what's a couple of other resources that communities does which you typically don't intimately too much about as developers writing applications this is a little bit more operation side you often need secrets secrets are things like locking and passwords SSH keys GPG keys tokens for web services and all those horrible security specs that keep changing all the time all that kind of rubbish you need security you need secrets to be able to access things securely right but what you don't want to do is put those secrets in your docket image so that the production login and password for your production database is then in your development environment the developer can do nasty things with so what you want to do is take the secrets out of your kubernetes Jason or Yama and out of your docket image and put it inside Cuban eighties in something called the secret vault so secrets are a place you put all that secret stuff which are specific to a namespace now what that means is in the testing you can just do things I always just generate like logging and passwords for everything we'll just we'll just automatically populate the secrets for the Roman testing cos who cares it's just a test environment but then in production your office people can preload the magic tokens and the magic login and passwords in prediction and you can have access control so that only certain people can see those secrets but the same time you can open up production if you so choose to let people have read-only access to see what the containers are actually doing so you can let people see what's actually happening in production but hide the secrets in a nice simple way so secrets are really really awesome environment variables are not a good place to put locking in passwords really because then you can look at those you can like you can type end on the shell and you can find out the password so yes service accounts is a way of adding roles to contain this because sometimes you want different containers that are allowed to do different things so you can restrict which roles are allowed in different environments through service accounts you might not need that but it's just one of those things you might need persistent volumes are absolutely key for stateful applications if you're writing like tomcat web apps you'll probably stay at less and you probably don't care about persistent volumes if you're provisioning a message broker or well a persistent message broker or a database or a stateful service that uses you know event sourcing or something you're gonna need for system volumes the persistent volumes in community support pretty much every persistent file system that's any real decency all the ones on the on you know EBS and s3 from ec2 all of googles persistent file volumes all of as you as person volume or volumes if you're on premise using like Red Hat stuff you've got a cinder from OpenStack and you've got cluster and Saif and NFS if you really want to go there and San and all sorts of other volume providers so it's easier to use real persistent engines for your disks and you just mount them into a volume and it's really simple a config map is a new thing I don't really have time to talk about it but come yeah definitely dove time to talk about a comfy map is a way of putting configuration into the environment so that you can change the configuration without having to hack your communities metadata two minutes crap okay right I better go really quick here's some command-line tools you can use to get and set things and there's keeping it easy ok cumulates really really awesome continuous delivery continuous delivery is the next step where you want to build your docker image you you want to take your Cuban sgsn and you in the movie from development to test the production now basically this is how you do macro services and kubernetes you write some code you put it you put it in a docker image you create some cuban aids manifest you apply the manifest environment say the test environment and then you do scaling and rolling upgrades and that kind of stuff and contused integration continuous delivery can automate everything apart from the writing some code right we can automate everything else on that slide and the fabricate project is a long story I don't have time to talk about too much but while the things we've been doing is continuous delivery on top of cuban ities canoes delivery is a bit like continuous integration but it's more about pipelines and long-running steps most people now do continue integration where you run a bunch of build steps before before you commit or maybe after you've commit continuous delivery it's more about you run long term longer pipelines like I wonder in a SERP test and a load test and the user acceptance test in parallel and then with a human approval if all of that works I'm going to move it to the staging environment and then with human approval I'm then going to move it to production so it's that kind of automating the flow of software through the environments you need for testing and then through into production or pre prediction the implementation continues delivery in fabricate uses something called Jenkins pipeline which is a new thing in Jenkins part of Jenkins 2-0 it was previously called Jenkins workflow plug-in just to confuse us all because there's not enough Jenkins plugins in the world so Jenkins pipeline is the Daddy right if ever you're thinking about doing anything seedy look at Jenkins pipeline right now it's called Jenkins workflow but Jake his pipeline is the official name for it basically what happens is you have a Jenkins file in your source code now and that defines your entire pipeline so all this stuff about having built gazillion build jobs for doing tests and code coverage and the integration test and citizen tests and all that kind of stuff you put all of your flow now in a single Jenkins file check it into your source control and Jenkins will now automatically create the builds ok crap I'm out of time Jenkins pipelines are awesome if if all you remember from today's talk is check out cuban 80s and try it it's a thing of pure awesome and look at the fabricator website to see the bits I should have done for the rest of this talk and use Jenkins pipeline for your CD of which there's an example it's a small goofy scripts groovy yeah yeah it's a small little groovy script to define your entire flow and we have an amazing console which I can't show you just yet for visualizing your entire continuous integration flow for example here's is staging and production and I can see the commits of each one and I'm waiting for an approval to go prediction and I can test each micro-service in each environment and I can see that they're different that one's returns that and then that will return something slightly different cuz the commits are different who isn't that amazing so we have an amazing console if ever you want to try it out on the fabricate website and you can literally watch your approvals I'm totally out of time I'm being very naughty I apologize so I've just done approval and now it's gonna it's doing a rolling upgrade you see it's good it's gonna start a new container of the new version and then the load balancer when it's green it's gonna kick in and that's gonna kill the old one so that's a rolling up few like Oh running upgrading that yeah result okay thank you thank you I'm here all day 