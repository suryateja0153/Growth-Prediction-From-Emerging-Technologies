 okay I think it's time to start welcome to this afternoon and I would like to introduce Chris Richardson give him a big hand yeah thank you it's great to see a roomful of people who are here to listen to my talk about how we live in somewhat of an event century sort of software world so there's really two goals for the talk one of them is just to describe how events play a very central role in our applications both as an application integration mechanism but also within events as well particularly within microcircuit echtua so sort of there should be a subtitle something to do with micro services for this talk and then I'm going to actually also talk about event sourcing which is a particular way of building event centric business logic which has a bunch of benefits and and fits really really well with the micro service architecture so those are the goals before I get into that a little bit about me so obviously Chris Richardson Ashley live in California got my start in programming back in the mid to late 80s building Lisp systems everything from run times with garbage collectors compilers all the way up to graphical user interfaces IDs and the like back when machines only had 8 Meg of memory that was quite a different world and then you know eventually I ended up programming in Java and then back in 2006 I wrote the book pojos in action which is all about how to build applications with spring and hibernate which is sort of very much revolutionized Enterprise Java development you know clearly spring continues to play a huge role within the enterprise java world and then back in 2007 I started tinkering around with Amazon ec2 which back then was an obscure service no very few people had heard about it I was running a jug and we had invite about an evangelist from Google to come speak about api's and he talked about the checkout API is and then the next month the Amazon guy shows up and we thought he was going to talk about api's for buying books but of course it was api's for provisioning servers which just made my head explode right you could get 20 servers for 10 cents an hour which ya just transformed the world really anyway ended up building an open source project that evolved into cloud foundry which was a startup for deploying a Java applications on Amazon ec2 so 11 clicks of the mouse you could upload a war file and have it deployed on an ec2 cluster and then that products got acquired by SpringSource just before Springs force was acquired by a VMware so that was back in 2009 and I spent a number of years there so doing doing various things left a couple of years ago and now I pretty much do everything related to micro so consulting and training around micro services helping organisations modernize their applications i've also a founder of startup and will we're building a platform that makes it easy for application developers to write micro services and got an event-driven architecture as the name suggests and we're looking for people to kick the tires and provide feedback so please go check it out a few more linked you know github I've got quite a few examples of event centric Mike the services applications I've got the website micro services dot IO which is a pattern language that can help you apply micro services my blog Twitter startup and so on so here's the agenda so I'm first going to talk about events on the outside so talk about how applications can exchange events as an integration mechanism and then I'm gonna go talk then I'm gonna talk about events on the inside and show how events play and important role in a micro service architecture and then describe how you can build event centric domain logic so actually build events right into the core of your business applications and talk a little bit about design issues and so on all right so let's get started so as I said first I'm going to talk about how applications can exchange events as part of the integration mechanism so big question to ask is well what's an event right so if you go to the dictionary you'll see various definitions parties social gathering so on but the one that's really relevant here is that is that it's something that's sort of important or notable that has happened right so something in a system has occurred that's worth telling the world about and if you think about it you know events there's sort of pretty much everywhere right so say when at a pharmacy the pharmacist fulfills of subscription a prescription I get a text message saying it's ready to pick up so inside the pharmacy of you know that business enterprise an event has happened and I get notified as a text message you know my airline regularly tells me that my flight is delayed right that's a pretty common occurrence especially with United Amazon you know when when my cookbook that I've ordered has shipped I I get notified I'll get a shipping confirmation and then UPS is going to tell me that the delivery has been scheduled and it's going to arrive so these are all notifications that I'm getting as an end-user that are based on events things that have happened within a with inside an organization inside some business application actually and then another intriguing example is instacart which is non line shopping application so you know I as a user I place an order a girl for groceries and then someone in the store is walking around picking items off the shelf putting them in their shop Carton then marking them as being purchased and when they do that I get notified in real time and I can see which items they've actually picked off the shelves and which ones they haven't found which ones they're still looking for and so on so you know some great examples of event sort of driven applications that kind of end up notifying me as an end user in the general case an event gets produced in a couple of situations one of them is the state of a business object changes write a prescription is fulfilled and order is shipped or so on but it also might an event might get generated when a business rule is violated so for attempted to you know an attempted violation so for example maybe my account has you know I I try and take out too much money and then it's good that debit is going to get rejected because my balance would go below zero and I'll guess and that will trigger an event even though the balance of my account is unchanged so systems produce events when either of these scenarios happen and then the question is what who consumes the event right so say in this case an order application generates an event to say that an order has been created that event could get consumed by an order served by a notification service which could send out emails or SMS Azure mobile pushes to notify the end user an event could also get consumed by another application that implements the next step of that business process so when an orders been placed maybe the shipping service gets notified because it's going to be responsible for actually shipping the order or maybe the event gets consumed by a dashboard right that's showing you know orders that have been produced today or as part of some monitoring application so one system produces events another application consumes those events yeah pretty basic stuff but it's sort of sin Schultz in most business applications so there's a few different ways within which a consumer can receive an event so for instance it could just poll right it could periodically make HTTP requests saying give me the next event give me the next event and so on a more elaborate approach which kind of builds upon that basic HTTP polling is the atom publishing protocol that just adds a whole bunch of structure to to the polling mechanism and has an interesting characteristic such that you basically get a sequence of JSON or XML documents that that each one contains a set of events and they're linked together and it's only the further head of that chain that's changing and the rest at the tail of that chain is that can actually be cached it can actually use the standard HTTP caching infrastructure so it can perform reasonably well but as you'd imagine it's sort of a fairly high latency somewhat inefficient mechanism you're just constantly opening HTTP connections to a server another option of course is to use WebSockets right well that's where a client typically a browser opens a long-lived connection to a server which can then push events down to the browser which can then update the UI and undoubtedly that's how instacart updates my view of the grocery list and it's quite common to layer other protocols on top of that so for instance if you're building a spring boot application a spring just bring framework application in general you can actually use WebSockets with with the stomp protocol layered on top of it and that gives you that's a protocol that lets you subscribe to various destinations and then you get message frames back another option is the whole web hook mechanism so that of course is user-defined callbacks right so that's where it consumer registers and HT registers a URL with the service saying when any of these particular types of events get produced execute an HTTP POST to this URL and then the service will periodically post to that URL and that's kind of a nice sort of low latency way of just pushing events out to to a consumer and that of course is used quite widely throughout the web many web services or websites actually let you support some notion of web hooks right so get you know with which wolf from github that we're pretty familiar with lets you register a web hook so say when someone commits a change to a repository that github will do an HTTP POST to a URL which could kick off a build or some other downstream process another example of web hooks is Twilio which is telephony as a service SAS offering telephony and SMS so basically that would Twilio you your application can make and receive phone calls and teton mate and send and receive Technic text messages so whenever you register a phone number with Twilio you actually specify a couple of web hooks an SMS URL that's invoked whenever a text message arrives and a voice URL that gets invoked whenever there's an incoming phone call so when either either of those two things happen right someone cools that phone number Twilio that will then make an HTTP request to your application saying there's a text message there's a phone call and then the the application can send back an HTTP response with Twilio ml sort of markup language document that tells Twilio how to respond to the SMS or how to respond to the voice course service a voice call that will detect the speech and so on so it's a great example of sort of the power of web hooks as an integration mechanism there are also some integration hub products I think IFTTT is probably the most right that's been around for quite a while and then there's another one I discovered some sort of last year was EPO and what's interesting about those is that they let you tie applications together so when an event occurs in one application which might and it might detect that event by either pooling or by using a web hook it will then invoke an action in some other application so you basically set up these rules that say when this trigger occurs which could be like you'd favorite a tweet or someone signs up on a website using some form collection service it will perform some other action and I have used that a few times to do some basic application integration and it works quite well okay so web hooks if you think about it it's really just kind of the web version of publish/subscribe right it's sort of a particularly webby HTTP based sort of version of a more abstract notion about publish/subscribe which occurs within just messaging systems in general and of course the classic definition or book about enterprise integration patterns using messaging is the book by Gregor hope a that defines a whole collection of patterns for for doing message based integration and abstractly it looks like this right where a sender a producer sends a message over a channel that resides within some kind of messaging system and then that message will get delivered to the consumer gets delivered to a recipient so so this is sort of the behind the firewall type of message based integration that you'd use and there's lots of examples of message systems right rabbitmq activemq sort of the classic ones that have been around for a while Apache Kafka is one of those you know new things that super hot within Silicon Valley you know developed at LinkedIn and they all created just a humongous scale and it's sort of a backbone of their of their business and then there's another one that gets that appears to be getting some traction nsq as well so you end up with a sort of model that looks like this whereas behind the firewall you've got applications that are integrated using some kind of message broker and then outside the firewall you have other applications so these could be third party ecosystem business partner applications or just sort of regular end-user applications that are integrated using web hooks or web sockets or atom pub and so on so that that's sort of kind of a quick view of just events on the outside of applications so it's really just an integration mechanism so I want to now kind of dig into what what do events look like on the inside and interestingly it ends if you dig into one of these modern applications it kind of looks like application each one of each each app each of the applications is really comprised of many applications or both services or micro services that are actually exchanging events in kind of the same way that applications of changing events so it's kind of somewhat of a fractal picture in many ways and the reason for this is you know if we think about the traditional way of building applications it's the the monolithic architecture right and I talked about this yesterday morning in my tutorial you know you might have a logically modular application lots of layers modules and so on but the standard approach to deployment is to package it up as a war file or an ear file and run it on some kind of application server and on the one hand this works really really well for small to medium sized applications you know monolithic applications are simple to develop and test Eston deploy in scale for instance our tools are pretty much oriented around building the application for example you know if that's a IntelliJ or eclipse the problem you run into is that applications have a habit of growing right you know you just have a team of people who are working away for years and years and years and applications just get bigger and bigger and bigger and looking successful applications will just live a very long time and will just keep growing but you end up with what I call monolithic hell where your application becomes too big it's too unmanageable and anything agile becomes impossible right making changes becomes extremely difficult there's just too much code for anyone to keep inside their head and for that reason the microservice architecture is becoming increasingly popular right where you actually functionally decompose your what would otherwise be a monolith and you just have a collection of smaller standalone applications or services so that's yeah so that's kind of the modern way of building large complex applications well these the ideal way for in many cases but there's an interesting feature of these applications is that each service will have its own database and the reason for that is you really want these services to be loosely coupled so that you can what do as much development as possible in parallel and as soon as my Christine as two services share a database than their couple it requires a conversation between all of the people who are using that database to actually make a change to any of those tables and that that can really really slow you down so it's very much a best practice for each service to have its own database so that sounds good but as soon as you start partitioning your databases you run into distributed data management problems and it's also compounded by the fact that we're increasingly using no sequel databases so you end up with sort of this polyglot architecture where not only are there multiple databases but you're using different types of databases as well elastic search for text search MongoDB Cassandra and so on all within the same application so create some really really interesting distributed data management problem so imagine that you're dealing with customer you've got a business application and it's got a customer service that's responsible for customers and you've got an order service that's responsible for orders right maybe the order service is using in those sequel database so if you think about transactions within a no sequel database they tend to be very limited you no longer have an asset programming model you can at most update one row or one document within that database and there's absolutely no notion of two-phase commit spanning multiple databases most no sequel databases don't support it and even if they did you probably wouldn't want to use two-phase commit any way so it's sort of a bad idea yeah at the same time you often need to have business transactions that sort of span multiple databases in order to maintain invariants right so the example I like to use is cout is this customer and order example where customers have a credit limit and there's a business rule that says that order outstanding order total cannot exceed the customer credit limit so this means that when you're about to create a new order you have to check that that order will not exceed the credit limit so if this was if he--if orders and customers were within the same relational database that would be a reasonably straightforward thing to do there's some tricky issues around isolation levels and so on but assuming you had serializable transit actions you could easily begin a transaction check the credit limit in certain order commit the transaction but if we're using micro services then orders and customers end up in different databases and it's sort of like how on earth do we implement transactions that span both databases so the approach that that's preferred these days is to you know to stay away from two-phase commit for a whole bunch of reasons and actually use an event-driven architecture and so the idea of course is that when something changes in one application sorry in one service when it updates something it publishes an event another service can subscribe to that event an update its own state which might then trigger other events and so you end up with these event-driven eventually consistent workflows and in a minute I'll show you how you could implement a credit check using that approach but you end up with an architecture that an application architecture that looks like this where you have a collection of services that are exchanging messages via some kind of messaging infrastructure and it looks at you know at a higher level that's what our applications look like so it's very fractal so going back to customers and orders here's how you could implement a reliable credit check mechanism so a request comes in to create the order it actually creates an order order ID four five six seven with a total of three four three and you can see that it's in the created state and then the order service then publishes an order created event so it's sort of announcing to the world I've created an order the customer management service consumes that order and it does the credit check so you can see that cus the customer object has a credit limit attribute saying customers credit limit is twelve thousand dollars and the credit reservations attribute that's really am that's a map from order ID to order total so that's the the reservations of credit against the credit limit so it can do the credit check and just it will record the fact that order four five six seven has reserved three hundred and forty three dollars and then it can publish an event to say the credit has been reserved which can get consumed by the order service which can then update the state of the order to open which in other words that this order has been has undergone a credit check and it's been approved the customer service could actually publish credit check failed event which would then get consumed by order management which would then cancel the order and send a notification to the user so you can sort of see how you know we're using a multi-step event-driven approach to achieve eventual consistency and you can imagine expanding this may be in addition to performing a credit check it could also reserve inventory as well and perhaps perform you know various other functions and the order would actually consume both the inventory reservations and the credit reservations event and wouldn't and then when it receives both of them could then say yes the order has been accepted or rejected and so on so that that's the general approach and companies like eBay have have used something like this for a number of years in order to maintain consistency across multiple databases but there's a couple of interesting problems with this approach why is you know how do you design business logic that works this way right it's a very different style of programming to the regular acid programming model that we're used to and and I'm going to talk more about that later and then the other problem you have is how do you atomically update the database so insert an order and publish an event right we need to actually do two things atomically because if we inserted an order and then failed before publishing the event our system would be in an inconsistent state and ironically the standard solution to interacting with both the database and a message broker would be to use two-phase commit right you'd sort of imagine using JMS and JDBC and they'd enroll both of them in a distributed transaction however for various reasons two-phase commit is really not an option in modern applications because of things like the cap theorem because of the fact that many modern pieces of infrastructure don't actually support two-phase commit so sort of the standard approach is really just not something that we can use in our modern web scale applications so the solution that I've kind of come up I've sort of settled on is actually to use event sourcing and you know anyone here actually using event sourcing so yeah so I mean event sourcing has been around for quite a number of years I sort of view it as like you know you got the domain driven design community in the event sourcing community is a little group a little subset within that and has always been super super interesting to me but more of a curiosity but then when I started doing work with micro services I suddenly realized that it solved some really really relevant interesting challenging problems and then looking back it would have solved some problems that I was facing dealing with no sequel architectures as well so I kind of once I had this realization I've sort of become quite quite a fan of using it so the big idea around event sourcing is that this is sort of a slight miss characterization of it is that rather than update the database and publish an event which is difficult to do atomically it just one thing it basically publishes an event so that that's a that's slightly inaccurate but it's some level it's like this and the idea the way you end up using event sourcing is for each business entity or in domain-driven design terms and aggregate you identify all of the important events or domain events for that aggregate there's actually a technique known as event storming that people have talked about quite recently and most of these events will correspond to state changes of that business actor of that aggregate but they could also correspond to attempted business rule violations like a credit check failing for example so you identify event and then you are then in your domain model you define classes for those events so the events become first-class citizens inside your domain model so shopping car that would be item added removed order placed those would be events for an order it would be created canceled approved rejected ships and so on so you know for any entity you can it's fairly straightforward so identify the event so that in itself is sort of no big deal right in a sense that's just better modeling important but not doesn't not earth-shattering but then what what event sourcing is all about is rather than persist the current state of a business entity so for an order you wouldn't normally have an order table in that and a given order would correspond to a row within that table you don't actually do that you don't store the current state of a business entity and instead what you do is you store the sequence of events or the state changing events for that entity so you could think of your entire data store of just having one table the event table and it just stores events for all of the different types of entities in your system so an order would be say be represented by an order created event then it would get then there would be an order approved event you could imagine other lifecycle events and eventually it would be an order shipped event maybe later on there would be the order returned event or RMA issued and then the order would be returned and so on so you just store the events that are corresponding to the you know various state changes of that business entity and when you actually whenever you need the current state of an entity you load the event and we play them to reconstruct the current state and it's very tends to be very very straightforward to do that and of course you might be wondering well if I think about a bank account that's been open for 10 years and it's got an awful lot of debits and credits replaying all of those debits and credits to reconstruct the current balance would actually be very efficient inefficient and you'd be right so the solution there is to periodically take snapshots of the current state of the entity and then when when you want when you need its current state you find the most recent snapshot and and then load the events that have occurred since that snapshot which is you know likely to be just a very few so that's how you can make this efficient for very long-lived entities and if you're functionally oriented you can think of reconstructing the current state of a business entity is basically doing a functional fold over those events so what's really interesting of this is that it kind of has yet another layer of sort of fractal ability so before we had applications exchanging events and then when you looked inside an application it consisted of services exchanging events and what events sourcing does that add another level to that where a service consists of aggregates the exchange events so it's sort of just through at least three levels of sort of entities that are exchanging event and in reality it's actually the events that are coming out of the aggregates that are actually filtering all the way up and being sent to other applications so at the aggregate level you can think of an aggregate as this thing that takes a command and response a request to do something like go create an order cancel an order approve an order etc and then it actually emits events in response to that that command and the event are both used to persist the state of that order but also to notify other aggregates and other consumers that something notable has happened so an order aggregate emits an order created event a customer aggregate can subscribe to that event and do a really perform a reserve credit command which then kind of so this sort of a mapping from event to command which then emits another event which can get consumed by it which then gets consumed by the order it turns into a command that updates the order which emits more event so there's kind of commands to events and events back into commands then you know if you look at how a particular request is handled so imagine there's a request coming in to update a particular order first thing you have to do is go load the events for that order you would instantiate a sort of a blank order by using its default constructor you would then replay those events to reconstruct its current state you'd process the command which came from the HTTP request which would give you new events you'd apply those events to the order to update it and then you would save those new events in the event store so you'd find some events and then eventually add new events you're just constantly appending lists or constantly appending events to the list of events for that entity and you would do that with an optimistic locking check so if there were two concurrent requests for the same order then the first one that saved would succeed and then the second one would get an optimistic locking failure and you then just loop around and we try and that sort of a standard thing that we should do all the time in our applications so that that's kind of how request gets handled and then what's really interesting is other micro services can subscribe to those events and when they get saved into in the datastore the subscriber gets notified saying here's an order created event for example or an order cancelled event etc and then the this consuming micro service can then update its own aggregate which can then trigger other events other consumers might process those events and say update a materialized view which a bunch of reasons I don't have time to go into it's very useful in the system to support queries efficiently it might also send out notifications so maybe it invokes Twilio to send out a text message or send grid to send out an email for it for example so when business when you when you update an aggregated event gets saved then the events can get consumed which can trigger the updates of other aggregates trigger the updates of materialized views or turn into notifications that get sent to an end user so quite a lot of there's a lot of use for these events so the events store itself is sort of half database half message broker so it's a database in the sense that it has an API for inserting events for an entity retrieving events for an entity and then it's a message broker because it has a subscription API that lets subscribers consume events that they're interested in there's a few different ways of implementing an event store you know I've talked with people who have just built their own on top of Postgres greg young who's been pioneering event sourcing and is off in the.net land has his own event store so if you go to cool event store so if you go to get event store calm and then that's part of the platform that I'm working on as well so if you you know look at the benefits of event sourcing there's quite a few so you know what got me excited about it is that it solves the data consistency issues in my sequel and no sequel architectures right I can write these event-driven eventually consistent business transactions fairly straightforwardly also event sourcing is a very reliable way of publishing notifications whenever state changes right so you can feed these events into predictive analytics you could you could use those events to send notifications to users because that's an increasingly important part of what applications do event sourcing is also quite interesting because it eliminates sort of the age-old problem of object relational mapping you know we've constantly been struggling with how do you take your complex object model a map it to a very flat very simple relational schema well the nice thing about event sourcing is you're not persisting your domain objects you're just persisting events which tends to have a much simpler much more easy to serialize structure so you tend just to be able to represent them as Jason for example and so he kind of by generally part bypassed the object relational mapping problem and then another really interesting benefit which can be which is really important depending on the domain is the fact that every state change of your business object is actually becomes an event that gets persisted so that has an um two benefits it means that you've got a hundred percent reliable audit logging the event convert record can record who did what when and because you can't change state without an event is guaranteed to be accurate so that's you know hugely important if your what you know for instance you're working in some domain that's heavily regulated and it's really really essential to know who did what when and that's quite different from the traditional approach of doing auditing which is where you kind of bolted on to the application as an afterthought and it can easily get out of sync and then another really important benefit is because you're actually saving the entire history of every business entity and what that gives you the capability to go back in time and see what the state of it was some time in the past once again the standard approach would actually be to bolt on history so you get this built in so that's pretty important and then also you're preserving the history of everything that has happened within the system which means that you could actually implement a feature today pass through it all of the events that have occurred since the beginning of time in that system and it it's basically behaving as if you had implemented that teacher in the past so he was like you've almost got a time machine which is really which is a really intriguing idea so there are some downsides of course right you know it requires an application rewrite it's a different style of coding but then that ties were ties in well with migrating to micro-services you know it's definitely a learning curve is a different style of writing business logic compared with acid programming events once they're written never go away so in theory you could make some bad design decisions and have to live with them kind of forever also because it's a messaging based system you have to be prepared to deal with duplicate events that tends to be fairly straightforward either you have item code and event handlers or you or you just keep track of the last scene ident event and discard the older ones and then another problem you can run into is sometimes querying the event store can be challenging right if you want to know the accounts whose balance is greater than $5,000 and more Eve God is a bunch of events that would be kind of that would be quite a complex sequel query to write it assuming your event store used sequel other event stores like the one I'm working on only actually gives you primary key based lookup of your entities so that means that you end up having to use command query responsibility segregation and maintain denormalized views of your data so it's a complication but for the most part it tends to work quite well so I want to talk really briefly in the remaining time about how domain driven design fits into this so I think I got my copy of the DDD book back in 2003 which seems like a lifetime ago right really is a must-read book and one of the really entry are interesting things about DDD is that it gives you a set of building blocks so I entity value objects services posit trees and then there was this thing called aggregates which at the time I just thought was kind of an interesting idea but it really did not resonate it turns out that domain-driven design and micro services go hand in hand really really well so we've got kind of a modern idea of microservices with this relatively ancient domain-driven design technique and they they worked well in aggregates end up being a central part of domain driven design in micro services so what's an aggregate so an aggregate really is a little graph of objects with a root so it can it tends to correspond to business entities like customers and orders and products and so on but there's some rules and one of the rules is references to other aggregates can only be in terms of a primary key so you no longer have object references between aggregates which in traditional object-oriented design would actually be a code smell but it that has a really important benefit that I'll talk about in a minute also an aggregate might actually contain copies of data from the wreck from an aggregate that it's referencing so an order line item might actually have the product name and price and the reason this is useful is that if you think about a standard domain model it everything tends to point to everything else right which if you want to modularize it and put different domain objects on different services that that really isn't straightforward so the idea with this what aggregates do though is basically make your give you a frame modular domain model that's comprised of these loosely connected little clusters of objects so in order no longer has a pointer to a customer it just has the customer ID an order line item no longer has a reference to a product or an object reference it just has a product ID which means I can just go put an order in an order service a customer in a customer service and a product in a product service and there's no weird object relationships that I have to manage which is really important and then another idea is with aggregates is that which I really did not understand the point of at the time is that a transaction corresponds to the update of one aggregate which back then was like well I can update anything I want I can begin a transaction update five different business objects and commit the transaction and it just works but if you think about the technical constraints that we're living in of the world we're living in today where we have no sequel databases that have very limited transaction semantics when we actually have we've broken up her application into micro services and we can't have transactions that span multiple micro-services this notion that you have an aggregate that a transaction is the update of exactly one aggregate fits in really really well with the concept of no sequel or the limitations of no sequel and the concept of microservices right so we can just like you know if we think about the transaction scope is within a service it just Y service contains an aggregate and then a request updates one aggregate and it works really well I mean we do need to think about aggregate granularity because you know if we do need sort of atomicity that has to happen with inside a single aggregate and we just sort of have to think about well how do we chunk up how do we break up or domain model we could make everything in a single aggregate talk to someone who did that didn't work but in theory you could a customer and their orders could be an aggregate that's not entirely under me the ball and product would be another aggregate but it tends to be better to have finer grained aggregates provided it just sort of you know fits within the constraints so kind of just threw a lot at you that you know domain events kind of big part of this right so they're just sort of simple value objects with kind of metadata and and some essential attributes the ReWalk required by the aggregates you might actually throw other attributes in there to make it easier for the consumers you know here's an example there's lots of boilerplate because it's Java this would just be one line of Scala code commands these are created from requests processed by aggregates once again their value objects so they sort of look like that and a lot of boilerplate because of all the getters and stuff and if you go look at my examples there's various different styles from sort of a traditional Java mutable object oriented domain object approach to that couple of different flavors of functional domain objects that are immutable the Java one kind of looks like this where you've got process methods that take commands and give you event you have apply methods that take an event and do an in-place update of the aggregate and it's really just taking a method that's sort of doing business logic VAT or validation and state changes and splitting it into a process method that does validation verification gives you an event which is then processed by a second method so it's sort of a different style of coding but it's really just sort of slicing it's slicing up your existing business logic in a slightly different way and then the remaining minute kind of want to show you an example of an application that's built like this so actually this is a really boring screenshot of it BAM board demo that I've been working on so standard board and you can drag tasks around but what's interesting about it is that it's sort of multi-user collaborative and events are used to actually update the browsers of everyone who's viewing a particular Kanban board architectural it looks like this right so there's an angularjs client that uses the REST API exposed by the Kanban application behind in the background there's the event store where the event sourced advocates for boards and tasks live the Kanban server uses WebSockets to push events coming out of the event store whenever a board or a task is created or updated pushes those events over WebSockets to the browser and then there's also a MongoDB database that's maintaining some denormalized views of the data for easier query and here's a simple video that sort of shows how it works is that if it's running it's that actually going oh yeah it's really so I'm actually like creating a board I've got two browsers here and what's really cool is the bottom one is actually just getting via WebSockets getting events that are coming out of the event store and then it's like I create a task you can't see it because the backlog is down here but then when I drag stuff around you can see that it's updating and kind of reasonable real-time so this is like from you know events are going from the application running on my laptop all the way to a server that's running an AWS in Northern California and back again and then another little benefit is that because the for a given task you have all of the event history you can just show that to you the user you get sort of the audit logging of you changed what and when so hopefully that kind of gives you a flavor of the style of applications you can build so in summary right events is central to modern applications using the integrate applications they maintain consistency in across microservices in these modern micro service applications and then I'm a big fan of using events or saying to build events into the core business logic of your application so hope that you found this useful here's all my contact info you know follow me on twitter and send me e-mail and check out micro services dot io so i hope that you found this useful thank you for listening all right any questions Jessica could you comment on how to how this scale on the organizational level how do you keep track of all of these events do you have any tools or do you use Excel files how do you keep track of them yeah I mean that's a really good question I could imagine least having a wiki for doing that and yeah I could have one of the things that I've been exploring is using for instance json schema to actually define the structure of events so i could imagine for instance having a git repository that's that's has the definitions for all of these events yeah how do you deal with updates because one of the biggest problems I see you with that the structure is that business evolves and then you will have to introduce new events that since we didn't have before then there's a different mismatch when rebuilding it aggregate isn't it oh yeah that's a really great question I mean that whole evolution of events thing is and I suppose it's quite a complex topic I mean there's at least two two parts to the answer so one is often you're just adding you're making backwards compatible changes to the events right so then the consumers of the events which include the aggregate just have to be smart enough to default any missing attributes right so that's one thing then if you want then if you're making backwards compatible or incompatible changes you're basically adding events and so either say an aggregate has to be risque pible of processing both the old and the new version of that event or at the sort of events store framework level there's there's a mapping that happens that translates from the old event into the newer event so that the aggregate only ever sees the the new event so that I mean I think in the event sourcing world they're fairly established solutions to that problem yeah I wonder if you have these lot of services producing events on an event pass on different services can subscribe turn doesn't that lead to that it's difficult to sort of predict what will happen if you change the service that generates event because you don't really know who will consume it now what they will do about it that's yeah so I would sort of have you think about what is the API of array service right in a traditional sort of sense the API is really just a REST API and we'd use swagger for that right so now basically the API of a service is also the events that it publishes and you just that that ends up becoming an interface versioning issue at that point okay I think you have to stop there thank you very much give a big hand for you 