 deep below the surface of the cloud there is a hidden world of our applications one without fear of vendor local cabbies roam freely lager gaiters lurk a DA consistory this is the journey to the center of the cloud sound three prepare yourself as a team into the deepest darkness please do not feed them so yeah thank you very much for joining us this morning so my name is Alex Leigh I'm a product manager for pivotal in London I'm gonna be one of the guys on your journey and I met King I work on the garden team also in London so just to set expectations that was our entire production budget for this talk completely gone so you know stay if you want to so this all started when we found this map we're in the National History Museum in London and we were just going through some old books and it turned out we found a map that takes you right around the Cloud Foundry going through the center of the Cloud Foundry so you can see that we're gonna be starting up in the top left at the CLI Beach and then we're going to be going past the UAA through the cloud controller across the CC bridge we're gonna check out Diego Island here there's a nice garden there we're gonna check also look at the root alligator and the blobstore now take us right back to the beach so the start of our journey we're going to be using the CLI so what's the end line interface so this is a primary way that you interact with Cloud Foundry and so has the commands for both users and operators and we're gonna use this to guide our journey and so you can see here that the CLI has a plug-in interface as well so you can extend the CLI with plugins there's quite a good marketplace for these with community and Cloud Foundry repositories so what do we first need to do on our journey we first need to log in and authenticate with the system and so you're going to see a lot of this from our talk we'll be jumping up to the CLI to see what the user would be seen as we're going through our journey and so you can see here that we need to target our selected platform and here we're just going to pivot all's public cloud foundry and then you need to authenticate so there's two ways you can do this the username and password as usual or you can use SSO so we do this to a component I could use the authentication user account an authentication service and so this is the primary authentication system you'll see used across most cloud boundaries and the CLI receives the UA information from the from a component with the cloud controller which we're gonna take a look at next and this performs kind of an OAuth dance and so it's based on a auth - and it can back onto LDAP SC I am and open ID and this is actually built as a spring MVC scalable web app it's one of the only Java components left in Cloud Foundry at the moment quite rare so so let's just take a look at this workflow it's quite straightforward so we'll send a login request from the CLI to the cloud controller we get back the UA details of where to authenticate against then we can send an authorization request to the UA a and we get back an access token right so now we're authenticated we really need an application so we're going to be using a spring music example app and so you can see here it's a groovy application we specify a manifest it's pretty straightforward and say we're gonna be using this to guide us through our journey so let's take a look we want to have a manifest to describe what the application needs to look like when it's running in Cloud Foundry so you can see we give a name we give it how much memory we need and we also specify how many instances we want running so in this case we're saying we want three instances of our app running and we're using this feature as well to have a random route so that we avoid like collisions because we need a way to access our application and so this is going to our Cloud Foundry to find a unique name to run our app as so now we need to get ready to push this into Cloud Foundry so as most people I guess everyone here must have run CF push right yeah good okay so you're very familiar with this command and so what we're going to be doing is when we run CF push it creates a record in the cloud controller database and the cloud controller will then keep track of your application and record this is the desired state so let's take a look back at the map so you can see we've gone through through got past the UA a we're onto a cloud controller which is on Kathy land and so let's take a look at a bit more detail about the cloud controller cloud controller so this component is the core entry point and it provides a set of restful api s these api's are used by app developers and operators and it's really a huge amount of endpoints you can see that's going under a big rewrite at the moment going to a v3 API the cloud controller also interfaces with your external services and it uses a broker API specification to do this so right next we need to get a way to access the application so we need a route so you can see here that you know Cloud Foundry is generated a nicely named random route and so how does your application then get messages to it so we use a routine release this routine release contains a collection components you can see here we've got a go Rooter and a TCP Rooter so this supports HTTP and TCP routing and you can see on the right hand side we've got the route emitters and these will be sending information to the rooters to make make them aware of your application ok so this component is uses it's like it offers HTTP routine for Cloud Foundry effectively and it uses a component you can see in the middle called Nats to advertise its availability and so consumers have to put messages onto Nats to register with the go Rooter periodically otherwise the go Rooter will prune it from its routing tables and then you know assume that your application is offline and this stops people from getting you know you know errors when trying to reach your application and it uses simple round-robin load balancing so next up we've got the TCP Rooter so this is you know for TCP based apps you've given a reserved port and route on a shared domain you can see that actually uses haitch a proxy inside and so this offers us a way to kind of move away from the Nats message bus and move towards a routing API so the rooty api is currently an experimental stage and you can check it out there's lots of good Doc's on the on the repo as well but this uses the publish/subscribe model but over HTTP so this allows us yeah like I said to move away from that but works in the same way where stale routes are pruned from the routing tables and so you can get started really easily by using this RTR client you can see the link there at the bottom so now we have our you know kind of application registered with Cloud Foundry we've got our route but next we need to upload the files right so you can see here that we're uploading all of the files in the directory and we're going to be passing these through to the cloud controller so the cloud controller obviously needs somewhere to store these files so in Cloud Foundry you know we normally attach a blob store dare you enter the mob store Caverns so yeah this effectively is where we store all of your application files and so it has three main concepts you've got resources app packages and droplets resources the files they're uploaded to the cloud controller and we track a unique sha you then have app packages and these are unstaged files that represent an application and finally you have droplets and this is a result of taking all of those files and getting them running ready to run on Cloud Foundry and so you might have seen a talk yesterday about the bit service and so this is underway to kind of extract the blobstore logic from the cloud controller so let's take a look at what the kind of workflow is for uploading an app so you can see to start with from the CLI we will send a resource map request to the cloud controller this will then go to the blob store and check for this unique chars so what you're saying is you're sending a list of all the shards for your files and you get back your matches and then based on the difference you're going to be uploading the changes or new files to cloud controller and this puts it into the blob store so it's quite straightforward so next up we need to start looking at how we're going to get our application because we've just pushed the raw source code and so we need a ways to turn this into something that runs in Cloud Foundry and so you can see here from the CL ice perspective you'll be seeing an output of this bill PACs downloading bill PACs downloading bill PACs and so what is this you might think so this is how we take your application code and build it into something that can run on the platform so you can see here bill packs really allow you to have a repeatable process for compiling and running your code on Cloud Foundry it means the platform can worry about the operational concerns especially on the underlying operating system and you just get to focus on your code so again we have a three step process for bill PACs to start with you have the detect phase so Cloud Foundry will run every bill PACs detects script until it finds a match when it's found a matching bill PAC it will then go through a compile phase where it grabs your dependencies compiles them into an artifact and then the release phase is when it gets it ready to be extracted into a droplet which we're going to a bit more later so here's an example of how we've you know running a Java app and so you can see that we pushed has been detected as Java and then we've downloaded the dependencies and packaged it up ready for extraction to run on Cloud Foundry all right thank you very much Alex okay so let's just briefly recap our journey so far so far we have created an app we have created a route for that app and we've also uploaded all of the source code into Cloud Foundry so what happens next well in order to answer that question let's just take a step back and think about exactly what it is that Cloud Foundry is going to do when it receives our application pushes and really Cloud Foundry has two key responsibilities the first responsibility is to take our application source code and compile that down into some artifacts that can then be scheduled to run on the platform and that's exactly the second responsibility we need to take the output of that build compile process and actually schedule it to run and ensure that it continues to run until we tell it to stop and then of course there are also all of the traversable responsibilities such as logging metrics etc etc so what exactly does this look like inside Cloud Foundry well the first process that compile process is known as staging and staging looks like this first of all we take our application source code we then combine that together with a build pack which as Alex said provides the runtime dependencies and we compile that together into some artifacts but in order to actually do this we need to have somewhere to actually run that compile step we need to have a root filesystem or or an operating system and in Cloud Foundry terminology this root filesystem is known as a stack and every deployment of Cloud Foundry will come with a default stack typically this tends to be a bun too but it could just as easily it would be something else as well and so what happens is we create a container using that stack that default stack as the root filesystem for this process once we've got these three components together we then run the compile step and we output a droplet so this is the immutable artifact that we can actually scheduled to run on our Cloud Foundry platform so what does that actually look like well next up we create ourselves another container and this container is based on the exact same stack that we use to actually compile the artifact in the first place this is how we can guarantee that it's going to run successfully and how it has all of its dependencies available so we create a new container and we simply copy the droplet into the container and we say start start running and this is really really nice because we've got a very very clear separation here between the developers who are responsible for creating the source code and the droplet and the operators who are responsible for the underlying file system it's a very clear contract and this approach to running your applications is really nice because it means that things like scaling is also very very easy here is a typical scale command in cloud foundry the - either scale it up to eight instances what does this look like well rather than creating one container we create eight and then all we need to do is copy our droplet on to each of those containers and tell them all to start very very nice and simple model there and I think that's one of the reasons the Cloud Foundry is really excelling at this nd running the applications here okay so we've got an idea of what exactly Cloud Foundry is trying to do when we push our applications how exactly does it do this and in order to answer that we are going to need to cross over the CC bridge and into Diego Island Oh hail Diego just making sure you're all still awake and sir okay so what is Diego well Diego is the component of cloud foundry that actually provides that staging and runtime support at its core Diego is a scheduler and it's able to schedule two types of workload tasks and LR peas and I'm going to touch on those in just a moment but one of the other features Diego provides is it can take all of the incoming workload and optimally distribute it across a cluster of cell components so a Diego task this is a workload that is guaranteed to be run at most once so this is perfectly suited to the staging process as we only really ever want that to happen once or at least once per push of your code another example there might be a one-off database migration for example a Diego lrp on the other hand these stand for long-running processes and this is what your applications are actually going to end up running as with under indeed in the Diego cluster so Diego provides some additional features here it is able to distribute the lrp instances across your cluster of cells and this is nice because it means if we lose one of the cells for whatever reason perhaps the virtual machine crashes or all goes away and your application can still continue to run as other instances of the P will be distributed to other cells and it also provides us with some fairly nice fairly nice health checking so if your application instance crashes for whatever reason perhaps it runs out of memory delia can't detect that and automatically restart it ok so we now know what staging is and we know what Diego is how exactly does Diego stage our applications well first off the cloud controller sends a request into the stage' and the stage' sits there listens for these requests and converts them into a Diego task in this case it's going to be a staging task it then sends that off to a component called the BBS the BBS stands for the bulletin board service and this is really Diego's cool Orchestrator and sort of the central data store of our cluster so the BBS receives this staging task and it persists it to its database this currently backed by at CD so at this point Diego knows that there is a staging task that it needs to work that it needs to perform but it doesn't know where it can actually perform that so we have an entire cluster of cells available to us at the moment any one of which might be suitable for running this workload how do we determine which cells ascend it to well in order to solve this Diego kicks off an auction process so the BBS will go and send out a request to the auctioneer and the auctioneer is in constant communication with the cluster of cells via a component called the rep which I think is the representative of this cell and so the auctioneer says okay we have this staging task one of you needs to go and perform it and it asks all of the cells to make a bid on that workload and the one with the highest bid is then assigned that that that workload so once we've decided the BBS sends off the request to the appropriate cell at which point the executor will create us a garden container and then this is where the actual process gets executed and I'm going to talk a little bit about garden in just a moment but also worth mentioning here that the executor will also be streaming the standard out and the standard error of that process into a component called Metron which alex is going to talk about in just a moment as well okay so at this point the staging task is now complete and as I mentioned earlier the output of that process is the droplet so we now need to take that droplet and put it back in the cloud controller so that we can schedule it to run and this is fairly simple the executor simply sends off a request to the CC uploader which is responsible for mediating that upload great so that's responsibility number one done we have now completed the staging process and we have this droplet which we want to schedule to run in our cluster how do we do that well there is another component here called NSYNC and NSYNC sits there listening for the desired app requests and it will convert those into El RPS which will it will then send off to the BBS so obviously we don't want our apps to run as a task because we want them to continue running until we tell them to stop and then again the a very similar process happens where the BBS persists it to the database kicks off an auction finds the cells it's actually going to run those that that application on streams or the logs off to met from another component worth mentioning here is the TPS and this is responsible for providing the Cloud Controller with information about the currently running LRP instances and it will also be monitoring activity for any crashes and reporting that information back to the Cloud Controller finally here there's one last component the converger and the converter is responsible for ensuring that everything becomes eventually consistent and it will take action to ensure that that is the case so for example if it detects that one of our lrp instances is missing it can go and kick off another auction to ensure that we bring that back into focus so that the desired State it's always equal to the actual state all right perfect so hopefully now I've described both of those processes the staging and the running and showing you how that actually works inside Diego there's one other component that I'd like to talk about and that is garden so full disclosure I do work on the garden team so I'm going to be speaking very favorably about it but I think with good reason let let me show you why welcome to the garden that's the last one I promise okay so garden garden is plowed Foundry's container technology and the first question people tend to ask with regards to containers and Cloud Foundry is can I run my docker image in cloud foundry and the answer is yes absolutely you can but as well as that garden allows us to run the build pack based applications as I've just described so what exactly does garden look like well at the top level we have the garden API and the API provides the functions such as create container destroy container etc etc and that API is implemented by multiple and pluggable backends and there are currently three main backends let's take a look at those the first one is garden Linux as the name suggests this is the Linux implementation of the garden API and this was essentially a rewrite of the warden container technology which which was induced in previous versions of Cloud Foundry prior to Diego and that's actually where the name garden sort of originated as we rewrote warden in go and then it was go warden which kind of sounds like garden I guess anyway this is what's currently running in most production plant factory deployments next up we have garden windows so this brings a long net and windows support into Cloud Foundry but perhaps most excitingly of all we have garden run see what is run sea run sea is a project that's being worked on by the open container initiative so the open container initiative is a body who are looking at defining standards around containers and this is really really exciting for a number of reasons so first on it means that the containers running inside Cloud Foundry are going to be running according to standards set by some independent body the body is part of the Linux Foundation and so that's that's fairly nice we have those standards there it also means that the containers running on Cloud Foundry will be using the exact same code base as containers running with docker and this is great because it means that things like compatibility is going to be much better and also with a lot more eyes on the codebase things like security issues are going to surface somewhat too quick surface much quicker and be easier to fix as well and so this is nearly ready I think it's currently going through the Diego CI pipelines hopefully we will be able to ship it fairly soon and once we do this is going to replace garden Linux as sort of the default back-end for cloud foundry okay so we've seen now our application is running in Cloud Foundry and so from the outside we need to access the application so let's take a look at the workflow here so we first send a request in and that will hit end up hitting the go Rooter while the go Rooter is working out what to do is continually being updated by the route emitter of where to find that application so you can see here we've got two Diego cells and then so the Rooter needs to know where to forward this request onto so once it gets the information from the root emitter continually it will be looking to forward this request first you know the first request will go to cell 1 the second request you go to cell 2 so this is just a nice straightforward workflow very similar for TCP routing as well so also my apps running but we won't really see what's happening because Cloud Foundry can be a bit of a black box you know you've just pushed a code and now you've got your app running in the container you know deep nested inside Diego so to do this from the outside we can use CF locks so you can see here we've issued a logs command and we're connected and tailing any logs that get emitted from our application so this is awesome you get a stream you know almost like a live stream of information coming from your app really useful for debugging and so what how is this you know being achieved so ed mentioned earlier we have a component called labra Gator and this is comprised of two main concepts so we've got dopplers and dopplers are there for collecting all of this information and then we have the traffic controller which is used to push this information so there's a few concepts in here that we might have seen throughout the presentation so the sources in this case will be your application the Metron agents are what is going to be connecting to dopler and you know sending your logs and metrics and events you then have the traffic controller which kind of collects this information and produces what's called a fire hose this fire hose can then be connected to and it's a massive information that's coming out of Cloud Foundry and so this is with one of the components it's under the most stress in the system because you can imagine you have thousands of applications running loads of system components all emitting information to this you know one component set and so you can you know see this has some real scalability challenges so let's take a look at you know how do we collect these logs so you have the Diego cells running the Metron agents you know so you could be emitting out logs or metrics metrics are normally from the system components these are then collected and pushed into traffic controller and then traffic controller creates the fires so now from the CLI how do we see these logs right because the logs are flow through the system into the and they ended up a traffic controller so we send a request for the application details and we get back you know everything we need to be able to connect to the traffic controller so we send off a request to the traffic controller which is using WebSockets so you can see here we head up an endpoint that's like slash tail and then you pass your out good and then so you establish a WebSocket connection and then you get back at blocks ok so that kind of concludes our journey we're just recapping it we've touched on you a a cloud controller we visited Kathy land across the sea sea bridge kind of looked at the staging and running processes in Cloud Foundry had a walk through the garden and then we came back out looking at the router and logger Gator so yes thanks for joining us yeah yes [Applause] 