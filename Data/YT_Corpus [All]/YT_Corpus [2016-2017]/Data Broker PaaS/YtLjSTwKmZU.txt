 lights okay okay thanks for coming my name is Dwayne Phillippe worked for Giga spaces technologies and we have a product called claw defy that's in open-source orchestrator for cloud platforms and others and I'm going to be describing the some of the challenges and solutions for orchestrating multiple platforms simultaneously with the same orchestrator how this can be done in a specific example described a real-world effort for orchestrating Coover Nettie's along with micro services on Coover Nettie's as well as having those services interact with external components that are outside of coover Nettie's so in a single description so i think historically this is a this is a good idea for our a good way of explaining exactly the value of orchestration and the kind of problems that can solve that are non-trivial so so we'll be automating not just kuber Nettie's but will also be throwing in MongoDB in there will be deploying a micro service and wiring it all up and then scaling it okay so here's our target architecture for those aren't familiar with Cooper Nettie's its container orchestration system so in this case cloud afya will be acting for Cooper Nettie's as a orchestrator of orchestrators to a certain extent so again the the goal of the overall project is hybrid orchestration so where I have multiple platforms I'm orchestrating so in this case we see whoops hang on see the the master and the minions so basically the worker and the Masters here mongodb outside and then the micro service we can scale Cooper Nettie's itself easily with the workflow we could also scale the micro service externally with the orchestrator now that it's kind of hard to looking at that diagram to understand the complexity of the the process that you need to do and the need for an Orchestrator but this is a partial list of the steps required to do the orchestration a lot of it involves the coordination between different parts it's it also involves setting up the network properly and modeling actually the services in and outside of Coober Nettie's in this case will be we're not trying to usurp the the the job of coover Nettie's and orchestrating containers were merely commanding hoover Nettie's from the external side so among other things will be creating dynamically creating templates of coover Nettie's deployment descriptors pushing those into Cooper Nettie's properly parameterised so that they can recognize the services that are outside Coover Nettie's in addition to that claw defy provides the ability to auto scale based on arbitrary metrics that flow into the system so part of the part of the orchestration is a an auto scaling workflow so automating that is a lot of work anybody who's set up Cooper Nettie's itself has discovered that it's a lot of work on its own I'm having this all in an easily reproducible blueprint and highly valuable to make for repeatable deployable environments you know that are bulletproof in addition making a making them cloud neutral is difficult so in this example we're running everything on OpenStack but we have Cooper Nettie's on OpenStack we have Luongo DB on OpenStack so we're only using the OpenStack api's but the way the modeling language works and clarify the the clouds are pluggable so there's the core orchestration doesn't have to change so in order to understand clarify a little better you have to have a basic understanding of Tosca so Tosca is an oasis specification it models deployments says graphs of nodes essentially nodes and relationships and a node can be anything that you need to orchestrate that would include network components software components virtual components hardware components anything else it's essentially code at the root level okay nodes are implemented via type system to avoid boilerplate so you can create for example in our orchestration it uses an OpenStack node that's based on a lower level node that has some basic interfaces and operations that are common across all target platforms and then everything is connected by relationships and among other things the relationships let the orchestrator know the order criticality of the different parts and what order they need to be started and how they need to be connected so for example in this standard sort of Tosca view we would have all these would be considered nodes in the the OpenStack world a floating IP a network a subnet an application the vm itself and so forth ok the orchestrator can interpret this model and deploy it in the most efficient way possible so once you have the model you can actually run a workflows on it pretty much nothing happens without workflows that's the execution model the models ultimately point actual code that can be run in distributed fashion across the clusters or on the server itself for example a server node for OpenStack what define operations need to inova Neutron and so forth so what we need to do for cuva Nettie's and this project was defined a type for Coover nutty's there's some obvious types in Coober Nettie's a master node which is basically to controller in the minion node and so forth and there's going to be code associated with each of those it's going to actually activate the api's on either so in general you would define operations on these to install and configure cooper Nettie's itself probably in a and the done properly we would delegate this step to a sem tool like salt puppet danceable shelf etc etc in this case not so it's just Python but so is also custom types for mongodb CFG manga less actually in this example I have I only have a d running but it's not important just for the example define operations on these to install and configure again that can be completely delegated to a CM tool ok so we model it out here we want to essentially have a micro service that runs in the master the master we contain in a master vm the nodes and the Cougar Nettie's sense running the node vm ok and then when we scale we can scale the node vm and the code so we can scale hoover Nettie's dynamically when we want to scale the micro service we can scale this alright see and that's what it looks like on a larger scale so we'll just for simplicity sake this model assumes a flat network we don't have any anything tricky with routing or anything alright so a standard workflow will essentially walks the model as I described earlier for the installation recognizes well-known end points that described operations related to installation like configure install start and so forth and those ultimately either trigger custom code that you write or chef cookbooks or puppet manifests or whatever you have note the VMS are independent so when this is traversed they will all be instantiated in parallel so when the when the orchestrator gets done these all finish and then the orchestrator is ready for the next level of dependency it's going to march down to the master node this is installing the actual Coover Nettie's code on each of those and then that's that now here's what the actual international descriptor looks like so in this case for OpenStack you'll note that the master host has a type which is a OpenStack server has some probably familiar properties you know such as flavor and image it also has some relationships define so ultimately these relationships are actually executable code when they fire during the install process it actually triggers OpenStack api's to do the proper connections for example created the connect security group okay and this is just an example security group definition nothing particularly tricky there it looks pretty much like what you'd expect now here's a special Cooper Nettie's micro service type an example of how that would be implemented so it's got it's very very simple it's got a a base type up here but the main thing is it's got some basic some basic properties here that need to be filled in the image to run the port for the service the target port to the map essentially all of these values are going to get substituted into the actual coover Nettie's descriptor before it put for replication controller in the Cooper Nettie's descriptor before it gets deployed and then here we see the interfaces for the behavior so this is just an example of how arbitrary code is tied to life cycle events for example up here these are actually pointers to Python packages it's actually running and exposing the Cooper nutty service here and another life cycle stop event might trigger a delete these are all standard interfaces for cloud afire okay I already won over that let's go we're running out of time this is an example of the implementation another about the micro service type here essentially one of the ways to configure the custom microservice type is to specify an external service definition file and then just define overrides and that's what going on here so this is the way that information from outside of coover Nettie's can be injected into the service launched so that it knows for example the micro service in this case is a is the old node seller application this is how we actually feed it the MongoDB port IDs and other information it needs in addition to this the lucubra Nettie's pod that's created will have metrics gathering which will eventually find its way back to the the claw defy server this is the Cooper Nettie's native description so this is essentially what we're over writing at runtime okay and like I said the I'll just skip over this is only have time anyway we as part of the the pod we we insert Diamond D collectors Diamond D and injects metrics into a rabid mq and the claw defy server from which various workflows can be triggered including auto scaling auto healing and so forth so take aways Tosca makes complex orchestrations more understandable it hides the cloud api's completely behind type definitions it's an Orchestrator can render a Tosca blueprint on any infrastructure so it's not living it's not limited to clouds any kind of virtual and from any virtual infrastructure cloud infrastructure or physical infrastructure it doesn't really matter and then it's an Orchestrator that can coordinate other orchestrators essentially it can orchestrate pretty much anything this is what the claw defy server looks like and ignoring here which is basically related to the rest api we have elastic search for the database rabbitmq at the heart which is where all the events are being fed into really all of the executions we have a celery task broker which is doing all of the remote executions for us asynchronously influx DB is storing a time-series database of collected metrics and Riemann is doing the real-time event processing to trigger automatic scaling so having said that actually started it up before this let's take a look at it or are we on here alright so oh that's good this is the claw defy you I so each of these the way the way this deployment was are these deployments where architected was to separate them so the meaning of this K here the blueprint this is Cooper Nettie's okay here's the base the graphical representation of that relationship the master being inside the master host the Cooper Nettie's is just a more of a graphical separation there it doesn't have any real meaning to it the minion host there's a representations of security groups and the networks if we want to look at the sources up it's too slow error browsing great so let's look at okay manga d is very simple it's just a host with and this is the hybrid service okay in hearing you get the idea and the hybrid service is essentially reaching out to the other deployments they all have a completely distinct life cycle they can come as go as they please this connects a node seller to the Cooper Nettie's proxy so if we were to look at how this is actually actually let's look at the let's make sure it's actually running here okay so this is the the actual application let's launch this is running in a micro service in coover Nettie's it's hitting the database described in there let me let's look at the cooper Nettie's side say so here on this is a Cooper Nettie's master node on here we can see we can actually see the the pod running with the the node seller a pin at the diamond D collector in there the events flowing back to the server where am I out here that's weird very long okay I'll never mind that we won't look at that just have to take my word for it the events are flowing back into the into the Riemann real time event processing if we want to run workflows I can actually come here that's interesting I lost it and I lost that ok nevermind so now one of the things that this kind of high-level orchestration lets you do is embed this capability of doing advanced orchestration inside of another basically a front-end that abstracts the cloud platforms so this is a this is a product by a partner of ours miss Taio that has a potential management sort of a unified management view across multiple multiple clouds and what they do is allow the implement the deployment of templates for example here's Cooper Nettie's encore OS and so forth lets you target any cloud independently so you cannot just offer that up as a as a service that's easily consumable this this product built on top of clarify and takes care of all the automation on the back end and then they take care of all the sweetener on the front end I guess we go to know we have zero minutes any questions though nope thank you you 