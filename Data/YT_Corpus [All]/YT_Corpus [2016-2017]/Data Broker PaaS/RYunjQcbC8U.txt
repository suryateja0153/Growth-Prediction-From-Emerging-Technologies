 also from Red Hot and working on Neutron and we would like to to thank you first for coming and and we're going to talk about how to debug failures and how to use this little tool called auto lock merger to to hopefully help you in solve your problems well some of them we all know that the distributed systems have complex interactions and in the case of OpenStack this is certainly true this is not a picture to scare people this is an actual diagram of the architecture the basic architecture of the different open stand components on how they talk what to want to another which is clearly complex for example let's see this complexity into something that we do every day which is request an instance so you could make a request in your dashboard or through the CLI the so you could get good connect two kissed on to get the authentication then it could make the request the Nova API nobody i could confirm with kissed on that the authentication is correct then it could go to the database to check that whatever you've requested is right so it can proceed it makes the request today a message broker places they in the queue the request it goes to the scheduler the scheduler does check again in the database and creates the intrusiveness ooh and then makes another request through the q2 a compute node that also access the database well through the conductor and then we start interacting with other components like like Lance Neutron cinder and then in those interactions we have some gum come on goes like I send umsha wait or I i expect you through to call me back and inside each of those component we also have complex flows so even something as common as getting on instances quite complex is not a simple operation so this and this is not even taken into account if you deploy things in a cluster where you could get your request or to your H a proxy it can go to any of the of your servers and then be delivered to one or more of your agent ok this is not that difficult to follow ok you can follow it and then when we get there the response they can go to another server because there's willing it doesn't really matter but it's it's it's getting harder to follow your your request paths with this and then you get a different request from the same flow and it goes through another server because it's balanced so this if you're trying to actually find which problem do you have this is getting a lot measure Monsieur to you to follow as we said OpenStack is complex it has a large number of component a those components have complex interaction between one another but also a complex it closed inside of them in on top of that we have a lot of configuration options that could go wrong and we have a lot of deployment possibilities so we could have different backends different hypervisors net were right agents it's complicated so when you're trying to determine the root cause analysis of any problem you have you know for a fact that most cases are non-trivial you may be lucky and it's something easy to find but it's usually not because otherwise you would have probably done it correctly from the start and requires a lot of knowledge of the inside if you're trying to do lock crawling through the different pieces you have the different component the different services you actually have to know where they are going next to be able to see where you want to follow that request if you would usually have this centralize all your locks so it usually it's easy to do but in many many cases you don't have your lock centralized you have them independently and maybe you just have a proof of concept you're testing so they are not centralized you but you're testing it you want to make sure everything is right something's wrong you have to go and check and you start opening files log files trying to follow where the calls are coming and going and like we said you would have to jump through a lot of different files so first quick introduction this is the OpenStack default format it can be changed but it's not very common to change it the most important part right here is the date and time because what we are trying to do is go from separate files that you have your logs to something with an alias that will order them correctly and good also let you know from which file those blocks came from so you can specifically go there and check for anything if you need to so this makes this would make it easier to to follow them and to follow the older requests and that's where always lock merger comes in it was born out of frustration of trying to actually debug complex scenarios with a che active active and how everything interacted and mostly in it has been tested for production but also where cases where you only receive the logs the log files you receive a bunch of log files from a customer and you're like okay there are a lot of note there are a lot of logs and you start trying to crawl through them jump from one to another trying to figure out where the problem is and then follow the path so this tool it's simple tool it will not solve all your problem but hopefully it will help you make it easier to to follow the the logs the functionality currently has is it allows to merge OpenStack format file log files a VAR log messages and then Delta logs like DMS it can get files locally and from URL if you get it from a URL it will catch the data for example if you're trying to to debug something that has failed on the CI gate you could get the files the idea of the machine it is in case you first only retrieve a couple of of logs you think that the problem is only in cinder you only retweet cinder logs and then you realize that you need more logs because it apparently the problems is with interaction with Nova so you don't have to and you increase you add those to your to the call to always lock merger and and you don't need to retrieve all the files again alias definition that is how we will be identifying each of the long edge is can be done manually you specify you give a specific alias you can you can use the the file name directly or it can generate automatically the names as it sees fit trying to make them consist small and easy to read it supports multi log entry and it can run for speed or or reduce memory footprint which takes slightly longer to too short the the files so installation you can stall it from PI pi you can install it directly from master or if you're in a customer environment where you don't have virtual mm you don't have pip you have basically almost nothing you can directly download the file and just run it let's see I use case you have this structure someone had send you a bunch of a tar file with this structure and you just you have no two not three and you just want to browse this in a sequential order you just need to make the call to lock merger here okay thus a three means that it's going to do auto Alison to the best to make it as short as possible the ML option will change the is to specify VAR log messages files then we specify delta time file and finally the log files as you can see it's using blob to include all the nodes and from all the nodes the different components we are interested in and this could create something like this where the date is the timestamp is preserved with an alter it so it's get it's easier to locate in the arena file it needed so and then you get the alias that is has been reduced from the from the directories in in this case it has only kept the the number of the note because the note was common in all of them the note part of the path customer has been removed as well and we see the alias with cinder API a quantum agent cinder scheduler sinner volume etc and they could all be in order so it makes it easier to filter what's in the file to follow request through through all your logs and everything now we can see an easy example of merging files from the gate where we are actually specifying the alias manually we define our base for all the files like all files are going to be here in this URL that's the base we define the extension the postfix of those files and then you define the path within that a base and the colon and they are alias so this could get those files merge them to with with those specific aliases this is where the caching would be useful if you certainly wanted to add a new file because you see that you're missing some interactions and now we are jumping to the fun part which is actually using this for something and we're going to see how you can do it so I'm jumping into a little live demo Michael is always tell me please don do live demos but I like so I hope it's a reasonable size of use this is an example of how to leverage these two to go through that kind of lock mace in indicate if you are a developer and you submitted a patch and you are drawing to the Borg a multi-node a multi-node failure you can use this this is I think this is the reveal number and where you can you can get that from the review output so it will run this in this case the HTTP requests are cached locally so it's now it's processing all the logs to to put them together and and and you get you get everything in a single law the compute node messages they open be sweet messages and so you can go straight to the place where you are finding the issue or or correlate to your specific block failure and then maybe the request number you could fill their by the request number for example and and see what happened I across the service across the services I don't want to go in the details of that log because it was a mess but yeah if before this I remember sessions of having an editor with five open windows and jumping through logs and it was horrible so okay after that I'm going to explain how how can we put this together with uncivil to to travel for for travel suiting so it's we can do this in an automated way if you have a deployment that it that is experiencing a failure on you know how to reproduce that and you can try it on the staging environment or give it to our customers because you are providing support for that deployment you can automate the whole thing and get get the results find what's happening but also you can leverage that to to make sure that if you are trying a bug fix it's it's really working and you can do it automatically so basically in this small mythology that i'm going to give here we uncivil to to orchestrate a manipulation of the host accepting debug restarting services to take the backlash introducing drops in in the system to to augment the information that we have for example pinging from one side of the network to another or to a fault in IP of an instance or getting the arp tables in certain nodes or more complex stuff that I ain't going to so later and yeah and finally when we reproduce the issue we grab the logs from from the different hosts we put them together in the way that we find more reasonable for our debugging purposes and that's it so I will go quickly through this I don't want to go too much into the details you will have the link up to the presentation later but basically this is very simple ansible do we use it to to configure the debug the debug flag on the on the nodes in this case for Neutron and nova because we were looking at inova Neutron issue during live migration so the next thing is doing a simple hack to rotate the rocks so we start fresh fresh on the logs and good rest are the services to make sure that they pick up the debug flag and that they start with the new log file and the same for the for the compute nodes basically yeah these clear that clears the logs restart the specific services the police battalion and then over compute and then in this was to to reproduce the issue that do we were trying to debug it was a a light migration from one node to another and there was a hidden race condition between Nova and neutral Nova was in at the time Noah was starting the BM before the underlying network was configured so the BN was starting and sending an Edward announcement of reverse ARP packet saying I'm here so the network topology will discover that new place for the instance and reconfigure everything but since the network was not properly configured the that notification that packet got nowhere so that the final result was that the BM apparently was taking like one minute or two minutes due to to be available again on the network regardless of being active and apparently working so once we finish the reproduce in the issue we just fetch the logs locally to the due to our host with the synchronize action and the the final step is getting a merge in a single one and looking for your problem so when one of the the internet and the interesting things that you can do to do get a more meaningful more meaningful information especially in the network context where things can be very complicated sometimes is introducing profs like i say as i said bingers or something to dump the flows of the open be sweet Ned probe which is a helper with we have recently introducer with it will explain and or anything that you want as long as it uses the OpenStack log format and you can put them together and I will show you a very simple three lines example of how to do that with with anything on your system so we introduce these this small tool it's again it's an a standalone one by one python file so it doesn't have any dependencies and you can upload it to any host as long as you have Python and and in this case TCP dump is going to work for you it watches the network main spaces and and the network interfaces in in the host with where you started and when it finds non patterns like router interface from neutron or a an instance tap device or RDH to be part is going to start logging the the control traffic on that interface get all the messages from all the TCP dumps that it's starting into a single log and write it to a file so in the end it will write something like this like in this case it found an interface in a DHCP a space namespace it's logging it and then the packets will look like this if they didn't fit in the screen so I cut them but basically an any packet will so here in the in the tcpdump format and you have the interface name here and those are them the default settings like which kind of interfaces it's going to look for but you can configure them in the command line and the default tcpdump filter like i'm logging the most control traffic for dhcp ICMP or ICMP six and her p in writing everything to the place but you can you have the common line and you can modify those parameters here here here so you can make it work for you and this is a very simple example of how to how to grab something in your system that you want monitored together with all the other logs that you are getting so it's just a matter of putting your your command here or a function that loops doing whatever and then applying that these this small rubber tool to open the I mean to prevent the the OpenStack clock for month so yeah this is this is an example of how to how to upload this net probe to the system and start it I make sure that i'll delete please my abilities are very low prolly there's how much better way of doing that but it works it's just an example of yeah killing any old crop that you have in the system copy in the net probs crib and starting it so you will have the logs available Indian you have links here to do some of the design to some examples i'm going to show you how it looks to to use an uncivilized cryptonic wanna deployment is a single no deployment so because my laptop will then take much more but let's go turn all in one and the black holding one and I think that that sit yeah I in this one it first I clean up all the resources that i already had on the system before setting the debug flag and reserved in services it waits for the resources to be properly clean up now it's restarting the services with the backlog took at them also writing in a new log file and yeah that copied and i started this network prob that i was talking about and now it's creating like two networks two routers to be ms and waiting for them to to come on by i'm actually looking into their into the net prop blog to find that the HTTP request so until I don't get sore now needs to be replaced and ICM be a world load that I said on the BMS so on the right on c day icmp I done I keep waiting so in the end it finish it it retrieve all the other log files locally I have them here and so happier all the logs that there is BM hat and finally the the logs after going through log murder if I look for example for a boot be request sorry going to chop the lines if I look for the boot p request we can see that right after a lower compute bounce the instance and starts prison resumes starts the distance we can see the instant of requesting the HTTP this is the the instant stop this is the router getting the candidates the P request what is not able to one this is the bhc be a giant board getting the request and this is the dhcp again responding to the to the request with the instance IP address the point three in this in this case this is the sense getting it so after a while we are going to see these distance looking for the router address like it says in worries what's the mac address of my router the router response sign here and that happens because they stance is trying to get there to do a meter data request so we can see that after finding the router addresses is doing the meter the request we see the new drama data service and that goes to neutron that also goes to to nova at some point and we can it we can follow that the whole thing if i do i feel director much what yes that was the incense asking for a limiter the requests from through the whole chain it has to do to the router it has to go to the new drama data service to nova and many many things happen so so that was it would what's missing on on on this project we want to do move it to to the stack fault because now we are not good hub maybe get all the other contributor other contributors i started and vodka join me because he found it interesting we also want to add maybe some more filtering up options make it this year to use with the gate mainly because we are developers and we find it useful we also want to make like a and a small uncivil generator like that it could be able to discover the the host that you have and maybe by looking at the neutron audience or maybe by looking at your under cloud if you are using triple o or something like that and also provide more props this is a network prob maybe some we we are open to ideas and also may be making a version for the gate because in the gate as developers we have like AB like a log viewer that works in JavaScript but it's only able to under one dollar and may be equal to have to have it handled several of them and that's it if you have any questions feedback ideas so please go to the microphones and thank you for coming hey so working yeah we're just wondering about you mentioned briefly about centralized logging I'm curious how this would work with you know doing everything centralized I've been trying to work on a project with it's very complex with five controllers and a VIP and everything is everything is a che it's very very big but it's a huge mess and so it's very very difficult to to get merged logs that are useful without having to you know manually dig through every single thing well the idea here this is for when you don't have centralized log did you have centralized via L or we are now flew in D or any other mechanism this is not really useful but yeah this is something also that we wanted to look at because yeah this is a first step for when you don't have any centralized log you looking at things like yeah but yeah right something that I want to look at is being able to integrate with that kind of centralized log systems to do queries like okay maybe I want this now there's no disservice to service the service and in this time frame and get something meaningful I get maybe keine I don't know if I separate to based on this or or maybe come online for that yeah but I think what you were asking is if we have a solution to the merging of your locks in your environment dynamically like life right or well something like that would be more like elk stack or something yeah right but I was thinking just being able to dig through programmatically and would be useful I mean once you have everything merged and you're using something like ELQ stock that's kind of out of the scope of this Yeah right but something that would be able to probe through you know right when you have an error right when you're having issues or something would be really useful to to to jump directly to that specific part German multiple to track down once you find a request ID for instance and be able to dig through the whole stack and find where you know where this failed that type of a scenario all right yeah but that I think they're there are some efforts working on that on root cause analysis trying to determine from an error why that happened and but I really don't know the specific or at what stage their art but I know they are working on that things slide if your database fails and and everything starts failing to do not report the small log errors just report that the database is down it's also they are also trying to do root cause analysis by detecting the arrow and determining where it's coming from but now they start at this point what is useful is the mechanism to to pass the request from one surface to another that we have so you can actually have a common request where I don't know if it's completely implemented but there is a mechanism to friend when nova called cinder for example to pass they are the original request that you can in logs follow it follow them easier so you don't have to actually do it manually like okay here Nova made the call let's see which call appears in cinder at that time so we I know there are efforts I don't know if they've completed the work because they were quite yeah yeah there are places to go because they're there it wasn't a cc as we all originally thought like okay you make you just need to add arena request yeah but we have Forks we have so when you actually start looking into it it's a lot more complex but you can be out at three of course yeah yeah but there I think that I for would probably be easier more helpful to actually locate because it's you locate their another or do you know the arena request you filter but I request on all your locks and if you use something like this like merch everything unfiltered by the arena request because all the requests from that crew will have it then you have a sequential order of events that are easier to follow I think I hope we have no excuse me I have a question isn't there any spirit in capability hope splitting low splitting output and even if we have a capability of split in the log for example pas par decreased or yeah if you yeah no not yet that that's one of the things that I also wanted to look at place during the law the final yes I mean because we usually just filter it for example if you're with less you just filter you has been a very big filter in the viewer like me I'll probably here for a second generally when I when I do this I open I open it with less and if I want to see the neutron services I can do this and that's going to give me all the neutron services or if I want them if I want the Nova for example now happy and maybe this is not there okay I'll but you just we use the reason why we didn't implement it at the beginning the filtering is because we usually do the filtering with less or whichever editorial using us build a query of your of your filter there for example if you want to request a specific request you say filter by request and if you also want to include a specific note do you use the pipe and you add more stuff that you want to filter by and then you only view that the view is only that but it is something we are considering yes I didn't filters to actually okay so you need okay my question is kind of you know just related to the previous gentleman and him is you know we have a cloud which is really huge we have distributed services and tools like this really helped because you know you want to aggregate all the logs but the challenge that I face is even you know so first thing is you have to figure out where the request is going so if I'm making a volume create right like it can fall on one of the cinder you know controllers basic ascender dm's essentially which we are running the second thing is and that was coming to the filtering right simple filtering does not help at least in my case which I've seen as if I'm just doing a simple grep or you know trying to figure out so let's I create a volume and I find the volume fail you know you try to look at the logs and try to search for the volume ID right in the logs to filter but you know the logs when some error happens usually you see you know let's say a request is sent right you would see a call request but then you know it misses all the part because sometimes not the whole log has the you know you idea of the volume so actually and most of the trace backs that show up like they don't have any new IDs let's just a big trace back so usually when i grep like you know have some simple filtering tools like I actually miss out on those trace back so I have to the only way I can do it is i just have to go into the logs and then you know find out the UID and then traverse through the logs yeah usually you locate the uuid and then you the request that it is in that uuid i filtered by that and then you filter only those and then you mark the specific location what you say oh here there is a trace back and I miss it so you market you hit ma for example to market you undo the filter and dilute yeah yeah but it'd be nice to have a tool which kind of you know does that for you cuz you know it takes a long time to figure that out yeah then the thing is we feel your pain because yeah we've done it so yeah so I have a similar tool like which is internally I kind of use and i would like to kind of you know collaborate with you guys if you hear things how to be great with you afterwards sure sure the thing about the more advanced filters is that it's something we want to do but we know that as soon as we get in in the code they come on the parent request ID everything will be so easy is that it's like now if it's if they are going to have it done in three months do we want to spend more time on these to get the filters and do everything if we're going to get so much more with the with the common request ID so yeah yeah I suppose maybe another tool on top of this like a log navigate or specifically built for OpenStack could be interesting then maybe hope you filled out of the things you got them because yeah you don't want to go back to a command line and your filter but do you want to navigate select stuff and move around but yeah we also have other world good or really good tools for that I than I could I know so okay well so thank you very much you 