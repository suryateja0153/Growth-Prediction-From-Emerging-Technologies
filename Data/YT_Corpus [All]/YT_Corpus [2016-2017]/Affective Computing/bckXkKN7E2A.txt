 hey everyone my name is Andy right I am a research assistant at a grad student at csail at MIT I'm in professor árbenz lab and we have recently started what we're calling our risky expedition so the past semester we made a 64-bit risk 5 processor with the IMA FD extensions it supports machine supervisor and user modes it boots risk 5 linux with sv 39 page virtual memory we have tandemly verified it with the spike is a simulator and it's all been written in blue speck system verilog in this same setup the same semester it's been integrated into Arvin's computer architecture course 6 175 and it's going to be used even more in future iterations of that course so this was a big task in its own but it's just the starting point for us so we're using this as the base for our risky expedition so this expedition is six different aspects combined together we're going to try to form a formal specification of the ISA or a subset of the ISA we want to do such with an operational model we want to construct formally verified processors or formally verified optimizations to processors we're going to explore memory consistency models for risk five including its risk five should have a weak memory model and if so which memory model there's some desire to explore accelerators for the architecture we're going to do some micro architectural exploration to improve performance and at the end of the day we're going to be targeting ASIC so we're going to be tuning microarchitectures to performance power and area numbers and asic there's no concrete plans for a tape out yet though so throughout this initial design we've been focusing on what we're calling verified design so our plan is to get a working processor first figure out why it's slow and then make it faster without breaking it so we're leveraging blue speck system verilog which gives us a very modular way of describing our processor and it also gives us a great platform to add on to and make changes to so simple changes and our processor may not break the whole thing we're a simple change in Verilog may break everything so in our group there's no separation of design and verification all the design it's being that is going on should be verified to be correct so currently we're using tandem verification using some technology developed by blue speck incorporated but in the future we're going to be moving to formal verification so to give you some background information so this is how we built this processor this is how we got Linux booting this is tandem verification so we run our design either a simulated version of it in Vera later or the design running on an FPGA in tandem with the spike is a simulation they have synchronized HTF interfaces so they see the same input and output at the same at all times spike has been slightly modified so that it's timer interrupts matches ours and certain other behaviors that we have adopted we have merged into spike so both spike and our processor have been configured to output the program counter instructions executed what the data was packets exchange with H tiff and the memory operations being performed if any so this has helped us find many bugs including some bugs and booting linux in our virtual memory system that may be a load at some instruction saw the wrong data because it was reading a page table entry that wasn't updated dirty correctly or something like that and then thousands of cycles later or millions of cycles later the two programs diverged so instead of catching the area of the the error a million cycles in the future we catch it as it happens so this is extremely useful to get linux booting but it's lacking in terms of complete verification so if you have a highly parametrize design what this is telling you is that your specific instance of your design that you tested works with the program that you're running on it the one time you in it and thats lagging for us so we're moving to formal formal verification so when we say formal verification we're saying we are going to be constructing a proof that our processor matches a formal specification or proof that an architectural optimization that we have applied to our processor does not change the correctness of our processor but this requires a formal specification force 5 and this is not an easy task because there are a lot of odd cases that really need to be completely decided before we can construct the formal specification so throwing out some concrete examples our reference bits and page tables allowed to be speculatively updated or updated for speculatively accessed pages so if your branch predictor says you're going to be running an a an instruction from a page that has been accessed yet are you allowed to set that bit even if that instruction isn't committed that would completely change the formal specification because that would introduce this idea where you can have some speculative instructions that are changing the state in your processor that don't correspond to committed instructions additionally a single instruction can result in 213 affective memory accesses at the top end and this may even increase with a hypervisor depending on the implementation of the hypervisor so how do these 13 memory accesses interact with each other and how do they influence the memory model so from here on we're going to talk about some of these details are looking at and we're going to start with just memory models in general so just a short overview there's many different types of memory models that describe how both threads in the system see memory updates there are strong models that are easy to understand understands such as sequential consistency and total store order but they restrict optimizations there is weaker consistency models that permit Hardware optimizations but they're very difficult to understand in their descriptions so like releases script release consistency is described in terms of operations performed with respect to certain processors and empower an arm they have a very unclear ice a memory model specification and there is a and it's sort of left to you can't really assume much except for special cases so for formal specification we really want simple operational definitions that doesn't imply a simple memory model it just implies that you have a memory model you can describe in simple terms and we want them to be an operational definition such that legal behaviors must be observable in some abstract machine and that the cores are performing one instruction at a time atomically and they perform them in program order you may have local structures that that brings out the reordering in your memory model such as TSO tso would be the application of these cores and a store buffer that the cores can read from their own store buffer but not their neighbor store buffers and fences and this model reflect are reflected in flushing local buffers so we are going to propose a new week consistency model that we're calling wmm that will have or that has a simple operational semantics that still prevent that still allow low store reordering and almost all micro architectural optimizations so it's described with a store buffer in an invalidation buffer pork or any loads and stores describe actions on these buffers and fences describe how these buffers are flushed this provides an easy to understand operational model between colors but it misses those 13 loads and stores that each core can do in the interaction between those 13 so talk about those for a bit so we're going to call those flavored memory accesses so here's a subset of a simple processor pipeline you have instruction fetch it's going to read instructions to execute you've got memory accesses it's going to load and store data from your data memory the risk five is a specifies offense instruction between data accesses and input/output accesses so that implies there is a sort of separate flavor of memory accesses for inputs and outputs so this is this is so what we get from this is this is sort of uncashed accesses and the fences describes ordering between those operations but at the same time you have virtual address translation loads and stores this looks a lot like four separate cores accessing the same memory so it looks like this may also have a memory model and we're hoping that it gets integrated with the same memory model so diving a bit into some details with synchronization between these effective cores or flavored memory accesses we see one example from the ISA for synchronization is s fence vm so tandem verification helped us in many places the biggest place it helped us was recognizing that there was an S fence vm a few s fence pm's missing from the Linux kernel so with the specification of essence vm its described from a programmer point of view instead of hardware point of view it's not a TLB flush it's a synchronization between stores to the data and virtual address translation loads so data stores coming before an S fence vm have to appear to the virtual address translation loads for the S Vince vm with those semantics every time there's a right to a page table you need an S Vince vm before that translation can be used but there's no instruction for the other direction yet so a virtual address store which comes from updating a page table entry as referenced or dirty there's no synchronization between that store and a load from the carnal to see whether these ads to see the new state of the page table entries so we're proposing that there should be another flavor of s fence vm that works as opposite direction so the TL bees can cache data and dirty and reference bits so we're looking really closely at these flavored accesses and we're combining them into our memory model too as a first step for a formal specification for the ISA so there's other directions to this that are even further in the future where we have a team member that's looking into accelerators he has been working on our blue DBM machine recently in Arvin's group that is a 20 fpga machine with flash memory attached to each fpga he was looking into neural network acceleration and he has decided that he wants to use a risk five core with a convolutional neural network accelerator or ice extension to for those applications we have a big desire to do some micro architectural research and we're also at the same time we want to focus on basic implementations so there were not leaving performance on the table in our designs and one other aspect of this is education actually Arvin's got a great computer architecture course it's using risk 5 right now and we want improvements that this expedition finds to find its way into that course as well any questions questions for Andy is this open source so it's not open source at the moment it's definitely something we want to tackle but we have to solve a problem first and the problem is with education so the 6 175 course the final project for the past few years has been pretty advanced to the point where also just to throw out some concrete examples one of the year's IT ated they were given an in order processor they had to make it into an out of order moto they had to make it into a multi-core processor with non blocking caches we have those non-blocking caches in this processor and we don't want to at the moment we want to figure out how we can keep those final projects interesting without and still have this processor out in the open so we're trying to figure out how it's going to work Tommy phone on affiliate the weak memory model that you propose is that is that more constraining that any existing implementation or is that sort of the weakest practical model that you can imagine so it it's a little bit more constraining I don't have the details with me at the moment I'm not the lead for that portion of it but I can definitely get you in contact to get down to some of the details of it there's still some open-ended portions of the memory model that we're trying to figure out before we make it public because it's the operational the abstract machine can describe many different memory models and we're trying to figure out what the best configuration is so that because we could make it very weak with this abstract machine or we could make it much stronger so we're trying to figure out the sweet spot for programmer efficiency and architectural efficiency before we release it to the public and it looks like it's going to be a little bit more constraining than other weak memory models so more constraining empowering arm for example so you mentioned microarchitecture research do you have any class of workloads and mine for that so we're planning on running the spec benchmarks in Linux kernel just to stress virtual memory and the whole stack we also wanted to when we get our multi core implementation up and running we wanted to explore other other multipolar benchmark suites and we are definitely open to suggestions oh do you have any spec score daughter get in my specs for target not going on 