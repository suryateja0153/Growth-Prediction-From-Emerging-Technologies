 good afternoon it's a great pleasure to be here with you as some of you will know you just heard there I'm co-author with my dad of the book the future of the professions and I've spoken a lot about the book since its launch a few months ago so today I wanted to talk to you about something a little bit different much much of the book focuses on the short in the medium term so today I want to to look at the longer term I plan to take three central themes in our book and asked for each of these themes if we are right what's the most important unanswered question that this theme reigns raises so the long-run story of the book for those who have read it is about the decline of the traditional professions so I'm asking today what are the questions that after the professions we will need to have an answer to I thought this symposium would be a good chance to start exploring some possible answers so these then are the three central themes from the book the first is a transformation in the way that we produce and distribute expertise in society the second is a change in the nature and the volume of the work that exists for human beings to do and the third is a shift in the way that our machines and our systems what we can call AI for short operate and so I'm gonna take a look at each of these themes in turn set out the main question that I think we have to answer so first expertise now our book opens with a fundamental question why do we have the professions at all and the answer and it runs through our book is because the professions in analogous ways are a solution to the same problem none of us has sufficient specialist knowledge to cope with all our daily challenges no one can know everything human beings have what Herbert Hart called limited understanding and so we look to doctors teachers lawyers and other professionals because they have the expertise that we need to make progress in life so what we call in the Booker a print-based industrial society the professions are the way that we solve these daily challenges professionals have knowledge experience skill nohow and our term for term for this is they have practical expertise that those they help do not they operate under a grand bargain when this arrangement entitles the professions often to the exclusion of others to provide certain services and they're entrusted to act as gatekeepers each profession responsible for curating and updating their respective bodies of knowledge so doctors look after medical practical expertise lawyers work off the legal practical expertise and so on so that's our analysis of the professions in a print based industrial society but we're no longer in a print bit a print based society we're moving rapidly as we heard today into a technology based internet society and our professions are creaking now they're unaffordable they're antiquated they're opaque and they underperform and so we ask the question in the book as we move from a print based society to an internet society what are the new ways of organizing professional work other ways to make at least some of this practical expertise available on a different basis so when we began the book in 2010 our main preoccupation was with the work of the current professions and however as our thinking progress we concluded that there was a more basic and fundamental question that had to be addressed how is it that we produce and share practical expertise and society now the traditional answer to this has been through the professions what we see at the vanguard and document in the book are very different ways to produce and share practical expertise and in the book we set out six alternative models for producing and distributing expertise in society I'm not going to go into each of them but what I want to do is just run through very quickly a set of cases that show this very different future emerging so consider that in the legal world every year 60 million disputes arise online on eBay and they're resolved without lawyers they're resolved using what's called an online dispute resolution system bear in mind that 60 million disputes is 40 times the number of civil claims that are filed in the entire English and Welsh justice system on this one website said that the best-known legal brand in the US isn't a traditional law firm it's legalzoom.com provider of automated legal documents and online legal advice 2014 the US tax authorities received tax returns for almost 48 million Americans using online tax preparation software either the commercial system like TurboTax or free software provided by the tax authorities without traditional tax professionals 2014 Associated Press with the help of the company automated insights started to use algorithms to computerize the production of earnings reports it was able to produce fifteen times as many earnings reports as it could when it relied upon traditional financial journalists and in 2011 admits some controversy the vatican and in the book one of the professions that we look at is divinity the vatican granted the first digital in parameter and so an imprimatur is the official license that's granted by the catholic church to religious texts it granted it to this app called confession which helps people prepare for confession so this this app includes tools for tracking sin and it's got drop-down panels of options for contrition and the controversy was that the vatican said that so the the allocation of implementers is decentralized in the church so it was a local church so in America that issued the imprimatur of course such a storm that the vatican had to step forward and say you're allowed to use this app to prepare for confession but it's no substitute for the real thing so we give several hundred several hundred we give many examples like this in the book and so here is the first question that we think is raised by this by this theme who should own and control tomorrow's practical expertise you know traditionally it was the professions as I said the professions were the old gatekeepers in the past when you're in need of expert guidance we turn to that you know the members of the professions knew things that other people didn't know the promise of the sort of examples that I just set out before is a liberation of practical expertise you know more affordable access so the sort of practical expertise that was traditionally locked up in the head sort of professionals are filed away in cap what we see is the human experts and the professions are no longer the only source of practical expertise and in this emerging world where the boundaries of the professions are being redrawn and very different types of people in institutions are creating new sources of Brac to expertise that old ground bargain I spoke about before that arrangement we struck with the professions it starts to make far less sense so just by way of example let's return to the example of TurboTax talking about the decline of the old gatekeepers one legitimate fear might be the rise of new gatekeepers so on TurboTax for example I think it's about 25 million people use this software alone third to automate their their tax returns just bear that in mind now jump to Brazil Brazil has a tax system called sped so it's eliminated a great deal of self-assessment for Brazilian businesses businesses are no longer required to file their tax returns but what they do instead is they submit their original accounting records electronically to the Brazilian tax authority and then the Brazilian tax Authority calculates calculates their tax burden rather than the taxpayer analyzes the data and determines how much it determines how much tax to be paid so in the u.s. the IRS recently suggested a similar thing not for businesses but for for ordinary taxpayers it's called a return free tax system so the software prepopulates the tax return for the taxpayer and a tax baked payer then either okz or doesn't okay and and revises it now the IRS claims it takes about four hours to fill in a tax return so this is quite significant had a TurboTax respond to this well it's claimed that TurboTax actively lobbied against it no the claim is that Intuit which is the company responsible for developing TurboTax spent about 11.5 million dollars on federal lobbying in the five years leading up to 2013 more than Apple or Amazon against the LOB and it was lobbying against lots different things but part of it was opposing IRS government tax preparation now in the statement the spokesman for that said return free programs kertel citizen participation in the tax process also have implications for accuracy and fairness in taxation that was their response and it's interesting by the way that this piece on turbo tax was written by Pro Publica which is not a traditional news organization at all and journalism is another one of the professions that we look at that's changing in the book but just with that in mind return to the question who should own and control tomorrow's practical expertise who are these new gatekeepers who do we want to be the new gatekeepers of any one and how do we shape and regulate the sort of behavior that we just saw from TurboTax if we want to you know the old grand bargain that was struck up for the traditional professions doesn't apply to these new gatekeepers so that's the first question looking at expertise a second theme in the book is then a change in the nature and the volume of work that exists for human beings now the change here as we write in the book depends on time skills in the in the medium run our expectation is that yes technology would reduce the number of traditional professional roles and you already see this happening but it will give rise to a whole new set of roles and is his 12 of them many of these new roles aren't familiar when I when I showed them to traditional professionals and many of these won't be performed by traditional professionals at all and if you're interested in these we go through them in the book but this is the medium term and in the spirit of today's event looking to the longer term it's very different and that's what I want to focus on now one of the difficulties when we think about the long term consequences of technology on the labor market is that we talk we always talk about jobs so in the professions we talk about doctors we talk about lawyers talk about teachers and accountants but the term job isn't entirely illuminating a job isn't an indivisible monolithic lump of work to think clearly about the future it's far more helpful to focus on what it is that people actually do in their jobs they're the type of tasks that make up their jobs so by way of example a nurse what a nurse does today the sort of tasks that they do are very different from the sort of tasks that they would have done 20 years ago whereas nursing of the past might have involved bedpans and bedside conversation today nurses are involved in performing mine operations or prescribing certain types of medication very different sets of tasks but we use the same job title for both why does this matter for thinking about the future of work so when we when we published the book The Economist reviewed it and it's a good review otherwise I would have mentioned it and together with the piece was this great illustration of the Economist called professor dr. robot QC and there's a sense in a lot of commentary on the future of work the account is that one day a doctor or a lawyer a teacher will turn up at work and find professor dr. robot QC all one of his relatives know sitting in their chair their job will have been entirely replaced by some robot and yet we take a very different view in the book we just we don't think this is how it will play out again by way of example suppose a new technologies inventor right invented that computer Rises a particular task how that professional does so here a remote monitoring system reduces the need for patients to go to a doctor for a medical check-up now clearly if this technology is introduced something has changed in the job of a doctor but to say that the doctor's job has been replaced would be too wildly overstate the case no she meant she may spend less time performing in-person medical examinations but she may also spend more timely reading the latest medical research what we want to say is that the job the doctor has done the job the doctor does has changed and by thinking about the tasks that make up the job we can do this far more coherent list that's why the term job is too general and sweeping because it masks this deeper underlying churn and change in tasks so why is this significant why does it matter when we look at the four types of tasks that we think professionals perform in their daily work there are tasks that require cognitive capabilities the ability to think underst and reason solve problems reflect there are tasks that require manual capabilities so physical and psychomotor aptitude there are tasks that require effective capability the capacity to have feelings and emotions both introspective and in response to others and then there are tasks that require a moral capability and the faculty distinguish between right and wrong good from bad just from and just and so on and often more than this to take responsibility for the choice that's made now when you look at those tasks what you see across all of them is what we call increasingly capable systems that are able to perform more and more types of each of these four categories of tasks whether it's robotics in the case of manual tasks or in the case of effective tasks for example the field of affective computing it's a relatively new field where researchers - developing machines that can both detect and respond to human emotions so across all these different types of tasks we see increasingly capable systems and machines taking on more and more of them so leaving aside the question of whether or not there will be less work for people to do there's a second normative question it might there be some tasks that only human beings should be permitted to undertake and again this is different from the technical question whether or not future systems will be able to undertake all tasks to a higher standard than the best human experts it's a normative question you know are there tasks that we feel should always be undertaken by machines even if they could be performed to a higher standard by Sur should always be undertaken by human beings even if they could be performed to a higher standard by machines you know for example should a machine make the decision to turn off a life-support machine even if it could reach a more efficient judgment about the allocation of finite resources in a hospital should a machine be responsible for passing a life sentence now these are things that I and I imagine many of you feel deeply uncomfortable with now we see an analogy here with the debate in the UK in the early 1980s over the moral implications of emerging technologies such as IVF and test-tube babies so at the time there was a national inquiry and a public consultation was launched and it led to this influential poor by the philosopher Mary Warnock now the subjects of the time generated a lot of attention and what the enquiry did was it really substantially raised the level of general understanding of the central issues we suggest in the book that before our systems become much more capable there's a need for a similar scale of debate on the moral constraints we should impose on the use of models for the production and distribution of practical expertise that do not involve human professionals now there's quite an interesting further complication here which is that suppose you do hand a task over to machines you can't escape the moral the moral dimension so imagine the the case of a driverless car Google driverless car and imagine it finds itself in the following situation so it's speeding along the road and out of nowhere a person appears in the middle of the road and the car in this situation only has two options it can either veer off the street certainly killing the driver or it can continue to speed on there's certainly killing the person in the middle of the street now if the Google lists driverless if the Google's driverless car finds itself in that situation today it has to do something it has to choose one of those two options and you know to an extent that option has already been chosen it's articulated in the code that the driverless car follows and it may have been I don't know what the programmer was thinking when he wrote it but it may have been decided I intentionally or unintentionally that it would have this sort of consequence so there's a sort of there's a there's an inescapability to some of these moral moral questions when it comes to automation as well so now I want to turn to the third and the final theme AI and how and how the nature of it is is changing in the 1980's my dad who as I said I wrote the book with he was doing his doctorate on artificial intelligence in the law and looking back on what's happened of in the field of AI and talking about it we've developed an account of the fields development that I want to share with you so my dad was involved in the 1980s and what we now call the first wave of AI and he did his doctorate from 1983 to 1986 on artificial intelligence and the law so very crudely he was asking could a judge ever be replaced by computer knows it was a more abstract question looking at the nature of legal reasoning is it such that this is something that could ever be automated and of course you're writing in the 80s the sort of systems and machines that exist today weren't available then so it was even more of an abstract question there so from between 1986 to 1988 he left the academic world and worked on the development of this now my dad my dad assures me that this at the time was quite cool this is cool screen cool cool as it could get and this and this was an expert system and what happened was this he had just finished his graduate work in Oxford and the Dean of the law school in Oxford at the time who was a man called Philip CAPA had written a book on a very very complicated area of the law it was called latent damage law which is a small corner of the law of limitation and Phillips said that this area of the law was so complicated nobody understood it and they had this idea of joining forces to build a system that other people could use in this area now this was an era when floppy disks genuinely were floppy and this is what the this is what the system looked like and together they published a book with these two disks slotted into the back of it to give you a sense of what they were up against this was the sort of law section 2 this act shall not apply to an action to which this section applies complicated and difficult stuff and that was one of the more readily understandable parts of the legislation so what they tried to do was they tried to develop a pathway through this complicated web of interrelated rules and frankly what they did was they developed a sort of decision tree and I was slightly more complicated than a decision tree because of the nature of the content that was involved but typically a question would look like this and again you know the content doesn't really matter but from what you've said so far it seems that the most likely basis for alleging liability will be torturous negligence shall we proceed on this basis yes or no and so you'd answer the question yes or no and by answering the questions you'd be nabek navigated through this this area of law now this is just a small part of the tree there I think I think there are almost two million paths through the complete tree and to an extent the two of them together had to map out this entire thing they had to describe each of the paths and right there right the questions now this is this is the first wave of AI where what you did and it was called knowledge acquisition or knowledge elicitation was that you'd sat down with a human expert and you mind the jewels of knowledge from the head and try and build it into a system for others to use you were known as a knowledge engineer may recognize knowledge engineering is one of the twelve roles that I've set up before now this wasn't just in law they were developing these expert systems in other fields to medicine tax audit and consulting and so that was the model in the 1980s you know taking the expertise out of an experts head dropping it into some system for non experts to use but these systems didn't catch on and there's lots of reasons why they didn't catch on if partly at turned out of the systems were very costly to build and particularly costly to maintain because the law changes so rapidly every time the law changed you'd have to go back into those two million paths and reconfigure them and rewrite the rewrite the question there was a little incentive for commercial organizations to adopt them I remember at the time most lawyers and still most lawyers charge by the hour there's no incentive to develop sort of technology that could take a task that might required four days and turn into one little it takes four minutes and you know finally the web came along and this wasn't you know the web wasn't the same sort of thing that the AI researchers at the time were were aspiring to do but what it did was it offered a really intuitive way to make content and guidance available online very quickly very cheaply and so the AI winter as its called the failure the initial failure of these first wave of expert systems at least in the professions we attributed to the web not because not because it was that people were distracted but because they were attracted to this new way of making expertise available it's just far more it's far easier to build a website and put some legal advice online than it was to build these incredibly complicated expert systems now turning point came in 1997 when Garry Kasparov who was the then world chess champion and it's well known was defeated by deep blue in the 1980s when AI researchers were working in the computer labs they talked about this sort of thing chess playing was one of the areas in which they were particularly interested and my dad and his colleagues for example were convinced that a computer system could never beat a grandmaster like Gary Kasparov and the reason why they thought this is incredibly important the problem with human experts and in Garry Kasparov is a great example he's an expert of playing chess is that they don't take in the case of Garry Kasparov he doesn't really know how it is that he plays grammar Grandmaster chess their struggles to articulate it and when you press a grandmaster they appeal to things like gut reaction heuristics it's accumulated experience and so on and these things are very difficult to articulate they're very difficult to model and so if you can't get a system or machine if you can't articulate these things in a set of rules for a system and machine to follow then assist and then the task can't be automated and that in the case of playing Grandmaster chess that's exactly what was happening these chess players couldn't articulate how it was they were so good and as a result you couldn't build a system that could perform as well as them now what these you know what my dad and his colleagues hadn't banked on was the exponential growth and processing power that we've heard about by the time Gary Kasparov played deep blue deep blue consider up to 330 million moves a second and Gary Kasparov could consider about a hundred moves ago yeah in a sense Gary Kasparov was beaten by a machine that was just playing a completely different game he was blown out of the water by brute force processing power it wasn't that the system had more genius than him it wasn't that a had greater strategic insight it was raw processing power now the insight here and it's made by Patrick Winston one of the leading researchers in artificial intelligence as this you know there are lots of ways of being smart to arm smart light cars and this is a vital point now we tend to be incredibly anthropocentric human orientated when we think about machines and getting them to perform at a higher standard we tend to assume it leads to this which is in some ways one of the most important ideas in the book the dai fallacy and it's this which is the mistaken assumption that the only way to develop systems that perform tasks of the level of hue of human experts are higher is to try and replicate the thinking processes of human specialists it's made by academics and it's made by commentators and it's simply mistaken you know many of the systems and machines that are displacing professionals displacing middle-class workers from performing tasks are doing so by for performing that task in a very very different way from a human being and this AI fallacy this mistaken assumption I think is the source of a great deal of conservatism in thinking about the longer-term prospects of Labor the templum all of our temptations is to say since the computer can't think it can't ever be creative because a computer can't feel it can't ever be empathetic and so it must be the tasks that require creativity or tasks that require empathy must always be performed by a human being and so on and the mistake is to fail to notice that many of these new systems can perform these tasks not by copying the way that human beings do it with our creativity or empathy but doing it in an entirely different often in an uncommon way it really leads to a related question can machines think there we love this question philosophically but we also love the answer that john searle a great philosopher put forward in a Wall Street Journal op-ed the day after Watson beat the two leading jeopardy so who knows about the story of Watson and beating the raise that raised a hand okay so Watson was a supercomputer that beats played the two leading jeopardy champions Jeopardy's in American quiz show and 2011 in a beat them both you know in effect this was a machine that was able to answer a question about anything in the world better than the two leading human experts know what John Cell said the day after I did this was Watson doesn't know it won on Jeopardy now Watson didn't go down to the pub to celebrate with his friends it didn't tell its friends how it felt it was overjoyed but it still outperformed the two leading experts and this is vital you know what we're seeing is the emergence of the increasingly capable non thinking machines they're not like us they're not like professionals they're not like middle-class workers but they're outperforming us at certain types of tasks that we thought could only be performed by human beings and this we call the second wave of AI and it has profound implications for the future of work not just professional work as I said I think this AI fallacy is the source of a lot of conservatism about what it is that machines might be capable of doing in the future but it also leads to a third question how is it we can understand the reasoning of second wave AI when we hold professionals responsible and hold them to account we almost certainly ask them for an explanation for how they came to their conclusions on why they made their decisions why doctor did you make that diagnosis why lawyer do you advise not go forward with this case and so on how are we to secure explanations from these high performing machines when they work in ways that are quite unlike the reasoning process of human beings so just to return to the system the system that was developed in the 80s you know one characteristic of expert systems then was that the system should be transparent that the term of art which meant that they could explain their their lines of reasoning so Phillip Phillip Kappa who this system whose expertise the system was modeled on tell stories of the the system reaching a conclusion that he didn't immediately agree with the system must have got this wrong this can't be right and and then what he'd do is he'd go and look through the look through the decision tree that that machine had gone through and he'd be able to see exactly how it got to the decision it got see it could follow the path through this tree it's not clear that second wave AI systems will be able to explain themselves in this way as it were as the first wave AI researchers had hopes it's not clear that these new systems will be transparent in the same way having said all that it's you know it's also important to be clear that many of our high-performing experts for the reason I explained before are unable to explain the work that they do again doctors who put down a diagnosis to gut reaction or experience or struggling to articulate precisely the reasoning processes that they go through but just just to close with an example of this Lex machinist a system that was bought very recently by my LexisNexis it's a it's a system that predicts the outcome of patent disputes which is incredibly important if you want seeing if you're a lawyer and wanting to know the potential outcome of a case where they want to go forward we're there how much resource to put into it and so on this system can more accurately predict the outcome of the patent dispute than the leading human patent Lewis now the most important thing again here it knows absolutely nothing about the law the way it reaches this decision is by crawling through a data set of about a hundred thousand past cases where the judge involved in the case the nature of the case the location of the case the people who are on either side and so on all these things are data points and it is able to reach a more accurate prediction than leading human experts I went back to the research paper where this was where this was first set out it's very difficult to interpret the reason it unless you know quite a lot of complicated statistics it's very very difficult to interpret the reasoning process that the system is going through in order to reach a probabilistic estimate it's a set of very complicated regressions now it might not be that lack of transparency might not worry people in the case of predicting a path of dispute but it might worry you if it's a system that is predicting given a set of symptoms whether or not you have certain type of cancer or whether or not again whether or not you ought to spend the rest of your life in jail if these systems aren't transparent and we can understand the reasoning process that they're going through to reach really important decisions than that that might be problematic so again this question of how we can understand the reasoning of these second way there I systems which are very very different from the first wave first wave of AI in the 1980s I think is is that isn't an important question so to close then from the book three central themes one a change in the nature of the production distribution of expertise in society and that raises the question who should own in control tomorrow's practical expertise secondly change in the nature and the volume of work that exists for human beings and here an important question is are there certain tasks that ought not to be performed by shooting machines even if they could be performed to a higher standard and thirdly the shift in the Nate in the way in which our systems are operating from first wave AI to second wave III how is it we can understand the reasoning processes of this second wave of AI and is it something that matters to us so I'll end there thank you very much comments questions okay I think the question about transparency reasoning might be one of the might be one of the really big obstacles to deploying this stuff in lots of areas and it's not just in medical areas and it sort of stands in the way of the triumphalism of the Evangelist for this stuff because they seem to be unconcerned about about things like lack of transparency so two responses the first the first is both the takes on the same so it's one response with two elements what's the benchmark it and what is it that we're comparing these new systems to as I said in the medical case if you were to ask a doctor how it is that they reach a particular type of diagnosis and really try and pin them down on it often the reasons that they give are not at all comprehensible it's things like I've just studied this stuff and I know it when I see it and that doesn't strike me as a particularly transparent it we shouldn't in other words hold these systems to a higher standard than we hold fellow human beings we shouldn't expect perfect an acidity of reasoning when we don't expect that from human beings so just we got we've got to be careful that we don't and you see you see this very often not only in terms of transparency but also in terms of the outcomes that these systems and machines are able to achieve there's a robot pharmacist at the University of California in San Francisco and it's made six million prescriptions without error that's sorry it's made six million prescriptions and it's made one error now a lot of people when they see that error get incredibly angry it's this could've kill sponsor but you've also got a bear in mind that at best human beings make an error in prescribing medication one percent at the time at one percent of six million prescriptions of 60,000 miss prescriptions it's a shut down this machine because I made one miss prescription would be to hold it to a wildly higher standard than we hold fellow human being so that that's the first point the second point is a more general thing which is that the promise of a loss of these systems that they is that they offer access to expertise that for most people at the moment is in unaffordable and it's in the legal case there's 60 million disputes that were resolved online on eBay those are disputes that without that system would have probably gone unresolved or if resolved resolved unsatisfactorily for one of the parties now it may be that the system that has reached that judgment is less transparent than the leading barrister would have been if he was brought into that judgment but again the benchmark for these for the people who are using the system is nothing at all you know it's no access to legal expertise and so we're just I think the well I do I recognize this as a big problem and it's a big problem in particularly significant areas we ought not I don't think it's we should that I mean I'm just thinking that it doesn't that also apply to say the example example you you raised your honor but the Google car having to make a decision between swerving off the road okay pedestrian and because human drivers are confronted with that dilemma don't don't sit around they don't stop and think about what exactly the optimum outcome here yeah so you can't hold in that sense you it's unrealistic to hold the machine to the higher standard that you would I think that's a really troubling line of reasoning I think it's you know we are being forced in writing code in this way we're trying to build in possible scenarios all possible to know is we're forced to make moral calculations in a kind of liberated way that we simply aren't forced they were in ordinary life we would make in a far more instinctive I mean is it not also is it the case that so in some areas of for example paralegal work that that already law firms use software to do for example in Discovery cases of course yeah absolutely if you look more rapidly than humans if you look at what it is that a junior lawyer does in the first few years of their career things like reviewing documents assembling documents and retrieving documents reviewing large documents for typos assembling documents that ultimately are very similar to the document they assembled the day before but with a couple of things tweets and thirdly retrieving documents from vast bodies for docking now those are the sorts of things that systems and machines are incredibly effective at performing and you see law firms already using these these systems but it then introduces a problem of at the first ten years of your career as a legal professional is in automated and the stuff that hasn't been automated is at the other end of your career how do you get there how do you train to doesn't mean in a way that means that in some areas the the future that that that people who are thinking about this stuff is some distance away or so it's already here and and if I had time I would have gone through many more cases where you see this this isn't this isn't fanciful you know we talk about the talk in the book about the decline of the traditional professions and it's already happening you know whatever profession you look at whether it's journalism consulting tax ordains auditing law education health care you see things that predict what see tasks that were performed reptillian basically in the same way since the middle of the 19th century by a similar group of people being done by very different people yeah all done not by people at all and by very different tysonis Tricia's Thanks so two reasons why company might be interested in automation would be either to replace an employee or to make an employee's job more efficient and certainly in blue-collar work it seems that the trend has been towards replacement right you have self-checkout machines so you don't have to hire as many people the checkout counter but you seem to have suggested that at least in some areas of white-collar of work with your doctor example it's not that the doctor is replaced you seem to have suggested that certain tasks will be automated but other tests will will take their place and I wonder so I wonder if you think that is first am i interpreting you correctly that white color are you saying the white-collar jobs are not apt to be replaced in the same way that blue-collar jobs have been and if that's not what you're saying do you do you see a difference sure so it's if I if I have more time I would have gone into exactly the mechanics of what I think is happening in the labor market and will happen what you've drawn there is a distinction between technology the complements people human beings and performing tasks and technologies that substitute for people and performing particular tasks and they're largely what people disagree about when they talk about the future of work is whether or not technology is something that substitutes or comprehensible for workers part of the problem with that story is that it's not a task-based story you know the question is why is it that technology's complement particular types of factors in performing yeah why is it that so if you read the economics electric chair the story that's told about the labor market and second half of 20th century is skills biased technological change the technological changes skills biased it has for certain periods in the US raised the skills premium which is the premium extra wage that you get from having a college education so the question is why why is that why and it's only by thinking about tasks that you can really think coherently about why it is that technology might be my complement particular factors and not complement other factors so it might to talk about the white collar and blue collar why is it the technology might complement white collar workers but substitute for blue-collar workers it's because it's complementing the sort of tasks that it is that white law workers doing it's substitute now the argument we make in the book is that while it may be the case that certain technologies compliment people today in performing certain types of tasks there's no reason to think there's no economic law that says when we create new tasks for people to do in the future that necessarily those are the sort of tasks that will be done by human beings and on the contrary when you see what it is that technology is capable of doing across all these different categories of tasks is able to perform more and more yeah it's it seems to others that it becomes more and more likely the tasks that are created in the future will be done by people rather than by machines so that's it thank you very much for their absolutely fascinating but I'd like to raise with you a problem that I think you didn't touch on is what I call human knowledge everybody in this room knows what I'm talking about you get a call from your mother and you know she's annoyed with you but you don't know why you walk into a room and there's been around and you can tell it you meet somebody and you think I don't like that she's not telling you the truth all that stuff it's absolutely essential to being human yes and everything that you talk about which i think is extremely clear and right and I'm sure is going to happen in one form or another excludes that essential element of human knowledge without which we can't live and it scares ya because nothing I mean we were asked to sign up by a mechanized system for this this conference why because it's there it's used if I just simply showed up and said is there space so I don't know what's going to happen to human knowledge without it okay so as so it's a really interesting so the claim you're making is that there are certain types of knowledge expertise wisdom we're gonna call it there are unique to human beings that can't be they can't be replicated by machines it may well be true that there are certain types of wisdom that can only be embodied in a person that's fine it may be that the question that I'm interested in is when you look at the sort of problems that human beings bring that human knowledge to bear on might there be different ways to solve those problems that don't require that human that kind of distinctly human expertise it's - let me put it another way you're at risk of committing the air AI fallacy in thinking that the only way to solve the problems that exist in the world are by drawing on this source this fount of human wisdom and that if a machine can't replicate this human wisdom then there's no way to solve the problems that that human wisdom self and what and just just very quick and what we're arguing in the book is you've got to move away from the kind of anthropocentric view that because we've solved problems in the past by drawing on these particular types of intrinsically human wisdom will necessarily need to draw on that in the future and machines can't copy at them that they're we there are very very different ways of solving let me give you let me give you an example there are now systems and machines that can more accurately than a human being tell whether or not a smile on a human beings face is a genuine smile or just a smile of social conformity you know it's not me not making that distinction based on the sort of yeah I dog use of human you could call it tacit knowledge we can call it wisdom whatever it's doing it by trolling tens of thousands of past cases of faces that the person whose face it is said that I'm expressing genuine elation and others who said I'm just trying to fit in so please and and and of course those those those aren't so absolutely but those aren't a stock and traded the professions the role of the professions is to solve some of the most important problems in society how do we educate our children how do we resolve legal problems it's not it's not the it's not the purpose of ill health to provide a living for a doctor you know it's not the purpose of the law to provide a living for lawyers and if we can find more effective ways of resolving these problems problems that for most people in society go unresolved and if those the way we resolve the problem those problems doesn't involve human beings we should embrace them and it's a must it's a mistake I think to - let me let me put it another way that the sorts of things you describe that you're valuing things like love things like you those that need to happen in a doctor's room no it's not it's not the purpose of the professions to provide comfortable personal interaction sorry I'm sorry to this day the expression on my face is genuinely regretful and could be established by machines at eBay we we have one more speaker to go so we have to we'll have to pass the Dan thank you very very much 