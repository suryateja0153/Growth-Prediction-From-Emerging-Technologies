 so about today's agenda Andrew you want to briefly in a couple of minutes explain or you know what are we going to talk about today yeah so today we'll be talking about gigabit Wi-Fi and the marketing surrounding the new 802 dot 11ac standard and the promise of gigabit throughput versus the actual reality will share some real-world benchmark throughput and performance numbers will talk about throughput as an overall metric for performance on a Wi-Fi network and why it may not be the best metric to use when comparing or evaluating performance of your network and we'll talk about how client devices affect the performance of that network because it's not only dependent on the infrastructure but also on the client capabilities and their performance characteristics very cool look forward to it and then we're also going to do a demo right oh yeah will be will be showing off some that kahawa Wi-Fi design exactly today was the first time you ever touched it right and let's let's see if it happens the first time I've ever touched a certain version which we'll get into yes exactly all right very good and at the end we'll reserve a plenty of time for the Q&A as well so if demos weren't bad enough already we have a brand-new product version that I just learned today they'll be doing a demo on so hopefully two thumbs up it goes well I'm sure will if it breaks you know blame the beta version or whatever all right I you can find us on Twitter and every time I emphasize the importance of Twitter if you're into Wi-Fi go to Twitter sign up you can follow us and see who we follow and you know start following your favorite Wi-Fi experts or Wi-Fi guys and girls there as well Andrew how do you how do you like to use Wi-Fi or Twitter is it like a source of news or or you know what's your primary purpose for Twitter I didn't see a lot of value in Twitter until I actually signed up and found the Wi-Fi community and realize it's a great source of information for content sharing finding out a lot about who's out there who else is doing Wi-Fi and sharing experiences learning from one another so it's a great tight-knit community good stuff even if you don't contribute you don't need to write anything to you know get ninety percent out of the out of Twitter's benefits alright so we are recording and yeah yeah without further ado let me keep give controls to Andrew and you can take off or you can take control not not take off I hope so here we go you're Andrew you have controls thank you you see let me go ahead and get my slides up here so a little background about me I've been in IT for 15-plus years been in mobility in Wi-Fi for over ten of those years I've worked in a number of industries from education retail I've worked in the Wi-Fi industry directly for vendors and am now employed as a managed service provider I've got a couple of certifications and I do blog at revolution Wi-Fi network ID to share as much information about the Wi-Fi protocol how it works and the realities around it on my website so definitely go check it out as well as echoes website so without further ado I'd just like to jump in and start talking about gigabit ethernet or gigabit Wi-Fi excuse me and so the kind of three high-level things that I want to cover with you from a technical standpoint today our first actual performance metrics around gigabit Wi-Fi and what we can expect from an actual throughput on 802 11 AC wave 1 and wave to equipment second throughput as a metric and whether or not that's good or bad to use as a metric and just kind of a hint I'm not a huge fan of using throughput as the performance metric or at least the primary performance metric that you use to evaluate wireless networks I think there are better options out there and I'll go through why and from a third point for the webinar that I like to cover is why proper Wi-Fi design is more critical than potentially feature checkboxes when you're evaluating infrastructure far for purchase a large amount of the success or failure of a wireless network goes into the into the Wi-Fi design and the thoroughness that you put into that so that's kind of technical points that I like to cover from a high level first up was the actual performance that you can expect out of through gigabit Wi-Fi or quote unquote give a gigabit Wi-Fi that is on the market today you hear a lot of marketing around multiple waves of 802 11 AC access points which are mainly you know vendor marketing differentiation to identify different generations of hardware that are coming out that boat that implement incrementally further pieces and parts of the 802 11 AC amendment and the Wi-Fi standard in general so there's no difference between 80 to live and AC from a standard it's a single standard but we do see wave 1 and wave to which implement incrementally more features and the marketing surround this is that weight one was gigabit Wi-Fi and especially now with wave 2 we're seeing a lot of marketing and analysts how the full 6.7 gigabit per second capabilities that are in the actual standard and manufacturers leveraging that to try to sell their equipment as just the more bandwidth you have the better and the reality around that is that current products even wave to don't implement all the 11ac standard so to claim that they implement or can can provide the multi-gigabit capability to a certain extent is a bit facetious orbit you know of a white lie there's a lot of hype surrounding gigabit Wi-Fi and why vendors are pushing it in the and the analysts are pushing it as a really great technology and not get me wrong it is really great but around the gigabit hype the raw data raesha sound higher than gigabits per second so that lends itself to a lot of a lot of hype that the throughput is just faster than wired and the performance levels are better than a wired Ethernet which to a large degree they still aren't confusion over the standard and the waves of ApS causes confusion in the customer market as well they don't quite understand the differences between let's say wave one and wave to and exactly how those differences translate into performance it also praised on poor experiences people have with with poorly designed Wi-Fi networks and place the historical trend of throwing bandwidth that problems so a lot of the industry is focused from a marketing perspective on if you're having problems replace your hardware because you need more bandwidth and that will solve all of your problems if you have higher client densities if you have more load being put on your network from Adam and perspective the only way to address that is through buying new equipment and that is just flat-out wrong a lot of poor performing Wi-Fi is due to the underlying design clause and not necessarily due to the hardware so that's kind of some of the topics that we're seeing or some of the advice we're seeing out there in the market today there is some good advice the appeal to two gigabit Wi-Fi and multi gigabit ethernet on the back end excuse me is that um you can leverage existing cabling like cat 5e without having to rip and replace your cable infrastructure in your cable plant within a facility and still get better performance as Wi-Fi starts to exceed the capacity of a one gig Ethernet cable that's great to develop a standard now feature deployment but just understand that actually pushing gigabit through an access point to the wired backhaul is not real realistic today and we're going to show some some numbers around that so first up is you know some of the latest and greatest hardware for both wave 1 and wave to access points from a number of different manufacturers and this is data that I've compiled from real-world testing that shows at a very strong signal quality with an 80 megahertz channel which is alone being kind of generous that you're more likely not going to be able to use 80 megahertz except in corner cases but to solve for those corner cases that you know want to make sure I was including that where you have one or a peak one or two aps and in an isolated facility the peak throughput that you could experience might be upwards of 700 to 750 megabits per second for a TCP type of throughput test and you can see here in this graph that on the left side is this is a percentile ranking about much throughput you can get through an access point from various vendors on the left side is very low percentile so you can only get it a very small fraction of the time and as we go to the right you can get a certain amount of bandwidth a larger percentage of the time so once you get all the way to the right is essentially what you can guarantee you know seventy eighty ninety percent of the time going through a Wi-Fi access point even when the client is staying stable and has a really strong signal strength so just because you have a strong signal doesn't mean that you have consistent performance you still have a peak performance maybe one percent of the time around 700 to 750 megabits per second with some of the best performing aps on the market but they start to level off and you see that as the graph moves to the right even the best performing aps level off and have a consistent repeatable performance level you know of around 550 megabits per second you know larger than you know greater than fifteen to twenty percent of the time which is when you can really start to count on that performance in your environment so performance from a single five gigahertz radio even with 11 AC wave 1 or wave 2 with a low client density and let's say a three spatial stream high end laptop or a few of those still is only going to net you about 500 550 megabits on a consistent basis and we use just a few low density client devices but because in high density environments you actually have worst performance you have worse RF conditions because you have typically lower capabilities and client devices they might be mobile device they don't have three streams they only have two streams or one stream as well as more overhead from contention meaning beacons for multiple access points clients probing overall retransmission rates and contention between clients trying to share the bandwidth that erodes the efficiency of the wireless network so you actually get your peak performance when you actually have load low densities of clients on your network but those clients are very capable high-end laptops if we take a dual radio performance scenario so look at both radios in an access point here we're showing a 2.4 gigahertz radio at 20 megahertz because that's should be the default for everyone deploying Wi-Fi I only use 20 megahertz channels and 2.4 because we only have limited spectrum and then five gigahertz with the best performing ap from the previous graph with 80 megahertz you can see that you know we still approach at best-case 900 megabits per second going through that access point but that's still only a very small fraction like one percent of the time more realistic list saves if we take the 10th percentile where we might be getting 550 to close to 600 megabits on the 5 gigahertz radio and more like 180 to 200 mega bits on the 2.4 gigahertz radio and we can approach on average or a more consistent basis somewhere around 700 to 750 megabits going through an actual access point again this is best-case scenario when clients are trying to offer that much bandwidth or throughput through a single access point and there's the low client density and high client capabilities this is also this testing just to you know be quite frank is is based on the very strong signal strength to the client so in those tests you saw they were very high signal strength around minus fifty DBM which is very strong and a very high signal-to-noise ratio but that also requires you know such a high signal strength that it's very unlikely that your clients will be able to actually achieve that for for most of the time so at for instance 80 megahertz you have to have between an egg 52 and an egg 54 dbm in order to achieve those highest data rates if you start falling off and you have any signal that is weaker than that you start data rate shifting down and then immediately your throughput also drops correspondingly so in order to achieve the highest possible bandwidth you have to be very very close to the AP and have a very strong signal strength so if we start putting all this together what's the probability of actually maxing out the scenario even though we're not at one gigabit we're at the you know approximate 730 to 750 megabits per second throughput of an access point well if we take we have three spatial stream clients and we're going to assume that I've got a low density scenario with all highly capable laptops so right off the bat I'm going to give it a hundred percent is going to be you know the probability that I'm going to have just high laptops high in laptops the probability of those laptops achieving those highest data rates where they had to have a very strong signal strength if you look at even a well-designed network with a guaranteed signal strength in all areas of next sixty six or so DBM you're only going to end up with about six to seven percent of your clients that fall within that's that range that would actually be able to achieve those highest data rates we start looking at those percentile graphs of even under those ideals signal strength conditions how often those clients will be able to achieve around their 10th percentile of performance because it's quite unrealistic to a you know plan for the less than 1% achievable through put a more realistic one is that you know plan for around the 10th percentile because that could actually happen on a more regular basis and if we add those factors up we get with probability of a fraction of one percent of the time that that that AP will actually experience 730 megabits or so of throughput on its wired backhaul port on the Ethernet port so you're looking at a sub one percent use case to even start pushing you know three quarters of a gigabit through your wired backhaul with a dual radio access point that has one radio and 2.4 gigahertz and one radio and five and this doesn't even factor in the offered load from the clients this is assuming the clients actually want to try to push that much that much bandwidth or that much throughput and and realistically in most environments we actually don't see clients trying to push that much pain booth so the actual offered load is not at that scenario and also in most environments you don't have these three spatial stream high and laptops as your only clients in a low density situation so the probability of actually pushing a very high throughput through an access point and and over achieving anywhere close to 1 gigabit per second wired backhaul is essentially zero with with the dual radio access point we're seeing some other newer form factors with not quite software-defined radios but like jul 5 gigahertz radios to take advantage of 11ac and and also overcome the disadvantages of 2.4 gigahertz because we end up disabling a certain amount of radios and modern Wi-Fi networks to avoid 2.4 gigahertz interference because we have a limited spectrum so even if we let's just work through a scenario where we have an access point with 25 gigahertz radios you may say that might push a geek of it so remember this is our single here's the graph again of our single radio on 5 gigahertz and if you're going to push a gigabit through an access point you'll want to know when each AP Radio could push about 500 megabytes or more for a single 11ac radio wave 1 or wave 2 to push 500 megabits it could do it around forty-one percent of the time you sing forty-one percent wow that's really possible that I could push a gigabit but again you take the probability of pushing both of those radios at the same time at 500 megabytes and your your probability actually drops down to around seventeen percent of the time okay that's still fairly reasonable I could potentially push a gig right well let's work through the entire probability scenario again I have again I'm get being very generous and giving you three spatial string clients a hundred percent of the time your Hall I end laptops in a low density scenario forty-one percent of the time on each radio I can push five hundred megabytes of actual throughput and I have my clients that need to be on those highest data rates again which are again only six to seven percent of the time even in a well-designed high-capacity network and your probability of pushing a gigabit through that access point is about one percent just over one percent that's a dramatic increase in the probability from our previous scenario where we had a 2.4 gigahertz radio it was less than a tenth of one percent now we're over one percent of the time but are you going to design a network with it with a use case for one percent of the time where you're going to forklift out a lot of equipment being not only access points but switching equipment as well for let's say you know n bass T multi gigabit ethernet to solve for a one-percent use case and I would say it's actually highly likely that that's much less than a one-percent use case because more than likely you have a mix of clients in your environment that are not all high-end laptops and you don't have an offered load for most of those clients that want to push that much bandwidth at a given time so it's really highly unlikely that you're going to be able to push a gigabit through an access point beyond just a simple lab scenario where you're actually trying to do it just to prove you could do it so reality is that you can't push gigabit through but through a modern access point unless you're really trying to do it in a lab environment and multi gig Ethernet which is being marketed and sold to solve that kind of perceived problem is really not a short-term solution it's a long-term solution that you should be planning for but not necessarily implementing unless you have some other driver to replace you're switching the reality is that the marketing focuses on those data rates rather than the actual throughput capabilities of an access point RF is still the bottleneck because of contention the client mix plays a huge part in to the actual performance that you're going to experience on your wireless network so evaluate the client capabilities just as much as you do the access point capabilities when you look to purchase devices for your corporate environment and if you have BYOD you know you're left supporting a lot of consumer mobile devices that are again mostly low-end smartphones or tablets that are not the same don't have the same Wi-Fi capabilities high density environments actually have worse RF performance so if you think that you need to buy gigabit capable Wi-Fi in order to solve or provide more bandwidth or those high density environments gigabit Wi-Fi is not the answer because of throughput it can be the answer because of other reasons like spectral efficiency and better rate over range performance but is not an answer because you need to push more bandwidth and really you push the most bandwidth through a Wi-Fi network when you have a low density environment or low density situation and you have a single or just a few clients on an access point radio where they're not chewing up a lot of air time for contention related reasons also mu-mimo is is a you know the new feature in wave 2 just a quick note on mu-mimo that it does not improve peek through put at least yet because it's more around improving efficiency and using the extra spatial stream capabilities that an AP has compared to the lower end mobile devices so if an AP has three or four spatial stream support but the average clients in your network only have one or two spatial streams support we can start to use those access extra access point antennas more often and improve the aggregate efficiency of our network and the aggregate capacity over time but it does not improve the peak throughput and finally do have a use case where a few or a single client is trying to push that much bandwidth through an access point radio and now would argue I've been in the Wi-Fi industry for over a decade and I still haven't seen one for the most part so the takeaway is really you give a wife I can't push gigabit throughput quite yet I mean it can in a lab scenario especially with the new dual five gigahertz type of radios but it's not realistic in a practical network or in a live network and watch lots of space for more improvements in the future that could make multi gigabit ethernet and actual gigabit throughput on Wi-Fi a reality some of those things we talked through the dual five gigahertz ApS a second ago how the throughput can eclipse one gigabit very often you have CCI issues or interference issues with those larger channels like 80 megahertz and 160 megahertz which really make it prohibitive for most customers to use except if you're a very isolated small environment and it's not realistic for pervasive deployment to deploy dual 5 gigahertz radios we're seeing it marketed mainly for hot spots not like public hot spots but more like high density or high just a high-capacity areas within your your environment where you may need that capacity more than a 2.4 gigahertz radio could could solve for but you complicate your channel planning as well why good could be a reason but we're only seeing consumer why gig hit the market right now we haven't seen any Enterprise capable equipment yet so keep your eye on that for spatial stream clients if they ever come about out could help push a little bit more throughput but three spatial stream clients right now are very rare and it's expected that for spatial stream laptops and high end Wi-Fi clients will be either very or actually non-existent mu-mimo like I said earlier improves efficiency we will actually won't see mu-mimo start to improve peak throughput until we have more antenna chains and spatial stream capabilities on access points because the reality is today let's say for a three spatial stream access point or for spatial stream access point we're actually only on average using one and a half to two and a half antenna chains of that access point when we talk to multiple mobile clients like smartphones so there's you know it's not a perfect efficiency use case if we have five or more spatial stream ap's we might start to see two and a half or three concurrent streams going to clients from a mobile device perspective so they still won't really probably start to eclipse that peak throughput of a single or a few client scenario with laptops we really probably have to get close to six official stream ap's before we really start to see the average multiple user streams peak above three or four average streams to start pushing that that throughput to where it could challenge gigabit Wi-Fi so the real driver for switch upgrades and that you might consider n bass T multi gig switching is really if you have some other driver right now at least maybe you have a switch life cycle that you're looking at already replacing them because they're getting old and that they're fully depreciated maybe you have other needs like you need to upgrade for POA reasons to just power the new access points or maybe you know during this other replacement cycle you're looking just future proof your network because you're switching equipment lasts much longer than your typical Wi-Fi deployment so maybe your Wi-Fi equipment only lasts three or four years before you want to replace it and your switch infrastructure you're looking at keeping four five six or seven years and you want to plan for the future and you're going to go ahead and replace it now you might consider multi-gigabit in order to to solve that future proofing scenario if you don't have an immediate need for some other driver go ahead and wait you know don't be an early adopter unless you really just want to play with it second thing I want to talked about on this this webinar is why throughput may not be the best metric to talk about for to measure on a Wi-Fi network so peek through put it the myth that it determines wireless LAN performance leads to a couple of false premises and and potentially some bad decisions when you look to evaluate your bio Wi-Fi network it leads to buying the vendor with the highest tested throughput even though that's not a realistic scenario in your environments it leads to using the widest channel with possible oftentimes because that's the default and the vendor out of the box and if you don't know any better or you weren't you didn't realize that you may have just left it the default and that can cause a lot of interference issues and channel planning issues that degrade the performance of your network and also it leads to focusing exclusively on your access point capabilities and ignoring your clients and since Wi-Fi is a shared medium a large amount of the performance has to do with your client capabilities as well as your access points so you need to have more focus on the clients that you are purchasing for your environment if you do have control over over some percentage of those clients so why is throughput a bad metric for Wi-Fi a lot of it has to do around our history and our experience as network administrators with switched Ethernet switch Ethernet has a consistent date link data rate you plug in you always get that same one gigabit per second for instance a speed it has consistent client capabilities you buy a 1 gigabit per second Nick it always has the same capability no matter which one gig Nick you buy that is going to perform at one gigabit per second or close there there too there's no contention because it's a full duplex switched Ethernet network we're long past the days of hubs and and shared Ethernet and there's very little overhead on a switched Ethernet network and all of that leads to throughput being closely acquainted to link you zation and so if you think I've got a 1 gigabit either link to a client or one gigabit link between switches if I see a throughput if I'm trending throughput on that link and I that's very closely equated to my link utilization and I can start planning for growth around that and that's a very good indicator of the capacity of my network if I'm you know seeing average throughput on a internet pipe or on a inner switch link of 750 megabits on a one gig link I know I'm not about 75% utilization and I should start planning for growth on Wi-Fi it's completely different you have an adaptive link data rate client shift data rates all the time as their signal strength changes you have variable client capabilities so a smartphone does not perform the same as a high-end laptop it's not the same as just having a one gig Nick in any computer that both clients I let's say both a smartphone and the latest laptops may claim 11ac capabilities but in reality their performance characteristics are draft drastically different the laptop may have three string sport and the client may only have one stream support they may have different chipsets inside that have different radio characteristics such as receive sensitivity which determines how well they can hang on to a data rate and stay at a high data rate rather than shifting down to the lower data rate contention is very prevalent so as more clients come onto the network they have to share the bandwidth of that access point and contend to get have access to transmit this leads to contention overhead so the the there's a significant amount of overhead on Wi-Fi networks because of positive acknowledgments retransmissions the medium contention when you have a large client density so all this leads to throughput not coming close to equate to link utilization or capacity on your network I could have a very low throughput but actually very high utilization on my network if I have a lot of low-end client devices in the same respect i could have a lot of three going through my network but if it's a lot of high-end client devices I could have a low utilization through my access point and so the real the real metric for utilization and capacity on your network is airtime how often you know is the network busy versus idle and so throughput is just not a consistent measure of wireless LAN performance or capacity a couple of examples and this is really where the rubber meets the road I can show you here four different scenarios where each client is offering the same amount of throughput on the network in this case 10 megabits per second but that results in drastically different amount of utilization from an airtime perspective on the network and overall capacity on the network for instance a high-end laptop with a very high signal strength and data rate might only consume a very low let's say four percent airtime utilization for that 10 megabits if that same client moves further away from the access point and has a little bit worse signal strength in it data rate shifts down that same high-end laptop may then consume much more airtime or much more link utilization on that access point or on the channel for the same offered load of 10 megabits a tablet which has maybe two streams instead of three consumes a different amount of airtime and us one spatial streams smartphone that is even lower capable even with the highest highest signal strength possible on it will still consume more airtime than than other devices given the same variables so just the key here is that you have to take a lot of client device capabilities as well as the environmental conditions into account and throughput really doesn't track well or align well to those conditions so if you're trending through put on your network it may not indicate high or low capacity you really have to know the surrounding context so the reality is instead of focusing on throughput I would like and I would advocate for everybody to focus on latency on the wireless work and Layton sees really what determines Wi-Fi performance there are three types of latency Geographic delay is just it's physics how fast is a Wi-Fi signal travel between my client device and my access point there's nothing that we can do as Wi-Fi administrators to change the laws of physics to make that that that RF signal that electromagnetic magnetic signal travel faster through space serialization delay is really how long it takes us to modulate the data over the network and to get those bits through that's really the same thing as our data rate it's just another another way of perceiving it or or of portraying it our data rates and our bandwidth and throughput are ultimately just a function of latency instead of really thinking them as a separate metric and then third is our variable contention delay and that is because Wi-Fi is a shared medium sometimes devices have to wait to transmit because other devices are using the medium and the medium is busy and that can spike especially when you have the high density Wi-Fi environments client devices can take on average a lot longer to get access to transmit and get their data through and if you've ever been around any type of networking for a while you know that latency is a huge factor in the amount of performance that you can she achieved even on a wired network this is big and when planning for instance you know on fiber optic networks you know if you have a certain way and latency across across your your link it's going to impact the amount of throughput you can get same on a Wi-Fi network you have more latency and you're going to end up with lower overall capacity so to reduce latency again we can't change Geographic delay we've improved serialization delay over time which are seeing in this graph we've been able to drop that serialization delay by increasing our modulation and our data rates through every iteration of the standard and this is how Wi-Fi has kind of historically grown to higher performance levels is that we've introduced higher and higher data rates that really dropped that serialization delay two fractions of the amount of time it took originally so through 11 be with 11 megabits to 11 a and 11 g with 54 megabits to 11 n with 450 megabits and now to 11ac with 1.3 gigabits or 2.7 gigabits per second that's have been a dramatic increase in the amount in the amount of data rate or the hot the speed of that those packets being are those bits being sent over the network the reality though is that we've improved those data rates about to their limit today we're using a very high order modulation with 256 quam and like I said earlier you have to be very close to achieve those highest data rates you have to have such a high signal strength that it's only possible usually only around six to seven percent of the time so there's not much room for improvement left with with data rates and improving data rates so what's left if we've knocked out Geographic delay weave draw we've improved serialization delay and data rates as much as we can the only thing that's left to improve is that variable contention delight and to make sure that we don't have clients intending for bandwidth too much how do we do that how do we make sure clients don't contend with one another for that shared resource and we make them the most efficient we do that through two things the first one is to keep clients at higher signal qualities through our SSI and snr that keeps them at the higher data rates and for a given offered load from a client they will consume less airtime the network will be idle more often than otherwise would have been and that translates into supporting a higher client density and supporting overall more aggregate capacity on our networks so design your networks for a high quality signal strength it's unrealistic to design potentially for the highest signal strengths to achieve those highest data rates everywhere but you can practically design for a good signal quality of neg 65 or sixty-seven throughout your environment and also maintain low interference levels between access points when done right the second method to keep latency low is to segment clients in two different collision domains put clients on different access points operating on different channels through frequency reuse and the smaller and smaller groupings of clients you can get onto an access point the better and better perfect performance you can guarantee nothing new here the problem with segmenting clients comes into the amount of spectrum we have and the amount of channels we have to reuse because that's a finite limit our spectrum is our as our finite resource that were that we're sharing and so until we either get more spectrum or leveraging all the spectrum we have available to us for instance with DFS channels those are the only ways that we're going to be able to improve this situation you can also improve it by using directional antennas and using high attenuation objects in your facility like if you have high high loss walls those are perfect for sporting higher capacity because they start to attenuate signals and segments ApS from one another so you can have you can start reusing those channels more often and once you can start reusing channels more often un can end up supporting a higher amount of capacity this is why we can get higher capacity in indoor environments that all have a lot of walls and attenuation as compared to a stadium environment which is much more difficult because it's open space and those access points can all hear each other and start and you can't really reuse the spectrum without them interfering so overall when you start doing those two things to reduce latency you start need to the next thing is you need to start trending airtime utilization to understand when your network is becoming highly utilized as well as when you need to plan for growth so x and net management system start trending airtime utilization on your access point radios and understand that when they start getting highly utilized you need to start planning for higher capacity by adding more aps on non-overlapping channels without introducing co-channel interference or you need to start leveraging new spectrum potentially that you're not using if you're not using certain channels already the breaking points for airtime utilization on a Wi-Fi radio really very out based on the type of traffic because for instance real-time traffic like voice needs that regular access to transmit and when there's a higher airtime utilization it starts introducing the latency and jitter that impacts the user experience so the threshold is typically about 80% airtime utilization for just data applications on your network and really if you have a mix of data and voice you might start being concerned more about a fifty percent threshold on your airtime utilization on the radios because that's when it would start impacting voice quality thirty-five percent there it's just shown it when you have a majority of a voice deployment but in reality very few Wi-Fi networks have mostly voice over Wi-Fi usually it's a mix of voice and data but if you had a pure voice over Wi-Fi network you might even be looking at a lower threshold around thirty-five percent airtime utilization because after those thresholds latency starts increasing dramatically as well as retransmissions use your network management system to trend this over time and and make sure your alarming when those thresholds are being approached so you can be proactive and know when you might have a capacity issue on your network and finally you know I want to get into Wi-Fi design because a lot of this comes down to reducing latency through keeping clients at high SNR and segmenting clients on two different ApS comes down to your design and just adding more aps where you think you need capacity is not a good approach if it's if new ApS aren't integrated into a channel plan to keep co-channel interference to a minimum you could be exacerbating the problem rather than improving the situation so a proper Wi-Fi design should always be performed that means you know the capacity is driven by two main factors again frequency were used between X points make sure that they're not operating on the same channel unless they can't hear one another and second available airtime within an access point of the clients connected to that radio how often are they using the network and how often is the radio you know the air time being busy versus idle on those radios and that may show you areas within your network that are more highly utilized than others where you know just the capacity needs to be higher in those physical spaces so the takeaway here is really design and validate your your networks and that can prevent those underlying issues especially as you need to grow your design objectives really should be four fold the four main things to understand when you're designing a Wi-Fi network is coverage quality what signal strength do I want to be able to guarantee throughout my environment coverage overlap for roaming co-locating ApS to meet capacities so if you have I density or high-capacity physical spaces maybe you need more than just one access point to provide the high quality signal you need multiple access points on different channels to provide the amount of capacity you need and forth minimizing that contention through frequency or use make sure those interview those aps don't interfere with one another you can do the design and a couple of different a couple of different ways the two most common are predictive modeling and a pee on a stick both have their pros and cons for instance predictive modeling has variable accuracy based on how much rigor you put into drawing walls and accuracy of the attenuation of those walls it estimates are propagation and but it's great for what if analysis so you can very quickly move aps around and see how it might impact your interference and your capacity on your network a pee on a stick however or on the other side is highly accurate it gives you the actual RF propagation through objects in your environment but it's very time consuming run different scenarios and figure out you know how you need to design your network if you need to move an AP 10 feet here or 20 feet over there or into a different room how that impacts your design so what I say is really consider a hybrid approach consider doing some a pee on a stick but not pervasively and then using that data to improve your predictive modeling so what I usually do is I'll usually take and do a pass at predictive modeling and then I will go do an AP on a stick on ten to twenty percent of those locations in in a facility and I'll look at what actual RF propagation looks like through an environment so here you see maybe i didnae pee on a stick in one location in the corner of this this office space and at a power level that you know maybe I play with a little bit or maybe I figure out where I'd like that power level to be to minimize the propagation through that office I settle on a certain power level and I know how r f is going to to flow through that space what I can then do is I can use that to work up a predictive model and you know make sure my predictive model matches that same propagation characteristic that I actually surveyed so put in your first AP on the predictive model tweak the walls and the wall attenuation values maybe tweak your your attend uation areas in eka how for your free space path loss and make sure that you know your aps start to actually that are simulated actually look like the propagation that you surveyed at those subset of locations and then work up a complete design on that and you're fairly confident that your design is accurate and then after you deploy validation is key always always always do a site survey after you implement the network to make sure that what you've implemented matches your design you can identify the deviations from your design to knit and learn so here we see the same network potentially I designed it and I didn't have any co-channel interference in my predictive design but I put it into the net where I install the network and I do a survey and oh look I've got all this interference what's going on oh maybe I forgot to turn off a subset of the 2.4 radios I made a human error or maybe things were just a little off and I wasn't as accurate as i had thought i was going to be so i can actually tune that maybe turn off some of the 2.4 radios and drastically improve the same situation just by doing that so we're now i have a well-functioning network and you need to identify those after installation to make sure that what you install matches what you decide so with that I think will go into a eka how demo alright thank you so much Andrew great stuff so let me quickly switch over to my eka how site survey software and for those keen observers you're noticing that I'm not running it in any virtual machine or boot camp on my Mac I'm running it native on a less time recover you get your hash on best I someone kind of mouth here at ekta how happened to you know show this to me today and allow me to install it on my machine exactly these are only handed over their security over a thumb drive so yeah no beep was transferred wirelessly it was sneakernet no Wi-Fi deployment eggs yeah so I just like to run you through a basic Wi-Fi design using hecka how site survey so we'll start up a new project and add a map or our blueprint in this case we're going to actually open up a CAD file and we're going to automatically use at the house Wow wall optimization well with a little hug lining reserves well outlining their group actually that you came up with a better name in so we've brought in our CAD i'm going to go ahead and just pick which layers i actually want to bring in yeah yeah so I just want mainly the walls it's the background map right yep I want the windows I want the elevator shaft exterior walls the elevator shaft and the doors I don't care about any of the other cat content like solo at it i'll select the wall type for each one so the doors i'll just do a Hollywood door I've got an elevator shaft I can do it's nice that Kyle has all these built-in so it's not really complicated to figure out which ones which could we order them finally Zoe's wool dry yeah yeah so i'll do a concrete wall on the exterior interior walls i'll just do a drywall and the windows I will do glass window interior and we'll go ahead and click import and the scale automatically is derived from the curve as well yes very good crunches numbers take some time so we'll let this go for hopefully not alone and uh hopefully no beta version you know trashy is happening anything like that not that we ever had that not even know you betta forget don't like how so good there's no beta craft yeah yeah exactly nothing ok so it's brought it in let me zoom in a little bit so you can see it a little better so you can see all of my walls have been drawn automatically based on the cab file sweet I like that I like not having to spend hours upon hours drawing walls yeah yeah if you've ever been there that that's horrible ah so why don't I draw my coverage area and we'll we'll throw some eye peas in there right alright so we would either do it or manually or get a starting point by using the order planner so that's what we're gonna do it right yeah so I'm going to draw my coverage area where I want the auto planner to assume I want coverage and capacity and then we're going to go ahead and have it auto plan I'm gonna skip some of these corners just so make it easier but then we're going to have Auto planner go ahead and plan to make these for me you're pretty truant with the tool I mean have you gone through the host certified survey engineer of course by any chance I have I am an Ekka house certified survey engineer number something or another I don't know what my number is okay I'm sorry so I've drawn my coverage area now i just clicked the handy-dandy auto planner icon and i will plan for a signal strength of pretty high think 67 and let's look that's a well-functioning network i'm going to do an 11ac network I want to plan mainly for 5 gigahertz I'm gonna go at a little bit lower power level than the default yeah i'm gonna go 12 and a half milliwatts and i also want to plan if we're going to go 25 on the 2.4 so you want to reduce that quite a bit to kind of associate but I'm more likely to associate 250 gig because even though the UI is pissa you know it can be misleading but you can actually configure the treasure cover to for sure from sure so and then i'm also on a plan i'm gonna plan for 40 megahertz channels on five Gators because i like the higher bandwidth 40 megahertz oh I'm gonna see if I can taste taste a man who brought the blog of game store or the wider channel is previously well no I do not directly against them just to be cautious i know i'm a 40 megahertz by default guy i 80 megahertz it's tough to justify and sometimes i do it all more than sometimes a large percentage of the time i do have to drop down to 20 yeah but i like to start a 40 and see if i can make it work very good socially nice more likes yeah we're really HD well and i would say i also like you sporty because i like to use all of the DFS fans and all of uni uni bands in the u.s. because i have access to all all those channels yeah you know if you man if you're somewhere else like in europe or somewhere where you have fewer channels you might just default 20 because you don't have enough to reuse but right i'm gonna go ahead and click create we're going to see what it comes up with and by the way your blog has awesome stuff on respect to my location and channels and all that so I'd refer to them more than once cool so it plopped in a fair amount of a piece here and look no no hallway placement either unlucky close yeah but they could be probably more into the room oh that one's that yeah that one's in a storage area I think I might use I might move this one out of a storage area and maybe into a Oh take up the wall oops yep hold on a ID click the wall not the AP there we go maybe that one up put in the center of the room this one up at the center as well do you think the number of ap's is roughly correct what it came up with I don't know yet let's let's see what our coverage and interference looks like so that looks good from a placement perspective rough so let me go ahead and let's see what a 5 gigahertz coverage looks like hey look I have coverage pretty much everywhere yeah you know I'm 24 well obviously yeah yeah that's five lets you for I should be you should be even higher yeah a little bit you want might be able to even to pull up don't be savoring some of those basic CCC on yeah let's take a look at co-channel interference so that's channel overlap look at that 5 gigahertz oh look 40 megahertz is just fine i have very little channel interference maximum too yeah it looks like maximum two might be overlapping in a couple of small areas but choose not bad choose pretty good I don't have to get perfect yeah let's look at it at 2.4 let me increase my limit a little bit layer 24 looks a little worse so I've got a maximum here of what for me on yeah it looks like four in some areas here I may want to disable some radios and from food through usual disease don't generally live right I yeah we're with a pop up yet channel 11's the worst channel 6 has got three as well let's look at channel 11 this AP is on channel 11 maybe I want to go ahead and disable that 2.4 radio um maybe I'll disable one other here on channel 11 and maybe I'll disable a channel 6 here somewhere there's one right at the scenery yeah yep we could do that one let's see what it looks like like now okay my eight my co-channel interference cleaned up quite a bit let's make sure i still have good signal strength throughout the environment cuz i'd hate to disable radio then have a coverage gap right but I'm still good it looks like I said that uses Evans oh yeah you're good so that's kind of cool i mean that's what that's the power of eka how right i mean i can do a wall optimization wizard by a while outline lizard by automatically importing a CAD file don't have to draw walls do the auto planner to place my aps make a few tweaks and i can come to a pretty solid Wi-Fi design pretty quickly exactly and then now if you were you that you were doing your let's say standard you so i know you will do the hybrid approach right so uh so right right behind this with some a piano speed measurements and kind of optimize the whole affiliation value is based on that because these are the intonations of these they're usually pretty close but they may not be perfect right so this would be my initial take in a predictive design I'd go on site now and maybe of these well how many ap's do I have you know 15 or 20 here 21 I might serve a you know like three or four of these with a pee on a stick yeah and then what I do come back do is compare what I surveyed with individual ap coverage models in the predictive and I try to tweak the wall attenuations and the attenuation areas to make the 20 line and improve the accuracy of my predictive model exactly so maybe in a future webinar will go through all of that like how you do to add assignment incident yeah I really I really like your methanol apologies it is a quick way to measure most of the walls and I'm kind of counting so super accurate predictive plant by utilizing field measurements yeah so um I think that's all we had for the webinar do we have any questions that we need to cover yeah so if you're uh you know hanging out online go ahead and submit any additional questions through the chat dialog box and we can try to answer them 