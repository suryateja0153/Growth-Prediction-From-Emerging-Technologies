 [Music] welcome to our breakout session on conversational AI best practices of building BOTS my name is Elaine Cheng and very honored to co-presented session with my colleague fish walk so both of us are from the al-jabbar service team our team together with a lot of partners have worked with many customers around the world of fielding bots and then in today's session we're going to share with you the best practice we've learned so nowadays bots and conversational AI are transforming how people interact with computers and how business provides services to their employees and customers across all different languages couch hosts and industries so let's show her four hands how many of you have built BOTS great how many of you believe that you know how to build great BOTS not a lot ok so what we're hoping is by the end of this session a lot of you'll be able to walk away with the answer for that question how to build a great part so to help companies across the world to build their conversational AI for their digital transformation journey two years ago at maxsa build conference we announced the public preview of Microsoft bot framework then last year we announced its general availability as odd robot service and in the last six months a drop our service has achieved Enterprise compliance including having successfully completed audit for ISO PCI HIPAA and most recently sock 1 & 2 so this week at the build conference we have announced major updates for Microsoft conversational AI tools so a lot of you probably all have seen the different sessions throughout the build you can also read more details in this particular blog on our website we're very excited for the great momentum for conversational AI we have over a thousand companies across the world fortifying their business with our Jabar service and you can find a lot of the detailed customers case studies in the custom start Microsoft comm let me show you a few examples just to see how bots are used in what scenario so the first one I'm going to show you is the whole bot in Microsoft teams so in Microsoft teams you can go to the app store and there's a bot category and you will see a lot of bots here one of them that I use a lot in this whole bot so let's take a look so the whole pod is integrated with Active Directory max or graph exchange so it can help you to really navigate and this is a very typical employee productivity scenario it's easy to use so in the textbox you can actually see the list of sample Chris that you can do with it and it doesn't just only do the simple who is this person it also does some interesting curries such as who knows about this particular part a topic for example who knows about our customers and one of the common scenarios a lot of people do is like you know who was in a particular meeting with so you can easily use this and say who was in the meeting about food booze and it will search your calendar and then get that information very fast for you so the second one that I'm going to show you it's called Eva which stands for executive virtual assistant so this is a bot that we use in the Microsoft executive briefing center so that's where we host a lot of VIP customers across the world when they come to Microsoft headquarter or other different places this particular one is the one used in Redmond so you can see the different scenarios this can help when the visitors come to the center it can help navigate these directions or it can actually help you to get information about the particular meeting or briefing your aim it's also very adapted to the user contacts that you can do multi-language so I can ask questions to tell me a story about Microsoft in Chinese cows or you go way Rhonda shot who sure let's see why will tell me so it's actually one of the tradition at Microsoft is that we provide free beverages and every year there over 23 million and drinks and the most popular one chocolate milk and orange juice so you get the idea it will actually help you get some interesting facts about Microsoft when the people are visiting and the certain example I'm going to show you it's flow for progressive so progressive is one of the major insurance providers in the United States so in order for them to take advantage of the increasing use of the mobile channel to interact with the brand they wanted to build a jackpot so they worked with our Microsoft service team and then picked this actually to the Microsoft band to that tree Facebook Messenger so let's have a conversation with flow so one of the things about progressive is they're really well known for this iconic spokeperson flow who is funny insightful and also friendly so they also wanted the same consistency personalities to show up in their chat bot so you can see that when you actually get greeted by flow you were actually already in the conversation showing you some of that personality flow can does a few things it can answer common insurance questions can also help you get quotes so that's a typical task completion scenario so if you let's ask her who are you you see what she will say so she status she's actually a unique on having tackle eating number one insurance plan so you can already see that it also used a little emoji so that's kind of the how personality is really showing up in the chat bot so let's summarize the few examples what do you think makes a great butt is that how much AI services it uses is it whether it actually used button or cards is that whether it's actually use boys or not great bus is very similar to create website of web apps one thing that they have to do one thing very in common is that they have to provide a delightful user experience so let's break that down so it has to provide valuable experience so that actually address a particular user need and solve a problem effectively so in the who bot so you see that how it's actually addressing the employee productivity scenario in the IVA but that's really addressing the user need when they are so visiting the max of exactly briefing Center in the flow but it's really addressing the insurance needs a gray bar has to be accessible what do I mean by that it's really adaptive to the contact to the user to the environment and also it's easy for the user to naturally know how they can use the bot and a great bot has to be effective that's actually better easier and faster than the other alternative experience otherwise why should people choose a bot so al-jabbar service provides the most comprehensive experience for creating the conversational apps a typical bot development workflow including planning building testing publishing connecting and evaluation in today's session we're going to focus the best practice especially in the planning stage build and testing stage and evaluation so let's get started at the planning phase so we talked about a great bot will provide great user experience then what makes that experience so in the last few years we see a lot of developers building bottle our users using BOTS one of the common mismatch we see is what the developer think the users expect and what the user actually expects it's very important when you're starting planning for a but to think from the users perspective so the communication between a bot and user what user would expect from the bot is what I say would be understood what I received at the response is a profit and what I get as a service is delightful and if I live and when I come back that context is carry-forward so where I left off is really remembered so they have to design such experience so there are five best practices that we want to talk about in the planning stage number one form a multi-discipline team number two understand your users in order to identify the but use cases number three create bot measurement plan number four define bot persona and number five design the conversation flow after those when you define the experience right then you can build that experience in parts and start simple and layer in sophistication we're going to show you how suppose are no different like a apps or websites that having a diverse team is very important and this is not saying you know everybody government has to have this exact same team the point is actually really having the diverse team take an example of the flow chat bot in that particular development so this was a the proof of concept was built by our Microsoft service team for progressive and in that five-week engagement they had full two full-time developers one full-time designers and one part-time they're inside consultant and one part-time p.m. so after we formed the diverse team where do you start so we really recommend that you think about to take a design that approach to start understanding the target user in order to identify the bot use cases so who are they what had a different range for your users and what are their objectives challenges needs and expectations and then where are the potential use case that the bot will add great value so this is a tool that we use in some of the pod design workshop so this helps you to quickly identify the full range of users and then what are their situations settings and environment and then what are their tasks then after you kind of identify this then you can prioritize which one of them the bot makes most sense and also if you really do this in a design workshop it's really recommended that you have cope with this with a diverse set of stakeholders like across all your organizations like if you're building our customer support bot not just owning including the customer support team you really want to get other teams like including in an operation IT marketing or even legal to make sure that you have that diverse understanding of your user and it's also important to really spend time with your actual user so if it's Co Center spend time in the call center listen to the cause that will really help you to build the true empathy of the user to make sure that you really know what questions they're asking how they're asking and also what tasks that they really need help with so after you really identify those use cases then it's a good idea to start defining the measurement plan so the importance of having the measurement plan in the planning phase is that you shouldn't think of analytics as an afterthought because that is a common thing that a lot of times just like app development like you develop something and then later on oh I should measure it if you are doing this at the planning stage then you can really help to know this is the use case and this is the success metrics they're after that the very important piece about bot is defined about persona so any bot is really representing your brand your your product your services so if actually some companies spend a lot of times to train their customer facing staff to make sure they know how to talk customer right you know what you say what not to say and if things goes around how to act then the same thing really you to apply to the bot you need to really think about how would your bot represent your brand your products services and what I'm saying here it's not just for external facing but because even for internal employee facing right let's take an example at HR bot that will represent your team service the HR service so it's also important to think how did you design that personality how did you design that persona to set the right expected user expectation and then there are a few aspects of this so how does the above look in the past case it's really the part icon that's usually the first time that your user will be able to see it right whether it's a company logo that's setting a professional tone or whether it's actually the same as consistent with they are consider I can't explode person in the flow case right and now what's the name the name is how user are going to find your bot and also they may call your bot in that name right so again what's the expectation you want to set and how does it sound because but unlike the other website or app and experiences it doesn't have a lot of visual elements for you to play with so it's all through the conversation so in order to really design that home voice right it's very important and then how does the bot respond in different situations for example like you know no matter how sophisticated how smart your bot is there would be questions that the pub will be able to answer there will be tasks that the bot won't be able to complete then what would you do in that scenario would you hand over to a real person or would you find some other ways to hop the bot so after you kind of design that kind of bad persona get the personality right then the last stage of the planning phase it's important to think about how do you design your conversational flow there's two important aspects I wanted about here why is the user interaction modality and then the other is dialogue and depending on the scenario you should choose appropriate one so in this particular picture it shows the increased complexity to the right it doesn't mean like for every scenario you have to get the most complex one so the more complex the more effort you should spend in the implementation to make sure that you can really design that experience well but it's really picking the right one that's important so for the user interaction right there's many different types of that it can be tax can be cards or buttons can be speech can be custom custom can be custom app custom website or even custom device or a combination of those kind of different user modality so depending on the different scenario how do you pick the right mentality right is a user already in the messenger app like Facebook or apps so users are already very familiar with that typing experience oh it's the user in the tablet or mobile phone factors so in that scenario they are already very familiar with navigating their way getting their task down by clicking and tapping right and also a picture really is worth a thousand words so in certain scenario you really want to communicate in that way and also another scenario is like you want to limit the different choices right like when you say welcome how can I help you you want to actually give a few choice it should set the right expectation what you can do so in those scenario it really makes sense so then when it's a proper to use voice it's very to some common scenarios like when the user is in a hands-off scenario or the body is integrated was a device that has limited or no display surface then it's very suitable for that so the takeaway is that you need to depend on the scenario and also it's not saying a bot have all the scenario the same a bot should actually support a combination of those depending on the particular term in that conversation the other important aspect is about the dialogue so there are different types of dialogue and this is the common types very obvious one is the one turn response that's kind of the question-and-answer pair but that can also sometimes kind of be the one turn chitchat like you say something and the battery small something but in that particular case neither the user no the bot would actually have any follow-up questions so that's kind of what we mean by wanting response and the second type is really about more for task completion right so have the guided assistant dialogue so in that scenario the bot requires collecting a bunch of missing information in order to get a task done so to do that then that's how kind of you design this kind of guided assistant experience and also it's typically in that scenario it's multi turn but it also depends if the user already giving all the information in the same term then you don't have to do that so the common scenario will be ticket booking product purchase or form filling then the third one that actually could be one term response or actual guided system but it's more that it's actually adding the contacts it could be the context of the user context of the previous term or context of the environment then after you kind of choosing the right modality and then the right dialogue then you design that conversation float so there's actually multiple outputs that you can have it depends on the scenario that you want and the depending on how your team likes to so one of the common output that we see is a kind of like you know they in the design workshop they will start storyboarding this on the whiteboard or some will actually turn this into a video and do a wireframe on that or it could be actually using the check down file the visual code demo later that we support so now you've kind of I walked through the five steps of planning so after you kind of design that now I am going to work on visual on the stage and then talk about the best practice in building and testing thanks Elaine all right so I want to talk to you guys about best practices that we have been able to distill for building and testing your bought and let me make sure and elaine was talking about starting simple and layering in sophistication when you think about building your board your board itself needs to stitch together a bunch of different bought parts bought parts include language understanding QA dialogue language generation cognitive services like vision speech knowledge and more cognitive services help have your board are more meaningful and more human-like conversation with your users but where do you start it's all in a spectrum so if you look at user interaction and dialogue Elaine touched on that quite a bit but talking about language understanding and language generation even those are a spectrum you can always start with the most simple thing for your scenario and then layer in the sophistication as is needed and quite often what we see that developers are using as a yardstick is the feedback loop or the telemetry to tell them ok my user is expecting this particular thing to behave this way and what do I now need to go do to make that happen and then evolve in and add that sophistication so three key takeaways or three key best practices that we have been able to distill for building and testing BOTS start simple and layer in sophistication based on your scenario needs build your bot in parts because if you're if you start by you know all the AI services out there then you can get pretty sophisticated very quickly but you need to absolutely name the core conversation model and all of the AI services can come in an argument that experience and make that better and complete and provide a rich experience for the user all right so for the rest of my talk I'm gonna take you through a journey of building a contoso cafe bot it's a cafe bought for a fictitious contoso cafe company that's based out of Pacific Northwest and let's actually go through the journey of them doing a little bit of planning all the way through to building something that stitches a bunch of AI services together and what that journey looks like and I'm also going to be using the you know several of the new features that we have announced today at not today this week at build I'm sure you might have seen a lot about the cognitive services that are coming up as well I'll touch on a few and there is an entire spectrum on the other and for sophistication but the core of the demo is going to focus on starting simple and then layering in sophistication so let's jump into the demo all right so Elaine was talking about this and what's our no different than apps and websites so for planning one of the typical things that you would want to do is to create mock-ups of conversations between the bot and the user so here in via skirt I have a mock-up of a greeting scenario and here's one for Q&A and question answer and having knowledge is another very critical things that every board should have here's one for who are you because a lot of users might say who are you or what's your name and here's one for booking a table this one is a little bit more sophisticated and it was multiple turn because the bot needs a bunch of information to go complete the task and as you can see these are simple text files so you can use any text editor you prefer and the chat files also support rich attachments like cards and images so in this case I have an adaptive card that I'm including and all of this can be part of your initial planning and iterative design process once I have the chart files then with a simple command-line tool I can convert them into a conversation transcript and view them in the emulator for sake of time I'm not going to go convert every them every one of them into transcripts and in the new brand-new bot framework v4 emulator I've got them all loaded and emulator renders these transcripts using the web chat control this is the exact same web chat control that you can also embed within your own application or website so here's the greeting transcript we did and here's one for Q&A here's who are you and here's the one to book a table while you're in planning and you're sort of looking at all of these design ideas through the team with the team you want to be able to iterate quickly sometimes it's easier if it's you know very clean and you can focus on the actual conversation so we have a presentation more than emulator that helps you do that okay now imagine that you know your design product management and leadership team or happy with the plan and you're just about gonna go build out these four scenarios so the rest of the demo is gonna be focused on that specific journey a good starting point for your board is to be able to use this to start thinking about language understanding and Q&A maker or question and answer part capabilities so Hagen and vias code I have simple markdown based language understanding files that describe language understanding for the four different scenarios that we had identified during planning so here's one for greeting here's one for Q&A and these also actually render as markdown and here's one for who are you and here's one for booking a table and this one even includes entity definitions once they have done that markdown files are great for authoring and collaboration but services typically JSON prefer JSON file formats so with a simple command-line tool I can convert all of the language understanding files into Q&A maker and Lewis JSON models and that's exactly what I've got done here okay as I was as Elaine was saying dialog you know in the spectrum for dialog starting with you know simple single turn conversations going through two guided assistants through two context carry over type conversations is sort of the right way to think about in terms of spectrum of complexity so we're gonna start with building out a simple question-and-answer scenario for the bar and Q&A maker da di is an excellent service for you to check out and where you can point your existing FAQ URLs and will be able to consume that and then be able to provide a knowledgebase of question and answer parts that are automatically generated for you based on that and Q&A maker is generally available now and we also announce that now you can actually point it to PDFs and that enormous amount of information in it and we can still crawl through that and and come up with the seed of question and answer virus that's based on that document that you pointed us to so let's take a look at getting set up with Q&A maker another thing that we've done this build is we've brought the full power of Luis da di and Q&A maker dot ai to the command line so you can actually adapt these tools to fit your own end-to-end development workflow so in this case I'm just showing that using the simple command line tool I can take the output of the previous tool and then pass it in to create my initial bootstrap model for Q&A maker the other thing that we have also spent time on and we have heard as active feedback is as you're building a bot and then as you keep adding in services it gets increasingly complex and it gets really hard for you to keep track of all the services that your bot depend on so the new CLI tools as well as emulator make it super easy for you to keep track of all the service references so if you look at the second half of this command I'm taking the output of the create step and passing it to another command line tool called Emma's bot that can keep track of all of these service references in a simple bot JSON file alright for sake of time I'm not gonna actually go create a Q&A make or model here I've done that already and let's see what the code looks like to hook it up but before I do that I want to spend time on two things one is the basic code structure here every single message to the board is an activity and there are different types of activities and every single great bot out there does respond to a method welcome message that's the message that gets sent out to the user the first time ever the user either adds the bot to their context or they start talking to the bot this is super critical when it comes to conversational interfaces because unlike apps and websites where you can have buttons and UI that explain to the user what is it that your app or website can do this is the only way that the user is actually going to know what is it that this bot can do so in this case the cafe board is coming back and saying okay I can help you find cafe locations I can answer some questions about contoso cafe and also book a table the second thing as the best practice I want to touch before we add Q&A maker is as your bot scenarios get sophisticated and complex there could be cases where users and users actually feel stuck like they're like okay I actually want to stop booking the table like give me an escape hatch and so planning for that even before you write any code or integrate with any services is super critical and as you add more and more dialogues you need to make sure that you constantly update the escape hatch and make sure the user is super aware and clear of how they can reset the conversation how they can start over or how can they cancer a lot of what's going on right now so what we call as global flow control commands and make sure that your planning and thinking about that throughout your development phase so I already got that code in here the other thing that I'm also gonna do here is uncomment this code and what this does and by the way all of this code is built on top of our brand new bot builder v4 SDK and it's available in github as a preview so please do go check it out so here I'm simply making a call out of the Q&A maker service and if I have an answer I come back and render that answer if I don't then the board is going to say sorry I don't have any results for you let's try and talk to this board in the emulator let's restart all right so as soon as I open my board and the new emulator I can see as I was telling you the list of all the service references so in this case I've added a Q&A maker model so I can see a reference to that right here and I can deep link into my Q&A maker model from right here within the emulator let's try and talk to this board the some of the questions that we had was who's your CEO this was one of the question and answer bars that we had identified during planning it comes back with an answer powered by Q&A maker what are your locations was another question we had it comes back and work so it's very quick for you to go from almost nothing to abort with knowledge using the power of Q&A maker and it's super easy for you to get hooked up in your code as well all right next up Alain was talking about adding cards in the user interaction spectrum so the first thing was text so we just saw that and the next one I want to talk about is adding card so we announced adaptive cards last year at build and we're seeing a lot of momentum behind this this is a way by which you can add very rich interactive pieces of cards within the board conversation it helps quite a bit depending on where your users are if they are on a particular device or form-factor but they're already used to clicking and typing around or clicking and on or tapping around then cards are very effective cards are also very effective to help orient and get a lot of information in one small interaction so we're seeing a lot of momentum with adaptive cards and we also have a bunch of samples on adaptive cards dot IO do check them out and hopefully you'll be able to use them in your next board let's see how to add cards to this exact same board nothing else has changed in the code the only real thing I'm doing here is to be able to start sending a card with the welcome message the other thing while we are here I want to do is to set up the top-level dispatch so until now only thing that the bots did was respond to give animaker questions and if you didn't have a Q&A maker answer then it was going to say sorry I don't know but we do want the bar to respond back to breeding we do want it to be able to book a table and we do want to be able to respond to who are you so just getting set up with the top-level dispatch and in most of those or all of those cases the board is simply gonna come back and say I don't know that or I'm still learning that this is just to give you guys a sense of what's going on as we are building this body let's go ahead and run this one all right let's try this water so right off the bat Naja's there was a welcome message but there is also a cardinal and I can click on the buttons to jump into a specific scenario and in this case is actually gonna say I'm still learning how to do that and who are you it's just coming back and saying on the cafe board so if I literally typed in hi these were literal hard-coded strings so it's not gonna respond to anything more than that if I say hello then it's not gonna work so it said sorry I don't understand but it's a good starting point for you to think about your outer layer of here are the five things that my board should do in terms of scenarios and get that set up all right next up in the spectrum of complexity let's go ahead and take a look at how to do multi turn conversations and these are the guided conversations that Elaine was talking about in the spectrum for dialogue so here for who are you and booked a table I'm no longer saying I'm learning that because the board has now acquired that skill so for for each of these I'm gonna model them as a waterfall dialogue and there are multiple different ways to model conversations waterfall being one of them you might have heard of form flow as being another one and so you can pick and choose whichever one that you want and that works for you the best but in this case I have decided to go with waterfall so if you look at the actual dialogue for who are you it's literally a waterfall go execute the first tab that is you know if the user says who are you then we're gonna use the text prompt and say hi I'm the contoso cafe board and ask the user for their name whatever the user replies back it's a text prompt so it's going to take every single thing that the user replies back that is not gonna be any more layer of understanding on top and we will just take that as the user's name and come back and greet them and then say nice to meet you so that's all pretty much the who are you dialogue does right now and here's another one for book a table this is a little bit more sophisticated than the other one because we are trying to get four pieces of information so we need to know a location we need to know a date a time and a party size number of guests before we can go book the table so if the user says book a table then the board is going through as of all asking for each of those pieces of information because before it can go book the table so it's asking for city first then date then time number of guests and then it's confirming to see if it should go book the table and then you call into your back-end service book the table and then you can come back and say ok I've booked the table or something went wrong try again later so pretty much that's all we have so but we have gone from a single turn to now also being able to support our multi turn back and forth conversation let's try and talk to this board but make sure this is running it is so now it's going through the waterfall so it's asking for city side Seattle tomorrow say 7:00 p.m. I'm gonna bring two years and then now it's at the confirmation step asking to confirm everything everything looks good and I booked the table the other scenario we did was who are you so if I say who are you then it's asking me for my name I type in my name they pick that up it was a simple text prompt and we are good so we have actually got the core of the conversation model figured out and then now we can start layering additional sophistication on top so let me show you - typical sophistications that are best practices for people to take back and think about adding to your bar so the first one is in the new bot builder SDK we have a very rich variety of prompts because as you saw the previous demo you might have been thinking wow like you know you're using a text prompt to get data and time and a city but I want to be able to set constraints like I don't want my user to pick a date in the past and my cafe is only open between this time window and so the the prompt system in the body builder v4 SDK allows you to do that and be able to elegantly model all of that so all that I've done here is I've added a choice prompt or number prompt a time Explorer and a confirmation prompt the choice prompt is what I want to use when I'm asking the user for a city so instead of using a text prompt I've swapped it to be a choice prompt and still the message that we are using to ask the user is exactly the same and then for booking for asking for date and time I'm using a slightly more sophisticated time explore that allows me to set a bunch of constraints and it can actually understand date and time and parse it and actually give me a result only if it matches my constraints and I'll show you that code in a little bit and then for asking the number of guests we are using a number prompt and then we're using a confirmation prompt to confirm and then we're done the last one is after we have booked the table successfully we can come back with a message saying it's done let's go ahead and try this and see this in action of the bad because we had a choice blonde and we actually did specify the constraints and I didn't show you guys where I specify the constraints so here are the constraints for the choice prom so we were even able to automatically generate a list of suggested actions at the bottom that the user can click on and go and I could do interesting things like I could say one and that did pick up Seattle it was the first option that was presented and our escape hatch continues to work so even though I'm in the middle of the dialog I can say start over and let's try another scenario there and I could say how about Bellevue I'd picked up Bellevue so there is a little bit of you know language understanding matching going on as well let's start over again I'd say book a table and then I could say how about the third one and I'm literally typing in the word third I picked up Renton so a bunch of these natural language based interactions to to be able to parse what the user is saying then as it relates to a specific prompt and as well as being able to set a constraint for a choice promise what you saw now let's take a look at the date time from because that's the next thing it's asking so if I said how about in three weeks from now too bad the board only accepts invitations for the next two weeks and it only does 4 p.m. to 8 p.m. where's that coming from so in my code I have this time x value later which is basically applying a bunch of constraints on the time x prompt itself so here I'm saying okay the user needs to give me a date and time that has to be either this week or next week and it has to be in the evening and the definition of evening is from 4 to 8 p.m. and that kicked in and that's why the board is like okay that doesn't work so let's try something else so let's say I'm gonna say Saturday at 7 p.m. notice what happened there now the board says ok I have this Saturday 7:00 p.m. instead of next Saturday or the Saturday after or the previous Saturday so we've also added a little bit of language generation capability for you to deal with time X or date and time operations so that you can the body can actually come back and confirm yeah I actually have this Saturday if you want to change your mind actually say that right now and this is actually a good practice for the bar to be able to do is to ground and validate and say what is it that it has understood after every single turn of the conversation of course you don't have to include everything that happened before that conversation it's just immediate validation saying okay I said you stay you got Tuesday I said 4 p.m. you picked up 4 p.m. I was just asking me how many people in the party just as with the other choice prompt we're using a number prompt so I could literally type in 5 instead of the number 5 and I'd picked that up I picked up five guests at random location for this Saturday at 7 p.m. I'd say yes and we're good to go so we haven't added any you know language understanding capability outside of what is natively available in the prompt system up until now but still you have gotten a little bit more sophisticated in terms of conversation and the last thing I want to show in terms of a demo is Louis door AI so until now the you know to trigger into a specific scenario you literally had a hard coded message so it was high if the user only said hi that was going to trigger but users could say a bunch of different things that you might want to trigger into that specific scenario so the user could say hello or good morning good afternoon and there are numerous variations for user to be able to book a table so they could say get me a table can you please book a table for five guests so on and so forth Louis is a fantastic service for you to be able to provide a list of example utterances and Louis can build a machine learn model that not only does intent classification so given I use the utterance it can determine this is what the user is trying to do but it can also extract meaningful pieces of information called entities which in this case is you know what's the date and time what's the location and so on and so forth so let's see let's take a look at how to now hook up language understanding powered by Lewis for this board so a while ago I showed you a markdown file for each of our scenario that that you know was a language understanding for greeting and Q&A and and who are you and book a table and and we used a tool to generate a Louis JSON model and so I'm just simply rerunning that tool to bring that back in memory for you and we have also got another tool called lose gen what this does is it can actually take a Louis JSON model and generate a strongly typed c-sharp or a typescript class and this is super beneficial because off the bat we just do this first and then show you what that looks like for every single intent and entity that your bot had now you can call them like you know you have a nice enum of all the intense that's right here and then every single entity is also strong type and so your code is going to look a lot more cleaner and then you're not directly dealing with the results from Louis you get a nice little abstraction there the third thing that I want to show here and if you're not gonna actually run the command but as I was saying we're bringing the full power of Louis to the command line as well so using Louis import application I can create a new application import the JSON model that I have created and just as we did in the Q&A maker case I want to be able to pipe that to a mess board so that now I can add that as a new service reference for my body I've got the lose model setup back to the cafe board code the real change that I have done here is his two pieces of changes actually I created a Louis recognizer and then this is my new Louis gen C sharp strong type class and I switched out all of my case hard-coded statements with specific lose intent so this is a greeting intent this is book a table who are you and for non intent we're gonna fall back and ask if Q and a maker has an answer or not let's try and talk to this board I think this is already running yep it is and as you can see when I connect to the bot I now see the Louis service reference in emulator as well so instead of now being a really hard coded set of things I can see I can say a bunch of variations let me pull up my notes here okay can you please book a table that regard let's start over give me a table you no longer have to exactly say book table that word start over the rest of the prompt is all unchanged you're still using all of the exact same problems that we had so what's your name you no longer have to say who are you that worked and all of this is getting triggered because we had at lewis and it was able to do the internet arbitration very well start over and lasting who's your CEO this is again from Q&A maker and that continues to work so hopefully that gave you a sense for a bunch of new tools that we have announced at build and you know as we start very simple and then layer in sophistication at each stage the the kind of experience that the bots can provide also grows but one of the the few things that we did at the code was include welcome message make sure that the user can restart or start over the conversation and handle like global flow control commands and then do the single one turn conversation with Q&A maker and then as you're thinking about multi turn dialogue make sure that you're starting simple nailed the core conversation model and then you can layer in you know AI services to argument that core experience but two slides think we had just have a summary yep covered all of that so start simple progressively layered and sophistication and build your board and parts and nail the code conversational model before and add the AI services to argument the core conversation model back to you Elaine thank you wasn't that cool so now after you build and tack the bot and then publish it and then connect to the different channels let's talk about the best practice in the evaluate face because conversational experience really provides a unique experience it actually tells you from the user conversation what a user are looking for so there's really three best practices I want to talk about number one iterate with the feedback and really get it out soon don't just really wait till you have like all the different functionality you can really get a limited functionality but get to the user because the user will tell you what questions they are asking how they're asking what tasks they want to get how is and no matter how you anticipate you won't be able to get all of those right like if your user can't even say different languages you wouldn't be able to know so get it out and then start refining it as fast as you can and also start simple that's the same principle even we should have talked about that also applies in the evaluation phase we have the out of box tools for our box for service and also language understand service at least start using that and then give it out and then if you need custom solution then that's the second point that I can talk about you can get there but you don't have to wait till you have all the sophisticated analytics to start evaluate number two focus on business KPI and leverages a custom dashboard so remember in the planning phase we talked about at the planning you already should actually define your success metrics so then back in the evaluation phase you should really review that and also look at your instrumentation to see whether they actually get the metrics measured correctly the way that you are expected and here is where we see a lot of custom dashboards that actually helps because we have the lock Singh application inside a common one that we see it's integration with power bi and now we have the path builder SDK before that's extensible and modular so we expect to see a range of the Analects middle where they'll be contributed by the community so if you actually have any other little middleware that you want to contribute please join that party as well so number three build evaluation into the processor and game business insights from the bots what I mean is here it's really not how sophisticated your analytics tool it's really important that even if you use simple to build that into your process because but provides the unique opportunity that I tell you that it's not just helping to refine your bot it actually helps your overall service because the user may tell you some product or services that you haven't provided right so you may tell you actually the certain part of your business that needs improvement so it's way beyond the bots that we start seeing as a common pattern that business really use patent Alex as a way to gain business insights and in the customer case studies online you can take a look at Dixon car film and telefónica they both talked about that of how they actually gain the business insights from the bot so this is just kind of the screenshot of the Loess tool for the revealed endpoint utterance so what I'm saying it's like you know you really can't start using that if you're really constantly improving your alternatively even with the very simple and you can start simple and already help you get to a part counselling better and then you can also and add phrase LeSueur patterns to improve your Lewis model that way as well and here are a few kind of sample examples that are for the bottle and Excel in the custom dashboard that we see if you use Lewis though of course the very common one is getting the Lewis metric the intent metrics so you can see that's the one that it helps you what are the common questions people are asking and it's important to really take a look at the non intent because that's where you can see we're not meeting the user needs right and then there's so the view at the right on top that's kind of like also a key phrase view that we're seeing a lot of customers using as well and another common one is sentiment analysis because this can give you a good user satisfaction indication right so if this is a common case when you do the integration with the text analytics and then you can get this view and also see the trend view about where does the user satisfaction the sentiment drops and then have a way to basically drill down to see what's the issue and then the other metrics here it's really more scenario specific we talked about you identify the user case and then see what had the business impact the bot can can really contribute then that's where if for example like a customer support but a common metrics people measure is hand over write how much of the percentage is your goal to be able to cover the common questions and what had a complex each issue that you want handle hand over to an agent and in that case we see that people also look at what are the issues that actually are the common case being handover then you focus on that to see whether you can refine that to let the bot take care of a little bit more so next I'm going to show you a demo of a control assistant so you've seen in the previous demo from which work that our report service really allows you to store simple but I also want to show you that we can also support the sophistication solution as well so in this particular case it's an intelligent personal assistant it can be in on a different environment but in this particular one I'm showing an in-car assistant so let me get a setup okay so this is the simulation of the in-car assistant so on the left and right those are simulate the different signals you can get from the car so in the actual UI won't be like this and it will probably have very limited screen place to show but this is really a more elaborated UI to show you how this simulates that assistant so in the car if you are actually driving in the car it's kind of hand off right so that's what we see in this scenario most will be a good help in that modality so let's try so imagine that I'm driving along and I wanted to really save the preference of the heating right now remember my seating preferences sure thing I'll remember your seat heating preferences for days like this I have gathered these settings for cease heat level zero I'm going to name it seat heating level zero would you like a different name no that's okay okay all done note that normally no means no and it's okay means yes but this is how we trained to understand okay that's okay no that's okay it means no so this is how we're language understanding comes in so imagine that I'm driving Allah suddenly there's a yellow light comes up and I want to find out what's that what is the yellow light in my - if the tire pressure monitor lamp comes on in yellow then the tire pressure is off about ten percent or more so this shows a car to display that information what if I'm actually really frustrated and the image input in my voice the particular word will show it being detected in the sentiment analysis it's kind of an active what the happy is that the yellow lights in the dash sorry to hear that if the tire pressure monitor lamp comes on in yellow then the tire pressure is off about ten percent or more sewing I can also help you troubleshoot or connect you to an agent so you can see that this is how you can generate the conditional response right based on the different result in your text and analytics and and the sentiment analysis then you decide a different response and in this case you may want to actually hand to a dealer the other scenario I want to show you is actually how it really helps a productive productivity scenario so let's say that I'm driving that I suddenly have an idea that I want to capture a note can you take a note of course I am ready to capture your memo now press the record button to start recording once you are done recording I will save the note so this is a simulation that I will click the record button but imagine in the car that you will be able to actually trigger that right follow up on the beaut session I got your note please wait while I save it so then it's actually processing this and actually then I will be able to show you later that it will actually add the note in my OneNote done your memo can be found in the memos tab in your OneNote okay so let's see so you can even see that the text is extracted from the audio so this is how the integration of office 365 can really feel powerful scenario and they can all be done by the car assistant that built using our a button algebra Service tools so this is how a sophisticate scenario that can really be achieved using our most comprehensive tools so in this example it really goes all the way to the most most complex so to summarize the best practice of the building bots in this session we really talked about the in the planning phase you should focus on designing an experience not just functionality in the building tasks face building parts and start simple and then they are in the sophistication and learn from the feedback and iterate and evaluate and refine so here are the three breakout session of a conversational area that we showed at build and this is the list of channel line video that you can also see later to know more about the tools we have so at the end I'd like to conclude with a customer touch personal testimonial from telefónica we have become data-driven our conversational VI era lets us put people first we are using artificial intelligence to change the way we are relating to customers and one of the reasons we begin to use microsoft technologies was because it offered an open framework it was very easy for all my development team to understand the tools we can very fast and very easy to move into the used cases we want to develop for our customers using tools like a Shabbat service and ways we keep getting new insights and we are applying them into our core business microsoft VI was a key piece in our strategy because they have the tools the platform the full ecosystem that we needed with that thank you I would be happy to take questions [Applause] we also have our team here so if you want to just stay here and then come here that we have also answer questions here as well so just a question on the dialogue you were building the demo the kind of table booking workflow you were kind of going kind of very deliberately step-by-step through that but can you maybe show like what what exists in the tooling today if you have something where you know you're gonna get three pieces of information at once so if I said you know booked a table in Seattle at 2:00 p.m. yeah you know I might know that the date but I've got a couple of pieces of information there so you're kind of extracting two out of three and identities and then no conditionally prompting for the for the rest of that yep so the native prom system that we have can only handle one entity at a time because it's layered at that level of sophistication okay or a for handling cases where you get multiple pieces of information and one utterance which is really what you're trying to do a good recommendation is for you to have one intent in Luis hopefully in a separate Luis app because Luis is really good with capturing multiple entities in any given utterance and it can come back with that value then all that you would do in your dialogue step waterfall step is to see did you get any new values and then be able to rehydrate that hmm okay so there's not there's not I guess is are there other plans that kind of uh started trying to address that in the dialogue model you've got yeah yep doesn't exist right now you're working on it but for now you should still be unblocked okay cool thanks yeah thank you I was wondering what you have for existing voice models so that you can talk to the bot and come back and what the roadmap is for future things like Alexa Google okay sure so for wise a couple of things right so you can only build a bot and publish to Cortana on cortana as a channel and anything that you do there is also going to be supported through speech but we are also making the vive actually already made the web chat control that you can embed within your own web site or application that supports speech and so you can either use browser speech or you can use cognitive service speech or you can even implement a custom speech recognizer and hook that up for your scenario the third piece of work that we've also accomplished when you go build a Louis model then we take all those occurrences and then Prime the speech recognition system with those audiences so that the speech recognition accuracy is improved as well so you know setting up the stage again starting simple and layering sophistication there is that part that is all be laid for you for you to be able to take that journey and the second question I thought you asked where about Alexa and Google home in integrations we don't have anything to announce at the moment but you know stay tuned to our blogs it's an area that we are actively looking into the thank you great question hi you showed a dashboard it's part of the presentation is this the one you have built it or it is part of the lowest it it will be generated which one is that the D sentiment analysis performance I think she's about the customer the business this one yeah this one yeah this is just examples of the power bi dashboard okay not out of the box one yet yeah it looks very similar to other such so you can publish those actually at the Middle where for our SDK before okay thanks yeah thank you thank you hey yeah got a couple questions one is if you have multiple BOTS its are a way to switch context and and reference another bot to have it run it's it's scripts and then return back to the context that you originally at and you're trying to do multiple bots that are still simplified for having expertise in one particular segment and without you know getting too complex and and being able to reference that and then bring it back into the context of what you were originally talking about right right so there are there are two things there one is as you are sort of building you know different groups of scenarios that you know you might have one bot do you know a good example is if you're doing a booking agent board it might want one half of the functionality might be to be able to actually book a flight yes a different set of functionality might be to be able to get a right to the airport and a different one might be to check whether that's an r8 exam and so what we have right now though is that is actually a multiple T layer problem the first one being we need to be able to dispatch into each one of those the right way so we have done a lot of investment in that space and we have a tool called dispatch and it's available in bot builder tools that once you have built a different Lewes model one for each scenario that it can take in just all of that and create a matter model that you can use to dispatch into the right scenario so that's step one and the second thing that you are asking for I thought was where you can get a piece of information that was captured by the first scenario and then make that available into the second scenario yeah so the the reason changes that we have made to the core bot framework itself you're in control of what state so you can have the dialogue and user and conversational State in your own Azure storage or cosmos DB or whatever you choose you want to have it but we don't have any native support to be able to pass that around except for the basic infrastructure that lets you to hook into the backend database but but then you're in control of state data so you should be able to persist information that you want either across conversations for the same user across conversations or within that specific dialogue depending on how you career code okay do you have a sample that dispatch on so github board builder samples or builder - samples we've got like 27 or so samples in there okay and in my last question was do you guys also have a sample using a Twilio to do an SMS based kinda bot I'm not sure it's already a channel we support oh it is great yeah yeah do check out the dispatch I would love to hear your feedback I'd like to do that okay thanks thank you great session thank you thank you you know two questions one was when you're showing the code there and then you you know created the lowest model and then you replace the explicit intents with the Luas intents and and then you know you quickly also added the Q&A service there as well the couny maker right but actually added the Q&A maker is the first thing it was very earlier so if you could you could just bring up that code of death go set up 10 more minutes so it should be good so this is where we added Q&A maker model which was like the third demo that I should because that was gonna help you do simple single turn conversations and then this code that we added was the exact same thing that I had laid it on so the later on at the end when I added Luis this part of the code stays the same so this this stuff didn't change at all that was already there and the only thing that I did was swapped out to the Luis intent so you know conceptually that's that's interesting so you're really bringing the cue name so you passed a site and then Louis model together right so there are multiple different ways that you can do that I think the matter question maybe you are trying to ask is should I call Luis first and then as a fallback call Q&A maker the that isn't the right thing because depending on how you set up your intense and example utterance inside Luis you might have false positives from Luis where are the questions that should have been answered by Q&A never end up making there and so depending on your scenario if you run into that The Dispatch tool that I was just talking about it can also take a look at all your Q&A models and then create a matter model that analyzes what's in your Q&A what's in your Luis and then it can dispatch into the right place and so we've thought about that exact same problem and so if your scenario needs that but that's not the common scenario that's why I didn't show that in here so if you are sophisticated scenario needs that then we have the tool for you to be able to get that set up to do to more cash or in the multi turn scenario that you're sure yeah you are explicitly managed you know the developers are explicitly managing the state yep what about you know managing the state for ourselves you know like I'm supporting a multi turn natively is that something like you know from like doing inferences yourself and and sort of managing the state for us rather than us having to manage that state is that yeah so one of the things depending again on your sin are you if that's something that is required or is interesting we've announced project conversation learner I don't know if you have heard of it it's where you're basically providing a bunch of examples machine learning model is an AI system and it does implicit state management you can go look at the state and you can hook in your business logic into it but it gives you a bad bond where you're not explicitly managing state but you're just providing example conversations and then building a model on top so it might be a good thing for your scenario again like the matter thing is that we have the breadth of tools and breadth of solutions but it isn't that like you know one size fits all and it really depends on the specific scenario you're trying to accomplish we do have you signed up for that's an experimental that's right it's available as cognitive labs capability and the final question for you Elaine as you talked about testing the bots is there any tooling available where I can you know maybe another bot which you know goes through my conversations and tries out all of the edge scenarios and chaos scenarios and tells me how well it is doing any any automation or framework that you know of which will help me evaluate the bot well then you know learn on the goal I don't think we have any particular framework on that yet right you're more looking for unit and integration testing kind of experience you know generally generate the test data for me and test it and tell me the quality of the bot and help you improve the border yeah so the thing that we have right now those the bot framework emulator that you saw in action one of the things that we are also looking at is possibly and it's already available as open source project on github and so we want to take what we have seen some of our developers do is also take the core of the emulator and then use that for you know a batch testing or being able to replay a bunch of conversations and see how the conversation model is performing but we want to be able to get to a point where we can mature that into a package so that you can use that for your testing needs but we are not there yet thank you very much sure thank you right can I jump in for a quick quick here answering that from the bot framework team there's two things that I don't think came through in the in the presentation one is that the emulator loading up a transcript really gives you the ability to look at a at any point in time which means you can take the logs from your actual conversations with users and bring them back and load them up and debug them as if they were live and the the other thing is that the v4 SDK has been completely refactored so that you have great flexibility over how you run your code and that includes the ability to drive unit tests use the transcripts from your logs or generated transcripts to be able to drive unit tests and so we have a lot of flexibility in the new v4 SDK which is in preview in our github repos thanks doc I got a couple of questions one is uh when we using lose app if we have unknown utterances I am like I mean some random utterances does that app Lorne or store that and score accordingly to the intent or do we need to manually do that now so to start off with when you use Luis as an example for your initial intent determination loser by default every single app comes with a none intent and the intention of the non intent is for you to be able to add utterances that explicitly you know should not should be things that your board should not handle and as you see you know if once you get your board out that'll always be cases for false positives and so that's the thing that Ellen showed where you can look at the active learning system and Luis and review all the utterances that users have said and then you can continue to classify that as a non intent there is no right answer in terms of how many author answers you need to have in none before the machine learned model can come back and do the right thing that really depends on the scenario but what you have typically seen is if you are able to seed it with about ten other answers that are varied enough that are things that you're bought absolutely cannot do and if you add those to non entrances and the model actually does really well beyond that point but until then you will have to do you do have to manually add them there any scoring methodology that would probably automatically make it on in turn I didn't quite understand that so for the utterances it it probably uses some scoring method right to say okay this is prop proper intent and this is not right so when you call Luis you actually get a confidence score associated with the actual results returned by Luis so it is it is okay to start with doing a confidence score based arbitration but typically where that doesn't end up being a best practice is because as you retrain your model all your confidence code change so it's it's a moving target really to use a score to be able to do the determination okay my second question was a the bot app is it always like waterfall method to enter to the bot or can we do random questions like you can do random questions depends on how you model the conversation right like so if you are doing single turn conversations then you can do random questions but if you're more asking okay if the user is in the middle of booking a table and then they ask something else can I handle that you can totally handle that like the waterfall system has a concept called replays so you can replace you know the existing dialogue stack with something new and you can also even come back and resume this previous conversation that was ongoing or you can just go do the do the other task and not come back to this you pretty much have all of that flexibility we can control that flow or is it you can control that flow yep great questions thank you any other questions Elena and I will also hang out down here thanks a lot for joining us and I hope you had fantastic bill thanks everyone thank you 