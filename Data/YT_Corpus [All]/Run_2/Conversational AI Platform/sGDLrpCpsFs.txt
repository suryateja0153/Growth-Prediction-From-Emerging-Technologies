 hello welcome can you guys see me it's okay okay my name is Danny Schneider I'm a program manager in the AAA platform team and that I'm working on Azure ml as an offering so are there any data scientists in the audience or people that would kind of they awesome yeah okay so um so as rimmel is a is a tool to help the data scientist be more productive using their to cloud basically so i have a quick talk today and the product that i'm working on is actually the ML Python SDK which gives you the ability to do pretty much everything that you can do with a ml through a Python right I have a very quick agenda only 20 minutes I want to spend pretty much 15 minutes or if not more demoing what we can do with with the Python SDK I'm just as a precursor it's something that you will see come out later this year but if you're interested in participating in our private preview please see us over there at the booth this an Azure machine learning booth right in the area and the I in the AI data and area right across from theater to please go there and have your badge scanned and then we can see whether we can kind of take you into the public preview so here's the agenda I'm gonna just give you real quick overview of what Azure machine learning is and where it sits in our offering of the the AI developer offering by by Microsoft and and then we will give you brief overview of the Python SDK but I'm actually really going to show it through the demo rather than through many slides right so here we have the overview of the Microsoft AI developer platform and this like three big pillars on the left top left here which is conversational AI which is basically building bots to have intelligent conversations with your customers through websites or through Cortana through Skype different different ways there was some even in the keynotes and in their planing nice sessions interesting sessions about their and how you how do you create those there is another pillar which is the cognitive services that's where you probably want to start if you're not very deep into data science yet or if you actually have a problem that is so standardized that we've already solved it and put it into a web service right so here you're actually interacting more as a developer with with the web service in order to solve your problem be it indexing a video you know transcribing the contents of text off of spoken words spoken recordings or just image classification these are all problems translation these are problems like this huge amount of cognitive services by now and they're really really useful now when we come to the customer I part this is where as your mal starts to play a role and here you're actually the data scientist that wants to train I build a custom model right so it's no longer okay I'm just going to take your model from somewhere and then I'm gonna apply it I'm actually building my own I'm changing I'm using tensorflow CN TK chainer cafe PI torch one of those tools or just plain scikit-learn playing playing machine learning algorithms in order to build my solve my problem right whatever that might be right so that's what we're as your male sits in this here's some some like rundown of a few features that we have so things that you can do you can manage your your training jobs locally and so as UML and I'm gonna show that in the demo as well is helping you to scale it up into the cloud so you basically take your you download your your tensorflow file maybe from from github and then you have fairly straightforward easy ways of kind of bringing it and running it in the cloud because what often happens is you train your model and then you run out of memory or you train your model and it takes a few months longer than you thought or then you have time for or a computer so that's where adjure is really useful because we have a lot of compute and it's really easily accessible right and so that's kind of the scaling up and then out is like hey I don't don't want to just train on one - I want to train on 10 or 100 right so in order to kind of scale up the training process make it faster yeah so as it says you're running this people tends to flow see indicate training jobs is something that we help with then kuiper parameter search I'll show that as well it's something that happens basically to every model it needs to be the I always have hyperparameters that need to be tuned right so I like things like a learning rate for example there's no good value for anyway it depends on your model and it depends on your data so that's something I'll show you as well we capture the logs of all your runs we catalog them we um captured the model that you create any of your outputs that you create so you can go back to them later like anything that you've created in terms of metrics for your jobs will capture that and then where you can you can kind of pull it in and and go to back to it later or you can iterate over it you can draw pictures like graphs with it and so really useful you can do like a leaderboard you see like which of the models that I ran which one performed the best what were the parameter said that I was using and what was the code I was using you pulled that back in right and of course all of that you can use your favorite IDE you can use your favorite editor you can use that in notebooks and you can use the framework that you want to use like tensorflow CMD case Park email or any other framework that is python-based that's basically where we're at right now yeah so this is the the as um SDK just a high-level overview kind of mirrors the future said so all the things that I just talked about you can do there and let me just jump into the code to to show you but I know actually there's one more here like this is kind of a rundown of what I'm going to show you we're gonna train a DNN on a Bachelor cluster we actually gonna deploy we're gonna show you how to deploy I betcha I cluster first and you can you can train on a batch or a cluster we're gonna perform the hyperparameters search or for for the tienen we're gonna pull data from the run history which is where we're logging all the run said that you make and then we're going to download the best model all right so it's like a typical flow you know you do run 100 runs and then you download the best model and then you we're gonna deploy an AC i compute is a container instances and then put that model on their compute so I can score score it through the web right so that's like I got fifteen minutes so we'll see how far we get so what I'm using is the amnesty de sets who knows the imitators that we've heard about it it's like it's yeah so it's it's hand written characters it was the Postal Service they needed a way to kind of you know get to scam postcode so I understood understand postcodes handwritten postcodes and so that's it's kind of the most basic example that people use to teach and show our Showcase TN ends DN n training because it really performs well with convolutional neural networks so one of my computer went to sleep okay so so first of all we're going to start with a workspace and if anyone anybody is already used as your mail they know that the workspace is that thing that that has all kinds of things attached to it and that it's kind of the central place to go to provision compute to deploy web service is attached compute targets it get attached and get models and so on so so that's what we've created now and the second step is provisioning of a Pecha a cluster so this takes a little longer than we have time for so I'm actually gonna take one that's I've got I've come provisioned earlier but just to show you the way it works is you have a provision config here what we're saying is one VM size nc6 which is our GPU compute the smallest smallest GPU compute that we have and this cluster is supposed to be between zero and four and four nodes which means it's gonna be zero nodes if there's no no job running on it and as soon as I schedule work on it it's gonna go to scale but it's gonna scale up to all the way to four and not higher because that's maybe well how much quota I have on which money I want to spend I want to make sure I'm not you know everyone be cautious with my cost and once those jobs are completed it'll scale down again and and so you're really only paying when you're running the job right so the way it works that you create on the workspace you say okay I want to create this computer target I'm gonna give it a name with this configuration here and then I'll need to wait for the provisioning and once that's completed I can actually retrieve it from the workspace again which is what I'm doing right now and says okay it's still telling me yeah the provisioning succeeded right so the other option is you have already a bachelor iCLASS to provision somewhere somebody like your whatever your your IT department has it for you and so you want to bring that one in so you can do that too you can just attach it and then then you have your your computer attached to your workspace so now we're actually coming to the to do some some training here right so what I'm starting off with is this entry script here which is a endless training for pie44 tensorflow so that is really much pretty much downloaded from the from the website and from the tens of our website as an example and we made just one change here is we added the logging so that Astro Malik she knows what the result is off the runs that we're performing and how it's progressing over time right so so this is how like your typical like this is like how a network a neural network is being built using cancer flow right you got like non-traditional layers and then you know tree lose you the activation layers and so on and so forth so that's just stuff that data scientists do and how they build their models and then there's this loop where you usually do the training run right and as part of the training run we're actually logging the accuracy so which every run we're tracking how good is the accuracy of the model so far and then we'll log it over to a dremel so that we can present it back to the user right so so I'm gonna kick off this job and as I this is basically just defining the job just like that guy had the configuration finishing off The Bachelor cluster further up this is just the definition of the job and kicking it off is by means of this fit function on this estimator object on this this tensorflow object this is a pattern that we've taken from scikit-learn they use that as well it's very kind of known to people that do traditional machine learning with scikit-learn though the fit function is actually what fits the data to the model or the model to the data so that you end up with weights that represent best fit to the model I took it to the data and so you can say so what's the status okay you can see that run is actually you know the driver lock is already starting to fill up and I could just go and say wait for completion and show up or true and that will show me the output of the run right here in the in the notebook right so it keeps flowing in here as it's doing work it's giving me whatever kind of warnings that I have because I'm using not the very latest version of the certain constructs here right but you see it's kind of starting to give me give me accuracy readings back so this is blocking my notebook now it's kind of not cool so I'm going to stop this and instead we have a widget that we that allows you to monitor this in the background and you also see all the metrics so it's kind of a prettier way to view this here you see the lock which is the same one you just saw so this one's gonna gonna keep updating and then here's all the data that's been logged and as soon as something gets locked multiple times so the accuracy and the iterations for example they will they get logged with every iteration of the training we'll turn this into a graph so hopefully this there you go right so so here's the graph and it's starting to run I'm thinking we're running this for like ten iterations which is actually kind of short for this model it needs to run for a more like a hundred and then it gets really good accuracy on the on the problem like 99% accuracy but here we'll just ten ten is fine right so this matrix that I've been seeing here and here I can just pull them out programmatically from the job so I can go and just ask the run made the run job that which is I what I got back from the fit function right I just asked it hey give me the metrics right and an SS team progresses I get more metrics out here as well right so I get three metrics here and then the next time I'm gonna get like you know the this is going to continue to fill up as the job reports more data okay so so this is all nice so I can run a single job now I see this thing is actually learning something it's working for me but now I need to find out for these parameters here that I was using I was using the learning rate of 0.001 and I was using a key probability of 0.5 I'm not really sure whether those are the best values or not right there's really no way of knowing other than trying this out right so so what you do is you you run a hyper parameter tuning job right and I'm going to kick this one off because it takes a lot longer to just start and want you to know what kind of some of the results before I talk about it so the first thing you need to do is you need to define your parameter sampling space and so you're basically saying learning rate can be either of those values I'm saying it's gonna be a choice off between it could be zero point zero zero zero one or zero point zero zero one or you know you get it right so so these are the values I'm just enumerated them right another way of expressing my parameter space or part of my parameter space is by defining a distribution right so so here for example for the key probability I'm actually using a distribution I'm saying use a uniform distribution across the the space from 0.5 to 1.0 right so that's where you want to sample from and every time that hyper drive is going to launch a new job for me it'll go to that space and randomly sample a value pair of it write a value in that n dimensional space two dimensional space in my case right and then we have something else which is an early termination policy which is in an in essence it kills jobs that don't look good and as a data scientist you look at jobs and you see well yeah okay that one I don't need to run any longer and then you could go and kill it by hand well the machine could do that to it for you right especially when your run hundred jobs and you run like twenty in parallel it becomes a bit of an artist task to do that by hand and and so what what what does is it will automatically look for those poor jobs and and kill them based on certain criteria which I'm describing here in this policy right and then all I need to tell it is basically as I put the conflict together I need to say hey what is the metric that I'm actually after and it needs to be a metric that my job is reporting back so I'm after the accuracy which is like how many of the classified numbers that I take I actually classify correctly that's the accuracy of my of my my model right and I want this actually to be maximized I don't want to minimize I want to maximize I want maximum accuracy and so it's gonna kill jobs that aren't looking good by that criteria right and then I say I want 20 runs usually one more but you know for interest of time and I want five to run concurrently no more than five and yeah and then I'm basically gonna shoot that job off by saying happy to I've searched me something right and again here we have a widget because there's many more jobs in play now it's not just one job and so we're gonna show these next to each other okay so I got a bunch of jobs they're reported as starting but they already started is there still some some issues in some of the reporting here but you can see there's there's some jobs here and and some of them are already it looks like yeah other so they're still reporting data I have a drive hasn't really decided yet which one to kill so it's only it's only kind of looking at so every so many steps is PI a by your definition so we'll come back to this one in a minute okay and now the problem is zooming now we have found we've run this this all through and it's it's you can see like okay so it's kind of progressing and I'm actually gonna go to like an older run that I did earlier since this one is still running and then we can go and just download all the data from it and pull it just in a panda's data frame I mean that's just I mean you could do it you could do it any way you want right but that's just what I'm doing right now so again speed here is something that will will will definitely improve on by the time we ship this but I'm just downloading like one dropper by one by one and there we can and then I'm sorting it it's in descending by accuracy so the one with the highest accuracy is at the top so I can see okay and my best job here was 98% accuracy and that was the property of probability that was used in that was a learning rate that was used right and yeah so actually if you want to plot that it's actually nicer if you have a few more so yesterday I rent something with 100 jobs and then you can you can plot these just using MATLAB so this is this is just Python here and here you can see like yellow is good and you can see which area is giving you the best results so somewhere actually quite in the middle here while are we actually getting the best results so you might want to go and okay based on this maybe do another run that extra narrows down the search field and then and then just keep keep looking more in the middle to really find that optimal spot right but it's really I mean it's like pulling it out and just boarding it is all just Python this is this is this is not that and that's the beauty of the sdk it really integrates well with what's already there we're not making all of this and we don't reinvent anything that isn't already there okay so yeah you the top run obviously it's the first one in that list right so in this case from from that the prior run yeah now so so that was what it reported so now since we're recording everything we can we can see what this run has saved so the output folder is this is a special folder for us because by default we scrape it after your run and we just copy it over to the artifact storage on Bob storage and keep it for you and here you see what we scraped out of the uploads folder and that's basically that model it's actually represented by four files right and then there's the logs that you can also get to and download so what I'm doing now is just I'm just downloading those those files and this again this is actually 30 megabyte model so it takes a little while so I'm I'm going to have to interrupt this and go back to my go to my previously safe model and now I want to test this locally for that it's just tensile model that needs as an input in image the image we will represent as a it is a JSON it's a base64 encoded binary that's put into a JSON right and that's what this function here is doing right and then I can basically take that model that I have locally and and score it and the scoring happens by means of the other script that I had taken pulled down which is the score script and is this run function it basically does the reverse it takes in a JSON and it unpacks it back into an image right takes the name basics for encoded image and turns it back into an image and then it sticks it into a tensor flow graph and runs it so this is again something that a data scientist would have in order to score their model because I need to understand how to how to run it in the end right and so what we have here is like okay we have with this model and we're scoring it and the number that we're scoring is actually this image is actually a nine so yes that was correct so now it's the last state we're actually going to deploy this to an AC I storage so a CI target here's the same pattern and we always define a configuration and then we deploy it so so we have the the the deploy configuration that actually contains how much memory I want and how many cores write and then there's this deploy function which deploys the web service which basically rolls like the image creation based on a camel file in a Python environment together with turning that into a web service that gets them put onto onto the compute right so that takes a couple of minutes so I can't reduce right now but I can go to the one that I deployed the other day and this this problem that I keep running into when my workspace gets I'm sorry I'm losing my workspace every now and then let me see if I can bring it back one minute okay I think I might have to owe you that one okay so okay there it is maybe maybe we can go back to this find the okay so I want to get my workspace okay and that workspace returns me a score like the service has of scoring your URL and then I can actually go and and run against that service so the same same model that I did earlier I'm actually scoring that one so it's a different number now but it's it's it's equally correct okay so that's that's all I had this is the Python SDK for a dremel and it will be available later this year as part of the HTML offering if you're interested in privately previewing it please come over to our booth and have your batch scanned so that we can inform you when we when we're ready for you okay thank you very much [Applause] 