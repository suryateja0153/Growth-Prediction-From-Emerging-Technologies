 Well, hello, everybody. Thank you so much for joining us today on another awesome session about health-care solutions here at Jamf. My name is Adam Mahmud, and I am the Solution Marketing Manager of health care here at Jamf, and I am so pleased and excited to introduce Brent Elieson, the Director of Technology Innovation at University of Utah Health. Now, for those of you that aren't familiar with Jamf's history in health care, we really launched our first health-care-specific offering in 2016 with a unique workflow to offer iPad at the bedside within the inpatient stay. We expanded to other members of the care setting-- for example, providers and frontline clinical staff that have their own needs as to how they deliver care more efficiently through Apple devices. And in 2020, with the surge in need around remote care, we've expanded into telehealth with new inpatient isolation solutions to allow patients to stay connected with providers and family. That said, I'm so excited to welcome Brent to bring it back to our first focus area today and tell us what University of Utah Health has done with their journey with Apple around their particular patient population in the rehab hospital. Brent? Thank you for the introduction, Adam, and welcome to the Accessibility in Patient Experience session. This topic should be of interest to health-care and hospitality industries, as well as any organization with interest in bringing smart technologies into the enterprise. Thank you for your interest in this topic. The technology I'll be covering is expansive and involves a deep level of development that we performed. The technology achievements that will be covered in this presentation are valuable to a broad audience. Specifically, in this session, we will cover why we took on this endeavor, what it is that we did technically, and architecturally how we did it. 30 minutes is not enough time to detail every line of code that we wrote, but hopefully you will take away new ideas of what is possible, and we will provide a path so you can replicate any of our successes either on your own or with any of the technologies that will be highlighted here. By way of introduction, for those of you who may not be familiar with the University of Utah, we are the premier academic medical center in the Intermountain West. The Craig H. Neilsen Rehabilitation Hospital, which is part of our health-care system, is committed to accelerating equality and function, performance and independence for the disabled community. We harness the idealism, energy, and intellect of our university's faculty, staff, and students to design and share innovative, assistive technology and adaptive programs. Earlier this year, with a generous donation from the Craig H. Neilson Foundation, we completed construction on a new state-of-the-art facility. It's the health-care-- It's not just the facility, it's the health-care providers, as well as the facilities, the donor support programs, and technology that make this one of the most advanced rehabilitation facilities in the world. Early firm commitment to design for full room controls by individuals with any disability type or severity. The term control, everything with anything exemplifies that goal with the building of our ongoing goal, to build or modify equipment to control any device our patients desire to control, all at a high, complex, and nuanced level. Within the technology space at rehab, there are many amazing capabilities occurring. In the interest of time today, I will restrict my comments to what we call the smart room technology there at the bottom. The smart room technology initiative within the Craig H. Neilsen Hospital set is just a portion of what this project entailed. And with that, I will cover the scope of what we are gonna be talking about, the smart room-- what we call the smart room technology. This presentation will focus on the unique accessibility and automation technologies that are implemented as opposed to the entire scope, right? So there's various components. I'm gonna start up with just the application here. And as you can see, this patient population has a special set of needs. Upon admission, each patient is issued an iPad. The iPads have an in-house developed application installed. This application can be used as a traditional touchpad application, or it can be used using a number of different modalities depending on the accessibility needs of each patient. If their accessibility needs change during their stay, their interaction modality can support their needs. The interface has a simple view and a complex view. The patient can use the application using their voice and just natural language. Or we can use the native Apple accessibility features. Natural language can even be used if the patient suffers from slurred speech, you know, for a variety of reasons, due to severe brain injury or, you know, all sorts of conditions. Using any combination of user interface, the patient can control their environment in what is often an extended stay. We allow patients and family to even use their own personal device to download a "Bring Your Own Device" version of the application to securely control the patient's room environment. They can stream movies to their 4K hospital-grade TV using Apple TV. They can play music through their room sound system, from what I call Enterprise Bluetooth. Have you ever wondered how immobilized patients request assistance from their health-care team? Normally, they have to wait for what could be hours for someone to check in on them before they can request something. At this hospital, this patient population can simply use their voice anytime. They can use sip and puff or whatever to request assistance. The care team receives not just an alert from the patient, but the actual details of the patient requests, like, "I could use an extra pillow," or all sorts of things they may need. Let's take a closer look at each interface. Oops. Back up. So the interfaces you see in the center of the slide here-- so the first one I want to touch on is Touchpad. So again, I mentioned there's a simple and a complex view here depending on your cognitive abilities. For voice, I mentioned that there's just a normal natural language, you can be slurred, and then we can use what I call tabs or labels. So using the Apple accessibility features, you can turn on a tab, which will just number each function point, and you can just call up that function point by number or by label. Each control has a name, and you can call the name of the label that we displayed and issue the command that way. We've got sip and puff. We've got lip switch as well. And then many wheelchair-bound patients use a joystick, and they're familiar with that interface. And so while patients are in a chair that's joystick-equipped, they can use that same joystick, and the commands they're familiar with and capable of using to control the room. And all these devices connect to the application just using simple Bluetooth to the application to execute the commands. We also go into each room and use a laser to scan the exact dimensions of the room and all the objects, and so you can use virtual reality like you're in a game and zoom in and fly through the room and interact with the light switch that may be on the wall. You can go over to the television and press the on-off button, so you can interact with all the objects in the room in that fashion. And then we've also got what we call in health care an ADT for when a patient is admitted, discharged, or transferred. We get automated messages, or rather, Jamf does, and I'll go over that in more detail. So with that, we'll proceed on to the next slide here. So the last thing we wanted to do when we built this new hospital was junk it up with a bunch of intrusive technology. We wanted to keep it as clean and modern-looking as possible. The only room automation technology visible in this room is the iPad on the patient's food tray there. That's all you can see. If it wasn't for that, you wouldn't know that there was anything in the room, and arguably, you still don't. Before I get into the solution recipe itself, I want to call out some of the novel innovations created by this project. I realize some of these terms I use here such as Enterprise Bluetooth or secure BYOD may seem like oxymorons based on common practices. The innovations achieved here push the limits of what can reasonably be done in a secure enterprise. Even things we thought were going to be simple, required significant R&D. Things like a regular commercial door that seamlessly doubles as an automatic door. The power of enabling a patient with physical limitations to open the door for somebody else is something that means more to them than most of us will ever experience. The stories from patients we received as we trialed the solutions in patient rooms kept us motivated as we had to overcome each hurdle of this project. Okay, the recipe. Let's get into the geek stuff here. Just to get warmed up here, so these are some of the foundational technology platforms that we built upon. Apple, of course, Jamf, and then Crestron, Carousel Digital Signage, and of course, the University of Utah packaged code. So here we go. This is how we did it. So this is our public facing architectural document of what we built, and I'd like to just walk through the slide. We're gonna spend a few minutes on this slide going over the details of what the solution looks like, beyond just its capabilities. So in the bottom left-hand portion of this slide, you'll see, first there's an iPad with the application running that you see there, so that's-- each patient is issued a hospital-owned iPad with this application on it as well as other applications, you know, from entertainment to patient education, Epic MyChart Bedside are all installed on this iPad. And then the patient can also, as I mentioned, bring their own cell phone where they may have their personal business. They may need to pay their bills during their extended stay. They can use their familiar device with their accounts already built into it. They can use those devices to airplay their Netflix account to the television in the room. We have an HDMI cord at the headboards, so they can plug in their gaming consoles. And I mentioned all of the various interfaces that we have that they can use with these devices. Above the smart room in this drawing, there's a red rectangle and that represents a load balancer. So in the data center, we've got a load balancer that ensures high availability of the system. So we wrote the application and then we have a middleware piece that performs much of the orchestration. And part of that orchestration is we-- the patients can actually operate the elevators throughout the facility. So they don't need--they have complete autonomy to be able to operate their room, and once using the overhead lifts, get into their chairs, they can navigate the facility, including using the elevator. And this is even for people that don't have use of their arms. They can operate the elevator, get in. And even if they miss their floor while they're in the elevator, they can talk to the elevator and call out common things, like they may know the floor, or they may just know that they need to get to the gym or to the cafeteria and the elevator will take them there safely. The nurse alert system also happens here. In the center of the screen, you'll see the patient room. So I've listed here the various devices that can be controlled all through the same system. We're actually using Crestron as our BMS system, but Control4 or other solutions should work equally. And then over to the right, you'll see in the common areas, we've got nearly 50 televisions in common areas throughout the facility, and we run digital signage on these televisions. So the digital signage content includes-- we have 4K moving artwork for wellness and well-being. We also cycle through simple things like the lunch menu for the day is broadcast there. We also have various events throughout the calendar year as well as throughout the day. Those events are posted here as well. And then something really special about this digital signage solution is, it also doubles as patient education. So patients, or rather physicians, let's say they're in the gym, and the provider wishes to communicate or train on a specific physical therapy, they can, using the physician iPad, they can simply airplay right to the nearest television where they're located, and they can present content; they can show, you know, a video of the movement that they're trying to teach. They can use a whiteboard and do drawings. They can display photos, and it's all seamless using the Carousel Digital Signage solution. And when they're done with the airplay session, the digital signage display resumes completely seamlessly, so it's really neat. And then Jamf performs quite a bit for us as well, and on the next slide, I'd like to talk about that. So this is my fancy automation here. Jamf automates what I'd call the Digital Hygiene. When a patient is discharged from the hospital or transfers rooms, the devices associated with the patient room are sanitized appropriate for each device automatically, right? We're not relying on somebody to remember to do these things. The hospital-issued iPad is factory reset and provisioned with specific settings for the room it is associated with. Organizationally approved applications are also installed on these applications, right? The BYOD phone shown there, whatever BYOD device is there, the certificates that allow it to communicate with our room controllers in the system are revoked. The patient room Apple TVs are factory reset, removing any patient account information that may have been configured on them, and they're provisioned in like manner to the iPads. Okay, so let's summarize this here in a Jamf space. So the functions we use, I think it's pretty cool that Jamf can automate Bluetooth and BYOD hygiene in an enterprise, in addition to the organizationally owned Apple devices. I think that's pretty unique. It expands my view of what's capable with Jamf. And I could even imagine that you could extend this to automating Wi-Fi access for guests if they needed to in a generic facility. If they check in and out, you could use that as your automation point to provision Wi-Fi. The capabilities are really pretty broad. Okay, systems in action. Returning even the smallest amount of autonomy and independent control for patients after catastrophic injuries or medical conditions is a powerful way to focus patients on what they can accomplish as opposed to what they have lost. The smart room clearly has the potential to operate as another member of the rehabilitation team. Several, in fact. The room will certainly assist physicians, nurses, therapists, families, caregivers, more quickly and efficiently and completely towards their rehabilitation goals. I have two short videos that demonstrate a portion of what the application functionality is that we have built. I'd like to thank you for your time and interest in seeing how we have advanced smart room technologies in the enterprise. As a public academic institution, we are interested in moving science forward through collaboration. If you have interest in pursuing any of these technologies, feel free to contact me at the email address listed here above. Have a great conference, and thank you. And with that, Adam, back to you. Thank you so much, Brent. We are so inspired to hear the work that you and the team at University of Utah Rehab have done, and I hope others can connect with you as they head down the same efforts. With that, we'd love to invite the audience to attend the other health-care-related sessions at JNUC this year. We have a whole host of them available for you. If you have more questions about these solutions, head over to jamf.com/healthcare. Thanks so much, and have a great conference. 