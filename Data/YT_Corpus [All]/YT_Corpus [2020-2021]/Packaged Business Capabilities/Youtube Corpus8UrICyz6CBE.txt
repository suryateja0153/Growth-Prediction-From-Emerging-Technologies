 hi everyone thanks for joining our media and entertainment breakout i'm gonna hand it over to our first speaker today steve take it away thank you so much for joining um our session today on winning the battle for consumer attention with data and ai my name is steve sobel i'm the global industry leader for communications media and entertainment at databricks and i have the great fortune of working with uh all of our customers around the globe to understand how they're using the platform but also kind of how big data ai and machine learning is helping to empower their business for databricks we help companies solve some of the world's largest problems that they have and specifically in media and entertainment as we'll review today there are lots of challenges that companies are having in particular here and now this is a very poignant time in terms of how companies data strategies are shifting as we all live through uh these these uh truly bizarre times in living through a global pandemic um you know you only really need to pick up the newspaper to see that uh we are living in uh some very interesting times in the media and entertainment industry and really what covid has done is it has accelerated the pace of change uh across every facet of media um you know there are many questions that the industry has around you know what is what is the long-term viability of um you know theatrical distribution in uh the film space uh how prevalent and how much of a um a how much growth are we going to see in the direct-to-consumer in the ott space uh how are media companies you know looking at the experiences that gaming companies are having in terms of driving engagement how are they going to change how they do business and how they go to market there's a lot of uncertainty uh as you can see here you know these are just a sampling of headlines from the last couple weeks on you know there's clearly a lot of doom and gloom but i'm here to tell you uh there is not all doom and gloom when it comes to the opportunities that uh the market transformation that the pandemic is helping to drive for many media and entertainment companies in fact there's significant opportunities a lot of which are driven by how companies are better leveraging their data better leveraging ai and machine learning to drive business outcomes um you know we see right now the here and now of you know how companies are responding to this disruption you know clearly even before um before covid started there was this massive shift to direct to consumer but we've seen companies doubling down uh everyone is either you know accelerating the launch of their direct-to-consumer service you you see within the last year disney nbc universal warner media uh really ad services or you see services like quibby that uh are new to the market or you see some of the incumbents that like fox buying 2v uh nbc universal making some acquisitions in the direct to consumer space ultimately with the goal of you know now that they have these direct-to-consumer platforms how do they then drive personalization at scale and focus on having a super vibrant uh consumer experience uh you know advertising generally the bread and butter of the media entertainment industry clearly has taken a hit that said not to present a a message of jim gloom we're seeing unbelievable innovation in the advertising space than we've seen previous to this use cases around driving more addressability use cases around advanced segmentation how do you make more effective use of programmatic as a channel both for buyers and sellers um ultimately with the goal again of helping to better monetize uh both the consumer experience and drive better outcomes for advertisers last but not least you know we see customers every single customer that we're talking to you know they're looking to find cost energy they're looking for new revenue sources they're looking for new ways to partner and go to market uh and frankly a lot of this is you know being being agile both in terms of your business model but then also what are the platforms that you have to help respond to these changes in market conditions you know many companies were agile were ready to move quickly when uh you know when responding to covet and many haven't been frankly it's no longer acceptable to not be ready for these changes in market as we just see the pace of change within the median entertainment industry advertising the martech world accelerate over time while that all sounds good and well and of course enterprise media and entertainment organizations want to be able to drive real-time personalization at scale they want to be able to better monetize their content and drive better outcomes for their consumers for their advertisers they want to execute with agility be able to stay ahead of the business and have it and data teams ahead of and kind of leaving the business but the reality for many companies that we work with is it's very hard meaning a lot of the companies that we work with have been brought together by years of m a activity uh you know they're maybe experimenting with digital platforms uh you know they're having challenges around taking streaming data like click stream or data coming from your ad tech your mark tech stack and matching it against batch data that might be coming from your crm uh your traffic data sources like you know wide orbit or operative or or other uh ad serving platform so when we talk about really the advances that machine learning and ai can bring to an organization getting to those use cases is very hard because most enterprises are not set up to have data directed self-service for analytics questions like how much is my content worth who's on the other side of my content how do i reduce churn how do i drive more return on my outspend these oftentimes are elusive and frankly you know what what we're here to say is have no fear you know basically what we do at databricks is we help you take all of your data we make it ready for ai and bi and we do so really fast it doesn't matter if your data is batch or streaming whatever the systems are coming we sit on top of your investment in your infrastructure whether that is aws or whether that is azure acting as an abstraction layer to get all of your data whether raw whether structured whether unstructured make it so that it is ready it is performant and it is reliable for those bi and ai use cases when it comes to ai we have a data science workspace which again is kind of one common platform where data engineers data scientists business analysts can work to drive more productivity uh and you can bring your language of choice whether you know tensorflow pi torch scala or others to our platform in order to drive more efficiency but also get more efficiency out of the investments you've made in your infrastructure we also have integrations to bi solutions like tableau click looker power bi and others ultimately with the goal of being able to access all of your data anywhere anytime ultimately when with the companies that we work with they're helping to drive outcomes that are affecting how do they drive growth in their direct to consumer business or how do we drive yield in our advertising business or how do we drive more efficiency in our content life cycle and aligned to this you know i wanted to call out a few of the use cases that we see throughout the media and entertainment space uh you know we are a platform i always like to tell people you know we provide our canvas our customers paint the art but if we see any patterns you know emerging it's that you know our use cases tend to fall in three different areas first around audience experience you know this has been a core focus for direct-to-consumer companies um both pre and and after uh covid things like personalization engines uh churn mitigation strategies uh uh being under uh able to stand who uh understand who's at risk of churn compliance use cases like gdpr ccpa streaming quality of service which we find to be the foundation for anything you know if you're not delivering a performant and reliable uh streaming video service personalization doesn't matter so we see a lot of customers you know that have really doubled down in use cases like this again before and after covid advertising optimization whether it is understanding you know campaign performance across multiple uh platforms at the same time understanding multi-touch attribution if you are a publisher or broadcaster doing advanced inventory and yield management this is a really strong area for us and you know what i'd say about both kind of these audience and these advertising use cases you know our ability to handle real time near real time has been a key differentiator for us particularly as there's been more focus on how do we mitigate churn how do we drive a better customer experience and how do we do so in real time last but certainly not least content life cycles kind of the the last area of use cases uh that we we commonly see these could be you know social sentiment analysis to improve you know product development it could be how do you package how do you apply machine learning and ai to better package uh your content that you're selling uh how do you understand you know if you're in the live production space you know how do you drive costs out of your business by ensuring that you know the the crew that and resource resources that you have are uh you know the most cost effective that you can put into the market a lot of innovation and spaces here around how companies are pricing their content how they're analyzing their content and ultimately how they're driving more revenue around their content over time we have the great fortune of working with companies across the median entertainment ecosystem you know whether many of these brands you know um you know some of the the biggest and largest brands in the world conde and asked for one you know uh an amazing magazine publisher that is doing quite a bit with us around both their direct to consumer business and optimizing their advertising business uh or what we're doing with a company like viacom where around their streaming business you know building out use cases around quality of experience in their advertising business uh having use cases around uh audience addressability and the like ultimately we are helping companies move a lot faster with their data to really gain competitive advantage in the marketplace and part of the way that we're doing this we've noticed over time in the market you know we've had a lot of customers where you know we they we paint division you know they're super excited about it and then it's like how do we get started you know maybe we lack data science skills to be able to move quickly maybe it's we don't have the domain expertise or we understand uh the ingress of you know uh data that's coming from ad tech martech traffic systems uh content delivery systems and the like or maybe it's that you know their challenges of you know we just need quick wins on the board we want to invest but you know we want to be able to move fast hearing all of this feedback we've developed a program that we call solution accelerators which ultimately our goal here is giving customers pre-built packages that they can use they can bring a copy bring into their own environment to get started with common use cases that much faster if you're a uh not a customer of databricks we make these notebooks available it could be a great opportunity for you to either build a poc or experiment with you know what our industry leading experts have built you know we have we have some of the leading uh data engineers data scientists frankly in the world so to get their kind of um take on you know common use cases that you would see across the median entertainment industry or maybe if you're a current customer it's a you have a wish list of use cases you'd like to get to just haven't had time you need kind of a accelerated path to get there these kind of pre-built notebooks as well as our how-to blogs that we give you with the notebooks are intended to kind of be 80 20. we give you the code we give you the research that we've done on what problem we're solving for we give you maybe a sample data set and maybe then you plug your data in as well and experiment ultimately with the goal of moving these use cases uh into production much faster than you would be doing otherwise we have a few accelerators that are currently available um and again we have a number of assets aligned whether both kind of our how-to blogs the actual uh solution notebooks themselves as well as kind of primer decks but um we focused in a few areas number one streaming quality of service again for the video streaming space we see this as a kind of entry-level use case on which the rest of the data science use cases follow customer lifetime value we're seeing this both in a b2b and a b2c context so how much are my advertisers worth if i look at things like seasonality uh in industry how much are my uh direct to consumer my subscribers worth based on you know what is the lead source what kind of payment plan they have what kind of package they have so we have two notebooks around estimating lifetime but then also estimating future customer spend and then last but not least we have a notebook around customer survivorship insurance so churn for any direct to consumer service is the number one priority so really starting to understand who's at churn risk why they churned and how do we mitigate risk moving forward as part of our program over the next few months we'll be launching uh a number more of the solution accelerators so you can see here in the next week or two we'll have a solution accelerator around sales forecasting and advertising attribution that'll be available uh use cases around gamer life cycle content recommendation clv specifically for a subscription business advanced segmentation and again you know use case we see quite a bit next best action next best offer how do we derive as much revenue from our end consumer as possible so this is something you know we're we're all in we're investing and making sure that our customers can move fast on our our platform we think that this is a high value uh program that we can give to both our prospects and our customers free of charge to get them in and using the platform and you know if you have interest in this we of course would love to work with you on on uh kind of our roadmap as we continue to develop these accelerators to learn more about this program i would highly encourage you to visit our website uh you can see it here there's a link dbricks.commedia this is kind of a quick uh quick link to get you specifically to all things media and entertainment at databricks as well as the solution accelerator program so with that and giving you an overview of uh kind of who we are what we do how we help you within the media entertainment space you know you heard me talk a lot about personalization super excited to share with you uh now and turn the program over to two of our customers that are going to deliver a presentation on how they built a a platform to deliver dynamic customer journey orchestration at scale i will turn it over to chris crew kurupath and sharad marshny from publicis epsilon and they will tell you a bit more about the work that they are doing to drive all things personalization take it away guys hello and welcome to this presentation on how to deliver dynamic customer journey orchestration of scale my name is krish karuppath i'm a senior vice president of technology at publicis epsilon my primary focus is on product definition and solution enablement for our clients and i have here with me today is charade hello this is sharon varshney i'm vice president data science and publishes absalom and my core responsibility is on developing marketing machine learning platform and i'll be co-presenting this presentation with krish thank you we have a packed agenda for you today in the next 20 minutes or so we're going to cover customer journey orchestration what why and how of it and we look at the model building and training aspects of it as well as some of the model performance and key business results that we have seen before we get started i just wanted to give you a one minute overview of who we are as a company epsilon is a leader in data driven marketing we have six products as you can see that enable the entire customer life cycle with the brand the first three boxes that you see on top discovery prospect and digital media solutions focus on the customer acquisition part of it whereas the customer loyalty and messaging focus on the customer retention and loyalty aspects of it epsilon is in a unique position because we have been in the data business for over 50 years and we have built customer identity graphs for over 200 million individuals in the united states with over 7 000 person level attributes top of that we handle uh data from 56 of all u.s non-cash transactions and we have experience managing loyalty accounts for 600 million customers on behalf of our clients all these capabilities enable us to deliver personalization at a scale for our global clients how do we do that our solution is built on top of three core pillars data activation and measurement all tied to the unique identifier that i talked about it is called core id which is 100 deterministic which has very high accuracy and matching across multiple channels and devices as i mentioned we handle a lot of transactional behavioral data that enable us to augment the customer information to create a 360 degree view for our clients on top of it our ai and machine learning models get updated fairly frequently because we have ad servers that serve billions of impressions every minute all this enables us to deliver performance-based marketing solutions for our clients enough about ourselves now let's dive deep into customer journey orchestration as we all know the marketing industries at a key inflection point the consumer expectations are rising every day you and i live in an always-on connected world where our attention span is very short and we are distracted very very often very frequently and we need instant gratification and the technology landscape for supporting these marketing initiatives is getting highly fragmented especially due to the compliance laws and creation of wall gardens and this makes the life of a marketer very difficult because they cannot see the individual in in his or her entirety we can see portions of the customer engagement with the brand but they are not able to get to that 360 degree view of the customer on top of that kovit 19 has placed additional burden on customers especially marketers because the marketing funds are being slashed and they're getting diverted into supply chain management and other initiatives and on top of that you're just one step away from losing a customer from this chart you can see that like 32 customers felt that one bad experience is sufficient for them to walk away from the brand that's a pretty staggering number uh how to address this you need to make every customer interaction personal and purposeful and it's pretty hard when we know that the customer goals are different from business schools customers want the brands to know who they are respect their time make it easy and fun for them to engage with the brand anticipate their needs and give them the most cost-effective option whereas the businesses want to conquest customers from their competition create brand affinity reduce customer lifetime value reduce churn and increase operational efficiency and when you combine these objectives you can actually deliver the best customer experience this cannot be done through data alone you need to combine data with breakthrough creative deliver the the right message through the right channel with empathy and understanding and the customer journey orchestration is all about that and our solution promises and optimizes customer journey by detecting micro moments and delivering the right calls to action micro moment is an intent driven moment of decision making and performance shaping and customer journey is non-linear and it's complex the customers could actually start from either online or offline so you as you can see from this chart they could actually come into your store or or like watch watch a tv commercial or go directly to your website through search or access your uh services through a mobile app the customer journey is i would consider it to be a networked set of events ideally uh customers interact with your brand through the right channel and get the right experience which is not always the case as i mentioned micro moments influence the customer journey as you can see i'm not going to walk you through every step but a customer's interaction with brand is influenced by the information they have about the brand and the product and the service they offer the brand offers we all know that we don't always make large logical decisions sometimes we rely on data but many a times we rely on our judgment and we make impulsive decisions based on emotions so we need to be able to identify where the customer is in the life cycle with the brand and understand their emotional state if possible to target them with the right message with empathy that makes the customers feel that they're making the right decision either the right purchase decision or a decision to become a loyal customer as you can see this is a single customer journey however if you are not able to recognize that the customer who is actually walking into the store and who browses your website and accesses your services through your mobile app as the same individual you're going to see three different journeys and you're going to spend three times the marketing budget to target that customer that's the total waste that's why identity is essential for enabling the customer journey you need to be able to bring data from various sources stitch these together the various sources could include the core customer profile then preferences uh your click stream data from the website then any social data about their interaction with the brand all these data needs to be brought together and stitched together to create a single view of the customer based on a single individual identity we call it core id but that is what enables a successful customer journey the next slide talks about a technical solution for enabling customer journey this is a solution that we built using databricks for one of our retail customers where we had actually built a number of configurable ingestion engines and configurable mml engines and outbound engines in ingestion engines allowed the customer to actually bring in their customer data and stitch it together using the configurable mml engines and algorithms to create the segments and recommendations and the channels and then using the outbound engines we were able to actually push the right recommendation right message to the right channel based on the use case that we were actually supporting all this was built using databricks on azure and for the machine learning services we leverage tensorflow and keras and sharad is going to talk about that in the next session thank you thanks krish that was really great overview of our journey orchestration and core id let's get into little more into what this journey orchestration enablement looks like and how do we really see a customer uh with all these attributes uh showing in a 360 customer 360 or a customer journey attributes now when we put together all these machine learning models and identify a different attributes we stitch these attributes back together which identifies a customer or keeping a customer in a center and identifies all these attributes which will decorate their profile with their on the customer journey so for example if you're looking at customer churn we would run these churn model let's say at some given cadence every month or every two weeks and that particular score which we could define as a high risk medium risk or low risk that could attach to their customer journey profile as in you know from given first month of the year versus the last month how their risk profiles have gone up and down so we'll take a look into this customer churn model little bit more uh in this particular next set of slides and we'll also look into a channel affinity when we talk about a channel affinity how or which particular channel the customer is more active on whether it's email sms push notifications or they like to browse the site more before we look into the modeling let's look in overall view of what marketing machine learning or an mml so what we call it is all about and how do we really get into our model building and training kind of an uh set of uh processes so if we talk about marketing machine learning models we have a set of tools or models based on machine learning predictiveness or a set of rule-based heuristics in some of the processes which identifies whether a customer given a certain use case let's say in a customer churn on their retention use case what kind of a profile they would really have if they want are looking to move away from one business and join somewhere else in the competitor we also have a text analytics based platform within mml where we used uh some of those unstructured data to bring in like sentiment analysis process these unstructured text and do certain sentiment or post processing analysis to identify whether there are some suppression use cases that we would want to enable on a segment of customers so moving from churn to customer cl tv which is a customer lifetime value what all factors do we want to ingrain into the customer journey so their clv gets a bit higher and higher as we move along the journey from moving on to clv it's about next best action and then cross category propensity is very very uh important and significant within our mml models we have variety of propensity models taking from single single individual offers which are personalized in nature based on customers or what they really want to see versus just a categorical base propensities and then moving from recommendation engine which is a skew level based recommendation engine given uh thousands of thousands of products it could be like hundreds of thousands of products which particular products that customer has higher affinity or in more interest into at least looking over those particular products versus buying together so we'll talk about one or two different models here but i just wanted to give bit overview of what our marketing machine learning model toolkit looks like and we're just not constrained with marketing machine learning we're starting to expand this with the supply chain machine learning models as well which includes the demand forecasting or multiple variations of demand forecasting model and also adding text based uh unstructured data plus image processing so a lot of uh data getting over on social media networks we're ingesting that back in into our platform to identify some post-processing of those unstructured data how do we really enable all this data because this data is at such a big or high scale processing these particular data takes lot of lot of compute behind the scene and is very labor intensive as well that is where we have identified some of our optimization on our architecture and we use a lot of uh modularity based uh libraries that we have coded by ourselves or using it from data breaks uh their compute engine or their scale auto scalable clusters that we use for spark or data distribution processing so thinking about transactional data sets these are basically purchase orders transactions from their pos or online systems uh their returns or the product info they all get aggregated into what we call it as aggregation features generator pipelines they are fully automated uh enabled through data breaks and azure platform currently uh we are looking to expand on different other cloud strategies as well and once we have all these features generated uh in addition to let's say there is a click behavioral data uh is coming through our website uh included with their device data or demographics data we do that stitching which krish talked about earlier in the slides uh whether it's deterministic or probabilistic we have both kind of apis at this particular point which feeds through uh our er or entity resolution api and brings back into our aggregations feature generator and this is what really enables our whole automation pipeline of mml or what we call marketing machine learning mml and all the use cases that we would like to enable for customer address which is retention our acquisition versus upsell or resell all these use cases is what we enable through this particular architectural of our mmo now once we have all these different models and all the different architectures set up how do we really look into our features and generally we talk about rfmt or rfm on a very simple mode these are the building blocks of our features what this rfm is its recency frequency or monetary value of when the customers are making those transactions so if we look into these circles or bubbles or dots the size of these bubbles they identify what kind of transactions like high in dollar amount versus low in dollar amount signifies the gap between these bubbles identifies how uh much time after the customer has come back and made that purchase and from let's say looking from today's timeline versus back it defines how recent those transactions have been so looking into these three different examples of regular customer who's basically making the regular purchases they don't really have to look too big but if there might be a instance where you know there was a long weekend versus you know birthday in their home versus something else and the big purchase happens that comes through but the majority of the significance of their features is the uh actually identification of uh consistent purchases over last three or four quarters best valued customer basically multiple different purchases and that happens also at a regular intervals they don't really again have to be a very big transactions but small transactions at every regular interval can identify that and churn customer looks like that you know they haven't really made a purchase in last two quarters but before that they were very regular so something must have happened around uh that time after q2 that some these some of these customers or this specific customers have might start away so we use lot of these hidden uh values or hidden features these are all coming from our transactional data uh i mean if you look into this data they are just like purchase order or purchase order details uh they don't really attribute these behaviors but once you put it together through some uh libraries or identify or extract these features they really turn out to be very valuable and we keep modifying or adding more components like from rfm we have gone to rfmt t is basically the 10-year piece and then we keep adding more and more uh different features into this particular feature generation phase so from this point on as we talked about the churn model i wanted to talk about one particular scalability issues that we faced because we feed so much data at scale that these model inference times were really really huge i think the very first time we ran it it took us about 18 to 19 hours to run this whole model on about 27 million customers with these 27 million customers we do a weekly aggregations uh of the features and they turned out to be about 2.5 billion transactions that we feed into this model so what we really had to do is to de-stitch an abundance layer which we built in into this model to identify the customer behavior and they reduce the model size from gigabytes to some kilobytes number and we use this layer into a separate uh in-memory database which we'll probably see in some of the next slides coming in and yeah the next point is about caching these embeddings in an in-memory database and reading it from uh when we really needed it at an inference time so given that let's look into a model performance and a business results with uh one of this particular model that we have been talking about churn so we looked into our data processing volumes of about 25 million customers and 2.5 billion weekly aggregated transactions they come from multiple disparate data sources and we activate omni-channel campaigns after generating the segments from this model after at least six or seven different version changes we had about 88 accuracy with 91 percent precision on this model which means it was very very highly accurately identifying whether the customer would churn out or not and it had a very less false positives with an f1 score coming out to be about 90 and that is on one of the regular customers that we have identified as a segment and when we calculated a hit rate in what happened in actuality when we did a back testing it basically proved to be about 67 percent accurate on that hit rate analysis what did we really achieve uh bringing this model and using data breaks as our cluster which was auto scale in nature and enabling business one of the business use cases which is the customer retention so we had an improved customer retention definitely an ability to increase the revenue for a retail one of our retail client by 2.3 million dollar per year and that 2.3 million was not even calculated on complete 12 months time it was about 10 months in actual processing for this model we definitely had an optimized marketing campaign dollars uh came back to or optimized actually into this the cost optimization through on-demand auto-scale cluster was basically about four to five x up in terms of operation excellence these are about 2.5 billion transactions as i've mentioned before and they were processed in less than 25 of the time so the very first run let's say in our legacy cluster environment used to take 17 to 18 hours and now it takes about less than five hours to be completely run through on this 2.5 billion transactions and it goes through scale automation and it also enables us to go fast uh very very fast uh to market the customer benefits around this we do have a personalized recommendation products engine into this and there are more personalized offers that we also bring out based on the different products or the category of products better promotional offers and deals based on their lifetime value so we do have a cltv model as well in addition to churn which works hand in hand with both of these models and higher customer satisfaction is what we were able to achieve at this particular juncture when we enabled all this architecture and data breaks as our cloud infra for running data distribution using spark so at this point i would like to invite krish back to identify some of the key takeaways thank you that was a great presentation on the machine learning models and the performance that we saw using these machine learning models running on top of databricks so let me wrap up with some key takeaways grouped into three categories data responsiveness and automation as i mentioned customer journey to support customer journey customer identity is foundational as sharad mentioned more data leads to better accuracy and precision so the more data that you can ingest the better uh but it's not easy so you will have to actually start small but be prepared to scale up that's where auto scale capability of data breaks is vital for supporting this these kind of initiatives and responsiveness is a critical thing because you need to be able to deliver the messages to the customer on a timely basis in order to do that if you can go real time do it because that's the best way to reach customer at the right moment to support real-time use cases you need to have faster model training and prediction and databricks allows you to scale horizontally and vertically to support that in order to achieve both the customer experience and responsiveness needs the entire solution needs to be automated because then only your your solution can say scale seamlessly and deliver the right performance and support frequent model updates and in the end be an always-on solution for this customer i know this is a vast topic and we had only 20 minutes to share these details with you i hope you can actually take some of these these findings and apply to your business if you have any questions feel free to contact us thank you for your time so thank you krish and sharad for that amazing presentation um you know i i think it's uh really amazing what you've built and kind of you know looking at the the level of complexity you have both in ingress and egress uh kind of around your your martech stack is is uh quite impressive and the ability to drive uh these results at scale is uh also super impressive so uh now we want to pivot for a bit um we've put together a a great panel of uh customers thought leaders uh that are coming from across different aspects of the industry to talk a little bit about uh what they're seeing in the industry um uh we're thrilled again to have uh krish and sherrod stay with us um for those of you uh who need a reminder uh chris is the uh senior vice president of technology for publicis epsilon and sharad varshny is the vp of data science for publicis epsilon also joining our panel is uh steven leyland who's the head of data engineering for 2b and last but certainly not least arthegola who is the head of product data science for wildlife studios uh before i get into kind of diving into the discussion on our panel i want to kind of give a little bit of framing for our conversation and kind of what we're seeing in the marketplace right now uh first and foremost um you know a lot of the customers that we're working with uh over the last year there's been a real focus on anything around real real time or near real-time use cases um specifically coming um uh with when covid started you know if you're a gaming platform if you're a streaming video service you know this has been the demand gen uh demand gen event of of all time for you you know there are some platforms that double triple quadrupled the number of users that were on their platform uh which of course led to uh a issue around great we've got all these people how do we keep them here how do we mitigate churns so um really uh you know focusing on you know kind of real-time bi and analytics use cases as well as uh any of the kind of real-time action use cases whether it be you know customer lifetime value next best action next best offer have been a big focus for what we're seeing in the d2c space but also um you know more broadly across some of the other businesses that we see in media and entertainment we've also seen you know advertising while advertising has been hit uh quite significantly um coming through covid you know i've talked to customers that initially when this all started were down anywhere from 10 all the way up through you know half of their business was uh was affected uh from an advertising perspective so while you know we we've certainly seen a pullback in uh many uh customers that you know are doing advertising use cases what we've also seen has been interesting because we've seen a lot of innovation around use cases specifically around customers that are looking to drive more into programmatic channels uh more into doing more around addressability and also a really interesting one and we'll talk about this later in the presentation uh is customers that are looking at alternative data uh as a way of understanding campaign performance particularly with apple degrading idfa you know customers are looking at new ways to actually uh to get to measurement so we're seeing quite a bit of uh i'd almost call it a renaissance of uh of different use cases that go above and beyond what we typically see in the advertising space and last but not least you know i talked about this in the context of real time and near real time but there every direct to consumer company that we're working with right now is doubling down on personalization um you know again whether it is advanced segmentation use cases if you're looking to do uh better targeting for both a direct to consumer and advertising perspective uh but also use cases around recommendation engines next best use cases customer lifetime value this has been a time where we've seen direct to consumer companies really double down on understanding who is on the other side of their content and how do they use personalization as a proxy for keeping customers engaged on their platform so with that as kind of our you know leading into our discussion and uh around you know kind of what we're seeing uh in the space um want to open it up to the panel you know on on this stage where we're super fortunate to have uh in wildlife one of the fastest growing mobile gaming studios in the world uh in 2b a massive advertising video on demand platform that uh you know was reported recently they had uh 33 million monthly users which is just astounding i mean incredible success there uh and certainly uh not to leave out you know publicis epsilon uh which really you know is is at the heart of many of these brands uh that they work with trying to drive more precision marketing more personalization ultimately driving uh better uh outcomes for the brands that they do uh work on behalf of um let's start you know kind of uh hopping on this this theme i just mentioned around personalization i want to start with arthur you know arthur at wildlife you know um uh during you know this the this kind of covent period this weird time that we're all living through um you know you've seen demand for your games and uh you know it was recently reported um that you had 100 million monthly active users uh across your games which is just incredible um you know just hearing from christian sherrod on on the importance of personalization is to their end clients and you know really how personalization is the core for driving sales driving consumer engagement um you know i assume for you at wildlife and actually i know for you at wildlife personalization is uh is a big focus um you know tell us what that means for you in terms of you know use cases and how you're applying personalization to drive acquisition and insurance mitigation sure thank you steve so today at wildlife as much as like 60 of our revenue comes from in-app purchases right so this is true for a lot of uh companies that work at mobile gaming uh and from those sixty percent of the revenue that we have at wildlife the majority comes from offers in-game offers and these offers are basically sales opportunities right where we show the user with a product uh like an item that he wants to purchase some coins for a price of course and with some discount when compared to a regular purchase in the store and this is very important to us and has been a very important use case that i'd like to mention here as a personalization use case and what's very interesting about our business is that basically up to 95 percent of the users who install our apps never even make a purchase right and from those that make a purchase about 20 represent more than 80 of our revenue so uh the the revenue is very concentrated and users are very different we have very hardcore users we have very casual users and being able to separate these different profiles is key for us to to have a good performance in our games and to tackle that the challenge what we did was we built a machine learning platform that basically makes it very easy for a data scientist to build a model and deploy a model that delivers recommendations in real time in our games right in the app of the user and with that we apply that to offers specifically for these offers that we mentioned and we had an impact of up to 10 percent of total gain revenue increase uh and when compared to a baseline of human curated offers so that was a massive increase of a massive result and we know we're just at step one we have a long way to go so so this is this is very important for us and these models today what we do is we leverage all the information that we have about the user both about how he got into the app right so he came into the browsing in the app store or perhaps he came in watching an ad on instagram this kind of information but also his behavior inside yeah right so this is the key this is where the magic happens so we know when the what screens the user visits we know every button he presses we know every point they earn we know every purchase they make and and that amounts to dozens of terabytes of new data every day that enters our system and that we leverage to personalize the user experience awesome steve i see you nodding your head you know you're you're kind of on the opposite end you know arthur's kind of focused on you know like how do we how do we kind of drive more transactions you want kind of the advertising video on demand side a little bit different but you know the kinds of data that you're looking at uh it sounds like a lot of it is is very much the same in terms of you know kind of tracking the user telemetry um you know tell us a little bit more about kind of you know how you're thinking about personalization what level of data what level of granularity you're looking at in terms of kind of getting to this you know one-to-one world sure very similar i mean personalization is going to be absolutely important for us to to keep growing and it has been instrumental in us to get to where we're at today um i think that there are a couple reasons for that obviously everyone's being a data driven company today uh but for 2b i think the one one of the big use cases was that our content is just massively large our content library has something like 24 000 titles in it or probably more by now and i think that's four over four and a half times larger than what netflix is offering in the us so there's a massive amount of titles to begin with and on top of that unlike netflix we don't really have like we didn't actually have the luxury of having really high-end content at the beginning so it was a lot of maybe older content that was transcoded to from video or real to real directly into um digital and so stuff that just maybe not be as relevant today and so personalization and recommendation uh became very important to find uh what type of content finding the right content for the right person at the right time uh to actually drive engagement and that that was basically uh key so the way we did that is we we invested pretty early on in a in a context-rich event stream similar to what we were just talking about so we oh my gosh sorry about that uh so we invested in a content wrench uh event stream and that has a lot of detail on to basically when when a video started what video started um where they were at uh what the um what what uh form factor they were using and then all the way down to like what they what their interactions were with the 2b application um so you know pausing a video fast forward rewind uh rotating the android uh device to from landscape to portrait mode anything that can signal more interaction or more more um engagement we take all of that into an ingestion pipeline which currently is somewhere around 40 000 messages a second and about not as not as large as what we're just talking about 500 gigabytes a day compressed of our of our enriched data coming in and that forms the basis of everything we do from our kpi metrics that we that we use in our in our data warehouse dashboards as well as our a b testing uh experimentation framework as well as driving the training data for our of our recommendation models so that's basically what we uh focused on early on to get to where we're at today awesome so it's like arthur steve you know big big focus on kind of you know managing scale of data you know streaming is a big thing for for both of you guys it sounds like real time um you know building on this a little bit christian sherrod you know uh clearly based on on the presentation we just saw you know personalization as the core of everything that you are delivering um you know it you know with anything with personalization and what we've heard from our third seed there's a lot of dependencies there's uh there's a lot of uh a lot of a lot of kind of uh both data com on the ingress and egress to make all of this work um as you've kind of you know developed your deployment as you've gotten further along you know what have been the key learnings for you as you've matured around building a lot of uh these use cases out around personalization yeah thank you steve um you've raised an important point in fact omni-channel personalization as we heard today is the holy grail for marketing uh effective personalization requires understanding customers and knowing when to contact them and when not to contact them that's also equally important and customer identity is a prerequisite for a number of business activities enabling personalization such as progressive profiling 360 degree customer view customer journey analysis and orchestration targeting attribution and media frequency capping etcetera this is something you typically encounter with any martech system in order to get the personalization right you need to ingest and stitch together a diverse set of data we heard some of the numbers like terabytes of data uh coming uh into the gaming platform and gigabytes and then the video streaming earlier uh when stephen arthur uh talked about uh so the same thing uh in the in the same context ideally you would start in order to build a personalization solution you start with the identity at the core and layer in uh information such as profiles preferences transaction and behavioral data what we have seen in the past is that you can start small start with whatever data sets you have but you should be ready to scale up on demand both from an ingestion perspective as well as on a compute perspective and sharad will talk about more on the machine learning aspects of this should i take it away thanks krish so just to expand a little more on the customer journey analysis and orchestration and the customer identity which krish were talking about we use that data at scale and just to name let's say the example that we were talking about personalizations we have the personalized offer recommendation engine which uses uh the models underneath but that models really work out when we put all this data at scale behind to this model for their learning and inference we've trained just to you know talk about you know what kind of a platform and the transactions that we have used for ingress is about 2.5 billion transactions when we do it at a weekly aggregation level and when we infer upon these it's about 30 to 40 million rows which goes out as an egress through a segmentation tool and to our next level which is the audio intelligence filtration so this using data at scale for training and scoring is what we really need to continue optimizing as a part of the process when we start with a very small data through experimentation and when we build a production based pipelines all this data really comes to play and we have used data breaks auto scalable clusters and optimized delta lake to process all this data in our models using spark data frame which is fully distributed across the whole cluster and just to take an example we use about 1.5 to 2 terabyte cluster to spawn all this data into spark and feed this through uh using either the batching techniques or even the parallelization framework with any deep learning machine learning libraries so over time this processing uh it used to take 17 hours uh as in you know a previous kind of a stack that we were using and now with data breaks it has gone over uh given us about four to five x kind of optimization wow that's that's uh that's amazing and and certainly you know as as kind of the the businesses demanding more of uh these real-time use cases you know certainly something that uh that is a differentiator for you um it's really good segway um shredders you're talking about scale and you know we've heard from from all of you guys you know that uh you're dealing with tremendous amounts of consumer data and you know the ability to have performant and reliable streaming pipelines is absolutely critical and at the core of making all of this work uh to get to some of these real-time use cases um starting with steven you know i would love to talk about some of the challenges that you've had in kind of getting you know more performance more reliability out of uh out of you know your your pipelines for for some of these real time or near real-time use cases sure i think the biggest challenge we've had uh so we've our our machine learning pipelines were originally batch our recommendation was originally batch and we're still trying to get to more online serving of the recommendations and so the training of that pipeline to getting the training data uh running through the entire uh the entire end-to-end pipeline took not too long but about six hours overall and so when if we did have a problem you know and it's expensive to rerun every single time uh and and also if we do have a problem and it takes two days to update the recommendations and we have stale recommendations out there uh we are serving real-time recommendations through uh you know on the to the clients it's just that those recommendations might be stale we want to basically move to more like right after a user watched a comedy episode now we want to say all right use that as more training data and get get a better prediction for the next uh recommended video and that's that's what we've been focused on right now uh the main issues i think that's kind of hurt us is that our feature engineering or feature extraction right now is all kind of um we don't have a central feature store and we've been building that out trying to create a feature store that where you we can reuse the same features over different models we don't have different machine learning engineers writing features in separate ways that sort of thing so we're spending a lot of effort towards building out a centralized feature store so that that can be used and then of course we have an online feature store and feature like syncing the offline and online feature stores are challenging as well um i think those are the biggest challenges that that we're facing right now in getting to near time predictions uh uh chris sharon you know you had mentioned uh you know kind of a 17-hour uh kind of uh time to run some of these uh use cases for you you know you're you're taking in again you know this is massive scale where you really need no uh agile platforms in order to uh to deliver uh tell us a little bit more about some of the challenges uh that that you had in this area as well yeah to let me ask you something what annoys you most about digital marketing well that's a good question it's a good question but i'm the leader for media entertainment so i can't i don't know if i can uh i can i can tell you without uh probably things that are not relevant to to me as a consumer yeah yeah so absolutely so for to me it's repeatedly seeing an ad for a product even after purchasing the product you we all might have run into this right yeah um yeah uh so for example you are in the market for shopping a car and um then yeah you visited a number of oem sites and other uh review sites even after you make the purchase you will see a number of car ads every day that doesn't go away for quite some time right so this is a problem that uh the marketing the advertisement advertising industry is trying to solve and in fact we addressed this issue recently for one of our clients in near real time we had to make a decision based on the fact that whether a person has clicked on an offer before purchasing something online or they had actually presented a coupon in store while making a purchase so you know that the person has redeemed the coupon or the offer and then we actually had to detect these events and then suppress the messaging delivered to this individual after he or she had made the purchase and then we diverted our ad dollars to target individuals who hadn't clicked on the offers or redeemed the coupons yet so this is the near real-time scenario so we have in order to accomplish this the transaction uh information had been brought in from the enterprise service bus in real time and we had a map with a specific marketing campaign and he had uh initially enabled through the legacy technologies but uh databricks uh structured streaming made our lives a lot easier as we were able to apply real-time analytics on top of this data while we are actually ingesting and processing and then making recommendations and sharad will add to the the machine learning complexities involved in this thanks chris i think the question is about the real time processing uh most of the machine learning models or deep learning models that we use they're not designed for real time right so you need to really complement lots of infrastructure pieces around making these analytics really real time so when i talked about those 17 hours of processing it's really processing about 2.5 billion transactions so when we think about real time it's probably we're going to feed one single row to get infer right at that particular moment in some let's say some milliseconds based uh timing so i heard steve also mentioned couple of different points about feature engineering so in our architectural slide we do show the feature aggregation being a centralized point so a lot of manpower goes behind that to make sure that you know we have the features that we define uh in our modeling so when we use these models uh just like examples krish mentioned about uh marketing campaigns we empower these campaigns behind from all the machine learning models behind but these models were done for uh batch processing but using that real-time analytics or having to dow those uh batch processed data kept into let's say a delta lake which we have it from their data breaks really have it seeded to align with the campaign and when it get needs to be delivered basically we just do the delta lake based queries to identify you know which customer we really need to look at and just provide the inference output for that so just to go back into the example uh there is a post purchase based uh use case that once i have really bought a product i don't really want to see that advertisement keep coming back to me so if you have enabled uh either those promo redemptions based use cases or the post purchase use cases back into these layering we could also identify that the product has already been bought and to show those advertisements around those products might be just a waste of money and time for our consumers awesome and arthur uh kind of wrapping up uh with you you know uh we kind of you know scale agility seem to be kind of things themes here you know tell us a little bit about your experience and um you know kind of some of the challenges you've had to overcome in getting to some of these real-time use cases yeah so basically we see a lot of use cases that are very very valuable right deliver a lot of value to the business and to get to them you have to do a lot of work right there's a lot of pre-work and the funny thing about having a robust data platform is that in our case at least it costed way way more than we planned in the past but that's actually a good thing uh not for the cost itself of course but because we are doing way way more than what we planned we would do and of course way more than what we were doing before so basically uh before we we started using databricks we were in a situation where our data engineering team was basically focused on maintaining services and not building the structure that we need to build upon and to do new stuff and as we got like this platform that releases time from these engineers they could start working with actually you know first making our core pipeline very robust then moving on to other applications more advanced applications improving our data analytics platform advancing in real-time data and everything that has to be built to allow for our personalization use cases that we are mentioning here so uh basically when you have a platform uh that gives autonomy to people uh what you have is the use cases explode right the number of use cases explode because you give autonomy to people and it's only limited by their creativity so basically the analysts and the data scientists creativity is what uh is between here and and you know a lot of new use cases and a lot of value generated to the business i think that this was really uh cool and that's why i said in the beginning that we it costed more than we planned because we are doing way more than we planned and the roi of that is huge so yeah that's great it's almost like you know platforms are like a gateway drug i i guess um so pivoting uh pivoting um quick here um you know clearly you know we're all we're doing this presentation all virtually because uh many parts of the world are still locked down we're still living in this uh very odd time of uh you know being in a global pandemic um and it's had an impact on every business and certainly you know we've seen our customers that have had to change their approach um uh you know you see you know we've heard from arthur and steve you know they have you know record consumption of their platforms you know for for christian charade in the advertising world it's had to change the approach and kind of drive more creativity in terms of how you actually get to a end consumer i just want to kind of go around the horn here and see you know how has how has covet had to kind of change your approach to the types of use cases you know have you had to adjust the the work and the groups that you're working with uh chris schreider i'll start with you on this one yeah thank you um so as you mentioned right uh definitely uh the the content consumption and and even the shopping behavior of the consumer has changed since covet um so as you can see there's record media consumption um that's happening around the world right down on all the um the digital platforms uh the it roku be it um hulu and like other streaming services and of course steven uh has actually mentioned that uh the platform usage is through the roof that's awesome um so um and it has definitely opened up avenues for online advertising but i wanted to actually focus on two different verticals that i closely work with retail and cpg so our retail clients are focused on spending their ad dollars on driving more online traffic so they want actually since the stores are not open they want people to buy shop online buy buy online um however the cpg clients are facing a different challenge in especially in the in the consumer goods section things are flying off the shelves um so they they have a different problem so they are they are actually running into supply chain optimization problem to actually refill or restack these products on ships um so at the same time retailers are also facing some kind of supply chain challenges especially to support shipping because um if you have a retainer who are who's actually primarily a brick and mortar had a lot of stores physical stores your inventory has already been distributed into this physical store now getting that inventory back into warehouse and then shipping it out is going to be a challenge so ideally you should actually ship it out directly from store uh to the end user so there are these um supply chain optimization problems that we have started in encountering with these these uh industry verticals should i had anything to uh to add there sure uh i'll add some machine learning perspective to this uh same example right cpg product uh let's talk about canned food uh during this pandemic kobe 19 and even let's say california fires with cyclone hitting all the uh gulf coast uh what it really does uh people buy in bulk they try to stockpile these kind of products so i'm in the team sitting behind the scenes what they're thinking is we don't really need marketing to market these products what we really need to solve is a supply chain problem behind the scene and we need to accurately do a demand forecast around these products uh what we really need to do is to basically pivot really really quick during this pandemic situation and not think about marketing solution but also go into demand forecasting bits supply chain but demand forecasting is a kind of a solved domain per se in machine learning but what it really hasn't done is to feed these kind of indicators which define the urgent need of this particular product in either local market or some national markets so that what we really had to do during this covet times some of these key indicators that could derive these models and really uh fit together back into these kind of pandemic situations it's really interesting and a good segue for for arthur you know when we we talk about kind of uh demand fulfillment uh you know a supply chain well well certainly not the same parallel from cpg to to gaming um you know you've seen an incredible amount of growth and uh have had to very i'm i'm sure had to very quickly pivot to uh ensure that you have systems in place to capture this growth tell us a little bit more about you know um you know did you feel like the systems you had were set up to handle the surge and any any kind of learnings that you've had during this time sure um so i think that all our systems are designed to auto scale right uh in our in our business in our market what happens is we have to we will have fluctuations and big fluctuations in downloads and active users like all the time uh just for like a little bit of reference when we launch a game we can have up to 10 times the installs that we'll have on steady state uh when when our app gets featured in the app store for example we could get even like double the amount of downloads of a regular day and our systems must be able to handle this kind of load and this kind of fluctuation right so i think that so covid in terms of engineering we were very well prepared for it uh i think that one interesting case where we had to adjust and we have to adapt is we had this inflow of users and we also have new users we had also have old users who started engaging more with our products right and we also on the other hand we use that information to model the lifetime value of these users right and of course the behavior these users will have in during the quarantine during covet and the behaviors they have as we uh let loose some of the social distancing uh policies that we have changes of course so we had to adjust our ltv models to take into account that you know the user the users will not be as good as they are right now and that's okay but of course as you said it was uh like very positive for us and drove a lot of users a lot of revenue uh just from this period yes stephen uh uh kind of pivoting over to you for a second i mean you you lead a data engineering team you know you've uh similar to arthur you know demand has been uh at a high uh you know has this changed any of the way that you've had to operate or or some of the new use cases that uh that you've had to enable um uh from your team i would say i don't think we've had to do anything different on as far as the use cases go uh but similar to arthur you know most of our cases have been most of our backend services are set up to auto scale so we've managed to handle surge quite well uh even the the the data pipeline that we've had has just been relatively i guess self-maintaining for a while it just kind of more data comes in more data writes to the delta lake it's it works pretty pretty well uh actually sometimes it works too well we didn't have uh we didn't have uh enough notification in place because we just didn't really think that things need to be monitored a lot it just worked uh and so we just found out recently actually just a couple weeks ago that we started getting seeing more lag and started seeing more uh it's taking longer and longer for some data to get through our data pipelines and into the into the recommendation system uh or our online uh we have a spark streaming job for that does a lot of real-time sessionization so creating all these sessions based off a bunch of uh of events and uh we had a lot of issues where the the session data would just drop because it was too old outside the watermark things like that and it took us a long time to figure out what the heck was going on and it's all the result of you know demand going up uh data kind of kind of slowing down a bit and then and then you know we figured it out and now things are smoothing flowing really smoothly and outside of that uh just like everyone else i think we saw a big hit in advertising spend early on uh and then once april may starts like that dollar starts trickling back in uh you know our revenue starts going up um but our tvt our total view time uh metrics definitely had a huge surge over the pandemic and it continued to grow as i just mentioned awesome so we've only got a couple minutes left i want to do quick round table uh before we wrap here on you know we've talked about you know scale agility personalization we've talked use cases um but you know as you guys are looking out over the next 12 months um again i want to want to kind of make it a sound bitey since we're short on time uh what are what are kind of use cases that you're looking forward to or or kind of innovation that you're looking toward over the next 12 months i'll start with arthur cool um one innovation that i'm that we are working on and that i'm very excited about is uh in our personalized offer system the one that i described before uh we basically spend a lot of you know blood sweat and tears into building the platform and making it run and it gave great results right so we kind of like bought ourselves some time to do new stuff and to experiment on new stuff and we are going to use this time and we are using this time to experiment on applying reinforcement learning approaches to uh selecting the best action that we can do to to each player and this is super exciting technically uh it solves a lot of our problems like just in one swing uh but it's also a big risk because you know reinforcement learning approaches uh tend to have very you know high variance in results right and so it might not go anywhere so that's a very big innovation that i'm very excited about and i'll probably share with you guys the results that we have in the near future awesome steve any anything you're uh you're looking forward to in terms of use cases sure we're powering more and more uh deep learning i think uh but basically more we have a data platform similar to arthur but maybe not as robust and building out a data platform such that users can can experiment on deep learning models easily and quickly and and making that iteration time uh very slow that's basically our biggest challenge for this next uh the next year that includes things like the feature store that i mentioned earlier and more work around real time just moving everything to real time real-time features real-time training um and then obviously real-time serving and predicting and last but certainly not least chris anything as you're looking out over the next 12 months you're excited about yeah so we are focusing on a number of things but uh i'll talk about the couple of them that i i'm close to uh working with uh the first one is uh the identity based recommendation so we currently do uh recommendations uh based on customer identity primarily on the digital media display side of things but we are actually actively looking to expand this capability to support websites and other digital channels so that's one initiative that we are working on um second thing that i'm currently involved with is the partner integration so we have a number of activation channel partners that we work with including adobe so we're in the process of creating an integrated identity offering with these partners so those are the primary activities that i'm working on yeah so a lot of innovation has been going in uh in our platforms what we used to call our machine learning platform is marketing machine learning platform but we're definitely innovating that is to a supply chain based uh machine learning platform as well in addition to marketing machine learning so a lot of supply chain based innovation has been going in for uh us just from the r d perspective but to grow these toolkits into our different and more modular approaches we have deep speech 2 model being implemented which is basically using speech-to-text-based use cases we also have a next-best action model coming in i think something which arter talked a little bit about it's basically uses reinforcement learning approach to try to uh optimize on certain campaign dollars versus you know whatever the objective is it tries to uh try to optimize it little and little better using uh incremental approaches so see the view of the innovation we are looking in well this has been super uh a super great conversation guys really appreciate um your time and your willingness to tell us more about kind of uh what you're seeing in the market and kind of you know where you're where you're taking your deployment so with that we could not be more grateful for your participation and uh thank you again for all the insight wow what an awesome panel discussion thank you everyone and that's all we have for today's inaugural data in ai industry leadership forum thanks again for joining us we look forward to seeing you next time you 