 welcome everyone i am harish and will now present our paper mask reconstruction based self supervision for human activity recognition the availability of wearable sensors such as accelerometers and gyroscopes on commodity smartphones and smart watches has made large scale collection of movement data a straightforward endeavor however labeling the collected data still remains challenging as the annotation process is expensive both in time and monetarily while having privacy concerns as video needs to be recorded synchronously due to these factors publicly available labeled data sets tend to be limited in size and variability as the data collection process itself is more straightforward compared to the annotation it raises the question can we leverage unlabeled data is it possible to utilize unlabeled data to improve performance on labeled data sets in order to do this we introduce masked reconstruction as a self-supervised pretending objective where unlabeled data is utilized for pre-training this brings us to our next question what is mask reconstruction we begin with the window or frame of data obtained after applying the sliding window process and randomly choose 10 of the time steps all the sensory data at these time steps is masked or set to 0 and the modified input is passed through a series of transformer encoder and fully connected layers in order to reconstruct the input only the sensory data at the mask time steps is chosen and mean squared error loss is computed between the unmasked data and the reconstruction output the network is forced to look at the surrounding values in order to reconstruct the missing data this incorporates temporal context into the model training which is beneficial towards learning on time series data the entire process constitutes a pre-turning step after which the learned encoder weights are frozen and utilized along with an mlp classifier for activity recognition we now take a look at the activity recognition performance of the proposed technique and compare it against both supervised learning and unsupervised learning baselines on four benchmark data sets and study the test set fund score compared to deep corner stm which is the supervised learning baseline we improve performance on two out of four benchmark data sets while performing comparably on the third we achieve a maximum relative improvement of around 10 on one of the data sets thereby showcasing the usability of the technique as it does not require labels for learning whereas deep cornell stm does compared to the convolutional encoder based on supervised baseline we improve performance on three quarter four benchmark data sets showing strong performance even in the unsupervised learning scenario as well putting everything together we introduce mask deconstruction as a self-supervised returning objective and demonstrate improved performances on both supervised learning and unsupervised learning baselines the proposed technique can be utilized as is in activity recognition chains in order to improve performance we would love to hear your thoughts so please contact us at 