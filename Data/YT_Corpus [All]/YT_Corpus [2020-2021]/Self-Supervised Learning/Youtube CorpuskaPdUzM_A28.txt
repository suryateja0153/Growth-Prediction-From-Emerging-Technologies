 it's a great honor to introduce see you on um i think it was uh the fall of 2017 when he officially joined the uh our lab the mq blob and that was after some time working uh in ted adelson's uh group and uh it was sort of a i would say like a unique opportunity uh for for the empty blood and an honor to be able to start working with him that was a time where um we came out of sort of finishing in the last year of the amazon robotics challenge and i one of the big realizations i think that we got from that sort of intense period was that there was a an intense need and a in our work and we believed in the robotics community's work to invest into adding a tactile feedback or digital feedback digital sensing into um so the reasoning of how robots approach contact and here we were thinking how our lab was going to ramp up fast enough to be able to push forward in that direction and uh chad was just at the same time that cu-1 was knocking on the door saying that he wanted to [Music] to join the lab and so it was a fantastic opportunity um and whatever happened happened after that i guess that's uh cu wants to explain but um if if one looks at see you on sort of breadth of research it would be easy to think of him as a one-man orchestra writes a cuon said he designed sensors and he build sensors and he has written the embedded code for almost all of the systems uh we use in the lab and he programs low-level robot motions and he builds robotic systems he does uh perception and uh he sort of implements uh um great learning systems that sort of uh show performance that um it's um sort of inspiring to see but i think that that sort of misses a little bit of the point of what cuant has represented in the lab because um alongside that cuan has shown i would say one of the most collaborative uh attitudes uh in our group right i think that there's very few people in the lab that hasn't uh benefit from or hasn't learned from having cu-1 right next to us we've learned from uc you want so much and um he has been oh he has always been that person ready to jump to help um and of course in any project in the lab that involves tactile feedback but in many other projects in the lab too so thank you very much for that ceon uh it's been uh it's been a great adventure of these years so please go ahead um thank you alberto for the generous introduction um hello everyone uh thanks for being here to join my phd this is defense today i'm going to talk about my thesis on high resolution tactile sensing for reactive robotic manipulation so um so during my phd study um so i'm interested in building um like high resolution tactile sensors and using this sensor to reason about contact to react to enable reactive behaviors for robotic manipulation so for example here i'm showing a video of we are using tactile sensor to enable safe contact and using the contact information to guide the insertion problem so um so tap sorry okay so tactile sensing is very important for humans textures and reactive manipulation skills so in the so it highly involved in many of our daily manipulation tasks for example so i'm showing four videos here like showing cutting folding screwing and placing so when we do all those things it's so natural that we are almost forgot that we are actually using tactile sensing to detect contact to detect and control the contact state so what i mean contact city is whether it's sticking or sliding because sometimes you want to stick to the surface of the object sometimes sometimes you want to sliding along the surface profile and so we definitely do estimate and control object pulses especially when are doing some uh in hand manipulation and uh so we can do force control by using our tactile sensing so i think i think all of those functions enables our super dexterous and reactive manipulation skills so i think to enable the same textures and relax reactive behavior for robotic manipulation we should also give good tactile sensing capabilities to robots um so in the past decade there are many different kind of tactile sensors has been made um so they are based on different techniques for example there is impedance based uh summer contact with uh with something the impedance will change and there's uh also like pressure based salon the channel of this bell tech showed in the in the first picture uh there is like pressure sensor sensing the the pressure change of the fluid inside of the finger and there's also um a capacity-based like robotic gripper and there's also faber optics based so all those sensors has you has its own characteristics can be applied in different modulation tasks so uh the type of sensor that i'm interested in is a variant-based or you can say camera-based tactile sensor so um variant-based tactile sensor i define it is is using tech uh it uses um the cameras to visualize uh the contact surface which i show here a picture of the gel site which originally developed by professor ted edelson at mit so so you can see this when in contact with this test piece it captures a local high resolution image of the connect surface and uh so so this is one of the key advantages of the sensor that when you're using a million pixels to realize a small part so you will achieve this super high res high spatial resolution um so the day format of this type of sensor is image or image sequence so they are highly synergistic with the popular savvy models and so this makes it easier to process the process the data even though it's high dimensional compared to other type of sensors um i mean tactile sensors so other good things about the sensor here is it has soft contact surface and so which gave some compliance during the contact and the cameras are low cost so uh so that means like uh is is this sensor can be mass produced so um so the sensor is getting more and more recognized and popular in in the robotics manipulation community so here i'm showing several of the other sensors that are using similar techniques for example the early gel force and the tech tip and the recent dj sensor by facebook and soft bubble by tri so my research is focused on the development and also the application of this type of sensor to take a real manipulation task so i divided my css into three parts so in the first part i'm going to talk about tactile sensor design uh i'm going to talk about two types of sensors one is called gel size sensor another one is gel slim sensor so um so based on the hardware design we also developed like some functions to process drawing images from the sensor to distill some useful contact information for example uh to detect incipient slip or to reconstruct the force distribution so the final goal of the cert of this css is to um based on the hardware and software uh how do you feed this information into the this control loop to tackle real manipulation task uh here we will show two kind of designs of the controllers by using the tactile sensor uh feedback one is uh cable manipulation another one is object insertion so um so let's start from the introduction of javasci sensor uh so gel side is a vm-based tactile sensor so it use a piece of elastomer that has a reflective layer so which is showing in the in the first image so when you price already cookie on the sensor surface so the surface will deform along along the surface of the of the contactor of the contact object so when you're illuminating the surface with some rgb light and then you can use this color shading information to reconstruct the depth map of the connect surface so the the already quick adapt map is showing this uh picture so so my first uh my first effort is to um is to design a finger tip version of this uh this uh sensor that can be used as a finger in the parlor draw gripper so the main uh the main difficulty here is to you know shrink the size to be compact and still retain the high resolution capability to capture the height the contact surface uh which you can see uh the my fingerprint here that when i when i touch the sensor so also we should design the sensor to be a uniform illumination and to have uniform elimination and then you can reconstruct a good depth of the contact surface so to give you a better sense of what signal you can take uh from the sensor uh so i'm showing the real-time signal in the bot in the top right and the that's map in the in the bottom right so uh so you may notice that uh there is you can actually capture very good uh local shape of the contact surface so which will be will be very useful to uh identify the pulses of the object during contact uh which i will show a bit later so you may notice there is also a distributed marker arrays on the sensor surface so the markers is to uh have to get the force information so when you apply forces the the gel the markers will move along the force direction and by tracking them you can get the force information um so javasci sensor is good in terms of it captures very really good 2d and 3d information on the contact surface however so because uh because of the bulky uh tip part so if you want to apply this sensor to uh something like a beam peaking or peaking from collateral environment so it will be challenging because uh this tip part will block the so under this motivation so we want to design a another version of the sensor that has a slimmer form factor and we want to make it robust for thousands of grasps for this usage that we can enable some data driven method and still retain this capability to capture high resolution of the contact surface so the main challenge here or i say the the general challenge of designing uh of designing a very in-based tactile sensor yes relies on two parts and first one is to design how do you put the how do you put the camera that can capture a good image of the of the sensor surface and the second challenge is to how do you arrange the illumination system to have uh high contrast and also uniform illumination so uh so let's take a look at the the first the left part of the image so this is the kind of stigmatic of the of the original javascript sensor so uh so you can see that the camera is just about the sensor surface which is here and uh so uh so this uh to keep a good image and also keep a relative uh large um con uh sensing sensing sensing field of view and you should keep a distance between the camera and the gel surface which is shown here so this explains why um this tip part of the sensor is bulky because you have to put a camera here and also keep some distance between the camera and this and the gel part so uh to make sure to make a kind of slim of a form factor so we have to redesign a better way to arrange the uh imaging system so the way that we are we're trying to solve it is adding a mirror here so you can take here so the gel is there in this color and so you can see in this way of the light from this gel will be bouncing by the mirror and to the and then to the camera so in this way so we don't need to put a camera here and uh so we just need a mirror here to excuse me to reflect the light all the way back to the top then we save a lot of space especially in the tip part of the sensor um so the second challenge is to design a uniform and also uh kind of incident angle of illumination to enable high contrast and uniformity through our entire gel so um so the way we are doing this is so we designed uh kind of a curved acrylic which you can see from the middle picture that uh then this this this kind of our acrylic will acting as a kind of wave guide so after light starting from here will be bounced twice and then enter enter the the gel part so when there is contact to the gel so the light will be bounced back to this mirror and the mirror reflects the light into the camera part so in this way we achieve a kind of a very um compact and slim form factor but still captures the whole uh sensing region of the of this gel so to give a sense of similarity i've given you this uh showing this video to show you uh what kind of signal that you can get so you can still see the sharp geometry information right when i push the screw and by tracking the markers you can get the force information um we are still improving the the design of this sensor so here i'm showing the how do i upgrade the sensor step-by-step so all the way from the original javascript sensor and then to the first version of gel slim and the second version and the third version so i'm going to show i will use the third version to tackle the object insertion problem so even though so sometimes we need some trade-offs to for the design to fade for a particular application but the general design goal is to make it more compact more robust and better to have some depth sensing capability and for the fabrication aspect it should be easier to assemble to maintain and finally to distribute that other people can use it easily so um so hopefully you have a sense of like what kind of image that we can get from the sensor and what kind of information that are encoded inside of these images so in the next step in the next part i'm going to show us how to design algorithms to distill uh useful contact information from those raw images so we are particularly interesting to detect incipient slip and to reconstruct force applied to the sensor surface so i think those two um capability of the capability of detecting sleep and detecting forces is very important that can be applied in many uh many uh robotic manipulation tasks so here i'm showing this a simple grasping task so if there is no tactile sensing feedback so the robot may lose the lose the object easily without avoiding it and then if you without force feedback you may easily crush the object that you are grasping um so i think this sensor has some unique advantage to detect slip or incipient slip so because we can visualize what exactly happening on the sensor on this grasping surface so so by analyzing the patterns of in the in the contact region so we and using some proper algorithms we can uh probably detect sleep without any prior knowledge of this of this contact object so we divide the problem of detecting slip or incipient slip to a classification problem to say to declassify the contact state whether it's in sticky mode or sleeping mode so let's let's talk about the sticking mode first so in the sticky mode so the gel moves together with the object that in the between the finger and so if we assume the object is rigid or is at least more rigid than the jaw so we can conclude that the gel but should move with the object as a rigid body motion so here i'm showing video of i'm trying to push or drag a little bit of of the object so because of the compliance of the gel so the gel will move together with the with the object so if we um enter this uh rigid body motion um constraint so we can actually simulate the ideal rigid body motion for each of the marker and we are using the yellow marker to track the real uh drill marker motion and using the red color to track the ideal uh marker motion under the base under the rigid body motion constraint so here because the two field aligns pretty well with it with each other and you cannot say that the right one so however if i push too hard and sleep will happen and so sleep happens when the gel cannot follow the motion of the object anymore so before fully detached between the jaw and the object so there is a phase that uh so some part of the gel is still moving together with the object and some part of the gel cannot follow so we call this uh period as in sapient sleep so so if you if you see the two um field when it's still uh the marker the yellow marker is still tracking the real motions and the right marker is still using the a rigid body motion constraint to simulate the motion of each marker so if sleep happens and you can see clearly see the difference between the two fields especially in the periphery of the contact so that's the part uh startup sleep first and uh so this is exactly the way that we can predict uh that sleep will happen if we say the difference between these two fields um so here i'm showing a case of this translational case and this algorithm can naturally adapt to rotational case or both translation and rotation case so here i'm trying to rotate the object a little bit but without slipping and if i push too hard to rotate it so we can say that the the difference between these two fields especially in the preferred region of the contact surface um so we can apply this technique to a bottle cap screwing task um so here for example so where you uh so we're giving a screw here a bottle cap here and without screwed and then we pre we grasp the uh bottle cap with smaller first beginning and then we do a slip control for the horizontal space which we are using uh showing the grasping force in the top and then we are doing pd control in the z axis of this robot to minimize the macro motion in the y axis so you can say in the beginning there is no slip and then when all the way to the end slip will happen and then we will gradually increase the force until the maximum force is is exerted and then you can see the bottle cap is firmly screwed so another functionality of the sensor is to reconstruct the the force field that applied to the sensor surface so this is also the most question that i get because you know the raw output of the sensor is just a geometry information on the contact surface so how do you connect this image to uh to the force that applied to the surface so the basic idea here is um so from the raw image that we can decorate two stars of the information and the first part is the depth information that represent the um the motion of the gel in the z axis and so we can also check the marker motions uh that does represent uh the motions in the letter space so if we combine these two so we can get the gel deformation in the 3d space so then if you know the young's modulus or and and poisson ratio of the of this material so you can use a finite element method to reconstruct the force that applied to the sensor surface that will result in this gel deformation so here so to be more accurate it should be inverse finite element method and so that's the rough idea of the hardware reconstruct force from the images and here i'm showing two uh showcase two um force reconstructions when the object when the robot is holding a ball and when the uh when the ball is inserted in this into this kendama and one is under uh graduation uh under um this different forces and you can say different force distributions so as i mentioned like uh the final goal of this of this this is is actually to apply this sensor and also the information distilled from the sensor to design controllers to give feedback in the real modulation task so here we are um going to talk about two applications one is cable modification another one is object insertion so i will show very different kind of designs of of controllers so before i go into the details of these two applications i want to highlight a unique feature or advantage by designing controllers for with this type of sensing feedback so which is uh you can do simultaneously contact state control and also object state control so for contact state control and what i mean is you can control the contact state to be rather in sticky mode or sliding mode and for object state control sometimes you can you can because you can capture the geometry information of of the contact surface that can be used to localize the pose of the object in hand and sometimes you can detect the collision signal between the object and the environment and then using this information to identify the poles of the object that you're grasping to relevant relative to the surrounding environment um so of course this is based on the capability of the sensor that that kind of sense these two type of sensing signals and so the idea of controlling contact state and object states simultaneously are used in both of these two applications so let's talk about the cable mutation first cables are everywhere and so cables is are deformable and has infinite degree of freedom so this makes it hard to manipulate them so um in particular here we are interested in a task of grasping one end of the cable and sliding along with another hand all the way to the end to another end of the cable so this task is challenging in terms of two aspects and first one is as i mentioned you have to modulate the contact state to be sliding mode and then bike modulate the cross beam forces and the second challenge is to modulate the gripper pose that you want to make sure the cable always in hand because it's deformable so if you do not do any control you will lose the cable easily because of the deformation of this material so to tackle this problem we designed a robot system that includes these four parts and the first part is the tactile reactive gripper so as i mentioned so we want to do the modulation of forces online during this sliding motion that we need a gripper that has a high bandwidth that can modulate the force with 60 hertz and second module is tactile perception so we use the tactile sensor to estimate the poles of the cable in hand and also we track the markers of this of this tactile sensor to approximate the friction force during the sliding um so the last two parts are the controllers one is to control the grasping forces and another one is to control the pulses of the gripper so as i mentioned we use tactile sensors to identify the pose of the cable in hand we also excuse me so we also track the markers together approximate forces um so during the sliding if you're grasping too hard so you will generate a lot of friction like the bottom figure shows and if you grasp with two small force so the contact surface will be small that will be very challenging for us to uh to estimate the pose of this contact region so so in this way we design a pd controller to keep the friction to be a target friction and then the target friction is modulated by this leaky integrator to ensure a good signal quality so what we mean a good signal yes we threshold the contact region and then if the if the contact region is big enough so we say this is a good signal otherwise it's bad so for cable post control we choose to use a model based controller so we can model this problem the the cable sliding problem as a planner pulling problem as this speaker shows i'm using the blue colors to represent the cable and the rectangle as the fixed gripper and the moving gripper so this system is under actuated so for example when the cable is falls in the one end of the gripper then there's no way that you can directly push it to the center of the of the gripper so the only way that it can do is to move this gripper to the corresponding direction then you form an angle between the fixed gripper and the moving gripper then you can pull the cable back to the center of the of the gripper so under this intuition uh so we collect some data by designing a some sloppy pd controller by randomly sliding along the cable and use the data to fade a linear model so the state parameters that are using here is the pose of the cable in the hand which which is the wide the distance between the cable to the center of the gripper and the orientation of the cable in the hand that is the sata so we also give the r for that is the angle roughly formed from by the fixed gripper and the moving gripper to tell you which direction that you are pulling so because the goal of this control is to regulate to this nominal trajectory uh to be all zeros in the state parameter and the control sorry so the control parameter is just simply the moving direction of the robot so uh which represents denominator trajectory that close to zero represent that the cable is always in the middle of this gripper and always lying horizontally and hopefully that the and also the fixed gripper and the moving grip are in the same uh y axis so um so we have linear model and we have this a nominal trajectory so we can simply uh solve this r crop our choir controller and get them uh get the optimal control so um this video showed the performance of this rqr controller so we are showing the real-time uh uh control input and the robot trajectory here so you can see after two uh regrass we can follow the cable all the way to the end uh so one application of the of this sliding uh motion is to combine the sliding and the insertion together and then you can you can implement something like this so you can following along the cable all the way to the end and then sensing the pose of this end part and then you can plot adjust the pose of your uh gripper and then plug it into a hole that is predefined so um it's worth noting that so the insertion part here is open loop so if we have some uh errors from the you know the post estimation on this plug part so the insertion will probably fill so this naturally kind of leads to the another project that i'm going to talk about is how to use this type of sensor to reason about the contact uh during this insertion process and still can correct this pose uncertainties to help the insertion problem so for the object insertion is a very classic contact with a contact rich manipulation task so it has a very close relation to the industrial assembly task so there's many many different method has been approached has been proposed uh so i'm classified this method into three parts um so first kind of approach is positive compliance device and it is the famous remote remote center compliance device but the problem of this uh passive compliance is it needs a small chamber of the hole to make to crack the pose of the of the plug so the second class of the method is model based measured with force control so this kind of method requires the 3d model of the of this object and this makes it difficult to generalize based objects with different geometries and so recently there's more and more learning based approaches that based on the forces or the variant feedback um so i think there's some unique advantage by using the vm based tactile sensor to tackle this problem um so the first advantage is the sensor has soft surface and it has a high resolution image to capture what has what is happening in this surface and uh so basically that means we can capture the rope the object motion during this collision process so so here i'm going i'm giving two um examples here in two different two different contact configurations uh so the blue object is held by the gripper and trying to go down and it will collide with the red object so during this collision the blue object will tend to rotate along the surface of this red object so then you can during this rotation so you can say uh the you can say the gel surface will be uh also rotating with the object that will that will result in the marker motion marker uh like rotations uh for this two it's rotate differently in two different directions so if you rotate 90 degree and the grasp configuration is changed but the object is still trying to rotate along the contact surface and then but in this time because of this particular grasp configuration we cannot sense the rotation anymore but you can still tell the difference between sensor one and sensor two they have different macro motion magnitudes so so we believe here that we uh the tactile sensor can give us enough information to identify different contact configurations and to localize where the contact to have the insertion and the second value of this type of sensor is as i mentioned in the second part of the talk so we can control the connect state by detecting incipient slip and then for example when we contact with the environment and then we can detect sleep before before a hard collision happens and we lose the grasp so um so we tackle this problem with a simplified insertion environment first and for example we show this picture that we designed a slot uh that the goal is to insert the object inside of this slot and so we want to use the collision signal that we got between the object and the environment with these two gel slim sensors and before generalization purpose we do not use any prior knowledge of the object so we can use we can introduce some post error in x-axis and also the rotation yaw angle so as i mentioned we want to build a map between the tactile images to the contact error and then we designed this super learning way to collect data for a driven data driven method so then we can propose some random errors in acts as theta axis and then we command the robot to randomly pick four of those objects and then uh trying to insert into the slot and then we use sleep detection to avoid hard collision so then in this way we can gather a lot of labeled data so we can use a simple cm plus iron model to regress the contact error so this will give us a contact error estimator then i think you can use a very simple p controller to kind of correct the contact error iteratively so we demonstrate this method works and can be generalized to new objects here i'm showing video of trying to insert this mastered bottle are some errors in the x-axis axis and you can say after two trials you can insert the object inside uh so i'm showing the real-time signal in the in the top uh in the top right here so for this object you can observe that so when you contact when the object is contacting with the right wall so you can clearly see the the rotation of this object that can be captured by this type of sensor and this is the signature that we can use to distinguish the content configurations and estimate the connect error contact errors um so we're demonstrating this uh this kind of experiment that the variant-based tactile sensor can estimate the context configurations and have the insertion process so to make it more realistic to be closer to the packing hole problem so we design a real whole environment and in this time we are trying to use a deep reinforcement learning problem to model this insertion problem as a sequential decision problem so uh later i will show the advantage of this rl controller over the super learning plus p controller way so the this picture shows a framework of this io controller so the the state of this rl framework is still the image sequence that you captured during this collision from these two sensors and so the reward is the the contact error in the adjacent states so which means if you correct some of the error in any axis you will get some positive reward otherwise you'll get some negative reward so when you insert the object you will get a huge bonus so we throw this image sequence into the neural network here and then we output some action that is that's the correction in the x y and zeta zeta directions uh but still in the planner uh space uh to i want to highlight that we are trying to predict the actions in the gripper frame so this then this uh policy will work in uh not dependent on the on the definition of this world frame so we are using a td3 algorithm that is off policy to be more um data efficient and is actor critic so for the actor model we are still using the cn plus iron model to map directly from the two image sequence to the access data action space but if there is something different in the creating network that because we know exactly the whole position and we know uh what action that we took in each step so we can directly know the contact error in any state so we directly throw the contact error in x y and zeta plus the action that we took to regress the q value for the creating network so uh in the following three slides i'm going to talk about the controller design choices that we made to make sure the rl network works better so the first design choice is the curriculum training um so we do curriculum training to accelerate the rl training uh in two ways uh we designed the curriculum training our insertion objects so in the beginning we only use one object to train the policy so after the policy is converged so we start to gradually increase the number of objects and in this way until we got the four objects that are works well so still for generalization purpose we use four different geometries so we designed another curriculum over insertion environment so we first try with this line environment which the previous slides i am showing the four different um like tactical signals in four different contact configurations that is generated in this by this environment so this uh kind of very distinguishable signal will make the training a lot easier to train and then after this converged so we will use this policy as the start of the of the next environment then we start increasing the constraint in the express space together a corner and to get the u-shaped to get a whole environment eventually so another type of choice that we made is the tactile representation so we found that different tactile representation will affect the generalization of the rl policy so for example in the beginning we are using the rgb image and which contains all the information including forces but it's also include some features that like geometry and texture of this for training objects so when using this policy uh it's easier it's easy for this policy to use this uh this kind of object uh specific information like geometry and texture for to have the insertion problem so we designed another uh representation that is marker flow that we simply remove all the rsvp values only keep the marker locations here so in this way we keep still the uh the useful information that we think is the forces and object motion during this collision and we remove all the geometry and most of the geometry and of the texture information so we will show later that the marker flow representation will will perform uh much better when they apply this policy to new objects so the last choice is uh whether using photograph sensor or tactile sensing so um tech dot sin phototalk sensor is the most popular sensor that are used uh for to tackle this problem so we train this policy to compare which sensor that can give you more information for this task give you a sense of the training process uh so we uh so this is a video train showing this training in different scenarios and uh so the whole training takes around eight hours and we take around three thousand data so in the next um so after we train all those policies uh some of the baseline some of the target policy and then we test those policies with 250 insertion tests with different initial post error and for each of this object so we use we test on the four chaining objects and these four nodal objects shown here so in the next few slides i'm going to show you some performance of the area policy with curriculum and with the tactile with the marker flow representation so this is for the keyboard you can see after a few trials and the the policy can insert the object inside and similar to other three training objects so those three objects are easier because they are closer to symmetric and it's not that sensitive to rotation error so we show this policy can be directly applied to uh to new objects for example here so we are trying to insert this this paper box that has similar geometry with the cuboid but it's very different materials so it does need a little bit more time to try but eventually it can insert and retrieve around 17 percent success rate during this experiment so similar uh things happen for other three normal objects and uh so bottles and uh the small bottle and phone charger is easier and the big bottle is a little bit challenging because it has a small chamfer that doesn't that is very different to the four training objects um so at last i want to show uh briefly about the the quantitative results and so here we are showing that the best policy that we get is the rl training policy plus curriculum training plus market flow representation and so here i'm showing the first line is the success rate and second line is the average number of times to insert the object so you can say for both of the training and the and the kind of new new objects so the the performance of this our star policy are pretty well uh so the the main uh so the paper box is dropped to 70 percent uh but still this is the best uh performance that we can get from this uh of these policies so we compare three uh the baselines of surprise learning policy that are used in the first experiment i mentioned so we compare the policy without curriculum training and the policy that this rgb image as the representation so of those has uh much lower performance especially in the normal uh for the null objects compared to the performance of the io star policy um so i want to highlight a little bit uh the perfor the comparison between the tactile sensing and force torque so um so the first lock sensor has a unique advantage for objects with a symmetric shape for example it does really well for cylinders and ellipses elliptical cylinder and those two uh bottles and but it has trouble to reason about the contact error in the rotational case so in this uh so then it does pretty well pretty bad for the cuboid and the phone charger and the paper box so we believe tactile sensor can give you more information especially to identify the the identify at the post area in the rotational axis um to summarize this uh control part uh so we talked i talked about one cable modification that we are using the distilled force and object pulse information to fit into a model-based controller and i also talk about the tactile based object insertion uh when the dynamics model is challenging to generate especially without any prior knowledge of the objects so we choose to use an end-to-end fashioned our reinforcement learning policy so to highlight again so both of these two tasks we are using the idea of controlling both the contact states and object state so for the contact state uh the cable one we are trying to sliding smoothly by modulating the forces and for the insertion uh so we are trying to make a sticking contact and for the object state the cable side is trying to maintain the cable is always in the center of the gripper and for the object insertion so we are actually trying to align the pose of the object with the hole so um all right so this is my last slice uh so uh overall to summary to summarize um so i kind of present my effort to uh enable the uh reactive behavior for robotic manipulation with tactile sensing and by uh by kind of designing two type of sensors one is geosite and gel slim and they can provide a rich information and by using the algorithm data i propose that you can detect incipient slip and you can reconstruct the force that applies to the sensor surface and finally i demonstrate or show examples of how to design controller with controllers with this type of sensing feedback to tackle our cable motivation problem and tactile based object insertion so before i end the talk uh so i want to highlight some um future works that i think are interesting and important uh through the three aspects so the first one is the hardware um so i think one of the limitations for developing or do research on tactile sensing is as i mentioned in the beginning so people use different tactile sensors and tactile sensors giving very different different tactile sensors give very different tactile uh signals so this will make it hard to share knowledges through the community so i think uh by making the sensor this type of sensor more uh modulized and then make it more easier to assemble to maintain and finally to distribute and when more and more people can use this sensor or fabric the sensor easily and uh i think things will uh getting much better and the pers for the perception side um i think i demonstrate the power of uh of uh real-time identify tracking the motion the the object pose of the cables in the cable motivation task so uh cables are special and has those unique geometry features however there's some some object doesn't have this uh this uh distinct visual features uh by using this local tactile image and then in this case we can combine a global view from the variance sensors and there's i know there's many good algorithms has been proposed to do pulse estimation with variance sensory and i think by combining variant and tactile uh from both global view to the contact constraints we will make a better state estimator and combining this real time uh as state as meter and the contact state information and contact forces uh it will enable a lot of model-based controllers that requires this kind of sensing feedback so the last one is for the application side or control side i think the sensor has a great potential to for deformable objects manipulation excuse me so not just for 1d uh cable that i showed but also for 2d and 3d objects i think by using the kind of local features that we can obtain from the tactile sensor um then by kind of tracking the uh the profile of this cables and tracking the edges of the 2d material or 3d material so we can uh kind of identify the edges or the key points of this deformable objects from a local view and this can potentially bypass the difficulty of of this complex globally modeling problem or global state estimation problem okay so that's concluded my talk so before i go to a q a session so i want to acknowledge some important questions during my phd study first of all i want to acknowledge uh say thank you to my advisor professor alberto rodriguez um so thank you for providing me a a comfortable a safe and uh and open space for me to grow and uh so also thank you a lot thanks a lot for um giving me guidance all the way from the high level ideas to all the details experiment design and the data analysis and i think i also learned a lot uh from you from your uh your humor your um your kindness your attitude towards life i think of those will benefit me a lot in the future of my life and thank you uh so next i want to say thank you to my committee members uh professor alberto sorry professor edward edelson professor thomas lozano uh paris uh professor paulket uh agrawal and uh so as as alberto mentioned that uh so i i spent the first two years uh that working with professor edelson and who is really the one that led me to the world of tactile sensing and uh so thanks for giving this to give me this opportunity to study this very interesting technique so i uh thanks a lot for advising me in the first two years uh so i want to thank professor um thomas lozano paris and and pocket for giving me those good suggestions and comments to my sisters and which really make me sing a lot deeper about the manipulation problem and i'm studying um so i want to say thank you to all the members of mnt imcubelab thank you very much for providing the help in both my research and also my personal life um i think i i enjoyed a lot uh through the three years that we study and uh working together and i think we are just like a big family and thank you very much um so i want to thank my collaborators uh that outside of my life uh i want to thank you sure and xiao xin wang from professor edelson's lab and i want to thank dewish and diego from morrow especially in this pandemic scenario that we finished this object insertion at tomorrow and uh so i want this i want to say that i'm very much enjoyed the work that we do together and hopefully we can still continue our collaboration in the future so last but not the least i want to thank my family i want to thank my parents and my sister um so it's uh so i'll say it's not easy to be a part for uh so many years that during my study at us and thanks very much for the constant support and understanding and love um so i want to thank my wife who gives me the um strongest support and love and thank you for uh always be here no matter what um all right so next welcome questions thank you oh wow that was uh that was emotional see you on sorry too long yeah are there any questions i have one um i'm kind of curious for these insertion policies like is there a specific reason why you have sort of this discreet step of like going down coming back up going back down versus something that's like more smooth and continuous that's sort of always sort of trying to wander towards the whole more continuously yeah so um thank you uh that's a great question so i think uh so that's definitely the future work that we want to extend the work to uh so i think there's uh two challenges uh for this continuous like motion for the insertion and the first one is i think how do you make sure the object is always stable during your exploration and you have to make a very good like control or using your sleep detector to maintain the object is always stable so especially when you are sliding uh not in the direction of the constraint of the gripper but not but in the another axis that it may be easier to kill the object during this exploration and the second one is i think um i think the the main source of information that for for this insertion of at least i observe is this during collision you can see this small rotations of this object and it's not very clear for me that how do you generate this how do you generate this this kind of information by just sliding along the surface and it's i think it's more like a kind of uh a way to do random or just the sphero uh this uh search i think this definitely expands uh the the space that we can uh explore but uh but still that there's those two concerns are kind of prevent me to like us to snap this uh forward on this direction that makes that's cool thanks thank you um any other questions i have a question so comparing um so gel side sensing uses some form of optical information right so comparing comparing that to um tactile sensing in the human hands um which kind of machine do you think is lost by using uh optical sensing um yeah i think um so uh thanks for the question so i think uh um compared to human sensing uh i think human tactile something has different kind of modalities uh some of them are sensing vibrations some of sensing forces and uh some some of them are thermal or different things i think gel says is uh uniquely just sensing this geometry and the force information and definitely uh because of the limitation of this uh frequency at this bandwidth of this camera and you cannot sense vibration all are all those like signals that with very high uh uh kind of frequency that you cannot you kind of loot that capability to sense that um i think in terms of the tactile sensors that are kind of closer to the idea of human sensing i think biotech is uh is designed to be closer to uh like kind of human style the tactile sensing that have uh pressure sensors to sense these vibrations and there's electrodes to sense forces and those things uh but then they are functioning with different frequencies and it's very similar to the way that the human technology work thank you yeah thank you so cnn what do you think is the biggest limitation of current touch sensors is it the fact that i mean they cannot deform right so you have to place them on flat surfaces so if you have a hand it becomes hard to you know place them underneath you make them very small right so do you think i mean making flexible sensors is probably the most exciting direction in making new touch sensors or is it more about you know be improving the gel site as is for you know getting more different kinds of sensing um uh well thanks for the question i think i think both ways are uh promising and i i i do favor the the idea of you know designing different even different grippers uh with different tactile sensings for uh this different task that we apply and uh i think also like designing the sensor that is deformable i think there's already work by professor edelson's group how this uh both have the tech test engine but the group is also deplorable i think both of them are very interesting and uh should should be the the direction that we should explore uh but the limitations still yes uh i think for this type of sensory is uh you cannot make it very very small and um so because the limitation of this you know you need a space to to form this image between the camera and the sensing uh field and so that's i think at some point you will reach this this limitation unless you're using some and there's some breakthroughs from the imaging or camera side or yeah or there's very smart designs and what was the duty cycle of your sensors how long did they last and like the experiments you were doing yeah so uh well i think the center is getting more and more robust um i want to make a think of the effort that people especially from professor eidelson's group that they are making this jail more and more robust and uh so i can tell you probably a rough number that when i do the insertion task i'm using this sensor to uh to i think at least gathered uh millions of data uh so even though i'm only showing uh here i'm using like three thousand data but i was uh being using one since the vampire sensor to gather a lot of data and so you can get a sense of how robust the sensor can be thank you thank you 