 you [Music] so hi everyone so today we have a great fist that I am very delighted to introduce if you don't do not know him but I'm sure like you everybody like know him so jot oh good is a research scientist at Facebook a Irish research his research interests lie in applying deep learning approaches to natural language processing problems specifically building an efficient effective and reliable neural machine translation system for human languages so far he has published several papers in top-tier conference such as a comm open your hips and I clear so Giotto is going to be talking about his recent work which is very exciting welcome Kjetil okay hi nice to meet you it's very great to be come back here so I have an internship two years ago and working with Hania and it's a very nice time and the joining journey so yes I am I was studying from introduce myself so so I kick already said so I'm a research scientist at Facebook I research in New York City and I have a PhD in Hong Kong and then before that I have my bachelor in Shanghai University so before talking to our our topic so first take some time to discuss what my research interesting affair so my research mainly lining to three aspects so one is a low resource and multi link on your machine translation and where we we've have read published papers about analyzing Hawaii zero shown your machine translation works or didn't work we also have one paper accepted by trip next year it is discovering the beta level sub words which would be a better way to modeling multilingual things we also yeah we also have something ongoing projects working on to combining pre-training or multilingual setting and which will be useful for Lawrence awesome the second expense of my work is is evolving the advanced message for natural language generations so I was very interested in to have a building a new way to generate not a general sentence from left to right by generating of many different ways for example we have a paper at the taco which is to develop a insurgent base generation to general words by using in certain process and we also have a new poster which will be next week if we will come here is great to chat with me in detail so not over it will not be discussed in this book it's using the insertion and deletion words to generate sequence in the iterative way a third part for my research is it was in the multimodal which is specially in speech and the text so we working on and to end speech translation with my colleague in Mara Park we submit a paper to like Adam salty and specially we were organizing another some intensity translation share task in next year adversity so if you are interested with welcome to participate so okay so that takes some time to discuss what I my general interest so today's topic is a bit small but concrete finding in our recent work so we were discussing about the sequence level noise dissolution which is not a new thing first the knowledge addition is is originally proposed by training weaker student classifier on the targets produced by a stronger teacher model so it's it's a generating a classification area so if you have a target it's not using the ground just labels to train a classifier you're using the teachers models two logits to build produced some softer labels which software will were training the student in a maximum that cross-entropy in the context of sequence generation so the sequence 11 north distillation instead that using the heart targets instead of soft to train the sentence so what can be seeing is you given be given the model with first to Santa coding method to find the best the solution translation or sequence and then using that sequence to supervise my current model so the sequence level nor decision can also be seen as a soft-serve version when you when this when this temperature goes to zero then the software labor would become harder APIs so these are actually the same thing but the good thing is because we we can all really maximize the target sequence when we doing the decoding so you're always using the some kind of approximation for them for beam search to find the best solution in this case so let's discuss in detail about sequence level nerd legislation so I put a figure like this and this figure will be using that again they're gaining the talk so it's generating three steps the first step is to training a teacher model with the codon labels and the teacher model is like this and the table is coming from sin theta D and then once the model is trained we use this model to generate the data so we're using some any kind of decoding method to get around data Y star and then when we have the X and the y star we using the this kind of pairs to train a student model using the same way as when you train teacher model like a maximum likelihood and here are using dash line to show that these things these are the same thing so teacher model I find it and the target when we have the targeting we use it to supervise each student model and this method actually works extremely well especially when we use it for model compression and for any other tasks but there are several questions if you look at this though at least to me first is so this method in tells you how to choose the student and teacher model usually we think about we need to have a stronger teacher and the and we have a week-to-week student but what if we say are the same or what if the student is even stronger what will happen a second thing is if you look at the decoding time we didn't actually have some correspondence between these two X so the sentence may come in from the same data set or may come in different data sets so what if we have more data to do the distillation and the first thing is why and the how this distillation works in generations so as we all know see one generation is quite different from the classification so it's still unclear why this kind of noisy distillation will improve model because after all we are using the fake data to train the model we are not using the real data to answer these three questions we're actually tackling this into two aspects actually so one is how to choose a model a second expect is how to deal with the data the first work I will introduce is is called understand noise decision in not question machine translation which is a joint work with trending and Graham and this paper was submitted to iclear 2020 so before that we need to discuss what is not crazy machine translation so after we all know that standard machine translation models are Auto regressive which means that with the coded Center we get the whole target sentence step by step so each word we got a condition on the previous generated world and predict next the world and this is good because it's very strong and that can be a can in theory model arbitrary distribution of the sequence however it is slow because you need to always wait the order Pierce word predict next words and the implementation wise it can be very small especially when we want to do very complicated model like like a Travelodge transformer like a GP d - something like this so instead not occurrence of translation trying to predict the sequence in parallel which we modo it's like independently pretty other words at the same time and of course it's fast because if we can take a map take the advantage of her rhythm you can predict all the world at the same time and the computer everything especially on GPU but of course it is weak and all the words are actually independent with each other we can really you cannot really assume they are independent and we predict them usually the non-question model have much worse in the authorizing models so in practice so no one really using the the pure and autocracy models there must be some intermediate presentation Z which trying to capture the ignore dependency in the output space so for example we can write with write everything like this we model sound in the immediate the representation Z first predicted by X and the condition of Z we pretty other words at the same time and the based on different Z with there's typically two types of Nod Quasimodo's are considered one years if Z is the kind of standard latent variables which may be continuous or discrete and the recalled VI base and eighty models a second thing is the can be immediate pressure generation for them per we first generate something and then we refine it on that as long as we didn't stop decoding everything in the middle at the other latent variables so we all call it like a refinement based models so I listed some papers here but I didn't have time to spell out so then let's talk about not gestation for another question models so as we all know as based on our discussions we all know that not quest model that weekers in the auto regression model right so it's a it's a nice standard way to do the north destination because typically we want to be using a stronger model for this later weak model and also in our discussion we assume that the ordered data are the same so both the student and teacher model are training on the same source sentence the only difference is that the teacher model training is using the real targets why the student is training targets produced by teacher models so here is an example of performance ways of the result not a distillation for not quest models so Eric performance is tested under Mt English German and the models are distilled from the same autoregressive transforming model with Bruce colitis around 727 and then we test it on three different models the first one is a very simple not crossing model there's no any latent variables so you can see it's like 11 plus cos sorry and second thing is the flow based Network NatWest model which using latent flow as a latent variable which can get a better performance compared to the non I've won so it means that latent variable actually capture some of the dependencies and the first thing is that we recent to the newest paper which using the insertion and deletion methods to do iteratively they refine the translation they actually can get very good performance like 25 but still it has at least like to Prasad tab between the autocratic models but just with discretion all the models just improved a lot even for the very strong model you can also improve a wrong life to Cusco and for the very naive model we can improve like April scope so this means that's the nor distillation is really the key for making these kind of Northwestern models work so so why it happens the original paper from the not question paper now modal paper and I'll use that this kind of not question models will suffer the problem card and multi-modality and there are the example which I use again again but they'll be easy to see so for them for wine sauce is my I want to translate thank you into German there are several ways to translate into German like a variant tank Ferran tunk tunk shrimp and dunk and everything a correct but if you model them in a prairie always so if we predict an interview we cannot avoid produce something like a dunk tank or finish on the actual wrong for northwest models cannot make them different however vault was model we can converse the predictive variant and the condition of them to predict tank and first predict tank condition on type operation so this is not a problem for general auto growth model but the problem for northwest models then the NOC our assumption at the time is that distillation helps to reduce these kind of multi-modality so in this paper we want to care for analyzes how this multi-modality is reduced so when things are unclear and too difficult to explain sequence generation tasks especially like a machine translation we use I think it's a good way a good idea to to act look at some point cases for example the other Khoikhoi example is we create a synthetic lead acid combine the ways three language pairs is English German English French English Spanish or from the Europe policy and we we make sure every English sentence corresponds to one three different languages like Eric English sentence will be translating to three different languages in the data set and that we don't provide the language ID to them so in this case we are manually created some Mahdi mentality in the data so every sentence needs to be translating to three times in the data and we force the model to memorize that to train either auto regressive model not cross model directly and during inference time we also don't know what language were output so we just gave the increase sentences and the model but choose whatever it blends to do the translation so what will happen in this case so yeah it's open point we have like thousands English sentence then we have 1000 jump so we have three thousand examples I saw the English standard integer bandsaw the ingress for the French there's something something in Spanish now they are the same English so we're just trying to make sure there must be some multi modality in the titles and then what happened so clearly auto regressive are no harder it is isn't the difference just in the decoding or you have actually it's different models so because the the way you decode I mean the other words money do you call the words left to right place and not quite small just pretty everything at the same time and it also affects the training because if you're training maximum likelihood the likely there's a lot the lodges will compute different three way okay so so there's four figures to show that if you look at the first two figures the first figure is them so we want to visualize how the model captures this kind of multi modality so we want to visualize the mode of language ID we we approximate the language ID by averaging this this equation looks quite complicated but it to be simple it's like this so I take a model I input an English sentence I ought to put some sentence and the son sentence I can calculate each word which this word is coming from English or coming from French or German or Spanish and I averages as probability which can be average probability of the sentence belongs to any languages it's a very rough approximation but as you actually works quite well so if you're using this a kind of approximation you can see that auto regressive models can almost good to to generate some sentence like it will either generate terminal or French or Spanish it won't generate something in the mix so it's means that if the folder will automatically doing decoding time to choose the mode it would language 1 to January however for our Northwest models everything is mixed so it can all completely this classifier would language I want January I want generate a German or generate French or general Spanish everything's in a mess so that's means that this kind of model is really the problem is that not the the multi modality is right then we what we do is we using the auto regressive model the targets to train a new models so we're using their targets to train a new model on our quest model and then we visualize the modes again so in this case because the ultra quest model when you decode it we we automatically choose the mode for each source sentence and when you choose the mode for the certain we train this the NatWest model again then the other one goes model will never or at least not so see theory stood up for something like mix it will also generally something like easier german or french or spanish and the other comparison is yes figure this figure shows that i will randomly to given the 1000 sentence as honey just ask if we have three targets we can randomly select one language are these targets so it's also kind of reducing the modes which is based on random if you randomly reduce the modes it's works worse compared to if you have an auto words mode select mode for you so it means that the distillation is actively selecting the modes for the data and then training under north and the landscapes model continue on that so in spite of inspired from the visualization on a toy data so we can propose something using the data uncertainty to measure the modem intelligence or we call it a complexity in a general purpose so how to do this so we using a token level conditional and trophy to measure that the the data is complexity which will be very simple so this equation means that we first generate the data so data may generate from the auto quest model or north coast model and then we apply an IBM or we pry at a faster line the alignment model on that we can find it order and when we have the alignment model we can get a long table using the alarm table we can compute the token level and trophy for this data set so this is also absolute row summation because it's not a real complexity of the data but we using a proxy which is an alignment model to get the entropy of the data so how this works so if you're using this measurement to measure the data set you can see that the one we using the area sentence with cross bonding to three different languages the complexity is like around three point six that is the average a token level and condition a trophy which is quite high however if you compare to the data coming from the other words in models generation the complexity just drops to like a two point six so under the results or the show doesn't exist so it means that the first is auto quest mode really is trying to the distillation is trying to reduce the complexity of the data and second thing is our measurement also shows this kind of correspondence and the later we can always using this measurement to assess the real data sets not English kind of toy sense and to be compare is the the random selection model can get like three point three which is in the middle of dating these two so it's care to better than completely everything is masked but also it's worse than using an autocracy model to select so we also proposed another measure called faithfulness because when we're doing distillation if the model produced something is far from true Anita we cannot this kind of measurement cannot capture that this so in your case we're using the same alignment model but computer KO divergence between the Rio Rio alignments poverty and the Castillo probability and using that killed our audience to measure the faithfulness over this dataset so okay so now we have order these two tools so we perform an extensive study on the right here of not receiving autocratic models with with with this kind of complexity and the face Modi's so we pick the one dress it with still the English German public voting but we using four different autocracy of teacher model and and many now to question student models so here we show the baseline circles so we can see when we is using different this teacher model from Chinese mop icepick the blue squad just get improved and because the parameter is getting more and more and for the Nano quest models we also rank it in front of weak to strong so it's really difficult to measure the capacity of a model in a very very detailed way because different model may using different ways to inference so for them for the non question one sometimes their parameter the same but if you do iterative refinement is just get better in fullness so right now here I'm just using the the Brusco to get on the rear of data to measure the capacity of the model so if you the model gets better performance on the real data it means you can use model is much higher capacity if the blue sky is worse just get a lower public capacity so this is only the past is only useful for the past and it's really only useful for the north classic models so here one past means that how many time in takes to do the one forward forward process I mean for computation so usually when I put here something like Y is the frosting is 13 it's because this model is using a flow to compute a latent variable which is quite deep and this model although this model is a Northwest model but it takes a long time to compute the prior which actually cost a lot of time so this is approximate the time to do one pass and the iteration means model which is based on iterative refinement and may need multiple iterations to gather translations and for example like I using the this is an instruction transformer proposed by Google which is a log to end time so you first predict one word and predict the two words produce a Leonidas and the four other models may be using a fixed number of iterations so we just I just list all the configuration here but we just need to right now we just need to care about the Bruce copper so the Bruce cross shows the I mean roughly shows the capacity of the model for these scenarios so then refers let's first us analyze that this tale data so as we obviously mentioned we have four teacher models right so tiny small place pick so we first visualize the the proposer complexity and the KO divergence the complexity is a cardiac condition entropy which shows that is the blue curve and it's it's quite monotony actually view increasing the data set the modal's output the compressor is getting bigger and bigger but the real it has much much more difficult compared to all the data that coming from the autocross model so which means that at least the models out was still much easier to run compared to the real data on the other hand because the model gets more complex then the phrase phone is I mean the ko diverges is getting smaller it's also meaning that because we have a stronger IT model then I will produce some data set which close to the real data I should be nice because we want what you really want to learn is to learn from the real data we also we also ProProfs the training Brusco to instead Brusco which you can see that the Brusco is very coil to this our proposed KO divergence face bonus so it's also shows another thing about the data then the other thing I think is interesting is we also analyzed the real ordering score for this translation so we pick one score called the body building scope which will measure is the target the decoder sentence how it is monotonically aligner to the saw sentence so as we all know that English German I in different orders right so German words moving on the back they should be she shouldn't be the same orders however if you look at this this figure you can see that by the way so the smaller this guy is it's means that the mole there's a mole lower regarding that he has so the real data has the most reorderings but for the all the other autocrats models the reordering scores just monotonically drops when the model gets improved and which also makes sense because if the model is just weak it were first trying to capture the easiest thing to run because reordering is more difficult to run for them not for the autocratic models consider compared to the other like monotonically generally words we also pick as it has a sample here but on position is all centers are using the different colors to show different two trunks or the words you can see the real it has it the words actually reordering a lot so different for them for the 30 years I put here and I don't know how to say but these different parts they are completely crossed and the grammatical is a correct however if you're using this tilde has it it's almost looks like monotonically which may also explain why this kind of the earth is more easier to further northwards most ruin the illness we discussed what is the was it the distillation strategy affected the process so in Indy put we always using beam search to output the sentence for the I mean here right but sometimes we may also want to see is a really neat beam search the answer is yes we must use some p.m. search or at least unclear decoding methods because if we're doing sampling we were just increasing the capacity compress the other data again it will get a much of worse performance if we're doing sampling during this time so there's no deflation at all if you do sampling you must use some deterministic like I mean you've trying to find the best approximation which is beam search you can get a better performance now we analyze all the Northwest models we propose here and all the other words teachers so we put everything in this bigger so you can see first we always put the red curve here the red curve means that the teacher's performance so the even the tiny teacher can get alive 24 cuzco which is okay compared to the this kind of Nod question models however if you can see that the stronger not question model is this kind not worth of the curve we are getting closer and closer to this autocracy models and eventually this model will get very close to the autocratic model and we also see that I mean the teacher model does not have to be the upper bound of a student which which will also discuss this question greater freedom pool for this Levenstein transformer here if we're using a small teacher small transformer to dislodge the data and training on that we can get a better performance compared to the original teacher model so those who know know that different they're different yes teacher that parameter actually is smaller than the student the parameter is smaller but people people maybe usually think about maybe when we sit the teachers they are right using the data from a teacher we cannot go beyond the teacher but it is not case for the noise isolation so as long as you're optimized properly you can all still be better than a teacher if you just train like this the third thing is you can see that when you increasing the capacity of the teacher model so all the curves share the same patterns so the northwest model when we increase the capacity of the teacher it first gets the performance get improved and at some point jobs and we we believe that as a point is that the model is that the data is too difficult for this model to capture because we already see that the more with them the capacity of the teacher is the more complex the data is it becomes so and for each student model for each northwest model a MA it must have some limit and when you beyond this limit you cannot learn any more and you can see that this limits actually different for all the models the weaker the student model is there's a limit to yard also much left for them for this kind of linear models it performs best on the Transformers more however if we took a look at like mask predict or lemon stand transformer the best performance actually achieved at like using a big transformer so it's meaning that when we develop a linear students models we always need to be careful that what teacher mode do we choose actually affects performance if we want to get to the best performance on a student model then we need to properly turn this the better teacher model to get to fit for that but that is also a very tricky thing because we cannot really analyze the woods the capacity years so we propose several ways to improve this kind of distillation so one thing is to improve over the week student models here we take them the nearly are not course model as an example slice do you have like an autoregressive student anywhere or no no so here this paper only using the for this paper we only using the not question model as a student so but this it's a happy the same patterns so do you also see in the autoregressive student that as then it drops off with the the teacher gets too big yeah yes so we are doing a lot of teachers to be training our students always follow the quality of the teacher the teacher improves zones inclusive teacher so I think this must be some so if you fix that he is a student you keep improving the teachers model again and again I mean some at some point is I only try this the thing I'll ask is I tried the arrestee em either small teacher and a small student that the teacher is a is the big transformer but these are not LSD yes they are also transport motors but they are not quite sure motors and this may make some possibility is like this pineapple this motor is very close to the teacher model already right so if there's one model the point is even on the right and also this is very depending on the data sense so for all these experiments I show here I'm using the English German there's which actually is quite complicated so if you look at it as I said it has many mister lying or a lot of wrong translations so it's just including the the complexity of the real data so if we also do the same thing on the analysis for them for people usually using like romanian English or similar language which you must easier the real data itself is not so complex mr. Bianchi 14 and yes have you tried going larger so we have some other experiments or knowledge in this paper yes and how houses look like when you go larger in terms of training data you mean this it's desolation or yeah doesn't pass the solution proof for the non auto regressive models when you have more training data so in this case we didn't - how come everything yet so this case is where the student is better than the teacher I mean we only saw a little additional data right did we ever see the school better than the future and seeing this in his last bottom right for some of the teachers I mean syphilis depending on the sport I mean will you have a small teacher right so you're stood in these stronger okay so it does in that small case the student actually has more parameters than the teacher yes okay okay yeah I mean this curve is just strange to say that so even though the the parameter same so it it may lots of things may happens also you're not familiar with Joshua NGOs paper on thinness they intentionally try to do distillation and get higher accuracy of the students than their teachers it's not uncommon to see a small gain inaccuracy on some students yeah but is yoshua bengio is work they actually that was their whole goal was to get hire a person so they developed additional tricks the other problem is that all this work is some employ paper sense so the moment we skip we do this for production and we usually see it works very great but there's always a small gap between students let me scale this so if this is a WPA the dataset that are Davis's are like a hundred Pence - what you used yeah and I agree with you whenever I've done massive datasets we won't be seen of those again yeah yeah I think it seems for change a lot we have a really large scale and I think for large scale training so the less you put the prior into it usually get a better voice but here I mean the goal here we've just trying to analyze when we when a student is still is like a low capacity and the teacher I mean the economic crossing models so how this seems change and we always see this kind of curve for all the models at least for Northwest models I think it depends a lot of things like a model capacity and the data contrasty itself if the data itself is too easy or it's I mean I haven't tried the largest chaos and maybe we mean the data set is large enough then this point will also shift to the to the right so yeah continue for this we have some improvements so to compare to based on the the distillation so one thing is the ball and game can't walk so because we see that the for the weaker student we may need to some easier data to train it otherwise it's my job so the the good thing is we find that if we delay the more your model is hit up again again so it's called banking which means that you first change a future model get the code and you need model the data set to train a teacher again and then they code again and she trains here again and then you train it a lot of times so you can see that the teacher performance will never drops so or at least it just just as a point as long as we'll be using a same date every teacher Malabo never drops or never improve however the students were getting better yeah we would will discussed self training in the second half second part but here because we using the same data so we never include a new data into it so the performance were always stuck here however for the for the NatWest models the more iteration you have is what generally getting better performance and we also analyze the complexity of the data set you can see the more we bombed iterating it has so every time you get a easier data set get the easier method and the one that I get easier you get a better performance on the north west models so it's also a example how to if we have a fixed the week of student how can we get to the better that it has it we can just displace it a teacher model again multiple times another thing is if you have a strong student model how can we further improve the performance so there one choice is called the sequence level interpolation which was proposed by the original paper past teacher student for others sequence level distillation and the thing is we we not only using the beam search in the best one but also using the K past beam search under using and then use Brusco to select the best the translation from this one so it turns out that if you select the key Afric truing this K for ample I use like top of five and then using this top five sentence and the the using sentence brute would select the best translate it worked get a better performance compared to the used just using beam search because we we snatcher elite get a kind of stronger translation model although it's not a really translation model but because we just used it food provide providing the better data then we can use it to train the stronger student models well it's always the the balance between for ample if the things that become too strong then the model was the performance work of your jobs so we need to find the point where to get the students so the code of the most of the non-crossing model can be found in physic it's already implemented okay so I think it it's called I don't have too much time but the said second parts we want to discuss is when we have what what if we'll have more data so we trying to rebuild it to the self training on your screen generation and this is a joint work with two inch ankle charging and the Mac will do so we put our I put self training here is because actually the basically the same thing so the the difference is the previously we always assume the training data for trainer teacher and the Train the students are always the same however if what if we have more monolingual data's because for the second problem we take all the targets we don't need the real targets here so we can using the very much mono lingo data to take code mode data's the targets coming from teacher model and to be simple simplicity for simplicity we we assume right now the teacher model are equal sized with the student model so we don't using different model anymore but we always using more data to train the student model and there's also another difference is we don't after we train the student model using the why we always you can always find two in the model on the real data again so let's they'll become a loop so we starting from teacher model we training and periodontal and when we and then we generate targets on the Milania dancing and once we general targets we train the student model and the fine tuning of parrot in a second and then they code again and fine-tune again and again again so it's kind called authority of self training so how it works so actually so if we remember lot previously I say that if you do iterative distillation they sell yourself you will never improve however if we you add in more data during training especially during training the student time every teacher she actually gets more improvements so for example we call the training on the station data thus called the studio training and and the training on the Rio de that we call the training or fine-tune so you can see that the first iteration the teacher model gets like fifteen Brusco and then then we do that installation and the training training under this table data we get sixteen point five and when you find out that the road is again we get the seventeen and then the for the next iteration get improved and the improved and here are some something just converged and there's one thing is very not very natural is this two numbers so the for the first iteration because of our teacher our students to the model the same-sized however the if we training on student model training that's it it's the same around the teacher the output it gets better performance which is actually not very natural because the model right now there's no difference they are all the same however we just become more because we have moaning what they have then we get a better performance and this model is never trained on any real data set it's just a trainer they not that produce the buys ice splitting Brusco models but get a better performance compared to 15 so we want to understand why this happens so there are several hypothesis the first thing we thought about is a decoding strategy and we mentioned large just now we always need to do a beam search instead of sampling so we do it again so if we do beam search and sampling to try different ways to get the target y star and the trained student model what will happen it turns out that sampling do get worse performance so is again it shows that beam search will help you to find out the better targets it's not so they are not actually saves the same size targets that the same size models because beam search always find the better targets compared to your current model output previously I'm sure it was is because you are training the teacher of the students are trained the student on the teacher said that oh the green arrow is it is a fine-tuning step so once you get this model we were fine-tuned on the real data again so so there's nothing going back from the student into the future there's nothing going back so so I mean it's just become a new teacher so this the program both as teacher one right teacher one trained and teacher wantacode and then we have a student the students are training on the teachers also the what the box that's labeled student here is the is the teacher - teacher - okay it's more fine-tuned I've become a teacher too and then they call again so there's no loop go back to the original teacher but right now what we want to compare these two numbers so the teacher - we go back to the original perineum so useful but that before before training on the we need to reverse the to see of training on the monolingual data and then we find doing on the same data 20 on teaching will train the first teacher you translate the extra model equal beta with that teacher yes then you train the second teacher with that more illegal data only or with that as well as the problem yes so that's that's the test tube numbers yeah so you first train with only the model they go yeah yes then you find 19 under parallel on the original panel radio of the retranslated parallel original parody we find you're not adding you are not adding in possibly just fine-tuning just thank you so drain on the to join P so we made me try so we spent like two or three months of doing jointly and then I some day I suddenly finds that fine-tuning works better can always works better so I just yeah here here for this for this figure is like the desert itself we simulate a lowly source case so that Perry organized about 100 case and his peers and this one is like three million not one one ago so we we also have a for data comparison later so it shows the same thing but here what we want to compare is this two numbers as you mentioned this this 16.5 is only training on the data coming from a teacher and the teacher one so the teacher to only training on the city is a foreign teacher one and you get better performance compared to the teacher one and when we're doing sampling in performance after jobs but still get a better promised an integer one so there must be some still something inside compared is not only the sampling makes better so then we find that so actually we always turn on the draw port which is common right during training we always turn on chopper but during inference there with no one will turn down dropouts so they have they become a some mismatch between the decoding and the training so when you're doing the decoding time you turn off the dropouts however once you get that they has it you turn on dropout and train on it again and that dropout makes you improve and if you do this the same thing if we turn off the dropout you can see for example we're doing sampling without report then the first iteration model whenever improves anymore is it was stuck at the same point as what you come from you were using dropout on training of the second module on the generated data generation no no doing generation we never using dropout right but during the second the training of the second teacher in search oh yeah yeah sorry so this is a that's this this is data in the training with yeah sampling is our job why would you find so we want to analyze why where the King come from so we want to see why the self training will improve because it's not very natural even if we using sampling even using sampling they still have gain compared to the teacher itself so we more the data coming from teacher data which is easier to fit your just easier overfitting yeah yeah by observing an overfitting effect not a drop in something that's specifically true due to drop out specifically due to the data or lucia trainer if you're strong is super simplified this is one of the horns with the noisy back translation that Facebook had that when you train or normal back translation that the data is easier to fit attention I see all still I mean here it's a different buying back translations even know it is coming from the enough in the in a source price different source of noise right so whatever noise you have always making it's always going against overfitting so so you you will see there's something we also amines the other analysis on this yeah so here what do we want to say yes on this control setting especially for this one I mean we actually twink so we're not just making methylated overfitting and get a fifteen Brusco we we just we always choose the best validation bottles and and up here you how to choice to get this model one choice is you starting from scratch to train a new model and the teachers output a second choice is you studying from the teacher model teacher one model right so then that is a very control setting so for them for you first you can't get a teacher one you train and you generate from teacher one and inverse you generate you're using the same teacher one to training out continue training on the data we generate so you will never improve if you turned off the dropout but if you will improve if it turned on the dropout so that is our analyzes here a little too easy and then rub out so just now what I'm saying is you can't do another thing is you continue training flounders the same teacher model so the model what the teacher model you generate and then using the same model training are the same data you generate I mean you are your training on your own output that is a real self training right so in this case if you turn off the dropout the model were just stuck at there there is never improves but if you turn on the dropout it will still give you improvements so that is we think that the dropout kind of is kind of noise is the key which makes the of training actually works and and then then the next slide is because we find that noise will be useful so why not we just add more noise I wish would be similar to the back translation paper was it if level or here what we do is we inject this exact noise in the imposed words which you is similar to the mouse consequence empty noise like worst warp or deletion or the word blank we further broke break the sauce words so sentence into like this X star and then training my stuff so if we do do this you can see that the pseudo training part you will never is just again the same performance so it's actually make sense right because we both source and targets a bike you will never train something you real things however if you're training on this you go back to fine-tuning on the real data you get a much better performance compared to just using the original sub training so that's fine tuning noise no is inject only happened in the self training plan so this is after that this the green curve is green arrow go back you're tuning on killing then in that case why do you get the gains in the fine tuning on the clean data and you didn't get the gains we were scanning all the noisy data I mean so this because in the in the noise part so I mean singers like this so in the noise part because our source and target our fake right we actually never trained something like English to do interesting is you've got the noise here yes the noisier and yet this improved yeah this because in this process you fighting on this right just lets the up training part you get a better representation of the model got pre-trained on the noise in such a way that its effect is invisible until you find you yeah nothing I do you you do sound the opposite requires learning stuff it's same thing for the efficiency share task on the same data set we noisy forward better translation multiple times and train or student models on that right and you got one and a half on father Richmond yeah but he's only getting real good when when he been five kids on this yeah because he's they're doing sub training when we go to teach a student training right yeah exactly the same thing so we do we lick the same thing then we go to the same ingredients I see this is accomplished already by summation okay because we have to saw our submission to the efficiency chef tasks on the workshop for natural w ng t mo P I've been something son of a buck for self training of a student training I think at the same improvements I see I didn't to read that you should they're gonna read this so that's why instruct me to I clear 2020 but yeah but yeah I think it no see former chiropractor for translations so he has a nice evening back transplant and then normally forward translate so create multiple fake data sets and training student on that and it also closes the gap between teacher and student I think I think so actually we also do this so you also try the wrong translation so not only in Genoa Smitha really as we said noisy run translate so you get X to translate YY go back to noise X and using the noise X and the noise why you think that want train the model and then you'll find two neon the clean data they need to get even more I mean I was a slightly better compared to injector the synthetic noise so I think wrong translate actually because it's more cinematics the correct - right so it may give more improvements but compared to the things that noise it's the game is not too big in our experiments so we want to understand what actually this noise is doing so is this just the same way that you had on the previous slide or is it the same yeah the only difference is this just noise part either you injected a synthetic uncivilized noise also by translation noise or you can do wrong translate don't transplant rip translate you train a backward model and you first ex get Y Prime and the Y prime go back X prime target time is always is a fixed also side yeah how could the part feeling how do you get oh you need to have a backward transition model to any other same dataset so training out oh no those just empty Oh perforating oh it's wrong translate right so you translate English to German and translation back and you won't get the same sentence so that centers around so here everything discussed here is always that the same data the 100k small it has English German though but we did experiments on I mean the later it's experimental session so I think we don't have too much time pass here we what we show is you want to analyze what noise in doing so we develop synthetically another which is to do the digits summing we input four digits and is the 11 and 23 and output is 34 and it's a character level things so it's very easy to be trained but if you're only using 250 pairs is the model will still have struggled to predict something so it's a good thing is we can visualize the the arrows in a 2d map so we visualize from 0 to 100 is able to 100 and the arrows like this and this too is first part is the baseline and when you inject noise doing self training then you can see the noise you just the output space getting smooth so we also using the kind of we using the word define the matrix to analyze the smoothness when you applying self-training and a prime know is easy of training you can always see that when you add in more noise during that the output space were getting more smooth and thus here the smoothness is only happened for the summing task is not generation well I think it would be generalized to the same thing in translation so so here we and we have some experiments for more serious experience so we have machine translation task which imposts the similarity the way is 100k and a real period which is around 4 million English German with 20 million new scroll we also the experiments on florist which is a facebook pro crowded the low resource mate translation pairs are English in the poly and we using the 5 million English sentence from Wikipedia as a monolinguals and then we do the similar things here we compare two back translation so we can see that our English German we do see some gangs compared to that transition and 100k compared to I mean it's not big but still have some gain by only using the noisy self training and on this on this largest scale case I mean it's not a larger scale but is on more data case you can get a steel catechins even using so it means that it's not like stuck at some pointers you still have something compared to the so here we don't do back translation because we only have 20 million English part so we also have experiments on Flores English Nepali so the interesting thing here is that the forest asset provides the source from as the test set so in the one sentence is translated from English or one sentence transplant and Nepali because there's some source target to me mismatch so you want to see the effects of self-training so we do see this so when we have the really compared to back translation we can see self-training works better for sentence from English in origin and get the words compared to the Nepali origin which makes sense because we're using a soft style mono data to train when it works better on English origin data and this is what we want to see and overall it gets just the same performance on the English but this Brusco is super low is because it has it is write quite quite quite difficult but still I mean using the provided asset we can catch this kind of improvements so we also do experiments on summer edition which is using the gigawatt as I said we also do to two sets one is a simulated case and another one's folio case for the for data case we're using formulae Monaco data's which come in from the original Giga word essay so it turns out that or you get out word he has said say they've a filter there are around 4 million documents because they cannot find a good title for dense documents but we can using that documents as the mono nado data to for the self-training in that case we can turns out we can get a very close performance to the very strong Pratunam based model at the time and also compared to back transition we can do see when we have a lowly sauce case summarization it gets better performance compared to back translation later we get worse compared to back translation because when you have more titles then the model is easier to do the summarization the conceptually I think this kind of self-training will be much better on the summarization compared with translation because in summarization the backward model is more difficult to Train especially for here you are using canned words because it's a it's an easier than hassle but if you're doing document translation and document level summarization your document will be very long they need to be very difficult to do a backward model for document summarizations however if you do a self-training you can always do this you can take any whatever document sent in and do it self training like this we also have some and the nicest for them poll when we increasing the when we for them we using a fixed and the mountain 100 dataset and we increasing the parody on set we do see the mode parody thing happens we get a more performance improvements on the noise chance of training we also try we just fix the problem as it but improving the increasing the volatility then we can get a more and more better performance but at some point for example we find that after 4 million going to 20 million I didn't see any improvements anymore so the landscape is a guest case and this must be some limits because coming from the party or the asset size and we also tested on the different noise noise level so we find I mean it's very natural actually so if we if we infinitely increasing the noise level you will never get anything trained right so then the homeless will get worse so you find that our first try it's like using 0.12 is the best a choice we doing all the experiments I mean if you're increasing the noise level it just gets worse performance so there the last thing is let's go stay one step back so what if we don't using new data what if we just inject noise on the part of yourself so whatever happen the next case we find something very strange so if we if we do the same thing like self-training but the data is coming from the using the producer to decode and use that to train and then using the party instead of fine chain we still get performance improvements like a sixteen compared to original X 15.6 however if we in general is in the sauce but target is real sentence then you get a much much worse performance like gets like wrong six if you don't do any fine-tune and you find you so if you replace this Y by star where's the real Y here but X is injected noise you get much worse performance you need to have noise X and the noise Y then you find two non real you can get it better so that is the ones you need noisy X and generally yeah I generated the why yeah not noise what yes that's true so no idea what means something that it wasn't also bad so not sampling beam search the Y but noise the X with arbitration always is fine oh yeah I never tried to using the noise x2 gender the white and the train something again and asked me if should be bad right because the noise X you just swap the world's Blanca words how do you expect something it works yeah yeah I think it should be very interesting thing to explore our Theory just the study explore more space because you know I mean some start running again key just to be fair now that the teacher of translate we have noisy stuff but I'm faithfully so you're just probing the teacher space okay that's what we were thinking if it's true it's a different question but the ratio yeah I think yes yeah I think this is the topic is quite interesting so yes for the last Isis would camp either future works one thing is we never try to combine these things so we never tried to put safe training in the non quasi translational stuff for them for we both have as you said that teacher-student case but we have more data between the student then I think we can find the same thing you find also how can we get rid of the distillation that will be a different thing so because I always think this machine is kind of hack which is not so clean maybe because it's it's all because we want to reduce the modality of the data set what if my model can itself can secret the modes in a training so you don't you do need to you need to have a teacher model to help you to reduce data so in this case you can using I can still training for these kind of models also another thing is previously I mentioned the noise level actually affects the self training a lot so if you have a bigger noise is also bad then how can we I mean smartly to identify the what's noise to inject so maybe you can have other ways with Apple like a meta learning or kind of methods to find a better the best noise level for each kind of self training or any other searching tasks lottery tickets offices in this context because if you want to get rid of let that semi go back to teacher-student and we have large teacher small student and you know look at the lottery ticket idea so doesn't that kind of contradict the idea that you could actually get rid of teacher student training because you want to kind of assume that the big model has a much higher chance of finding a ticket hmm the small law really doesn't so no teacher-student training you're just moving the responsibility to find the ticket towards the teacher and then okay I have found the ticket now let me show the thing all the tickets are you alright I think I went on hustle has some people in this way you and don't en he also did something like a teacher-student sing buying that he his key in his case he trying to find out what his tickets it so what I mean yeah you can I cannot explain detail / yes I agree but what I'm thinking is sometimes why we want to this get rid of the staging is its mob because we don't sometimes we don't care our model to capture all the different modes in the data right so if we always trying to do maximum likelihood you're trying to find a model which you're trying to find all the possible things so if the model only need to care the closest the motive for my current generation then it's done so yeah I don't know but I agree that an analysis under the rotary check a theory so I think one of the advantages of escalation is they are giving you no second and third opportunity at doing regularization and why you might be able to find another technique to do that right now it's easy way to get that yep extra chances in regularization when you're trying to train a really small model from a large teacher a lot of the benefit seems to come from the fact that once you go to continuous targets Lujan's it's actually just very hard to overfit two logits whereas it's very easy to improve it to original original boolean targets so you can pound the hell out of a small student and just keep forcing it to learn without having the overfitting problem lately we've had from the target so that's where so I think the lottery effect could be real as well but I think a lot of the benefit that we're seeing in the smaller models is just that the logic data is so resistant to overfitting maybe really can sort of keep forcing that student aligns without worrying as much about everything no I think both of these things the second and third opportunity of regularization and this resistance that were fitting also kind of is compatible with and explains some of the results you're showing where I think we're rejecting noise you know another form of regularization and there multiple rounds of student-teacher training or or helping and fortunately you don't have the overfitting problem when you once you get there just so you know cases so you see what's level we don't really using logics right so yeah just I wanted to say so we trained our climate models on large amounts of translated data so we're trending it's hot pockets but we also are able to completely switch off any regularization so really forcing to be actually happy for it to overfits to the generated data right and that's because the day is mastered yeah and so we generate massive amounts so it's a tiny mole we just get over fit as much as you want so that's right then but now we get the added advantage of having a very peaky softmax right so we can go from research degree research yeah so what one way I think that I can she's learning in health fair and you know imagine you have patients given their symptoms have a 50-50 chance of dying so I mean some of the patients live zero in the descendants of the patients died and on one in the data set and the teacher model which is seeing those zeros and ones it has a very hard learning problem because it has to learn not to try to distinguish between the zeros and ones in fact they might have identical features and yet just by chance someone saw something what would be better a course would be is if you could just give them all in fives and now suddenly the learning problem is easy because the teacher model doesn't even have been worrying about trying to distinguish between you know the flip of a coin that wins zero for some and one for the other race you know if God would give you the probability something it's a much easier learning problem but the other solution to this is not to have the probabilities but to have a hundred thousand patients we're all just like that and now half of them will be zeros and half of you once and it'll turn out the girl net will never learn to distinguish them does it can so it's almost as if you had the soft targets but we made up for the soft targets by having so much more draining data in the first place yeah so I agree that that you should get very similar results in that setting actually I mean one thing I feel I always not feel were unclear not very clear is because in in cubicle for classification we always using soft targets like because we believe is kind of soft probity is kind of talking duck knowledge making training much easier right but here everything we using in sequence level training is always using a hard target which using beam search to approximate these kind of lodges still it's it's if you think about one hot doctor over the whole sentence space so it's still only one point but it still works much better compared to using the real point then that is not something I'm not very clear because it cannot be easily explained by because we're using 0.5 0.6 right and and also which if we try using softer logits to train this model usually will fail so for ample for training and not question models I never try any self training case I never use it but for northwest model if you replace in the distillation with soft Lodge it's regressive okay in that case it will never improve so have you played around with of course the kilrush paper has this terrible in the end but i also show that they mix the two distillation methods hard targets and soft lodges and they seem to be getting their their best results from yeah seems like this but i mean my previous where previously we're not doing our crushing models i first try I mean everyone will first try soft but 10.5 house yeah where I was you know I also trying to combine things and also pinaka song who like several English because I thought that they were just they were the hard targets generated by a teacher yes original hard times ha no ha caucus generate lecture and the softmax distribution on top of it just a combination and the paper says that that's like the best method I always wanted to try it but it feels like a lot of work to actually implement it I want to go there yeah maybe things will change for autocratic models so yeah I think it worth exploring but another thing is we're not doing not Quasimodo's whenever so here for self training we always trying to go back to fine tuning right I hope you do not quest mod oh because the model is weak if you do fine tuning you just your original I get a better performance it subtly drops if you're tuning on the REO theta so I think it is to work are kind of still different this is for self training when these two motors are same and therefore the non question models will be just you only using the data coming from the teacher model and only using the hard targets no subtext [Applause] 