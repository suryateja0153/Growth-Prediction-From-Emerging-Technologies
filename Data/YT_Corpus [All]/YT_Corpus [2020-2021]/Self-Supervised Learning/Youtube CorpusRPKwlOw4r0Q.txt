 hello everybody my name is fernando from  university college london and i'm going to   present our work on simulation of brain resections  for quantitative analysis of epilepsy surgery   epilepsy is a chronic disease of the  brain that affects around 50 million   people of all ages which makes it one of the  most common neurological diseases globally   it can often be treated with drugs however about  one-third of epilepsy patients are drug-resistant   and the way to cure these patients is by resecting  the part of the brain that causes the seizures   this image shows a coronal slice  of a post-operative t1-weighted mri   where the right temporal lobe has been  resected as shown by the green arrow   however only half of the patients who undergo  a resective surgery are seizure-free after five   years therefore we need to better understand and  predict who will be seizure-free after the surgery   and for this we need to know exactly how  much of each brain structure has been removed   to quantify the resective surgery the resection  cavity must be first segmented from the post-op   mri bottom left postop mri is registered  to the pre-op mri and the segmented cavity   is projected onto the pre-op space using the  resulting transform finally a brain parcellation   obtained from the pre-op mri is masked using  the transformed cavity segmentation the masked   parcellation can then be used to compute the  percentage of each resected brain structure in this talk i will focus  on the method we developed   to segment the cavity from the postoperative mri cavity segmentation is a difficult problem due  to the variability in shape and texture of the   cavities and to the different post-operative  phenomena that make some parts of the image   unexpectedly dark and unrelated to the cavity  it is also not trivial to compare the pre and   post-operative images using registration  due to the missing correspondences and   non-linear deformations here green and  red arrows show parts of the images that   do and do not correspond to resection cavities  respectively in the first case on the left white   matter hyper intensities make it difficult to  differentiate white matter from csf in the cavity   in the second case the brain has shifted after the  surgery generating a new cavity filled with csf   in the second and third cases a  postoperative edema has also appeared   in the third case there is also a hyperintense  blood clot within the cavity the fourth case shows   an arachnoid cyst adjacent to the resection  cavity which has a similar appearance to it we could use deep learning to solve this  problem however there are no publicly available   annotated datasets and manual segmentation  is challenging mostly because of the lack   of intensity gradients between resection cavities  and other areas filled with csf as shown by the   yellow arrows in these two images on the right to  generate large datasets for training convolutional   neural networks we have developed a method to  simulate resections on normal brain mr images we generate an image of a resected brain and  the corresponding ground-truth segmentation   from a normal t1 mri and the corresponding brain  parcellation that can be computed using standard   software such as freesurfer i will now explain  how we generate the cavity shape the ground truth   label image and the resected image to generate  the cavity shape we first model a sphere as a   geodesic polyhedron built from an icosahedron  that can be subdivided using any frequency   depending on the number of vertices we'd  like to obtain the sphere is a mesh whose   vertices will be radially displaced using  a gradient noise to perturb the surface   if we use a uniform noise distribution like the  one on the left changes in perturbation between   neighboring vertices are too large and therefore  not realistic using a smooth gradient noise such   the one on the right results are more realistic  perlin noise is a type of gradient noise typically   used to generate natural looking signals such  as handwritten lines clouds terrain in 3d games   we use simplex noise to perturb the sphere  vertices which is a variation of perlin noise   that is more computationally tractable for  a large number of dimensions and generates   fewer directional artifacts simplex noise is  computed on each vertex of the sphere and they   are radially displaced accordingly in this figure  noise values have been computed for all voxels for   visualization purposes negative noise values are  shown in blue and positive values are shown in red finally a random affine transformation is  applied to the mesh for increased stochasticity   to generate the ground truth label segmentation  we start from a normal t1 weighted mri   and a corresponding brain parcellation grey  matter binary mask from one of the hemispheres is   computed from the parcellation and a random voxel  in it is selected as the center of the perturbed   sphere this is because the epileptogenic zone is  always in the gray matter therefore all resections   must include this tissue then a resectable  tissue mask is computed from the parcellation   by excluding certain brain structures and  applying different morphological operations the   ground-truth label is computed as the intersection  of the surface with the resectable tissue mask masking out the voxels in the mri with  the ground truth label generates an   unrealistic simulation that could lead  to a poor generalization to real cases   therefore we use a csf mask computed from  the parcellation to generate a csf-like image   that is blended with the original mri using a  randomly smoothed version of the ground-truth   label as alpha channel in order to mimic  partial volume effects near the boundaries as the simulation takes only a couple of  seconds we run it on the fly during training   which allows for large variability  in the training set the simulation   is implemented as a TorchIO transform and  the code is available at this repositories to test the efficacy of a method we have  used data from two different sources   first we collected images from 430 subjects that  underwent resective surgery at our institution   and performed manual segmentation of  the resection cavity on 133 of them   plus 67 from two other human raters  to assess inter-rater variability we also downloaded more than 1800 t1-weighted  mr images from the OASIS IXI and ADNI datasets   for training we simulate resections during  training on the images in the green rectangle   the yellow rectangle corresponds  to the EPISURG data set I'll now explain some of our experiments  first we train a baseline model with our   133 manually-segmented images using ten-fold  cross-validation then we use the publicly   available images to train using only simulated  data for self-supervised learning we also added   the pre-operative images in EPISURG to test  whether using images from the test distribution   was beneficial finally we used the model from  point 3 to create pseudo-labels for the unlabeled   postoperative images from EPISURG and train a new  model from scratch using semi-supervised learning   we use the same custom implementation of  a small 3D U-Net for all the experiments   and test all models on the  manually segmented images we found that the baseline model performed  quite poorly with a median Dice score of 65.   training using a larger simulated dataset we  obtained a median Dice score of 80 which is a   statistically significant improvement with respect  to the baseline adding the pseudo-labeled images   resulted in a marginal improvement obtaining a  Dice score of 82. we can see that the score for   all models and the inter-rater agreement are  within the same range except for the baseline and here are some qualitative results in these  images the manual annotations are shown in green   and predictions of the best model are shown in  magenta we can see for the median case there are   some discrepancies around the border where it  is difficult to define the resection boundaries   in the worst-performing case the model partially  misinterpreted a region of brain shift as   a resection cavity and most failures are caused by  brain shift or by blood clots within the cavities to conclude we have developed a method to simulate  brain resection cavities on pre-operative MR   images and we train a convolutional neural network  with simulated data showing that results are   superior if the dataset is large enough the  code is open source and available on GitHub   in the future we will explore different  simulation models to understand the necessary   complexity to model the resection cavity we  will also explore additional semi-supervised   learning techniques to better exploit our  unlabeled postoperative images to improve   results I'd like to thank my colleagues  and my funders and thank you for watching 