 hello everyone my name is Yu Sheng Feng. my advisor is Professor Chiu wei chen my research topic is semi-supervised anomaly detection what is anomaly detection anomaly is the sample that is different from most other objects so once you want to define anomaly you need to define normal object first anomalies are also referred to as outliers novelties and noise and anomaly detection ad is the process of finding anomaly the ratio of anomaly is usually small or equal and 5% another detection is a principal in variety of data domains like temporal data time series and images for example fraud detection finds the crime from temporal Reiter most of records are normal transactions only a small fraction of record belongs fraud another example is detecting anomaly from IOT sensor data since the data is a time series we need to find anomaly from its time domain a time neighborhood another popular topic in industry is deferred detection is usually tell anomaly from an image as you can see the first row is no more image and the second row is the same Prada with DV like here you know a hot dot and here the pillow has no heart out now NASA TV and the third rule is the running of the defect there are three types of an air injection the first one is supervised on our connection and the second one is called semi-supervised on our attention and the third one is called supervised on normally detection super fast enough detection require the trained dataset that has label instance for normal as well as anomaly cursors so you have to test in this setting and the key difference to many other statistical classification problem is no protection has in balanced cast distributions the ratio of naruto's is usually less than 5% and semi-supervised anomaly detection use training data has labeled instance only for the normal curve so there is only normal cast in your training data we saw any outliers only model the behavior of normal data and in my personal opinion this property is very important because anomaly usually has high variation I'm predictable if they appear regularly we would not call an anomaly so we don't have any assumption in lease we don't have any assumption about anomaly in this foreign stating the third one is called unsupervised on our attention in this proceeding it did not require any train data we directly detect anomalies in an unlabeled test dataset so we have only one data set include normal data and some anomaly we want to find an anomaly in this data set okay in this talk I will focus on imagery data so here I give some application in Judea first application is remote sensing for example after disaster the government want to statistic the total damage of layer building so it takes a lot of pair images and he wants to identify whether buildings have been washed away by tsunami or not the reconciler is an example the left image is before - tsunami and right image is after a tsunami okay and the second example is medical image we can detect disease from a clinical image right here are just extra image we can take a segment or classify whether this image is no more or abnormal and nest is survelliance like this image this is x-ray security screen image from airport custom um in this red rectangle is illegal item as we know illegal item is really short so we cannot label many illegal item to do classification so this is an architectural problem okay next I will introduce some basic idea and basic idea of semi-supervised anomaly detection the first is reconstruction best Mesa this idea often combined with generative model like auto encoder Oregon's we turn on normal data then we assume the model only generates normal images after we get our trend model we can select anomalies based on the reconstruction error because this model only Tran normal image so the intuitive behind list master is the Reconstruction era of abnormal image will be large and thus taken here is classification path Mason the spirit behind this approach is that they want to learn a good representation from normal data so they can separate no more of a normal based on these good features the separation between space region contains normal data from all other regions so we separate our future space into two or more regions and one region containing only normal data and other regions is from our anomalies and the to cast a true classic test technique of this Mesa is one cast classification or self supervised learning now first I will introduce reconstruction bass master an autoencoder is one of the most well known deep generative model it contains two-part encoder and decoder or generator an encoder map input image too late and space and decoder Maps latest best feature to back to include image space and we want the output is the reconstruction of input so an autoencoder reconstruct include itself and we usually use mix crew area as loss function okay so auto encoder learn a meaningful letter representation without any supervision these are unsupervised learning master and nest get good and generative at a versatile network also called gap gang transistors consists of two networks one is generator and another is discriminator generator Maps a noise from later space to data space this grenade er learns to distinguish Rios pose back samples we train this way inator to maximize the probability of assign the correct label to post real example that is samples from generator in other way we simultaneously channel generator to minimize this turn look one minus D of G of D let us maximize the probability of G of Z solar generator wants to generate the realistic image to treat the discriminator okay so the ng player 2 player minimax can with this value function okay okay here comes our first an our detection algorithm the anomaly and anomaly come by auto encoder and Ken and in their province 1800 of train data are normal examples so this is and semi-supervised anomaly detection algorithm and here is their model structure illustration your lay used and auto encoder and concat followed by decoder and there is a discriminator to distinguish the reconstruction and row input okay there are three loss functions contextual loss encoder loss or the posterior loss contextual loss Emax reconstruction similar to raw image the retouch option is denoted by X hat raw image is denoted by X this this loss is distance between X and X hat so it will let the best autoencoder to reconstruction X okay the second loss encoder loss there's no second encoder learn to encode normal image from our assumption the auto encoder only generate no more image no matter is input is no more or of a normal so the second encoder only encode the normal image to is too late and space okay the third loss of the fusteria loss this loss guide the auto encoder by difference between internal feature of raw images and reconstruction on the other hand we can utter just discriminator to distinguish real the fat image by cross-entropy so this is can structure with an autoencoder with additional encoder okay after we get a trend model we can start to infer our test dataset if X is normal through the auto encoder X hat is also a normal image and through the second encoder the Z hat will close to the right because X is a normal image so exhale it's also a normal image so they had NZ post feature of normal image so Z will close to the Hat I'm gonna have if X is anomaly then soonest autoencoder the Hat will differ from X because this auto encoder only generated normal image so X head we are differ from X so the Hat we are far away from the right this is the feature of normal and this is the feature of anomaly okay so late the fine layer anomic score as the distance between Z and Z have two Layton features because the distance in input space is easily affected by small noise so it is due to be more robust in compare the feature in Layton space Hey the second idea classification best Mesa to starless part I need to introduce selfs revised representation during self service learning is one of supervised representation during its learning ring for feature without any human label Hey for example protecting image retention for any ever image in the asset we can duplicate every image by four transformations like 0 90 180 and 270 degrees like this figure for any image we can produce your degree image 90 degree image and 180 degree image and 270 degree image because we know hot transformation was applied on this image horotec whole rotation decree was applied on this image so we can give every image a label per se zero degree is y 0 90 degree Y is 1 and Y is 2 1 3 so we have image label pair right this is a supervised data set so we can turn a convolutional neural network to predict the rotation in a super fast manner okay we only give this model images without any label and it labels itself right so it's an unsupervised learning but we train this model in a supervised manner so this family of learning artisans are called self supervised learning model supervised itself so because self supervised learning okay now we know how is self supervised learning the desk question is why does it able to learn representation in this way okay there is intuitive way to think about this problem okay now we trained a model that is able to recognize the rotation transformation and how does human know the rotation degree on an image I guess the answer is here look look this image now you know there is an object in the foreground yeah right it's a bird and you know the chef of birth and the location of this bird um you can look the first image and you know the first image is rotation 90 degree from the second image right because you know this bird is stand this way and if you rotate 90 degree and the image will become the bird will become this okay once you can recognize the rotation degree you must know the type of the object the shape of the object and location of the object right so the model will be required to understand the concept of the object depicted in the image like type there is a bird in the foreground and stand on a branch the post the location this bird is in the center of image and chef or bird okay so the model learned the type the location the shape of the object now this is a good representation of an image okay based on the self-certify learning we can introduce our second anomaly detection algorithm enormity central use geometric transform geo anomaly detection they used self-service to learn representation and they use rotation shift a mirror transformation rotation the 180 180 and 270 degree there are four transformation and shift along x and y axes four minus zero plus C minus C 0 and C pixels right on top flip or not so there are 4 times 9 times 2 72 transformations in total and their detection algorithm is travel world first we trained a classifier on the transform training state so we have a model it can predict our transformation was applied on the image this model up to the probability about transformation they approximate the probability to be a illustrate distribution for each transformation this is called post-processing just a parametric distribution approximation yeah ok and then once we get this the usually distribution and trend model we can infer our test set so if image in test step and for each transformation TI is one to 72 and we can get the software for beauty y of T I of X Y is softmax for ability and then we have the rich led approximation so we can get the usually likelihood called P and let detect anomaly based on the score function and is written in this form summation log P and P is PDF of delayed so locked PDF summation locked PDF is just a log likelihood of the dictionary transform okay highest score function work for each transformation the authors used a dictionary distribution to model is normality right so we have 72 the Richland distribution of ransom Asian because our model only Tran no more data so list the root flare distribution only model the behavior of normal data lady fine layer score function as the product of all density function based on likelihood okay and if an image has higher score then this means this image is more likely normal right hey this is intuitive your counselor experiment result like did the experiment of Civitan see hotel has ten classes so we can create ten different experiments every experiment use one class a single normal class in this experiment so for example experiment liberal use car 0 as in liar it's human 1 use first one as in liar so the train data has 5,000 images only one class and test data consists of 10 classes there are 10,000 images and the here is the AUC result FC score of our first equation has taken algorithm as you can see the second algorithm I'll perform the first algorithm only stochastic okay next is our proposed amaze office false okay first we do the simple analysis on the latest best of geometric anomaly detection here is our observation feature of inliers should be grouped together in the invading space in this space and inter-caste separation is large real and intricate separation right because Jo ad to do a classification of every trance of every transform so it can separate every transform and group lost and transform together but the problem is that outliner if we if all the input is all right here then the feature of a liar will we'll look at on a strange location and there's no guarantee low likelihood because this is extrapolation next the model may know the rotation from back wrong so maybe it will now learn the shapes the location from object is learn features from back row as you can see we can know the rotation degree from land and sky we saw knowing any single polish object okay now based on this observation we propose our approach we combine auto encoder and so purify slurry first if a lyre is isolated so we can project a liar to normal manifold and because we're seeing this manifold also encoder only reconstruct in liar so if an aligner is projected to normal manifold it will reconstruct very bad second if the model North is rotation from background so this outlier will look at normal manifold so it will reconstruction bad yeah so our idea is very simple the button is our motto architecture we use three loss functions first is Chris vacation loss is to trim the curse fire to predict transformations and the second one is reconstruction loss is to chain the autoencoder to reconstruct T of X the transformed image and the third one is feature reconstruction loss it's like auto encoder inside and bigger auto-encoder once we get D we want to project it onto normal manifold so we chain another auto-encoder to reconstruct the and because this this autoencoder only learn to return from normal feature so this the head is the normal manifold so here is the result and all experiments taking the same and here is our AUC and as you can see our AOC score is better than 280 by 0.01 0.01 fine yeah only slightly improved row ID so we are still looking for better master like better model architecture or better called projection Mesa summary we combine two different ideas reconstruction and classification an our approach improves a you see my real point zero one five it was you're looking for better model architecture to improve list doubles and we also want to try down linear projection rather than linear projection okay this is my presentation thank you for your listen 