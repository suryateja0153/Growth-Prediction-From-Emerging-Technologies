 Hello. My name is Joe Hardy. I am a  compute solution architect at Hewlett Packard Enterprise. Today I'd like to talk to you about how you can deploy different hybrid cloud solutions on top of HPE composable infrastructure. There are a number of different technologies in the hybrid cloud space and a number of vendors, all working in that same area with their own technologies and own capabilities. Typically, we see the public cloud providers providing their own software and platforms a service offerings and also, we are seeing customers wanting to leverage those capabilities on premises where appropriate, and off-prem when they need the right resources that those public cloud providers are able to offer. Where HPE is fitting into the marketplace in this is both in the infrastructure layer in terms of the physical resources and the solutions that provide infrastructure for those different clouds. But also through things like GreenLake as a service, a way of brokering the connections between what is On-Prem and what is off-prem. Now, when we are talking about building a hybrid cloud solution or a multi cloud solution. Quite often, this may involve a number of different technologies within the On-Prem environment and what we have seen in a lot of customers doing the past is set up a separate sort of technology silo for each, there will be a lot of infrastructure dedicated to one particular ccloud technology. Perhaps Red Hat OpenShift, perhaps another silo of technology allocated to Microsoft Azure Stack. Composable infrastructure gives a single infrastructure API to connect into all of these different technologies. So we have got that out of band connections. This API could be used by any of the on-premises resources to consume their infrastructure so potentially you can then set up their server profile for a particular environment and allocate that to a number of hosts. Maybe this one, and this one, and these ones over here, and this bit of storage, and they all get consumed by that one environment. When I start allocating a separate server profile for one of the other environments, for instance, Microsoft Azure Stack again, I can start consuming my resources from that same bit of physical hardware. It doesn't matter whether these are deployed in the same rack as long as potentially that they are the same security level or availability zone within the customer. These things can be deployed alongside each other because they kept isolated by the Virtual Connect technology and the OneView API. This also applies to the storage that we consume underneath these resources. So we have the ability to set up separate volumes, potentially on a Nimble array, or a 3PAR array or technology from HPE Primera and these things are all then sharing that same infrastructure resource underneath. Potentially, we can even allocate the same things to rack mount servers within OneView profiles as well. What we are then able to do under technology contained within the HPE GreenLake proposition is tie the workloads together with what you are deploying in the public cloud space as well, so you can have the same virtual machine deployment capability in your Microsoft Azure public cloud environment as your on-premises Azure Stack. But equally you can have those same sort of containers defined that you might be using in AWS and OpenShift or AWS and on premises vCloud Foundation, for instance. So there is this now way of sort of doing parallel deployment both in the private and public cloud space. If you'd like to learn more, please look in the description where we have got a number of links to this sort of capability or speak with your local HPE representative. I hope you find this video useful 