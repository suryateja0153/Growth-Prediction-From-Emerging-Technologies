 [Music] you welcome to fundamentals of artificial intelligence in this module we look at planning within problem-solving estate space search we saw that an agent can consider the consequence of a sequence of actions even before acting to arrive at the best first move knowledge representation and reasoning on the other hand allows explicit representation of a state as well as actions and ensures that an agent is able to succeed in a complex and in accessible environment that is too difficult for the problem-solving agent we combine these two ideas to arrive at the planing agent planning in its most abstract form can be seen as problem-solving planning is problem-solving with the agent using belief about its action and consequences of the actions to get to a solution by searching through a abstract space of plans planning algorithms are special-purpose theorem provers and they are able to arrive at a plan by using the actions as certain axioms in this lecture we would look at first the planning problem then we would look at a variant of first-order logic called situation calculus which can use an inference mechanism to arrive at a plan thereafter we would introduce strips of formalism in which planning problems can be expressed and a plan can be arrived at but first let's look at what's a planning agent in order to understand a planning agent we look at what is called the sense plan and act sequence so planning is one of the most useful ways that an intelligent agent can take advantage of the knowledge it has and its ability to region about X and and consequences here we have shown an agent which has both sensors and actuators so the senses sense the environment and through the actuators it X it decides about the plan through a sense plan act cycle actions can be seen as a sequence of certain activities it does on the environment now planning is central to the idea of artificial intelligence wherever AI is achieved through computational means because it is concerned with generating intelligent behavior using what is known to find a course of action that will achieve the goal now the planning agent is very similar to a problem solving agent for all it needs to do is achieve its goal through a plan which could be looked at as a problem to arrive at the goal now in spite of this similarity the planning agent and the problem solving agent has a huge difference this difference comes from the very fact that when I'm talking of a planning agent I have to somehow think of representing its goals States and actions and use explicit logical representation now these use of explicit logical representation enables the planner to direct its deliberations much more sensibly before we proceed further let's try to understand what we mean by planning when we are talking of planning planning is reasoning about future events so as I can establish a series of actions to accomplish a goal a common approach to planning is about representing the current state and then determining the series of actions necessary to reach the goal State therefore it could be thought of as a problem-solving technique plans on the other hand are created by searching through a space of possible actions until I arrive at a sequence necessary to accomplish the task and therefore planning could be thought of as a specific kind of state space search it deals with steps and goals that it need to interact coming back to the planning agent we could now have a better feel of how it acts it senses the environment and does decides which state it is under that state it needs to know which actions it need to perform and move forward towards the goal and therefore it interacts with the environment by acting planning as we can make out from this short discussion involves search through a space and the search could be either of two ways you choose an action whose preconditions are met until a goal state is rich such a planning is saved to be progression planning this is a forward approach whereas we could have regression planning in which case we choose an action that matches an unachieved sub-goals while adding the unmanned preconditions to the set of sub goals and this we continue until the set of sub goals is empty as you can see regression planning is a backward approach which is goal-oriented and tends to be more efficient now just a couple of mansions on the early planning systems the first mention should be made of the logic theory test by Newell and Simon in 1956 these were one of the first to use problem domain information and they could prove theorems in propositional calculus the logic theory tests operated by using backward reasoning from the theorem to the exams then around 57 we the general problem-solver by a new Alan Simon these looked at questions of how to solve human intelligent problems looked at propositional calculus proofs puzzles symbolic integrations etcetera the general problem solver actually introduced means and analysis find the difference between the current state and the goal use their table to find an action to minimize the difference between the two states and thus come up with a plan the earliest methods of planning made no distinction between more or less important plan elements and the lack of structure led to poor performance one of the earliest non hierarchical planners was strip's the Stanford Research Institute planning system we will look at strip's in more detail during the course of this lecture hierarchical planners on the other hand made a distinction between more or less important parts of the plan now let's take a minute to understand what we mean by important and non important parts of the plan for example you are thinking of purchasing a new car and there's such a scenario one needs to decide where to get the funds while planning it doesn't make much sense to find a good parking place on campus for your car before you have the money to buy it so non-hierarchical planners could not make that distinction for them every element of the plan was equally important hierarchical planners on the other hand made a distinction between more and less important parts of the plan and one of the first hierarchical planners is the abstract base strips it's like strips but it plans in hierarchy so that greatly reduces search space and is much more efficient at solving large problems now what it means by able to distinguish between more or less important parts of the plan is that certain preconditions are just as more important than others by adding weights to those elements so early recognition of bad paths and getting rid of wasted search is a criteria of such planners use a hierarchy of abstraction levels that is such planners solve the highest level of abstraction once that passes it increases level of detail there are certain assumptions under classical planning and here is their list we assume perfect information deterministic effects is what is assumed under classical planning and the classical planning any action is assumed to be instantaneous that is execution is instantaneous for a given action such planners are single agent and these agent is not concerned about time cost or resources and the environment is finite and Static now these assumptions look very strong and one needs to remember that these were made early on because complex tasks were too complex to solve so these assumptions were used to complete smaller tasks such as the blocks world examples modern approaches to planning deal with scaling issues which we will cover in the next lecture now let's try to understand and define the planning problem the planning problem as we have been mentioning is about finding a sequence of actions that achieves a given goal when executed from a given initial wall so what we have is an initial state description thereafter we know that possible a set of action descriptions which define the possible primitive actions by the agent and a goal state description and when we say we need to compute a plan we mean that it must come up with a sequence of action instances such that executing them in the initial state will change the wall to a state satisfying the goal state description now the goals are usually specified as a conjunction of sub goals to be achieved so here on your screen is the initial state of a blocks wall problem now the purpose of planning is to find a sequence of action that gets me from the initial state to the goal State that's shown on your right so the idea is to pick up Block C put it on the table pick up B put it on C pick up a and then put it on B to arrive at the final set which is ABC stacked one on top of the other now even if planning at its most abstract level can be seen as problem-solving one needs to understand that planning and problem-solving are different and this difference comes because of the representation of the goals states and actions and of course the differences in the representation and construction of the xn sequences now consider the robot shown on your screen on the right and imagine that it needs to solve the following problem it's asked to get a quarte of milk a dark chocolate and a good book now the goal of planning for the Bayesian is to choose action to achieve a certain goal is this exactly the same goal as for problem-solving now we need to understand that there are some difficulties with problem-solving the successor function is a black box it must be applied twisted to know which actions are possible in that state and what are the effects of each one suppose now on the other hand for the robot here the goal is to have milk for some initial state where half milk is not satisfied the successor function must be repeatedly applied to eventually generate a state where half milk is satisfied an explicit representation of the possible actions and their effects would help the problem solver select the relevant action and this is what is done in planning and missing in problem-solving otherwise if that is not done in the real world an agent would be overwhelmed by irrelevant actions now on the other hand if you look at the goal test the goal test is another blackbox function states are domain-specific data structures and heuristic must be supplied for each new problem on the other hand for the robot suppose the goal is have milk and have booked without an explicit representation of the goal the problem solver cannot know that a state where have milk is already achieved this is more promising than a state where neither have milk nor have book is achieved so give an explicit representation of the goal it is possible for a planning agent to know which is a more promising state and this is possible for a simple problem-solving agent now the goal may consist of several nearly independent sub goals this is not possible to be known to the problem-solving agent at all whereas when we are talking of the planing agent half milk and half book may be achieved by two nearly independent sequence of actions and this we can have somehow encoded in the representation schema of the action so representation in planning actually opens up the black boxes by using logic to represent the action states and goals this is the first idea behind planning the first idea behind planning is to open up the representation and the planning algorithms use descriptions in some formal language usually first-order logic or subsets they're off so if you look at planning planning is about problem-solving and logic representation being brought together the second idea is to add actions to the plan whenever they are needed rather than in an incremental sequence starting at the initial state for example in order to have have milk satisfied I can include an accent sequence by milk when it is required now making such obvious decisions first can reduce the branching factor and reduce the need to backtrack the final key idea behind planning is that most parts of the wall are independent of most other parts so a conjunctive goal like get a quarter of milk and a chocolate and a book can be solved by divide and conquer strategy that is by generating three goals out of this to get a quarter of milk to get it chocolate and to get a book planning and problem solving as we saw can often solve the same sort of problems however as highlighted here planning is more powerful because of the representation and the methods used the representation of the state's goals and actions which are decomposed into set of sentences usually in first order logic and then the search in planning proceeds through plan space rather than state space so we are searching over an abstract space of plans rather than this state space though during the course of our discussion here we will also talk about state space planners and the most important thing to realize is that sub goals can be planned independently reducing the complexity of the planning problem we will now talk of a situation calculus which is a dialect of first-order logic in which we can express beliefs about a changing world now one needs to realize that this is not the only way to represent a changing wall however situation calculus is a simple and powerful way to represent a wall that is changing and it lends itself naturally to various sorts of reasoning including planning situations and actions are explicitly taken to be objects in the domain of situation calculus you may be in the situation of holding a crystal vase now the action of dropping and breaking it moves you to the next situation of having a broken crystal ways this is what tried to represent in situation calculus so the ontology is about having a situation variable a timestamp added to fluence fluence our predicates or functions whose value may vary from situation to situation I then have a situation which is a snapshot of wall when nothing changes like in this example there are two situations one where you are holding a crystal vase and another when you are having a broken crystal vase these are snapshots of the world when nothing changes in between you have the action of dropping the vase and breaking it which is when the world changes so action is represented in logical terms so I could have actions as already you could figure out the action of dropping it and breaking it or you could have other actions like the robot moves forward the robot takes a right turn so on and so forth constant and function symbols for actions are application domain dependent now there is a function that returns the next situation after applying action a in situation s and that's written as result a comma s where a is the action and s is the situation and this function returns the next situation so in our example of holding a crystal weighs dropping it and then the next situation of having a broken crystal weighs could be best represented by as being the situation where I am holding a crystal vase and a being the action of dropping and breaking it so this function would return the next situation of having a broken crystal vase fluence has already mentioned our functions and predicates that vary from one situation to the next I could also have a temporal or external predicates and functions that do not have a situation as an argument like gold G 1 so G 1 is where gold is and things like that so here is a situation calculus example for the blocks world problem on the left you have your first situation s0 and you could see that I have a block a and I have a block B is on the table and B is on the table kindly note that I could have added more predicates here to say that the hands of the robot are free and I could have added a proposition saying hands-free what I want to show here is that I have a situation which could be expressed in terms of certain predicates and functions that I define and then I have a neck situation here which is s1 so this situation could be about holding a and B on the table thereafter I could have a third situation where a is on B so from moving from s0 to s1 I would need an action like pick up a moving from s1 to s2 would require a action like stack a on B and in terms of the results function I could write situation s 1 as the result of the action of picking up a in the situation as 0 so that's situation s1 and I could write as to as the result of stacking a on B from a situation that results from picking up a in a situation as zero so now as you can see this I can embed the result function as I want because this situation here is s1 and the action of stacking a on B and then on s1 gives me as two but instead of writing s1 here explicitly I could express it using the results function so finally after these three situations I have the final situation here which is about block a and block B Block B being on the table and a being on top of B now this is where you need to take a minute and realize what is the sequence of actions in situation calculus look like so here when I have results and the xn sequence is empty I remain at the same situation s but if I have an X in sequence which is a followed by the whole sequence then I can write it as the result of having the sequence and the situation that results out of a on s and this is what we did in the previous example just now describing a vault as its tense I define in number of actions and then I attempt to prove there is a sequence of actions that results in some goal being achieved this is what is done in situation calculus now in order to do that what has to go in our knowledgebase to prove these things is that we need to have a description of the actions now representing actions in situation calculus uses two axioms one the possibility exam specifies under what condition it's possible to execute action a in state s so it gives a series of pre conditions under which it is possible to have action a in situation s like the agent could be at X in situation s and x and y are adjacent so it must be possible for the agent to go to Y the other exam we have is about the FX it specifies changes that results when action a is executed in state s for example I am told that it is possible to do action a in state s then I should be able to write down the changes resulting from taking that action and that's the effect axiom so if I say here that it is possible to go to X from Y and the situation s then as a result of that the FX x IAM should be able to state that the agent is at Y as a result of that action in situation s so FX axiom are too simple they say what changes but not what stays the same now this is a very important problem of how much of the things that do not change do you want to cover in the exams that you want to write so the frame problem is about representing all that stays the same this must be done in addition to describing what changes when in action is applied since almost everything stays the same from one situation to the next we must find an efficient solution for stating what doesn't change so consider how each fluent evolves over time instead of writing the effects of each action that's what is one solution to the frame problem so this is called the successor state axioms the successor state axioms specifies truth values of fluent in the next state as a function of the action and the truth value in the current state so here is what is the successor state exam saying I have the possibility of action a in state s and this fluent becomes true so I have to list here all the conditions under which a in situation s makes the fluent become true in the successor situation and I should also describe all the conditions under which the fluent becomes false in the successor situation these is called the positive effects and this is called the negative effects and this is how you need to write the successor state axioms let's take an example to understand this so here I have the possibility of having an action a in situation s so my fluent F would become true on doing a in s and this would be all the positive actions or I would just have F and the situation and I would have all the negative actions not being there so given that it is possible to perform ans the fluent F would be true in the resulting situation if performing ans would make it true or it is true in s and performing ans would not make it false that's what I am saying in the successor state exam so let's take this example and see what we mean by here I have an action a in s and let's say that the object oh I want to do an action in s now if the action is about dropping oh and I know o is frizzle then it is the condition that it would be broken and it would be broken in s and not repairable is what I am saying so here what I am saying is or it was the case that it was already broken in s without the action being done and the action was not about it being repaired because if it was broken in s and the action was about it being repaired then I would not have this being broken so the action is about dropping I would break it what doesn't change is not being covered in terms of explicit facts but what is covered is the fact that it would have remained broken without even the action if the action was not about being it repaired so the successor state exam is talking about performing an action in s and the fluent F be true in the resulting situation or it is already true in s and performing a would not make it false now planning in situation calculus enables and knowledge base agent to reason about the results of action by projecting the future results and finding a plan and it achieves a goal but these are the requirements so proving a plan is about achieving a goal and requires a goal to prove an initial state description that says what is and isn't true successor state exams which take into consideration implicit effects and an efficient inference procedure using this kind of exams now let us look at the strip's representation which is an alternate representation to the pure situation calculus for planning in strips the wall we are trying to deal with satisfies the following three criteria only one action can occur at a time actions are effectively instantaneous nothing changes except as a result of planned actions now actions are not represented explicitly as part of the world model and we do not reason about them directly in strips actions are thought of as operators that syntactically transform the world models now the main advantage of this way of representation is that it avoids the frame problem changes what needed and leave the rest unaffected so all states are represented as set of facts we will also refer to facts as propositions here so on your screen on your left is a particular state I call it state one and it is represented by the following facts that C is on the table B is on C there is nothing on top of B so I say it clear B and the robot is holding a so these four propositions of holding a clear B B on C and C on the table is what describes state 1 state 2 on the other hand if you see is about hand being empty nothing on top of a so clear a a on B B on C and C on the table we have in strips what is called a closed world assumption that is the facts that are not listed in a state are assumed to be false so under closed world assumption we are assuming that the agent has full observability goals in Strip are represented as set of facts again for example if I say on a B is a goal in the blocks wall that I am describing then here on a B is not there whereas we can see on a B in state 2 so state 1 is not a goal State for the goal on a B whereas state 2 is a goal State for the goal on a comma B goals are represented as set of facts for example a on B is a goal in the blocks world and we could see a 1 B as part of the description for state 2 and not in the description in state 1 so state 1 is not a goal State for the gold a on B whereas state 2 is a goal State for the goal a on B actions on the other hand are defined in terms of a set of preconditions a set of a deaf X and a set of delete effects like to continue a discussion from state 1 to state 2 I could come by performing an action of stacking a on B now the action of state a on B is defined in terms of three sets the precondition set is a set of precondition facts that is conditions that must hold for the action to be possible so if I am talking of stacking a on B I must be holding a and there must not be anything on B so this is my precondition facts once the action is done what is the new scenario that has emerged is shown by the add effects facts the set add here lists what are the new propositions that will become true so once I stick a on B a on B would become true and the robot will no longer be holding a so I will have hand empty and of course I will generate a new proposition being nothing in top of a which is clear a now if I was maintaining a database of facts then I could clearly see that on taking this action of stating a on B I should no longer have holding a and b-being true so that must become false and one way of doing this is by saying that these facts need to be deleted so they are the delete effect facts in terms of semantics of the strip's action I have state 1 which is s here holding a clear be on BC and on table C and I have the action stack a be giving rise to state 2 which is about hand empty clear a on a be on BC and on table C so in terms of the preconditions the preconditions are to be checked here and final state description is about taking the union of the add and removing the del of the action so I would add add to this set of propositions describing the state and I will subtract the delete effects from the description of that particular state so a strips action is applicable in a state when its preconditions are contained in that state and taking an action in state s results in a new state which is I add the add effects and remove the delete effects effects so a strips planning problem specifies an initial state a goal state a set of strips actions and the objective is to find a short X in sequence reaching a goal state or report that the goal is unachievable so here is an example I have the initial state where the robot is holding a and B is on the table so I have holding it clear be on table B and the goal is when a is on B and the hand is empty and B is on the table so here the plan is just stacked a B because that's the short X in sequence that will take me from the initial state to the goal State for convenience we typically specify problems via X and schemas rather than writing out individual strip actions what it means is like instead of saying stack a comma B any action would be written in terms of an action schema I would say stack X comma Y and then given a set of schemas an initial state and a goal propositional planners with then compile the schemas into ground actions like I could then say stake a comma B which is about holding a and clear B and adding that after stake a B is done I would have on a B and hand empty and clear a and I would be doing deleting the holding a and clear B or I could have another action from that schema schema which is about stacking be on a so each way of replacing the variables with objects from the initial state and the goal ilds a ground strips action the original strip system use a goal state to control its search now the system is a data base and a goal stack it focuses attention on solving the top goal this may involve solving sub goals which are then pushed onto the stack like I have the goal one in the goal stack and if I have goal 1 and suppose goal 1 has sub goals 1 & 2 then I would place onto the set the sub goals first and tries to solve the sub goals and continue now there are a couple of stack manipulation rules that need to be quickly looked at before I look at the strip's problem to be solved so the first rule says that if I have a compound or single goal matching the current state description then I would remove it from the stack if I have a compound goal not matching the current state description then the idea is to keep the original compound goal on the stack and list the unsatisfied component goals on the stack in some new order if there is a single literal goal not matching the current state description then you got to find a new rule whose instantiated at list includes the goal and you replace the goal with the instantiated rule place the rules instantiated precondition formula on top of the stack and if the top of the stack is a rule you remove the rule from the stack update the database using the rule because you know once you have a rule it will have some add effects effects and delete effect FAQs which you need to look at the database and update and then you need to keep track of the rule to remember that it's part of the solution and if your state has nothing on it this is where you stop and you have a plan so let's look at a simple strips planning example as an illustration here so I have the initial state here which is C is on a and B is on the table and finally I want to arrive at B on the table C one B and a on C so I first place the original goal on the set which is a on C and C on B now that's the original goal under stack this goal is unsatisfied compound goal so I have to list its unsatisfied sub goals and put it on top of each other and I need to remember that to start with my database is about the initial state which is I have a clear B I have C on a I have C being clear is on the table B is on the table and the hands of the robot are empty now since the top goal here is an unsatisfied single literal goal I need to find a rule whose instantiated at list includes the goal and replace the goal with the in Senshi ated rule so I place the rules instantiated precondition formula on top of the set so the rule that we are looking for is the rule of stacking C on B and it has the preconditions that you must be holding C and B must be clear so that's what is placed here on top of the stack and now when you look at the top of the stack this is a compound goal so I will list its sub goals one on top of other holding C and clear B now this is interesting because clear B if you see is a single goal on top of the stack which matches the database and so according to the stack manipulation rules that I have described little while ago I will just remove this from the set now I have holding C there so this is an unsatisfied single literal goal so I will find a rule whose instantiated eggless includes the goal and replace this with the instantiated precondition formula so this is about unstacking CNA I have the precondition on see a hands empty and clear so this is what I put it here and next I see that the compound goal on the top of the stack matches the database so I simply remove it I now have unstack CB so I want to get to the top item but the top item is a rule now so if I remove the rule from the stack I need to update the database and I need to keep track of it for the solution so when I am trying to move this rule out I see that it has a list and a delete list so things to be added I add it to my database which is holding C and clear a so I update my database and I have to remember this for my solution before I move it out so I remember it from my solution here and as I remember it from my solution I remove things from the delete list in my database so I update my database once this is done the compound goal and the top of the stack matches the database so I simply remove it and then I now have again a rule on top of the database now in order to bring it and make it part of this solution I follow the steps that I did for unstack that means I add things on the add list into my database so I add clear C I add on CB I add hens empty and I delete holding C and clear B from the database makes taxi be part of the solution here then I have now the top goal which is a single literal goal I find a rule whose instantiated Atlas includes the goal so that rule is about stake so I get that rule written here its preconditions written as top of the stack and now this is an unsatisfied compound goal so I will break it up into two and stack it here on top of one another and I have clear C now now you could see that clear C is a single goal on top top of the stack which messes the database so I remove clear C from the top of the stack and then I have holding it now this is an unsatisfied single literal goal I find the rule which satisfies this this is about pick up a I give its precondition here so this is about on table a clear a and hand empty once I have that I have now a compound goal on top of the stack that matches the database because if you see I have on table a clear a and hmmm T so I have on table a clear a and hen empty so I can remove that once I remove this I have the top element which is a rule I will add the add list of the rule to my database which is holding a I will delete things from the delete list which is on table a clear a and hands empty I will remove this rule from here and make it part of the solution so I have the solution there the compound golden top of the stack matches database so I remove it and then I have holding a clear C being removed now I have the top item which is a rule I follow the four previous steps that is I update the database I make it part of the solution and then remove it from the sack I have on AC and on CB there which if you see is part of the database here so I am in a position to remove this but before that let me clean it up first and show you that what I have here is a compound goal that matches with the database and therefore I am in a position to move it out and I have an empty stack so once I have an empty stack I have the solution so the solution to the problem is about unstacking CA and then stacking see on be picking up a and then stacking a on top of C so that's the final solution that we get so the strips planning example in this example while we were solving this problem we branched in the right direction in practice searching can be guided by heuristic information so you could try holding X last or you could detect unprofitable paths when new as goal set has become a superset of the original goal set or you could consider useful operator side effects by scanning the stack now let's slightly change our goal state if you remember we had stacked BC na instead of that if we think of stacking ABC on top of one another then what happens is that non interleaf planners would separate this into two sub goals of a and B and B and C now this is called a Sussman anomaly because if the planner starts to look at goal 1 the basic step is to move C out of the way and move a atop B but while this sequence accomplishes gold one the agent will be left with no option but to undo goal 1 in order to pursue goal 2 now if instead the planner starts with goal to the most efficient solution is to move B but again the planner in that case cannot pursue goal 1 without undoing gold - so even if I have separated it out into two goals satisfying one goal and then looking for the other goal would force me to undo the first goal and this anomaly illustrates a weakness of non interleaf planning algorithms so undo on a b2 clear B when solving on BC so let's look at that so here is our start state we pick up C and put it on the table and then we pick up a and put it on B but now when we have to do the other goal then I would have to put C back on the table this is one way of looking at goal 1 and goal 2 and then if you look at the other way doing BC first so you would love to do BC so you'll state B on top of C but then if you want to reach the other goal of a on B you have to again unstick CA to clear a that means you have to take B down again and undo that goal so you begin work on on a B by clearing it that is putting C on table achieve on BC by stacking B on C achieve on a B by stacking a on B we could not do this using a stack with in strips and this requires interleaving interleaving planners is what we will look at in our next lecture thank you [Music] you 