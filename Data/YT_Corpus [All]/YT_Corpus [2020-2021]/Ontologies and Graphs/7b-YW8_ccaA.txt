 so today I'm going to talk a little bit about a use case that we have at Thompson Reuters and so I work for Thomson Reuters special services which is a group that works with state federal and local governments and we have we've been using a graph neo4j is one of them but we've been using graphs of self problems for a number of years and what I want to talk to today about is a project that I've been on for a while where we index all the information that we have is a giant data company in multiple different places so that our analysts and our subject matter experts can search and get the insights that they need and so today we're going to focus on how we do that with neo4j and solar and we'll talk about some of the lessons that we've learned and what I'm hoping is that if you are in the stage if you're exploring what a graph can do for you if you are in a space where know your customer is important where understanding the flow of money is a big deal or building a knowledge graph is something that's in your your strategic goals that hopefully something I say helps either spark spark a conversation with your colleagues or people in your organization and please please please feel read feel free to reach out I am a huge graph advocate and I love talking about this stuff so you can grab me during one of the breaks introduce yourself I'm more than happy to talk about these things and I have found that coming to the the graph connect and graph tour has enabled me to make relationships that that have helped our organization and other organizations because we've come across the same problems so quick overview I'm gonna talk today about our environment how we have everything set up I'll talk a little bit about it the use case that we have in the goals we had in doing all of this because a lot of work went into organizing the information here setting it up and then serving it to different customers I'm also going to talk about the outcomes right not all of them were completely positive and hopefully you can learn from some of the experiences that we went through so that you don't make the same mistakes and you can get from zero to done a lot faster so like I said my name is Nathan Mane's and I work for Thomson Reuters special services I've been a user of neo4j since 2015 I've been coming to Graf Connect for the past few years and I work on a project where we look at a knowledge graph that describes corporate supply chains in corporate hierarchies it serves as the backbone for a number of different applications that have very different views into that data so over the next 40 minutes we're going to go over that and I'm going to hopefully talk about this problem that I think is nearly universal which is how do you search effectively relationships in the real world and we're going to talk about what we learned as we work towards solving it so in 2017 Eric Pugh gave this talk about the hierarchy of search needs right to supply on Maslow's hierarchy of needs and I found this to be an extremely helpful info graph because whenever I talk with customers or stakeholders they always say and whatever they have they want it to work like Google and for us you know we are taking and parsing dozens of different data sets some of them are ours and so we have a lot of control over them some of them are you know commercial fee-for-service so that's another professional data provider so they may or may not be structured and then others are these are the ones I like to call the fun data sets others are custom in-house ones so we have everything you know these can be really nice these could be one individual who's been keeping notes on maybe a text you know a notepad there's been keeping for 20 years and we need to actually do something with it they want to be able to search at all maybe they want images and one of the problems is getting all that data into the hands of subject matter experts who are gonna do something with it and so they always ask hey we've got all these you know data silos this big data like we just want it to work like Google can you do that and I usually say you know I would love to work on a search team that had the resources that Google search has but it looks like that's not happening today so we're gonna have to read we're gonna have to reframe the question that you've got and what we end up doing is figuring out how searching works today and so I've seen you know that could be somebody searching a file system they're using Windows Explorer on you know windows 95 and they're going through and looking at directories of files that doesn't work really well when you're looking at images it doesn't work really well when you're looking at locked PDFs but it's something that they're trying to do then I say well what is it what's it going to take us to move to the next level right if we're down here at that search box level because they're just doing a directory what do we need to do in order to get boolean and fuzzing search peg nation what do we need to do to get there sometimes we've got customers who are pretty sophisticated and so they may be looking at more contextual or predictive search needs and setting up our information in a graph helps us get there it helps us enrich the kinds of search results that our subject matter experts want to see it helps us get that into their hands so you know to try and wake everybody up get everybody involved I just want to ask what is your least favorite data format I'm a data engineer I work with a lot of really cool formats I look I also work with a lot of really terrible ones so this is you know your chance to shout your frustrations out what's the format that you deal with that's your least favorite PDF okay that's a good one I figured we'd get some love for PDF any other ones XML okay oh latex source code great yeah that's a fun that's fun so there everybody kind of has to deal with stuff that's not always clean I like this is my this is my example like when I'm having a nightmare working with somebody's information I always go back to this back in what is this like a year or two ago yeah yeah 2016 the city of Detroit produced a lookup table for its absentee precinct but the problem was it was an Excel but even worse all the values were clipart and so this was loads of fun right this this is this is my nightmare and perhaps you share something like this or you've worked with data that makes about as much sense as this one does so a lot of work goes in the reason I talk about this there's a lot of work goes into getting this information into a knowledge graph and so let me talk a little bit about the scale of information that we're dealing with so our knowledge graph currently we're processing this is a little old but we're processing of roughly 75 data sources we've got a 1.7 billion triples in there and a triple if you're not familiar with the way that RDF serializes data is a statement so it's a subject a predicate and an object it's basically a thing its relationship to another thing we have over 18 million unique entities and we're leveraging seven different open-source projects a lot of what makes the backbone of our information kind of like puts that together is we have eight million officers and directors their positions and the companies that they're related to we have over 10 million public and private companies and those are all sitting on top of multi node cluster we recommend five so that that'll make it fairly snappy and it's scales so you can keep dumping information in there so if you work for a company that say has access to all of Reuters news content you can continue to dump that into your into your data Lake and not worry about running out of space the really awesome news about this is that that data set with the officers and directors and companies is open so there's no reason that you guys couldn't go out to permeate org download it and it's in RDF format so it's in a graph and process that right so if you need a really interesting POC and you were sitting there going ah I need some data / - org you can go ahead and write that down you can go and download it it's a giant dataset that is real world it has a bunch of information about people and companies and it contains information that you know buy and sell side traders are using every day so our knowledge graph is a little bit smaller scope it's narrower and scope than say a knowledge graph like Google's Microsoft's Facebook's IBM's we focus on business dealings we focus on officers and directors and corporations I always like when people give certain statistics because you know people will throw around the word big data I like real numbers so our current implementation and our current knowledge graph when you run it in neo that index is about 60 gigabytes in size and I will say it's fairly snappy so cipher queries come back pretty quickly even for complex you know when you're doing matches in complex queries that will come back and you'll get your results pretty quick so let's talk about the process and what we do to get all of that really difficult to deal with data into a nice clean graph so that we can do interesting graph things with it we go through these steps and we break it down into a mapping process a stitching process a tagging process and finally our indexing phase the indexing phase is when neo4j comes in and our other graph databases but before we can get there we have to clean and prepare and then model the information so what we start with is we start with our mapping stage and this is what we unified data attributes into a common vocabulary across data sources this can be a really difficult and time-consuming task and personally this is where I like what certain things that RDF gives me right it allows me to place various mappings across my information with context-aware domain-specific or customer centric modeling without messing with the underlying entities sometimes I bring this up and people are struggling to figure out why this is difficult so I'm going to use an example if I asked you how many countries there are in the world what answer would you give me maybe you're an iPhone user so you whip out your iPhone and you ask Siri well I'll tell you what Siri will tell you it'll say 206 maybe you're an Android user you ask Google assistant it's going to tell you 195 this was yesterday so maybe they've updated it but this should be an easy question right now this is where I get to the most controversial part of my talk and perhaps the whole day this is not an easy question there happen to be political and other kinds of things going on in the world that make answering this kind of question really tricky and it makes it specific to the domain that you're answering it in so if I'm working with the United States government I'm gonna go to they're officially defined list and that's 195 now what do I do with countries like Taiwan that's not on that list but that's a country that you know if I asked you if that's a country you'd probably say yes well I need to put a different domain model specific layer on there to help manage that this ends up being really tricky and you might be sitting there saying cool Nathan enough with the semantics right a country's a country like I'm okay with some fuzzy details I wish that you could be that okay with fuzzy details when we're talking about projects like this you'll have customers that have a totally different definition of something than you do for example you may be working with companies I promise you the banks in this room people who work at banks you all think about companies slightly differently they could be a legal entity depends on what country they're registered in they could be maybe an individual that has a trust set up and it could just be maybe you call them a customer everybody thinks about these things a little bit differently sometimes we turn to outside organizations to find our definitions right so for our country example perhaps we're looking at the state must have this is the Monty viedo convention of 1933 so the state has to have permanent population defined territory a government and a capacity to enter into relations with other states that definition still doesn't help me what do we do when we have a you know a not a nation state that's big and powerful but doesn't have a geographical border but we want to model relationships with them we've got to be domain aware and so this ends up being tricky and this is where mapping comes into play this is important for us to get it right but be flexible enough to handle some of the ambiguities in the real world but good news is once you get all that done now you can move on to the fun stuff you can start to stitch things together so we can take the entry from all of our countries in different data sources and start representing them as a single entity with different pointers this if any of you are used to traditional data warehousing and maybe you've been working with I don't know I won't say any names with certain companies that do like big data warehouses and you're doing complex joins and they go on for days right this is where that starts to be really useful because you'd have to create another table with another ID that points to all the other IDs you care about but in our graph we just have our single entity that provides that view and gives us adjacency lookups so that we can go and look at any of those connected nodes and the nice thing is that that connection has a relationship so we also know what kind of connection it is but spoiler alert these definitions once you get them all ironed out they're going to change they're going to keep changing as the customers the stakeholders come back and they talk to you about their needs so be aware for that and and include that in your process in our country example less than 1% of our entities have a status called the official observer these are countries that the UN recognizes as sovereign states but they are not allowed to vote in the UN General Assembly but they are allowed to participate and to observe and be there pretty important flag that we need to track but it's on to nation-states so in our small trivial example right we're talking about less than 1% of all of our data we need to track that that's a pretty sparsely pop related column or an additional relational table but in the graph guess what you just have two relationships and that's all the space it takes you don't have to worry about it if that changes you just add new ones and that's fine so these models allow us to represent relationships in the real world that are much more ambiguous than columns and rows and important you don't want to be the person who makes a mistake by calling somebody a representative a country say wait a second you're not in my database you're not a country that's a big mistake just I'm giving that tip out for free don't do it so next step we go into tagging right and this is something that we've been doing for a long time as we process a lot of unstructured text right Reuters publishes thousands of documents every day thousands of stories and some of it and they do add some structure to that but not the structure that necessarily I want or my customers want so this is where we we bring in the capability to tag and extract relationships and entities the key piece here is being able to resolve those entities as you extract them to something other than just a document so you want to have your graph that stores these stitched views of entities and you want to have that so that when you're tagging in an ideal world you're bringing it back to your model so you know that the bowing that shows up in the document is the bowing related to ID number one two three in your graph you want to know that the relationship that those two companies have is the same relationship that you've seen before so that you can manage and maintain that now this is a difficult problem and I think is one of those areas that there's still quite a bit of growth but this is something that we do it's a will process not just Reuters content but other unstructured content well tag will extract entities resolve those and then we create kind of a relationship validation if you will by inserting a relationship and a document to back that relationship up this is a process that we have that's semi-supervised we have machine learning models that run and extract information but we also have humans and analysts in the loop that will go back in and validate those and make sure that you know they they spot-check they do some QA work for us and so this part even when you're processing loads and loads of unstructured content you also need to do stuff that's not as fancy you just need to do some set up some simple filters maybe I don't need to know about the latest tennis the ATP events that are coming up for tennis right I don't need to store all those documents in my graph because my graph is watching say mergers and acquisitions between companies so I don't necessarily care about tennis and who's winning or even soccer now that gets tricky because I may care about who's buying or selling a soccer team or even who's sponsoring the ATP but that's where your filters come in right that's where you get to use your brain and think about how you're going to split up some of that information so you put it in the right spot you validate the right kinds of relationships the other ones you store but you don't want to necessarily bring those into your graph because what you don't want to do is make your pristine graph with all of its nice traversals just a big muddy mess where your graph traversals are bringing back hundreds of thousands of documents about Serena Williams when what you're trying to find are mergers and acquisitions between a targeted set of companies finally what we end up doing right is we index us all so indexing allows us to search all of this information and so you may be used to using relational databases to do this we're having an application that sits on top of relational databases to bring back information but we all have been frustrated by search results that don't read our minds right maybe we're using fuzzy matching maybe we're using some boolean we're getting fancy and our query is you know 200 300 characters long we've got a lot of X or symbols parentheses and but we're still missing stuff that's where our index comes in we want to make this searchable for any kind of Hana list be it somebody who's skilled in cipher we want to give it to him so they can run their cipher queries and find the kinds of relationships they need to do maybe they need to do community detection centrality measurements great cipher lets them do that we also want to support maybe somebody who's new and they just want to type in things right they just want the Google experience they want to type in some words and hope that relevant stuff comes back that's where our index comes in and the choices that we make about where that information lives starts to matter and in our case we put we have solar for some of the free text lieu scenes searching that lets us just cruise through free text documents we also have neo which we use to do community detection Network centrality and use some other fancy graph algorithms that are actually written about in that book that you can pick up at the registration decks and they're really nice right I'm sure there are a lot of smart people in this room it's really nice even if you are that smart to not have to write all the graph algorithms they exist in the neo library and so you can start using them in your project almost immediately which is awesome and so once we do all this right now we have a searchable index that our subject matter experts can begin to gain insights from they can begin to find the things that they're looking for and the things that those entities are connected to so that's where this starts to change so let me show you a little bit about how our architecture is set up this is just this isn't the right answer it happens to be a right answer it works for us and so what we've got is this whole stack that helps manage the resources of our computers in our servers and then serve those up to a user and a customer over here on the side in our gray box that's where we put the different kinds of indexes that we may want to use so in this example right we have neo4j over there which a user could access either directly or through an end web application an end user web application we also provide an API that allows them to come in and call specific functions so that API users or developers on our team have access to the network's information and other kinds of analysis tools that they can build in and baked into their applications the nice thing about breaking things down this way is we allow data to come in in basically any format that we can parse so we take CSV we take RDF relational databases as long as they have a driver web service responses so give me JSON give me soap give me whatever goofy thing you can think of as long as we can as long as it's something that we can parse we can build a map for it and then X amount right we can take that in and parse those relationships to all of this ends up all of this ends up serving the end user so that the users can go and find what they need to find so one of the questions that I end up getting is why do we use both and like I've been hinting at we like to use things that are good at certain tasks for the tasks that they're good at we happen to have the luxury to split that apart and we have a number of experts in-house who can do different things with say RDF or we have experts who are really good at writing cipher queries so we just want to be able to show them the information in a format that they're comfortable with because ultimately we're solving a search problem we're helping them go across all the information we have in our data Lake another major advantage that we have is we decouple that searching layer from the storage layer so that our storage can grow and do whatever it needs to do we can make tweaks to the search without having to worry about what's stored underneath so that just keeps scaling just keeps getting bigger we have an archive schedule if we need it and that just it doesn't affect or impact our end users we also you know we want to be able to leverage the kinds of query languages that people are familiar with so ciphers great sparkles great graph QL will support as many of those as we can we want to leverage algorithms written by written by and reviewed by multiple people so the neo4j graph algorithm library lets us do that and we also want to perform domain-specific modeling again when we build those indexes what we want to do is give an index to a customer in the way that they need it so if a if I call something a company and another customer calls them a customer we want to be able to provide them that context and that domain-specific modeling so that they can go in and feel comfortable in ultimately the same data model that sits underneath so let me talk a little bit about the rdf to neo mapping there i know that we have a talk later today where if this is something that's interesting to you they'll go into a little bit more detail but here's some this is the basic stuff and the only reason I'm showing you this is I want you to understand how easy it is right there are ways you can optimize this and get better but the basic steps are pretty straightforward we iterate over all of our relationships that exist in rdf then we just go and look at each node and we match it to all of its nodes that are that it's connected to and then finally we do some merging right we merge all those paths with to the relationships that matter now this is the tricky part this is where you create a map so that you can collapse relationships on top of each other if you need to or leave them as verbose as you want and one of the things that you've got to deal with when you're dealing across datasets especially in RDF is you're going to have different oncology's that are exist inside you're inside your data and so you may need to make choices about how you're going to map those and manage those but that's up to you and by doing this process and kind of separating in and out it allows you to play with it where you're not blowing away your entire data store over and over and over again you're just dealing with the index so some things that you know are worth shouting out and mentioning this procedure that we have roughly 500 lines of Java code and we're able to do that straight into neo and even here a graph tour I found out that I can get that even shorter and we can make that even more compact by using stored procedures that sit on the server and compiled us we don't have to write or generate cipher queries to inserts this the process runs fairly quickly and it's pretty straightforward to troubleshoot so you're not talking about having ton of domain knowledge about say the neo driver to get up and running this is something that you know your your developers would be able to look at and and start making an impact right away start squashing bugs or doing anything like that shout out to the unwind function and cipher that's a lifesaver we use a lot of you know match statements and then the merge paths again that's a your opportunity to build a map and merge those relationships in a way that makes sense for you so let's get to something a little bit more interesting not that that wasn't just riveting to all of you but let's talk about use cases right when I come to these and to these kinds of events I want to see how people are using the technology or the techniques that everybody's talking about in the wild so I'm going to show you three I think three that we've got that I think are pretty cool and like I said we'll have a question for Q we'll have some Q&A time here at the end and I'm happy to field some questions about it and if you have more specific ones please find me and we can talk about it so one of the things that we do is we've got to support different kinds of use cases we've got you know think about it right we may have some know your customer style use cases we may have some supply chain risk use cases and those the way that we present that information is going to be a little bit different for everybody especially when we put in the domain-specific language that different customers are going to need and so the first one that I'm going to talk about is one that I'm really that I really like and one of the inspirations for this was if you've ever been on IMDB and if you like movies or you like websites and you go and check out IMDB they have a section called the star meter are any of you familiar with that the star meter lets you know who is popular that week in the realm of movies and it shows you a ranking so you may have a big movie star that just came out with a new movie and they will move up and you'll be able to look at their star meter ranking perhaps you've noticed it on their page and it'll show you not just their ranking say it shows you their ranking relative to all the other people in the database and it changes fairly regularly so one of the things that I wanted to do was to take that much further and be able to target things that I actually need to care about instead of just movie stars and how popular they are and so what we did is we used graph centrality algorithms to help us compute you know essentially page rank or some small variant of that on targeted populations so think of this as your customer portfolio think of this as you could do this with anything right you could do this with the network of people that play in the Premier League and you could see who the most influential players were or who the most influential companies were but you would be able to facet that down from a single search display without recomputing everything and so what we end up doing here is you know on the the top left with our most influential box we keep just the network centrality right you can think of this this one's pretty close to Google Pagerank so you're looking at who the major players and in this case we're looking at industries who the major players are and then we can filter that down further by geography or a handful of other facets that one's interesting but when you're working with subject matter experts who are in the space that you're talking about right we're working with somebody who is all about the oil industry in Egypt they know who all the major players are they don't need that panel what they need is what we've got over here and the it's kind of in the center but our biggest movers and this is computed centrality with a timestamp right this is something where you can see who has shifted the most and they can then drill down on the events that have helped that particular entity become more or less we have the inverse less influential in the given time span that ends up being really really good for any kind of targeting exercise you're going to do if you need to learn about your customer supply chain if you need to learn about say an industry that you're a little unfamiliar with you can go in and drill into the big movers and shakers you can also look at people that have been added or dropped from your networks so if you have a network that you know this is something that you might be thinking well I'm watching a hundred people that's not too hard to keep track of in this particular example right we're watching close to 20,000 entities and we want one or two analysts to be able to monitor that so that they can help notify customers who are interested in the movement within those spaces this helps them find the things that they need to look into or learn a little bit more about in order to help the customer stay informed of happenings in an industry that they're particularly interested in so this is and then of course we provide the graph view so that they can click and look at the relationships and there's a visual that they can generate PowerPoint slides with right so this is really cool I like this like I said I'd like to remake this for IMDB so that they have something a little bit fancier than just like page views but that's another that's another conference talk the other use case that we have is we do this relationship validation between via the automated document processing so we go through and we read a ton of content right and Reuters and other news providers that we partner with we'll go through and read those those documents and extract relationships and entities out of those documents that allows us to watch relationships in near-real-time develop so they can wane they can ebb and flow you can watch you can move your time series to look at say three months in the past and I want to look at how certain relationships changed for the six months prior to that and then you want to move that window and just keep chunking by week into the future that's something that you can do by looking at these relationship validations and this automated document tagging and I've saved of course the best for last and this is one where we take all the investment data that we have and we model it in our graph and then we figure out cool things that we can do with that and so in this particular use case you know I haven't I have yet to be in a demo or a sales meeting where somebody doesn't say you know it'd be cool put it on a map and so to preempt that you know would be cool we put it on a map and something interesting happened we were cruising through and looking at you know some of my hobbies like Russian mining just looking the activity in that industry and what we ended up seeing was what I first thought was a mistake we ended up seeing that a lot of money from Florida was flowing into a particular Russian mining company now this was something that you know as a as a developer not uncommon where I went whoo man we missed the decimal spot or oh ye that's not the right entity but digging into this a little bit more I wasn't the only person that noticed this right around the same time the Rolling Stone published this really interesting article about a certain teacher firefighter police other retirement funds going into sanctioned Russian companies which raised a number of questions and then was quickly forgotten because our president tweeted something that captivated the news cycle but anyway this is this is the kind of insight that we can get when we structure our data in a graph and we do it in a way that supports these use cases and for the current environment if if you're following right there is a new wave of sanctions for certain Turkish companies and that's this week I would have gone in and made an updated slide which would not have been too hard it's just I ran out of time and I'm sure you'd find interesting things about other pension funds going to places that are newly sanctioned because overnight it became not okay to give them money so to wrap up next steps right this is where I invite you as somebody who's interested in the graph community to do something we've got entity resolution is still a big problem if you know anything about it you have any good ideas jump on board there's a lot of work to be done and last year the big tech companies identified this as an area where we have room to improve to move towards supervised or unsupervised learning method for tagging and resolving entities open identifiers using them in the in your own data sets will help other people use them so just a handful to mention perm ID or grid AC wiki data freebase and JSTOR topic codes those are a handful of open IDs that I've use and I find very helpful and then promoting graph literacy so here's something I'd like to invite everybody to do you're here a graph tour and you're going to receive a ton of information no matter what stage you're in I'd invite you to become a graph advocate and you can do this by either writing a blog post about something that you've done and graph with using graphs you can write a blog post about cool things you've learned that graphs can do or you can become somebody at your organization that champions graph classes and I think that's something that everybody in here can do and will help us get to a better stage with our ecosystem I just like to thank the open source projects open I like to be an open source advocate these are open source projects have been invaluable to our process and the things that we are doing and the problems were solving and so if you don't use any of these or you're unfamiliar please check them out all right we have zookeeper Tomcat Postgres accumulo solar Redis neo4j and Hadoop all excellent projects and I just invite you right with you're becoming a graph advocate feel free talk to your colleagues if you're here by yourself or you're the only person at your organization who is into this please feel free to reach out to me you can find me on Twitter I'm at Nathan Mane's and I hope to hear about your Europe adventures and graphs thank you [Applause] 