 our next speaker is Mark musin from Stanford University mark is going to speak about knowledge technology to accelerate open science in addressing the covert 19 pandemic thank you all again thanks for the opportunity to be here there's been a lot of discussion in the lay press about how the co mid-nineteen pandemic is going to change a lot of features of society one element of society that actually hasn't been discussed a lot is that Koch the 19 is going to change science and the way we do science in some profound ways and what I want to talk about today is how some of the work we're doing at Stanford may be helping to push that change forward particularly in the context of the current epidemic and now I can have asked my slides there we go and the I'm sorry the the main thing I want to take heavy takeaway is that science in the past 10 20 years has changed radically as people are recognizing the importance of making available online the very data that scientists are using to form their hypotheses and to publish their their papers that there's been a shift as we recognize that the output of science is important not just in terms of publications but in terms of basic data so that other scientists can go and look at those data can verify that the results of the experiments are correct and also can take those data and reuse them and potentially make new discoveries and nowhere has this been more important in the case of the Kobuk 19 epidemic where suddenly all these data that are filling up resources all over the world with information about koba 19 suddenly are available and people want to have access to them quickly want to be able to use other people's data to make new observations and there's just enormous excitement about the whole idea of open science and the opportunity to take advantage of data that already exists to be able to make new observations and hopefully to address the epidemic that's all the good news the bad news is that although we have lots of data out there it's kind of like having a library where you don't have a good catalog we don't know what all the resources are when you can't actually easily find what you need to find and so the scientists who are most interested in being able to find other investigators data and learn from them are kind of stymied and there's timing for reasons that's gonna sound rather arcane they're starving because they don't have good metadata the data that described what the datasets were all about let me just show you why I say that in this little first let me just emphasize that the buzzword that has become so frequently used now to describe the problem is the idea of trying to make data that are fair that are findable so you can actually search for them that they're accessible that even once you find the data you can actually download them and look at them that they're interoperable that you can take your data and mix them with my data and we can actually get something better than the sum of the parts and then the data are reusable so there explorable by others so this buzzword of having data that are fair pervades biology right now and the challenge as I said is that most data are not fair so here the metadata or a tiny piece of the metadata that describes samples that are in a repository at the NIH called geo and these shows you these these results show you in several records how scientists have described the age of the patient from age to age to age the pop age to age after birth to 18 years - god knows what if you're a scientist and your goal is to find a specimen that's described in a repository we want to look at the data that we're accrued from some experiment you have to know what to search for and if you have to know and if you're interested in patients of a certain age you have to know how the investigator might have chosen to represent age and one of a million different ways including a million different typos we looked at a repository called bio sample another NCI repository and wanted to really quantify how bad are the metadata which means how bad and how difficult is it to search for someone else's results well 73 percent of the boolean metadata values are not true or false their values like nonsmoker or former smoker 20 6% of the integers don't know parses numbers and 68% of the metadata entries that are supposed to represent terms from standard vocabularies well are not terms from standard vocabularies and what that means is is if you're an investigator you're trying to find a particular set of data you're often really stuck because the metadata are terrible and why is that important for code 19 well what if I relevant studies you wanna be able to integrate new results for those that are already available if they want to re-explore existing datasets want to verify published claims we may have a lot of difficulty finding the right answers and one of the things I find remarkable is that just in the past couple of weeks there's been this absolute flurry of activity in the in the Kobe 19 community demanding that we get data that are available in it that are more fair data that are more accessible data that are more reusable and the question becomes how can we actually come up with better data like that when frankly the data that exists online are very difficult to search and very difficult to use well like many other people's in this session we have technology that we're trying to be purpose specifically for koban 19 we have technology we've created at Stanford called cedar where cedar is the Center for expanded data annotation and retrieval and cedar basically offers a three-step process where initially we author metadata templates we decide for different classes of experiments for different kinds of experiments and for a lot neurology in chemistry and whatever what are the kinds of experiments that people do and can we come up with a way of standardizing what the metadata for such an experiment should look like we then have a mechanism within cedar that allows us to annotate those templates we basically fill in those templates with terms from controlled terminologies that are consistent with well-defined data types and ultimately that gives us the ability to take the metadata that we enter into cedar and use those metadata to annotate the data sets that are stored in the repositories that investigators don't want to explore one minute one of the things we also do is to look at those data so that we can easily use those data to make it easier for people to fill in the blank the form so for example here's a form for filling an information about a specimen for a repository called bio sample and the drop down menu gives you all the control terms that might be appropriate for the tissue however if we want to look at what the disease might be if you already said the tissue is long then because we know a lot we can use AI and say but look they don't get provide all the possible values we just look at lung cancer or chronic obstructive pulmonary disease or other kinds of conditions that might be associated with lung tissue we say the tissue is brain tissue then our menus can be much more simple and we can specify for example what are the kinds of diseases that might be associated with a tissue coming from brain what that means is when we use create metadata we don't deal with a mess that we currently have but rather we have metadata that are really tailored for the situation and that use the kinds of terms that people want to search with for the past couple weeks the Gopher organization the people in Europe were promoting the fair principles in the strongest way have created something called the virus outbreak data network or Vodun and one of the things that bowdan is doing is using technologies such as cedar in order to be able to make it easier for investigators to create data related to the epidemic for data related to virology data related to all the kinds of experiments that people need to do in this area and make this data more readily available we know that data are never gonna be fair unless we have common templates by the way when we have controlled terms and we have technology that makes this a little easier and so it gets is very excited here at Stanford is the ability to take our existing technology known cedar and to repurpose it for the purpose of making it easier and faster and more reliable for workers in the kovin area to be able to get the kinds of datasets they need in order to do the kinds of analyses or they view a tree most important thank you very much mark and I'm just struck in this session by how many people have pivoted their organization in their efforts to be relevant and useful for kovat it's quite inspiring 