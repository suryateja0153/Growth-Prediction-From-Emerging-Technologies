 well good morning everybody as you said my name is David Meza I'm the chief knowledge architect at Johnson Space Center in Houston I kind of rotate back and forth between here Johnson and Johnson Space Center Houston here in DC headquarters acid they mentioned earlier I got an email friendly email late Sunday night saying one of our guys dropped off can you please you know I know you're gonna be there can you can you decide to give a talk so fortunately I had this project I've been working on the last couple of months I started it I'm gonna show it to you guys it's still a work in progress so bear with me but it's something we've been working on for a couple of years as far as the research behind it and hopefully it'll give you an idea what we can do with knowledge graphs within your organization as they mentioned before I've been working with neo4j product since it was back in command line interface type so neil 1.0 or something like that many many years ago and i'm excited to see some of the new things that they're bringing up especially the most multi instance databases within and in 4.0 i think that's going to be an exciting time for being able to use craft databases within your organization so really quick when somebody asked me okay what's the knowledge architecture what do you do with the chief knowledge architects the first question I usually get in camera man I walk so you're gonna have to follow me as the chief knowledge architect my main priority is to develop and implement the technological roadmap that allows us to turn our data into what I call actionable knowledge something that we can utilize so knowledge graphs are a basic concept that I want to try to introduce if you guys probably heard about it it's been kind of a buzzword over the last year year and a half but I want to break down one specific project the one specific set of information that we deal with on the international space station but first off I want to start off with this code I usually deal with Peter Drucker the most important contribution management needs to make in the 21st century is to increase the productivity of knowledge work and of the knowledge worker he said that back in 1999 I think it's even more important today especially with the amount of data that we're seeing in our organizations the the growth of data that's coming out there the terabytes and terabytes and petabytes and zettabytes of information that we're starting to see we need to be able to actually utilize that information why is that because we face an enormous amount of challenges 46% of our workers can't find the information that are looking for about half the time we're constantly trying to develop ways of searching and finding information if I had a nickel for every time somebody's asked me why can't we just do in our organization what Google does I'd be a very rich man unfortunately that type of solution does not work in the enterprise I said this meant over and over again I've said it in front of a room with Google people into it and they kind of shook their heads yeah we know it's hard to work it really quickly I'll tell you my opinion as to why those type of algorithms require you to be able to index everything we don't index everything in our organizations I know at NASA we probably index 1/10 of our known data that's our known data and with that we don't have as many queries as Google has Google has 5 billion queries a day and I think that was back in 2016 it probably had more than that at Johnson Space Center we had a thousand queries today and my data scientists in the room you can tell what the probability of finding the right information with only a subset of a thousand queries the data that compared to 5 billion queries today very very difficult to define information so we got to be more specific in how we search for an information more repository specific and acknowledged grass will help us do some of that also 30 percent of our total R&D is wasted duplicating work we've previously done quick story on that four years ago we were testing the Orion capsule and we were too active while we were testing with the up writing system on the capsule so when the Catholic comes down and falls into the water and did the ocean these big balloons will inflate and help the capsule to upright itself so the astronauts don't drown well a few of those balloon big balloons didn't work so the organization's tried to look for information about the Apollo era because we had to say similar operating system and the Apollo capsules they went looking through our databases couldn't find anything again because that was well over 50 years ago in some cases and the information just wasn't stored correctly we didn't see we don't have it they went to the history office that had by 62 terabytes of data during the Apollo era in a very antiquated sequel system with key word base it took them hours and hours an hour they went probably three or four days looking for information and found three documents they went so far as to go visit retired engineers from that time frame talk to them about what they did those engineers went up and literally went up into their attics brought down boxes of research here you go good luck that's the type of things we're facing because it's amount of data we've had for years and years ago fortunately we were able to do some work with which search algorithm utilizing some things with knowledge graphs we developed a system that allowed them to just look at that historical Apollo data we had in through those algorithms we created they were able to find information fairly quickly within three hours they found 200 relevant documents that's the kind of help you can receive in knowledge graphs but the last thing the one that really gets me is the 54% of our decisions are made with incomplete inconsistent or inadequate information you know if we're making decisions based on half the information that's kind of scary especially the type of things that we do so we got to improve about how we try to do those things and how do I do that several years ago I developed a framework that I call it Nass that I that I call knowledge architecture and by that I look at that as a combination of three different disciplines knowledge management knowledge informatics and data science knowledge management is the strategy for how we identify we collect we create analyze store and percent our data the knowledge informatics is the pipeline those applications and tools and methodologies that allow us to transmit that data to our end users and the data science which has really been become more and more popular over the last several years it's the - it's the methodologies the algorithms the methods we use - in order to transfer that data into some form of actionable knowledge I'm going to talk a little bit about all of that as I go through this scenario and then show you how I've started to put that information into a knowledge graph that's going to allow us down the road to get the information even faster and why is this important of course this is another curve comment that I have from a former CEO Google we have an opportunity for everyone in the world to have access to all the world's information this has never before been possible if your big goodness information so profound it's a tremendous equalizer information is power and here's where I play the semantic word actually knowledge is power in my case having that information that's great but if you can't turn it into some kind of actionable in knowledge if you can't really utilize it you can't find it then it's not really worth it so these type of tools and techniques that I'm going to show you will allow you to actually find that information to make it a lot easier and it can be done from the smallest projects to the largest projects I'm going to show you a small project if you why is that it's because with great power comes great responsibility you guys are responsible for take a looking at your information looking at your data and making sure that your end users can utilize it in a timely fashion not so matter finding that information is finding it at the right time when you need it though and how are we going to do that we're going to turn our data into a graph we're going to take these reams and reams of Na da q Minh type of orientation that I'll go about to talk about a little bit and turn it into a graph that shows us how we can connect the dots a little bit easier so let me start with the little story first so it gave you kind of a background of what we're doing anybody recognize this picture at all ice a few folks back into August of 2017 we had a solar eclipse bar during that solar eclipse this is what I call the greatest photo bomb ever the time-lapse photography of the International Space Station pass it between the Earth and the Sun during that solar eclipse so it's kind of one of the coolest pictures I think I like and I kind of kind of show it off because we're going to talk about the International Space Station here so what we're trying to do with the Internet in the International Space Station is we're going to demonstrate and this is the the data science portion of the of the solution that we're trying to derived here we've got a huge amount of text within comments that have been given to us by the by the astronauts and through that we're going to look at the sediment analysis how we do the calculation and information extraction I'm gonna go through that very quickly I said I put this presentation together really quickly but I just want to show you kind give you a background of all of that before I actually show you lo live demo of the graph that graph or the knowledge graph that I want to show why that a little bit of background every time and a group of astronauts come down from the International Space Station that returned to Earth they get debriefed and over the last 15 years they've you know they've been a lot of DBS going on we're not talking about a 30-minute conversation we're talking 6 10 12 15 hours at a time going over everything on the International Space Station all about law the life weather how was the food how was the exercise equipment what was the environment like the exercises the scientific projects you were working on all that needs to be captured so that we understand what life is like on the International Space Station so we can make it better for them because we just can't go up there and take a look at it and kind of doing it at home inspection you know they're our eyes and ears while they're up there so because of that we've collected well over 80,000 wealth now we're at well over 90,000 documents on that and they get like they get DDT boots on a lot of different things so here's a quite a quick picture of care and I bird doing an experiment I think she'd do with some gene sequencing on the international space issue that you can see the environment is very congested it's got a lot of things going on so we've got to figure out better ways to make it easier for them here's another image of a cosmonaut a Russian cosmonaut who's actually working on this laptop I believe but he's in the galley area now you can see somewhere up at the top there there's a laptop kind of up on the wall there's other equipment it's not very easy for them to get around so all the information we get from them helps us and we have to be able to analyze that information that they give us a lot faster well what's happening with this is that again we've got well over 90,000 comments now I need to update this slide which we equate that to by 90 copies up to kill a mockingbird but we've got to get the astronauts views so what would happen is that once we've collected those they again put it into a sequel database with very limited keyword based search so a question would come from one of the engineers or maybe one of the astronauts what was a particular exercise equipment like well you know maybe they're looking at the exercise equipment in its functionality so they'll have to go in in in a sequel database lookup exercise equipment and try to pull out all these comments and a human factors engineer would read the comments they would code them they would theme them they would write their notes on them they would try to get him into different types of sentiment trying to understand us it would take him anywhere from three to four weeks to do that just to try to get that a little bit of information and pull that put that out there we were trying to help them so they came to us to try to figure out what can we do that we try to start applying a little bit of data science a little bit of analytics to that information so we were going to take a look at sentiment theory on the text itself and I'll go through this again pretty quickly utilizing utilizing our packet called key tap we were able to look at the particular polarized word in the words around it so for a really quick look for example the polarized word here would be love and we could decide based on the we can tweak the algorithm decide how many works around the we want to look at it so in this case I assess the polarized word is love and ISS it's a noun that's applying the two we get a score 0.57 or the reverse of that I hate ISS you get a negative point five seven so you can see how the scoring works you have things such as the amplifiers and amplifiers which raise and lower that so you barely love the ISS that the amplifies love a little bit gives you a little bit of a score you have neutral you have negator so there's a way of looking at the words the sentences and the paragraphs and actually give them a score that tells you how negative or positive from a score of negative one to positive one on that reading that information becomes essential metadata that you can add to your knowledge graph one of the great things that I found about knowledge graphs like this like a neo4j graph is that you have these properties you can assign to your entities those prop 19 new to your entities but your relationships also your edges I know those properties can be utilized for run further analysis and I'm really excited to when annalisha comes up and talks about the there her use of AI in some of these algorithms because I want to see what the next step we can go forward on some of these things so here's the quick implementation of a paragraph they're showing you there it took we detect the sentences within that paragraph we can give a score for each sentence within that paragraph is still negative 0.314 the first sentence of negative point 19 for the second and a positive 20 so that's where we're starting to break down and do the the algorithms on top of the text to be able to give the human factors engineer an idea of what these comments are about at least from it from a sentiment perspective and here's a quick way of visualizing it for them you know darker red for more negative the lighter shade of red as it goes down a little bit and then the blue for positive other variations of visualization on this comes through from core diagrams again this is just how we start it I'll show you how we're turning it in not trying to turn it into a knowledge graph box plots do very similar since a lot of different things you can do for visualization of these type of data bubble plots are very exciting because this starts to give us an idea okay how can we take this and then bring it into a knowledge graph here you've got bubble plot the size of the plot represents the the level of sentiment so the larger the bubble the the greater the sentiment the coarse blue is positive right it's negative and as you can see your famous Latin words in that I can't show you I can't actually show you the comments that's not that I can't do but I can least show you that this is what it would look like for somebody else going to read it and then we can also do trainer analysis all of these things were going to start being able to implement within a knowledge graph you know we ran this through because a lot of the things we were doing here we have a data scientist doing this we'll eventually be able to develop stored procedures in the graph database that allow us to run this automatically for them so they can visualize it and get that information out a lot quicker we can classify through this and if we if we look at this classification as you run through down at the bottom left over there you see these three little circle around I mean it's come sorry the rectangle around those three Carl comments there if we look at those comments they're all classified they're all about some type of noise some grinding noise or or loud noise so we're able to we're showing that the analytics is working its clustered again more information to put back into your knowledge graph and then we go to look for information search and extraction theory we're using the cosine similarity to look at the the sensitise attend the words at how close they're related together again more information so we can put back into our graph database and I'll show that example a little bit as we go through here and what it could do in this particular case having put that doing that cosine similarity and get in the term frequency inverse document frequency we can we can request a result from the data set that has a term nutrition well as you can see here's what the return came back and talks about food food warmer eat ate well eat everything not once that it had captured the word nutrition in that comments because because of the cosine similarity we said this word is close to nutrition and it pulls up all of these words also all these senses it's also so those are the things you can do as you started applying these type of analytics into your text so there's a paper written on it that's the information there on the paper that's my twitter handle if anybody wants to reach out that talks a little bit about but let me show you really quick the actual graph database they'll give you an idea that we're starting to develop this thing 