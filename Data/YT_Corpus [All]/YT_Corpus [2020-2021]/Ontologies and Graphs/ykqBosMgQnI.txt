 so the central problem in AI is how to represent knowledge and how to reason about knowledge and the AI systems that we have today are representing knowledge in like first-order logic in axioms and those axioms are created by humans they are not automated. It is very hard to go from text to first-order logic Teaching that to students is really a nightmare and my vision is that NLP in the tools we can create with NLP can facilitate extracting knowledge from text and transforming that into some actionable knowledge right and now I'll show you how we can go from text to knowledge representation that can facilitate reasoning now the other hand you have machine learning and machine learning facilitates natural language processing tools it's basically present in all the modules from early part of speech tagging all the way to extracting semantics from from text and machine learning therefore enables NLP but also this way it enables building robust AI systems. Ontologies play a very important role ontology is basically our knowledge bases that are dedicated for some domains they represent the most important concepts and relations in a domain and people build the ontology by hand and that's a very tedious process and because ontologies are useful they for example help us with abbreviations they show the connections between concepts you build this ontology hierarchically for example you refer to a vehicle then that's a car and the truck is related to a vehicle or a sports car is a vehicle, etc. so we have to develop tools to build this ontology automatically and it's possible to do that so we start with some important concepts and then you extract more related concepts and then the snowball grows. You build large and larger ontologies. And then we have here the knowledge bases this is the result of transforming text into some semantic triples we build the knowledge graphs so this picture really shows that NLP is central to all these activities and if you want to build some large, robust AI systems then NLP will be a good way to do that. I know this audience is interested in in chatbots and I want to classify these dialogue systems into... This is how they are classifying some NLP text books as task oriented dialogue systems and chatbots which are more intended for extended conversation it's not only ordering something from a restaurant like you do in the task oriented dialogue system but you engage the machine into some dialogue and then the machine responds and then you ask kind of the clarifying questions and eventually that conversation takes many turns so that's how I look at chat bots and it's a different architecture and we have to be aware that chat bots are not necessarily task oriented system there is a fuzzy line and people can argue that there is no need for this taxonomy but it's being made in the in the literature now here's an architecture that I came up with that is for dialogue systems. So we have here the input from the user... see let me use my laser pointer here alright so the speaker has some question and that speech is converted to text and these modules convert speech to text and text to speech and I'm not working that area so I'm not going to say much about that but once we have text here then that question will be processed by this NLP unit and we extract in information like: What's the intent of the question? What is the focus of the question? What's the question all about? and what kind of answers the user is looking for etc. and there's a dialog manager that is present in all these dialogue architectures that really manages the dialogue, keeps track of what questions have been asked, what's the history of the dialogue, and it chooses where this dialogue will go such that the answers will not be repeated the responses prepare here and then it's converted to speech so this is just the dialogue part now more sophisticated systems need to extract answers from some databases or from some repository from some documents. So that's where question-answering comes into to play here. We have now the question being sent to the question answering system and the question answering system has to find the answer to that question by looking for the answer in some documents so now there is another unit here NLP, plus some indexing that converts the documents into some knowledge graph. And this knowledge graph is basically a set of semantic triples and then certainly the ontology can help with the NLP processing as well as with the question answering the SOL system here which is trying to extract answers from documents is a hybrid way to help the question answering system such that some answers will not be found in knowledge graph maybe there is no match between the question graph and the graph that was obtained from the documents but still there is some answer into into these documents so in to build a system that to be more more robust we send a question to the solar and then the documents are retrieved and then we process those passages further to extract the answer so we have here an architecture that I think it's strong enough sustain many applications that could be fairly sophisticated. Any questions? "Does SOLR stand for something?" It's a way to index documents yeah I don't think it stands for anything... yeah that's right it's the name of an indexer okay all right so now we focus on how to convert text into knowledge graph and that is the RDF triples so you have here a pipeline of NLP modules and the text is presented here and at the end you have the graph representation of the text so first there is a module that does document pre-processing now this is a very important step because the documents come in all forms and shapes - could be double columned, could be tables and documents, could be pictures, could be captions could be.... so the system has to understand what that piece of text is referring to right so the the document preprocessing transforms the document into some representation that the machine can process further. Then there is a text segmentation identifying punctuation and word boundaries and sentence boundaries, paragraphs, etc. then part of speech it identifies the part of speech like nouns, verbs, adjectives, and adverbs... and then we go to extracting concepts these are entities as well as events. Entities are, for example, names of people, companies, and events.. are things that happen, like our meeting is an event and... this is called concept extraction these modules that have star are customizable modules they require to be adjusted for just about any other job you do but whereas the part of speech tagging and document pre-processing could be generic. Word disembiguation  is the module that specifies the sense of the words. if we have the word Bank could be the bank is an institution or the bank of a river, and typically that boosts the performance to some systems if you work in some domains. Then,  is the module that must be there that is the syntactic parsing it transforms the sentence into some parsed tree and once you do that then we have a module that it extracts semantics from the sentence so... these are semantic relations that are present in the sentence. If I say John went to the shop to buy flowers for his mother, then there are number of relations there: John is the agent of buying, and buying what?  Flowers. and where's he buying from? from the shop, etc. Those are the semantics and extracting semantics from from text is really hard and not too many systems over this module. Then you have the module of the core France this identifies that some names are the same, like John is equal to he or the professor or the CEO is maybe the same person so this module solves those problems. And this core effort can occur even between documents right so or you have an event like bombing event in one document and how do you know if it's the same bombing event in another document so that's the typical hard problem to solve then we have the module that is the machine learning this extracts features that could be used for some applications and eventually the module that converts the semantics into some RDF representation that will be stored in the in the graph so the end result of processing documents will be to have this triple store representation graph. And there are many companies offering different kind of knowledge graphs and it's your choice which one to use now I have here an example that shows you how you go from a sentence to knowledge graph. Okay and there is this little story here that the train was an Express number 176 the 176 was scheduled to depart for New York City at 10:30 a.m. and arrived at 1:30 p.m. on March 15 and to parse the sentence we go to all those modules but then after we parse the sentence we identify that 176 is a number right so it's a named entity number and also 176 is a noun and we have some arguments these X's and E's are the arguments of the predicates. These words become predicates so this shows the it's an event here, departing is another event and there is a relation between event and the New York city is... the machine doesn't know so it's New York City and eventually this is concatenated into one concept New York City and New York City is a town and then 10:30 it's a time and March is a date and so on well this is represented directly from the parse tree so you can automate the creation of this part what you see here in blue are our semantic relations that are extracted from the sentence. X7 which is this one 76 is the theme the object of scheduling. Schedule what? scheduled for that one 176 was scheduled because this is a passive voice here so there are some other semantic relations: location, time, topic - topic is the relation between the verbs and so on. So you can come up with this representation that and that can be automated and that's a very important step so this is not like first order logic. First order logic cannot be generated automatically now once we have this then we we can generate a graph that and that step is a very small step once you have that previous representation and you can come up with this graph that x7 it's a number and it's referring to 176 this is the argument and between x7 and E 1 there is a theme relation and there is location relation here between departing and the New York City the time between depart and 10:30 a.m. and etc you see them here with gold these are the semantic relations and the others are entities and this software can be created to generate this this tree parse, and this is a huge step because now you have something that is almost like a standard 70 semantic triples RDF triples and you convert text into these and then you can reason about about any question yes please "In your previous slide you mention about the machine learning..." "You mention about machine learning: what does machine learning do.. does it form the RDF triple?..." right it is not only forming these these triples but it's a good question but you might extract some features that you want to have for question answering or for sentiment analysis or for some other applications so typically that module extracts these features that will be used later and for some applications so now those features may be linked to the semantic triples if you really want to do that so the more knowledge you can put in the semantic triples the the better it is all right so now let's go to a question answering which was one of the modules in the architecture so ..I like taxonomies because put some order into some into into what is out there and in thinking how you approach the problems one type of question answering is open domain question answering that means you ask a question and the question has to be extracted the answer to that question has to be extracted from a large set of documents you can have a 1 million documents or so and the documents could be 20 pages or or one page it doesn't matter and you have a question in English or some other natural language and then you extract the answer to the to that question so that's open domain, right, will be any domain financial could be medical whatever domain now there are other and the documents obviously comes from webpages and libraries and maps books etc you can even link this open domain question answering with processing images and that will be even more powerful system then there is the frequently asked questions or can question answering there are situations in which the answer is so important that many companies do not want to venture to have a system pick up the answer no matter how good the system is because you can get some legal troubles if you provide the wrong answer so you have the question and and the answer to that question so now the problem here becomes how do I map a new question to one of the frequently asked questions that I have answer for and and how do I increase the the number so we will address that so having this in mind I want to say that question answering is not only the information retrieval that we use in all search engines right information 3 we get documents back information extraction we have documents and we fill up a template who did what to whom when where things like that and even it's not ir+ is much more it requires some processing ok here's an example of your easy question what is the fastest car in the world and it's a factoid question and the point I want to make is that just looking at paragraphs where there is a match between the keywords that is not going to be good enough because you have the the fastest in the world and the cars here in this paragraph but this is not the answer we are looking for the answer is in this paragraph right and the answer is this this car that was an easy question of fact we the kind of question and then there are more difficult questions like will the fat change interest rate in the next meeting I had this slide even 10 15 years ago is still valid right because the fat still does this job so to answer this speculative kind of question you have to acquire information about the Fed interest rates and and then stock market the employment and inflation you have to extract all this infusion freshly I got to have a model and then through that model you will be able to figure out if this is going to go up or down or stay the same right so it's possible to attempt a hard answer those hard questions but not immediately we have to extract more information the taxonomy of the question answers over here we have simple questions like what is the largest city in Germany and answer is Berlin the largest city in the determinant so there is a snippet of text giving you the answer more complex question would be a question where you you have to do some reasoning to pick up the answer how did Socrates died was Socrates poisoned himself so you have to figure out poison himself is related to dying it's one form of dying or you can have questions like you have to put together the answers and come up with a list what are the arguments for and against prayer in school and one part of the answer comes from one document another from another document and sister had to be smart enough they come up with a list of arguments for and against and then there are interactive questions like clarifying questions like chat BOTS or the dialogue systems right and these are considered to be more difficult and then speculative questions that I mentioned before so so the state of the art is that the systems today even Watson can answer this fact with question like in jeopardy sort of this fact with questions that the answer but certainly when it comes to even some more complex reasoning the system's break they are not able to answer this complex question never mind the complex question that our category-five so generic question answering architecture looks like this you have the documents and could be very few or many many documents and the question goes to question answering system and you have to pick up the answer now the answer some people want to have the exact answer who is the mayor of Dallas for example there is a name right we have to be careful you have to give the today's mayor of dollars not I know ten years ago mayor of the house so through some reasoning that has to be in order to provide the correct answer if you look at more details on this box you have a module that process is the question so the question has to be understood if you do not understand what the question is about there's no chance for getting the answer so if we have to form a query and have to know the intent of the question the the focus of the question of the type of answer we are looking for and the traditional question answering since this query and retrieve document through solar or some other information retrieval system and get some relevant documents out of the million documents that you have up here and once you have very few documents then you do the hard work to extract the answer from those documents and this query goes there and then you eventually have the answer there are some resources that could be used like even Wikipedia or some dictionaries or see a fat book and many other inform repositories that provide some partial answers now if we look at more detail it tells about the architecture this box is here with the orange color part of the processing question so first we have to figure out the spelling and how to split the question maybe the question can be broken down into two simple questions so you do that there then you construct internal representation of the question and you have to pick up the answer type what is the question all about and we have to select some key words if the question is very long then some key words will be eliminated only the the important key words will be kept in a query and eventually sometimes we have to form the query expansion like what's the capital of Texas here you just have Texas and capital so we have to look for some other words that are related to capital because capital could be ambiguous is just a town or maybe some some capital like a monitor or something that takes us s value so anyway at the end of this we formed the query and that goes and to the information retrieval and extracts the passages where potentially the answers come from and then we identify the answer in these three box three modules like a candidate answer the we rank and sometimes the the system gives you list of answers and they all have some figure of a merits and then we have to pick up the one that you think is the most likely answer and then there is answer formulations so this is more detailed architecture of a question answering system that typical has been implemented just for you to have an idea where the errors are occurring most of the errors are in occurring in this detecting the answer type and also when we expand the query from simple query to to larger queries capture answers and even the identification of candidate answers so there are some numbers here that indicates the percentage of the errors produced by each module one innovation of this architecture that has been well received in literature instead provide some feedbacks for sequential modules equation architecture and in case you do not have enough passages that can contribute to the answer then you go back and you retrieve more passages and if you are not satisfied with that you go back and you retreat you you change the query formulation so there these feedbacks provided an improvement in generating answers because you don't have to give up you work the system and the documents until you get the answer that you want all right some complex questions that could not be answered with that system are listed here and these are some questions and look at recently for investment institution and what the analysts this is an analyst working for for that institution top recommendations now right so here's the name John Burroughs top recommendations now so we have to figure out what recommendation is and for that we need an ontology because just the word itself recommendation doesn't mean much to the system but if we have an ontology and then this is translated into stock recommendation or some other securities what are the key value of growth drivers for a certain company right it's another complex question that requires an ontology what are the terms risk or concerns for a certain company right so all questions that analysts are asking and like I said tensed is complex questions typical question answering system will not be sufficient so what's the problem how do you solve this problem well we build an ontology that's specific for that domain and then we take each type of the question and we we try to have patterns for figure out how to create an answer for each pattern of the question so it's not as simple as matching the question graph with the knowledge graph that will fail now so the point is that since we cannot provide answers only by matching a question graph with the knowledge graph of the document then we have to use the hybrid approach and that means to use solar that will provide indexing so true solar we index the document and this is a more robust yes please RDF it's a standard for for me yes yes yes thank you yeah we use that all the time so it's a standard for semantic triples and so this alone will not be sufficient neither will all be sufficient but the hybrid approach is is superior because sometimes we get the exact answer to some difficult questions by matching the graphs but sometimes just the information the the indexing will be sufficient all right so I was mentioning oncologists and how many of you are are using ontology in your work you're using I think more and more and there are jobs like want ologists then now that her I seen companies are hiring and they are looking for oncologist and there are not too many of those markets so there they were paid so the role of the ontology is to create some knowledge that links different concepts such that if you look for a word like that that doesn't have much meaning but then the ontology is connected to other words then that will enhance the query and you can you can get the answer here here's an example of a question what are the key stats for Microsoft in the last quarter so we have a matrix here key stats we have a company and we have the time and the answer is from was coming from this sentence now how do we link that question to this sentence so Microsoft has a ticker then we have the word revenue reach 1 million in what fourth quarter 2017 so the key stats is linked to to revenue through ontology and then we know that revenue is 1 million that's easy to find out Microsoft is a company and this is a time for the last quarter and then here's the answer so without ontology will be difficult to provide such an answer if you're interested this is an ontology that links shows for example how the word recommend links to to stop to shares to assets so it the intentions indentations mean is our relations right so acid it's an honorable economic assets an asset financial asset is an asset so these are these indentations represent is our relations and recommend it is here under the stock ok so you can answer a question like that what is our recommendation on VMware well we have to understand what our is it's the analysts view and then the recommendation is picked up from there it's a it's a stock value and VMware it's a company so you could transform this question into some semantic triples and then you can get the answer hopefully the English question which is shown here can be translated into a sparkle question that it's sent to the knowledge graph and that transformation from English to to Sparkle is automate it can be automated with a little bit of effort because people don't want to use Sparkle to query the graph so instead you have this module that converts English to Sparkle and then this is sent to the knowledge graph and then you can get the answer from from there so it's possible to do that but it's not so simple it requires a little bit of effort but it's possible now I'm coming to frequently asked questions this or the other type of questions and I'm using a use case that helped for Fannie Mae if you look at the web page there are 22 free frequently asked questions and those questions have answers and this is an example of question and the answer okay so but what can you do with just 22 frequently asked questions typically a user may ask a question that is in total different format so now the task is to make sure that that question maybe links to one of the existing question is the same it's one of the existing questions and then if that is the case then you have the answer for that question so here the problem is how to generate questions that are semantically similar they are paraphrased so for that we use a neural network mod module the board system and data augmentation so you have a question and then the data augmentation first takes some words at the time and then for each word it generates relax ago syntactic patterns so for example if I have a question like can I see something then through this augmentation you have is it possible to see something or is it allowed to do something so that's what we mean by this augmentation so there are patterns that are replacing words and we generate more words into that such that the questions are semantically similar and then through neural network we can generate even more words that are related to those words because of the semantic similarity of the vectors and then eventually we end up with the model so we use this architecture and we generate it for those 22 fanime questions 58,000 automatically generated frequently asked paraphrase questions and that was large enough to satisfy people asking all kinds of things about Fannie Mae web pages so that's a large number okay and the accuracy of the generation was about 91% with the birth mother okay so in order to yes question please no that means they are wrong matches they did not match correctly that that's what ID % indicates in 90% of the times the the questions match different they are not considered here so we only consider questions that had a match but they missed yeah because we want to know how good as the system was real data testing meaning you know real populations population yes yes yes yes well here's some examples of questions let's see okay so this is a frequently original frequently asked question for employment offers and contracts if the lender is unable to obtain a pay stub to meet the selling oil requirements do we have options now what we did help the system we manually generated about fifteen twenty questions that are different but they are semantically similar so you generate that in one hour or two right and then just to help the system to generate even more questions automatically and this is a question that was generated the manually what are the options if the lender is unable so this is exactly same question but different words and then the the system pickup paraphrased questions either from there or from here and you have here at least three examples of questions that are semantically similar to these questions that are part of that 58,000 questions so these questions are pretty real right if you read there's no nothing strange about this question is a sum how people speak so that's that's pretty good yes that's what I mean yes that's right that's right it's from the Semantic Web yes can you give us a little more details about how those paraphrases are automatically generated is that a natural language generation model yes so let's go back okay so there are two to two steps one step is to look at the question and and change the words come come up with some for one word you replace the word with a phrase like a verb phrase like I gave the example before can I see through that window is it possible to see through that window right am I allow it to sit with that one and things like that right so is a human doing that subs are done automatically by the machine so that's a look up into the source exactly exactly so some work has been done to come up with the lexicon for this data or whether but you do that once for all and you have it so that's one step and then you go to the next step through the birth system that takes a question from from here and generates even more questions here by the virtue of the language model right and so so you use Berk for that for that yes yes thank you yes all right so this world well and like I said there are many companies that valuing these frequently asked questions because they want to make sure that the answers they produce are absolutely correct and they are not liable to any misinterpretation so the the input text that the user asked like can the realtor Commission go towards the borrower down payment so that's a question somebody's asking and then that maps to this question which is frequently asked question for which there is an answer so like that the problem is how to generate these and the questions that are generated in other words the user doesn't have to use exactly those words it can the user may may change some of these words but then the new question let's say the user will can can use some other some other words here then through the neural network then this is considered to be similar to that question for which there is an answer so those 58,000 questions are not the only questions that somebody can ask the system right there are other questions that can be similar to those 58 hours and questions so it's very very large number of questions yes please so the we try to be here very strict about similarity so in the literature there is this semi eval semantic evaluations and so too they use five degrees of similarity zero no similar one a little bit more but still not similar if you are level three they are close level four is closer in level five is very good similarity so there are these five five levels that I use in the literature and you can put the threshold you accept only level 5 level 4 and those are considered very good similarity questions so that's what I mean by similarities right there is the measure of belief there's the probability right so the similarities basically derive with a neural network and then you have the outer layer the that gives you the the probability of the output and and that's how the that is mapping to those levels 3 2 3 4 yes now the last topic I want to touch upon is is it possible to build the question-answering system with neural networks and I think I know many of you are interested in that well here's the answer first of all I just want to say that for neural network we have to have some collection of documents that train the system and one collection is the track system that NIST the government agency NIST has prepared over the years and there are about there are some competitions in fact the precursors of Watson system was part of that competition so it's limbo so there are about maybe 5,000 questions and there are 1 million documents and there are answers for for those questions so if you want to train your question answering system you can use the track collection probably there are some paperwork to be done but they are generally available so that's one good resource for training the other one is the square the the collection of paragraphs from Stanford there are about 100,000 paragraphs and the questions and the answers could be in those paragraphs or could not be in those paragraphs right but the difference between the two is that here you have 1 million documents and some of them are long documents and here you have only paragraphs right so the work in question answering is only about the squad collection the right they never attempted to come up with a solution for the track correction why because you have to retrieve the documents is not possible the process to neural network 1 million documents right so he's the architecture here's what's going on we have a question and then first we still pre process that question to find out the user the question focus was the question about what type of answer will have etcetera those modules that I mentioned a beginning are still useful here and then we have to if we have a collection of documents like in this case we have to have an information retrieval system and it pick up the paragraphs that are potentially keeping the answer and then then the question and the paragraphs will go through the neural network model because here you don't have documents you are dealing with some paragraphs that have been already produced but by the ir system and then we use birth and we use also Excel which is much better because it can input larger paragraphs then birth is only taking a 512 tokens but Excel net allows you to input much larger paragraphs thousands of tokens right so then then you get the answer in the answer you get here is very good so this part of the architecture works very well the part where it doesn't work is this the neural network cannot replace the information retrieval in other words you cannot have here one needed documents and send them to the neural network expect again some answers you have to couple that with the information retrieval in order to get answers so here's the architecture that this word so here's the question and there is this tokens that separate the questions from the paragraph and this is the paragraph that may may or may not contain the answer and then the output will be the word that starts the answer if there is one and this is the word that ends the answer and so yeah I think I have an example some examples here what is the largest volcano in Europe and the answer is Edna so in the birth architecture will be only one word that is the answer in this case the beginning of the answer will be pointing to this quotation and then this will be the end of the answer right so that because that's the answer okay any questions before my final slide to some takeaways so I think that NLP tools allowed us robust AI systems we have parsers we have semantic parsers we have some equations now this these tools are not necessarily part of your open source repository for example open source doesn't have any semantic parser tool synthetic parts are yes but not semantic parser nor does have core reference and some other so there are some sophisticated tools that have to be built or in some laboratories and so on but these tools exist and they becoming more and more popular and those tools we can convert text into some semantic triples and then we can then case based reasoning or some other common sense reasoning that was not possible to do on a large scale so you know not only toys systems then another idea is that it's possible to transform text to knowledge graphs and perform reasoning and that representation the representation I'll show you goes directly from a parse tree to semantic triples without creating the first order logic actions which are difficult that they create so we make some simplifying assumptions we don't need the quantifiers and some other sophistication that first-order logic has so we renounce that but then we and we'll build a more robust representation dialogue systems using natural language and question answering is a powerful architecture that enables new applications and which is a big step towards really intelligent assistance so now of course we didn't talk about the the intelligent system being able to ask questions right because the clarifying questions nor does it have any personalities so there is a long way but I think those things could be added on top of that architecture that contains the the NLP and modules and the question answering and last the fact that neural network technology changes NLP and really is seen if you go to an NLP conference about 60% of the papers are related to neural networks it's amazing and everybody's in universities in researchers doing deep learning NLP but neural networks alone are not enough and I had an example where you had a couple with information retrieval to resolve a problem by questions you 