 [Music] welcome to the second lecture second week this course on machine learning this lecture will focus on the characteristics of objects categories and features essentially the building blocks needed in the area of classification and concept formation this lecture will discuss the following items first we will talk about objects and features and then we will also discuss something we call the objects base and something we call the object language and furthermore we will discuss categories category structures what we call the categories base and what we call the high plus so the first group of items refers to the way we phrase our data and the second group of items refers to how we raise our abstractions so let's start to talk about objects and by object I refer to the basic data the basic data items on which we base our analysis as you see there is a very complex journal of terminology people use very many words object III like personally as a term but I think in many cases data or maybe data item is a good word big because he's understood by many people some people talk about record some people but tuple some people talk about row some people talk about vector people from statistics tales obtained about instance for example or training instance or training example there are also someone more exotic terms like thing nor entity but essentially all these terms is supposed to refer to the very concrete data items or data objects on which we base our analysis so then the question is how do we characterize an object and then we come to the to the use of the word feature so in the same fashion that there are many words of synonym words for object there are many synonym words for feature so I highlighted feature as I like it object but there of course alternatives you can talk about property of an object you talk about attribute of an object characteristic of an object you can talk about a field but a field in a way is compatible with record you can talk about column but then that also is somewhat compatible with with it whether you talk about Wagner or row and so on and then we have words which are primarily used in statistics variable and for variable there are various variants of that we can talk about output variable you could talk about independent variable we could talk a predictor variable we could talk about variants of feature we could talk about target feature we could have a category feature and of course special special semantics here I mean a predictor variable and an independent variable immoral society that is separate from from an output variable because normally when we talk about output variable we mean the kind of class label that relates to abstraction we want to create the same for category feature so output variable and category feature could be more or less synonymous unfortunately I don't think anybody can assume that people will be totally consistent I must admit myself I switch between words sometimes it feels right to talk about data item sometimes I feel it feels right to talk about object but as long as as one of the basic understanding that there are two kind of phenomena here on one hand there are the quantity concrete objects and there are synonyms for that and then there are ways of characterizing those objects and then there are synonyms for that so far nummy one can say that you need a formalism to express these things it doesn't it's not very something very advanced it's just a simple conventional formalism in which you express your features and of course some formalism in how to group features so that they can form objects but when run refer to this formalism of this kind of simple language in which objects and features can be expressed we normally talk about the object language or the data language or the observation language so just a few words about the types of features now of course can be any types but the the common types or normal types that we will see within this course are the following so first of all are the ordinal you can call them binary or and then we have the numerical which can I'll either be discrete or continuous and finally we have the symbolic symbolic features which are simple symbols or we can have simple structures in the most common there is of course lists but it could also be more complex like the graphs and so so here comes one example from from the zoo it does that one data item picked up happen to be buffalo and as you can see the object language here is a very simple one it's simply commencing for for for listing the features okay in a row and you can see then below that is that already that the the features here are mostly ordinal only one is discrete two features are special because they are not predictor features in the sense that they predict the class but they are classification features that pre classify each object there are like two here because on one on the task is to classify these animals on a high level so the class type with values from 1 to 7 issues for that but then there is also an animal name jeez Anthony the name of that specific kind of animal and because there are no duplicates here it's all over over Buffalo or or of work or some other animal it's it's just the identity of that title item so let's talk now about object space so by objects space I mean essentially the space of all possible objects as can be described by the object language so this is depending on on the language and this can be bigger or larger but this should be separated from the set of objects that we consider so so this means with this convention the data set the set of objects considered for evaluation is just a subset normally of the object space and depending on how the features are set up or chosen this could be a dance or spares space meaning that only a certain the subsystem is pretty small subset out of the total object space but there can be other words here the sample is a world of learn statistics which also means the set of objects you actually look at training sample statistical sample then one can also use words related to vector or record we can talk about tables and arrays so so if the data item is a row the feature is a column then then then the data set is that is the table Lazarus and Olaf's car all those herbs and of course an array is a way of representing a table training example set is another word that can be used for for the school substance of of objects that we consider so let's take a few examples from the zoo data set so we look at the object space first of all again so the object space or population is the set of all potential feature vectors with feature values as can be expressed in the zoo okay okay so objects space in the way I phrase it here is a syntactically defined by by the object language the sample or data set in this case in this example is the whole set of su feature vectors as described on one of the earlier slides the word that is a little tricky to use because it's inherited from philosophy is extension because normally in philosophy extension of a concept means the set of all entities in the world so the extension of the console mother would mean the set of all buffaloes in real life it's a tricky to use pick because not necessarily we have chosen our representations in such a way so that they truly represent all all living creatures on a certain cap so therefore I would avoid the word extension so now we come to what is called the hypothesis space and actually how they are defined from the definition of a category so so actually if we look at the term category there are many synonyms really a lot so we can talk we talk about categories we take concept little bit of classes you talk about hypothesis and talk about target function we can talk about time pick you look at schema we get a model we can look at what classifier can even talk if we are a little more philosophical about the intention of a concept so all these are words to capture the abstraction of the concept the hypothesis language the language for expressing the abstraction can of course your etiquette be any language it could be different from the object language but in many cases very typically its syntax wise consistent with the object language of course there have to be minor even in the simplest case have to be minor additions so for example the syntax for feature values have to be extended with Jupiter generalizations the normal manuals because the hypotheses or concept in Ephesians is always an abstraction from a concrete object so if we have a complete object expressed in terms of features with with will go great values you will want to formulate that abstraction we need some wild cards we need some variables that allow us to to generalize the feature values normally we have a variable background knowledge that also can constrain which kind of abstractions are meaningful so these are this constitutes a priori not knowledge outside the knowledge that we get out from from our objects or our from our data so this background knowledge we can normally be bedded in the hypothesis languages through simple language constraints and if we embed this knowledge in the language we normally call this a language bias it actually is a learning bias but because we can only learn the language allow us to learn finally what is a hypothesis base so the hypothesis base is event actually the space band by what can be expressed in the hypothesis language okay so let's talk a little more about terminology here so we introduced the word object we introduced the word category so we have a definition of a category expressed in a category hypothesis language so once a you're talking a way of talking about it as an object is an instance of a category and of course a category is a generalization of it or an object but then we also have the relations to the object space so so essentially given a specific category definition one can look at the subset of the objects based consistent with that category definition so this means that all objects that fulfills the dogon strange of the category definition this space subset sub space is normally bigger than the actual subset of the data set consistent with the category definition because there may be a lot of objects that that that is not there at this point but it's still expressible in the language week we we we created so of course there is a subset relation between the subset of the data set and the total subset of the object based consistent with the category definition and of course an object is is a subset is an element of the subset of the dates so this is a just a little picture to show you these kinds of relations that exist within this technological framework we have set up so you may have found the discussion around the last slide little abstract so let's take a very simple example from the zoo data set so actually here you find the subset of all fishes taken out from the data set ok so so then the question is what what is a meaningful generalization of all those data items yeah the simplest way of handling this is of course first of all to choose hypothesis language which is close to the object language which I've already earlier stated that is the normal way of going forward here and apart from following the same instruction what will have to do with of course to introduce some generalizations of feature works that in this case we only have ordinal ordinal values so we only need some kind of wild card here like question mark so you can see in red and an abstraction an abstract record which is in this case is the concept definition where you find white card in the positions where the subset of the data set include compare and contradictory complementary values so so going back to the the last discussion on terminology we have a data set which is a subset consistent with the concept definition then theoretically of course we can think about that object space which is slightly larger because there may become there are typically combinations of the wild card values not covered by the actual subset of the data set but it's not explicitly depicted in in on this slide so now we turn in to something different so apart from just looking at objects and categories we can also look at category structures which is press the typical in any domain analysis which means that we not just have a simple level of one category but that we characterize objects in or domain in some structure and such conceptual structures or category structures have also many names because class structure class hiring a class that is concept struct a concept or a key type structure or taxonomy yeah and of course it's possible in machine learning not only to learn one level of categories but also to learn multiple levels of abstraction which means it's possible to learn category structures so apart from persistence and domain relevant category structures that really make sense in the domain is of course also possible to work with temporary structures as part of the learning process and we will come back to that but are examples of such things like for example working spaces so obviously when we add levels here with with categories on several levels of course we can generalize so we we can define specialization and generalizations relations between between all these levels so finally in in this slide and the next slide I'm just going to illustrate for you how it can look in the yellow case so the most common case is one looks at concept hierarchies which is a tree structure so so we abstract from objects in several ways levels in in a hierarchical way the the other variant of that is what we call the concept lattice analysis is similar a very similar thing the only difference here is that in a lattice it's allowed to have multiple generalizations upwards this means that you can generalize from category six to categories three or category to give in parallel many times in reality lattice is better maps on to the real situation but technically most cases hierarchies are more easy to handle so to convince you that multiple levels of abstraction multiple levels of categories or concepts it's not a theoretically a theoretical thing I show you here an extension of the zoo example where I'm actually just followed one path from one kind of item in our in our data set the Buffalo and actually what you see is the all the established so logical super and sub-categories and as you can count there are thirteen or fourteen levels from Buffalo up to two animal of course this is a domain where solo just have worked for for hundreds of years with the effort to find the kind of optimal taxonomy for the area so of course it's not likely in new more artificial domains that you'll find this depth but I take it want to show with us one extreme case an illustrating that many levels of abstraction is is not just theoretical thing but that it occurs practice and other observations on this line which is me over parenthesis is that if you remember the the features that were you in in this dataset and then compared to features that you can infer to be important from this kind of categorization you will see that they are not identical not surprisingly so because actually what's shown on this slide is it is the line from the Buffalo to the top and of course if we only want to classify animals on that line starting from Buffalo going up to animals then a certain set of features would be optimal in the general case for our data set we want not only to classify mammals we want to play classify fishes and insects and so on so this means that for that general scenario we need a broader range of features than the that set that is optimal only for going down the Buffalo lines so to say so one everything here of course depends on on the purpose so finally I wanted to comment on the what happens to features in in this kind of more abstract category structure so of course when a conceptual structure is formed during the learning process features will be attributed to the categories of different generality I mean in the simplest case we only have a job you have a category it's it's not an issue but if we consider many levels the normal way of looking at this is that every level in a way of abstraction contribute to a certain specification of certain features also the common way of looking it is that when you understand what what is the features of an object in a certain subtree our conceptual hierarchy and one looks at it the way that hierarchies further down the line inherited inherit the same features ask categories higher up the line and also normally features are not normally spread evenly across the abstractions level most features are grouped in the mid-range of the conceptual structure and this kind of mid-range is termed the basic level of course it all depends what you want to classify and how you arrange your structures but anyway doesn't really matter how you do it because depending on how you do it it's possible always to say that some level is basic and a very simple example you can see here so well so if we look at various kinds of fruit trees in the middle we have trees like apple trees peach trees grape trees and so on more abstract is fruit trees more specific or specific kind of apple trees like McIntosh trees delicious trees and so on and then it turns out that if you think about Oh what kind of characteristics you can attribute to each level you will normally find that that is more natural and more easy to attribute category sticks to what is here termed the basic level of course again with the disclaimer that is the basic level is something relative and relative to the way you set up the category structure so we reached the end of this lecture thanks again for your attention the next lecture will be on the topic feature related issues bye and thank you 