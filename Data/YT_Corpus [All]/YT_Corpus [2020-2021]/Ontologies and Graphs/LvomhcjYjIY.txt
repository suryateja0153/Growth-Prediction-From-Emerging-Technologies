 uh hey everyone thanks for joining today at Sabina sense we will be talking about graph algorithms and we're going to explain how they can be used we'll give some examples specifically in the context of banking and banking data so we'll start for those of you who might be new to neo4j with an introduction to graphs and and you know for J the graph database in the graph company will talk about the neo4j graph data science library which is what we're going to be using today and our examples then we'll review the data that we're going to use before we have the live demo later and we'll talk about specifically the graph algorithms that we're going to use as part of that demo on that data and there'll be time at the end for some Q&A so first introduction to graphs and neo4j so most people are familiar with relational databases tables columns rows this is the the kind of classic way that we've been working with data and databases for decades now Meo for j is a different type of database we're gonna be talking today about graph databases graph databases are all about the connections in your data the relationships between your data entities so rather than being oriented and rows and columns we're going to be talking about entities and the relationships between them so you can see the difference on the left the relational approach on the right the graph database approach and this is really powering a new wave of innovation and competitive advantage for people who are using graphs for companies that employ graphs it's really a unique way of approaching data and one that's really centered as I said on connections between data and sometimes this is connections between data that might be held in the same database that you have already are in the same data source or it could even be relationships across different data sources that you have and being able to make those connections and take advantage of them in the context that they give you the insights they bring really is driving a new wave of competitive advantage and an innovation across any number of industries so neo4j is the number one database for connected data we've we've been around the longest we have the highest level of market penetration the largest number of customers and you know forge a really is an enterprise-grade native graph database so what we're gonna be seeing today there neo4j database in action is is designed specifically for working with graphs there's no translation layer between another type of database or data store underneath and the graph you're working with you know for days graphs all the way down and by enterprise we mean it has all the features you would expect of an enterprise database any other type of database it's acid compliant it's scalable it's performance it's secure it comes with a full set of tools for operations and developer productivity you know can run in the cloud as well as on-premise so all the things you would expect from any other database you have in your enterprise you can expect from database from from the neo4j database as well so for anyone new to graphs it's a different paradigm as I said it's not oriented on tables with rows and columns instead it's really oriented around three three components and this is what we call the property graph model neo4j a way of representing graphs so the first element of a graph are nodes a nodes are usually nouns things objects you can see them here in our diagram the circles are our nodes and nodes can be labeled here we have two types of labels we have a person node on the left a person node on the right and a car node on the bottom and labels are just just that they're just a way of labeling a nodes you can work with it know how to query it know how it fits together but it doesn't necessarily imply a schema in the same way that like in a relation where they base every table every row on a table has the same number of columns you don't necessarily have the same sort of restrictions on nodes just because they have the same label then we have properties so properties can be applied to nodes as well as to relationships we'll come on two properties are key value pairs they're kind of descriptors for your nouns your nodes so you can see the person on the left has a name property of dan dan was born May 29 1970 we have his Twitter handle at Dan the person on the right also has a name property of Ann and she was born December 5th 1975 we don't have a Twitter handle for her there's no Twitter property and that's okay like I said both being person notes doesn't imply they have to have the same properties if we get her Twitter handle later we can very easily add it if instead maybe we get her Instagram account or her email accounts we can add that doesn't mean Dan has to have that as well so it's very flexible out-of-the-box its scheme a lesser or schema light so that's nodes and properties lastly and the thing that makes graph databases graphs are the relationships between these entities so you can see there are a number of arrows that link these nodes together for example a Dan drives the car which n owns so relationships are usually verbs and they link together your nodes and say how they're related to one another every relationship that neo4j is stored with the direction so you can say Dan drives the car right kind of fits together as a sentence you wouldn't have a car that drives Dan sometimes the direction is important and sometimes it's less important so for example dan lives with an we can see here and that means logically and has to live with Dan so we don't then necessarily have to have a relationship in the other direction we can know that because Dan lives with an she must live with him as well we can choose to ignore that direction when we query the database other times the direction is really important so dan loves and it doesn't necessarily mean and love stand back so here we can see that she does we have the relationship in both directions but we would need to know that Danny loves Ann as well as and loves dance so then we have a relationship in both directions to relationships so those three very simple elements are what make up the power of the graph really properties relationships nodes these three things will tie together as we start working with some of our algorithms and visualizations later on in that demo so the neo4j graph data science library some of you may be familiar with our graph algorithms package it's it's been out for a while that was produced by neo4j labs the graph data science library is the next iteration of that and it's really being productized kind of moving forward brought closer into the database product and really kind of standardized stabilized made even more performance and even more scalable so what are graph algorithms there's a lot of buzz around them really there's a lot of talk about them people are very excited about them I'm very excited about them basically graph algorithms are calculations that describe the topology the shape and the connectivity of our graphs its way of working with the graph in an automated way to find to find patterns maybe to do global traversals to work through the paths and our graphs to get a sense of the structure to find structure in in our graph to make measurements approximations get some heuristics find things that are important in the graph but really what it boils down to is it's a way to get new insights or to extract new views of your data new data from what you already have in your graph and so what do you do with them we'll see some very concrete examples today and I think this is always the big question everyone knows that there's probably something exciting they can do with their data and in a graph and with the graph algorithm but what that is can sometimes be a little hard to visualize so we'll be looking for patterns in our data we'll be generating scores against things in our graph enriching our graph and today we'll be using that to visualize our data to understand how we might use that to drive some investigations into fraud or something like this but you can also if you you know if you do data science or you have some analytics capability you can take the outputs of these graph algorithms and feed them into your machine learning as new features right which then you can use in your data science pipeline so the graph algorithms in the graph data science library really break down into five main categories which we see here the first is centrality or importance and this is these are ways of generating scores or you know determining how central how well connected how important nodes are in your graph second is community detection and this pretty much does what it says on the tin it's a way of finding communities or clusters in your graph and it's doing this not using some sort of demographic data but by looking at properties and how old is a moan or you know what do they do for a living or so on and so forth but it's looking at their connectivity in the graph the shape of the graph around them so how connected are these nodes and does that fit into a little community by the fact that they're all so well connected to each other third is similarity so this is comparing nodes in your graph and saying how similar they are again not by looking at some demographic information but by looking at their shared connectivity in the graph and the shape of the graph around them so how alike are they in the neighbors that they have or in the relationship they have fourth pathfinding inserts these are ways of evaluating paths in the graph at neo4j i already has a shortest path and all shortest path function built right in that looks at the shortest path between nodes based on the number of relationships or how many hops in the graph that path is the path finding algorithms are many of them take a different approach and instead look at the shortest path using some kind of weight on those relationships so for example you could use distance or cost or a time or something like this as a weight on your relationships and then the shortest path will become the one that has the shortest overall time as a weight on those relationships and lastly there's link prediction so this is sort of similar to the similarity algorithms again they compare the shape of the graph around two nodes and use that to predict or to estimate the likelihood that those nodes will be connected in future right or that there is some sort of more implicit link relationship between those nodes that isn't explicit in the graph already and if you want the full list here's the the full detailed list of all the algorithms that are implemented in the graph data science library and you can see on the bottom there there's a link to the library documentation which has all the instructions for installation and how to use all the algorithms and that link will be included with the materials we share afterwards and you can see there's four graph algorithms that are highlighted here these are specifically the ones that we're going to be working with today in our demonstration so lastly we'll take a look at the data that we're going to be using in our demo when we talk about banking and looking at you know graphs for banking or data for banking a bank can have a lot of different types of information right you can have internal information organizational information you can have information about your customers about your products and your services event data of payments or money trance or even third-party data social media or credit rating agency data and this kind of stuff but today we're really gonna be focusing just on two of these areas we're really going to be looking at customer data and specifically bits of identification you might have about a customer as a bank and event data so movements of money transactions between accounts so our graph is is pretty simple the shape of it is really made up by just a few key components so we can see clients in blue so these are customers of our bank the sort of red and pink shapes nodes down to the lower left are the forms of identification that we can have about them so we could have an email address for clients a phone number or this is an American data set so social security number social security number is a unique identifier for people in the US and it's important to know that a client could have multiples of these we might have more than one phone number more than one email address but social security numbers are meant to be unique in transactions over here on the right in green these are movements of money so we have a node to represent the transaction itself that would have things like what time it was executed ants what the amount was and so on and then the relationship between clients is you have one client who performs a transaction so that's the sender of the money and you have one client who's at the end of a two relationship from the transaction so that means that's the person receiving that money and then over on the far right we're not really going to work too much with this today but just to give a sense of how else we might be able to extend this data we could have not just clients a regular retail banking customers but also merchants so we could understand who's buying what from whom or maybe even some information about other banks so you might be sending money outside of this bank to another bank and you would know what banks were transacting there's also some relationships here in yellow so we're not again we're not really gonna focus on those today but just to help you understand what a more realistic dataset might look like we have basically a linked list of transactions for a client so we have from a client's we have a relationship that says it's the first transaction for that client and then that transaction links to the next transaction in time that one links to the next transaction in time so we can understand the order in which transactions happen for particular clients and then the end of that linked list we have the last transaction so we can very easily find the last transaction that a customer made and then understand that whole sequence in time so that's our model we've done a couple things to the data to get it ready to run some algorithms and to find some interesting patterns so there have been this is a randomly generated data set so it should should look realistic um but it's completely fake it's not taken from any real Bank and a few of the transactions in the database have already been flagged as fraud so this could be maybe someone ran up and said their credit card was stolen and they didn't make that payment or maybe some other analytics or manual process has led someone in the bank to flag a particular transaction as fraud so we know there's a couple fraudulent transactions in the database so we can see there's three ways that an account client could be flagged in our database one is they could be associated with that fraud so if there's a client node performed a fraud flagged transaction that customers flagged in our database another way that you could be flagged would be if you have a social security number in common with another client node so as I said before social security numbers are meant to be unique but if someone is stolen someone else's identity or is using a synthetic identity they might be using the social security number that someone else's are using so if two accounts have the same social security a big red flag and both of those clients accounts are labeled as flagged and then finally if you have a client who has more than one social security number that would be a fight as well you should only have one social security number and so if you're pulling data in from multiple sources you have multiple different records for a customer and you find that they have more than one social security number in your graph that would be another reason to flag so here we're using the word flagged you know we're not necessarily implying that we know something is fraudulent these people could be victims of fraud as well and so we're not necessarily implying that any of these people have done something fraudulent themselves but it is a reason to find this account for a review because something fishy is going on so now we'll cover the four graph algorithms that we're going to see in action shortly using that same data model so the first algorithm we're going to look at is PageRank and this is a very famous very popular algorithm used by Google invented by Google to help order search results and what this is going to do for us has helped us find important nodes by looking at their relationships it's really kind of measuring the flows of money through the graph and and to what nodes those flows head towards right and so you can see here node B is a big node it's got direct relationships with a bunch of other intermediate nodes that are a little bit smaller those have another set of nodes beyond them that are even smaller so kind of this measures how influence moves through the graph if money is kind of being transferred to one person and that person then transfers money to another person the third person that chain has kind of got a higher PageRank score when he moves in their direction and this can be used for things like fraud detection and anti money laundering so for example if we were to look at a graph of my bank and we looked at my node in the bank we wouldn't expect my neun to have a very high PageRank score right and if it did that would be suspicious right why why it is why is Joe sitting at the end of all these kind of chains of money and it can also be used use it really to kind of prioritize analysis we'll say you know what are the most important nodes in this graph in this visualization where should I be focusing my attention this is one measure of importance in our graph and we do that by really looking at the the performed and the two relationship so we look at transactions between accounts so we've already run the PageRank algorithm for the sake of time and we took the results of that and stored them in a PageRank property as you can see here on our client nodes so we'll be able to use that PageRank score and our visualization and any kind of investigation we perform second weekly connected components so what we'll use weakly connected components for is to find kind of disconnected sub graphs in our data islands of data and and in our case we're going to be doing that looking for communities based on shared bits of identity so who has who shares phone numbers who shares email addresses or even who shares social security numbers so in real life you could use this for something like house holding so so it's a common problem for a lot of businesses trying to figure out you know your customers might not explicitly tell you who they're related to who they share a house with who's in their family but you might be able to determine this by using a very similar approach understanding who shares bits of identity and can you build a little community based on them also we'll be looking at it from the viewpoint of maybe stolen or synthetic identities right so that looks like this we use the weekly component a weekly connected components algorithm using the email phone and social security number nodes and the relationships to clients to determine these communities and again we've run this algorithm already and generated a component ID and this is what we can use to look at community as all the clients who have the same component ID are in the same community based on their shared relationships two emails phone numbers and social security numbers then we'll look at node similarity so again we're going to be doing node similarity based on relationships to phone numbers Social Security numbers and email counts and we'll say which nodes are the most similar because they have these same neighbors right and instead of writing a property back to the database like we have with our PageRank score or in our communities instead with node similarity we create a relationship between two nodes to say that they are similar so in real life we could use this for entity resolution is really good for data quality cleanup looking for aliases things like this so if you have two nodes in your graph who share the same pattern of behavior connected to so many of the same things 95 percent similarity something like this you might say actually I think these are the same people maybe there was a type though somewhere maybe someone who's given me an alias maybe we can condense these things together into one one entity in our graphs are very good for entity resolution and data quality again will can also help us identify synthetic identities are stolen identities where identities in our graph are so similar by the fact that they're sharing these bits of ID so again we'll be using the relationships between clients and emails phone numbers and social security numbers to do this comparison we write a similar relationship between nodes to indicate that there's a similarity between them and on that relationship there will be a score property it says how similar they are zero would be no similarity and we kind of cut everything off we only run the similarity algorithm here in our demo I'm on clients that share two pieces of the same identity so we wouldn't have a zero or like that one or something like this but zero using this algorithm is no similarity at all and one is an exact match so somewhere between zero and one is where our scores will end up and then lastly we'll be looking at the llueve modularity algorithm so again this is a way of finding communities in our graph based on the relationships between them the neat thing about Lu Bain we won't we won't get into it so much today but Lu main can generate it's kind of a iterative so it'll generate a number of sets of communities that a node might belong to until it kind of reaches the end which is kind of stasis and you can track those intermediate communities throughout so you can get a different view of communities within communities within communities and to kind of arrive at the final the final result so we'll be looking at this community instead of shared bits of identity like we did with weakly connected components today we're going to be looking with Lu vein at transaction behavior so community is that transact with each other can we find communities based on transactions between them so this could again be used in real life things like fraud ring detection or anti-money laundering we have a lot of accounts that are transacting with each other more so than other accounts okay and again that looks very similar to PageRank where we're using the transaction behavior around nodes to generate the output of our algorithm we're storing the the final Lu main community as a property on the clients again and we'll use that in our visualization and our searches to find groups of people based on the transaction behavior so that was our intro and our overview so now we'll actually get into looking at our graph first just to give you a sense for what our graph looks like so what we're seeing now is the neo4j browser this is a free tool that ships with every instance of neo4j but it's really quite developer focused so to do the data-driven styling we can see here in the bloom interface there's an option for changing the color or the size based on our PageRank property what we want to do is make nodes for the higher page rank score bigger and lower page ranks scores can be smaller right and this will help us very quickly identify we can see now there are some nodes which are much bigger and will get our attention will give us a place to start so we might be more interested in looking at some of the the nodes with high PageRank scores okay so we can do the same thing we know that there's a flag we know there's a label that can be applied to nodes that are that are flat right and we might be interested in being able to see those nodes as well so that it's clear to us which ones might be associated with fraudulent behavior so here we'll apply a red color to any node that has the label flagged so we can see here and what we've pulled back there's two two nodes here that have been already flagged in our database there's Sophie and there's Connor Connor has a higher PageRank score we can see that straight away if we wanted to we could start to understand you know maybe what what transactions they've performed and start to get a sense for what the graph might look like around them let's take a look at all the flagged accounts in the database and start getting a sense for how much potential fraudulent behavior or how many victims of fraud there might already be what those look like in our database can seem very similar visualization here every node that we're looking at has already been flagged again if we want to drill in and start to understand maybe why they might be flagged so here this node has two social security numbers which would be an automatic reason for them being flagged as we discussed before you should really only have one social security number in the database took another one and see this one only has one social security number see if that social security number has there's two people who share that social security number so both Charles and Angel have that social security number and so that would be a reason for both of them to be flagged right so you can you can really explore the data manually right if you're doing a specific investigation want to to start understand understanding specific details are from a particular starting point that's perfectly fine in blue mic you can do this sort of searching and this sort of investigation manually but often what we want is to be able to execute a particular type of query all right so as a business user maybe as an analyst you always want to be able to execute something you want to look at the you know find me the the node with the highest PageRank and understand the network around them something like this right so as someone who knows cypher what I can do is write a pre pre-written site for query a templatized query that I can then put behind a very simple search phrase so that people can use it right so here for example we have a number of them that I've already written if we look at so maybe we want so maybe we want to do this show the I want the transaction within the largest community you can execute very simple search phrases and use that to bring back very complex results right so the cipher behind this you can hide from your end-users each one of these cause a cipher query and then that cipher query can be arbitrarily complex right and so there's a we'll see some examples of this in play today where we're executing kind of more complex queries that are already pre written so that your users don't have to know how to do this so for example if we wanted to see the client with the highest PageRank and explore the transactions around them this goes to the database finds the node that has the highest paid rank score and then pulls back that the network of transactions that are around them so this will help us understand why this person has the highest paid rank score all right so this is jordyn Conway you can see he sits in the middle of a large number of transactions and it kind of makes sense you can see visually all these yellow nodes are different clients the blue nodes between them are transactions you can kind of see a lot of clients transacting with you know maybe a node like this one that then transact with more central nodes and Jordan sits between these networks of connections right so money kind of generally moves towards the outside of this the little clusters in the outside the leaves may be in towards him which is why he has such a high PageRank score it's in the middle of this network of transactions and this is only looking a few levels out it can be very difficult to visualize our whole graph with all the millions of nodes but that's what PageRank does it considers the whole graph it looks many levels deep excuse me in order to in order to generate these scores so that's a little bit about PageRank and how we can use PageRank for searches and to drive our visualization now we'll take a look at the weakly connected components communities that we generated so I can show you actually in the browser what it looks like to run one of these algorithms right so weakly connected components even though I've already saved to the database there's another option that I can use in this algorithm to stream the results back to the browser to the consuming client so that's what we're doing here we're using weakly connected components basically to pull back every client and then looking for clients that have the same intermediate piece of ID so either they share a phone number an email address or a social security number and that's how we drive the creation of our communities who shares these bits of identity right so this is what it looks like to call one of the graph algorithms we can run that and in a second or two we should get the results so here's a number of component IDs community IDs that's generated and it also tells you how many members there are in that in that community so community 106 has 18 members community 49:32 as 14 members and this is really just an arbitrary kind of identifier for the community there's no no other meaning behind that component ID so we've saved those results to our database and the component ID so we'll say 23 we'll take a look at community number 23 so these are all the client nodes that are labeled with component ID 23 there's three of them Charlotte Owen and never they all have the same last name Harrington if we expand in the the in the bloom interface we want to specify we're looking for particular relationships in these so we want to see what email phone and social security number they have right which is how we'll know how how they form this community so we can see they each have a phone number and they each have a social security number all three of them their accounts have the same email address and if we highlight these things if we select the Social Security numbers the phone numbers and the emails and try to expand beyond them to see who else they might be connected to we can see that they're not connected to anyone else so that's what makes this the community all right you could draw a ring around these nodes in the graph and no one else is connected to those my emails phone numbers or social security numbers it's only these community members who share these bits of identity and so that's how we've identified them as a community if we take a look at the one that we just saw from our live results the streamed results component ID 106 we can see this is a bigger community and there's already a few people in there that are flagged as well as some some pretty sizable page rank scores right bigger nodes than we saw before so if you take a look at the way these folks are connected what we can see is a couple sort of little little clusters really so if we take a look at this group up here at the top they all use the same email address and this looks like the Knowles family there's maybe another family on the right the Roche family the Tran family down below and then really here in the center of all of them the bridge between a lot of these communities it looks like as Kayla knows right and this email address here so again if we were to look at these emails phone numbers social security numbers no one else would be sharing them this is the community built around these shared bits of identity with with that kind of bridge node in between them so the graph and the graph algorithm are able to do this at scale to generate these sorts of community scores look at the entire graph in these relationships at scale and as you've seen you know quite quite good time so a very interesting way to start finding you know if maybe you're looking at kyc scenarios groups of people that might be sharing pieces of identity maybe those are stolen identities or synthetic identities quite common so this would be a good way to identify those patterns to add scale okay so that's our look at weekly connected components we'll take a look at similarity and and this will this will be quite similar to what we've seen I guess because our similarity algorithm was run on the same thing the shared bits of identity right so rather than looking at large communities who share a little bits of identity here we're looking for client nodes that themselves are alike and the fact that they share at least two bits of identity so we could start just by looking for client nodes that are similar to other clients nodes some type that pattern into bloom and it will return every client node who has a similar relationship to every other client I am you can see that maybe not unsurprisingly there's a lot of flagged a lot of flagged clients that share its identity with each other but again it can be we have page rank here we can see which nodes are relatively more important by that measure in our graph but what we can't see is how similar these nodes are all right we could drill into them and see this one has a score of 0.33 this one has to score 0.33 that one has a score 0.5 it it's better I think easier to visualize if we apply the same sort of rule-based styling to our to our relationships for similar so we can do that by applying a size rule a higher score generates a thicker relationship which we can see here a lower score is a thinner relationship so again we can start to visually understand in our graph how different entities might be similar to each other but maybe we're more interested in trying to see if there's any clients that are unflagged that are very similar to clients who are flagged right so if you're not flagged but you're very similar to a fact account maybe you should also be flagged right so we have a query written for this and we can see there are two unflagged accounts that are similar to ones that are flagged so Annabelle has point 5 similarity to alia if we do the same thing and try to understand why they're so similar we can see the emails social security numbers and phone numbers that they share so they share two pieces of identity and then they each have one piece of identity that is unshared so they each have their own social security number but they share a phone number an email address and you can see the bits of information that they share as well so they each share two pieces of information and then they each have their own pieces of information as well so this is another way you know if you identify specific patterns or specific entities in your graph you want to find out who or what is similar to them these are the sorts of techniques you could use to to then understand who is most similar who then might also be will say likely to commit fraud or likely to be a victim of fraud or or whatever it is that you're trying to compare and then lastly we'll take a look at moving and we'll start by maybe looking at the five largest levain communities so these are the communities generated by the Louvre an algorithm that have the most number of members right so in here are five different groups we can see there's a couple flagged accounts in there as well here I think instead of wanting to see the difference between flagged and I'm five we want to be able to visually identify the different communities that were working with right so instead we're going to remove the flagged rule and we'll apply something for Louvre and community so now we can see we've colored the lubing communities differently we can see which which nodes are members of which communities and then we can start to think well this you know this is a pretty big PageRank score this purple here here's another one maybe we want to drill into some of the details or take a look at these particular communities right so we can do this this is there's a hundred and fifty nine nodes pulled out now we can take a look at just the purple ones by dismissing all the other ones so now we can look at the details of this community fine so it's a community one nine eight two three and we have another saved query so show transactions among moving community I've gone and forgotten one nine eight two three and so here we can see transactions that have happened between members of this community and from there we can start maybe we can turn off the loo vein styling and turn back on flag stylings we can start to understand whether there's anything dodgy happening we can combine some of these things together so we could we have another pre-written query we want to show the community with the most influential flagged account so here we're taking an account that's flagged the one that's flagged with the highest PageRank score that's most influential and then we're taking a look at the community that sits around that so again this is taking advantage of Lorraine we can see its Aubrey here who is the flagged account with the highest PageRank score we can see the community and their transactions that sit around that so we can see money moves from down here Nathaniel Adrian and Brodie towards Aubrey as well as from Jack here and then we can see Aubree has also transacted with Gabriella so this is the community based on transactions that sits around the flag to count with the highest PageRank score right so this might lead us then to take a look at Gabriella or maybe we want to take a look downstream and say well if our burry has been flagged and is potentially fraudulent maybe Colton or Henry or Blake should also be investigated to understand whether they should be fired or whether they might be involved in some kind of fraud we can also see the community with the most flagged accounts or a a community with the most five accounts what we did was looked at all the loujain communities and counted how many flagged accounts they had in them and now we're looking at at one so three is the maximum amounts of flagged accounts in any of our lubing communities this is what one of them looks like so again we could see a scarlet here has quite a high page rank score we could see money moving towards this account through this network and again we can see there's a number of flagged accounts that might make us further our investigation right maybe scarlet here should be a flag or under investigation because there's three flagged accounts sending money towards her accounts and I also look on downstream so you know are any of these accounts that send money through any of these other fraudulent accounts or flagged accounts like Parker do we want to look downstream through that community to see what else is going on okay so hopefully that's given you a nice taste of how some of these graph algorithms can be applied to some you know basic transaction data it's very simple data model you know as long as you know who sends money to who these are the sorts of tools that you can use on top of that data as long as you know bits of identity about your customers are how they might be related to a piece of ID or addresses or phone numbers this sort of thing then these are the sorts of analysis that we can apply and the ways that we might the ways that we might visualize that output and so with that I'll hand over to sub unit for the rest of the time we have for Q&A thank you to one question we received several times is if you can if you can share the demo data and the cipher queries so I have good news for the people that ask my question yes so the graph data Science Library is kind of just launching and there's a Connexions event at the graph data science neo4j event which is happening April 28th there's a series of virtual conferences I'm doing a similar presentation to this with a few different graph algorithms and a few different approaches but on the same basic data as part of that conference and at that same time we'll be launching a neo4j sandbox that has this data in these queries on it so in the next two weeks you can look forward to that you can just google neo4j sandboxes or we can send a link to the Sam boxes after this there's a number of Sam boxes that exist already for all sorts of different use cases but what you saw today will be into a sandbox pretty shortly Thanks another question is which algorithms could be implemented in real time process to catch fraudulent transactions sure good question so just by their very nature right just because of the way they work mathematically some graph algorithms are not very well suited to real time scenarios these are algorithms that have to look at the whole graph that have to do things iteratively so things like between the centrality that have to compare the shortest path between every node and every other node in the network and count who sits on that path they're very computationally intensive and they can take a lot of time so things like that are better suited to run more in a batch mode right but other graph algorithms are better suited to being able to run in real time right so especially things like the path finding algorithms you know we have a start node in an end node and you want to find the shortest path between them by by using a wait these sorts of things are good for running some of the other algorithms you can marry me the time I mean it depends on the size of your data I suppose as well you saw I was able to run weakly connected components very quickly on my laptop on this sort of data set so it depends on how much computing power you have but some algorithms are just like not well-suited to doing in real time but there are many that are and if you're looking at an isolated portion of the graph so maybe if you're trying to do fraud detection or prevention you want to look at the data around the data you're inserting it's your graph so maybe you're inserting a new transaction you want to look at the transactions around it or the people near it if you're looking at kind of an isolated part of the graph then you could use some of these tools as well and we're looking at the time I'm going to take one last question this is is it possible to implement your own algorithms within the neo4j environment another excellent question so yes it is I mean you always you always could you know 4j allows you to write custom procedures so anyone who's used any of the graph algorithms before or has used a POC you know it's a jar file that you write that uses neo4j api's and kind of sits it's a plugin in the database so you could do that but the graph data science library also comes with some tooling to allow you to implement new algorithms or kind of spoke versions of algorithms in a much easier way so yes it is absolutely possible to extend what's here to customize with here or indeed to implement you know you're your own algorithms pretty easily on top thanks again Joe thank you for presenting and thank you to our audience for joining us today so bye-bye from our side and have a great day thank you 