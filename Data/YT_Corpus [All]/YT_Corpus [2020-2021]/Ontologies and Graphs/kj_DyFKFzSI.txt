 I'm Dan mercury and I'll be presenting a little bit on canoe health care I should just give you a little background story on myself and how I got here I have been stunning the process of how organizations select databases for about 15 years I'm gonna really go into a little bit about the challenges we have in healthcare and why in the past we haven't picked graph databases for healthcare and I think I'm gonna then give you a little a picture of how graphs can help some of the problems and towards the end I'm gonna go into a little bit of how we've developed processes to explain why graph to healthcare executives and I think this is important because healthcare executives often are not the people who actually build these systems and the people who decide on which systems to build so it's not a question of whether we understand it it's whether we have the right metaphors to explain it to others and I think that really speaks to some of the other presentations we saw from Hillary this morning so just a quick background about Optim if you haven't heard of Optima we are the effectively the IT division of United Health Group our mission is to help people live healthier lives and to make the health system work better for everyone we United Health Group is about 200 billion in revenue in 2017 over a quarter million employees 42,000 IT employees over a billion year a billion dollars a year we spend in doing data analytics we have over 3,000 people that have a title of data scientist or similar and most of these people are using very very traditional COBOL mainframe relational and other systems and the reason is what we acquire a lot of healthcare companies that aren't on the bleeding edge and we purchased them because of their data getting access to data is the central thing in building good predictive models so my background is I'm now what's called a distinguished engineer and working in what's called the advanced technology collaborative the word collaborative is really important because our job is to get all these different organizations that acquired that have been acquired UnitedHealthcare requires twenty to thirty new companies every year and our job is to get them to all work together my background is the no sequel now space and I started a conference called no sequel now back in 2011 and my wife and I wrote a book called making sense of no sequel and ml and a lot of the people at yoshipro J have been very strong supporters of our process of helping people understand the database selection process so so our book is really about the ways that organizations choose to store data and there are about six basic high-level patterns relational on the upper left where you have to put everything into tabular structures and if it's in the third column it has to be a date format so it's a very rigid structure and you have to model that before you put it in the relational databases there's also analytical that star schema where you have all the facts in the middle very good for aggregate reporting but as they say aggregate aggregation is not knowledge and then there's the for what are called no sequel patterns key value stores column family graph and document and although we've studied a lot of them I think one of the most underutilized today in healthcare is graph and it's too bad because there's so many reasons that healthcare data fits beautifully and correctly into a graph structure so our job then as a education organization that builds collaborative is to work with solution architects the main character in our book is a woman named Sally solutions and her job is to given a business problem what's the right architecture which one of these six patterns is right here and we want her to do this without bias bias means just because you read a blog article on something last week doesn't mean you should just try that it means that we're looking for the fitness of the problem to the solution and we want to do that before we start to select products what I'm really seen in the past is that many organizations are dominated by one technology and that might be relational for example and they bring a single perspective to the solution space now what we're saying is to be competitive in the world with all this healthcare data that's changing so quickly we need a diverse set of perspectives and it's not just graph but it's graph in combination with other things key value stores search engines would call multimodal systems that are really making organizations in health care competitive so let's let's just talk a little bit about that process then at the top row here you see all of the different ways that we decide what are the requirements what are the quality attributes of a system and what we're saying now is that that bottom row that middle box that has the architectural approaches we want to now start to fill in with these different solutions and this is a process developed at Carnegie Mellon it's called architectural trade-off and modeling approach and it really goes through and helps us rank these do the analysis of the fitness and understand those the trade-offs and what we see is that certain things have critical requirements like a high availability or ability to manage complex rules those often fit very well into graph systems all right so let's just talk about the big problems in healthcare when we think about it today when we acquire all these companies we get many many different data silos and some of these companies do to influence things we might buy a company that does lab testing another one that does MRI scan another one that does ophthalmology exams and we look at all those the data from them and they're completely different right high variability data many diverse formats and it's not just CSV Zitz JSON XML all the different formats that are coming across fire fire and rdf all of those are different formats that we have to ingest healthcare also has a huge amount of complex terminology all the names of every drug every symptom all the disease is those all are appearing in patient charts and we can't just use an off-the-shelf graph that has wordnet loaded into it we have to have all our healthcare terms directly into that we also are trying to build more trust this is something that graphs aren't designed to do but if you study blockchain and blockchain technologies if you search for Google Google search for optimum blockchain you see we're doing a lot of work to make healthcare organizations exchange data in a better trusting way we also have huge privacy issues everybody knows about healthcare privacy and HIPAA how our systems that hold pH I personal health healthcare identify data have to be very very rigorously audited and and then the complex rules that are get executed on those we also wanted to start to do things like chat BOTS I wanted to be wonderful if we can just open a chat bot and ask hey I want to know if my flu shots are covered by my health plan and then we're also going to talk a little bit about machine learning and explain ability and then the scaling problems alright so the first thing is this integration challenge so today we have all these different systems often running in different companies built at different times with different technologies and we think of them as just silos and when people do analytics they're usually only doing analytics on one silo and when they merge data from multiple silos it's very difficult connecting what we'd like to do is move to an area where everything is in one now large healthcare knowledge graph where everything's connected where every person in one database is correctly Clint connected we call it entity resolution where we're integrating not just claims providers and remember providers includes not just physicians but every van driver that drops people off at a nursing home complex clinical systems electronic medical records all your prescriptions all your allergies to certain drugs your entire genome and your entire Fitbit chain or your glucose blood monitoring systems all of those things are contributing data to your healthcare individual patient record and our vision is that all of these things will eventually hit fit in one large connected graph and that's a it's a long term vision but that's the goal that we're trying to move towards and and a lot of this is not just do does it live in the graph but all the things around it so that we can take your clinical documents and hook them up in the graph and find those words correctly using natural language processing the other thing I want to just remind people of that when you think about data variability if you think of relational databases the classic thing that start in a relational day something like a general ledger right where every company has a general ledger but the structure of that general ledger is very consistent if you look on the other extreme side the far right clinical data has very very high availability so one of the questions I often ask organizations is can you tell me about the variability of your data what percentage of your records have exceptions sometimes even 1% of your records having certain things they have to add extra columns to those databases and those tables get very very wide and then very inefficient and sometimes we we look at these structures and we see that we can see some variability today and when we ask them what is variability going to be like in five years they can't tell us right very few people can predict future variability how many people could predict what the structure of IOT your Internet of Things devices will be five or 10 years from now it's not just going to be your Apple watch but it's going to be all these other biometrics every time you you go to bed your smart bed is going to tell you what time you wake up and how well you slept so there's a lot of data that we can't even predict of what it's gonna be like in five years on top of that we're trying to build chat BOTS so typically somebody might want to open a chat in their healthcare systems and we're expecting an Anubis my coverage and we need to have a chat bot that knows new baby is associated with maternity coverage alright and that really talks about taking words and alternate words and and labels and linking them together how do we do that we do that in a graph so we've built taxonomies for all of our benefit plans every time we see chats and questions come in we can have people that add those to those taxonomy x' and we use those taxonomy n--'s for two things one is every time a new benefit plan is published we can look at the words in that and we can associate it with the right parts of that taxonomy it's called the document classification problem and the second thing is we can start to look at the patterns in these graphs and see that as you go from baby that baby and is you can walk the tree and say that's closest ly related to the maternity care tree so these are the standard ways that we're starting to use graphs to help us with our search more chats that are answered more search their answers means fewer calls through our call centers costs companies typically $10 to pick up the phone and answer a question like this but we can't do that today easily because everybody's benefit plans may be different and what you what you what your deductibles are and how much you've paid and your co-pays might be different too so those are very dynamic databases that we have to look up so the question we're starting to ask is what's the value of connected data we had a group come up to us a while ago and said well we have these new genetic tests that we've never had before and they're getting cheaper and cheaper and we have these icd-9 codes diagnostic codes that are associated with our medical records what genetic tests should we be recommending so it is what are genes associated with these diagnostic codes and the challenge we have is that we have some connections but we don't have all of these and so what we're seeing is that what we want to do is we want to add other oncology's that help us map these things together and we find a lot of these ontology x' out in the open link connection so there's a system called the unified medical language system that has a database of icd-9 codes and they're connected to concepts we have genomics information those are connected to concepts by putting these all in a graph we can do the graft reversals and we can recommend what genetic tests are associated with the right icd-9 codes so what we're trying to do then is build this connected healthcare network graph and it has all these different objects that we see in the healthcare system and and this is just kind of notes that we had from a typical whiteboard session with one of our groups and they were very interested in providers and the referrals of those providers and things like that and then we'd often put this into some documents and we meet with another group and they say yep that's exactly what want but you know we're interested in our Net Promoter scores for providers our providers call in and they talk to an operator that operator has had certain training and we want to associate the training how that training affects the Net Promoter Score for our providers so now we have to add more and more bubbles to these charts and it just keeps growing and growing so we really need to add all of the information about our helpdesk all the training all those things need to be in a single graph and we've never had all of that information tied together simply because if you were going to do this in a relational model it would be much too complicated so our hope is that by putting things in a graph we can make connections that have never been made in the past so what are we moving towards we're moving towards trying to store individual healthcare records or in individual knowledge graphs and we want to then connect these things together now if you have a diagnosis that has an icd-9 code we're gonna maybe just store that code in an individual app but it's going to point to a very very large graph that has all of knowledge about healthcare so all of you MLS from public system every time there's new papers that are published that might add some more connections to that graph so we're anticipating that there's going to be a rich set of pointers between records and this Universal knowledge and queries need to be able to access both of those but we also need to be able to lock down an individual patient at a certain Hospital so that if you're doing a quarter on them you may not be able to see the others there are some cases though where you're you're doing high-level statistics across multiple patient pools and you're gonna need to be able to that so we really need very robust role-based access control over all of our patient records and still allow them to be linked in to this Universal knowledge all right so what we're really trying to do is promote the thinking about new ways of looking at data where in the past we've our employees kept thinking the model that we have in our relational database is fixed it's unchangeable we can add one new column Buttle what we have ten thousand reports and if we change this one to one to a one-to-many we're gonna change the sequel for all 10,000 reports so we could do that we can add one column to our database but it's gonna cost us a half a million dollars and now we're saying don't worry about that anybody should be able to add data we should be able to harvest data from our call logs and add those things together and we should be able to love leverage public datasets so one story we asked one of our call center people was saying you know we have a lot of people in Medicare and retirement and some of them don't drive I would love to be able to recommend a provider that's near a bus route and sure enough yes we can get access to public data about bus routes and yes we can rank every one of our providers based on how close they are to a bus route that changes the value that we add and we could do that because we could add bus route data in a way quickly in a matter of days which on a relational databases would have been a year long project in multiple millions of dollars so it's the agility of be able to add and and add new datasets at anytime and cross link them that's helped us to really provide better value faster all right so let's just talk a little bit about when you're in a clinic and you have this big knowledge graph and you run some machine learning on that knowledge graph and then it says well we recommend that you should do some diagnostic tests for diabetes here and the doctor will say well why did you recommend that why didn't you recommend something else and how do i how can I trust you what what's the probability of this score how can I correct that if you make a mistake and that's what we're in today when we were using the traditional deep learning models what we want to go to is a new architecture where instead of just having it a function what we want that machine learning process to update what we call learned explainable models and these models are graphs that are updated as we do more machine learning and that allows our physicians or our members to actually ask questions through an interface that looks much like bloom why did you recommend this explain it show me the traces of the weights of why this is important give me some metrics how do I give feedback into the system and then that's going to promote trust so in the healthcare system we cannot use deep learning algorithms that don't have a explanation but we think that using graph models is going to be a much better way to build explainable AI another thing to look at is our model-based machine learning if you study machine learning today you take a lot of variables and you flatten that you put it into your features typically store it in a in a tabular function and you have these things in your model that you have to then unwind and you have all these complicated different algorithms that you have to use to unwind that flattening what we're really trying to go towards is this idea of a single graph that encodes the assumptions that we make about that data and what we're finding is that by using that there's going to be a lot fewer algorithms that we need and those are going to be much easier to understand and so this is all called model-based machine learning where graphs are an intimate part of that learning process all right so to wrap up I want to just talk a laugh you things about some metaphors that we've been using to explain this to management and I just want to reach out and thank Dan Flavin for some of his great work helping us test these metaphors I think they're actually being used in some of the neo4j training classes now so there's three metaphors that we've been using to help understand how graphs are very different the neighborhood walk the knowledge triangle and the open world assumption so let's just go through this so start out with this one then a neighborhood walk let's say you lived next to a neighbor's house and you wanted to go over to your neighbors house how would you do this well you'd open the front door you would walk out the door and you'd point to your neighbors house and you'd walk there it's very simple it's very direct and it's really a metaphor of how we store relationships by storing permanent pointers in a graph database is adjacent anything in the real world that has relationships we store those as hardwired pointers in it's one hop away you don't need to consult anything else to get to your neighbors house how would we model that we'd model that as a graph dan lives next to an and so we see a very nice relationship in the physical world something we can draw on the whiteboard let's contrast that with the way that relationships are calculated in relational databases relational databases do not store permanent pointers in memory they actually when you do a join that where clause is actually a search that search has to go into a central system to do that search so the picture it wants you to paint is well you can't walk over to your neighbor's house directly you need to walk downtown to index town right and so what's index town well it's a huge beer pratik building and you're gonna go stand in line and you're gonna it's like the DMV takes a long long time when you finally get to the front of the line you say I want to get to one two three main street then they're gonna plug that into a computer and they're gonna do a binary search the more data there is the slower that search is your data gets bigger we have a log in search performance hard to predict that performance because you don't know how much data you're gonna have and then they finally find that record and they give you the GPS coordinates you plug those coordinates into your phone and then you can walk over to your neighbors house okay now that sounds like a silly story and it's designed to be silly it's designed to be silly because I want you to remember it and we've tested this two weeks later if you come up to somebody and say can you explain the difference between graph and relational if they can remember this story and they can remember the DMV they'll try to express it right and they may not get it the first time they have to go back and look at their notes but this is a story that works and we can do you can you can test this you can send out a survey two weeks after you this training and ask how many people can explain it all right do we do search when we do traversal in a graph you can they can if they remember this story they know it no we do drinks if if you think of one thing that makes a graph unique its understanding index free adjacency but nobody's gonna remember that term they will remember the story all right so try to use that story to explain it especially if you have managers that want to understand the story but they don't they don't have the the time and energy to repeat it and remember a complex technical term second story we use is called the open world scenario or open world assumption and we borrow this term from the world of semantics and descriptive logics you can go google open world assumption it means something slightly different but we're borrowing this term so in the relational world we have what's something called the closed world closed by the sense that everything is prohibited storing in the database unless you model it unless you create rural rules for it everything is prohibited until you create a permission rule you can only data add data that you model and adding that data may impact all your queries in the future all right that's bad the good world is the one on the right-hand side the open world the open world solution is that everything is permitted in the database unless we put in a specific rule that prohibits that data from being used and the thing that's different about relational and graphs that is so important is that when we create new vertices of a certain type we also put types on the relationships between them so our queries use those relationships they don't use wildcards sometimes they use wildcards and sometimes those are going to have the impacts of those things but that's a pretty small subset in general in the open world scenario everything is permitted unless I have a rule and what that means and because of the way that we model things if we write our queries correctly we can add new data without disrupting our existing reports and that makes all the difference the world that makes our graphs more modular are more open easier to build easier to test the open world is really what gives us agility so that's the second metaphor is that open world so the third one is the knowledge triangle and the knowledge triangle is pretty similar to what we've seen in some of the other ones where we have this low-level binary data at the bottom a lot of numeric codes from the system's relational databases like to use a lot of codes look-up tables the pick lists are all stored in in IDs for fast lookup on top of that we have concepts than nouns in our world on top of that we have knowledge pattern and relationships the graph level and on top of that we have wisdom and AI and wisdom and AI is can we structure the knowledge in a way that can be reused across projects so the way that our CIO looks at this is we have spent a huge amount of money building data lakes and a lot of come nice data Lakes was a was a very useful mechanism for taking data out of our transactional systems putting it in ones place that we can query it over and over and we're not going to disrupt our transactional systems constantly it was a way to take the burden off of our slower relational databases and store it in a cheap way but many organizations were sold a bill of goods about data lakes and HDFS as it's gonna it's going to be a database itself but when we put all those numeric codes we couldn't have tools to decode decode them now what we're saying is that we need a whole new generation of tools and AI and machine learning and complex rules engines where we're actually using graph technologies to extract data from our data Lakes to put them into this this disconnected nouns but also verify it and make it consistent and then from that also pull it together and find new relationships right so this is the entity resolution camp and there's some fantastic tools out there that are starting to get really really good at entity resolution where you can start to just look at this data and find it and make those connections and then that last step is the very top of the thing if you go and Google this concept of transfer learning we're gonna learn things in our in our AI models we're gonna capture them we're gonna put them in spot that they can be reused so we don't have to do all that training and then we're gonna on a base model maybe it's images models we're gonna add models for specific types of images and then add customizations for that so in healthcare we're gonna have a whole set of reference data here about healthcare terminology we are working very hard to make sure that we can represent all healthcare terminology and a uniform graph structure for all of our applications to use that and that's an ambitious goal but one of the things that is important because right now we have literally hundreds of people within organizations that we purchased that have already duplicated this data and it's our job to try to bring all those things together all right so what's at stake here if you have read the book The Book of Y by Judea pearl it's a fantastic story about causality and how by building these things called causal graphs we can make much deeper understanding of our data the story in the left is this apocryphal story called the smoking gene and it was promoted by a lot of tobacco companies and it said well there's probably some gene inside of you and it causes you to want to smoke and it's kind of a coincidence that you also get lung cancer but there's probably no direct relation between your urge to smoke and lung cancer that's just that's just happens because it's caused by the same root cause what we found out unfortunately almost 20 years later is that we can understand causality between smoking and tar in the lungs and causality beating tar and lung cancer but we didn't get our causal graphs correct and this is the same thing that we see over and over for every type of procedure that people are trying to get health care coverage room that may not be effective what's the benefits of vitamins what are the benefits of homeopathy and acupuncture and all those things our job as data scientists is to figure out which ones are the most cost effective which ones have good outcomes to take real-world evidence from our claims and understand the effectiveness of certain drugs in the context of the people taking them a lot of drug studies have been done only on 50-year old males but now we ask what's the population for younger females right so all of these things have different causality and and we have lots of data but we need to store them in graphs and understand that to make sense so data scientists really have to understand causality to to really do this so as an employee of optimum I'm not specifically allowed to endorse any specific companies but I do want to mention that we had a lot of summer in and we let them pick a lot of different projects a lot of them gravitate towards graphs a lot of them actually made great projects process on their graphs and you can see that they a lot of them got certification and and they were really happy and I think they're also leaving Optim to go back to school to go back to their colleges and universities and so many of them are also starting to look at graphs as a fundamental way to think and how to solve problems so what I really want to do is I want to throw this out as a challenge to every engineer out there that I think that graphs are going to be the foundation for helping us lower the cost of healthcare but it's not just graft alone we need people that know Graff has that foundation and then are going to layer other technologies on top of that we call these wicked problems in healthcare where we have lots and lots of dyskinetic data that we want to put together and build all these things that will lower the cost of health care and we've here seen very good presentations graph and natural language processing graph and machine learning graph and search and semantics graph and search traversal visualization all these wonderful vendors out there doing graph realization distributed systems high availability statistics from causality so it's not just graphs alone that are doing this it's really other technologies that work with this so I think that's what I wanted to cover today we have a few minutes for one or two questions and and if if people are interested I do have this deck I'll send it out to you I should have mentioned at the very end I do have a few slides on what I call our cognitive biases when we're picking databases and we go we go through these in some of our other presentations to help your executives so each of these has a little story behind them about how people thought they were being objective and we really challenge them they say is this really helping Matt and those things can all be described in helping your organization be more objective so in any questions yes go ahead right yes that's true they say that good good relational databases cache that information very often it doesn't happen yeah right exactly yep it forgets it good point yeah damn question true right yeah so if I have a general ledger system I want very very consistent reporting and I don't want people to disrupt that I think we could do a GL in a graph and we could limit the queries to the vertices that really mattered and we could add other information notes and things like that to it and still not disrupt those queries so but I think the point your point is really that different databases have different benefits consistency reporting acid transactions all those things and as you scale up you you kind of turn down the dial on having consistent reporting because it takes a while for a node cluster to get in sync so yeah everything is different and I you'd look at the requirements and figure it out and figure out what architecture to use a question back there yeah that's a good question up I shouldn't take take a page from Thompson writer Thompson Reuter has a product where they sell a knowledge graph and they sell a permanent ID system and they publish financial data in the terms of a graph you can ingest that India graph and then you can associate things using their IDs what we have with many healthcare standards we have fire fhir and there's an RDF version of fire but we're not at the stage where we can assign IDs it's actually illegal to assign some patients permit IDs in some states because of privacy laws right because they don't want people passing around IDs that can be identify data so we do have a lot of challenges there I think that what we have to do is understand how to balance the the precise exchange of healthcare data with respect for people's privacy and that sometimes those are in conflict but I'd love one of the best examples is provider data right we spend two billion dollars a year in the United States just updating provider credentials to make sure that our providers have the right licenses to do the right procedures and all of those things are done by hand in manual forms and there's no incentive for providers to make sure their phone numbers or fax numbers or whatever are up-to-date if we could do that once use blockchain and other technologies to verify that information we can make huge savings so there are plenty of opportunities outside the firewall to make healthcare data transmission much better and one of my passions is just getting everybody to use umls and sno-med and using a consistent uri for every concept right that would be a good good step in the right direction Mayo Clinic has got a lot of material and papers online about what they're trying to do to get all their people to use consistent identifiers you are eyes and and just because we're a property graph by the way doesn't mean that we can't steal concepts from RDF graphs right I love the fact that there's consistent IDs and RDF graphs let's use those in our property graph and and take all the good things and the inference patterns and bring them into our world so good question no one question over there absolutely totally agree yep yep especially when you have data of questionable veracity where you can't trust it maybe it should be in a special list where only certain scientists can see those relationships once again access control lists are very important and only when you go through certain quality standards would that be relevant in a patient's record right because we don't know where it came from or whether it was authenticated so yeah I agree with your points and I think that rules engines and access control lists and veracity queries on the graph could could be helpers for that yeah another question from the back there go ahead absolutely yes so patient journey is a really important use case where when a call comes in to a call center we'd like to know every event that happened to that person in the past that got them to that point in time including every email that was sent to them every ELB that they've that they called on questions they've had in the past questions that a provider might have asked about coverage for that patient and things like that elder buildings so all of those things are part of that patient journey and in the past our systems were so constrained we only loaded about 10% of that eligible data and so what we're trying to do is dramatically expand all the data points and tie it in together to see how we got to an endpoint from things and what that means is that we have this concept of next best action a patient journey if they called confused ten times about an EOB we need to know that and contextualize that when we're answering questions in the phone not everybody is flu in English and and has all the understanding of the healthcare system that we have and so that adding more data to the patient journey helps us conduct eyes especially in Medicare and retirement where we get maybe a hundred calls a year and we need to know that we have to change the way that we address those answers and caretakers right caretakers is another good thing our systems they don't understand the fact that you may have a caretaker that helps you take your medicines and things like that and if we get a call from a caretaker that has to be part of that patient journey - so I think the answer is yes we we've the the the hope is that we load far more data and integrate together in our call centers the challenges everything we've talked about scale and security all right we've got to overcome those it's a great question all right so with that I think we'll wrap it up thank you guys very much for coming and enjoy the rest of the conference [Applause] 