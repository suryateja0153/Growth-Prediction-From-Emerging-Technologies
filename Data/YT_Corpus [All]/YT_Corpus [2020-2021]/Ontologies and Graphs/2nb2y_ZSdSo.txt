 hello again my name is Craig Cavanaugh and I am going to be presenting building spatial search algorithms for neo4j and this is going to be based on a mixture of some old work that we've done as well as something we did very recently this year so to start with I have an agenda where I've tried to minimize the old stuff into just a two minute history we'll see if I can achieve that two minute deadline I'm then going to talk a bit about what's currently available in the standard neo4j that's shipping today and then move on to the spatial algorithms themselves so we've actually done some recent work in an internship where we built some new algorithms and I'd like to show you how we can demo those in a full stack application so quite a bit of the presentation I'm going to spend actually going through each of the algorithms and explaining to you how they work how we wrote them and how we use them let's start with the two minute history so you probably know if you've seen any of my previous presentations that I've been involved in near Vijay since 2009 and in 2010 I did a collaborative work I was a community member at the time not working for Nia Vijay I did a collaborative project with neo4j to build a GIS modeling library which we called neo4j spatial this is not something we recommend that you use these days because it was designed for the embedded deployment that neo4j focused on in those days and now on your JS being a server deployment for many many years you can access some others through the server but it's it's it's history shows somewhat it's also not a special database it's a special modeling library its strength is only in that because it wraps well-known libraries like jts and geo tools it is very very comprehensive but it is not very scalable and it has issues that you would really experience in a enterprise deployment where you have high concurrency high volume situations so only look at this if you are interested in the features and you're not going for a high concurrency high volume the one thing I wanted to highlight about it is that at the time in 2010 we also wrote an Open Street Map importer and a ingrowth Open Street Map model which is something that we still use today and is a main major part of the algorithm work that we've done this year so I'm going to talk about Open Street Map more later on so don't worry too much about the clutter of this diagram I show it because I have nostalgia for this picture I drew it in 2010 when we first built Open Street Map and it's a bit archaic but the model itself is still very similar the most interesting thing to take away from this is that Open Street Map is one single fully connected graph of the planet and that's fantastic there's almost nothing in GIS that's like that so I'll talk about it more later just remember that point the last thing to say about the old library is it's very extensive but only if you use it in embedded mode because it wraps all of these other capabilities the one thing that we did to support it in servers in 2016 was to add some procedures so that you will be able to access some reasonable subset of its capabilities within a server deployment and that's the last thing to say about the old library because I think I'm assuming 99% of you are going to work with the new stuff it's good to know the old ones there in case you need to use some of that so what is new Neeraj a 3.4 introduced to new data types this is the first time in a decade that neo4j had introduced a core data type that was new the one was the temporal types of which there were a whole bunch and there's lots of documentation on that elsewhere so you can look at that I'm not going to talk about that today and then there was the spatial types we only supported natively in the graph one type and that's a point a simple point but we did make it a little bit powerful in the sense that you can have both 2d and 3d points and they can both be in Geographic and Cartesian coordinate systems and I'll talk more about Geographic and Cartesian throughout this presentation because it's an important factor when it comes to the algorithm development but for 2d and 3d this presentation is going to be about two the only so ignore 3d for now another thing about the native type theory is that we developed a spatial index I have a slide or two on that but there's only one algorithm built into neo4j only one and it's distance I say only one they are actually two incarnations of the one for Cartesian one for Geographic slightly different calculation because Cartesian is just Pythagoras and everyone's written Pythagoras whereas Geographic is a little bit more complicated with trigonometry and I'll mention that again later so to describe in brief how the index works just so you know about it we targeted a particular use case which was to find points inside regions unfortunately what's built into neo4j today only supports the special case of the region being a circle requiring that you can find points within distance of a point of interest so I will describe that now and then we can show you how you can enhance this to actually support regions even if near-future doesn't do it natively so if you have a query like the one at the top where you've got some point of interest it could be and into the query as I've done they're all passively in as a parameter which is what we usually do in an application and let's say you have a graph that has businesses of certain category and they're certain locations as expressed by the match expression up there you can have quite complicated queries that actually have pretty codes both on the category and the location and cipher if there are indexes on both category and location it will pick the the the most appropriate index for highest performance and return the results and the way it does it with the spatial index is it identifies that that distance function if you look at the predicate thereafter and it says the distance between the location of the business and the point of interest is less than 10 kilometers that's what it says right there it can realize that it can interpret this as an index query and it does that by putting a rectangle a minimum bounding rectangle about that circle and it passes that into the index that will return all the tiles that have points in those in that part of the rectangle and then we do a post filter and in this particular example here there was nine candidates filtered down to five and you can imagine even though we do a second pass filter if you had nine million points the index returning nine is giving you massive performance advantage so this works very very well we benchmarked this by the way and it is performing very well comparable to other spatial databases the last thing to say about the built-in support is what I said before about 2d and 3d but it's the Cartesian in Geographic so some key points about Geographic is that the points are on an ellipsoid model of the earth and they're in decimal degrees angles latitude longitude and this also means that the distance function is going to work differently in Cartesian you have no units so whatever the units are of your points will be the units of your distance in Geographic we assume the points the locations are in degrees decimal degrees and we'll return just in metres so it's very very strict about what the unit's mean let's get on to an introduction to these special algorithms so one of the motivations I had forgiving this talk this year was that in the spring and summer this year we had a very interesting internship as a collaboration between neo4j and Eindhoven University and they had a student Stephane Delinda who came out to Melbourne sat with us for three months and did some work on spatial algorithms and the task that I set him was to develop a few sample complex algorithms so we didn't go for coverage we wanted to have a few complex algorithms that could be useful for benchmarking the performance of the algorithms in both Cartesian and Geographic systems and a very interesting element of the work was to have the algorithms run on alternative data models so you could have a data model that is a polygon in the graph or you could have a data model that's an array of points you could have various different data models and we wanted to see how these algorithms would perform when comparing those I'm not going to present the results of the of the benchmarking here you we can take that offline if you want but some of the conclusions were that some data models were clearly a lot faster than others and that's definitely makes a big difference to the data model that you plan to choose in how you're going to model your data if you intend to write complicated algorithms on it the another key element for the geographic side is that we wanted this to work on Open Street Map data because that is such a valuable data source so if you remember that really cluttered diagram I showed you a few slides before Steph has redrawn it symbolically here which is a lot easier to understand this is the typical tree structure of how you assemble complex geometries in OpenStreetMap the bottom row of that tree structure all the nodes and that word know is the node is in the effigy know that's an OpenStreetMap node the term means a point location then if you go two rows up two ways ways chain nodes together into a line segment so it's a chain of nodes which will represent maybe a piece of the street or a border of a building or maybe the piece of the outline of a of an area of a park of a province administrative region something like that it turns out though that there's an nobility in OpenStreetMap to arbitrarily collect things together in progressively more complicated structures and that's this relation concept at the top so relation can contain multiple ways multiple nodes ways and nodes are the relations and you can get very complicated data structure an example would be a polygon with holes that have polygons inside them then you need to have quite a complicated data structure for that so Steff modeled a few ways of doing this and the way that seemed to work best for us if you take this example on the Left that's a complex multi polygon let's say for example that might be a in a game reserve or a native area or some kind of park that's made of multiple disjoint areas and some of them have got lakes in them and some of those lakes have got Islands then you end up with something quite complicated we modelled it with a tree structure like you see on the right there where each simple polygon is a single node containing an array of points now neo4j natively supports both point and a razor points just like it supports integer an array of integer and arrays of any of the primitive types so that is very convenient it means that we can use the native near the j types in order to structure this so the complexity comes only in the tree structure and this is working very very well and the demo I'm going to show today is based on this data structure and as you can see you can have multiple simple polygons containing multiple holes which can contain multiple simple polygons which contain multiple holes etc it can be arbitrarily deep and this is possible in most GIS systems as well but it's very convenient in a graph because we have the violence concept the traversal of the graph to find these things and I'll show you examples of that later as well one important point though I mentioned before and that is that Geographic is a bit different what Steph found is that there is a whole class of maths for algebra for the spatial algebra that uses the N vector representation so a point on the surface of the planet is modeled by a vector normal to the surface then two points which make a great circle as you see on the right hand side there will be modeled by the vector normal to the great circle which is what we shown there and there's quite a lot of algebra that we've got inside our algorithms that are based on this concept and I'm going to show you a little bit of that but I try to avoid going into too much detail because it's a bit mathematical and it's worth reading steps paper if you want to know the details so I have got six algorithms to show you the first two actually we demoed last year at graph connect and in a few meetups after that by we I mean will Leon and myself we developed the first demo and he focused on the route finding and I focused on the point in polygons so I'm just going to go through that first before I show you a demo of the new stuff don't want to go into it in too much detail though so this is what we showed last year the simplest route finding you can do of course with cipher is to just use the built in cipher shortest path function this is not the best choice it tends to give you non-ideal paths in the real world and will show this scary face to show how upset he was about when he first found this bug or bug this limitation in using shortest-path instead what you want to do is when you are traversing a path you would like to have weighted relationships where the distance at least the distance you could use also the time it takes to traverse based on speed limit and other things like that but in in our demo we use distance and it gave a much much better approximation then shortest path so how do you do a shortest path including a weighted function cipher doesn't have that built in but neo4j actually in this embedded API has had that since 2007 or eight long long time ago and lucky for us the epic library of procedures has exposed that for us and that gives us access to these two algorithms that is the Dijkstra algorithm which considers weights and so it will always find the shortest path based on weights but it doesn't go very fast because it's searching in all directions it starts from one side and just searches in all directions until it finally finds the other node the a-star is a bit cleverer you give it two functions one for the weights and the other one for a preferred direction or what's an additional cost function which in our case implies a preferred direction tends to be much much faster and so we demoed this last year and we did it in Manhattan and you could find the shortest path between where you were in the coffee shop that you wanted to go to and it worked very very well and here's a small animated gif that we'll put together showing you some of these shortest path calculations just it was quite effective so the other thing we demoed last year the part that I focused on was the point in polygon and what I did in the demo was I wanted to limit the the potential candidate destinations to certain regions so I pre calculated in OpenStreetMap model the polygon of Manhattan and Brooklyn and Queens and very areas and I stored them as simple polygons so in last year's demo we could only support simple polygons steps new stuff by the way complex polygons - lot richer I am getting messages that my network is unstable send a message in the chat if you can't hear me I may have a look at the chat it's all good great then I will continue so the it's worth looking at last year's presentation if you want to know how we constructed all of those complex all the polygons and how we prepared everything I'm not going to go any of that any of the detail now I'm going to focus just on the pointing polygon function and I implemented it in a very simple way and I've exposed it with this function here I'm Manzi within polygon it was branded with my own brand a man Z back then and that's a library that's not defunct because ifs project is completely rewritten all of this in a much much better way and I'll show you that later what did my old library do this is the point in polygon algorithm that I implemented basically take a ray in any direction from the point of interest and count how many times it crosses a line segment representing part of the polygon if the number is odd you're within a polygon if it's even you're not and this works great it worked great for the demos but there are some limitations it has some issues with Geographic there's some possibilities where you might actually miss an intersection in some extreme cases because of the great circle curvatures also it goes mad if you go near the dateline or the poles so Steph's improved this a lot in the latest version one other thing I wanted to mention about this is that if I go back to this query I'm doing both a distance and a point in polygon and that's because the distance triggers the index and the width on poly within polygon does not so how do you trigger the index for a for polygons where near for J doesn't even know where they are it's possible to do it with another trick and that is if you have a second function called bounding box that takes the polygon and builds a rectangle around it you can then use the query if you look at the third last line there find the location that is greater than this bottom left corner and smaller than that top left top right corner if you say that if you write that to cypher it will figure out that you want to use an index and it will use an index so that's a good trick where you can actually trick the cipher into using index for a case where run you wouldn't think it's actually capable and this is something that's worth doing when you have large amounts of data so I am before moving on to the actual the next set of four algorithms that Steph implemented I'm going to switch to a live demo let's find that window let's see is the demo appearing yet it looks like it might have appeared right I think I can see it so this demo is the same application we used last year it has the the routing and all the rest I'm not going to demo that part that's down here in Mama I put the spin at the neo4j engineering office instead I want to show you the new stuff and the new stuff involves the fact that we've built these polygons according to the tree structure that I showed you that staff made where we can select on the left here I can select the polygon representing scorner that's the province that we have our office in and you'll notice that the OpenStreetMap view of that province actually includes part of the sea because it's a part of the administrative region you can of course perform intersection calculations not done that in advance to show you the intersection between in the province of scorner and the land area and that uses the intersection calculation we can also click on the map now there's a little demo are made to click here I clicked and I get the administrative region around Stockholm and this stur uses the point in polygon function the new version to give the polygon over there you can click pretty much anywhere and take them away for example you can also show areas so this is actually when I click that it actually goes to the database and says give me the area of the polygon and that actually involves a traversal of the the database finding those things calculating area and returning it to the client and as you can see that was very very fast as well which is very nice the next part of the demo is not so fast I am going to say debug distances down here and ask it to calculate the distances and that took a little while so I'm going to make it take even longer I'm going to click on another polygon and this is going to take quite some time so while it's busy doing that I'm going to explain why at sir slow the actual calculation between two points is very very very fast the problem is finding which two points of the polygon are closest together and at the moment we have an algorithm that is just brute force it's breaking up each of the polygons into little line segments and looking at all combinations so if you just compare scorner to Stockholm it's going to let's say scorners a thousand line segments and star comes another thousand it's going to look at a million possible combinations calculate all those distances and find the shortest before it's going to return something and if you have three polygons it's going to do that three times if you look at all the combinations it turns out that this one's even slower than that because of something surprising which you should see in another 10 20 seconds when the results come in and that is this particular one yeah there we go took its time you would expected one line between each of these provinces but look at this weird line in the middle here when I first saw that I thought I have a bug in my calculation it's not about it's a result of the way I queried the database and I'll show you the cipher query in the slides look down at this area there it turns out this polygon has a hole some reason the people living in this area wanted to be in the province adjacent to this area they didn't want to be in that province so this is a hole and actually belongs to the other province so when I searched for my simple polygons to calculate distance I actually searched for shells and holes and as a result I'm finding the distances between four simple polygons here the last thing I'm going to take that away the last thing to show is convex hull so that was very quick I hope the screen refreshed I'm going to take it away again put it back you'll see that it's very quick to calculate convex hulls this was actually calculated live I'm going to select a bunch of provinces and you'll see that convex hulls overlap if I take away the convex hull they the provinces don't so you might already have guessed what a convex hull is let's go back to the slides and I will explain in more detail let's find my slides there should be loading now I think great let's go there we go so now we're going to go through the four algorithms that I've just demonstrated the calculation of areas intersections distances and last but not least convex hulls so how do we calculate areas that top equation might look a little scary but it's not the important points to notice is that you divide the area by half I'll explain why in a second then you sum over this X Y X Y is basically the cross product of two vectors and we subtract a different set of XY z-- so to explain how that all works look at the diagram what you can do to do this shoelace formula is choose an arbitrary origin it doesn't matter where can be inside or outside the polygon in this case we have it outside now you take each line segment that builds up the polygon and a line segment is made of two points calculate the triangle of those two points back to the origin and the area of that triangle is the cross product of the vectors which gives you the area of a parallelogram you divide it by 2 you get the area of the triangle so the / - there is coming from the conversion of the area of the parallelogram to the triangle all of the green triangles are the ones on the left they are too large an area you need to subtract these other orange ones so we need to know when we're going round which side of the of the polygon we are it actually works out naturally from the cross product where you're going to get a positive or negative value anyway so you take all the green and you subtract all the orange and bang you have the area so the shoelace formula is actually very fast and and efficient but this doesn't really work in geographic coordinates properly it's some conceptual similarities but in Geographic one we do something that's somewhat more complicated that involves calculating great circles and there's another theorem called Gerard's theorem that produces the area as an equation from the great circles I will show you briefly the code for this but I'm not going to go into detail it's a little bit complicated it's better to read the paper so how do we query that well this top line in the match you might have seen before we find the relation that's the top of the relation and you for length Traverse down this tree structure that I'll show you on the right - all of the sub polygons that are within that relation and I do this for every single relation in my set of relation IDs so if I'm calculating the area for 20 polygons then that will have 20 region IDs over there and the most important thing is the very last line returned spatial Algor area this function is taking the simple polygon represented by that property of that node passing it into the function returning the area and as you saw in the demo super fast which is really nice while we're showing you one algorithm I'm Becky just gonna switch quickly to the code for that see if I could find that let's see when the when this appears how do you actually write code that can be accessed from cipher like that we've got other presentations on this I'm going to be very brief about it but here is a simple set of three user functions we use this annotation if you're not a developer ignore the next half a minute of my talk otherwise maybe this is interesting to you this is the name that we refer to it in cipher and then we pass it in the simple polygon as a list of native near vajay points we're going to convert it into the data structure that we've used in our library there's a simple polygon this get calculator just says give me a calculator for Cartesian or Geographic it has a look at the data and then deduces that for you so we can now go to the implementation of the actual function it's abstract because we have two different versions Cartesian and Geographic so let's go to Geographic is more complex but it's not that bad it takes only one page to do a Gerrard's theorem it's as we said before you've got to traverse to find all of the traverse the data to find all the great circles and then you do this angular calculation that was in the equation that's used by Gerrard's theorem and it works really really well the other functions we have spatial distance and we have spatial distance ends the difference between these two is only that in the spatial distance ends I'm actually going to return the distance as well as two points representing where which two points were closest between the two polygons so that I can show it in the demo so this function I wrote just for the purpose of that demo I'm not going to go into the actual code for that I don't want to spend much time on code I'd like to go back to the presentation let's see that should take a second to come back see how we offer time all right it looks like we've got ten minutes I better be quick let's not bend too much time on these other ones so that we have time for questions as well intersection it's a little bit complicated so I try be brief you we've got this concept of a monotone chain sweep line you can Google for that if you want more or read Steve's report but basically you break all the geometries down into pieces of line segments that don't ever overlap don't fall back on themselves on the x-axis so you end up with this and then you sweep across it and you can as you sweep by reordering the points you can detect intersections and that's what happened in B over here and every intersection is just added to a stack and you continue the sweep and at the end if you have no intersections they don't intersect if you have intersections you can actually produce an intersection geometry in geographic coordinate systems we needed to consider the fact that any two points don't define only one possible line they define a great circle so we could mean the other side which side do we mean we've had to have some rules for deciding how that works we don't I mean if you look at the intersections here the red is defined by two red points the blue by two blue but the which do we want we don't want the black intersection or the gray intersection we want the black one in this case and we need a rules for defining that another consideration for Geographic is if the polygon touches or overlaps a pool things go haywire so we have to have some detection code for that and turns out that if you simply Traverse around the polygon calculating the bearings and summing them all up you will end up with 360 degrees if you don't touch or overlap a pole you will end up with plus or minus 360 degrees depending on whether the polygon is anti-clockwise or clockwise which is very important many GIS systems will use the direction to define whether it's a a shell or a hole so it's quite important to know that it also affects our area calculation under the green or the orange that we talked about before so this is a very important thing we in our current maths here we're not actually calculating areas and intersections if they do intersect the poles we just throwing an error because you have to change to a totally different algorithm and we assume that that's an edge case if you want to add to the library and code for the poles you're welcome to do it the next one is distance and the reason either distance after intersection is only that the first thing the distance calculation must do is work out if they intersect and return zero so we have to code intersection first so distance it did the stuff I told you about that doubly nested loop to considerable combinations and then find it gets down to deep down what is the distance between two points and so what I'm showing here is the version of that for geographic coordinates which is a cross-product again and the arc tank converting it back into distance on the arc so it's a pretty straightforward equation and it's very very efficient and very very quick that part's quick as you noticed that W nested new loop was not quick how do we query this I'm trying to show you cypher examples for everyone and this is unfortunately the most complex cipher the part you probably care about the most is the very last line very simple special algo distance ends if you want those points pass into simple polygons all the rest of that cipher is just finding all the polygons for those provinces making sure that we get the polygons as these things and then we can pass it into the equation there but that's pretty standard cipher what you might notice is that I've got this concept of Paris so I am passing in to the query all combinations of provinces up front and I'm doing that in the application and defined by just an integer ID so we can do a quick search so the first part of this query is very fast the only part that's expensive is that finding closest points so I'd love to find a way to optimize that the last thing to show before we have hopefully a few minutes for questions is the convex hull you might have deduced what convex hull means by looking at this if you haven't I'm going to explain it it's not too bad if you compare those two the first thing you can see is that the right-hand side looks much simpler but the word convex means it doesn't have any dents in it it only has rounded surfaces a dent is called concave so the polygons on the left have got lots of little dents they've got convex and concave shapes to them convex hull is like taking an elastic band around that shape and the elastic is not gonna dent in it also simplifies the polygon dramatically the way we calculate this is the first thing you can say is that convex hull doesn't require polygons it can work with any kinds of geometries you can have a complicated line segment a highway or something any of your convex hull around it'll it'll be the elastic band around all the points of that line segment so the first thing you do is just turn it into a bag of points and then what we do is pick an origin normally by convention you pick the southernmost and if there's multiple ones of the same south latitude you're going to take the westernmost of those the most negative or smallest x-value and you make that the origin sort all other points in anti-clockwise order by angle and then you just start sweeping through it and this version is the Cartesian version I'll show you the Geographic version in a second it's only slightly different when comparing any three consecutive points in this case a B and C we calculate the angle from A to B versus B to C well the angle at B if it's less than 180 degrees B is a concave piece and we throw it away so all this algorithm does is throw away step by step all points that create anything concave so it's reducing the total number of points dramatically and it will then go AC to the next one and do the angle there so it's going to sweep all the way around and throw away all the concave points so why does this not work in geographic coordinates it's to do with that angle and the lines because the calculation of the angle on honest curved surfaces is a problem what we really want to know is if you imagine a straight line between a and C is B to the left or the right of that line and another way of asking that question is the vector from origin to B does it intersect does that line segment origin to B intersect the line segment AC an intersection we've already solved for Geographic so that's what we do over here here is the calculation and you notice that if you look at that red line the constant the line of constant latitude is a gray curve below the red line so we we have to be aware of geographic coordinates otherwise I'm going to get it wrong the actual line we care about is the great circle which is the red line so we need to work out an intersection of the great circles that's the important part and we've got that solved in other places and that gives us the convex hull in geographic coordinates and this is how we query it those two pictures were created with identical queries except that very last line you see instead of just returning the polygon we return the convex hull of the polygon super fast it's doing the calculation every time I click that button it was very very quick very very nice so this brings us to the end it's almost the end we've got some Hunger Games questions for you if you're interested I will leave this up on the screen I have some references as well we you can get that from the presentation later we don't need to look at them now instead I'll leave Hunger Games questions on the screen and see we have a few minutes for questions and answers so there is a Q&A section over here I can see some questions let's see okay the first question I'm wondering if it was possible to draw for example 15 minute drive time area in neo4j okay one of the algorithms that Steph actually implemented a thing called linear referencing and linear referencing is to take a geometry which is that could be a polygon or a long line segment and say give me the point that is X meters along this geometry if you've defined how to calculate meters and so that's what we've done I didn't include it in the demo but it's definitely will answer your question you've asked for time so the calculation we did was based on distance but it wouldn't be a big issue to to change the way you do that but you need to then of course model speed limit or something you know because the GIS data will include actual distance and if you put speed limits on that and model your speed then you can also do the same equation in time so yes it's possible then we see max de marzi asks if you have drive time as weights in the relationships you could do this by first getting a circle of points at the max speed let's say and then for each point calculate the shortest weighted path back to the origin within 15 minutes is that a circle of points as the crow flies because I think that if you talk about routing across a graph it's never going to end up being a circle right unless you hear your you mean use the circle in order to trim the result set down into the minimum possible search results here that sounds like a good one because then you'll get it in deck that sounds like a good idea Ivan asked where can i download a copy of the slides I believe all of these presentations are going to be shared with all attendees later I know that I've made the presentation links available to the organizers so I think they will provide that to you afterwards Maryse asks how many points or polygons will still be scalable example find Tesla superchargers in the entire Europe or Amsterdam to Cape Town routes well first of all there's no superchargers in all of Africa I'm sad to say which surprised me but yeah in principle this should scale very very well I mean neo4j can handle many many billions of nodes but as you've seen that every algorithm depending on the algorithm can have performance issues the distance algorithm we had there with only a million combinations was showing problems I'm sure it's possible to improve the performance of that but it's it's always a cost benefit ratio one thing I can say what we did discover I mentioned this in the beginning when we modeled polygons as raw OpenStreetMap graphs versus arrays of points cached in a different graph structure that we got a massive performance improvement so that kind of thinking can be taken further every time you have a performance problem what you want to do is find out where is the cost and the cost can be both in the way you iterating too many times or it could be in the data model in this case it was obviously improved by data model so you can improve your data model in a way that will improve your performance or you can improve the algorithm I think that I would be surprised if there's anything that can't be solved here in terms of scalability and Tesla superchargers there's only 50,000 of them we're not gonna have a problem that's that's very small number it should be very very quick okay that's all of the questions that I have over here I'm sure that you people will be leaving to go to the next session I'll stay on I'll stay on line a bit longer if anyone else wants to ask anything but you're welcome to attend the Nexus next session 