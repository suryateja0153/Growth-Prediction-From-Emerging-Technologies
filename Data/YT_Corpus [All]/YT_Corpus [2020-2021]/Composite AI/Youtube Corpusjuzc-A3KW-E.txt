 (relaxing music) - Hello and welcome to Kafka Summit 2020. My name is Levi Bailey. I work with Humana as an associate vice president of cloud architecture. I'm happy to come and talk to you today about how Humana is using event streaming to deliver interoperability at the point of care. Before I get started, I wanna talk a little bit about my history. I've worked in technology for 20 years, and I've worked with a lot of successful teams. I'm also worked with some teams that were not as successful. One common denominator that I found between teams that were very, very successful was that they fundamentally understood the business problem, all the way from the developers, junior developers, through leadership. So before we get started, I wanna talk a little bit about the problem that we're trying to solve. And then we'll start talking about some of the technology that we're using to solve that problem. Let's talk a little bit about interoperability. Interoperability in healthcare is defined as where we communicate across the different participants in the healthcare ecosystem. The U.S. healthcare system is made up of three groups: consumers, providers and health plans. Interoperability is the ability to communicate data between these three separate entities in a standard, seamless way to enable a better healthcare outcome. There are three organizations that participate in the healthcare landscape in the U.S. healthcare system: consumer-based applications, providers and payers. Each of these systems focus on different aspects to administrate healthcare. In the past, they really focused on their specific task. But what we found is that each of them overlap, and we have a need to exchange data to be able to create a better experience across each of those different solutions. The reality is interoperability is about data exchange. Now, we've been exchanging data for a very long time, but it's really been point-to-point solutions. When we think of a better healthcare ecosystem, we really need to think about the opportunity to exchange data in a seamless way where all participants in the ecosystem can freely exchange that data and integrate to that data to help drive the outcomes and the experience within their organizations. The way we do this is by adopting to an interoperability standard. Interoperability, at its foundation, isn't just about how we communicate, but it's also about what we communicate. The standard around interoperability for healthcare is FHIR. FHIR stands for fast healthcare interoperability resources. It's based upon a concept of a standard way to communicate, being API driven, and then a standard way to communicate a specific subject based upon the FHIR resources. Humana's central strategy is around integrating and being a leader in interoperability. Why is that important? When you look at the diagram displayed, you see that we're already near the lead. We're right behind Kaiser Permanente. When you think of Kaiser, you really actually don't often think of them as an insurance company, you think of them as a provider, and that's because they're a closed network. Now, Humana's strategy, when we think about improving healthcare and we consider the ways by which we can create better outcomes, is to transition ourselves from an insurance company with elements of health to a health company with elements of insurance, which would be much more akin to the experience you would get with something like Kaiser. But we're gonna do it on a grander scale. So by adopting interoperability and continuing to lead in that market and invest to get to a leading status in the market, we have the opportunity to really make an impact to the overall experience and outcomes within healthcare. In order to achieve a leading status, we have to be fully event-driven. Let's talk a little bit about some of the technologies or the approach that we're using to develop an interoperability system that will be able to lead in the healthcare market. So Humana has invested in a platform approach to delivering an interoperability solution. We feel this best positions us to continue to evolve and guide ourselves towards that leading status. There are a couple design principles that we put into place when designing and building out this platform. I really wanna highlight a few aspects of that to describe how do we transition from an insurance company with elements of health to truly a health company with elements of insurance. Humana has invested in migrating towards a value-based care system. That means instead of paying people for services, we're trying to deliver payment and adjudicate insurance based upon the outcomes. In order to do that, we have to think of it more from the patient perspective, the consumer perspective. So one of the core design principles to an interoperability system or an interoperability platform is for it to be consumer-centric, health plan agnostic and payer agnostic. That's very important. Second, it has to be built on standards. If we're not basically adopting the industry standards, we will not be able to create an ecosystem where we can freely onboard additional payers and providers and consumers to create a better overall outcome across the lifespan of someone's healthcare journey. It also has to be cloud resilient and cloud scalable because if we're gonna be a participant in an ecosystem that continues to grow as more and more participants begin consuming the services and the capabilities that we deliver, we can't do that in a data center mentality. We have to adopt the power and the scalability that comes with a cloud environment. It's gotta be event-driven. If we're trying to impact the point of care, if we're trying to allow for the healthcare journey to be interrupted when it is important or when it will drive to a better outcome, we can't have latency in the system. We have to be able to notify and make data available when it's important, not after the fact. Not waiting for you to ask us for something, but telling you when something has changed or when something is relevant to what you are doing. It's gotta use analytics. It's gotta be predictive. It's gotta understand, you know, it has all this data. If it's just exchanging data, it's not creating additional value. We have to be able to interrupt the healthcare journey to create better outcomes. We have to be able to look at the data that's coming in and determine when that creates a new event or describes a new insight that can be made available to improve that outcome. And it really has to be built in a product-centric mindset. It's gotta use microservices. We can't wait to have the complete solution there. We have to build in an iterative fashion. We've got to add new value over time. This is the only way that we're going to be able to impact and deliver value and continue to invest in to get to the point that we are of a leading status. We have four components that comprise the interoperability platform. We have an API management layer, we have an event management layer, we have a knowledge graph and we have an optimized data layer. Each of these components allow us to create an ecosystem by which we can lead in the interoperability space. At this basis, again, interoperability is based on the FHIR standard. It's an API protocol. So foundationally, we have to enable APIs. But if we're gonna lead in this space, we have to use event management because, again, it's about having the right data at the right time. So by having an event management framework, we can publish additional things, including data insights and events. Now, in addition to that, we have the knowledge graph. The knowledge graph becomes important because we're exchanging all this data from different participants in the ecosystem. It's important that we derive additional insights that will help improve the healthcare journey. And so the knowledge graph allows us to make those connections. And last, but not least, we have to have an optimized data layer. If we don't have that, we won't be able to meet the demands of having data available for use at the point of care when needed. We cannot put the constraints on the source systems to be able to create the resources that are the standard of the interaction. We want to be able to do that within the platform and have them readily available for consumption. Let's dive into how you create those different components. We are primarily a insurance company. We're not a technology company. We have technologists enabling our products and our services, but fundamentally, we're not a technology company, and we don't want to build technology. We wanna orchestrate technology. We wanna take the best-in-breed technologies, bring them together to solve a problem. In this case, we have worked with different partners and different solutions to bring them together to create the platform that we just talked about. The current iteration uses a couple of different technologies that I'd like to highlight. One is it has an API management layer and it uses API Connect to allow us to manage and administrate the APIs that are produced and deployed through the platform. It has demands for compute. It has to be able to serve the API request, as well as process the data that's coming in via event streams and data pipelines to optimize and create the resources that we're going to be exchanging with the participants in the ecosystem. For this, currently, we're using GCP services. Those include things like App Engine and Compute and GKE, or Kubernetes services. In addition to that, we use stream sets for data pipelining and to basically maintain operational pipelines that serve the data to the optimized data stores from the system of record. And then, the engine really running that exchange of data is Kafka. This gives us the ability to publish data from systems of record and consume it as those events occur, the changes of data, whether they're inserts, updates, deletes, and take them to create, bring in multiple topics across data sets and systems of record to create the different resources represented in the interoperability landscape. And then we use an underlying optimized data store to cache and store those resources so that we can serve them up quickly to the consumers of the ecosystem. As you see, you kinda end up with those multiple participants. You have the operating platforms that are generating data, and then you have the consuming platforms that are consuming that data. Now, the exciting thing about this is it's not one directional. It's actually bidirectional. We allow for data exchange to go both ways. Let's dive in a little bit about how you orchestrate these technologies within the platform by looking at a solution blueprint. This is an example, and actually it is documented in the next section where we'll talk about one of the successes. In this case, it's about medication data. We have systems of record at Humana that basically manage the medication data for our members. It keeps track of what medications the member is currently on, along with what allergies they may have. And then we also have other systems that maintain the immunizations of that member, in addition to other pharmacy-related data. So what we've done is, again, those systems of record are doing it from their perspective. It's the operating platforms, their basis of the view of the world. And we want to take that data and create a combined resource that represents one of those FHIR resources for the participants of the ecosystem to be able to take advantage of and use it at the point of care to influence the care of the member or of the patient. So what happens is these systems of record publish their data to a set of topics. Again, these are events that get published as data changes and as we're made aware of new medications that are added, which they can get from claims information that comes in, or whether there's a new allergy that's documented in an EMR or within a medical record. And then, as well as immunizations and other relevant pharmacy-related data. This data flows through a set of topics. Now, at the end, we have a consumer within the platform that is taking that data, reading those topics, and then creating that combined FHIR resource. And it's storing it in an optimized data store so that it can serve up based upon the demands of the consumers of the platform. That API is then exposed through an API management layer. And then the participants of the healthcare ecosystem can subscribe to and consume that API. Now, as you see on this blueprint, we also are already showing the capability for us to publish an additional topic, representing that FHIR resource, that they could subscribe to. So it's no longer an API integration, where they're making a call out to us and saying, "What do you know?" It is us letting them know when something changes. Now, that is how we evolve. So when we look at where we're currently at, we're still kind of in our infancy stages of that interoperability journey, or we're kinda in the middle, but it's really based upon those APIs and consuming those APIs and that response request integration. But the next step on the external, or on the consuming side, of the platform is to not only provide the API integration pattern, but also to allow them to subscribe to the composite event or the composite record around medications or whatever that FHIR resource may be. All right, let's talk about some of the successes that we've recognized over the course of the last year 1/2 since we began this journey. Some of them are very exciting, and we've seen direct impact to outcomes into our members' experience by enabling this journey. So I have two really good examples. And again, I'm calling out some partners here where we did the integration, but the reality is these are reusable, you know, components, they're reusable resources. We are actually gonna be onboarding some additional partners to these exact same resources. They're gonna start leveraging them. And we've already began that journey and in the process of getting things established and them adopting to start consuming this industry standard. The first one is really an exciting one because it was recognized for a CIO 100 Award. We, from my knowledge, it was the first type of integration of this nature within the healthcare ecosystem. So again, it was kind of groundbreaking and it's directly impacted our member outcomes and member experiences over the course of the end of last year, and then it is accelerating and having a greater impact this year. And that would be our integration with Signify Health. This is really represented on the previous slide where we kinda talked through the solution blueprint of how we're leveraging the different components and technologies within the platform to deliver a set of APIs or capabilities that are going to start shaping the ecosystem and allow the ecosystem to begin functioning and building out improved outcomes. With this one, what we're really targeting is being able to adjust the experience of a member when doing a health assessment and evaluation within our member base. We primarily work in Medicare, so that's our primary market. And in Medicare, there are some processes that you follow to basically make sure that the health journey for a Medicare member is being managed the right way. And one of those is really the health assessment process. So we send in our partners, like basically, there's a clinical partner that goes into the member's home and does a health assessment of the member. Now, you may or may not know this, but it's fairly obvious. If you have a chronic condition and you're not taking medication that's prescribed to you, you're not gonna have a good outcome. There's a direct correlation to medication adherence and good medical outcomes for individuals whenever they're dealing with a chronic condition. There is a section of the health assessment that can be relatively painful in the past. And that really, that was the medication assessment because they have to, and many times they're going into a home with an elderly patient and there may or may not be a caregiver there. And you're kind of, oftentimes, they're either sick or have some sort of condition. And, you know, they may or may not have knowledge of exactly what they're taking, dosage information and all of that. And they feel like they've been, they've talked to their provider, their primary care physician, and this information should be known. And the reality is the clinician that comes into the home has to start the conversation with, "What are you taking?" Well, that can be a long, drawn out experience because they may or may not know that information. And the quality of information they have may not be sufficient for what they're trying to drive for in the assessment. So then, the provider has to go through and try to find the pill bottles or whatever else and document it. And depending upon how many chronic conditions they have, they may be on quite a few medications. By enabling the medication profile resource via the interoperability platform, we were able to share with them the information that we have, which we, as the payer, actually may, most of the time, if not all of the time, have better information than the provider that's going into the home because we have the claims from filling medication. We also have the medical records from what was shared from their primary care physician or other places that we can bring in, mine the data, put together this medication profile and have that available so that we can share with them, here's the medications that they filled. Here's what they've been prescribed. Here is the dosage information, so on and so forth. Now, the conversation really changes. They can just validate with the member, what are you taking? And they can also provide back to us any updates to that because this is bidirectional, as we mentioned. And we can then reconcile that information, update our records if we feel and deem that we collected some additional information that's relevant. And now that we have that up-to-date information so that we can do some additional benefits for our members, such as looking for drug-to-drug interactions or other things. Or even finding them cost benefit by saying, you know, "Well, "they've been prescribed this and they're taking this, "but the reality is there's a cheaper option, "and should we notify them?" So there's a lot of secondary benefits that can be generated by having this exchange of data. So again, that's a really exciting one because it's directly impacting the member experience. It's actually not only the member experience, but the provider experience. It's making their job easier and they're getting a better overall outcome of what they've been tasked to do. In addition to that, it's bidirectional, so we're getting data back, so it benefits us. So around the entire ecosystem, we're seeing a benefit by creating this integration. The second one is a little bit more interesting as far as what's represented here. This one is more innovative. So we talk about the FHIR standard being kind of that standard interoperability definition that allows us to create this ecosystem we're talking about. The reality is, though, it's still evolving. It's using some basic concepts, and they've developed and spent a lotta time developing the set of resources that seem to be the most relevant and shareable across all of the ecosystem and all the participants. But what we find is, as we start looking at opportunities, we see things where maybe the FHIR spec, in its current iteration, does not have a direct support for. What we're able to do with Sound Physicians is we were able to take the FHIR standard and add to it or innovate an additional capability there around a situation where we have a physician group that does not directly have knowledge that the person they're working with is a Humana member. So we get into data exchange constraints about PII and PHI. The member doesn't want their information shared with Humana if they're not a Humana member. And we do not wanna share information back with the provider of one of our members, or basically receive information about somebody that's not one of our members because that would be a data breach constraint. So what we did is we were able to use, again, event streaming to publish seven points of light and create a hash out of that, a standard hash, that we were able to cache in an optimized data store. This allows Sound Physicians to call our API, this FHIR API, and pass in a hash value in from the seven points of light within the request. And then we send them back a member task profile that tells them the next thing to do if we match that hash and we've determined that it is our member that they're working with. So again, this was a way in which we are able to adapt and evolve the interoperability standard to address some limitations with the current set of resources that were available. And last, but not least, I'd like to talk a little bit about an internal success because we've talked about the overall provider integrations of the ecosystem, but this really is focused on the payer side, which, again, we're a participant in that as one of the payers that would take place in the interoperability platform. And we have invested in Humana internally, again. The entire point to doing an interoperability platform or basically any of the strategic objectives we have, changing the way, you know, integrated care delivery, is all about creating better outcomes and driving towards this, a consumer focus. Moving away from just an operations mindset for what we have to do, but how does the consumers of our systems and our services, how are they represented and how do we kinda work with them? And one of those paths that we went down to enable that was around adopting AI and machine learning to create and define a better experience for our providers. So providers, typically, when they have to do a EOB, that's explanation of benefits, or check on referrals or some of these other things, call an IVR system. In the past, that was a menu-driven system and it was a little bit hard to navigate. And they're normally not doing this just for one patient or one member. They're doing it for a group of people. So it can be kind of a long, arduous process, but it allows them to do it without going out of their workflow. Because, again, they have a system they're using and there's no way for them to directly integrate with us. So they basically use the phone to do that. What we wanted to do was improve that experience. Basically, allow for a better integration and a better conversation so that they could get to their answers quicker, get through that process quicker, save themselves time and, by proxy, money. And so we built this AI system that allows us to answer those questions for them. But if anyone knows anything about developing AI systems, you know that the feedback loop becomes very important. You need to know how that conversation's going so that you can make adjustments to the AI system so that it can learn and that it can become better at answering those questions and reduce friction and produce better outcomes. So early on, they did this with the standard technologies that we used in the past, logging technologies, things like Splunk and other solutions. What they found was that that had some limitations. There were delays in the process. It required a lotta manual intervention. And frankly speaking, it was, from an operational perspective, from the business's perspective, it was not a good experience and it caused a lotta errors in the process. Then, once the interoperability platform was available and they could start publishing data to the ecosystem, they started publishing these events, these conversational events, and then using that to drive the, allow the analyst to have access to that data quicker and be able to get better results from the way that they review and maintain that data to make those decisions on how they're going to augment the AI platform to create a better experience. And they've went to production in the last six months, and they've noticed a humongous change in the way that they're able to respond and react to all these events. One other aspect of going to a platform-based system is really the ability to react quickly. Because we're building these reusable components and using this technology to orchestrate a unified experience with how we drive towards interoperability, we were able to react very quickly to the COVID-19 crisis. We had an opportunity to take data from a couple of different integration points, that would be like our CRM systems or our call centers, as well as different agencies and state agencies and other organizations to bring that data in and generate insights out of it. So within a matter of days, we were able to create integrations via this reusable platform to start integrating and make data available in near real time for those analytic platforms and reporting platforms to be able to generate insights and value off of that data to help influence the trajectory of how we respond to COVID. So it's a very exciting opportunity, and it really cemented in our minds the value of taking a platform-based approach to deploying these types of capabilities. With that, I would like to close with three things that you really need to take from this. And if there was anything else, this is what I want you to remember. Fundamentally speaking, these points are not specific to what we did as much as they are the approach to solving a problem. First and foremost, know your problem. (Levi laughs) You can't solve and build a good solution if you don't fundamentally understand what your outcome needs to be. You've gotta know the business problem. If you don't know that, all the way from your junior-level developers to your business and to your leadership, you will not end up with a good solution. You are going to just be using technology, but you're not gonna be meeting the goals of what you're setting out to achieve. And then, two, event-driven solutions are really the only way that you can truly impact customer experience. Fundamentally speaking, anytime that you're waiting for a system of record or an interface, some sort of customer-facing entity to offer an experience, they're gonna be limited based upon what they know. And the reality is if you want to truly change that experience and improve it and drive towards something that will impact them directly, that system needs to be made aware of the changes that are going on around them. Those events become very important to driving experience. So fundamentally speaking, if you wanna change experience, you have to adopt to an event-driven architecture. And then last, but not least, what we've learned is that by taking a platform approach and by building these capabilities in a systematic, reusable fashion, it really allows for a lot of adaptability. The reality is markets change all the time. Your business changes all the time. Situations, events occur, like COVID, where by taking a platform approach and building in a standard architecture that will support adaptability, you can really quickly adjust to what the current situation is. So fundamentally speaking, thinking in a platform and in a capability-driven approach will allow you to react quickly to change in your business. Thank you, again, for listening to this presentation and taking some time outta your day to consider our story. I hope it was of value to you, and I really enjoyed sharing it with you. Thank you. (relaxing music) 