 Hi everyone, Grant for the Flame Learning Channel. With the release of Flame 2021… The machine learning models have been enhanced yet again… To give you more choice and flexibility… When working on your productions. So previously, the machine learning models… were able to recognise and isolate the human body and human head… for various finishing tasks. With this new release… You can now segment various parts of the human face… For any compositing, grading and beauty work. So you can isolate the skin, eyes, the mouth, nose, ears and much more. This is all achieved using the familiar Semantic Keyer workflow… And the Human Face Segmentation is available in the timeline… As well as Batch and BatchFX. We’ll run through some examples to cover the features. But as a usual reminder with Machine Learning… This is not a perfect solution. Similar to all the previous videos… The Machine Learning Models are only as good as their training… And depending on certain conditions… They may or may not be successful. As long as you try these tools on multiple shots… You’ll eventually understand… Which situations may be successful. With all that said… If you would like to follow along… Please download the media via the YouTube description… Or use the link that is currently displayed. So let’s start off with this shot in a sequence… And you’ll go through the various steps… To isolate the parts of the person’s face… And then apply SelectiveFX to make some adjustments. With the shot selected… Switch to the Effects Environment… And choose the 1st Selective in the viewport. To access the Semantic Keyer… Change the keyer type from Diamond to Semantic. Under the Analysis Column… You can choose between Human Body, Human Head, Human Face and Sky Extraction. To enable the Human Face Analysis… Just click Active. Flame begins to analyse the frames… And starts to identify parts of the human face. The timings of the calculations will vary… Depending on the platform… as well as your hardware configuration. Once the analysis is complete… You can hover over the viewport… And switch to the current Selective Matte view. So this matte has been generated using the Machine Learning… And since the Human Face Analysis is set to Skin… The matte isolates all the skin around the face… With the exception of the eyes, eyebrows and the mouth. To see a more contextual representation of the analysis… You can switch to the current Selective Input view… using the same keyboard shortcut… To see the isolation as a coloured overlay. Now you can adjust threshold of the key to be more or less tolerant… And you can also shrink, dilate and blur the matte of the Selective. So this affects the overall skin region of the face… And you can use any SelectiveFX shader to affect this region. Now the human face analysis… Has also been trained to recognise other individual or combined aspects of the face. If you click the pull-down menu… You choose from a range of options to tweak. For example, choose the eye-bags under the eyes. Now, switch back to the result view. With the default MasterGrade… You can grade the look of that area. However, if you add another SelectiveFX… And choose A2Beauty from the browser… You can smooth out any issues under the eyes. You can also go back to the MasterGrade… And tweak the grade to match. So looking at the Front and Result with F1 and F4 respectively… You can see how Human Face Segmentation… made this a very quick task. If you scrub the time-bar… the Human Face analysis also tracks with the face. If you switch to the Selective Input view… You can see the icon tracking the face… Which drives the isolation. Now it is possible to combine multiple Human Face segmentations… To continue the look development. Let’s say you’ve been asked to add more red to her lips. So choose the 2nd Selective… Enable the Semantic Keyer with Human Face… And choose lips. If you don’t see the viewport update… This is because the viewport is still looking at the first Selective Input. So cycle F9 to update to the current selective. I would suggest adjusting it slightly and adding a small amount of blur. Now switch to the result view… And adjust the MasterGrade to enhance her lips. Scrubbing the time-bar… You’ll also notice that selective is tracked to her lips… And the task is complete. So that is how the Human Face Segmentation works with Machine Learning. One other aspect that will come up… Is how does the human face analysis work… When it comes to multiple faces on screen. So switch to the second shot in the sequence… And here we have three models swaying back and forth. Now Human Face Segmentation… Can only work with one face at a time… Unlike Human Body and Human Head extraction. So to choose a face… You perform the steps as before. Choose the Selective… And enable the Semantic Keyer with Human Face Analysis. When the Analysis is done… Switch to the Selective Matte Output. So the analysis is only affecting the face of the girl in the middle. If you look at the Selective Input View with the overlay… You will see that there is a circle with a crosshair… That controls which face is isolated within the current selective. And as part of the analysis… This icon tracks with each frame… Ensuring the chosen face is locked in for the length of the shot. If you wanted to choose another face… Simply click and drag the icon to another person. The cursor will always snap to the closest face to ensure a proper lock. So for example, look at the result view… And brighten your chosen face with the MasterGrade. As a tip for a more interactive experience… you can switch to a two-up view… And have your result in one viewport… And the Selective Input view in the other. So as you move the icon… You can see how your result will update on the chose face… Without having to flick between the views. So as long as the Machine Learning is able to identify a face… The isolations should work quite well. Now before I conclude the video… I just want to focus on the various options within the Human face Segmentation. To illustrate this, you are going to go to Batch… And use the first shot of the single model again. Now you’ve seen this work in the Image TimelineFX… And these tools are available in the Image node… And Action 3D compositor. Since Human Face Segmentation is based on the Matchbox technology… You can also add it as a Matchbox node… If you just want to output a matte from the analysis. In the browser, it is called “MLFaceExtraction”. You can connect your source… And inside the shader… You can go choose any of the available presets. We have tried to cover most of the common scenarios… So there are plenty of options for you to choose from. However we accept that there are cases… where these presets may not meet your needs… Or perhaps you’d like to refine them for yourself. So we have also included the UV unwrapped tile of all these presets… For you to adjust. Let’s build a quick use-case example. Swipe back to Batch… And add a MasterGrade node to the flow graph. Go ahead and connect the Source clip… And give it a bit of an obvious grade. Now let’s combine this with the matte… from Human Face Extraction. Using a comp node… Take the graded output as the front… The original source clip as the back… And the Human Face Extraction as the Matte. When you look at the result of the comp node… Most of the forehead region is covered… But her hairline is higher than what the preset allows for. In order to fix this… You’ll go back to Batch… And call up another Matchbox node. Looking in the list, you will find a shader… Called “MLHumanFaceTemplates”. When you load that from the browser… And look inside the node… You can access all the templates… Including the one you’re currently using. This is a UV unwrapped tile… Meaning that the Human Face Extraction node… Can take this tile and map it onto the analysis. To use this option… Go back into the Human Face Extraction node… And set the preset to “Input Matte”. Now connect the output of the template into the blue matte input. So the template node is driving the isolation from the Human Face Extraction node. You can now place anything between these two nodes… To enhance the preset. For example, just set a Context on the COMP node as a reference… And insert a paint node into the blue connection. Now go into paint… And set the Range to paint on the entire sequence. I also suggest using a two-up view… To look at the tile as well as the context while you’re painting. Now as you start painting on the tile… It automatically increases the area around her forehead. So you can tweak this as much as you like. And since this is mapped to her face… When you scrub the time-bar, it is automatically tracked in and locked in place. So it’s easy to refine the presets to match your subject. If you wish to build your own preset… We have tried to make it as easy as possible for you. Going back to the Template node… You can choose the “Stencil” template. This template gives you a stencil of the face as a UV Unwrapped tile. So you can see how we identify the eyes, nose, mouth etc… And how it is currently being mapped onto this face. If you return to the paint node… You could paint on the template… But obviously you may not want those guides affecting your final matte. So as a suggested workflow… Go back to Batch… And use the matte output from Paint instead of the front output. This means that when you go back into paint and clear the canvas… You can still see and paint on the template… But only the paint strokes will be fed through the pipeline… And not these guidelines. So if you start painting on different parts of the face… You can create your own specific shapes… And focus exactly where the isolations will be. This blends comfortably with the Machine Learning analysis… Which makes this work quite seamlessly. As a final workflow… You are also able to use the Human Face Template in the Image node and Action node… With slightly different steps. For example, go back to Batch… And delete the Comp, MasterGrade and MLHumanFaceExtraction node. Now drag out an Image node. Connect your source clip as the front. Add a new media input… And take the matte output from paint as the front source input. When you go into the Image node controls… You select the Selective… And enable the Semantic Keyer with the Human Face Analysis. Now it’s not that important at this point what SelectiveFX you’re using… But do something to make the region stand out. Now in order to use the painted template as a preset… You first need to go to the schematic view… And use the context menu… to assign the painted matte as an input for the Selective. Now change the Human Face Preset to Media Input… And look at the result view. You can compare that to the other supplied presets by toggling the menu… And you can carry on tweaking the selective using any SelectiveFX. If you need to modify the matte at any point… You could go back to the paint node… And adjust the matte further. So that concludes the human face extraction and segmentation… using Machine Learning in the Flame 2021 products. Hopefully these models will continue to improve… with future releases of the Flame products. Don’t forget to check out the other features, workflows... And enhancements to Flame 2021. Comments, feedback and suggestions are always welcome and appreciated. Please subscribe to the Flame Learning Channel for future videos... And thanks for watching. 