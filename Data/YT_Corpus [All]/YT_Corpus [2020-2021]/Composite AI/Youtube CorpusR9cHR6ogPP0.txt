 Welcome to Part 2 of my four-part series where I gave a talk at the Torrano AI User Groups. Last time, we learnt a little bit about what models are. This time, we're going to learn all about optimization and more. Make sure you tune in. [MUSIC] This is a good question. This is how I explain calculus to people that don't know it. Because I'm like five years old, you're going to get why I do it this way. So what we want to do is we want to minimize the amount of mistakes we make when we choose these W's. You were able to choose W's in your head because there weren't so many. Now imagine there's 10,000 of them, and then there's 50 columns. So that's a bigger problem. So what we want to do is we want to find a way to measure how bad we are at this. I like to call this the sucky function. But not to my superiors, I call it the cost or loss function because that sounds fancier. But this says how sucky are we at it, given our choice of parameterization. There is our h of x. The answer is y, that's the right answer, and we subtract them. So if we predict the right thing, say we guessed the answer is one and then the answer is actually one, this equals zero. But anytime we make a mistake, it's not zero. Then we square it, and then we find the mean. This is the sucky function of this thing right here that we just invented. The thing about this is I am going to go back to this thing. I'm going to say that this looks like this function. Do you remember this function from a long time ago? The parabola? This is how I explain this, how we optimize it to people that don't know what it's doing. You-all know what it's doing. But now this is another tool because people are going to start asking us, "How does this work?" Because there's going to be regulations coming out soon about how is this even happening. So this is what I tell people. So imagine you're Mario from Super Mario Brothers, and you're standing on x equals 3, and you're like, "Boy, I still would love to live in the valley of happiness." How would you tell him where to go, to go to the value of happiness if he's blind? What would you tell him? So Mario is sitting there and let's pretend you're Mario, what would you do to figure out which way to go? Well, I'd put my foot back, I'd put my foot forward, and then I would see which way is going down. In other words, I'd measure a little bit of the y, I'd measure a little bit of the x, and I would divide them, maybe dy by dx. Then I would find this slope that tells me which way I need to go. Then for all of you, smart people, we make this go to infinitely small and that's basically all the particulars. Well, derivative, differential calculus. Then we do it in multiple directions. So here's an example. Everyone knows that the derivative of x squared is 2x, and the way I know again it's because I'm two years old. Basically, when I look at polynomial differentiation, I look at the top number and I learned that they move to the front. The people that are left over are so sad that they lost one, so they lose one, and so that's how I do it. S the derivative of x cubed is 3x squared, etc. There's others you have to memorize. But take a look at this, and intuitive, this actually works. When x equals 3, the value of the function is nine because x squared is nine. The value of derivative is six, so it's a positive number. Which way do we want to walk if you're Mario? Well, you want to walk in the negative direction. So we subtract off the derivative. So what's 3 minus 6? We're at negative three. Let's do it again. Negative 3 squared is 9. The derivative of this function at x equals minus 3 is negative 6. So what we'll say is minus 3 minus 6 because we got to subtract it up. What does that equal? Three. We're at x equals three, do you see the problem? So what we have to do is we have to take a scaled version of that step or we'll miss the bottom. We call that the learning rate. In this algorithm, it's called gradient descent. Well, now it's called gradient descent because we're basically doing it in a bunch of directions. So the workhorse of all of deep learning is gradient descent. You're like, "Well, I use Adam." It's basically a variant of gradient descent that's a little bit smaller because gradient descent tends to swing wildly around the space. Then Adam does some other things that are smarter so that it goes to the solution faster. So basically, we have this huge for-loop that's taking all of the data and the answers, it is looking at the current parameterization and subtracting off a scaled version of the gradient or the derivative of that function so that Mario can find the value of happiness. This is the derivative of that thing. You've probably noticed that I made a mistake. There should be a 2 over n. But it doesn't matter, it's just a two. Nobody cares. Here's a gradient with respect to b. So you're doing this for the w and the b. I implemented this in NumPy, and it comes up with the right answer. You don't need a framework for this. It's just math. It turns out that all of those other frameworks are just math too, but they make things a little bit nicer. For this, if you look at this thing, it reminds you of something that looks like this, where you have the input x's, that get multiplied by a bunch of w's, and that output a number between zero and nine. Are you following me on this? Because this is the part where I lose some people. So basically, these are all the pixels and the values of the digit. We multiply them all by w's and we add them up and they turn out into these nodes. Each one of them, the one that has the highest density at the end, that's the one we guess. Is this deep learning? Tricky question. Most people will tell you, "No, it's basically a linear model." But what if we stack them? Is this deep learning. No, that was a tricky question because a linear combination of a linear combination happens to still be a linear combination. You can prove this inductively. It's pretty, pretty easy to do. You actually have to add something in-between to add a non-linearity to make it do that. Then this is now neural networks. So basically, we've gone from first principles all the way over to something like neural networks. Here's the thing that frustrates me. People make this out to be so magical, but it's not. It's basically just math and optimization. It's basically linear algebra in calculus and optimization theory. So you see this, these neural networks are pretty powerful, and they do a lot of things. Now, here's the beauty of this thing. How do you find the derivative of something as clunky as this? Well, there is something in calculus called the chain rule, which says that the derivative of a composite function is the derivative the outer times the derivative of the inner. So when you look at this thing, you're basically feeding numbers to it to get an answer. Then what you're doing is you're finding the derivative of the cost function with that answer. The derivative of this bit is derivative of this times the derivative of this, times the derivative of this, times the derivative of this. It's almost like you're going forward to solve it and backwards to differentiate, and that's why it's called back-propagation. You see that? It's pretty simple now that you see. I always think of, "This is going to date me." But I watched Knight Rider as a kid, and had that little thing in the front of the car be like zoom, zoom." I always think of Knight Rider. That's what it's doing. It's knight ridering its way through the valley of happiness for Mario. But I don't explain it that way to professionals. Well, except to you because we're all friends and we shut the door. This is what this now starts to look like when you're starting to small it down. This is a matrix, you multiply the input digits by this matrix, dot-product it out. You do a function over the answer, and then you do it again. Then you softmax, so that sums to one and then these things start to look like probabilities, but they're not. But we will tell everyone that they are because that's what we do. Not yet. I didn't get there yet. He's like "Where are the convolutions?" They're coming sir. I know you came for the convolutions. I saw it in your eye when you wired and he's like "Convolutions." Yeah. How do you do this in TensorFlow? Most of you maybe use TensorFlow. I like to think of TensorFlow as three different things. You craft a function shape. In Scikit-learn, you basically pick one, you don't make one. You pick a function shape or a model. You optimize the function or the model using a cost or loss function and an optimizer. In my case, that thing that I showed you was mean squared error. It turns out that categorical cross entropy is better for the digits one, and then you pick an optimizer. I showed you gradient descent. Stochastic gradient descent is when you batch everything up, and then you use the model to predict. The model again has its function, the loss function is how sucky we are. Here's what it looks like in TensorFlow. It's pretty nice. Before Keras, this was kind of a chore. I think PyTorch got it right before TensorFlow did, no offense. I'm an equal opportunity person. I was in Israel once and I was doing a talk on TensorFlow and they were like, "Seth, aren't you from Microsoft? That starts from Google." I'm like, "Yeah, we don't care what you want in our Cloud, the slower the better." I have caused joke for you-all. Actually, TensorFlow is really nice. I really like a lot of the stuff they're doing with their datasets. Before, I didn't like it in TensorFlow. But now I was really ticked off by their datasets. So I brought it off and went to PyTorch and then now I'm coming back. So you can see all of this here. Now the thing is that these are all the optimizers, these are all the loss functions. Here's all the models you can build. I'll get to these a little bit later because you sir, very adeptly said, "What about the convolutions?" I'll get to them. So the question that always gets to people when I give this talk is like, "Which one do you pick?". [MUSIC] 