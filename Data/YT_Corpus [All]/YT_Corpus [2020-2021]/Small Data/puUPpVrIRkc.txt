 [Music] today we're gonna talk about performance patterns for building inclusive web experiences let's kick things off with addy cool so any user can have a slow experience it could be the site it could be their hardware or it could be the network now have you ever watched someone that has poor network service they uh they usually look like me staring at their phone and then their arm just slides to go up and up and up and up almost as if they're trying to pierce some force fields that will give them 4G now I personally think that I probably have the worst network service here if if I go from one part of the stage to the other I just twirl around a little bit I go from 4G to edge edge edge being both my network connection type but also my mental state now we've all had user experiences that are fast and also plenty that are slow so to support a web ecosystem that's inclusive of users who are both on low end and high end devices and networks as developers we need to start doing something we need to start respecting the user's hardware and network constraints you see these characteristics really matter your users hardware and their network type can massively impact the experience that they're going to have with your site so let's talk about why that is what are components that can contribute to that well what's in a modern smartphone we've got a CPU memory storage a screen and battery phone Hardware can vary quite a lot the hardware that's in your your pockets right now can probably vary by quite a lot compared to the stuff that your users are accessing your sites on l1 l2 l3 caches all of these things can have an impact on the overall experience in pretty noticeable ways now let's quantify this problem a little bit here is a visualization of the performance gap on mobile what we can see here are the top 10 highest selling smartphone sales for the first half of 2019 and what you'll see it is that there's a huge gap between high-end devices and everything else like it's about a 2 or 3 times slow down if you're talking about the other hardware now device characteristics matter quite a lot because one of the things we're doing is putting Java scripts increasingly into our sites today a lot of it and given that javascript is inherently single threaded and more single threaded than the rest of the platform this stresses things like single core performance and so we need to care about things like the CPU so if you're making sites that are only going to work on high-end hardware you might be excluding some of your users so this is something we've said for multiple years if you want to build a fast site use slow Hardware Alex Russell has been on the stage plenty of time seeing the same thing but I just want to remind you that that's one of the things that we need to just make sure we're constantly doing now I talked about smartphones but this problem the variance applies equally to desktops as well there's a huge performance gap on desktop over here we can see the CPU performance this is using Geekbench data the same as the other slide this using Geekbench CPU performance data and it shows us the highest-selling laptops on Amazon and at the very bottom I have a modern popular developer laptop a MacBook Pro what you can see is that the devices that we're building our experiences on are so much faster than the devices that people are actually out there buying on mass you can have old hardware that sticks around for years and years people that tend to have longer refresh cycles for desktop hardware and there's just generally a huge performance disparity between low end and high end so a question the Nate and I would like to pose to you today is do we need to deliver the exact same experience to every user we think that the answer is no in a world with widely varying device capabilities a one-size-fits-all experience doesn't always work slice that the light user is on high ends devices can sometimes be very unusable on low antwon's particularly in emerging markets and on older hardware now we think that responsive design was a really good start we think we can maybe increment on it a little bit and improve it so today we'd like to introduce this idea of adaptive loading now adaptive loading is this idea that we build the support low-end devices first and progressively add high-end only features on top of it this allows users to get a great experience best suited to their device and network constraints with fewer frustrations so one core experience everybody people on high end networks and devices get something that's just a little bit better so let's chat about a few ideas in the space and how we can make it easier for everyone so give users a good experience on low-end devices we're gonna kick it off with a demo so let me switch over real quick alrighty let's see if this is working cool so Paul Irish and Elizabeth earlier today they mentioned this this really neat YouTube lazy loading element that Paul had built for improving performance and I thought it'd be neat for us to actually try integrating that into an app and show you a few ways that we can improve on it before that how many people here know what styled console logs are all right it's like 30 30 40 percent of the audience so they basically look like this they let us like create these nice fun funky console logs one of the really nice things about you know style console logs is that we can we can also kind of abuse them to create our own console and messages so in my case speaking after Paul Irish an Elizabeth Sweeney but we're going to try to give you a decent demo of this idea so here what we've got is basically a Riemann tation of YouTube it's using live YouTube data and I'm going to keep the network panel open over here we're going to navigate to a video so let's go to this one real quick and what we see is that 514 kilobytes worth of scripts are loaded for this experience now imagine we were to swap out the core video experience here for something a little bit lighter now I want to do something real quick to to show you we're gonna do so we've got this little window debug thing what we can see in green is there like core content for this experience in red we've got all this extraneous stuff we've got recommended videos we've got comments and I thought it'd be interesting to think about you know what if you're on a slow network or a constrained device something with low memory or fewer CPU cores what if we were to do something where you know we can navigate back to the main experience we can emulate this let's go into fast 3G right and if we now go to the video page what we see instead is that we've actually used that lazy loading element from Paul Irish earlier and it's only loading up three kilobytes of scripts but we're being very intentional with only shipping this down to users who are in the worst conditions so we're gonna talk a little bit about these ideas I'm gonna switch back on to the slides right now now there are three or four key signals we'll be looking at for adaptive loading today first of all we've got Network for fine tuning things like data transfer to use less bandwidth we've got memory for reducing the amount of memory consumption on low-end devices CPU for limiting costly JavaScript execution and reducing CPU intensive logic and we'll talk a little bit about client hints and we'll talk about JavaScript API for doing some of this stuff now to make all of this easier today we're releasing a new experimental set of react hooks for adaptive loading that you can go and check out if you're using react to build experiences today whether it's react on its own or next Jas you can use these hooks for everything from Network memory CPU to employ some of the ideas that we're gonna be talking about in just a second and by the way all of these are built on top of web platform api's and so if you're if you're using a different framework if you're using angular or vue spelt lit any of these things you can still employ these techniques it's just that we're going to be focusing on react for now well thank you thank you one person so let's kick things off with adaptive media loading now this is the idea that we serve low quality images and videos to users reducing bandwidth and memory consumption so picture you know I've got a site where maybe I'm shipping down videos to ever buddy but do I need to maybe I could be shipping down lower resolution images instead if your network can't handle it if your device can't handle it so you could picture a photo gallery application and shipping those lower res images or using less code heavy carousels you could imagine a search application where maybe you're limiting the number of media have any previews you can imagine a news oriented site where you're emitting some popular categories that maybe have preview images in there as well and the way that we can determine network connection information on the platform is using the network information API so the net afo api summarizes performance of a user's network connection and on the web it's what allows us to live our experiences based on how slow or fast a connection is now you can use this API via the web platform and you can also use it for things like conditional resource loading using the react hooks that I just mentioned so let's actually take a look at a quick demo of this we're gonna switch back over to the other machine real quick and here we have an experience called react movie by the way for all the demos today we are integrating adaptive loading on top of existing apps built by the community none of this is just stuff that was written from scratch you can employ these ideas in your apps today so here we have an app called react movie and this is a sort of a movie discovery app I can see all movies that are out at the moment I can click through and I can browse sort of thumbnails for them but what you see is that this core experience is currently shipping 2.7 Meg's worth of images if I'm you know if I'm any casual user we can employ adaptive media loading techniques and actually deliver an experience where if you're on slow 3G so let's actually clear the sounds might take a hot second so it's a load up given it's so slow but the idea that we're going to be trying to represent here is that you can still offer the users an experience with slightly lower resolution imagery in a lot less bytes so it's taking its time it's taking its time ok ok it's it's getting there but these are all lower resolution images the overall payload size is significantly smaller than what we were showing you before and it actually doesn't take a lot of code to do this we're just using two or three lines of additional code after importing in that network hook and everything works the way you'd expect so next thing I wanted to show you let's switch back over to the slides please so the next thing I wanted to show you was data saver aware resource loading so the safe data client hint is something that is a request header that lets you deliver lighter experiences to your users who opt into data saving mode in their browser and when a user has this feature on the browser can request low resolution images it can defer loading some resources and this is available as a JavaScript API but is also something you can use via client hints so once again here you see we're using our react talk in order to achieve conditional resource loading a company that's using data saving as a mode they've got a custom mode quite effectively today is Twitter comm so Twitter is designed to minimize the amount of data that you use they've got a really nice data saver mode and when you opt into it you can get anywhere up to 80% reduction in overall data usage images on the web and anywhere up to 96 percent if you're including things like disabled video autoplay I thought it would be neat for us to try reimplemented something like the Twitter data feed so we're gonna go and take a look at another very quick demo so here we have the Twitter feed it's a simplistic version of it I can scroll through this feed I got to see plenty of tweets 20 of resources and the overall payload size of this is something like six point nine megabytes overall so this is including high resolution images videos anything else that's that's supported now using this hook or using just the web platform API is for data saving I can go and I can toggle this and what you'll see is that we've switched out those high resolution images for low quality image placeholders I can scroll through this feed pretty quickly I don't have to be fetching the original images at full resolution and if I want to see the full resolution image I can just tap and get that same experience now scrolling back up here there is actually a video that has its autoplay disabled this is by mr. doob and I thought I'd play this for you so this is basically what it looks like when we as developers have a nice payday you're just like do you know you're I love that so much my my my version of this is unfortunately a lot a lot worse oh oh great okay live live stage feel let's let's try this out again and see if if the guys okay all right okay that's this is this is me cool very very accurate so let's switch back up to the slides for a second now for awhile people have been asking for a media query for your safe data and although one doesn't exist just yet there is an active proposal that's been made about introducing this idea of a user preference media query prefers reduce data that would let you design data reduced variance of your site for users or express that preference um if you're interested in something like this existing on the platform there's a link here where you can get involved in a discussion I personally love to see something like this existing next up let's talk about memory so the device memory API adds navigate or device memory and it returns how much RAM the device has in gigabytes ran it down to the nearest power of two now this API also features a client hints header device memory that reports the same value and similar to before it's relatively straightforward to use the memory hook in order to conditionally load different types of experiences now I thought I'd show you a demo that's slightly different using this let's switch over to the the other machine real quick once again I discovered this really awesome website called Dixie and Dixie do a bunch of consumer electronics one of the things that they do is they sell mechanical keyboards and on their site they have this really nifty model viewer usage where you can kind of go and check out this is nice you can like spin it around it's it's really pretty but one of the downsides to this is if we if we go and we load up our dev tools we go to the network panel and we try to reload this experience up is if we organize things by size and there's go to the very top you'll see that this 3d model is actually almost 5 megabytes in size now in addition to that it also uses quite a lot of memory on low-end devices to get something like this running on high-end devices on desktop it's perfectly fine but for users who are on those low-end devices what if we were to do something like let me reload this page real quick what if we were to do something like use memory signals in order to decide whether or not to just send them down a static image like we'd save on multiple megabytes worth of resources being sent down to those users while still giving users who are on high-end devices a really really slick experience I personally love these 3d models love model viewer let's talk about JavaScript so adaptive module serving is something I'm excited about and this is this idea of shipping a light interactive core experience to all of your users and progressively adding high-end features on top so if a user's device characteristics and network and handle it now it's this device awareness that takes progressive enhancement to the next step so on high-end devices we can conditionally be loading more highly interactive components or more computationally heavy operations you could imagine servers of the future being smart enough to use client hints and other signals that come from the web platform to decide like what code to send down to their users so bundles that are you know the core experiences versus bundles that are a little bit heavier in this example we're looking at something like an e-commerce site where the core experience represents sort of the product images the cart experience and the higher end ones can include things like zooming into images related products videos and a are version of the experience and go crazy I wanted the demo a slimmer version of this idea adaptive code splitting and code loading so actually before we go into that some of you might be familiar with react out lazy and suspense these are basically primitives that help you do things like add code splitting to react apps and then define fall backs for that content as its loading up and you can in fact extend react out lazy's you can get Network aware or memory or wear or data saver wear code splitting so in this pattern what we're doing is we're basically doing a check for the users information effective type values and depending on those values were able to generate different chunks for people who are on 3G people are on 4G maybe a light experience a slightly heavier experience and I wanted to show you an example of this real quick so eBay are a company that are exploring this idea of adaptive surveying and they're able to conditionally turn on and off features like zooming if users hardware and network conditions don't necessarily support them well so let's switch back over here we decided to implement a version of this and what you can see is this is a lot like eBay on desktop and if I hover over this product image I can see this in a very high resolution I've got this nice additional magnifier dependency that's being pulled in but overall we're shipping down about 62 kilobytes of JavaScript to our users now picture that I'm wanted to you know look at what this might look like if I'm on a narrower viewport site so let's imagine we're in this situation and I'm unloading this back up now in this case we're actually only loading 45 kilobytes worth of overall scripts we don't have that same magnifying experience on mobile what we're doing is we're just shipping users down an experience that just shows them the image and it most maybe we show them a modal so people who are on those higher-end situations they can get the slightly more enriched version of this and next let's talk about CPU so desktops and smartphones can have multiple physical processor cores and their CPU and each core can run more than one thread at a time so a four core CPU you might have eight logical processors and in order to determine this insight from the platform you can use the hardware concurrency API now there's a hook available for this as well that allows you to use conditional resource loading very similar to some of the others and one of the downsides this I mean one of the values of this is that you can use it to do things like determine you know the optimal work or thread pool if you're using web workers in your application the platform does have however limited information about CPU and I think that it's interesting to consider should we have more could that unlock other use cases another pattern is adaptive data fetching and prefetching so whether it's on the client or the server reducing the quantity of data that you're sending down to users can decrease overall latency an adaptive data fetching can use signals like the slow network to send fewer results down to your users and we've been talking about a bunch of different patterns today and you might be wondering okay what we're seeing a few folks who are using these in production is anybody using most of these in production and one example of a company that is is tinder web so tinder web and tinder light are using a number of these patterns and productions keep the experience fast for everyone if a user is on a slow network or has data saver enabled they disable video auto plays they limit route prefetching so prefetching the additional routes user might navigate you across the experience and they're also able to do things like limit loading the next image in the carousel so they just load one at a time when you're swiping they've seen some really great stats off the back of this great improvements and things like average swipe count so for tender light they saw seven percent more swipes and areas like Indonesia on the back of using some of these signals and finally we've got adaptive capability toggling now this is this idea that instead of serving image like instead of serving animations down to all of our users for people who are on lower end hardware maybe we consider not shipping those animations at all or throttling the frame rate in some way so what we're gonna do is demonstrate using this with client hints now client hints are something I've mentioned a little bit in other parts of this talk but they're a mechanism for proactive content negotiation the client advertises a set of hints via HTTP request headers and the server provides hints that adapt the serve resource they can be extended to a number of different use cases now one of them is helping automates the negotiation of optimal resources based on the clients data saver preferences and I've got a quick demo using next js-- and client hints I'm going to switch to you right now just to show you this idea in action so here we've got adaptive animation imagine that we've got a blog site or an e-commerce site of some sort where we've got a number of different cards worth of content now me on my high-end device lots of memory I can probably handle things like nice navigation transitions pretty pretty okay and they look relatively smooth but if I'm on a low-end device I've tested this out on moto G Force you can end up with pretty choppy experiences maybe it doesn't make sense to animate on those devices and stuff so one thing we can do is we can simulate all of those conditions that client hints allow us to do and if I now try transitioning I just get a very simple basic navigation the same type you're probably used to seeing in many single page applications but we're we're still able to give everybody an experience that best suits their hardware and network characteristics in these cases so I'm really excited about that now I'm gonna invite Nate to the stage in just a second he's gonna talk a little bit about how Facebook uses these patterns in production and one of the areas that we don't have a great solution for on the platform just yet is this idea of device class detection so you might have noticed across some of these ideas we've been basically bucketing things into you know you were on a slow site you're on a slow device or you're on a fast device you're in a slow Network you're in a fast Network now one thing we could do to build like an ultimate solution around this stuff is have a setup where we're taking a look at the user agent string determining like what is the hardware we think you're on we could connect that up to Geekbench performance data and then we could decide based on thresholds you know R is the combination of your RAM your CPU and your CPU score considered low end or high end now this is very difficult to duct tape together in a way that makes a lot of convenience today but I'm really excited actually for Nate to talk a little bit about how Facebook tackles this problem and a little better ways so please join me in welcoming to the stage Nate thanks Addie so one thing faced with Lee Facebook recently announced is a redesign of the website we're calling this FB 5 one of the cool things about going through and redesigning the site is we've been able to take a lot of the things we've learned over the last few years about adaptive loading and different types of hardware and making sure the site responds correctly to that and really integrate that into the core of FB 5 one of the core principles we considered when trying to go through and design FB 5 is we didn't want to just build a site that responded based on screen size we wanted to build a site that actually adapted based on the user's actual hardware so actually changing what loaded and how the site ran based on what hardware it's on not merely responding based on changes in the screen size there are a few steps that we took to implementing this the first step is we actually needed to define consistent buckets for how we were talking about different types of hardware and how we were considering a hardware classification kind of across the site across different teams across different products the next step was integrating these buckets into all of our logging looking at in our performance logging our general metric collection logging our engagement logging and really making sure we were able to see a holistic picture of how things were working based on these different types of hardware next once we actually can see the full complete picture and understand what's going on for different users and different situations we can actually adapt loading and change how the site runs how it loads what happens based on the hardware so on mobile grouping hardware's not that so complicated the mobile UA actually just tells us what this device is and then there's tons of public datasets where you can actually plug in which type of device it is and get information about the CPU clock speed how many cores things like that and then we can use this like predefined concept of your class your class is a very popular framework on native you can use it basically to figure out in what year would this device have been considered groundbreaking so by looking at your class and by looking at kind of like the public information about a device and like obsessively like what this model is and how fast it is were able to have like a general way to talk about different devices across both the web and native and that's pretty powerful so on mobile we can just look up exactly what this device is and kind of get all of its hardware and performance information however in desktop things aren't so obvious sure the user agent tells us all right is it a Mac is it a PC is it 64-bit what browser it is most of the time everything is 64-bit nowadays it doesn't really tell us much about the actual hardware that the user is on right now so what do we have well we have navigator that hardware concurrency which tells us generally how many CPU cores and many browsers also give us navigator dot device memory which tells us how much RAM so maybe on desktop there's a way we can use these two fields and figure out some generalized buckets that we can apply consistently across different devices and different are different metrics so the first step for doing this is to actually log hardwick and currency and device memory everywhere once we actually have these in our tables we can build metrics and understand how things are different based on these devices so once we have done that the next step is actually group by hard-working concurrency device memory OS when looking at our different metrics and basically come up with charts to really understand what the full picture is like once we did this we start to see natural bands for different types of hardware and how they're performing and kind of different barriers so at Facebook once we did this we came up with five different kind of classifications for devices and the heuristics we use for them actually vary across different OS and browsers so this is something that we did some analysis to figure out where the natural bands were once we figured out the buckets based on the groupings we're able to apply it kind of like deep in our data sets and log it everywhere and actually the consistent way to talk about different performance and different device types across different metrics and across different teams and this is pretty cool because when integrated is performance logging this Hardware class reveals a much more complete picture we can actually see everything that's going on understand how the experience varies for different types of users in different situations much more holistically so take for example this this chart so if you're just looking the average it looks like basically your performance stayed the same maybe got slightly worse but overall it looks like things are fairly consistent in performance but when we break stuff up by hardware type we can see that maybe on the sixth we had a improvement ship for loan devices however there is a large regression for mid-range devices the way low-end devices and mid-range devices are gonna load your site is going to be very different low-end devices are often going to be blocked on parsing JavaScript actually executing the JavaScript and they're just like execution will may be mid-range they might be blocked on network or other different bottlenecks the way users interact with your site is going to be very different on both types of devices to low-end users might do different engage with your site in different ways in different spots then mid-range users might so you might see your metric shift as your mid-range users end up in a slower performance class but you won't actually know why so we're breaking stuff up by different hardware type you're actually able to see in pinpoint where your regressions are happening the other thing that this can help you with is shifts and user population let's say that alone device suddenly goes on sale in emerging market and all of a sudden you have a lot of users on your lone device if you're just looking at the overall average you might think oh I have this big regression right now when in reality there's just more users taking advantage of the promotion on a low-end device so by breaking stuff up you can actually see I'm consistent like if you're loading consistently or not and kind of counteract changes in just populations on different types of devices so once we have this like kind of core this core metrics and we were able to break it up and have a consistent way and understanding of what different types of hardware are we can actually consider this in our core frameworks one of the first things we did is we looked at animations animations take time to render the browser will attempt to paint a frame then if we cancel this throat all that work but every time every frame the browser is attempting to paint something and render an animation it could be doing something else and actually helping you load your page so unknown devices animations kind of looked like this they were so much Enki they would render like a frame wait awhile show another frame and eventually stuff would load but it's not a good experience this kind of animation one one of the first things we did is we just stopped shipping animations in many instances on low-end devices this enabled many more users to finish loading the page and actually engage with the site much more because they already weren't getting much benefit from the animation that wasn't really loading and now that wasted work is no longer happening and they're actually able to see the page much quicker another thing we do is on our mobile website our mobile website we have a totally different site for Android phones and iPhones that have the touch screens and have powerful CPUs that can run a lot of JavaScript versus feature phones that maybe don't have as many powerful CPUs and can't run Java scripts as well our feature phone site is mostly a static HTML a little bit of CSS very few images I mean it's really optimized for this like low powered device case even when the future phone screen is big even when the feature phone has a touchscreen this is an instance where we're not just scaling the site based on screen size we actually have two totally different experiences based on the underlying hardware and really optimized for that hardware one of the cool things we're doing - and especially on the FB 5 site is we're actually taking advantage of the fact that there's this trade-off right now on the web between load and quickly and responding quickly when you're loading your site often you get advice to chunk up your JavaScript that's needed to load the site into different chunks and yield to the browser in between each chunk so the browser can dispatch any events that may happen so if these are clicks on something you don't actually have to wait for the entire load to finish you can respond to that event as soon as the click happens on high-end devices yielding it to the browser after each chunk is fairly cheap the browser will quickly see there's no event and just go back to running your JavaScript over and low end devices this can be somewhat slow and it can often take quite a bit of time so there's a trade-off right now where you want to chunk up your JavaScript into small chunks but on low-end devices if you make too small chunks you're actually going to slow down the overall experience by quite a bit so one thing we've been able to do is on in reaction current note that I talked about earlier one of the core things is this concept of a scheduler now this is an experimental API it's almost definitely going to change but one thing we're doing right now is if it's on a low-end device schedule has this concept of forcing a frame rate generally scheduler and react is going to try to schedule each frame and run it whatever the browser is currently running at so 60 fps there fps something like that however by forcing a frame eight we're able to basically tell react alright ignore it the browser's trying to do right now and just take longer run at 15 fps and actually run more JavaScript each frame so the user can actually load more of the site before we check for each event so yes some events interactions become slightly slower but overall it's a much better experience for users because there most users are just waiting for your site's hello it and this can happen now much much quicker one interesting thing here too is that hopefully eventually this trade-off goes away altogether with this new API isn't appending eventually we hope isn't appending we'll kind of ship everywhere and it'll just be a quick cheap way to check is there input right now so then this trade-off will be gone because we can just run all of our JavaScript during loading and we don't actually have to block stuff up we can still be interactive hopefully this gets integrated interact too so if you're using the latest react and once the ships you should just be able to kind of get this for free so by using consistent definitions for our bucketing and our logging and adapting based on those definitions consistently we're actually able to share this understanding of how the site works across different teams across different orgs and really figure out like what is this overall picture that we're seeing so in metrics change based on something one team does we know that it's based on this kind of consistent hardware definition and that's a lot easier to pinpoint changes and see what's going on now I'm going to invite addy back to kind of take us home had some better network service in the back so that's it for adaptive loading today we talked about adaptive media loading code serving data fetching in general a lot of these ideas have got some promise and we're very excited about them they do have some potential drawbacks that are worth being aware of adaptive loading does use this idea of often point in time information about the user's device and network constraints and you do want to keep in mind like what impact is gonna have that gonna have on things like hey should be caching so just be very careful with adopting these techniques I do think they can have a lot of promise but that nuance is probably useful to talk about as well and adaptive loading isn't like it's not this this groundbreaking a huge thing right it's an incremental practice many many over many many years we've been talking about this idea of trying to increasingly become more lazy first with our content and so adaptive loading is really just an incremental pattern on top of those things and so in general even if you take nothing else away from this talk try to reduce defer and coalesce the resources that you're serving down to your users ultimately what we're trying to do with these patterns is build experiences that have inclusivity in mind though the core experience ideally that works great for everybody and toggle or layer on features that can make it even more awesome if a user has enough memory CPU or a fast network so that's it for adaptive loading thank you [Music] 