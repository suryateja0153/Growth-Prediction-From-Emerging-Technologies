 Hi this is Francesco Rulli I'm the CEO of Querlo I'm  also the Forbes Insights AI Solutions Business   Partner I'm here today with Reid Blackman who covers  different roles one is the CEO and Founder of   Virtue Consultants and also is the Senior Advisor  for EY and the former Professor of Philosophy   so Reid if you can share with us a little bit  more about your background and your work today.   Yeah sure so my background is as you said I'm  a you know by training I'm a philosopher or an   ethicist so you know I was a professor for 10  years prior to that of course there was tons of   grad school so I've been teaching researching  publishing on ethics for about 15 years   I left academia a couple years ago maybe two and  a half three years ago something along those lines   and I founded this company virtue  which is an ethics consultancy   that focuses on digital risks you know so  think about the ethical risks associated with   artificial intelligence or machine learning  big data blockchain vr ar all those things   and so most of my work is helping senior  leaders to figure out how to systematically   operationalize ethical risk mitigation right  so you've got this company and you're building   products or building ml products or data  driven products how do we build them in a way   that vets for ethical risks and  capitalizes on ethical opportunities   that's sort of like that's sort of the  core of my work. Very nice thank you Reid   now we are going through a very special time coronavirus the pandemic the change of the   the future of work is today basically so what  are your thoughts about the role of artificial   intelligence in the this new environment that  we're living through. I mean you know look at at   the end of the day ai is a tool right so the  its relevance to covid is to what extent can   it be deployed in ways that will help us solve  the problem whether it's contact tracing or   ferreting out who's got who has the who has  the virus or figuring out what vaccine or   or treatments might plausibly work so it's a tool  that can help us along all those fronts and more   okay and this tool can should be shaped or defined  from an ethical perspective are there parameters   are there advisor you give to organizations  that they start embracing this specific tool   yeah look i mean it's gonna depend on what they're  doing so let's say that they're doing contract   contract tracing right and you wanna  sort of use ai to you know vet through   the patterns of people who have it and try to try  to identify its source of where it's going to go   one of the big issues there is privacy  obviously right because you're collecting   the you're collecting a tremendous amount of  data about lots of people not only whether or   not they have it but also where they're going  what time they're going there how long they   stay there who they're going there with so on  and so forth so if you want to get anything like   wide scale or at least sufficient adoption of  say a contact tracing app that uses ai you're   going to have to make sure that the privacy  controls are very strong and that there's a   lot of transparency about what those privacy  controls are and why they are what they are   you know when it comes to things like i don't know  say diagnosing who has it you'll have to think   carefully about things like explainability  whether whether explainable outputs are important   in that context or if we only care about accuracy  sometimes often there's a trade-off between   the accuracy of a of an ml output and the  the explainability of that output you know   the extent to which we can articulate as you know  metaphorically speaking the the reasoning by which   the machine outputted the output that it did  sometimes explainability is very important and it   pulls and it pulls against accuracy and sometimes  it's not so important so you'll have to think   about why is explainability porn is it explainable  in this context and if so why and how important is   it relative to relative to accuracy so there's  a whole bunch of sort of you know different   kinds of ethical questions and pitfalls that  any company needs to think through when they're   using the when they're using this technology. very  interesting thank you now talking about use   case we developed we I am the Cognitive Officer  of the Cathedral of Florence and with the 700   years of history we decided as a team to  resurrect basically the voice of Michelangelo   we built an artificial intelligence that  allow people to talk to Michelangelo and the   ai itself through machine learning communicate  back to the experts in Florence who shape their   answers so also from your perspective as a former  professor of philosophy what do you think is the   contribution of artificial intelligence is it good  is it bad or is it something we have to explore   about using this technology to give voice again  to someone who's now around and eventually   how we avoid the interpretation of  his opinions to be hijacked. Yeah so   look it could be it could be really great right  so let's talk about the context that you're   talking about using it to sort of quote-unquote  recreate Michelangelo it could be great in so far   as it gets more people engaged with the works  of Michelangelo and Michelangelo as a person   maybe that era of time maybe gets them  interested in art history more generally   it's a way of engaging with the history and the  art that's new and some will find more engaging   than say reading a book or watching a lecture on  youtube or something along those lines so you know   that's great there's a there's obviously  questions with any sort of chat bot about   again privacy so is there clarity around what  data is being collected from that chat and who's   asking it so maybe I'm asking questions that  I don't want people to know that I'm asking   I'm not totally sure what those might be but who  knows right people type all sorts of weird   things into chatbot you know interfaces  so maybe they incidentally reveal   information that they don't want anybody  else to know like I'm gay Michelangelo   was Michelangelo gay too or something along those  lines right and they don't want other people   knowing that so there's a question about what  data you know are you collecting and what are   you doing with that data and is there transparency  about that with the user there's questions about   potential bias so suppose that you think that  you know i'm trying to think how bias might   I mean it depends on how you train the chatbot  right so there's an infamous case of microsoft   training taiyo their chat bot by feeding  it with the data garnered from twitter which   led to being a racist anti-semitic chat  bot in less than 24 hours I don't think   that's how you're training Michelangelo so  that doesn't seem to be a particular concern   but you might think about the people behind  people who are giving the answers right so suppose   that the people who those the experts that you  referenced they are say of strong catholic   faith they have a they have a very strong  interest in sort of promulgating catholicism   or something along those lines and they see this  as a way of sort of pushing a catholic agenda by   sort of revealing certain information about  Michelangelo that would put it you know towards   a that would cast a favorable light on catholicism  or hiding some information about him again to   cast a favorable light on catholicism or at least  to refrain from from casting a negative light on   catholicism so you know you want some level of  clarity about who is who's providing those   answers what kind of whether what the source  of their expertise is you might want to know   about the vetting process behind that information right so think about if you're going to pick   up a book about Michelangelo there's going to be  something like about the author and you might   also google the author's name and find out oh this  person is a you know devout catholic that might be   relevant to you but if it's just an ai you know a  conversational interface and it's just sort of   completely obscure who's behind it then you know  there's a worry that the lack of transparency   will cause lack of distrust and of course for  the people developing the chatbot there's   hopefully interest in making it as objective as  possible in this domain and so you'd want to vet   your sources properly. Perfect thank you very  much Reid and that's very good insight indeed   very good insight for us going forward now  if people want to learn more about your   business and your work what's the best way to  reach out to you and learn more about your work.   So there's a number of ways you can find me  on LinkedIn I post quite a bit on LinkedIn on   you know ethics and data ethics and ai you can  always reach out to me at reid@virtueconsultants.com  you can go to my website virtueconsultants.com  you can go to reidblackman.com   you can read I have a recent article in  Harvard Business Review on a practical guide   to building ethical ai you could check that  out anyway Google my name I promise you   you'll find me I'm around. thank you very much  Reid really appreciate it. My pleasure thank you. 