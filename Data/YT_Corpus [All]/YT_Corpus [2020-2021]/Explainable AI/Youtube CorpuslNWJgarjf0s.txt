 hey everyone so a topic i wanted to talk about really quickly is this idea of ai related injuries and death and who's responsible for that well it turns out that this is sort of a new area of what's called negligence law and venturebeat recently covered a paper in an article that they wrote on this very subject that i thought was really interesting so i just wanted to mention a couple of things about it here and then i highly recommend you you check out the paper uh links are in the comments below um but anyway there's this idea of what's called a moral crumple zone so if you think of a car and actually i used to work in indy car racing for many years in those cars they go like 230 miles an hour and there they often you know have crashes where the car hits a wall going that fast but the car's designed so that the suspension and the body parts and everything absorb the impact so that the human doesn't right so that the human doesn't absorb all that energy and sustain an injury and so on but this idea of a moral crumple zone is kind of similar in the sense of you know let's say in the case of an autonomous vehicle or a semi-autonomous vehicle you know there's an accident right so who who sort of absorbs that impact right and takes the brunt force of that impact in this case when we're talking about like negligence law we're talking about liabilities right so you know currently because there's not a lot done in negligence law around this and there aren't regulations and so on it's possible and there's an example talked about in this article and paper where you know the person involved could be the one that takes the uh brunt of the liability and responsibility and accountability for this ai related injury or death and so that's the idea of this moral crumple zone where you know basically technology is protected at the expense of humans um and and again there's this gray area of like well what if the ai related system is like a fully autonomous system or is it semi-autonomous and you know with autonomous vehicles on the horizon more and more these are certainly questions that need to be answered also you know there's also the the concepts of algorithmic bias transparency and explainability when dealing with these advanced ai algorithms that you see in neural networks and deep learning and so on and control systems and autonomous vehicles and so you know there's a lot of different ways that this could be approached and this is certainly an area that needs to be addressed further so it'll be interesting to see because these are definitely challenges that need to be addressed and you know some of the ideas out there are around um you know maybe it is a strict liability thing like somebody has to be held strictly liable uh whether it's you know the makers of the ai or the person in the case of this moral crumple zone concept which isn't at all the best idea obviously um maybe there's an insurance option maybe there's just more regulations maybe more oversight people that look out for these sorts of uh potential you know risks of negligence type scenarios and so you know review algorithms for potential biases and also these risks uh and so on so anyway really interesting concept certainly an area to keep an eye on i want to see where this whole negligence law goes in terms of ai related injuries and death and especially in terms of accountability because you know clearly there's a lot of ethical and considerations and so on associated with this so check it out link to the full article in the comments let me know your thoughts and uh have a great day 