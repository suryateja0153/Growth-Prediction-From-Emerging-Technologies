 hello everybody and thank you for joining duke science and society for the latest installment of our coronavirus conversation series my name is sarah rispin zedlack and i'm a senior fellow at duke science and society society where i work on organizing these talks also be sure to head over to the duke science and society website to look for our future coronavirus conversations right now we have in planning stages a talk on wearables and the ethics and so of their use for early covet detection and the policy and ethics of using human challenge trials for finding coronavirus treatments and vaccines while you are there you can also learn about our master's program where our students and faculty address the issues we've discussed the past in the past few weeks during these conversations on a daily basis with that out of the way let's meet our moderator and guests dr nita farahani is a leading scholar on the ethical legal and social implications of emerging technologies and science she is a professor of law and philosophy the founding director of our program the chair of the duke m.a in bioethics and science policy and a principal investigator of slab lab at duke she is also the co-ed editor-in-chief and founder of the journal of law and the biosciences rachel dralos is a duke md phd candidate in the medical in the duke medical scientist training program and a researcher in dr lawrence karen's lab she focuses on developing novel deep learning methods for clinical use and has recently written a paper now in pre-print on machine learning for abnormality prediction for large-scale chess cts dr timothy dunn is a post-doctoral associate in the duke department of statistical science and a duke forge scholar specializes in deep convolutional neural networks researching how to use neural networks for predictive modeling in healthcare including functional brain imaging and finally dr raymond geiss is a senior scientist with the american college of radiology's data science institute and a fellow with the society for imaging informatics importantly he is a lead author of the october 2019 multi-society joint statement on ethical ai in radiology nita thank you sarah it's a pleasure to be here with all of you today and thank you to our panelists for being willing to join us and talk about these important issues um particularly during a global pandemic uh and um with applications for the global pandemic um i think the way that we're gonna do our conversation today is that we'll hear first from dr dreylos then from dr dunn and then from dr geiss who will give opening remarks for about five minutes each from there we will move into a conversation amongst the four of us to talk about some of the social and ethical and legal issues with respect to ai and radiology focusing in part on the pandemic and more broadly to be able to give us the best information to understand this relationship the hope for this conversation along with every conversation that we have at science and society and as part of our coronavirus conversations is to make sure that we have a firm understanding of the facts and the science um in partnership with the ethical legal and social implications and so my hope is that we'll start with some of the establishment of the facts and move into a broader discussion with that i'll turn it over to dr dreylos to kick us off and ask that she give us her beginning remarks before we dive into a deeper conversation thank you very much i'm looking forward to being on this panel today and i'm excited for the opportunity to participate it looks like we're having a little bit of technical difficulty so let me turn to tim for his opening remarks and we'll come back to rachel hi everyone i'm excited to be here today can you hear me okay great i'm going to use my five minutes to touch on general problems and pitfalls with ai model validation um and ai is in in this exciting phase where we have generated a lot of promising sort of proof of principle results on highly curated academic data sets but taking these methods and then applying them in the real world requires very careful attention to detail um and ideally i think new sets of standards for validation hopefully we can touch on that today in our conversation because it's it's current forum it's sort of a new science of course they're sort of old techniques reimagined um but uh because of that it's not always clear what to do and it's it's easy to take shortcuts uh spurred on by impressive preliminary results right and really wanting to to get these into the clinic as fast as possible um but if you don't properly validate them they might not work as well when they get to the clinic in the real world application phase we have of course some general best practices for validation but it's becoming increasingly important that these are more formalized and regulated and that these regulations might need to be domain specific so to illustrate this i'll tell a story um about a colleague who is working on a system for detecting birdshot choreoretinopathy this is an autoimmune disease that if left untreated can lead to blindness and birdshot has some fairly obvious visual signatures if you look in at the retina and take pictures of the retina um and so it's one of these diseases that seems like a prime candidate for ai diagnosis right so you want to go in you want to get screened right but maybe you can help ophthalmologists make these screening decisions by training one of these algorithms to help you with with diagnosis so one day my colleague came to me and asked for help interpreting his network's performance his network that he trained on a data set of you know positive bird shot images and negative healthy controls was getting close to 100 diagnostic accuracy on the test set right so if you're unfamiliar with the test set a typical way to do validation for these models is that you have a data set they're using to train these algorithms and then a held out test set that's supposed to be estimating the real world performance because you haven't the model hasn't seen that test data during training right so it's not supposed to have ios on this test set so it's supposed to be a good estimate and he was getting close to 100 accuracy on this test set um you should always be suspicious if you're getting close to 100 accuracy and he was and so he came to me uh for help and so so what was the problem i reviewed his analysis plan and code and everything was by the book but once we started to review his images by hand we figured out the problem for some reason nearly all of the positive bird shot images in the training and testing set were slightly different than the controls in terms of cropping so not in terms of real image features right that correspond with the birdshot but the birdshot images because they had come from a clinic of specialists have been processed differently than the images they were using for for controls which came from a general duke ehr database um so what that means is that the neural network that was training on these images learned to just use this cropping artifact as a signal for the disease and not actually real image signatures for this disease um which of course is not going to to transfer very well to the real world of course when these images are different so how this is a fairly insidious bug right because he was doing sort of all the things you need to do right have a good training set a testing set right but obviously this would have failed in the in the real world and so how can we try to address these issues and find these problems right before they actually get approved and make it into the to the clinic and there's several places in sort of the full clinical ai stack where you can do different types of validations um for example a best practice here at duke is once a model has been built and trained you actually get it into maestro care right so you get it in the place in the care pathway where where it will actually be run if it ever makes uh makes it to market and then you run it in silent mode silent mode for a time right where all it's doing is making predictions right but in a way that's utilizing the full the full pathway right so there's no ideally probably very unlikely these types of artifacts that could arise because it's it's using the real data as it would see it once it was um in the clinic um so doing that for this birdshot example of course because these images of controls in birdshot would not be processed differently once this method was in the full pipeline in silent mode the model would have failed and you would have known right that something was up um before we even get to silent mode you can also of course get a sense of problems in your data by being very careful about inspecting your data distributions right and uh and properties of your images basically being a rigorous data steward right before you get to training your model um remember that your test set is only good for estimating the accuracy of your model in the real world if the data in the test set looks like data in the real world so it's also particularly important that the analyst is in the loop with clinicians and clinical i.t to make sure that the data are representative right of real data finally in another part of this ai stack the algorithm researchers themselves right have the opportunity to to research and change their algorithms to be robust to these types of errors so for instance if we did have something like explainable ai right perhaps the model could have indicated what it was using to classify write these images and point out that in fact it was not something real and corresponding to birdshot um okay so i'll end here with saying it's obvious why these models have such an allure the results are extremely impressive and have the potential to transform medicine but it's extremely important that we have conversations like this one um and i'm excited to see where the discussion goes thanks thank you and i'm going to press you as uh after dr geiss speaks because i think we have a number of generalists who are um dialed in with us today and a lot of the things you just said um i think could might have gone over a few people's heads at least with some of the messages i'm getting because they don't have a good sense of what some of those ideas mean but boiling it down i'll press you a little bit to unpack for us bias uh talking about what it means to look at data distributions um and how to make algorithms more robust so kind of uh the simplified version of this is garbage and garbage out right but uh the basic idea of some of the concerns that exist with respect to data data quality and suspicions about really high accuracy rates that people claim with respect to algorithms um i think we have dr drelos back on and so why don't we uh see if her audio was working before we go to dr geiss and then come to dr grace so dr draylos how's your audio working now you can let me know does this sound okay yes it sounds terrific so i'm going to jump in yes switch to my phone so i apologize if it falls over it's kind of propped up on my laptop screen um so i'll get back to the uh covid and ai models for imaging um so as i was saying the current gold standard is this rt pcr test but there have been several international groups and societies that have released guidelines for usage of cts and other kinds of medical imaging and covid in general one of these is the flexner society's multinational consensus statement which was released recently and they recommend that imaging is not indicated in patients suspected of having coveted and mild clinical features unless they're at risk of progression but they do recommend imaging in circumstances where a patient has coveted and worsening respiratory status and also in resource constrained environments to help with triage there's also a really nice review paper about chessy teas and covid that was published recently in the american journal of regionality genology i can't say that word and um this one went over numerous studies that have claimed very high sensitivity or very high specificity for ct scans in covid and it identified several issues with these studies and their claims drawing the conclusion that even when rtpcr tests are negative delayed or unavailable there are currently no data to support ct as a replacement test for rt pcr because it's true sensitivities unknown and ct findings are non-specific meaning that the types of findings which are seen in covid can be seen in many other kinds of pneumonias and um so they do not uniquely identify covid with that being said to summarize at the moment imaging in covid is not recommended for diagnosis or screening but it may be helpful for evaluating complications or performing triage and resource constrained environments or possibly prediction of worsening versus improvement and um this ties in with an interesting concept which is that um building a model and and developing it is definitely different from deploying it as one example a covid diagnosis model where you feed in a ct scan or a chest x-ray or some other kind of medical imaging and get out a copic diagnosis could be deployed appropriately or inappropriately an appropriate example that is in line with current medical guidelines would be to deploy such a model to assist with triage in a resource-constrained environment and an example of something that would not be a good idea according to current medical guidelines would be to deploy such a model as a replacement test or rt pcr um so i think that is uh an interesting thing to keep in mind and uh fits in in general with the with the with the concept that it's a good idea to have all deployment of machine learning models be in agreement with with current medical best practices and under the oversight of medical professionals i also wanted to briefly touch on um this is about ethics and imaging um the the notion of fairness and machine learning models i there are sometimes uh i i've heard a hope that because machine learning models are trained in computers that they'll somehow inherently be objective or free from human issues but um in fact because machine learning models learn from data it's very easy for them to become biased and um there have been numerous high profile examples of sort of embarrassing models that people have deployed that have turned out to be very biased but the thing i want to bring up now is that there are a lot of concrete steps that can be taken to make sure that any models that are deployed are fair and um these include trying to quantify the fairness of the model for example using concepts like equality of opportunity or equalized odds um and in these concepts um you can actually get a number out of them to tell you using these definitions whether your model is fair in a quality of opportunity uh this is a fairness metric that measures whether a group of people who should qualify for an opportunity or a group of patients who who should be classified under a certain diagnosis or in a certain label are equally likely to do so regardless of membership in a particular group like race or gender or another demographic characteristic and then equalize odds is another metric that can be used which will be satisfied if no matter whether a patient is part of a particular group such as such a demographic group if they meet certain criteria then they will be equally likely to get a positive label from the model and if they don't meet these criteria they'll be equally likely to get a negative label um so i i bring this up because you can do these kinds of checks on machine learning models pretty quickly to at least get a sense for whether there's anything egregiously wrong going on and then there's numerous techniques in the algorithm design and as well as in the data preparation that can be undertaken to make sure that the models are not going to be exhibiting human problems um so any case i will i'll hold off on my other thoughts but i'm looking forward to this conversation today and thank you great and um rachel you may not have heard me say the same to tim but we're going to drill down in a lot of the concepts that you raised uh i think um we have a quite a few people who are not as familiar with algorithms who are dialed in today and um particularly in disappointments with respect to covid and so i think some of the highlights that you provide i'm going to just unpack with you in a few minutes after we hear from dr geist to get into some of the issues with respect to the ethics so thank you for your opening remarks and we'll turn to dr guys thanks very much uh so you know former supreme court justice potter stewart described ethics as the difference between what we have a right to do versus what is right to do and uh when we deal when i think of medical ethics it's sort of a collection of balances you know what's best for self versus others or we're balancing money fame the ability to influence others versus what's best for patients and society and we're also balancing what's best for the individual versus best for the society and common good from a practical get stuff done point of view uh i i always think about trying to actually specifically write tooth down two things we want to define for ethical ai and medical imaging or even the rest of medicine first is what's the goldilocks balancing point what compromises between things like privacy or distributing benefits and harms equally are we as decision makers comfortable with because let's acknowledge upfront that we're not saints you know ai is going to cause some harm or inequalities you know through data privacy loss if nothing else some people are going to make money off of other people's suffering [Music] i guess more succinctly it's what compromises are we willing to make for the infamous incremental gain of in this case hopefully better diagnosing and treating covet the second point is what are the guard rails beyond which no one should be allowed to go in the effort to get control over covet suppose i said i could stop covid if each of you allowed me to see every part of your medical history every place you've been the last two years how much you drink or do drugs or the details of your sex life you know how about if i say you need to allow me to release that information to the world so i'm curious about where we want you know finding these two things you know where do we want to go and where we just shouldn't go and we might also consider the wiggle room between the two what i call the new york times territory where you might not end up in court but you do make their front page because of headlines with your evil technology i used two different frameworks for considering radiology ai the first is described by a ethicist named floridi who looks at the ethics of data the ethics of algorithms and the ethics of practice and the second is a more operational approach to think about independent verification and validation uh that's sort of a process that was originally started to deal with complicated high-risk things like ballistic missiles but that's to deal with ai through its entire life cycle and here again i look at it in three parts first technically does it work then ethically does it do what's right to do and finally contextually which in this case is does it have a positive clinical impact the current covid pandemic adds wrinkles to our approach suddenly society as a whole is prioritizing short-term survival that's not something we've thought about very often in the past sure we're considered concerned about our individual and collective long-term prognosis but this collective focus on acute actions is way new and it may have changed society's definitions of both the goldilocks zone for ethical radiology ai as well as move the guard rail farther into the new york times zone or beyond uh in the end these points are going to get defined by the people who control the data and build the tools they'll be influenced by public perception to more or less extent but after watching the tech leaders at the regional congressional hearings i assume this public input's going to be less influential than we'd like um you know finally you know i googled rachel and tim and they're just they've got a lot of amazing stuff and so i look forward to hearing you guys take on a lot of these things thanks terrific q for your um opening remarks dr guys and uh your helpful framing between the goldilocks and the new york times uh for us to think about these issues i'm gonna back us up for just a moment um and i'm gonna play the uh uneducated in some ways about ai because i am in many ways about the ways it's being deployed for covet and and just make sure that i have it right so when we're talking about covid um right now as as far as uh the new york times tells me and other scientific journals there's a constellation of symptoms um and uh we're trying in some ways to figure out is there a way to have early detection before somebody or in the pre-symptomatic or asymptomatic period that somebody has covered um we then have when somebody actually has a set of symptoms and they come in or they don't come in and we want to do a test and there's a nasal swab test that we can shove up your nose to figure out if you have it um and then there's a whole set of symptoms that may or may not develop and there's just a whole lot of unknowns is that all fair if everybody agrees with that that we're kind of in that we've got a whole bunch of things at the front end and people are trying to figure out is ai useful in any of this right and um in in radiology in general people have started to use ai uh in at least in some areas right so uh in breast cancer in other areas uh where we're using a whole bunch of images to try to so-called train ai to be able to detect things and detect things that potentially even the human eye can't see or can't see as well maybe earlier signs of breast cancer before a radiologist would normally be able to do so or if a radiologist is unavailable or unnecessary we could use artificial intelligence that has been trained to be able to look at an image and be able to make predictions do i have all of that right so far if i jump in and correct me if i've got any of this wrong okay and so with covid given that we have a whole bunch of unknowns um rachel as i understand it from your remarks right now looking at chess scans of the lungs um is not best practice for diagnosing covid is that fair yeah so and the funny thing is there have been a lot of papers that have been published on machine learning models for diagnosis of covid um so that's a really popular thing to do right now and the thing about these models is that the the way that they're motivated in the papers could be with or against medical guidelines i've seen some papers where they say we built this diagnosis model for covid and we're hoping that maybe it could be used to help with triage in a you know super busy emergency department or something um and then there's other models where they uh bring into question for example the the current practices of using rtpcr test and whatnot say you know maybe we could just replace that with ct's um and let me talk let me pause you there for a minute because we already have a question from the audience about that which is just so that people understand when when when somebody's shoving you know this nasal swab up your nose and down through rgbr but what they're doing is they're looking for some signatures dna signatures is that right of covid what are they what's the pcr test because some people don't understand the pcr test or rp pcr test the implication any of that so maybe you could just explain that in 30 seconds sure um so the nasal swab is looking for pieces of viral rna so parts of the viral genome and um the test itself involves making lots and lots of copies of the sequence of the virus and then um because and that's what takes a while right is the is is the reason that you can't get a test result immediately is that you have to make lots and lots of copies of whatever has come off of the swab to see whether or not those pieces are there it's so it actually can be done in about 20 minutes um i i actually had to have a rapid coping test at some point and they swabbed my nose and then maybe 15 minutes later they had the result so um the actual copying can happen very quickly but i think what's the reason why it can take such a long time several days in some places is more just a logistical problem where you have only one machine and then you have a bajillion different tests you need to run and you can only get so much throughput of the machine so okay so the gold standard right now is that test people are looking to see if ai might help us and uh looking at things like would chess scans help us and if you don't have those tests available does ai prediction looking at the chess um ck scans help you diagnose covet like suppose that you're somewhere where there are no tests available is the ai better than a physician doing a diagnostic and saying you know what like based on your symptoms it seems like you probably do have covered um so i have seen uh one study where they were comparing two doctors and i believe they compared to a senior thoracic radiologist so someone who is an expert in chest imaging specifically and has been practicing for a long time and then they also compared to i believe a fellow who would be um someone who's completed their residency and then they're in the middle of some additional training um and then i think they may have also compared to a resident who was doing their radiology residency and what they found was that the their particular algorithm which was a combination of a chest scan as well as some clinical data was able to perform about on par in terms of um the the performance metrics they were looking at with the senior radiologist and um outperformed the fellow so and this is for copay in particular or just in radiological scans yeah it was covered they took um ct scans of the chest and then they also took some clinical information like uh some laboratory values from blood tests and age and whatnot and then built an algorithm to predict covet or not so it was just binary classification zero one and then they compared to a couple different doctors and um they they found it was about on par with with the senior doctor but i i think there haven't been that many i haven't heard of any cases where there are absolutely no rte pcr tests available but i guess hypothetically if that test suddenly became unavailable then a ct could be well if it was better and more efficient that would be great rain you were about to jump in well i was gonna say this whole deal of you know ai is better than doctors it's it's not that this stuff doesn't work i mean i can build an algorithm there's no question that these machine learning things can extract more information from the pixel data of a medical image than two human eyes can yeah the kicker is that these things don't generalize and so i build it and we see this over and over where i build an algorithm i train it on my own data the validation data set or even if i'm using it clinically is exactly the same i'm using it on my one ct scanner say and yeah it oftentimes is better at you know finding the pixel patterns that correlate to that disease but then i take that algorithm and i put it on another ct scanner or i send it to my friend at a different hospital and it might work and it might not and this is the thing that from a practical standpoint right now is just it's this happens all the time you know so it's um and in a big place like duke where you have hundreds of different ct scanners uh i'm you know i haven't talked to the guys that are doing this there but i you know the other places where i deal with this it's it's a nightmare you know got it how is that each ct scanner has its own fingerprint pixel fingerprint and you know maybe tim can probably and rachel can talk to this better than i there are ways to deal with this but uh it's just because i have a system that works great on on my sort of prototype you know you might even call it a toy that i have it in my one scanner don't conf fuse that with now i have something that's ready for production at scale in the wild well so i've got two questions for you raym um i want to hear from you in one second tim let me do a quick follow-up here because i see you want to jump in so suppose you're somewhere like duke where you have lots of different ct machines could you train the algorithm using um the results from all of the different machines and could could you then have a better model is it just too expensive or two yeah well no that and that's uh certainly if you that's the deal is if you can train it on every different kind of scanner um and that goes back to understanding what data you have in your trainings that's actually what i did with uh always that i put together is just all the ct scanners in the hospital but um just the download time for that data set that was a couple months and then the pre-processing time was another couple months because it was so much data coded when we're moving as quickly as we are but but this is this is just one of the issues right rain for you um you know you're you're one of the authors of uh this important joint statement and report looking at the ethics of radiology and as we're looking at bias and validation of data sets it's really important for policymakers for regulators to be looking at what is the basis of the data that it has been both tested on and validated on is generalizable before you kind of rush to approve it's important to understand is it going to be useful in other contexts other than the single area in which it was trained on is that fair absolutely yeah reality were part of this um regulation process was testing and perhaps even incorporating right a little bit of data on a new scanner right so you know not necessarily requiring that it generalize immediately to everywhere but you know if you're actively monitoring the performance right on this different scanner and there's a potential issue you can detect that and you probably don't need that much more data right to sort of fine-tune the process right for that new scenario and this this issue of things not transferring across sites and instruments is not a ai deep learning thing right so you can go back to very simple you know logistic regression linear models right and you'll see differences across hospitals right across countries right um it's a big problem when you're going from high income countries to low middle income countries right trying to get these models to to transfer and and the idea is you have to basically fine-tune these models change the way they're calibrated right potentially retrain them and modify them a little bit to adapt them to this new scenario so if that's the reality and we have to do this people have the appropriate expertise and knowledge to do that right i mean so i think part of when you're thinking about the ethics of using different ai models particularly if you're talking about under-resourced areas as a way to as it's been discussed in some instances right i mean so if you don't have a specialist available or you don't have a radiologist available could you use ai instead and if that's the case and you don't have anybody who can validate it or test it or train it or modify it or even understand it yeah it's not appropriate to deploy it in that context and i think it's important for people to understand it may not be right there may be some significant it's not as simple as simply saying okay we have a ct scanner and nobody who can read it but we've got this ai machine so we can just plug it in and it's going to give you a response and then we're going to treat you based on the response it gave you right we're going to assume if it says you have it that you have covered it's scary but this is how some people are contemplating it and what some i think regulators and policymakers are imagining might be possible is to approve something like ai diagnostic um you know algorithms deploy it in settings where you don't have experts who are testing validating and interpreting it and not necessarily providing the transparency and the explainability of what's behind it both to the end user but also to the regulator who's overseeing it so how do we how do we bridge that gap right let's assume that um rachel for a moment let's assume that the algorithms actually do get to a place where they are as good as or better than potentially predicting not if you have covid but if you're likely to develop some of the longer term symptoms right one of the things we're trying to figure out with covid is not just do you have it but are you going to be in the population who ends up hospitalized or with you know cardiomyopathy or with longer term lung damage can we start to predict and see the differences of the different pathways people might take and and here ai might be helpful right if we're able to process a huge amount of the differences if we're able to collect the data and start to find trends if that's the case um how do we ethically enable those things to happen rain to your point if they're not generalizable right maybe at this hospital this predicts the pathway but it's not going to be that useful in you know developing country acts or a different country y or even a neighboring state z that has a different ct standard any of you jump in here rachel do you want to start carefully go ahead well i think from a practical standpoint um companies that are building these things are going to want to try to stick with simple stuff because they like you know do you have covet or not because they have data uh that they have labels to go with the images that that most of the time radiologists are providing they if you're looking at something like predicting who's going to have say cardiomyopath some cardiac complications going forward now your label has isn't going to be the radiology report it's going to be following the patient clinically now those so it'll be somewhere in the ehr and it's going to be at a time later than what you have right now to find the ground truth uh this is a difficult thing just i think it may continue rain i'm not that optimistic that we're looking at an end to this anytime soon so it may be that later is still going to be useful um but uh so people like to do things right at the moment at least that are where they can get easy labels you know and i kind of going back to what both tim and rachel have said is that you know i work at with some of the students at carnegie mellon and they all the phd computer science students there often joke that you know it takes them five years to get their phd the first month or two is building their algorithm and the rest of their five years is figuring out the data and the data structures and i think that's um we don't give enough credence to how difficult it is to try to figure out the issues with the data right now to make these things work i mean right at the moment i think we're in a what i call a prototype era where we're building things almost more to learn you know how to do this but because there's a business case involved and the thought that maybe you can make a lot of money doing this that's getting scrambled into this right at the moment and so people are trying to you know in my estimation oftentimes make money off of things that are not as robust as they should be so do you guys have any i mean the three of you have any worries based on the current state of where we are i often hear um you know kind of anecdotally as people are going into medical school you know you shouldn't go into radiology because there will be no more radiologists ai is going to replace all of radiology um or uh you know already you know the there's going to be a substantial reduction in skilling de-skilling of radiologists because they're going to rely on you know ai rather than being able to actually interpret a scan for themselves and if you look at you know ram as you've said you know at a kind of pixel level um ai is going to be better than the human eyes at being able to pick out you know kind of very small and fine-tuned differences you know the earliest signs of breast cancer the earliest signs of um you know kind of other kinds of cancer like you know is there is this a realistic concern on the horizon that they're either we're not going to have you know kind of trained radiologists or that it's going to be just de-skilling you might have a technician who you know kind of validates what the ai says but there won't be a need for that specialty anymore because ai will replace that specialty i i read an interesting opinion piece on this issue um that i believe was written by radio just in california i can't remember his name at the moment but um i i thought it was an interesting uh at least it was an interesting opinion piece to read because um he was saying that at least it was his personal belief that perhaps the number of radiologists needed would go down but maybe the the job description would somewhat change so you could have a radiologist who is an expert in and very skilled and they sort of oversee some automated approaches to doing some image interpretation so um it was at least his opinion that that perhaps the the total number of radiologists might decrease but there would still be radiologists there to you know keep an eye on everything and also deal with really weird unexpected things because that's something that machine learning is currently really bad at is dealing with the unexpected and um humans are are still much better at that in general than um machines are so i i don't think it's realistic to assume that the entire field of radiology is going to become automated because there's um just too much uh there's too many issues with the current models for um for that to be automated safely would you say current rachel right so what about in the future five ten years from now uh if you were advising somebody going into medical school would you advise them against radiology and say like that's probably not your most promising specialty because technology's probably gonna eclipse the specialty i i get asked this question all the time i'm sure you do yeah and uh and the answer is no i mean radiology from the very beginning with x-rays is a combination of technology and humans trying to figure out what's going on inside the body this is another tool to do that a couple of things one the more you learn about machine learning just like anything else i mean it the more you learn about it the more difficult you realize it is but i think it's going to get more interesting going back to your point about you know can i not only use technology to figure out does somebody have covet or not but can i use it to predict some things that i haven't been able to do in the past right and i think a lot of the just fascinating stuff in radiology right at the moment is going to be okay i've got this tool that can extract a whole bunch more information out of the pixel data of a patient's insides what can i do with that extra information that i can get i can do just and i think i can do a whole lot more than i'm doing right now kovid's an interesting example so we can say oh i can look at the infiltrates the sort of white places on the ct scan or the chest x-ray that might indicate that a patient has coveted pneumonia or you know inflammation due to coving but there are also these complications from covid like micro emboli little blood clots out in the periphery of the lung those are hard to diagnose and especially like right now in patients with covid you don't want to do usually the sometimes some of the traditional tests that we do to look for those blood clots uh can i use ai to try to figure that out yeah but you know and i don't they're going to have to be humans in that loop um for a variety of reasons i mean we haven't talked about a lot of the other complications we talked about data set shift but there's just a whole bunch more we're going to need different skills if you just want to sit in a dark room and read scans that's probably not you anymore yeah no you might not want to go into radiology but in terms of the fascinating stuff it is going to be so cool and we don't talk about how robots or ai are going to affect other specialties but you know i mean if i would i think i'd probably be more scared about being a surgeon right then i would be about being a radiologist right now yeah well you raised some interesting points here one of them is thinking about okay so maybe there's these little emboli or other things on the scans but presumably there's also some other data from patients that will help us predict their outcomes i mean we already know that there are differences socioeconomically there may be differences by blood type although i think that's you know kind of up in the air as whether or not that actually means some anything there may be genetic differences and genetic susceptibility differences um presumably there's a lot medical and medical history i mean there's there's a whole bunch of things that may be useful and i assume that despite what rachel said about it taking months to download this entire like enormous data set and we'll get into like how are we going to validate if it takes that long and need that much computer computing and processing but presumably the more data that we could get about patients and put into these sets the better the models will ultimately be if what we're trying to do with something with prediction right it'll start to see trends that we don't necessarily see and as we think about that as we think about pooling a huge amount of information from electronic health records or from patients themselves or you know other kind of information like all of these apps that are being developed for tracking symptoms and tracking information and tracking who you're in contact with etc do you all have concerns about how that data used consented to by patients stored shared um you know what what are the risks uh to individuals and to society of the collection and use of this data and i know this is some you know some of the things that you address raim uh and the group of people that you wrote the ethics artificial intelligence radiology the summary of the joint european and north american multi-society statement gets to some of these issues but i'm wondering if you all i know rhame has if you guys have thought about this issue of how do we ethically do this gather these huge datasets without posing a risk to the individuals whose data is being used to do so i could go on all day but tim i know that you've got some interesting things and rachel you you talked about this already weren't you guys why don't you each hit on it because i think we've got about seven minutes left we have we have one more question some of these are questions that i'm bringing in from audience members by the way if you are watching continue to send your questions to tim mcdermott or to ben shepard who's fielding them to me um but rhames did you since you're part you know isn't your uh lead on this summary statement why don't you kick us off and then um and then we'll turn to tim and rachel to comment on this issue as well because rachel already was commenting both on the collection of the data the huge data she's pulling but also some of the privacy concerns and i know tim has thought about this from um data use and collection and storage i so you know in summary no data that you release are going to be anonymous it's just a matter of how expensive they are to re-identify for variety of technical reasons um and those data are going if you release data it's fair to say that those data are going to get used in ways that you didn't anticipate um so this is a a real problem that we see in doing that one of the practical solutions that we're doing in radiology is instead of releasing the data to the algor sending the data to the algorithms like letting data outside of duke's firewall and giving it to a company to do something we say okay you bring your algorithm inside my firewall you know bring the algorithm to the data and you know we'll run it inside but we're not going to let you actually see the data even then you probably have to do some things to your data to keep the quasi-identifiers small the american college of radiology is building a thing called ai lab where we'll actually do that for a lot just about every imaging site in the united states because we already have those pipes for accreditation um and so i think that's one way to keep the data private uh but i i mean i'm very concerned about this you know that sort of 360 view of patients from all the different kinds of data i mean anybody who does that right now would love to be able to add medical data to that 360 view and and we see this right now with people reusing the data and reselling it once it gets out there it's interesting that the ai lab sounds like an interesting model i know a number of different kind of industries are thinking about a federated data model or having some sort of entity which might be an entity that safeguards the data and you know firewalls the data people can come in and query it but the data doesn't leave um but i think this suggests we need a data solution right before simply um you know continuing the process of researching uh without having a clear idea of uh how do you consent the patients how do you firewall the data how do you deal with attacks against the data and how do you think about the 360 view what the implications are for um invasiveness to the individual tim i see you're nodding and i assume you you you have some thoughts on this issue an additional point which is um one thing that's been frustrating over the past few years is these methods have been taking off in in medicine is that unlike other machine learning data that is typically released with the paper right with the code right so that people who are interested in you know rigorous validation and reproducibility go in and find the data and run the code um right to double check all of these results and to not have that option for most mathematical data sets can be not only frustrating right but also potentially damaging i think to to the entire enterprise and so finding a solution in which that's somehow possible right in some way behind these firewalls right i think is important right so not just training and storing but also providing access to others right right yeah i mean so we both have to safeguard the data but we also need to find ways for people to be able to validate and review and review the data but you know but potentially by behind firewalls rachel please i cut you off oh it's all good i i was i would actually also argue for sharing data openly whenever possible so there are lots of different you know even for medical images there are lots of different data formats and they come with different potential risks so for example if you share imaging data in dicom format then anonymization can be really tricky because you have to account for all these metadata fields that can include protected health information whereas if you share the same data just as say an array of the voxel data then at least you've eliminated the risk of accidentally sharing information through the metadata and um and at that point the concern would be would you um be able to identify someone and do something malicious on the basis of their chest image um could you you know from just that image alone could you could you identify the person or you know what's up with something burned into the image um but that that becomes a lower risk than say releasing the dicom and i think one advantage to sharing data openly you know when it's feasible to do so in a way that protects privacy as much as possible is that it gives a lot of people the opportunity to work on the data set and and as they work on the data set they can identify any problems with it or they can kind of collectively work on getting better models on the data so there are some advantages to being more open um and and it can solve some problems to allow more eyes on the data set i think these are really good kind of points and counterpoints right which is good science is responsible science responsible science requires that you'll be able to validate the data and validate results and the only way you can do that really is by having some form of transparency explainability understandability and access to the data to be able to do so so trying to find ways to balance those sound like they're really important we have just about um 30 30 seconds left here i want to um but first thank you all for this really enlightening discussion there's so much more for us to dive into but i was hoping we might just take a few seconds from each of you uh for you to tell me kind of most optimistically uh what would you say in in two sentences or less is the is the role of a.i um in radiology for getting us through the pandemic and so rachel why don't we start with you uh i would say that the role of ai and radiology for helping us get through the pandemic is uh as something which has the potential to help with perhaps predicting future outcomes um or triage and it's a tool that maybe could alleviate some burden on clinicians if it's designed very carefully with uh clinical application in mind great tim yeah i think something that's in reach um and this is related to triage uh you know there is this scenario in which we have no tests right and then you want to try to use the chest x-ray as a test and that's probably not feasible right but there's also another situation we seem to be in now which is maybe a limited supply of tests right and so can we use the performance which might not be perfect but could be perfect on edges right like the model is 100 sure this person doesn't have it or 100 sure they do right and it's this middle right of your calibrated model that you're using to to assign these resources which might be scarce makes sense i think you know going back to that if we say that we're in the prototype era for these things right at the moment i'm leery of saying oh let's put one out in the wild and say we're going to use it you know at scale to do something i think it's more deal that we're going to put them out there to learn things but i i wouldn't confuse that with saying you know we just shouldn't advertise these as being a solution right at the moment yeah that makes sense well so maybe one of the ways through the pandemic is that we learn a lot which will hopefully prevent the next pandemic um all right with that note i want to say thank you there's so much more for us to discuss i would encourage even post um this uh conversation for people to share their thoughts and comments uh with our panelists thank you for joining us again uh please tune in for our next coronavirus conversation uh and go to science and society at duke.edu in order to learn more about both our offerings and future sessions thank you all and have a good afternoon thanks very much 