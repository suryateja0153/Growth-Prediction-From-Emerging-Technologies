 hi everyone we are here to show you a brief  overview of our new product galileo xai   a graph platform for data analysis based on  artificial intelligence network science and other   innovative approaches to make the information and  knowledge produced understandable and reliable in   order to support decisions define new strategies  automate processes and create new business   opportunities this demo focuses on the new  galileo xai feature responsible for explainable ai   implemented with fujitsu deep tensor we are using  a subset of the darpa intrusion detection dataset   so we are talking about dos type cyber  attacks galileo includes a rules engine   future for automatic event handling that  allows users to specify business logic in a   declarative manner each rule in the  monetary and executed at scheduled intervals   in this page we can see one defined rule and now  create a new rule by clicking the plus button each rule is currently defined  using the cipher query language   but we are experimenting with the native language version and here we can see the newly created rule  with its name description frequency and statute   in particular we can notice that the frequency  is every 10 minutes and a first execution is   already started behind the scenes the eyelid  function displays the results coming from the   execution of each single rule for this data set  it extracts patterns of suspicious or abnormal   activity this is the list of the extracted  patterns grouped by date let's see the alert list here i can assign a pattern to  myself and then visualize and   investigate a graph before setting  the outcome as significant or not as we can see here galileo integrating  curious in order to let the user visualize   and analyze each alert as a graph this  graph pattern looks like a real cyber   attack and we can understand it  better by changing the layout   here we can see the server  in the middle of all around   the network of both that are floating  website with too much traffic so now we can review the alert and confirm  it is a real attack also this future   comes from the integration with lincurius   but what's the problem here in order to review and  complete this activity we need a team of analysts   that every single day investigate the alerts to  confirm or dismiss them a really expensive effort   in terms of time and resources that can be reduced  using ai so let's start the deep tension process as a first step we need to train the  model the space is necessary at the   very beginning of the process or each time  we decide to retrain the model with new data   for example when the analyst saves classified  new malicious patterns as we saw previously   moreover in case the graph  doesn't contain enough knowledge   to train the ar engine we can run the  training phase with an external data set as you can see there is an already recommended  configuration automatically determinated by deep   tensor these are tailored to the structure  of the graph selected for the training   settings can be changed but in this execution i'll  reset the configuration to recommended values now   we are ready to launch deep tensor and we can  see three distinct running phases the training   phase the engine trains the model to match the  patterns defined in a subset of the training data   the validation phase the engine tests  the model against a different subset   of the training data the cross-validation  phase identify overfitting of the training data   now that the elaboration is finished the confusion   matrices relative to the three phases are now  available and also the two chart representing   the step loss and gain a currency for the  bot training and cross-validation phases in order to evaluate explainable ar we'll  look at the explainable table that allows us   to investigate the results produced by the tensor therefore it is possible to select a subgraph  and understand whether it is an attack or not with a separate of chromatic palettes  and a proper visualization algorithm we   can see that there is a central  node with many incoming edges   and we can evaluate which elements deep tensor  weight most in order to classify this case red   colors represent information used by deep tensor  to determinate its outcome on the opposite blue   colors represent information that deep tension  considered not so significant to process this case   now selecting a true negative and changing the  layout we can immediately understand that it   is not an attack in fact we can see a sparse  graph without any central node coloured in red this allows us to understand how fujitsu did  tensor obtains a transparent decision making   process after having trained diptension clicking  on the calculate using your dataset button   we can feed it with our complete   data set in order to obtain an outcome for each  case not yet investigated by the honest team we obtain a score and the expandability view  on all alerts not yet classified by humans   which indicates whatever this is an attack or  not let's take this one and as we can see now   the graph is enriched with explainability  part represented by colors so ultimately we   saved a lot of time and resources supporting the  analyst team that's all for the demo feel free   to reach us for any following questions about  project thank you very much for your attention you 