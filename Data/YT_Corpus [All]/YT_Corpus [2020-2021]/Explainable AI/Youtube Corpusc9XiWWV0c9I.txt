 hello everyone hope you're having a good time here at spark a summit 2020 thank you for being here my name is vishakha Sharma I'm a principal data scientist at Roche and I will be co-presenting our talk with my colleagues Yogesh pundit who's a staff software engineer at roche and johnson labs CTO David tell me and the title of our talk is automated and explainable deep learning for clinical language understanding at Roche in the first part of the talk we will cover why patients and doctors need accurate and automated natural language understanding at scale in the second part of the talk we will cover how we build deep learning and NLP deep learning NLP and OCR models and pipelines that address the challenges and the last we will cover achieving state-of-the-art accuracy on real healthcare data introduction full disclosure Roche is a happy person or chance to lapse we are presenting this talk to give a high-level overview of the roles of SPARC NLP a product from John so lapse nothing contained or stated here in during the presentation constitutes a Roche endorsement of John so lapse products a Johnson lab is fully responsible for accuracy and completeness of any statements related to Johnson labs products including the products performance to tell you a little bit about rose it is a 120 years of 120 years old company with headquarters in Basel Switzerland it has two main business divisions the diagnostics and pharmaceuticals it is number one in in vitro diagnostics and a leading providing of cancer treatment world one within Diagnostics we are a team called diagnostic information solutions our our primary focus is the Nephite decision support portfolio where we are working mainly in oncology Navis ITB tumor board is a cloud-based workflow product that securely integrates and displays relevant aggregated data into a single holistic patient dashboard for oncology care deans to review a line and decide on the optimal treatment for the patient the clinical decision support apps ecosystem is secure and fully integrated with Navi fight women pool we have three clinical decision support apps Nerra file guidelines verified clinical trial match and never fire publication search for a cancer patient a large number of data points get generated along their journey for example genomics pathology radiology their clinical data the goal here is to navigate through the complexity of patient's journey and generate a longitudinal view by unlocking these data sources and for more comprehensive view unlocking on structured data is very important because a lot of the time a lot of the time this has diagnostics and treatment information these data allow us to clinical to do clinical decision support and population analytics for this talk we are going to focus on the unstructured text data in the pathology here is an example of pathology report pathology reports are very diverse or they have jarvan's tables key value pairs and handwritten notes if you see on the right side which is a sample report from pathology to me in a lot of cases in a lot of cases when a sample report gets reviewed by a pathologist it looks like this how many of you have seen something like this this is handwritten text and if you read closely you can see they are talking about demo site humor staging ICD codes and a bunch of other things all of these annotations make this report extremely valuable but the challenges how do we extract all this information it is quite clear after looking at these reports that along with NLP we will need OCR to efficiently extract information what is NLP natural language processing is a field of artificial intelligence that has computers understand interpret and manipulate human language NLP draws from many disciplines including computer science and computational linguistics in its pursuit to fill the gap between human communication and computer understanding what is OCR optical character recognition is the recognition of printed or written text characters by a computer so we need natural language processing with high accuracy specialized for medical data when didn't minimize time to Train models and that can be extended for new content types we need OCR with high accuracy and ability to retain document structure like tables list and bandpass we had a bunch of requirements from tools and services that would help us achieve this task or needs like scalability compliance low cost ability work to run on prayer or in the club the success of NLP approaches heavily depends on being able to understand the domain and as a first step we want to identify named entities from the domain-specific documents these entities are highly specific to the use cases healthcare data is extremely heterogeneous and complex and requires high quality quality labeling data and domain expertise and that can be very expensive and time-consuming for any organization at Roche we have extracted more than 45 oncology entities from pathology reports here are few examples of a surgical pathology report from patients diagnosed with lung breast and colon cancer the highlighted text shows the entities of interest and its associated labels the first example shows the diagnostic information of a lung patient lung right upper lobe lesion ciolino carcinoma moderately differentiated where love is the location and right is electrology wedge biopsy is the procedure and two point five centimeter is a size of the tumor and it says surgical margins are not involved the second example shows the microscopic description of a breast patient histologic type is invasive doctor carcinoma with metastatic features areas of sarcoma toid carcinoma histologic grade his not mention an overall grade is three in this sentence we have labeled invasive ductal carcinoma as cancer type and sarcoma toid carcinoma also as cancer type and three is lip three is labeled as script so the last example shows the clinical data and pathologic diagnosis of colon patient cancer location is ascending colon mass and final diagnosis says right colon with appendix he moved hemi khalaqtu model colectomy to add to adenocarcinomas proximal ascending and distal ascending colon so if you see this example you see multiple mentions of style localization and procedures and our approach has been as first step categorizing the content broadly and as possible and this helps us achieve I recall with entity extraction and with then in next step drill down into achieving higher precision by mapping entities to standard concepts ners in simple words is entity extraction and is a sub task of information extraction that seeks to locate and classify named entity mentions in unstructured text into predefined categories such as tumor site timely humor etc spa NLP provides both CNN by lsdm and biobot implement and we have trillion models to extract more than 45 labels from the pathology reports CNN by Alice diem is a novel neural network architecture that automatically detects word and character level features using a hybrid bi-directional lsdm and CNN which is a convolutional neural network architecture eliminating the need for most feature engineering and bird stands for by direction encode of representations from transformers unlike recent language representation models but is designed to pre-trained deep deep by directional representations from unlabeled text by John Lee conditioning on both left and right context in all layers by overt is the first domain specific bird based model that is pre trained on biomedical domain or corporal and fermented strikes and TMC full-text articles so let me hand it off to Yogesh who will tell you more about our virtual thank you so much for the background osaka so so let me briefly talk about how we landed on this approach let me again to get into a little bit of background so when we started we started off with a more traditional entity recognition approach like CRS and it worked really well for us when we had like a small well labeled dataset but as we started to expand beyond domains like from pathology radiology of the genome a sort as we started expanding beyond cancer types this approach started to craft training was taking much much longer you couldn't efficiently leverage word embeddings clinical world and buildings and transfer learning across domains and cancer types was was not efficient so so that is when we started to experiment with the CNN based approach and it has been working really well for us we use a spark energy based implementation of it and you've been able to achieve good results with it it is also a state of the art implementation based on certain publicly availability customs so the next next component in our in our workflow is optical character recognition so so vishakha briefly introduced introduced this but let's quickly reiterate optical character recognition is basically being able to convert PDF or images with text within PDFs and images to form or machine readable text so the goal here has been like as you can imagine right to be to be able to consistently convert PDFs to to text that are machine readable either actually in the domain of pathology and genomics and radiology so to evaluate a system like like an OCR we used a combination of matrix starting with character error rate which is which is nothing but the minimum number of operations required to transform your reference document to your output text so then we also evaluated it based on a word error rate which is nothing but how many words of substituted or deleted or or inserted between the reference document and the output text so as you can imagine like evaluating based on word error rates it's it has its own challenges like dealing with spacing or like dealing with the lens of word sequences so because of that we also looked into a slightly slightly more advanced matrix which was based on bag of words so instead of evaluating word error rates we looked into evaluating bag of word error rates which is which is as you can imagine just of just a bunch it's a multi set of words basically so each of these matrix we measured against a bunch of hozier system parameters like like engine mode which which tells you basically if the document is plain text or if it has an image layer on it then then something at page segmentation mode which basically tells you if the document has just like a character on it or like a blob of text on it or does it have Abel's on it or something like that and then some other factors like scaling of to layer on the PDF and erosion now of that so overall based on these matrix and against the ground truth that we basically generated ourselves we landed on a set of values for the parameters that that has been puffing performing really well for for the data that we have so this is kind of how we experimented and optimize our OCR Python so the next component within the pipeline is entity resolution so we spoke about named entity recognition and we spoke about OCR but with just these two approaches you cannot get a structure or the fun structure text so what is entity resolution so entity resolution basically is removing duplicates normalizing data base and big waiting records that correspond to real world entities across within your data set base it so so this the what you see on the screen is just an example of example of concepts and the codes for those concepts so the idea has been that we've been exploring is using clinical word embeddings and the chunks resolved from entity recognition we try to resolve these chunks two to one of the concepts within within a standard terminology so like you would imagine or like you would have multiple models for your entity recognizers you would need to have multiple models for your entity resolutions depending on the terminology that is being being used so now that we've discussed the techniques that are at play here let me talk about about the process so what you see on this screen screen is on the left side we're talking about like labeling data and building the models and on the right side we're talking about deploying the models and like serving the models based so so there are many elements here so far for building the model in an automated manner we we stuck with old fashion Jenkins which use for orchestration I mean the primary reason was this is readily available in our infrastructure so we start with Jenkins another choice we made was to stick with Jupiter for for of course for our exploratory analysis but we also stuck with it to run our pipelines so what we do is we use an open source tool called paper mill which basically parameterised is our Jupiter notebooks and we can just run them as like command line scripts in in our Orchestrator so so this has made our workflow fairly fairly straightforward so we didn't did not need to maintain a notebook and then maintain scripts that that basically run run in our state universe basically after that if you can see if you see on the on the diagram we use ml flow for tracking our parameters our performance and blocking our artifacts so this this kind of gives us the ability to compare pull and deploy any artifact from any of our historical runs and after that we deploy the model basically in a container which which is sort through a model server and then it is sort through two EPs so this is more for our sandbox kind of an environment when we move towards production izing this it is a lot more manual because we are in a regulated kind of an environment so just to continue on the workflow this is kind of a zoomed in view of what what the consumer off of all of all of these techniques and techniques put together what kind of kit so that's the slide basically tells you like if you have a PDF document you would need to run it through OCR which brings you back on the text and if it is not a PDF document of course you don't need to need don't need to use OCR this text then runs through named entity recognition models you could have one or you could have many and that basically fetches you all of the entities that model predicts and after you get these entities you will hit them to map terminology AP ice and you basically have them resolved to standard terminology so there is an edge lambda that we have in place that basically orchestrates all of this so the end user only needs to deal with input as a document and output as structured data so so you might wonder right I mean looking at the whole pipeline how much of code one would need to write to kind of get a model Ronnie so fortunately it is not a look at this is this is a snippet of code from spark NLP you can see this there is a model being built using bot embeddings and deep learning based entity recognizer so our pipeline looks pretty similar to this of course there is some boilerplate around it to get things going but the the training of our model is is as simple as what it is so this has really helped us keep things simple and we've been able to reiterate with with changes or experiments are much much faster so having having said that so I just want to conclude on this section by saying that this whole NLP process it has kind of been a journey for us we started from scratch and we've been working towards expanding to two more domains and trying to automate as much information extraction as possible so we want to we started like like the chakra introduced we started with pathology and we're working towards a lot more domains like radiology and genomics we're hoping to leverage what we've learned so far to kind of scale up or to this new challenge so now let me hand it off to David who will tell you more about spark NLP which is the tool that we've been using or our haul of hard work Thank You yesh and hello everyone what I would like to talk about is spark NLP is a library which is a wish I could explain one of the enabling libraries for this project in these kinds of use cases so we hope that this will enable you to understand how you can best use this for your own projects for the general case if you're working on end up in healthcare yo if you really just working on this type of very domain-specific takes understanding problems on one hand you want to start with state-of-the-art algorithms models implementations but on the other hand you also know that you're waiting to train your own took you need to answer specific questions that you need answered from text so spark NLP is an open source library its goal is to provide the the industry production gate implementations of a state of the MLT research is so so what the team does is it reads the the latest Reapers latest research tries to it would you seek hey whatever doesn't produce and generalize it becomes part of the product and grade a product spangly P is an open source library for any Python Scala and Java API is he also had an ecosystem and comes with more than 100 in pre train models and 325 lines which you can nearly just activate within three lines of codes in nowadays it's a very active community a super 20 sticks new releases in 2018 30 new lists in 2019 he and the same pace is continuing in 2020 in early 2019 Sparky will be became the most widely used and lt library in the enterprise and the just a couple of weeks ago O'Reilly published 2020 a doctrine in the enterprise surgery in once again Spartan B is a by far the most widely used in the library I mean in production production and possessions yo top of spark will be the product that was used to build this project is a Spartan LP for healthcare which is an extension which is required because is I think you've seen here in medical NLP biomedical NLP is a different problem than general language NLP all the way down to having different company search papers conferences even benchmarks to deal with it it's - there's a it is really there's a different code base and different set of models in the delivery of state-of-the-art clinical and medical and dissolutions as you can see here it has the entire the same entire base which we talked about which you can use for anything else but then it's health to receive specific first of all things that tokenization part of speech in spell-checking and even segmentation and then on top of it recognising clinical entities and for example the agenda so here implementing clinical entity linking so doing the entity resolution is explained in being able to make anything to go to specific code in a medical term finding that start to solve an assertion so it's very nice that we can extract the term diabetes but for most use cases if we cannot tell between patient is diabetic patient is not diabetic suspect suspected the abilities or you know our patient is a family history if there be this so if you cannot tell between those four it's almost useless to have just the term if you know patient risk matching patients for clinical trial you know recommending isn't it just notify the best next section from a clinical decision supports it the other very important features like the identification of both structured and unstructured data as well as the OCR capability here which will simpler on top of its public NLP comes with more than 53 training models in some of the main buildings some of them are you know any our models assertions status models and tinking models but very important is you've seen is the ability to train wrong because most often if you're interviewing health care setting and your specific specialty of specific use case you will want to two new models to extract specific for example specific entities in this use case we don't care about symptoms problems drugs became about the specific size materiality he stole og of the tumor and then the question is okay how fast can you get to a point will you have a very high accuracy more than four be specific uses so in general in the design of sparking will be a struggle before healthcare and sparkles the other three main design go into accuracy scalability in speed with accuracy we say state-of-the-art it's it's not a marketing term it's an academic term yeah which means that algorithm is a state of the art if it really provides the best accuracy achieved on public academic benchmark in papers so basically this is the best that the research community has been able to produce in a verifiable manner and you can see this is definitely much better than other other libraries they really be just by adopting some of the latest advances in transfer learning it sounded really new things that have happened in the past two three months he released to the 2.4 release the deep learning algorithms which was reworked enabling fold out the biddings spark OCR he now has 20 different annotators to be able to pre-process an image so he s mentioned things like erosion scaling in now he knows to do in a noise reduction and the automated scaling skew correction in another in algorithms that enable you to improve the accuracy of the image before you try to extract text in clinical entity resolution now it's also being in a completely world to newer and more accurate algorithms actually enabled aiding in new models is such as making to larger terminologies like salami blowing can Alex Don which are now also available out of the box two point five things have been added really just a month ago is integrated support while built in accelerating buildings in to new in tasks for which is Tony P non-believers we need state-of-the-art results as of 2020 still shaking and sentiment analysis here which which really because it's trainable enables also broke the motion detection in terms of scalability so spoken LP is based on apache spark and such it can it's really the only way to get a distributed open source energy library you can run into a name spark cluster yeah also one important thing especially in healthcare setting when you being with patient data a using this it's just libraries so this is not that as a service offering you don't not need to send your data to the quality in which case its own kind of compliance reading privacy issues you can run it on your own local machine on a container which you really need to scale you can scale on a cluster and the bench ones that you see on the right is it just from a double your CMR with really zero code changes and this is kind of the whole story behind this benchmark if you like to produce it is available online a apache spark really benefits us here because it deals with all the really nasty issues that come with distributed computing like minimizing traveling a optimizing caching minimizing the amount of bandwidth that we was doing execution planning of the whole pipeline before we actually run it so a lot of it was done with the artistic community in the data bricks team to make use of those and make sure that's part continually squeezes the most out of the harbor which give it of course that distributed computing is not magic and the speed-up you see depends heavily on the use case so if you're doing inference focus until you feel like it's a nearly linear speed ups but if you're training say you know in an RNN which is by nature more iterative when you see suddenly now speed ups in terms of speed want the other thing that sparking will be slow team is making sure it's optimized for the latest and greatest Huggle platforms and specifically the ones from Intel and NVIDIA so Nvidia obviously has a GPUs and it is several generations of them in each adding different types of memory architectures and even instructions in Intel in the power three years we'll started releasing chips that have deep learning specific instructions and one advantage it says it it can use more memory then only the memory on the GPU which definitely helps in some use cases a society has optimized build for both Intel and NVIDIA in this specific use case it compares two generations of internships and the Tesla T 100 for specific case for a specific use case we saw straining initial model a for the French language in Intel actually them to be about 19 percent faster and almost they have priced on AWS compared to compared to Tesla so in this specific use case we don't just use the open source panel people use part in T for healthcare so what we also care about the Kate how accurate is it for these use cases and the two most important tasks are recognizing clinical entities so we can we actually correctly extract the entities or the audio ports and then can we correctly resolve them to medical technologies so clinical entity recognition so by the way both of these algorithms have a different implementation within the healthcare a code base because that is that will get you state of down within this domain and as you can see when you compare state-of-the-art nowadays that she's become really nice does the energy progress online which actually would list the papers and the benchmarks will tell you what is the state of deities of today and those papers with codes and have some really nice freeware websites that enable you to keep track of this pace which is amazing because it's moving amazingly quickly in the past couple of years you know what when you if you publish your academic paper and you claim that you have a state of Terror results you likely to be at the top for me or maybe 8 to 10 weeks which means that our globe to actually catch up with the state of the art is really means if you just have to keep running right and keep adding new things not just to keep taking advantage of all of these new innovation which is fantastic yeah so here you can see some public mint marks on entity mission he really shows that nothing in this is the next to latest version stock an LP which produces out-of-the-box from public benchmarks a the highest accuracy if understand those commonly later sets and what was important the loss a newscast was not only that but also the fact that if you contrast for example to just you know only using three training models sparking to be is trainable so what we were able to do here is general training data using clinicians for specific on quality data right and then may be able to you know model right so we're still using the same architecture we can use the bio bells and semi buildings but we can produce the highly accurate model focused use case which is a unique up to be if the second important task is entity resolution and that's another thing that you need to do attending P stage because you need you want your system to know for example at renal failure in the Christian function really the same thing in health there are many many ways right what is essentially the same thing yeah so if you don't know my eyes and you just use the entities as they are instead of mapping them to standard terminologies yeah the problem is noticed integration with other systems it uses those codes the pony is that a much shallower feature space alright because really what's what you the way you want to use it is okay look if I if I know this is you know insufficiency you know that that increases patient please that may imply how I treat them okay and three different ways to write it is completely separate features that I cannot connect and that's something that you want to do at the text level at the MLP level and this is also something that it comes out of the box with Spartan before filter but also trainable so for example if you're looking for specific tumor characteristics in this case we can train a model to just just achieve those here also here you can have public benchmarks on to back unto the academic data set so share and NCBI in the in the car numbers out of the box folders so if you want to learn more or just try to understand yourself and one nice thing that's available in our post-punk indeed I'll echo lab notebooks yeah if you look at those those things here which is basically either blue cones which Johnson Labs slash star canopy workshop underneath you have public notebooks and when you open up a bit laughs there's one but and it says running Cola and then you can run in within your own Google account so there's really nothing to convinced all Lucetta they need to show you both how to use pre train models and then how to train your own models in different kind of cases which is a great way to get started a other than that if you're working in healthcare definitely you know consider trying Spartan before health care if you're working in another domain that requires you to train your own model is weakening eagerly waiting in finance waiting insurance a the best thing is probably start with a open source library and see how what's the smallest number of documents and extreme examples that you need to give in order to train a to model for your domain and I think that what you'll find is that that number has gone down significant in the past few years with advancements in transformers and transfer lane yep any other questions we'd be happy to be able to answer them please get in touch with us yeah there's a we're always interested and you know what people are doing in regardless there's a very active community that you know will most likely be able to answer your question whether it's a simple out of memory issue or a bigger question on how we would get the use case done so with that thank you very much and we'll be open for questions you 