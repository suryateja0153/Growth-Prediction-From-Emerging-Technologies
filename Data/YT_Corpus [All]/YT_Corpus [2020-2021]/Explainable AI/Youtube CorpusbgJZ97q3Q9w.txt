 So this is my presentation and I'll be brief so as to catch up some of the time and I'm pleased to represent the University of Maryland, next slide please. and the image computer interaction lab the interdisciplinary community that is celebrating its 37th year. I was the founding director but we're now on our eighth director Niklas Elmqvist. We have partnerships with many other groups on campus and you can see more about there's a thousand tech reports on our website, 200 project pages 200 videos and lots more information, next slide. so just to take back a little breath of air this is the view from Vancouver here where I am right now where we found it more comfortable to self isolate here and so that's sunset that we see over the water it's quite a beautiful place meant to give you a little reflection and take on a broader view, next please. The whole excitement about artificial intelligence has provoked a you know huge number of books some of these are the more famous ones that celebrate the great things that are gonna happen from AI but also fear the dangers the loss of jobs from automation, runaway robots and machines that take over and leave us in a weaker position. There's many counters such as Cathy O'Neil's, yes please next slide, Cathy O'Neil's excellent book Weapons of Mass Destruction, the recent book on rebooting AI talks about the problems with AI and proposes a solution to go further and a maybe more critical view is The AI Delusion Gary Smith, next slide. For a thoughtful analysis of how we might produce a more human centered AI that is based on governance processes there are an excellent early report from this year that focuses on eight themes privacy, accountability and so on but I want to turn attention to human control of technology as a clear message and promotion of human values and that's what this session and that this workshop was all about, next please. So you know the other side of the coin I see is that HCI pride that HCI has been I believe the driving force for making sure that six billion people have access to information through mobile desktop, web and cloud and we've done that because we've been very inclusive in many ways continue next, and it stresses and the three million apps in the Apple and iOS app stores are built around the principle of user control that people not apps are in control and that's a strong strong principle that's very different from what you see from many other commentators and the second principle that I want to stress is a flexibility to give users complete fine-grained control over their work, next please. So that's stronger I think than many of the AI design principles which I want to change. The two I have focused on humanoid robots which have long been wonderful demonstrations and provoke great interest but few commercial results. Maybe crash test dummies and medical mannequins are the outcomes but the successful products have shifted away towards appliance-like designs which are more human censored and sometimes the dangers of excessive automation may be highlighted by the 737 max crash in which this autonomous system was not even presented to the pilots for them to know about next please. So what I really want to advocate and human-centered AI is about amplifying augmenting enhancing and empowering people next and the goal is what it's always been for technology thousandfold improvements in human capabilities. That's what the web and information resources do that search does, navigation systems, digital photography and other tools that's what we want next and the goal and the driving force I would say is reliable, safe and trustworthy next so that more people are more creative more often next and promoting self-efficacy and societal benefits. My recent paper that clarifies how to do this has already drawn more than 4,200 downloads and that's available there and in the journal international journal of human-computer interaction, next please. So let's just again take a little pause but let me move on quickly here, a relaxing pause. The notions about autonomous systems were really promoted in 1980s by Tom Sheridan, a wonderful MIT professor whose important work was greatly helpful but he advocated a notion called levels of autonomy from totaly human control to total autonomy of the computer system: total computer control and I was absorbed in that notion and then the 1986 version of my book, I had a section called balancing automation and human control that was a central idea that you had to choose a point on this continuum a one dimensional model between human control and computer automation and for many years myself and many people believed that that was the way to think about it you had to give up human control in order to get computer automation, next please. However I became aware that there was another possibility and I began to write in later editions of the book ensuring human control while increasing automation which seemed like a puzzle to me and to many of my readers but the notion was simply to break out of the one-dimensional model and to suggest that there were two dimensions. Human control and computer automation were separable dimensions next which we might represent as a two dimensional layout and my suggestion is that you can have high levels of human control and high levels of computer automation, next please. We see this in simple devices like maybe not so simple but elevators or your digital camera. Your digital camera has a high degree of automation in it but it also gives you a high degree of human control it automates the things you want automated like the focus, jitter and lighting and gives you control over things you need which is the composition, the zooming and other factors, next. There are times where we need full computer control. These are special cases like heart pacemakers and airbag deployment which requires to be done within 200 milliseconds next but there are times we also want human mastery and we want total human control and no automation such as riding your bicycle ,playing your violin or piano next and you know oh we've gone a little too quickly back up one there we go but there are dangers also of excessive human control and dangers of excessive automation so excessive human control often leads to interlock devices such as your self-cleaning oven proceeds normally but once the temperature reaches above 600 degrees Fahrenheit it's impossible to open the door, the door is locked because it's too dangerous. Similarly there are many such things on aircraft and automobiles that prevent humans from making mistakes. The other problem is excessive automation such as 737 max I've described, flash crashes on stock markets and other mechanisms. So let's take a look at how we might design for this onwards, next. If we think about this four level approach to pain control designs the old, old fashion of low human control and low computer automation was a simple morphine drip bag simply provided a city delivery of morphine. However it could have been excess or insufficient morphine. Therefore next, we could have an automatic dispenser which would control and maybe limit it, but then you might not give enough medication because pain is not detectable or measurable in an ordinary way next. So another strategy was patient controlled and PCA or patient controlled analgesia was a popular mechanism and still remains so where the patient gets a trigger to be able to deliver increased amounts of morphine if they need it but there's limits you can't get more doses than are healthy for you within a limited amount of time. However next please, there are still more sophisticated ways where it could be patient guided rather than patient controlled by clinician monitor and a hospital might have a control room that monitors let's say a hundred of such devices to detect failures, to understand patterns to see if anything's going wrong so the reliable, safe and trustworthy approach has a more rich structure of supervisory control, another phrase introduced by Thomas Sheridan and I think you can see through this diagram that there are many different forms of design and the idea is to open our minds to more than just a linear possibility and look at the two-dimensional possibilities, onwards next. So you know we can also see this in self-driving cars. We started with low automation and low control 1940 cars next and we went to 1980 cars which had higher levels of human control and richer features and functions that enriched the capabilities of the driver next, and we see in the 2020 car we've gone to self-driving cars which have high degrees of computer control but insufficient human control in many circumstances and next the vision I see for a 2040 car is where there's a proper level of reliable, safe and trustworthy designs. I've you know shortened my time here so I will pass on and it is described in the article in more detail, next please. So I just want to summarize the design strategies here that the high levels of human control and computer automation I believe are possible and that's what I want to achieve and we do this through comprehensible, predictable and controllable interfaces that provide a continuous display of status and informative feedback, please next. So I think that's sort of the end here this section but next let me just briefly say there are a set of design strategies that appear in a new paper from IEEE transactions on technology at society that suggests the new set of strategies of how you can make compromised designs that have powerful tools tele-operated devices supervisory control and mechanoid appliances. I'm going to shorten my talk here because we've started a little late and let me just go on next and next we'll just emphasize the responsibilities. Let me just pass through a few slides here next next next next and that's it that's to go back go back go back to the diagram. The next paper that will appear in ACM's interactive intelligent systems will describe a three level set of governance structures and that will give further descriptions. I'm sorry to be so brief but I do want to keep closer to our schedule and so I will let's see go next and suggest again the goal of human centered AI is to amplify augment enhance and empower people and looking at the time I'll just pause a moment and see if there are any questions. 