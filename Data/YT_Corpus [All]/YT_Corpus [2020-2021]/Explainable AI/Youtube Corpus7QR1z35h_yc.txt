 [Music] [Applause] [Music] hi i'm amur i lead developer relations at google cloud what's developer relations you might ask we are engineers who love talking to people who are hands-on that includes developers operators data engineers data scientists any technical practitioner who makes the information technology world go round we are constantly inspired by and in awe of what you do we succeed by supporting you along the journey to modernize your applications and innovate ever since google cloud started working with you we learned a lot about the challenges of building and operating enterprise workloads while also dealing with the business imperative to constantly innovate for instance we see teams struggling with these four problem areas first they are constantly occupied with lots of non-productive repetitive tasks and in many cases reinventing the wheel for things that have been figured out many times over second the businesses are afraid of frequently updating their high value workloads due to stability and security concerns which significantly hinders the rate of innovation third they struggle to keep up with all the mandates around compliance auditing security availability you name it and fourth it's almost impossible to write applications once then have them run anywhere whether that be on premises in the cloud or at the edge and as you know this isn't about whether you're in the cloud or not many of you have made the transition to the cloud already but you still face these challenges we want to help you significantly accelerate the speed with which you solve create and innovate we do this in three ways first we think it's important to automate as much as possible this means eliminating repeatable tasks in pursuit of important objectives such as secure by default monitoring by default canary testing and continuous integration and delivery in other words let's stop reinventing the wheel second we want to increase your productivity we know that everyone comes from different backgrounds and works in different environments with different tools we embrace this diversity by supporting your favorite open source frameworks and enterprise software applications and we do this as you see in this talk not just on the infrastructure side with efforts like kubernetes but also for developers by supporting code editors like intellij and visual studio code third you need portability options for where your workloads run our goal is to enable you to write your applications once then have them run anywhere with minimal to no code changes while transparently carrying over all the security governance and observability requirements to demonstrate how google cloud helps you with all of this my colleagues and i will highlight the key parts of a journey from migration to innovation we will use a sample financial application that we call demo bank a traditional two-tier business application that simulates a bank it's already been migrated from virtual machines to containers running in google cloud what's next in the mobilization journey for demo bank let's talk to my colleague megan a developer relations engineer for anthous to find out hi megan great to see you hi amber i heard you run on coffee so before you start would you like some absolutely here you go thank you let's take a look at how demo bank is running in containers on anthos i'm starting in the google cloud console where i've deployed the app onto a kubernetes engine cluster in my project i actually have multiple clusters running for development staging and production plus a cluster running in aws which i've registered to the anthos dashboard this aws cluster is running some legacy workloads that we're trying to migrate into google but for now we can see the status of that cluster in the anthos dashboard let's take a look at the production cluster to see what's running demo bank is a two-tier web app with a front end and two back-ends one back-end is written in python the other in java the back-ends are monolithic each with an embedded sql database as someone who works with platform administrators a lot something i really like about anthos is the observability you get right out of the box let's navigate to antho service mesh to check it out when i migrated demo bank from virtual machines to containers running on anthos each workload here the front end the account service has antho service mesh enabled a service mesh tracks all the requests flowing through the app and generates metrics like request throughput and latency i didn't have to refactor the workloads to get these metrics it all just works and the result is that i can see a live network topology diagram of the application at runtime so as an admin or a platform engineer the anthos dashboard is like my copilot showing me what's happening with the app from this dashboard i can also dial into one of these services to view metrics and service health from there i can set up service level objectives or slos to ensure that the app is meeting any required thresholds for availability and performance antho service mesh is also integrated into google cloud monitoring so i can create a single dashboard to see all the metrics relevant to the application from the app code level to database metrics all the way down to the underlying infrastructure and because i just migrated this app from vms to containers these dashboards are really useful and will help me figure out how to right-size my workloads and set appropriate resource requests overall moving existing workloads into anthos helps me gain deep visibility into this app at all levels of the stack catch you later armor thanks megan this looks great however this is not the end of the modernization journey modernization is a continuous journey to improve your ability to deliver quality solution easier faster and more securely after the migration to anthos demo bank is now more secure available and responsive but next they need to accelerate the rate with which they deliver improvements and innovations to meet the ever increasing customer expectations in their case demo bank wants to expand its online capabilities and serve more lines of business to do this we can adopt a microservices architecture versus two-tier so that we can scale out just the parts that need it and feature teams can own individual services to release more quickly and frequently to help with this modernization journey google cloud provides end-to-end development tooling which allows you to focus on your business logic and the automation takes care of filling in the rest for you furthermore you can iterate more quickly with the confidence of knowing that automated observability will detect production issues early for you let's now talk to daniel a software engineer working on spring boot integrations for google cloud and see how we can quickly develop a new microservice using tools that you are already familiar with hey daniel we can't hear you try this mic oh thank you armor [Music] so to modernize our application let's try refactoring the authentication features of demo bank to a separate microservice this area of our app has experienced a lot of growth and increased traffic normally this task would be complex but we're going to take advantage of a variety of google cloud managed services for less maintenance and better availability and also use various tools to make use of cloud much easier for the new microservice we will use cloud sql for our database and we'll configure it for high availability with the click of a button next let's start writing some code our development team uses java and prefers the spring boot framework we'll create a spring boot service from start.spring.io to generate some starter code for this project select gcp support as a dependency which allows us to easily integrate with google cloud services now as we write code we're able to just focus on the business logic there will be some points where we can leverage more cloud services in addition to the database for example we use a private key to encrypt authentication tokens previously this key was stored in an on-premises secret store like hashicorp vault on google cloud you can continue to use vault if you need to but for this demo we'll switch to google secret manager which is a secure way of storing secrets on the cloud so you don't have to manage the infrastructure yourself we can use spring cloud gcp libraries to access the secret through the application's configuration without any extra code spring cloud gcp is one of the many libraries and tools maintained by google in partnership with the open source community also as part of the modernization effort we'll trace service calls have centralized logging and generate custom metrics using spring cloud gcp all of these features can be added to our app through configuration alone so this is the big idea we don't have to write any extra code to do all this and with minimal configuration you can now see in application traces in cloud trace and clicking show logs will show you the logs associated with each request you can also see jvm and application level metrics exported to cloud monitoring and explore them in a dashboard now because our application has no custom code to access google cloud services it's portable across hybrid environments if you need to deploy the same application on-premises simply change the configuration without modifying the code and similarly an on-premises application can easily adopt google cloud services through just configuration let's test everything before we ship it for cloud sql to start the postgresql instance with data for testing we can use a third-party open source project called test containers now the database container is automatically started when we run an integration test for cloud databases such as firestore or cloud spanner you can use our local emulators we'll use a tool called jib to containerize our java application another alternative is a build pack which can achieve a similar outcome these tools let you use best practices without needing deep expertise in container tools let's also run our application locally to test it out i can easily do this with the cloud code extension in either intellij or vs code ide and launch the entire stack in minicube so i can see everything working end to end on my local machine if i make a change to the code now cloud code will automatically redeploy my changes into the local environment alright everything looks good i'm ready to check in the code and see how it gets pushed to production back to you armor thanks daniel that was awesome as daniel showed you google cloud provides comprehensive end-to-end development tooling namely ide extensions integrations with widely used frameworks and fully managed cloud services this significantly accelerates your productivity so you can realize the true potential of application monetization while using skills and tools you already know and have so what's next it looks like we're ready to deploy daniel's new service into our anthos environment google cloud is here to help you with that as we increase the number of demo bank services it's important that we build consistency and automation in our processes this is where continuous integration and deployment commonly known as ci cd comes in cicd helps you to quickly confidently and safely roll out updates for many services in parallel this means you can innovate with lower risk and higher velocity let's bring megan back to show you how google cloud supports you to release new services in a secure and low risk way hi megan before you start have some more coffee thank you armor now let's take a look at daniel's pull request in the demo bank repository the repo uses github actions for continuous integration here on daniel's branch we have integration and functional tests running to make sure that daniel's code changes are compatible with the other demo bank apis once i review daniel's code i can go ahead and hit merge doing this will automatically trigger a release pipeline running in google cloud build this pipeline builds the demo bank container images then uses binary authorization to sign all the images this helps us ensure that any container image deployed to gke is safe and trusted once this pipeline completes another cloud build pipeline starts up this is our continuous deployment pipeline which takes the release deployment manifest configured with the new image tags and applies it to the production gke cluster then from our development slack channel cloud build sends us a notification that the new service has successfully deployed now that the container's running i can control how traffic gets sent to this new service to ensure a safe rollout because the existing account service is still serving requests i'm going to keep it running in the cluster for now but i can use service mesh to rewrite http requests from the account service monolith to the new user service with no code changes and on top of that send only a small percentage of that traffic to daniel's user service then i can return to the antho service mesh dashboard to view metrics for how the user service is faring in production then incrementally send more traffic to it once i know it's healthy i can even take it a step further and configure security policies for this new service anthos config management is a tool that allows you to push policy configuration to a git repository and automatically sync those policies down to your clusters this can help you apply org-wide policies across many services at once because we're dealing with the banking application data security is really important so one thing i can do is create a policy to encrypt all http traffic across all the demo bank workloads once anthous config management syncs this policy from git i can return to the service mesh dashboard to see the encryption status for all of our services here i can now see that traffic to daniel's new user service is encrypted with mutual tls authentication so that's how i use google cloud to put a new service into production on anthos over to you armor thanks megan for showing us the cicd process for demo bank services i think this is super cool for several reasons first it's really compelling how safety and risk reduction are top of mind throughout the entire release process we ensure the safety of the deployment itself its ability to serve traffic without errors and the authenticity of the release artifact through binary authorization second notice how the automation supported by cloud build github actions and anthous policies help build that safety automation reduces human input which in turn reduces the possibility of human error this allows us to deploy new code changes several times per day confident that for instance the user data encryption will automatically be maintained a very key point of this entire talk is that safety speeds up innovation and increases room for creativity now that we're here we are in a good position to take advantage of more of what google cloud offers in this case let's see what machine learning can do for our financial services workloads let's call sara hi amer having our application and data in google cloud allows us to easily tap into other parts of our platform in our app finding a way to flag fraudulent transactions quickly will save everyone a lot of time and money machine learning is a great fit for this i'll use bigquery automl tables and ai platform notebooks to build our solution and i'll use the explainability tools in automl to understand how our model is making predictions as a data scientist i'd like to do my data preprocessing from a notebook environment where i can interact directly with bigquery data i'll do this with cloud ai platform notebooks we're using a publicly available bigquery data set of credit card transactions to train our model for each transaction we have data on the time amount and a few other variables we see that the original data set is heavily imbalanced which could negatively affect the quality of our model to reduce the imbalance i'm using a technique called down sampling to take all of the examples from our minority class fraud and a random sample of our majority class while still maintaining a diverse sample of the non-fraud data next i am saving the updated data set to a new bigquery table this data is now ready to be sent to a model to build train and deploy our model i'll use automl tables it'll let me do all these things without writing any model code with automl tables i can train an ml model while keeping my data in bigquery when i press train automl takes care of transforming our data into the correct format and finding the best model type for our task fortunately automl has some optimization methods to handle the remaining data imbalance after down sampling here i'm choosing to optimize our model's performance on our less common class during training now that our model's trained let's look at some evaluation metrics the confusion matrix tells us the percentage from each class that our model predicted correctly this model reached 86 accuracy with no false positives on our fraud class which is looking pretty good rather than writing our own algorithm of hard-coded rules for catching fraudulent transactions we built a model to do this by finding patterns in our data even with a high quality model it's important to understand what led our model to predict fraud through the explainable ai integration with automl tables we can see which features our model is relying on most to make a prediction i can now deploy my model with one click then i can get predictions in the ui or with the automl prediction api let's try it out we'll make a transaction with this credit card and see if our model flags it as fraud looks like this is not a real credit card yikes oh wait this is a banking demo not a banking demo let's go back to the code i'm making a request to the automl tables prediction api for my notebook to get a test prediction on our model with feature attributions in the api response we get the model's prediction and the instance level attribution values indicating which features our model relied on most to make this prediction for my notebooks instance i can create a new version of the data set and even programmatically kick off model retraining let's train our model for more time and see if automl is able to create a better model in addition to testing our deployed model from a notebook we also want to get predictions from our web app we want to keep the client code simple and handle calling the model and parsing the prediction response on the server i'll take the python code that calls our deployed model and put it in cloud run cloudrun lets me take code in any language and deploy it in a scalable container environment without worrying about infrastructure management with two commands i can deploy the container to cloudrun so that it's triggered whenever a transaction is made from our banking app as we iterate on our python code and model we can also make use of cloudrun's traffic splitting feature to serve new versions of our service to a small percentage of users to test out my cloud run service i'm making a curl request to it here although the service is deployed i'm only charged for the time it's being used since cloud run supports auto scaling by default this means it'll scale to zero when there are no requests and just like that from data pre-processing in bigquery to deployed automl tables model we built an end-to-end fraud detection solution with the right tools machine learning really is a piece of cake would you like some armor thanks sarah that cakes looks delicious i can't wait to taste it that was very impressive we just saw how sara applied flow detection to our financial services scenario using tools she already knows i believe that every industry could innovate around the kind of cloud scale data analytics and machine learning made easily available to your data engineers data scientists and analysts also stepping back as megan and daniel showed you we are bringing to dev and ops an integrated set of automated capabilities that represent the best of what googlers learned about code workflows and tooling over many years while developing our own planet scale consumer services the end result is that we make you as productive as possible while improving the quality of your software and enabling faster and safer release rates we bring this to you through your favorite open source and third-party frameworks enterprise applications tools and languages meeting you where you are so you can start solving immediately with the skills and code you already have you saw megan use mthouse and cloud build to deploy and operate containerized applications in a safe predictable way this means developers can focus more on the application logic versus the infrastructure allowing them to iterate at a faster rate you saw daniel use sprint boot and spring cloud gcp to set up tracing logging and monitoring with only configuration changes this also means that your code is portable to any cloud provider on-premises or the edge and you so sara go from raw data to a trained deployed automl model all without moving data from bigquery this means you can train high quality models with less code allowing you to focus on improving the predictions and getting them faster to your end users to learn more we have the google cloud certification program which allows you to specialize in our products in an industry recognized way we also have our youtube channel blogs and online tutorials authored by many of our engineers at google whether you are already using google cloud or just starting i hope we have inspired you on your application modernization and data powered innovation journey we are so excited to be working with you let's get solving now i can finally enjoy some of sarah's delicious cake [Music] hi there this is the death video i'm here to tell you a very short story how gcp has made my life easier to take one [Applause] [Music] will run only takes five minutes to hide my solution deployed bigquery makes it possible to understand analyze and even forecast our world a planetary scale gcp's data proc was not only having all the applications that i needed but it was extremely easy to fire up a stack in the cloud within a few seconds i once had to set up a kubernetes cluster and it took me two whole days to get everything up and running now when i moved to google communities engine it just took me two minutes i really do love the cloud share it's so easy that you can focus in what you want to do since receiving the google professional solution architect certification i was able to help solve for our analytics problems i could not imagine if you have to build everything from stress today you can unleash your creativity by using what you want and what you like making a complex choice being it's absolutely magic okay so thanks thanks okay we've come to the end of my story so raw credits now bye 