 [music] Good morning. We're going to talk about tools at your disposal that can help you demystify the inner workings of an AI model so that it is no longer magic, but rather something you can assess and use quantifiable data to make meaningful modifications on. Let's get started. Today, AI is everywhere. Sometimes it's in obvious places, examples being your personal assistant such as Alexa, Google Assistant, or Siri. They are behind the music recommendations that you get from your Spotify or Apple Music services. Still doesn't explain all the weird recommendations sometimes, but hey, it is behind those models. Sometimes AI could be in not so obvious places. You may think of them as boring. For example, the license plate recognition software, which uses visual recognition models every time a traffic camera issues your ticket. Someone isn't going down and reading all those photos, there really is an AI model behind it, so you can blame any failures or wrong tickets on AI. The next one is more relevant, as impacts us every day in a meaningful way. Almost all banks have AI models in the backend systems that use existing transactions to determine potential fraudulent ones. All of those notifications that you get when there is a fraudulent transaction are driven by these models. We've been getting them for quite some time. Again, no one in the backend is going through each transaction, it's humanly impossible, and trying to determine whether it appears fraudulent or not. Now, sometimes AI is found in unexpected places. For example, a company is using AI techniques to do facial recognition, then based on that it is trying to determine your personality classification. Think about this. By looking at your face, it will classify you in one of the many categories that they have developed. It's a very interesting use of facial recognition, to say the least, so I'll just leave it at that. Now, AI is not perfect, it makes mistakes. Sometimes they're funny, but you can laugh. One example being this image blending. Like in this case AI model think skier is part of a mountain, and it's amusing. In this other example, a businesswoman was ticketed for jaywalking because her face was on side of a bus and the AI camera recognized her and fined her for it. These are good but funny, but sometimes though, these mistakes are not funny and have meaningful impact on people's lives. The story was Mongo was being used to filter out applications who were submitting their resumes online. Ideally, you would expect the model would fairly treat each one of these resumes that were submitted but unfortunately, it was biased toward a particular demographic and treating the other group unfairly, in essence creating a hiring bias. Again, there could be several reasons for this mistake. By training data, less oversight on the model outcome, lack of model monitoring could all be potential causes. Let's look at another example. This is another serious mistake. This might even have had an impact on you. A financial institution was rejecting loans even for applicants who would have no credit risks, no bad credit history. This was baffling the bank as they kept losing business. When the teams dug deeper into the model, they found out that the loans were being rejected based on the ZIP Code where the applicant lived. There could be several reasons behind that rejection, but ZIP Code highlighted the bias in lending practices over decades as certain neighborhoods were always considered high risk. The model was doing its job on what it was trained on. I'm going to be using this last example throughout this session to highlight the importance of trustworthiness in the AI. Keeping that example in mind, how do we ensure that an AI system is doing the job it's supposed to? It really boils down to three simple points. First, you need to have access to the data that you can trust, data that you can count on. The data could be coming from anywhere. Your MongoDB instance, Db2 hosted on any platform, be it Azure, AWS. The important point to note is that you need to be able to have faith in the data that you are going to train these models. Second, no more black boxes. I think this is really the crux of what it means to build a trustworthy model. We need to be able to look into the inner workings of these systems. We simply cannot rely on the outcomes of this model without knowing what is driving those decisions. Going back to the loan example, if you were able to identify that neighborhood was playing a role in making a decision for the loan, we could adjust our training data to accommodate for that bias. Lastly, we need the ability to course-correct. When we are presented with these imperfections in the AI models, we need to be able to identify these issues beforehand and be able to make updates quickly and communicate back to the data scientists to adjust the models accordingly. Here at IBM, we have a prescriptive approach that we have applied with many of our customers to help them on their AI journey. We call it the AI Ladder. This is our prescriptive approach to help customers accelerate their journey to AI, which connects their data and AI capabilities within a unified data and AI lifecycle. This is also a way to help our clients identify where they might be in the overall journey and where they need to focus based upon their maturity on their journey to AI. What we have learned from AI pioneers is that every step of the ladder is critical. Again, as I said at the beginning, AI is not magic, and it requires a thoughtful and well-architected approach. For example, the vast majority of AI failures are due to data preparation, failures in data preparation and organization, not the AI models themselves. Now you know briefly what AutoAI is all about, let me show you a little bit of that technology in action. This is a Cloud Pak for Data running on IBM Cloud. We have several capabilities within Cloud Pak for Data, but I'm not going to go into details. I'm just going to walk you through how we're able to train these models quickly. Just to show you, we have connections from all kinds of data sources, one of them including MongoDB, but specifically for this use case, we're going to look at a mortgage example like the loan example that we've been talking about. Let me start by opening a project again. In interest of time I have done some asset import including other things into the project itself. The main thing I want to focus and show you on this one is the AutoAI capability. Auto AI is experiments that are already built into Cloud Pak for Data platform. I just want to show you how simple it is. In this, all I had to do was create a project. I already have a project with a bunch of files in it, some of them being simple CSV files, which I'll use one of them here right now. All I have to do is I'll say New AutoAI experiment. I say Sample 1. I can pick how powerful I want the compute clarification to be. I'll leave it as standard for now. It's asking me where I want to get the data from. This is where I can point it to any data sources that I have imported into my project, including MongoDB, Db2 that could be living on cloud of your choice, but I'll just pick a simple CSV right now, just in the interest of time. Very quickly it identifies which column I want to use, what I want to predict on. In this case, I would typically select whether someone would default or not. I just select that, and I do an experiment. That's really it. That's all I had to do. The AutoAI system would actually do all the work. Go in the backend, pick the right algorithms, pick all the right candidate pipelines, do the feature engineering, come back with the best possible candidate model. Just as with any good cooking show, I have something trained already that I will pull up for you here. This one is completed. The model running takes like a couple of minutes. This is a very small experiment. This one is completed. It shows you all the details that you need to know, which pipelines were used, why they were picked, why is this one being recommended? I have the option to save it as either a model itself or a notebook. This is crucial for fellow data scientists if they want to get something built quickly and then start using that. Those notebooks, by the way, can be exported and used in any tool of your choice. Of course, we would love for you to use Cloud Pak for Data but we don't limit you to just this platform. You can export them and use the tool of your choice. Once I have the model, I also want to show you that the model itself is actually-- In this case, we can push this model out to an actual deployment space. I do have a model here exported and trained. This model as a matter of fact is actually deployed right now in a production environment that we are running for a POC. In this case, you see this model deployed in this environment. What I want to close out and what I want to show really here is, as a developer, with just a few clicks I was able to train a model and push it to a stage where I can actually import it and use it as part of my application. I don't only get an endpoint that I can just test it out, I also get code snippets. Whether it's Java, which as you know is the language of my choice, or any other language that you think is relevant for your application, or if you just want to use the simple Web API, that's fine as well. The point is, you're able to get this model trained and deployed with just a few clicks. That is really the power of AutoAI. As we have more and more AI models trained, deploying and running in a production environment, we need to start thinking about implications of their decisions. If we cannot make the consumer of the model trust the outcome we cannot make them successful. This is where IBM's commitment to open source and fairness factors in. Open source, open governance, and open communities have been part of IBM's DNA for the longest time. From our work, whether it's Apache, Linux, Eclipse, to our current work across all layers of CloudStack, be it application development, Blockchain, AI, Quantum, IBM as a company had sustained commitment to driving innovation in open source, delivering a broad portfolio of offerings. One such initiative is ensuring trustworthiness in AI. IBM has three distinct libraries available for ensuring that. By the way, these libraries are all available to you. Download these, the links are on the website. First is dedicated to adversarial machine learning. It allows you to rapidly craft analysis of an attack, defense and detection method for machine learning models. The second, and again, AI Fairness 360 is an open-source library to help detect and remove bias in AI models. Third is around explainability, so AIX360 is really a toolkit that helps explain AI and ML. Is it easy to understand? What does it mean by this prediction? All of these tools are available to you right now on GitHub and are applicable to a wide variety of domains. Healthcare, finance, human resources. We as IBM, we make all of these tools available as part of Watson OpenScale on Cloud Pak for Data. That allows developers to monitor in production the AI models that are deployed. Going back to our previous example, think about this. If the financial institution had been using OpenScale, they would have been able to detect the bias against that particular ZIP Code as soon as it started to appear and course-corrected. With Cloud Pak for Data, they would have been able to track actual data used to train the model for an even deeper analysis. Understanding there is a problem with model is one thing, but it is not enough. We need a way to truly open the black box and look inside to tell what is driving the decisions. Which feature has a higher weight that is responsible for rejecting the loads? Once you understand the factors responsible for a certain outcome, it is possible to explain to end consumer the justification behind that decision. This is crucial because this is what ultimately leads to an increase in trustworthiness of this AI application, which is something we all are striving for. The last topic I want to touch on is less related to AI, but more focused on the ability to use it on the platform of your choice. In a recent survey of CIOs, almost 100% stated that they are using multiple cloud vendors. Not surprised. Surprise is no one wants to be locked down. We expect this trend to only grow as technology such as Kubernetes become more prevalent. More and more applications are architected to be cloud-native with microservices. With recent acquisition of Red Hat, IBM is committed to ensuring that our entire portfolio can be deployed on any underlying infrastructure, be it AWS, Azure, Google Cloud, or even bare metal hardware. You might say, so what? That has been the case forever. The key difference this time though, is that we are leveraging OpenShift as our container orchestration platform. The exact same code is running across multiple clouds, making portability of these enterprise applications and assets a breeze between not just IBM environments, but across other cloud vendors. That is extremely, extremely powerful. We're doing this through the concept of Cloud Paks. They are essentially enterprise-ready, containerized software designed with cloud-native deployment in mind. We have several Cloud Paks available already that span our entire software portfolio. Starting with Cloud Pak for Data as your data and AI platform, to Cloud Pak for Security that helps secure data workflows. Since we are focused on data and AI in this session, we have several Watson services and AI applications available on Cloud Pak for Data such as Watson Assistant for conversational interfaces, Discovery for search and text analytics, and Cognos for reporting and visualization. They all work in close conjunction with data sources such as MongoDB that have been connected to the platform. All of the Watson services that have been discussed throughout the sessions, Watson Studio, Watson Machine Learning, Watson OpenScale, AutoAI, are available on the platform of your choice through Cloud Pak for Data today. In closing, Cloud Pak for Data delivers the foundational platform for building and deploying AI on any cloud. With the ability to access services and data sources such as MongoDB natively, it provides access to a wide variety of data sources that eliminate data silos, help automate and govern data and AI life cycle, reducing data prep time, and build trust into the AI models that are in production. With that, I will close and hope to see you in one of the speaker rooms to join me for a chat. Thank you. 