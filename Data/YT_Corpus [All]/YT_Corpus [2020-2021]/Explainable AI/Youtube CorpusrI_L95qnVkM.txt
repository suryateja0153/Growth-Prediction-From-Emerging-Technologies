 Uh, it's great to be here. Uh, I'm very excited to talk to you about some uh-uh latest AI work at the Microsoft and the Microsoft research, but more importantly, I want to talk about two topics, uh very timely topic in AI. It's called AI buyers uh and explain about AI. Uh, let me flirts of all uh share some of the latest AI breakthroughs. Uh, we're actually gradually approaching human parody in a number of those human tasks, especially perception, from computer vision, to speech more and more in natural language. is actually talking about uh our work in object recognition. Uh, some of you might know that the ResNet now is the most popular deep neuro net uh in computer vision. Uh, we actually invented in our research lab in Beijing by my students uh using 152 layers of neuro networks. Uh, we accomplished 96% of accuracy for image nets, uh that is really the image database that people typically use to do recognition. Uh, that's really amazing, and in a way, this is uh at least as good as uh any Stanford graduate student to do this kind of recognition. The second box shows our progress in uh speech recognition. Uh, in speech, uh there's this very extended data set called the switch board data set that is really recording of two- uh, from two sides and uh phone conversations. Uh, two years ago we accomplished a 5.1% of error rate. Uh, that is really, really, uh amazing. Uh, this is actually the human error rate 5.2% is for those people, professionals, doing transcripts. Uh, most of us actually have uh up to 9% of the error rates when we do speech recognition. Uh, you may not believe in me saying that we actually have such a high error rate, but you understand that, you go home, talk to your spouse. So we continue to march on and uh really are making a lot of progress in the machine comprehension using Stanford database, and uh also in machine translation, this uh-uh 69.9% number is actually for our English-Chinese and Chinese-English uh translation on the new sculptures, and most recently we have been working on even conversational AI. Uh, all those things shows that we are actually gradually you know approaching uh human parody. But what does this really mean? Uh, it means that we actually now can enable a lot of interesting uh innovations. Uh, let me give you an example that we have been working hard in China and Japan, uh it's actually uh a social chat bot, called Xiaoice. Uh Xiaoice now is very popular, uh with 120 million um monthly active users. But even more interestingly, uh she's very famous uh in China. Uh, she's on 60 TV programs and the ratings shows, and she's very creative. Uh, she actually writes music, and sings very well. Um, and she's also a good writer, and she writes poems. She actually published a book. I actually wrote a foreword for this book. And, she can paint uh amazingly. She actually, using a pseudo name, she actually uh accomplished her work, and graduate from Chinese uh Central Academy of Fine Arts uh this summer as a master student. Uh, it's really, really amazing. But what's most exciting to me is how we have been designing uh this chat- this social chat bot by incorporating uh EQ. Uh, this is very important because you know with IQ, you know we helping people accomplish tasks, and with EQ, you know, we have empathy. We have the social skills, and understanding of human being's feelings and the emotions, and that's important because that is going to help uh the chat bots uh to really extend the lens of conversation. I'm sure you use some kind of digital assistance, whether on your phone or with the uh speakers, but the typical digital assistants on the market will have roughly a few you know turns of conversation with you. Xiaoice CPS conversation turns possession, on average actually achieves 23 times. Uh, that is a stunning number. Incredibly, the longest conversation any human user ever talked to Xiaoice is actually over 29 hours of 7,000 turns. I guess some people just have too much time. So, then you say, well, "you have this kind of capability, what can you really do, you know, for business?" Uh, I give you uh a very exciting example, that we have collaborated with Lawson, uh which is the second biggest uh retail chain in Japan. So, we used Xiaoice and Xiaoice EQ to power a key code that is really uh the voice persona uh that's the persona, the online persona that Lawson has. So, we did an experiment with uh with Lawson and using a key code. Uh, with- basically, have a key code talk to you- uh-uh Japanese users, and they uh- she can chat, uh, she can do uh protect recommendation, and she can contact surveys at the appropriate time, and she can even uh distribute coupons. So, we did the experiment with the coupons, and amazing that you know we distributed a million coupons in 13 hours, and the in-store conversion rate hit 40% in the next four days. Now, for those of who don't understand the coupons, this is really an amazing number. And of course we can apply all this kind of technologies to you different verticals. Uh, we actually now power 90% of uh-uh um, the quarterly earning report summary uh for 90% of you know Chinese companies, and uh powered by Xiaoice. All those things are possible because of the huge amount of data that we actually use to train AI. So nowadays, with more and more data using AI, and those more and more complex AI models, especially with deep learning models, we actually face some serious challenges. In particular, AI buyers and the explainable AI. I assume that many of us probably have seen uh-uh [inaudible 00:06:47] a few days ago about Apple card, and the creative comments. Now, if you think about it, what really happens? You probably would agree with me that very likely, there's some kind of AI buyers in the machine learning system. They have butte, and they really need to do a better job to have this kind of explainable AI. Why this kind of credit decisions were made. So, let me give you another uh motivational example that we actually have been working on in Microsoft. So, MPR interviewed my colleagues, and they wrote this article. It's called, "She is Brilliant, she is lovely. Teaching computers to be less sexist." So, we actually trained the machine learning system to do job classification. So, we actually defined 27 jobs, titles at the bottom, then we took someone's in the bio, and this person is a philanthropist, but we don't really have philanthropists in our training. So, then we rung through the system, and this bio, and the system says, "This person is a teacher." Well, this is reasonable, and um if you read the text, but if change nothing but only a few words from she to he, from her to his, this is what the system says. Now we start to see the problem. Maybe this machine learning system is not as accurate as you know as you would like to see. It might have something inherent in the buyers, because of the data we use to train that. So, what's really happening there? So, we decide to dig into that, and use something in natural language of processing, called uh word embedding. It's really- it's a geometry model with dimensional geometry, but there are really two very important concepts, that is called proximity and uh parallelism. If you think about Apple and Microsoft, and you think about Cupertino and Redmond, you say well, "They're really very, very much you know strongly correlated." You know Cupertino is to Apple as the location, is the same as Redmond to Microsoft. Similarly, Steve Jobs and Bill Gates, uh they are funders of those companies. So, now let's use this word embedding to take a look at the relationship between the he and the she. So, she to he is analogous to sister to, I'm sure you guys know, to brother. Okay, so far so good. Let me warm you up, and she is a nurse, and he is- now, now you start some problem. Some problem. All right. So, she is a homemaker, and he is a computer programmer. By the way, we-we didn't do anything. In fact, we used the training data studies even coming from Google, so it's nothing to do with us, and it's really in the data. So, so now- now she says, "Oh my God." And what would he say? Don't be shy, I know some of you guys say that. All right, the next one if you get it, I will offer you the Microsoft intern. So she is a feminist, he is... anyone? Well, it's not easy to get in the internship at Microsoft. Well, someone said chauvinist and uh that's actually not too bad I guess, and the... oh, I know, I know. I- yeah, yeah, yeah, yeah. So, the last one uh if you get, I immediately offer you the job at Microsoft full time. So she has pregnancy... oh my God, no, no. All right, so... so-so you get it. You get it. So-so, again, you know, it's all- it's all analyzed coming from- coming from the data. The data we collected over the internet has something inherited to buyers. So, if we just blindly use the data to train AI, we know we have problems. So, this is actually a more complete view about the number of words coming from this data set. If we plot in two dimensions, horizontal axis is all the way to the right, those words have nothing to do with gender. All the way to the left, you now have very much strongly correlated with gender. If you go up, it's-it's more about the she, and if you go down it's more about the he. Now we really start to see problem. The Y is genius, you know, Y is brilliant, more associated with man versus a woman. So, once we understand there's a problem, of course we can think about how we can deal with those problems. You know, approach, you know, you could take is try to squash this vertical axis, and you could say that brilliant should be applied to all kind of genders. So, we actually wrote this award winning paper you can find out on the internet. So, I only have a few minutes. Let me quickly move to the second topic, which I think is just as important. It's about the explainable AI. So, why this is a problem is because we now train all this kind of complex models uh with millions even trillions of parameters. So effectively, we are building AIs as black boxes, and that's a problem, because you want to trust the AI, you know. We need to be- we need to really you know have a transparent AI. So, we have to open the black box up to understand that you know each and every piece of the decisions. So, I give these three reasons why we absolutely need explainable AI. The first one is very obvious. Uh, that is AI machine learning, they are just latest tools. So, we use those tools to help users to do a better job. So that is about augmenting human. Second one, I think you also probably understand pretty well, that is basically that we need AI to be transparent. Why we making those decisions? You know, can I trust this AI? You might think it's probably harmless to get some kind of Netflix recommendation about movies you watch, but the political ads on social networks can be problematic. Medical diagnosis, or even military decisions based on AI, you know, can be deadly. The third one really more for AI practitioners. That is really we want to help the humans improve AI. We need to understand it, you know, double click, you know, really dig down to the system to understand that where are those errors happening. To which part of the data segment? With which part of the model? For example, you know, do we see buyers? Where is the buyers from? So, a lot of people nowadays working very hard, really thinking about the different kind of machine learning models. You know, how-how can we make them both explainable and also very accurate? So, the graph shows that the horizontal axis is really the explainability. The more you to the right, you can actually explain. You know, for example, logic regression, you know, the um something that we all understand. And to go all the way up is actually getting bigger, and the bigger models and the models are getting more and more accurate. So, what's happening? What's in the field? You know, people are really pushing very hard is that-that two school of thoughts. One is that you started with simple, explainable models on the lower right. Then you tried to explain- really improve the model. Push it up. For example, the-the G2M model is really this new version of generalized additive model. You know, we have developing is actually going that way, but most of the effort in the field is actually on the top left going all the way to the right. That is, you start with some kind of very accurate model, and the model agnostic. Then you try to explain probably using some kind of local approach, or other approach there. So, I'm going to just finish my presentation by coming back to the black box, or opening up the black box and the uh- try to convince you that uh it's very, very important uh we have transparent AI. Uh, we are going to be the first generation of humans to ever live with AI. I see tremendous business opportunities uh by doing AI. I also worry about, and I believe we have also tremendous social responsibilities to develop the AI and the- because I really believe we cannot accept a future where AI making decisions that we cannot explain, that we cannot understand. Thank you very much. 