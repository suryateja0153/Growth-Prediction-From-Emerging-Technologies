 hello everyone and welcome to robotics today my name is Luka Catalunya and I'm excited to introduce nida over Kinyon as our speaker today ladies going to talk about a very hot topic which is self learning and control after her talk we are also going to have a panel discussion and to the WebEx I have two wonderful guest panelists Claire Tomalin from UC Berkeley and John Howe from MIT NIDA is currently professor of mechanical science and engineering at the University of Illinois at urbana-champaign she got her PhD in physics and mathematics from the istituto high mathematics of the russian academy of sciences in moscow and before joining the faculty at UIUC in 2008 she spent some time as a research scientist at Stuttgart University in Germany she was at helium France in a Georgia Tech he also was also on the faculty at Virginia Tech so in 2015 she was also named inaugural director of the intelligent robotics lab at UIUC Knight has been a pioneer in adaptive control she's been providing a number of fundamental contributions to control optimization autonomous system neural networks game theory and she also did extraordinary contribution to applications in aerospace robotics agriculture biomedical engineering elderly care among many other fields she has coder two books six patents and more than four hundred publications NIDA has received multiple of words I will try to sample few of them just to give you the flavor here in 2015 she got the AI EE mechanics and control of flight Awards in 2015 she was awarded the humble prize for a lifetime of achievements in 2015 she got da Triple E control system Society Award for technical excellence in aerospace controls in 2019 she got AI EE Hendry aerospace literature award his fellow and life member of AI ee m fellow of I Triple E and I work in robotics for elderly care was featured in the new not New York Times and Fox TV and CNBC beside being an excellent researcher nyah-nyah is also an excellent mentor in 2015 she was awarded UIUC and ready in consular word for excellent advising and she's also co-founder and chief scientist of Intel anair which is a company which is working on drone technologies to redesign the future of agriculture and farming NIDA thanks for being here and welcome to robotics today thank you for hosting me today I'm very honored to be here and so let me share my screen okay so I guess I'm good to go saying thanks again for having me here it's a great honor for me to have this opportunity to present some of our recent work that may have impact for robotics for this audience so I will talk today about safe learning and control without one adaptation and to get started we had these two animations here that show how the recent [Music] applications of reinforcement learning methods have created great great impacts across not just our community but widely across the globe like the animation on the left from deep mine I checked today has more than 10 million views it basically shows how the agent learns to run jump climb without having any prior model it learns from its own mistakes collect data fails again collects defenders has a reward function which keeps it going moving forward and so on on the right you see the blue bit too big that I'm sure many of us have played in our younger days we did so it can be today reconfigured with with a robotic arm so while these applications seem very impressive and they show what artificial intelligence methods or machine learning methods like we would like to say can achieve from having data having learning methods obviously we cannot afford having this method on safety critical system safety critical systems will not forgive mistakes we cannot allow hailing collecting data trying learning failing so every crash here can be catastrophic human deaths are not allowed so accidents can be very expensive and we have experienced here applying the learjet we are more just talking here artificially the airplane on the left you will see through this presentation numerous times the drone here is a picture taken in our lab on the right we have the wyman car my student is working in the company so the safety critical applications can punish us severely if we afford playing with them assuming that we can have a mistake collect the data learn on the goal so let's look what's happening in a typical site hub where we try to collect the data and use an optimized controller like that typically we have a model learning blog that learns the model from the data there is an optimization that produces a controller and the controller drives the system so what can happen that the external disturbances or the modeling errors can basically destabilize the system what wanted to do one is to understand that the safety must be built into the control architecture from the beginning by design so this means that we need to have an augmentation with a safety controller that would ensure the safety of the system throughout the learning process so no matter what are the mistakes errors data collection learning the safety must always be there so that every new knowledge acquired in this process subject to errors failures and so on will not let the system be destabilized so looking through this type of development so what do we need from the safety controller with a set from the safety controller we need typically certificates of performance and robustness which include transient performance steady-state performance time delay margins and disturbance rejection something that we learn in a junior level control class like the alphabet of control technology so everyone adaptive control architecture that we developed over the last 15 years has proven it's worth already on a variety of big platform that I said I'll show some flight of Learjet we've commercialized lead evolution about pilots evolution autopilot of Raymarine for some drone technology went into hydraulic pumps of Caterpillar we have test start oil on drone technology Intel in error and many other industrial applications it has an architecture in which estimation would be decoupled from the control so we are able to tune for performance and robustness in a very systematic way and be able to quantify its robustness and performance robustness margin and its performance bounds a priori and be able to be in hold of those throughout its performance so when the old man didn't want adaptive controller to a type of a model learning controller that I described so what we are able to do we are able to retain the keep terms of performance and robustness of l1 adaptive controllers yet at the same time benefit from the versatility offered by these machine learning methods so this is what we will explore through this presentation and this is what kind of makes up most of our current research program at Illinois these days so the Elven adaptive control theory as I said provides some type of decoupling between estimation and control and helps us to establish the type of performance bar that we showed here so there is a desired system tragic read upon the light to follow there is a reference system which is a hypothetical reference system it's not implementable but it describes the best type of performance that one would achieve without one adaptive controller if the system uncertainties were known so it's not implementable so between this system and the actual system the performance can be quantified inverse proportional to the square root of the adaptation rate while the performance of this reference system with respect to the desired system can be quantified proportional to the filter bandwidth and augmented with an error that would be exponentially decaying dependent upon initialization error so with this decoupling we are able to tune the performance and robustness of the system in a systematic way it is this architectural versatility well one adaptive controller that helped us to achieve quick tuning across different applications in different industries and to achieve transition to different industrial platforms and here is a timeline how our development went the first papers appeared back in 2006 American control conference and in the same year in AI EE guidance navigation control conference where the first flight test we'd enabled for post graduate school on their rascal UAVs with pickle autopilot we were doing work mentation of their outer loop to apply aggressive path following trajectories later in 2007 we got NASA grants to apply their air star subscale commercial jet we were able to successfully put a plan into stolen possible to give the pilot smooth recovery opportunities from all conditions that led to joint publication opportunities with Boeing Raytheon causers giving lots of visibility and opportunities to write papers with other car so here is where we got collaborations with Scarborough marine capital or Eurocopter MBDA Seagate so this company's got attracted to the technology and there were lots of transition opportunities then we got the opportunity also to test or relay play so what NASA was testing it on 5.5% sub-skill commercial airplane so Lear did f-16 were already the relay plane that you see with pilot inside that we were able to fly in 2015 16 and 18 and now with the explosion of these machine learning methods the robotics industry we were able also to take this framework of safe learning and control and to move into robotics applications so before I will go so what we do with safe learning and control for robotics I want to show some of this flight test of Learjet because these are very interesting and will keep everybody entertained somehow so we live that so when we go to fly the Learjet so we have basically pilots and plant based engineers the Learjet is a calcium vehicle that's variable stability system configuration where they can basically inject some accidental configuration that they design with us carefully to validate these robustness margins that we claim theoretically and they are able basically with their safety switches to take over in case the power theoretical claim don't get verified they can save the craft with their safety switches that's why they take the risk to fly into these configurations so they're going to test in the in the next movie that I'm going to show they are going to test for handling qualities flying qualities basically when you fly the plane in normal configuration you have no fasten seatbelt sign that's flying all it is level one when you have some turbulence and you have fasten seatbelt sign that's already degradation expired oh it is level two and so on so the pilot are put into configuration when it's very shaky and they have cooperhog the rating scale in their hand where they have to read size whether it's flying qualities level one to four from which configuration how much they recover and because the situation is very shaky they are not able to read from the piece of paper they are asking the l1 to come so that the airplane can be stabilized so that they can read basically in which configuration they are how much they recover so I mean just listen so I gave a little bit preview so that where you listen you manage to catch up because it goes pretty fast its shape its accidental so it goes a bit fast that's why if the Trivium constantly overshooting my desired bank though Jason's probably hating life right now [Music] I'd recommend we just do the task with l1 on it you did not get adequate on that one good okay so you want to run through a CHR real quick you did not get adequate so we're starting in three two one now Alan is on thank you you didn't ask I was gonna and now it's a landing scenario basically Landing is very challenging for example NASA never decided to land with alwa but we live that they agreed to land with again some type of abnormal conditions 100 feet Pepe you there's a ground effect you see that you [Music] you I've done event poker thing so basically this was 2015 deployment upon which in 2016 we got the 2000 in 2016 we got the f-16 which we cannot unfortunately show on talk because the f-16 in 2018 we got the lived it again and here they implemented an accident from 1967 which is a lifting body incident when the aircraft goes into raw spiral mode configuration and here in design accident of 1967 luckily the pilot survived they have the phase data from this accident which they are able to inject into the Learjet untested so this tests are extremely valuable and extremely kind of pressures in some sense for training the pilots training the students this experience is extremely invaluable for everybody involved in this process now just listen to the recordings you careful and do you have your mic the student on the left is my student finger oh yes a tasket 3 2 1 now so you can feel they're at high frequency I made some high-frequency input it's excited the roll lower-frequency to roll over shoot our oscillation tendency is less there's still something I'm having no issues fine tracking and gross tracking are very good at pitch alright I have a dinner complete now they're going to engine-out test right recording on in ready ready pack running okay power is coming back my hands are free three two one controls fixed and recover please and cars back you I'm ready to try this now with you with a pilot corrected for it I'll give it about one secretary action time about conditions recording on my call ready ready pack okay power will be left frontal okay in three two one now Lauren potato and recovery and recording off a recording off matching problem and we delve on they come to three degraded relationally I'm ready for the recording nod ready ready pack okay left throttle coming back in three two one not touching the controls nice demonstration yeah check that out about three degrees of left bank speeding at the rudder to match I could feel that it is descending a little bit that's just sitting a bit but that would be easy to compensate for it yeah okay I think you got some good data there magic power recording of it all so this is what I tell the students that in real world there is no zero right three degrees pretty good after what we saw with twenty degree without pilot with pilot it was 12 degrees we don't want without any pilot it was three degrees so zero is the artificial number right making all the math work so three degree in real world is a pretty good achievement and we got some press obviously from MIT and so having these demonstrations naturally the next thing was coming already historically to our life where the robotics application so the first robotics application we got it was interesting with this elderly care grab from and aside the goddess also some press into New York Times it's interesting that this was kind of the first opportunity that brought us and it nicely rings the bell with a funny custom that would now come and entertain everybody so deploying these drones at home environment was interesting because we could kind of bring in VR technology and study people's perception of it and kind of compare it to Cinderella that was maybe fill the few decades ago and ask questions how safe she feels in the presence of birds showering her or helping her with household tasks like setting up her bed or something because this brings up lots of interdisciplinary research how people feel say in the presence of these robots because now we talk about package delivery tasks so the interdisciplinary research problem to make our light very interesting very region the questions that we can ask and train our students become very important and far-reaching with their application so as I say the for this seminar series I wanted just to pack a number of problems where we look how to do safe learning and control simultaneously so the first problem that I want to show here is what we did in in collaboration with a Bangalow student from Georgia Tech we integrated l1 adaptive controller with his model predicted path integral controller that provides a framework for solving nonlinear model predictive controls with complex constraints in near real time so we integrated an architecture here and you see them in his auto pilot project environment here is the environment that I want to show the paper is accepted in this year's IRS conference and let me run the movie here and explain what's happening here so what you see here in red is when they run the autopilot just with mdpi basically takes them this long time wise to finish the lap when they add the l1 on the top of it they seen is the lab in a much faster time and the green segment just show that in these cases the MVP I didn't survive without l1 and we don't want they were able to take these few other cases as well so here is that drone racing environment and now as we are talking actually and Georgia Tech has reopened their campus on June 18 the students are working to fly this l1 mtpa architecture on a real drone in their bike and environment does the campus opening was happening so we didn't get the real drone footage from their love otherwise most likely we would have had today the real drone footage and not just the goggle environment but we are very excited by this work with evangelist and hopefully we'll have the real drones flying there is home not for this pandemic we would have had it construed similarly we have integrated also again with evangelism l1 with differential dynamic programming that model learning so basically the model learner continuously improves the knowledge of the model based on that the trajectory optimization does a better optimization and in adding that process as the model learning and the trajectory optimization improve as one ensures this safe control and safe guaranteed performance without losing the robustness and so on so we demonstrated in the simulation environment of this imperative card Pole is you see so prior to learning the doctor learning so when l1 is on you see better performance in both cases here is the post function plot on the right where you see that with the help of learning actually by the end of the process you achieve the same value for the cost function but what the learning about l1 does in the process of the learning l1 helps you to have better robustness and better performance while without l1 you have basically much higher value here at the cost function so it's the contribution of l1 or the transient here is crystal clear that during the transient it does its job by ensuring this safe guaranteed performance so moving forward we want to show so for example if Gaussian processes could be safely integrated with l1 architecture right now why do we do that for example if the data is being accumulated can we simultaneously use this accumulated data to learn the model without any persistently exciting signals the Gaussian processes say the Bayesian learner can learn the model with a few data points right if we store them in the kernel matrix can we learn it and can we use these learn the model for example for better planning purposes without any prior knowledge again these paper was published and present it recently as for the sitcom proves that we lost our opportunity to travel we simulated it for a quadrotor models so what we show here is a demonstration basically that in the beginning where we don't have enough data we see the l1 contribution the minute enough data has been accumulated the learner takes over and there is no need for l1 so the L want element in the control signal dies out and the learner takes over and acts as the main controller by doing so basically you can save some of your robustness margins already for other purposes inside the system while the robustness margins are defined through the l1 architecture they do not change but when they are not used already per your uncertainty conversation because you have learned the system you can use it for other purposes so inside your system you can use it for better planning better for just other purposes that your mission may require so for example in the in the middle you can have change of mass center of gravity and other things like for package delivery so long like a disturbance but it implies in one will keep propagate cocoon again to pick up the uncertainty to compensate for it till the learner again picks up enough data to learn and compensate for it once the learner picks up enough data to learn l1 contribution will die out this is a benefit of the architecture so how to synthesize an architecture that would work in a way when you don't have enough data on wall work the minute you have enough data the learner takes over ml 1 goes into passive mode so this is the benefit of data architecture that detailed in that paper of l4 deseeded can be downloaded and study next I want to talk a little bit about navigating robots in confined spaces in between different obstacles how to build safe attitudes around those and this is relevant to our work with marco i mean we have a project game from an array with marco so we use here contraction theory so imagine revenue linear system work with modeling uncertainties and again we have safety critical applications and we have we want to have a planner agnostic approach to certify safe tubes around desired trajectories that we want the robot to remain inside this safe tubes and navigate inside this safe tubes in between obstacles this paper has been submitted to CBC it can be downloaded from archive so we design a contraction based controller that would keep the robot inside the same cubes and augmented with an l1 adaptive controller that would give us multiple knobs for tuning between safety performance and robustness right so here having multiple obstacles and say we want the robot to follow this orange path it would be safe in between these obstacles but the blue would run into for example into an obstacle right if we design a tube like this orange and it's not sufficiently conservative it would run into these obstacles obviously we would like it to be tighter around the desired path so that it doesn't run into this obstacle so what contraction Theory does it leads into this romanian energy as a controller no function and tries to minimize gamma which is the geodesic path between the desired path the actual path by using the optimal function is the energy of the shortest path on the manifold right and we augmented with an l1 adaptive controller due to the architecture these are one adaptive controller that is this natural inherent decoupling between performance robustness so we have these three tubes now that are inserted one into another so the first tube would be just purely due to the initial initialization error it's like a funnel it will be Disick's financially decaying performance due to the initialization error the second cube which is the green cube it will be tunable based on the filter boundaries and the last tube the or attitude would be tunable based on the adaptation rate so here is the for example where we can simulate and show this effect so basically having the three tubes inserted one into another if we increase the adaptation rate so the orange and green troops will collab collapse and when we increase the bandwidth will make the tubes narrow and get closer to the desired path so here is just the contraction controller here that you see with the blue line it may collide with the obstacle but when we put the old one and we tuned it tighter we can get closer to them desired path by appropriate tuning and what this framework allows us as I show that we can incorporate Gaussian processes by region learner we can use these previous architecture together with a contraction controller to learn the uncertainties for better planning by doing so we can make the troops tighter around the desired path and have one more note for tuning here is a racetrack simulate either these paper will most likely go to the choral conference within this next month so if we have a beginner driver we would like to give him a wider craft or an intermediate driver will make the desired path with a intermediate width of a tube for an advanced driver that you can be very super narrow right so the rediscovery metric and the retuning of l1 parameters will not be required so under some mild assumptions of course so the model is the model uncertainties we learn it will be updated but the controllers would not be retuned so once these papers submitted to Korell everything will be downloadable including the software and everything from our github sites and now I want to move to some of these big projects that exist in our group where these type of controllers have been motivated and they can be used most likely over the next few years so this is the project that we would mark oh this is an inner eye project from NSF on the last mile delivery so the underlying concept is that for the last mile delivery optimization one can take advantage of the ride-sharing vehicles and drop the packages and pick up from the glass sharing vehicles for the last mile delivery optimization and that's the part of the city were already you have more Spock science that low speed limit and you optimize just over the random network vehicles obviously the cars have to be retrofitted with appropriate magnetic dog the technology has to be there now with pandemic we see more more use of these UAVs for this purpose there are some already preliminary results both in our group the amount of proof that we cite here so what we show here is an animation from our group paper was submitted to Walker so this is an animation showing like a point of no return when a drone is trying to approach a vehicle or drop in the parcel and there is a point from which like a point of no return we call it here we're trying to move now how to embed a deep learning type of architecture that would have computational optimization for energy savings to maximize the flight time we call it safe learning here another project in our group where we're trying again to use safe learning which control is related to this virtual solid project all of you remember I believe the landing of American Airlines in Hudson River and we know that it was the captain's decision to land a put some rivers so what the captain did with his 40 years of experience he debated his options between landing in LaGuardia Peterborough or Hood symantec took the correct decision to land in Hudson so it's his experience with all the neurons trained in his brain to land in Hudson and that was the correct decision so can our learning the optimization algorithm today reproduce similar blog in our autonomous system that you take the right decisions every time to endow our autonomous systems with similar safety path planning state mission replanting objectives so that at every moment a safe missionary planning can happen to ensure safety and submission be planning and save the vehicles from crashes the Patrick planning and execute everything naturally so we call this multi level adaptation and this is another NSF project kind of again in our lab and another project that we have again have are very excited going on with around ellos this has to do also with a resource aware uncertainty resource aware control architecture where we refer to computation is our budget and we would like to understand how should we budget the computation for control for perception for navigation so this is very interesting and we have another collaborator from Georgia Tech here is old Kiera so that Evangelos works with so this work is also partially supported by NASA Langley and we have here kind of fast computational algorithm for collision tracks but it was published last year in robotic science and systems conference all of these add to our portfolio methods were safe learning and control finally I want to give a brief overview the cooperative past generations have following framework that we've developed in our lab four long years this work was founded also by a or some NASA work through decoupling of path generation and path following we have enabled multi vehicle missions and we implemented it NASA in a very challenging environment innocence Langley's autonomy incubator let's let's go through these how to drones can fly they have Network we drop out here and they have the model of the maze but they still do see wedding form project reshaping and these two drones go through this maze and they coordinate with each other to achieve simultaneous landing so this is a time-critical mission where they coordinate with each other their arrival time they exchange their relative error positions and they coordinate on the arrival time so it's a kind of next step we plan to bring these contraction control contraction metric augmentation approaches to these to enable multi vehicle missions in these type of constrained environments to enable more agile collaborative missions and with that I guess I would like to acknowledge my current collaborators very successful interesting the meetings all the time my past PhD students and all those all my collaborators my current group all the people at Air Force who enabled all this flight test only ended at 16 and my students are Lakshmanan who compiled this presentation for me thank you all very much I'm happy to stop my slide share and go back to this more happy to take any questions if you have I don't know how I did with timing you can tell me right yeah thank you very much for your very interesting talk I really loved how you gave a nice historical perspective on and one adaptive control and to see how such a control technique has been used very successfully in the context of safe learning and control so that was really interesting and example so today we are going to have a fortunate to have a two great guest panelists at clear coming from Berkeley and the gemfile from MIT so as usually robotics today I would ask them to kick off the panel with some questions and then we take it from there so maybe Claire you could start yeah I'd be I'm happy to thank you Marco and thank you an IRA for a wonderful talk as Marco said really talking about the historical perspective of l1 adaptive control and the research that you've done in your group and a beautiful set of theory and experiments and then bringing that together with these you know very popular and new methods of learning and then really bringing the two together nicely so I thought I had three questions and I thought I'd start with you know the more detailed one and then maybe go to the more broader questions and the first question is something I know you've thought about a lot which is you know as control theorists we're we're very careful about models and about developing these and and you've shown us in your work developing and in your work decoupling these bounds on performance and robustness and you know the Delta's that you get in the certificates that you get out of l1 adaptive control and then you bring in learning and and learning and you showed you know very elegant frameworks and and with your MPP I work and your DDP work you can really marry these together but but what maybe you can talk about this kind of peace at that intersection where you know very simply put you have you have a model you've developed your l1 adaptive control framework and then you're applying that in a system where you know all of a sudden you're faced with an unknown environment where the uncertainties and the things that are coming at you from the environment just violate those those restrictions that's the that's the kind of dichotomy that I think we're faced with and you've been able to maneuver that beautifully and I'd like you to just comment on that and talk about you know how you do that perception you know the learning and perception how do you deal with these big uncertainties that come and violate what we've already developed has control theorists how much time I have to answer that question it took us six months with everyone get those they'd like six months it was put an architecture that would make it work because first is the architecture right so it took us really six months to make that l1 and PPI and the l1 with GP that was in and for DC to work because first we first and I have to give here evangelist a lots of credit because him he pushed me to do it he said why don't you do it because it's very important for the community if you don't do it others will do it and they may not do it right you better do it you will do it right I said okay well let me do it so first the first question is it can dip it be integrated without one feasibility equation and that person will look at that Kenji please be integrated with l1 as a feasibility question not a to achieve something more but can we have a GP insider one that can learn and this whole learning will be safe so and there are a few ways you can put this GP inside at warm like it's 90 texture right so how to put it right so that it can learn and when it learns for example l1 can go into passive mode because it's learned already you don't need it to do anything if I know because everyone is needed for adaptation for robustness and if I know then I don't need it right so comprehend is correct architecture so so using what what I always like to say and emphasize that the most important thing are the architecture so as you can say you can put one fix gain control architecture and struggle all your life how to compute your control gain how to solve your optimization problem to compute your control gain so that it does a job and then all your life you are solving your optimization problem in a better and better way another parallel philosophy is how to synthesize a correct architecture so that it does the job better so in this process were struggling how to make the correct architecture in the correct architecture according to me the one so that when the learner learner's l1 dies right and it dies correctly it dies as much as much as I have learned right so how to come up with this architect but it's work it's six months old of work okay then l1 and PPI where was Robert L right MVP is super fast right it is its sampling requirement l1 has its own way of being fast estimation slow control and how to make all these samplings of work with each other and work robustly so that it works its six-month work right and there are postdocs in both students involved day and night talking meetings so I mean if some of your students want to work with us we can have them during our meetings but it takes persistence it takes work I'm sample to evangelist for pushing me to do it it was worth the journey was worth now we have opened a whole new set of opportunities we'll take it further it's not one free concert yeah okay thank you that's some maybe now leading to a broader question that you've you've also thought about I know is deep learning so you know as we integrate perception into autonomous control systems we're going to be using deep learning mechanisms right that's what 99.9% of the computer vision community is using what are your thoughts about that we what are your thoughts about analyzing or verifying deep learning components within control loops so it's it's gonna be hard it's not gonna be trivial but one thing I know if we want these systems ever to be certified the thing that I have learned and this may change over the years but I know that any any software that gets modified on the flight will not be certified today at least this is what I learned from Louie Shah who is my colleague at Illinois and who work with great Authority for certification community he always says any software that gets modified on the flight and this is the these are some of the tough lessons learned also from the 737 they're cheap quick certification solutions may not work so one has to be very careful when you talk of deep learning going into safety critical systems and not being very thoroughly and carefully analyzed so again the architecture has to be correct and the architecture correct implies you need to have some type suite that there is this expert controller that's always there that whenever your uncertainty estimation threshold gets violated right you can have a deep learning there that takes raw input outputs a controller in a very benign environment but but when your environment is not benign and it gets it becomes very adverse basically we have our certainty type estimation that gives you thresholds that are very violated and that has to be pretty conservative and safe for your operation when dead gets violated that you had to kind of have an expert controller that takes over overrides everything shuts down the system navigate safely I would say architecture architecture architecture what makes your system say architecture has to be right yeah Thank You naira and then maybe one question before we move over to a John question model models free learning what is the place in in all of this for model free learning is there a model free learning I can build a toy give it to a five-year-old kid to play with it but not with safety critical systems I'll do my own due diligence so k-12 outreach we came with toys and gold okay twelve all three it's also we can engage the smarter kids into our community and then help them do system ID and model based controllers thank you an area that fools yet perhaps controversial statements we can you need discussion to our research on how right thanks Marco I know it thanks for a great talk it's great to see the work you've been doing on the l1 I mean you're now I'm spoken about it before but it's it's almost fun to see the videos of the things you've been able to do recently so Mike I open any question that was similar I think of what Claire was just asking in terms of you know as we begin to get close to deploying these types of systems in the real world you know you start getting these sort of unexpected sort of consequences in the sense that you you mentioned sort of maybe in a sandbox or or these algorithms start learning and going outside the box of things that you maybe have thought about before so performance perspective that's good but from a sort of certification perspective maybe not so good and that type of uncertainty and how it behave translates into conservatism and then you start seeing people talking about well maybe we should put that on there now we've we've faced this as a community or all along thinking about adaptive control but I'm just thinking in terms of you know for the student audience out there is there perhaps advice you could give on types of research directions and things that they can be thinking about to address this problem where you know maybe for the past decade we've thought about how to make things better for the next decade maybe the focus is on not just better but actually saying a lot more about what what how much guys are gonna behave you know can you actually give the insight of certification and things like that so just thinking in terms of advice for researchers what types of things should they be thinking about as they move forward in their careers yes that's a very good question what I think we should do maybe unique other senior people here together with the junior people we should maybe form a traffic consortium and invite FAA to talk with us how the modern paradigms for certification it to be formed that would not depart the conventional paradigm but would leverage the existing practices yet allow room for modern methods to make their way there along with practical evidence simulations and all these experiments because as you see I'm trying to build up the way we have work to build up so if there are people who want to come and start the conversation I'm ready for that but we need to have a consortium of people who are ready to get together to support each other to negotiate that requires a big room with lots of people even it can be assumed room in a physical room would be easier but it requires certification is not one person game it's it's lots of people in one room that's industry that's government that if they eight NASA boring MIT Berkeley Stanford I don't know so it's lots of people in one room but but a certification can be done only that way yep one last question it won't be quick because it's open-ended as well but as you look at these occur in IRS conferences and you see just how many papers have the words deep learning in them which i think is bordering on more than half one of the concerns that came up and one of these debates about the future of these types of conferences was that we'd be starting to generate a lot of some researchers whose answered every problem is deep learning and that we start losing an ability to solve some of these problems using other techniques and any advice on sort of moving forward I mean it's it's as a field I mean where it's like if you have deep learning in the paper title you increase the probability of it getting in on the other hand it's not always the solution and so it's a question of how do we retain the skills as a robotic community and and and yet you know still recognize the value of this technology but also his limitations [Music] there's always a proportional right and I always said there are always 30% of good work 30% of mediocre I guess I guess we just have to be critical and constructive with respect to each other's work and try to to be supportive in our critical comments because for active and helpful to be good role models and some people just use the deep learning to be in fashion and to get attention to be probably I mean human factors always play a role people become friends sometimes just to get words so I mean just a little bit more careful and rigorous approach to reviewing peer review work everything methods okay that's your presentation thank you much Claire and John we also have a what-if equation on the audience along with several comments actually complimenting you for the talk maybe in email you could start with there your question we had have a three students that are doing the heavy lifting equations from the audience and asked me once go ahead yeah so first question is from hamid reza he asks what is your main reason for using l1 adaptive control over other or bus control methods okay that's a very good question that's true that l1 adaptive control input output map is identical to internal model controls input/output map but everyone adaptive control does not have a model inversion block suite so it's forward method it does not invert so it's very easy to implement and it's easy to accommodate all kinds of model knowledge updates that you acquire on your way so in that sense it's tuning notes are very easy decouples it's estimation from the control loop so any new knowledge you acquire about the system you put it into your system predictor and it helps you to get it closer to the main system and its robustness you just kill with the filter bandwidth so it's tuning it's just much easier well if you're using internal model controller every new knowledge that you require acquire about the system will require you to do modeling version again and the game of the game and game which makes it very complicated for nonlinear systems and more challenging classes of systems actually it's not even clear horribly okay then we have poison from yeah so I have a question from Blake would you mind elaborating on your collaboration with Raymarine what unique constraints of marine autopilot design are well addressed sigh oh and adaptive control my collaboration with them that was in 2012-13 what would you like me to elaborate I mean that was kind of a consulting arrangement I can't talk too much about it but it was there autopilot evolution autopilot and whatever is on their webpage that's all I can say and it was I know we couldn't publish it unfortunately a little bit consulting arrangement I can't focus too much yeah hi so Lenehan bali ass or mentions that bringing contraction with learning and the disjointed architecture that you mentioned seems to be key for a lot of significant future developments I was wondering if you had any comments about that earth kind of what you see bringing into a future developments oh I see lots of potential there because it would make all this work will have a complete framework from planning to low-level control enabling more agile and versatile missions for autonomous system we look forward to making it all happen so this is still work in progress the first papers will go to this coral khakhra and then we will see how it develops in future just follow our website our archive for things ok actually there is a follow-up question from Nima in terms of to test regeneration yes thank you so how many OSA follows up with heavy compared your proposed trajectory generated with other robust generative methods so which which tragical generation method you mean we have a few and yeah we compared so there is I mean what is of interest here so we have many aircraft with this DDP here we have NPI we have so many methods in different cases and it depends upon the context upon the application so when we had this M PPI with Al Warnock's because around it was headed in this alpha pilot he wanted just to put l1 on the top of it when we had the same DDP putting l1 on it it's a game it was his interest there we have in our non sub project we have the Bezier curves we have some our T also there involved so in every case we have something different it's not like we have one project regeneration method and that's it we have a variety of different things in different places and now we're this also contraction metric coming so know didn't do kind of we never wrote a paper on comparing different trajectory generation methods in some sense we haven't done such analysis okay actually have many questions but I always start with one one of the attractive features of and one adaptive control our d sharp theoretical guarantees so I was wondering if you could elaborate a little bit on to what extent you were able to lift austerity no guarantees in the context of automatic mdpi hdpi and so leave the guarantee so would basically provide esthetical guarantees in those contexts that's a built on top of the tradition and wanna that different alternatives so in the control in the contraction paper and in the l1 DP paper I mean you can download those from archive let's see the proofs are done completely provided in the l1 and PTI paper and the l1 DDP paper these proofs are not provided yet they'll want empathy our paper that went to Iris and their one DDP paper has not been yet posted anywhere but the framework from this contraction l1 can be adapted to provide the proofs also there we're just hopeful that it's doable but for the contraction the paper is on archive and for that l1g betoken archives although those books we're hopeful that they can be adapted to those papers as well okay great there is also question from Jeanette sorry I have to unmute myself so thank you for the great talk and IRA that was really interesting and you have answered strongly to Claire's question a lot of free versus small based that you're a strongly for model base because you have the ability to basically introduce a lot of guarantees but even in a model-based approach there are lots of opportunities for learning right lots of different ones you could learn some state representation if you wanted you could learn the dynamics once maybe cost functions well where do you see are the most interesting opportunities for learning and where should you keep yeah maybe non learning based methods in the overall system architecture CPU GPU I mean today it has to be like what's the beauty of this MVP eyes because it's parallelizable so it can be implemented in real time so so there is a price to be paid nothing comes up train so this is very important to keep in mind the minute we deployed it almost robust I get delivery drawn the project that way with marks all right it has to carry a payload the minute you to do payload or UAV it reduces your flight time so you have to budget if if my waving is precise 15 minutes the deliverers package right and it is to deliver a package that's too hard for example and it has to for 15 minutes how much learning it came to write it so it you have to budget so it has good amount of CPU GPU whatever it has it has certain amount energy based on its batteries right so that's why we're now exploring for example these deep science and it's provided by one of our professor static of desire that has energy efficient computation which is deep learning for example we go already to that level anything we can explore for energy optimization to maximize the flight time so that we can pick up more packages for longer distances so computation is your budget okay so think how much learning I want to do Versalles what distances I want to cover what robustness I want to have they are all in trade-off if 20 30 years ago my only trade-off was T plus s equals 1 today my trade-off is not limited to t plus s equals 1 ok but this trade-off is lot more it's it's this computation if it's learning it everything so everything gets into one big equation that none of us have yet maybe figured it out but the trade-offs are very complex in today's learning plus control environment so the control trade dogs were performing powerful vastness in learning plus control environment the trade-offs have not been yet completely figured out and those had to be figured out before we can answer the questions that you are raising these are very actually very good pleasure and they can lead to lots of these interesting PhD dissertations thank you next Luca right thank you so much for the talk was very interesting and this was an incredible perspective I think so I had a question which I believe is a follow up on what John was anything to unclear as well which she's certification for robotics an autonomous system as well as the role of perception and so I like using the video set here at the beginning this Learjet system in which you inject failures and disturbances and essentially elevate the system in the response of the system with and without l1 certify the performance or like you know evaluate the performance and my question for you is do you envision a similar technique to be useful for our own certification of self-driving cars certification of robots this kind of disturbance injection and I guess the broader question here is what is the main takeaway on your side out of the deployment of these very complex and real-world systems what would you want to share with the young researchers young researchers I would suggest get your hands dirty with real-world systems give you give yourself the opportunity to experience the real world system right the real world systems I will will give you the type of experience that the simulation environments don't give the learning experience that you get from touching the car touching the drone going taking the data collected coming trying going back and coming shaped here is a different thinker the thinking that gets into your brain after that experience it's invaluable you can't get it otherwise you just can't get it by proving theorems publishing going to conferences presenting that's a different experience you want to publish papers to go to conferences to present get theory news comments criticisms getting under the car loading your software coming back testing going back again and doing that for months and years it gives you different muscle that's that's a different experience you want to have it and it creates different thinker and that's very important I highly recommend all of you don't lose your young years by just being analytics get that practical experience because today's reality is the reality of all government systems and it's very important to understand it from end to end what does it take what is the epsilon what is the Delta Gold try to understand that five is greater than 4 it's it's not like 5 is greater than 4 we all know but it's different when you sense it with your this is what it means you know this is what it means and you get when you give go there it's it's important long with your chance and I it's about about self-driving cars certification was anything else that you want to share about that well some driving cars and airplanes are different in some sense right well they all have control systems and they all have certification challenges the challenges of airplanes are different from the cars because for airplanes is the stability it's different it's a disability mostly right for cars it's more the navigation in confined spaces in the perception it's a it's a close contact with the obstacles the day a plane don't have so it's these are different therefore the certification challenges are also different but the car is how you would integrated perception close in close contact with pedestrians and different obstacles around so even the communities of certification will be different but I mean one can understand what's common and what's different and leverage what's common and share the lessons learned understand the differences and try to work on the differences with different communities on the common things with the common communities I think it's very important that be partners with the right industries who are pushing it the right way right because in self-driving cars I guess the level of autonomy that people are trying to reach is the level 5 but today is the best we have level 3 right wrong I haven't heard of level 4 still the in the street somewhere so the partnership today is the most important thing that you need to have industry partner in government partner when you want to go through certification and if you don't have all three in one room industry government academia certification may be just too far unachievable good common okay thank you Thank You Lucas yeah I do want to say I love the advice of like get your hands dirty I think it's fantastic we have a couple of anonymous questions that ask what are the open problems or limitations to l1 what's an example where an l1 scheme might fail for example oh yeah there are I mean the open questions of l1 are the same like open questions of control theory right if you talk of non minimum phase system output feedback and so on these questions also exist for a long we did not solve those problem we just we just have an architecture that we didn't exist in limitations within the existed assumptions gives us an implementable architecture with easily tunable no no for which we can quantify the performance of the robots as a systematic way we can predict the margins and the performance of we came to offer those right so the open questions existed if you say I'll put feedback for no minimum phase systems we have very limited cases where we have solutions for those so I mean these questions exist people want to work on this problem and they want to reach out to me I am happy to point them to the very last paper from the last dissertation of our group where we couldn't make further progress and they can start from there thank you and we have another question from the audience since from Mussina dad have you looked into extending l1 adaptive control to a hybrid setting to address hierarchical architectures [Music] okay so Sam one more general questions related to also what the point that John was making and so on for our students what resources you suggest in order to get a better appreciation of control theoretical tools that need to be accounted for even if they are now using more you know computer science tools such as AI so what resource or what techniques you suggest that everyone should absolutely not I think before learning AI they have to fundamentally learn estimation they have to learn back propagation they have to learn the foundation the mathematical foundation is very important never use or apply anything blindly I mean there are so many tools today in AI that like this resonate decent that you can download apply use but don't do it without understanding tried needs to understand some of the basics what are you applying how are you find get a simpler version of that try to understand what's happening and then maybe once you're familiar with the tool then you can maybe get another mouth to look try to apply see what you get but the mathematical foundation is very important very important actually what you see in my background in my alma mater I always say they absolutely the proofs I learned in this university so it's year I was fake University in Armenia so this epsilon Delta proves the math the underlying foundation is very important you can't engineer safety-critical systems without the right level of rigor so it be rigorous otherwise the safety critical systems will punish you in a bad way technically and the question about Sunday night you mentioned I've at some point you mentioned virtual reality and understanding of patterning in human perception of risk one of these from the user I was just curious about how do you factor in that kind of perceived safety into the mathematical model yeah that's a good question and so what we did we work with a psychology collaborator at illinois francis warm so psychologists know apparently how to measure humans perceive safety if they're humans and they measured this positive driver hood these are for GSR signals so that skin conductance heart rate and head tilt if they measure from their skin conduct a signal they decompose they get this positive driver which measures humans anxiety level if it has certain level of activation so they do the machine learning model and they can judge whether the human is scale excited so the anxiety level they can measure but they're machine learning level appeared to be very predictive giving lots of false positives basically with to become more sophisticated for example build a machine learning model with a lattice variable using human attention state to eliminate lots of their false positives to get a more reasonable human anxiety model path planning that we started using in a cost function to the past planning for drone need but is practical every task or flying around human so that the human won't feel stressed when the drone flies around so that's maybe a subject of a separate talk but we have a paper from last year i car workshop that you can download maintain check actually it will publish even if ACM transactions on my bike in this issue human robot interaction would be doable thank you and that yes yeah I we're now at the end of today's seminar and I would like to thank professor naira Hakim Ian again for a very interesting talk and the great shown a and your message to the students about getting your hands dirty with real robots was actually also brought up last week or two weeks ago actually Wescott Kunduz MA from Boston Dynamics and there seems to be a theme here I would also like to thank our guest panelists professor Claire Tomalin and Professor Jonathan Howell for their great questions and thank you to the audience for coming and submitting all the questions I hope you're all coming back on July 24 when Syd Srinivas are from the University of Washington will give a talk on his research so thank you everyone goodbye and have a really nice day 