 Thanks a lot, to Roy and Fan, for the invitation.  It's always a pleasure to talk with the people on   campus about some of the work that is happening in  other buildings. Hopefully graduate students will   learn something about this, I would say, new area  of research. I’m not a trained plant biologist,   I’m trained as a chemical engineer, but  I’ve found this really fascinating field   which is full of lot of opportunities. I’ll  just tell you what I’m going to do today is   just tell you about some of the methods we are  developing to address challenges in this field   and then give you one very important  example. My work has covered many examples,   but I’ll just talk about one big class of problems  that we are doing. Of course, my lab does a lot   of medicine related work as well which I’m not  going to talk about today, but you can assume   that all the methods that I’m talking about would  be translatable to problems in medicine as well. Okay. You know, I think all of you realize and you  know it may not seem like that there's an urgent   need to enhance crop productivity considering how  many corn fields are around the Urbana campus,   but there is a need to enhance crop productivity.  This is a review paper that was written by one of   our UIUC faculty, Steve Long, in 2015 and what  he's showing you is the projected demand in dash   and the projected yield in a solid line. The  point that I’m trying to make here is that the   dashed line and the solid line, there's a big  difference. Traditional breeding methods for   plants give you one percent yield, but  if the world population is going to be   increased by 50 percent, 9 billion in 2050, then  those methods that we have been using from 1970s,   let's say, those are not feasible. Therefore,  there's a growing interest in this area. Then of course I have to mention the other issue  that is making it difficult to achieve these aims   is that there's a lot of environmental  stress. What you were seeing here is the water   stress level in different parts of the world,  southwestern United States. I come from India   and I live in the US, so both these countries are  facing big issues with water. We'll talk about   this water problem as well a little bit in the  context of molecular biology and plants. Right,   so we want to grow more and we want to do it under  stress. That's the problem, that's the challenge. One big set of projects in my group  that we're trying to understand is these   few chemicals. In the last five  years what we have been able to do   is to understand each of these chemicals  in great detail. These are plant hormones   and these hormones regulate all sorts of processes  in plants. Today I’ll just talk about one of these   nine chemicals and then you can extrapolate  these to the remaining systems in detail. These   chemicals are really important and they control  every single physiological aspects of plants.   You can make a mimic of these chemicals then  you can control a yield, you can make a mimic   of these chemicals you can control water  loss, you make a mimic of these chemicals   you can change the ripening time, the flowering.  All sorts of aspects of plant growth can be   regulated with these chemicals. The agrochemical  industry is still at the level where I would say   it's all trial and error, more or less. There are  regular chemicals that are made long time ago,   people are still using them and the systematic  approaches for chemical design that are   found in pharmaceutical companies were not  translated to the to the agrochemical industry,   although agrochemical industries is really big  and there's a lot of money there. But still,   all those modern approaches have not been used  and that gives us an opportunity for people who   are well versed with the methods for chemical  design for molecular modeling simulations   to bring all that expertise to this problem. This  is just one problem I want to talk about today. These are the different proteins that bind  these plant hormones. You have these 6-7   proteins here and they bind these different plant  hormones. People over the years have crystallized   these structures with these plant hormones bound.  But now you can imagine that, although we have   crystal structures for I would not say not all  plant hormone, but some of them, but they are   all in a model system. So if you if you say that I  want to do some engineering for wheat or for rice,   which are you know important crops, I have nothing  in terms of crystal structures for those systems.   This becomes a really big problem if you really  want to do modeling simulations, you are you're   modeling things for a for a you know a grass  essentially right instead of real plants. So it's   interesting and all these plant hormones also have  downstream binding partners so once these hormones   are bound, something comes in and binds to them,  and then activates downstream signaling and events   further. These are the different structures,  we have worked on all of these systems and   found very interesting work. Today I’ll just talk  about this one case, which is the abscisic acid. Abscisic acids are, if I have the next slide,  abscisic acid is a plant hormone that regulates   water loss. On the top what you're seeing are  some of the mimics of this chemical that have been   reported in literature and even now some of  them are being used in fields as well. The   interesting thing from an engineering viewpoint,  a graduate student might find really fascinating,   is that this molecule regulates water loss from  the pores on the plant and you all know the pores   are stomatas. What you're seeing here on the left  hand side is no ligand and you have Pyrabactin,   Quinabactin, or the plant hormone. You're seeing  that with these chemicals, you can spray the same   amount or give these plants the same amount of  water but you know the plant grows really well   when you spray a particular chemical and it does  not without them. It's very interesting especially   now you know with high temperatures and you can  imagine in California temperatures reaching 101   degree Fahrenheit. So if the future is going  to be hot, if you have to grow things in some   parts of the world, you need to have protection  in terms of these drought-resistant chemicals,   but there are not that many of them. In fact,  I did a literature review and we found very few   chemicals that are more effective as compared to  the plant hormone itself, and this plant hormone   you cannot display, it's not a stable outside,  it degrades pretty quickly in the environment,   so you have to make a mimic. The second challenge  is you have to make something that is really cheap   because you want to spray it over the entire state  of Illinois right, so you better be really cheap   and environmentally safe. So the challenge here  really is that the plants have these pores to take   in carbon dioxide but what happens is that for  every carbon dioxide that goes inside the plant   you end up losing 200 water molecules. You  know you can do this balance as engineers here,   that that's a lot of water. I would say 75  to 80 percent of the water that is being   used is used for irrigation and essentially  everything just evaporates pretty quickly   due to this water potential difference between  the environment and the plant. If you can close   these pores you can actually reduce water  loss but maintain productivity. It has been   demonstrated in various papers, some of this  work is from our collaborator in UC-Riverside. This is the plant hormone receptor here in front  of you and the crystal structure for Arabidopsis   came in 2009. This is a pretty interesting  molecule. What happens is that this molecule   goes in and then there is a little flap on  the top of this protein that closes. One other   striking thing that sort of caught my attention  when I was looking at these structures, is that   if you're coming from a drug design perspective,  you always see very hydrophobic molecules that   are drugs. But here in plant hormones, suddenly  what you start finding is that the pocket is not   really hydrophobic it's a really polar pocket  and it is filled with a lot of water molecules.   And it's not just true for this particular  hormone, just if I look at all the plant hormones,   you can find these hormones  binding to water filled pockets.   What is the reason for it? Now that's  not clear, but what I will show you is   that this could be a very important area for  future research and for design of chemicals.   Okay, so just hold these thoughts in mind that  this is the chemical, it binds to this lysine   in the pocket with the carboxylate group at the  end and there's a loop that closes. So this is all   great, you have a crystal structure and you  have a problem. You want to first understand   the mechanistic basis of how these things work,  so why not do molecular dynamics simulations? University of Illinois is I would say is  the home of molecular dynamics in the world.   So why not just look at the inactive-active  state and the binding of these systems and   then run long simulations and understand this  these processes? But the problem is that these   processes are really slow and if you want to  have meaningful statistics on them, you have to   do really long time scale simulations and that's  really hard even with Blue Waters on our campus. What is the other challenge? The other challenge  when I start working in this field is that,   first of all, if you look at sequence versus  structure for all proteins that have a sequence,   the structures are very few. If you compare the  UnipPot versus PDB, the size of these databases   are, there's a huge difference between them and  that you can see. This is from our review paper we   published in 2019, but the numbers are not that  dramatically different, I would say, in 2020.   Now as compared to the human proteins, the  plant proteins are even at a lower levels.   Basically there is no structural information at  all. So as a modeler, where do you start? I don't   have this AB receptor for maize and if maize is  the most important crop for which you need drought   resistant chemicals, how do you go ahead and do  it? That becomes a very interesting problem. This   is an opportunity and that also explains why there  are not many people doing molecular modeling,   or computational structural biology as we say,  for plants because there are no starting points.   It's a really challenging problem. And what  you learn from one protein in one crop may   not be translatable to others. So that's another  challenge that we work on. There is very limited,   and I will say for cytoplasmic protein there is  some information, but if I go to membrane protein,   last time I counted on PDB, there were just 100  structures of membrane proteins of any plant. I’m   not talking about one helix or two helix network  crystallized, if you look at a full protein in a   membrane, there is very little information. For  cytoplasmic protein, there is a little more,   but not that much. What makes it really  challenging for us is that, some of you might   be doing these molecular dynamics and different  techniques for understanding these ligand   binding and conformational change processes, the  challenge here is that if I don't have a multiple   structures of a protein I don't know what is  important. And if I don't know what is important,   and what I mean by importance is collective  variables or order parameters, and let me just   explain you know in briefly here what I mean by  collective variables and other parameters are some   parameters that can describe a bio physical  process. Right, so if a protein is changing   this confirmation, what is the parameter that can  describe it okay? And that's very hard if I don't   have a structure. It's like playing football  with the picture of someone playing a football,   one picture, like you're trying to learn to  play a game and you just have one snapshot. So we don't know what is important and  these proteins are not very similar to   other human proteins so the homologies are  also not pretty good. So you have just one   starting point if you're lucky and,  at least for plant hormones, we have   these one crystal structures for these, one or  two crystal structures for some of these hormones,   so I have no mechanistic idea. I don't know what  is important. So all these advanced methods that   people develop, they rely on this type of input.  You need to know what is important in the system.   You can use it as a variable and then you can  quickly investigate a very slow process. But   if you don't have this information you are stuck.  So that's the challenge, if you can think of it. And obviously the challenges for the, so one  approach is you have one starting structure,   why don't you just run really long time MD and  see all the structures? The problem is accuracy,   is one problem which we'll not deal with it right  now. But there are really long time scale so   we are not going to do milliseconds  and milliseconds of simulations.   If I’m doing it on a good GPU, you know  this is going to be a really long process.   So you need either a very huge computer  or you need to think of better methods. And then finally, once you have  done all these simulations,   let's say you do a few milliseconds  of dynamics on these proteins,   and then the problem that hits you is how do you  analyze this? This is the code that I really like   is you know how do you deal with this data  because you know if it's a few terabytes of data   how do I put it together into a model? You know  my standard would be you know something that I can   attach to an email and send it to a collaborator  and he can get useful information from it.   Or how can I generate automatic insights rather  than you know a student is spending six months   analyzing those terabytes of data? Can there be  an automatic method to deal with these large very   large simulation data sets? And so that's the  background and I hope you now understand this. So if I have to phrase it into a question  what I want to say is that how can we simulate   experimentally relevant time skills,  which are very long for systems with   limited structural data? And once I’m able to  do it, how do I convert that information into   useful knowledge? And so that's the big picture  question and that's where we are. My group is   trying to answer this question and that's  what summarizes all the research I do. Let me tell you one approach that we use  and that approach is Markov State Models.   You know this is Bioengineering seminars so  all of you would have done some type of kinetic   network models or some chemical kinetics  for cellular signaling type of problems in   your homework. So if you think of ABCD as four  species and there is an equilibrium between the   conversion between these species and you have  these 16 rates connecting these four species,   I can write down very quickly a chemical balance  here. KLJ are the conversion rates from I to J   and if I can know these rates and if  I know the initial population of these   ABCDs I can actually describe the dynamics  of this system as a function of time.   You can also use this transition probability  approach which is where your capital T here is a   transition probability matrix which is essentially  telling you "what is the probability of conversion   of A to B" if I have an I-J element of this  matrix? What is the probability to go from I to J?   Or what is the probability to just stay in the  I if you're in the I state? And this formulation   is pretty useful because you can pose it as a  there's an associated eigenvalue problem there   and you can solve those eigenvalue problems and  you can get time scales of different physical   processes happening in your data set. You can get  information, though eigenvectors will give you   information about which states are converting,  which sets of the states are losing population,   which sets are gaining population. So you can  see what kind of process is the slowest process.   So Markov Models are very useful for visualizing  slow processes, characterizing their dynamics,   and obtaining insights into the structure of a  protein. So you know there are a lot of people   working on it, if I cite you know when I  started working on this 2014 there were   not many people using Markov Models for protein  conformational change, but now you can find a   large number of people trying to use these ideas  for protein dynamics and confirmation change. So I’ll tell you one approach that we use  a lot for sampling really slow dynamics   and you will see why this approach is  better than traditional simulations.   So what you're seeing on your screen in the first  figure on the left here is a two it's a potential   it's a two potential it's called Muller potential  and this is just for illustrative purposes. So   let's say I’m sitting in this deep minima-the  blue is low energy, red is high energy-and   I’m sitting in this deep blue minima here. This  is my dot, this is my starting point and I want   to go to the other side of this barrier and it's  a rare process. What I do is we run a lot of very   short simulations starting from this point and  then we cluster all the confirmations of this   protein and then we use some criteria to pick the  next starting points for my simulation. So you can   imagine I’m running something on Blue Waters: we  submit the jobs, the simulations run, we collect   the data, and then there's a script that analyzes  that data and spits out what should be the next   starting point for my simulations. So in a way  what you're doing is you are restarting your   simulations all the time from some chosen starting  points and that is the reason for the efficiency   of this system. You'll see what is happening in  the next movie. I hope these steps are clear. So let me show you a quick movie and this is a  movie this is a you know there's again a review   article wrote in 2015 and I made this toy model  for that. So what you're seeing on the left hand   side is adaptive sampling, on the right hand side  is your regular MD simulation. So what you're   seeing here is that same amount of computer time,  same amount of integration steps, you can say,   but what is happening on the on the left-hand  side, which is adaptive sampling, is that you   are choosing your starting point to be the states  that are least visited. So what happens is if you   are starting your simulations again from the least  visited reasons of this regions of this landscape,   and I don't know what is the landscape I’m just  showing the landscape for illustrative purposes   so that you realize where we are. But I don't  know the landscape, I’m just running simulations   and then I always pick after every round  of simulation, I pick the starting points   to be the least visited state and if I  do that you know, by the nature of this   very simple simulation scheme what happens, is  that you cross these barriers much more quickly.   Whereas the MD simulations are sitting in  this deep minima and trying to jump out of   this minima and waiting for that rare thermal  fluctuation that will take it to the other side.   By design this approach is better because you  are sampling from the least visited state which   typically is the transition state. You get a lot  of information about the transition instead of   keep on sampling the minima that is already very  well visited. I hope everybody gets that. And then   I can go further, there is a conformational  change that happens in this case where you   go to the other side on the single MD trajectory  but you just got one transition whereas what you   are seeing on the left hand side is that we  have a lot of stats on the transition state   just by using this very simple scheme. Now  there are a lot of variants of this scheme   and obviously you have to show that the long  time scale MD gives you the same statistics   as these distributed simulations or these adaptive  sampling simulations and we have done all that.   So this tells you why these approaches are better;  they could be two orders of magnitude faster   than long time scale MD or three orders of  magnetic faster. You get a this huge scale up   so you can really study processes that are very  slow and observe those events which you are not   going to do if you are going to do traditional  MD. Okay so that's one approach I will show you. We were doing this, and I was doing this in  2015, and recently we have further refined this   protocol for running these super long simulations.  So now you have just one starting point and you   have to run really long simulations to see  all the other confirmation of the protein.   One interesting observation that we were finding   is, I should have given you an example of a  ligand binding here that would have been better,   but I have three examples here. On the left hand  side is let's say a substrate transporter protein.   So what these proteins do is they are open on  one side. They close and then they're open on the   other side, so if you just plot the intracellular  versus extracellular distances for these proteins   you see that there are some distances that are  very important in first half of the cycle and   there are some distances that are really important  in the second half. If I’m looking at enzyme   dynamics, the second example is a kinase. What  happens typically in, this is a Src family kinase,   what happens is that there's an activation  loop that unfolds and then the protein,   there's a helix called C helix and that just comes  inside to activate the kinase. So again you are   seeing this, that is in one half of this cycle  there is something, some variable is important,   and the other half another variable is important.  In protein folding, if you're trying to do protein   folding, what happens is protein collapses first  and forms this sort of a gooey state and then   there is a movement of the protein to go to the  native state. So if you plot RG versus RMSD you   realize that “oh you know there's a collapse”  and then there is a search for the native state.   So this is very common in a lot of these  processes that you'll see you'll see a   L-shaped landscape if you choose your variables  properly for a conformational change of protein.   So one of the things that we want, we thought that  if I know what is important based on my current   simulation data, what is important in a particular  region of our free energy landscape of a protein,   then I can make it even more efficient. So what  was happening in the adaptive sampling is I’m just   choosing the least visited states. I’m trying to  explore all the directions from this one starting   point but if I know which variable is important  at this point in the trajectory then I can just   accelerate it and then the current simulation  data has to tell me. I don't know it a priority. So we use this method, we have this method  called REAP, it's called REinforcement learning   based Adaptive Sampling. I’ll give you a quick  example, and this is my one of my students used   this example and I like it a lot, is that what is  happening in this game is that you are trying to   maximize the exploration, you're trying  to maximize the exploration of the space   and the information that you're taking from  your current area is the area explored and   the position of the ghost. And your goal is,  or your policy is, moving direction away from   the ghost while maximizing your awards. So  this idea of using the current information   to maximize your rewards can also be used a  very simple example of reinforcement learning.   You can also use this in molecular  simulation first when you're sampling   and I’ll give you a quick example. So what we have done is I’m showing you an  L-shaped landscape as a standard system.   On the first figure tells you the regular  molecular dynamics. The second figure is   the adaptive sampling that I just described, so it  does better. But the third figure is when you know   that X is important in the first half  and Y is important in the other half,   then with the same amount of simulation time you  can actually see these big conformational changes.   So what we do is we define a lot of variables   for the system, in this case you know X and  Y are the two variables that are important   and we also added another variable here Z which  is a random variable. So if this variable is   not important or related to the conformational  chain it should drop out from my considerations.   So what we do is we choose a lot of these  variables X and Y and we attach weights to them   and we give all these three variables, one Z is  a random variable, we give them equal weights   at the beginning. And then based on the simulation  data we learn the importance of the variable   as I’m running different rounds of simulation.  And so initially you find that the X is the really   important one and then the Y becomes a really  important one and then you have explored this   region and then eventually these X and Y will come  to 0.5 if you keep on running your simulations.   And then Z which was the variable that is  not important for this system its weight   quickly drops out because it's just a random. So  what you're doing is you're attaching weights,   you have a list of variables you're attaching  weights to them, and they are learning those   weights during the simulation to sample more in  a particular direction and what we have been able   to show is that we can discover of for this toy  potential, I will show you, we can discover the   full landscape pretty quickly whereas regular  MD and the least count based simulations that I   described earlier they actually they do good lease  count base, MD does well but not good enough.   So you get another order of magnitude faster  sampling here if you know the important variables. I’ll give you one example. So my group works a  lot on kinases, or I was working a lot on kinases   I should say in my postdoc as well, and here  on plant kinases we have done a lot of work so   I’ll give you one example on using REAP  for this system. So here you're seeing a   big conformational change that's happening  which is this red loop. Red loop unfolds   and this orange helix moves in.  That's the conformational change. So   let me show you, this is the inactive state so  you have this red loop is completely folded,   this orange helix is outside and this hydrogen  bond between a glutamate and lysine is formed.   And I’m showing you the underlying free energy  landscape which turns out to be an L-shaped one.   So what happens when this protein  activates, if you see the animation,   you know it's not just that this loop unfolds,  this helix moves in, and then there are these   four residues, they're called a regulatory spine,  and they perfectly align. Right so let's see this   again: so you're seeing this what is happening  yeah so there are multiple small conformational   changes that are happening in this protein and  you can give them a list of important variables,   you can make your list as long as possible  and once you have a really long list what   this approach is doing, the algorithm that we've  developed is doing, is attaching an importance   to all of those variables and if these certain  variables are not important they just drop out. So let me show you a trajectory  from REAP. What is happening,   and you cannot even distinguish it from a regular.  It realizes that the A loop is the most important   direction it catches a higher weight to it. So you  see the unfolding in the A loop direction and then   it says that “oh I have sampled a lot on the A  loop side and it has more weight to the Y axis”.   So this is the hydrogen bond moving  between from this side to this side.   So let me show you again, you see this  hydrogen bond was formed in the active state.   So this is a trajectory from us and this  process takes several hundred microseconds   but now with just few microseconds of data  we are able to see the full advantage. Okay so I’m giving you a lot of test cases for  this and these are the two variables. We chose the   first variable is the unfolding of that red loop  and it's important in the first half of the cycle   and then in the second half of the cycle your  this hydrogen bond shifting for the orange   helix to move in. That becomes important and it's  really good. These are several hundred instances   of different algorithms used for sampling and  you see that our approach works much better. Let me move quickly, so some people say “okay you  can do it really fast but where is the list of   the coordinates”? And in plant biology that's the  big problem. If I have a single crystal structure,   I don't know what is changing. Kinases are great  because we have 1500-2000 structures of kinases   in PDB, so I can just look at those structure  and say oh XYZ these are all important distances   that would change in a protein. But for plant  biology if you're a single protein structure   where what is important I don't know what is going  to move at all in the protein. So this became an   interesting problem, where are the a priori  reaction coordinate if you want to sample these.   And you know the interesting idea is, again  I go back to these, that there's a lot of   sequence information. So if you really want to  sample these real rare processes in proteins,   you have a lot of sequence information that is  available. So I’ll show you one quick example.   What people have done, this is a very interesting  work from Deborah Mark's lab in 2011, they   actually calculated what are known as evolutionary  couplings. So these are correlated residue pairs   that co-evolve during evolution and they say  these residue distances are very important for   folding of the protein. What they  have shown in subsequent papers   is that you can actually fold proteins if  you put these distances as a restraints.   So one thing, though I mean our contribution  in this story is that we said you know these   distances could also be very important for dynamic  change in the protein all the conformational   changes in the protein, they may not just  be coding for folding of the protein. These   co-evolved residue pairs could also be coding for  the dynamics and that was a very interesting idea. So typically what people do is they take these  coupled pairs and when the protein falls these   residues come together. And they say “oh this is  very important for folding”. So you can predict   this structure but what would happen if a protein  is changing shape is that some distance some   residues will come together and some residues will  be very far but when the protein conformational   changes, the other set of residues, which is the  blue residues here, they can come together and   the red ones now move far. So when the protein is  undergoing these dynamic conformational changes,   some of these distances or the couplings  evolutionary couplings they call them, they could,   when you do structure prediction, they could be  predicted as outliers or some people will say   these are false positive. But actually what we  were able to show is that these false positive   for structure predictions actually are very  important for dynamic conformational change.   I’ll go back. So this picture is from Nature  Biotech paper 2012 from Deborah Mark’s group. So what we were able to show, and this is a very  complicated picture let me just summarize it   for you, don't worry about the ticks these  are time independent components and stuff,   imagine this is just a free energy landscape  for a protein conformational chain so this is   for a transporter for which we had a lot of  data, and what we were able to show is that   if I just look at the top five  evolutionary coupled residue pairs   I can describe this free energy landscape. And  then X and Y axis are the two slowest degrees of   freedom in this protein. So that's how you can  imagine it. So tick one is the slowest degree   of freedom, two is the second slowest degree of  freedom in this protein, and there's an algorithm   to identify them and I’ll not go into that. But  the interesting thing is that what we find is that   evolutionary coupled residue pair number  three and five are the ones that can explain   the slow processes. So if you look at just the  third highest rank evolutionary couple residue   pair and the fifth one, you can describe  the change in this protein completely.   This was very interesting. What happens to  one, two, and four, people ask me? One, two,   and four are coding for the folding and three and  five are coding for the dynamics. So this was very   interesting and we did it for all the proteins for  which we can find a large molecular dynamics data   set. So that we can identify the slow degrees of  freedom that are involved in the conformational   change and then relate them to the evolutionary  coupling. And what we were able to show is that   you just need to look at the top one percent  of these evolutionary coupled residue pairs in   any protein in our set and that will tell you  the important variables for conformational chain.   And with the REAP what happens is you can give  that list to the REAP and it will throw out the   folding couplings from it will just use the  conformational change related residue pairs   for dynamics. So this is how we can  start from a single structure, identify   reaction coordinates, that you cannot  if you don't have multiple structures   and then run these long time skill simulations  really fast. I hope that these ideas become clear. And then finally, this is a more  recent work from a graduate student,   is that you can use these evolutionary pairs also  to predict multiple structures of the protein.   So imagine I don't have multiple structure, I  have no idea about what changes in a protein.   So we have developed this algorithm called  Fingerprint Contacts which basically identifies   the key clusters of residue contacts that change  during the conformational change in a protein.   We have applied it to a lot of different  systems. Here I’m just showing you one problem   where you have a protein that undergoes an open  to close transition. So the magenta and the blue,   these are the two confirmations and we started  from the blue one and we removed some of these   important residue pairs and we predicted the  structure and we can get an open structure   and there's an algorithm to identify these  important couplings and stuff. So this is a very   interesting work. Now you can take a plant protein  and you can use sequence information if it is   available for that protein, predict the important  set of contacts that need to be removed to get to   a new confirmation of this protein and from there  you can get important variables and insights. Okay so this is what this is showing, that  this protein there are clusters of contacts:   cluster one, cluster two, cluster three.  If you break any of these clusters you   transition to a new confirmation and that's  how we have identified this for multiple   cases. This is actually a  published paper recently. So we use or we developed all these methods. There  are many other ideas that we have developed for   studying plant proteins but with using all these  ideas we can actually look at the hormone binding   and receptor activation. So what I’m showing  you here is a conformational network of this   PYL proteins which bind abscisic acid  which is our drought resistance hormone.   And what you're seeing on the left hand  side is a network of confirmation that   this receptor can take. We started from  one conformation, which will be one circle   in this network of confirmations, we started  from one of them let's say in this purple blob   which is ABA is outside and the protein is in  its inactive state. And then we simulate and get   this entire network of confirmations and we also  get the active structure with the ligand bound   and on the left hand side you're seeing the  simulation dynamics. So this is three milliseconds   of simulation. So you're seeing multiple ligand  binding and unbinding event. On the Y axis you   have the ligand, which is ABA, binding to the key  residue in the binding pocket which is the lysine,   if you remember I described it, and so you're  seeing unbinding-binding of this hormone over a   really hundreds of microsecond time scale. And you  can see multiple events. On the top you have this   closure, the loop closure of the  protein, happening as the ligand binds.   So we can describe this really rare processes now  with really long time scale dynamics. I can also   convert it into a free energy landscape. So this  is again the same distances and same variables the   gate loop that I showed you at the beginning. ABA  is unbound, it goes into this intermediate state,   and then there's a big barrier here which  is 6-7kcal, which is a really high barrier,   and the ligand goes in and then the protein  closes. So what is happening here, ligand is that   the mouth of the protein goes in and then this  loop undergoes a conformational change to lock   it inside and this makes sense, 7cal. So it tells  you that there's a very high barrier and there's   an opportunity to maybe reduce this barrier for  plant hormone binding. And we have done different   things to reduce this barrier. I’ll just talk  about one very important observation which is   what we found is as this plant hormone  binds, they actually shed a lot of water.   ABA would shed up to 30 water  molecules and the receptor itself would   lead to will shed like 10 water molecules. So  it's a water filled pocket, the ligand comes in,   it removes a lot of water from the pocket, and  then the ligand is bound. So what you're seeing   on the left hand side is a trajectory of ligand  binding and you're seeing how the number of waters   that need to be excluded for the  ligand to bind as a function of time. So this was a very important observation that  water is the big barrier and I’ll give you   some very quick. I have only a few minutes  I didn't realize. So I have like 10 slides,   so I’ll be a little fast. What we were able  to, so water is really important for ligand   binding and people don't appreciate it much,  there are a lot of examples for example biotin   streptavidin binding it's very strong  binding, 10 raised to a minus six nanomolar,   and it's because there is this five-membered water  ring that is formed at the interface and there's a   huge amount of energy. Once you release these  waters, you get a lot of gain in energy, free   energy, and that's why there's such a high binding  similarly for a lot of drugs. Just putting in,   let's say a methyl here, methyl group on this  cancer drug what happens is that it displaces   a water molecule and that makes this binding  much more favorable. So you know 1kcal would   mean five times higher binding affinity by  just adding a methyl group to a chemical. So what we were able to use was we were very  interested in looking at the solvation effects   and the reason is that a not just ABA but all  plant hormones have water in their pocket.   And so we want to look at how this ligand moves  into the protein and then it displaces water. Some   waters remain inside. What is the contribution  of the waters in this ligand binding process? So we used a lot of different methods and  theoretical techniques to identify these   hydration sites and now once we have identified  this hydration site we can calculate the energetic   contributions of removing these waters using a  inhomogeneous solvation theory and other methods. So what we do is from our simulation we identify  the waters that are really important inside the   protein. Let me go to the next slide and there  are a lot of waters, they were like roughly 30   water molecules that need to be removed, and  we can classify these water molecules into   different groups. And then I can, so we have  got favorable-unfavorable which means they are   making a favorable interaction with the protein  or an unfavorable interaction with the protein   are these frustrated means that are they  interacting. How different is the native   environment of this water from the bulk solution  or they are enhanced means that they have a much   stronger binding in the protein as compared to  the bulk. So we have different classes of water   molecules. Just remember that we don't  have to go into these groups and we can   we can classify these water molecules into  different types of waters and we can calculate   by the water displays the delta-H and the entropy  loss. And it seems to be as waters move out of   this pocket they gain a lot of entropy and that  determines the binding affinity for these ligands. And there's obviously a lot of these are some of  the waters that remain when the protein is bound,   the gray dots here and what is their total  energetic contribution? What is the enthalpic,   what is the entropic contribution of these waters?  And we can classify it and it gives you a lot of   it gives you it can explain the  differences in the affinity. So one case that we found very interesting, and  I’ll just stop here. So this is that landscape I   showed for the hormone binding what we were able  to find, is that if you look at these different   states along this free energy landscape for  example, state 1 and state 2, state 3 and 4.   You displace different types of water  molecules as the ligand is moving in   and there are, this is the pyrabactin which is a  very commonly used drought resistant chemical, and   it acts as a very strong agonist for one  of the plant ABA receptors but acts as an   antagonist for the others and nobody  knows why it is a selective ligand.   For one set of receptors it's an agonist, for  another set it's antagonist and what we were   able to show is that because of the residue  changes in these proteins, the type of water   molecules that you displace, this molecule  displaces in this protein versus this one,   actually explain this binding infinity difference.  So you can imagine you can make a same ligand   as an agonist or an antagonist depending upon  which water molecules it displaces. So what   happens with this pyrabactin in PYL2 is it's an  antagonist because it binds in a non-productive   pose and that is the most stable pose it can  adopt in this protein and that is because   of the water displacement in it is  very different in the two proteins. So this was very interesting. So we did  it for all the plant hormones. This paper   is just being submitted and we find a lot of  very interesting things, very similar ideas. You don't have to worry about  BRI1is a brassinosteroid receptor,   AHK4 is a cytokine receptor, and,  again, same exact same analysis   and this idea of the water entropy enthalpy  loss is consistent for all plant hormones. So   we can explain the binding affinity for a lot of  agrochemicals and explain their selectivity even. So I will, and again you are seeing the same  thing for other receptors as well. So these are   all the different plant hormone receptors and the  different types of water molecules that displace. I’ll tell you, and what we have here is  the binding affinity gain and the entropy   loss for these different plant hormones and  these are very significant numbers. Binding   affinities are typically few kcal, so you see  the entropic loss is a very dominant factor   for these plant hormone binding. And this is saying we have done huge simulation  so these are milliseconds of simulations   done for these multiple systems, we can identify  the slow process which is the ligand binding and   the conformational changes in all these plant  hormones. So don't worry about this figure,   was just telling you we have sampled all these  processes of binding and conformational change. I’ll give you just one example of what we have  been able to do. For example if you look at this   is for a receptor which is a jasmonate receptor.  So look at these two chemicals on the left hand   side, what is the difference between these  chemicals? There is this ring closure here   and then there are two hydrogens that are added in  red here and this chemical coronatine is 10 to 50   times more effective in binding this plant hormone  receptor as compared to this native hormone.   And people don't explain this affinity  because their binding poses are very similar,   they bind to the same pocket, the same residues,  nothing is changing. Why this little changes and   these when I make these changes in the chemical  I don't interact with other parts of the protein   there's no difference in the pocket. So these  two ligands sit in the same space they don't   interfere with the confirmations of  the surrounding residues in any way,   so what is the effect? What is  happening? Again, what we find is   that these two groups displace these two very  unfavorable water molecules and that leads to a   10 to 50 fold increase in the affinity. So now  we can go to the agrochemical space and with this   simple physical idea, we can start designing  chemicals by putting in groups on them   and classifying them based on their ability to  displace water in these pockets. And with that we   have been able to explain, successfully explain, a  lot affinity for a lot of different agrochemicals. And I’ll stop here one other area which is very  interesting and I thought is funny, is that   there's a big competition for growing big, there's  a large competition even in Champaign County   for growing big pumpkins. And Li-Qing Chen is my  collaborator in plant biology here and she found   these set of transporters that transport sugars  from one part to the other on the protein. So what   happens is there's photosynthesis in the leaf and  then the sugar goes from the leaf to the fruit.   And it happens via these transporters  and nobody has studied their dynamics.   We don't know how to regulate it and we have  done a large amount of work. So this is just   another example where we have done plant membrane  transporter. There's a lot of work being done.   And there's a huge competition if you want  to buy a seed for one of these pumpkins,   it will be like $2000, somebody will sell it. So you can see rare processes like membrane  transport now with these methods in plants. Again   you have just one crystal structure, so this is a  glucose transport happening in a sugar transporter   and you identify a lot of interesting residues   that block the glucose transport. We have been  able to use these simulations to design sugar   transporters that can transport different types  of sugars and express them in yeast for biofuel   area of work. So you saw this very rare  process of conformational change again   for substrate transport that can also  be modeled very well. I’ll not go into   great detail we've done a lot of work on memory  transporters and I’ll stop with last slide here. So you know one of the things that we really want  to do, and I think the entire plant biology or   crop sciences area is sort of realizing, is that  there has to be if we are looking at this circle   of understanding of a sort of a scientific problem  modeling has to play a really important role and   I would say there are very few groups, which  is an advantage when you're starting out   that you can get and nobody is doing it. So you  can attack all sorts of very important problems   in this area. But what you really want to do is  to develop this integrated pipeline where we have   experimental data from our either  in my lab or with collaborators.   We analyze this, we model these systems,  they obtain new understanding, new questions,   and then design better experiments. And this  cycle is sort of missing in the field of plants   and so what my group is essentially  doing is just to build this cycle and   we have been very successful because again the  reason for that is there is not many people   working on it and so it's a very ripe area for  research and a lot of lot of good opportunities. And with that I end I think you can take few  messages from this talk: there is limited   structure information, conformational dynamics is  difficult to sample for planned system because we   have no mechanistic information, and therefore  we need computational approaches for this field,   and it has its own unique challenges and that's  where we are. So these are some of the papers   where we have described the methods that I  talked about and with that I’ll just end. Most of the work is done by these five people,  three of them have graduated in the last couple   of years and there's one student. A couple of  them are still in my group working on it. I   showed you some transporter work that was done  in collaboration with leaching and I thought   I would talk about some work with Eric Procko in  biochemistry but he's also very close collaborator   on different projects. So again with that I would  just take any questions that the time is left. Thank you Diwakar, that was fantastic talk  and really great work from you. I have   one question but I will let audience ask  their question first and see if there are any   questions from the audience.   So just to the audience you can also type your  question in the chat box if you like, then we can   read the question. Okay I guess I will ask my question.  So you did a lot of work in terms of   mapping out the conformational landscape  of the different protein structures,   I’m just curious actually how sensitive are the  conformational landscape are to the structural   changes in the proteins? When you show the  slides where you map all the conformational   landscape energy landscape for different plant  proteins and they seem to be quite different.   So I was just curious that how much  will a confidential landscape of a   particular protein change if I slightly  perturb the structure of the protein? I would say it could it could change  dramatically. I mean think about mutations are,   we all know that if I introduce amino acid  mutation at a key site, I can kill a particular   minima in a landscape essentially. Or if I  introduce for example a post-translational   modification of any sort on a protein and we  have shown, I’ve not talked about it, I’ll just   in the context of the work I’ve already shown,  I can say for example, we found out that   on hot days the agrochemicals don't work. The  drought-resistant chemicals stop working on a   really hot day and that has been a problem;  when you want them to work, they don't work.   And the reason for that turned out to be that that  there's a post-transformation modification of this   receptor where some of the tyrosines  in the binding pocket get nitrated.   So you you're adding an NO group to a tyrosine  and then it just completely kills the activity   of the hormone and we were able to show that you  can actually design a chemical that will bind   to this nitrated protein. So if you've a very hot  day when the chemicals are not working you should   use this particular chemical. So you're seeing  there's a tremendous change with just a little   modification. So the landscape, the minimas  that I’m showing you in different landscape,   the active minima will completely  disappear from the landscape,   in this case. And when you have a new hormone  that comes in, a new chemical that comes in,   it can actually bind to this modified  protein and then you restore that minima.   So there's more physical chemistry perspective on  how these molecules are working but it can have   really practical implication and huge changes  in activity, with very slight modifications   and the good thing is that the simulations  are accurate enough to capture these effects   of these small changes. And I would not have said  that when I started my PhD in 2006. I would have   said that the error bars are too huge for me  to say that but now, in 2020, I think we can   say that the accuracy problem is also somewhat  resolved. Not fully but it's somewhat resolved. Do you think the, so what do you think are the  main factors that drive the advance of technology?   You think it's the advance of computing  techniques plus the modeling and something else? So if I go back and I think look at what  has happened in last like 10 years in   MD field, so obviously hardware has driven a lot  of innovation. With the GPUs, like 10 days ago   the new GPU that came out like 3070s, they can  simulate a microsecond on a small system per day   and if you do 100 days of simulation on that you  can, sorry thousand days simulations, on that as   three years you can actually sample on a single  machine you can sample these rare processes in   three years and but if you have hundreds of these  which would be for any large computing group if   you have 100 of these you can do that in a month  few months time. So the hardware has driven this   big speed up. What has happened more recently in  the last few years is that the accuracy problem   is not going to be solved by just by  more sampling or getting more stats.   If there's an intrinsic inaccuracy in the models  itself that means you need to have a new model.   So what has happened is with this all these all  these ML (machine learning) developments recently,   now you can have more accurate potential.   So you can instead of looking at a 1kcal  accuracy for ligand binding affinities,   you could be going sub kcal which is good as  experiments. So I would say hardware drove the   speed up to some extent. Most of it, most  of the speed up comes from the hardware,   smallest speed up comes from the software. But if  hardware gives you 100 and software gives you 10,   you suddenly have 1000. So the methods give you a  speed up but hardware has given you a bigger speed   up I would say in the last 10 years. And then the  accuracy problem is ML is solving that for us. Now   another limitation that ML is solving now  is doing reactive dynamics which is like   nobody touches it, it's too slow. You do DFT, very  slow, you can simulate few hundred atoms only.   So now with new techniques some of those reactive  dynamics some of these accuracy problems are also   resolved. So these are, so I hope that I have  answered this long answer for your question. Oh yeah, wow, cool. So hardware, software both are both are important. 