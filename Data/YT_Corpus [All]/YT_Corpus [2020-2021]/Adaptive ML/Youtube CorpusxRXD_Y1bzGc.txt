 Janet Callahan: Hello. Tony Pinar: Tony Janet Callahan: Good to see the team. Welcome, everyone. Janet Callahan: Thank you in advance, Susan. Janet Callahan: And Bryant. Janet Callahan: Oh, Tony. What a beautiful day here. It is Janet Callahan: 79 degrees. I was just reading Janet Callahan: Oh, wow. Yeah. Tony Pinar: I'm in my cold basement your Janet Callahan: Case, he had to. Show me, show me your full basement. Janet Callahan: There you are. Janet Callahan: I descended into Michael basement twice to do laundry. Janet Callahan: The laundry stuff is down there. Janet Callahan: And it's Janet Callahan: It's remarkable how much colder it is down there. Yeah. Tony Pinar: Well, we also have air. So it's also the air conditioning schooling it off down here, too, so it gets kind of July. Janet Callahan: Yeah, no, I'm it. Well, you probably can't stay down there all day. Then can you you Tony Pinar: Gotta go with pretty hard. Tony Pinar: By the end of this, I'll be shaking, you won't be able to see me clearly Janet Callahan: Do you go down there for peace and quiet, though. Tony Pinar: Oh yeah there i i. This is also where my music room so I play guitar. Quite often down here. Tony Pinar: This is also my home office. So I'm down here. A lot of the day anyway. Janet Callahan: And you've been playing guitar for a long time. Tony Pinar: Yes, I'm over 20 years I think. Tony Pinar: By this point, Janet Callahan: You'd like in that in any local bands. Tony Pinar: No, I haven't played out in quite a few years. I don't know how people can do it. I'm too busy. I don't know where they find the time Janet Callahan: I don't either. I don't have any. The only hobbies, I have are things that, like, help the house to function. You know, I am I have them gardening or, you know, home repair and I consider them hobbies at this point. Janet Callahan: You know, you do enough gardening. It's your hobby. Janet Callahan: It's predatory anymore, it's a hobby. Oh, Janet Callahan: Oh, I can see some Janet Callahan: People who've been here before. Dr. Hunters here again. Janet Callahan: And Steve camp Chair of material science and engineering welcome Steve. Tony Pinar: 15 minutes early. Janet Callahan: Yeah, no. People chime in early. Yeah, so you guys know, you can communicate with us by sending us a Q AMP. A and even if it's not a question, you can actually just say hello. That way, if you want to Janet Callahan: It's kind of a handy handy way to communicate. So, um, Janet Callahan: Yeah, I know what Tony Pinar: One should I make the slides live or share my screen. Janet Callahan: I think I wait a little while because Janet Callahan: It's usually just kind of conversation. So maybe at five at five of us probably a good time frame. Tony Pinar: Okay. Janet Callahan: Yeah so beautiful day we had, you know, I moved here from Boise, Idaho, two years ago and Boise is what they call high desert it's it's elevations about 35 four 4000 feet and Janet Callahan: I actually think it's 3700 in my Janet Callahan: And it doesn't rain very much there. You know, we used to get about 10 inches of rainfall per year. And here in hotan were more like 50, you know, so it's like Janet Callahan: You basically don't need to water things here. You can just wait for the rain to come and Janet Callahan: Unless it's in a pot. You know, you know, you don't have to kind of run out and water everything on it and it's still mind blowing to me because Janet Callahan: You know water was practically ration and I in Boise, we, we didn't, we didn't have enough water because it's all snow melt off the mountains that you know Janet Callahan: The Idaho mountains. So it's not like we're waiting for a river to flow through us. Janet Callahan: But I'm there, but I know it's remarkable how much fresh water there is here. What an enormous asset and the Clean Air. That was the other issue with Boise was that Janet Callahan: there would always be a fire somewhere in the west and to fire just kind of like the smoke just diffusers all over that part of the US and it's just not very healthy to brief smoky air all the time. Tony Pinar: Yeah, I was the snowfall like their Janet Callahan: Snowfall up in the mountains, they would, they would. It would really accumulate. I mean, you'd get a really I don't know how many feet 20 feet. I don't know, just Janet Callahan: Ridiculous. And I'm snow up in the mountains, an excellent skiing, of course, but and big elevations right so you, you know, my husband used to Janet Callahan: That country ski there and that's that's the. It's a really crazy sport where you, where you Janet Callahan: You have special skis that have like high heels. It's kind of like a strange kind of scheme and you could you walk sideways up the mountain, then you Janet Callahan: Turn your leg around it, this elaborate procedure which I could never do. And then you walk up another and then you turn around and you go and you walk your way. The top of mountain and then you spend five minutes skiing down and then you repeat the process. You're exhausted. Tony Pinar: That Nordic skiing. Janet Callahan: They call it back country skiing and they do it because they want snow that other people haven't ever skied on before they want to have powder. Tony Pinar: I see. Janet Callahan: So, you know, and Janet Callahan: If you're less Janet Callahan: Less of a purist, I guess you can get yourself dropped off by helicopter at the top of mountain and accomplish the same thing for a lot less calories. Tony Pinar: I was more expensive. Janet Callahan: Yeah, no. So do you have winter hobbies. Tony Pinar: Oh yeah so well. Recently, we haven't done much snowboarding or skiing downhill skiing anyway. But we have done a lot of cross country with the kids. Janet Callahan: Mm hmm. Janet Callahan: So what does that mean you're dragging them in a sled, or they're actually skiing. Tony Pinar: dragging him in a sled. Tony Pinar: I'm hoping maybe this winter. Our oldest which will be for this winter, he'll be able to go on his own, a little bit, but it's mostly just a trailer that attaches to your head. And Janet Callahan: Saying it's your job to pull the kids or do you each pulling kid. Tony Pinar: My wife gets both because I can't do it. Tony Pinar: I'm not as I'm not a good skier. So I'll just follow her. She's really good. She's been doing her life. Janet Callahan: Now that takes a lot of string like serious thing. Tony Pinar: It is, but she's into that too. Janet Callahan: Well then what do you do, and it's a it's a downhill thing Woody, what do you do, do you kind of like let the kids go first and slow down from behind. Tony Pinar: And she's able to break somehow enough to Tony Pinar: Really, I don't know. Janet Callahan: I can cross country ski except when it's downhill. Because, you know, I just can't snowplow and cross country skis, it doesn't work at all. Janet Callahan: They're not stiff enough to let you dig in and I do not like the concept of falling anymore. I just the whole idea of falling. It's not so Janet Callahan: My husband is a much better speaker than me and Janet Callahan: You know, I just take my skis off and start walking down the hills like Janet Callahan: So, Tony Pinar: You have to strap a sled to your back or something. Janet Callahan: Well, I don't know, I, the heartbreaking. Yeah. Yeah. Well, when he, when those backcountry skiers there. They've got some sort of special skins on the Janet Callahan: That sort of stick to the bottom of their skis and that's how they have the traction to be able to kind of march up the hill like that. Janet Callahan: And this is the this is the crux move like if you do this back under skiing and now you're at the top of a powder Hill and you're going to stick ski down Janet Callahan: You stand on one foot, and you raise like one leg in the air far off the ground, so to speak, and clear your reach up and you pull the skin off and keep your balance on one leg at the same time you're pulling and pulling Janet Callahan: And then you roll it up and put it away and then you do your other leg. Janet Callahan: I went back to skiing once that was it for me. Tony Pinar: More than one is your ankle attached or the back of your heel is it attached to the ski or is it able to lift. Janet Callahan: It lists. And then I think you lock it in when you ski down the hill, but it if you end up with kind of somehow that little bit of lifted the heel. Janet Callahan: Helps you get up the hill. I see. Janet Callahan: Yeah, for that one time we just sold my skis and that was it. Janet Callahan: Because the other horrible thing about backcountry skiing is if you fall, you know, fallen in powder right and standing up in power is almost impossible like trying to get back to your feet, almost impossible. Janet Callahan: You know, standing up on snow, snow, when you're falling down wearing skis is one thing, but the first because you can't stand up without the skis on because you sink to the bottom of this you know all this powder. Tony Pinar: But Janet Callahan: You have to be able to stand up with your skis on somehow and yeah Janet Callahan: Yep. Janet Callahan: Know what I really needed to get down that hill was snowshoes. That I needed. Tony Pinar: A problem there. Janet Callahan: So hobbies for you. Guitar playing for many, many years. What kind of music do you like to play. Tony Pinar: I'm all kinds. It started Tony Pinar: I had like a mental space for a while. Heavy Metal phase, but I kind of drifted away from that. Tony Pinar: I think everybody goes through that because that all the playing is so flashy, you think, Oh, those guys are the best, but then you learn how well, anybody can do that it's it's really something else. So then you kind of meander around Tony Pinar: These days, I'm more like rock, rock and blues based stuff. Is where I'm Janet Callahan: Do you sing to Tony Pinar: If I need to, to me, that's the necessary evil. Janet Callahan: Our planes. The fun part. So do you do you pick and like kind of like pick Janet Callahan: Notes individually or do you strum or do you kind of do both. Tony Pinar: Oh, I'll do both. Tony Pinar: Yeah. Tony Pinar: It's, it's kind of Tony Pinar: Go back and forth on that too. So, I enjoy playing acoustic both acoustic and electric guitar. So when I go to acoustic it's more strumming or finger picking maybe type like classical music type stuff. Tony Pinar: Or classical guitar. Tony Pinar: But then I go into a different gear and I pick up an electric and I played just straight ROCK MUSIC It's I tried to give a very Janet Callahan: Nice, nice. Maya. Janet Callahan: My Janet Callahan: My oldest son is a very good guitar player in my opinion. Anyway, he and he enjoys it. He began playing guitar with his dad, who's kind of more of a Janet Callahan: Heavy metal, kind of, you know, strong like chords and make it loud and that kind of stuff. But Daniel became a very good guitar player, it's and it's he's really good and you can Janet Callahan: Pick and strong and sing and the whole thing's. He's really good. Oh. Tony Pinar: What type of music to see and do it. Janet Callahan: Um, I would say kind of popular music, I think, is you know songs that people know that he feel one of the ones he plays really well as Janet Callahan: Blackbird Janet Callahan: Which is a fun. Nice. Tony Pinar: Yeah. No, and he's Janet Callahan: He's very good music is a good hobby. Tony Pinar: I think so, yeah, it's all, it's you can find something new every day with it never gets old. Janet Callahan: What's the latest song, you've been playing on your guitar. Tony Pinar: Oh, that's a hard question I often don't Janet Callahan: You read Tony Pinar: I often don't play songs. Actually, it's, it's more improvisation. Janet Callahan: Just coming up with Tony Pinar: Interesting guitar parts over things Tony Pinar: The last song I did learn it was Tony Pinar: A Robin trower song that I can't think of right now, but the artist is Robin trower So maybe that's enough. Janet Callahan: So do you have them do you have Janet Callahan: A boy and a girl or two girls are two boys are Tony Pinar: Two boys on one is a year and a half. The other is three and a half. Janet Callahan: One of them, sort of, I would call it almost like communion things that my oldest son's Janet Callahan: All the children, but especially the older son and his dad, they would play, they would every night right around like kind of as he became more of a teenager, they would. That was their, their fellowship Janet Callahan: They would play music together and play it loud and and we got Daniella set of pearls as well. So we had a drum set in the basement. Janet Callahan: Well, it was, yeah. Second, like where you are now so I'm just letting you know you should get your son, the set of pearls, because Janet Callahan: They'll be able to accompany you and your guitar and well in every Christmas. We got just another musical instruments. So we had like set of pearls. You know 17 guitars and, you know, just a ridiculous amount of Janet Callahan: The keyboard, you know, he had the entire band in our, in our basement. By the time Janet Callahan: The person. Janet Callahan: Say time he grew up. Janet Callahan: Yep. Tony Pinar: Oh, I've been you will like I do have a drum set in the garage and every time he goes out there. He wants to beat on them. Janet Callahan: Oh, gosh. Tony Pinar: I'd be a drummer. Janet Callahan: I think at one point, we actually got Daniel drum lessons to Janet Callahan: Which was good because he, he, you know, just just learning the rhythm. Part of it is sort of unlocks half of music, music, right, because if Janet Callahan: You know, part of it is the rhythm part and the other part is the you know the notes. And so he's, you know, if you can unlock either part of that the rest of it is more easily decoded Janet Callahan: So Tony, you can go ahead and share your screen. Janet Callahan: And we should be able to see your our first slide. Janet Callahan: One of our panelists. One of our attendees asks is, have you done much songwriting or original compositions, Tony. Tony Pinar: I just answered via text. Tony Pinar: We answer was, I've done little by myself when I have been quite a bit with various bands and other people. I've been associated with Tony Pinar: In fact, I've done a few in the last couple years I've done a lot of a virtually where they would send me a song and say, hey, I need a guitar parts. So I would record it, send it back to them. Janet Callahan: And that sort of thing is working out very nice with Kobe. Janet Callahan: Good. We can see your screen. Janet Callahan: Okay, except it's randomly. Now we get to see a line going through the middle of the screen. Tony Pinar: Oh, Janet Callahan: First, I saw part of the slide. Then I saw the whole slide that I just saw line. Now I see just a mind. Is that what you're seeing to Bryant. Bryant Weathers: Correct. I'm just seeing a line, but I did, I did see the full screen there for her. Maybe five seconds. Janet Callahan: Try doing a stop share and start again. Janet Callahan: We can see your, your well no, we can't see your screen anymore. Janet Callahan: Right now it looks good. Janet Callahan: All right, and just flashed to the second slide. And let's make sure that works good. Janet Callahan: All right, back to the first slide. Well actually leave it there. That's a good place for people to see. Janet Callahan: Because if anybody's ever dropped. That's where to go to get onto Facebook Live. If you can't log back into zoom Janet Callahan: Yeah so well. It's been in a really, you know, it's really interesting times to be at the university. You know, there's a lot of Janet Callahan: creative energies going you know lots of people have been able to kind of do Janet Callahan: You know, different kind of work than they are used to doing. So lots of our faculty members have been writing up papers and all of our modelers have been doing a lot of modeling, but the you know that the people who are research experimentalists they've had Janet Callahan: They've had a kind of hiatus from doing a lot of their research, but at the same time, many of the faculty members were able to participate in coven 19 focused research because that was considered an essential Janet Callahan: Activity and so that those those faculty members and researchers who had coven related research were able to kind of keep keep their research labs open with with rules and restrictions. Janet Callahan: And now it's full on summer here in the in the q&a just beautiful day 79 degrees, blue, blue sky with a little bit of I'll show you. I'm going to turn you show you my view out my window if I can show you my turn this around so this is what the day looks like in the queue and Janet Callahan: I got a view of this ski resort through the bush and just a beautiful day. Janet Callahan: optimum time of year. Janet Callahan: So Tony, how many of your former students do you think you invited Tony Pinar: If I'm going by a roster. It was a mass sort of blast to the Tony Pinar: Last couple classes that I had in the spring. So it would have been Tony Pinar: Maybe 150 200 Janet Callahan: Holy cow. Well, if you're a former student of Tony tell us that in the Q AMP a Janet Callahan: Just because so that Tony will know who who came Tony Pinar: Actually, one is here, who was not on that list, and he was the one asking the questions. That, oh, there you go. Janet Callahan: THAT'S DANIEL. Thanks for joining us, Daniel. Well, and then we're going to do a poll question to find out kind of who's here. We haven't done that in a while, relative to that audience is a mix of Janet Callahan: Of future students current students, alumni, faculty, and staff and Janet Callahan: Tony students are going to be, I think, a component, this, this time and then Janet Callahan: I put a category in here. None of the above. Janet Callahan: So you can prepare yourself for that panel. Janet Callahan: Well, it's 601 Welcome everyone to husky bites is my pleasure to do this Monday's in July, June, we're still in June. Janet Callahan: I've learned a lot already. And I'm going to learn even more tonight with with Dr. Tony Pienaar Janet Callahan: If you were to drop out, you can join us also on facebook live live stream which is the College of Engineering Michigan Tech's Facebook page and you can go straight to that link, or you can just jump back in the zoom meeting go ahead to the next slide. Tony, please. Janet Callahan: And so this is this evening's event has been sparked sponsored by the chair of electrical and computer engineering Glenn archer. Janet Callahan: Thank you so much. Glenn for your sponsorship and if if anyone is you're listening are interested in sponsoring a future husky bites, please let me know. We are encouraging sponsorship, because we have a lot of students in need for this fall because of the of the pandemic. Janet Callahan: 100% of your donation will go to a student in need of support this fall. And so we are actively looking for sponsors and we encourage you guys to to do that. Janet Callahan: I wanted to now introduce Dr. Tony Pienaar who is one of our faculty in the Department of Electrical and Computer Engineering here at Michigan Tech. Janet Callahan: And he's going to be speaking with us about how machines, learn and a little bit of Tony's background and maybe you can add more to it, but Tony is Janet Callahan: Is is one of our own. He earned his Bachelor's degree here in electrical engineering. And then he couldn't get enough of that. And then he earned his master's degree here and couldn't get enough of that and then got it Piled Higher and Deeper with a PhD earned in what your Tony was that Tony Pinar: Um, Janet Callahan: Two or three years. Janet Callahan: Okay, yeah, not very long ago and Janet Callahan: Tony's also active in research. And so with that I'm going to turn it over to Tony Tony Pinar: Thank you. And thank you to everybody that showed up to, I guess, all of these husky bites, especially this one. Tony Pinar: Title how new machines, learn. And so, as was mentioned part of my interest here is in machine learning. And if that wasn't a proper apparent from the title here, that's where we're going. So this talk is about machine learning. Tony Pinar: And I'll admit, I'm not really a machine learning researcher. I'm not working on these algorithms that push the envelope forward in the arena of machine learning. I'm simply a user, I use machine learning and some of my Tony Pinar: The research that I've done. And it's also happens to be a topic that a lot of people outside of academia, when you when you bring up either artificial intelligence or machine learning. Tony Pinar: A lot of people kind of put up their guard. They really don't understand what it is they think it's all over their heads. It's all black box magic. Tony Pinar: And so because of those two things I thought it would be really good to give you an overview of what machine learning is to start and then go through some examples on how the learning is actually done with these algorithms. Tony Pinar: And then at the end, I'll show you some results from other research groups that have been able to fool these sorts of intelligent things Tony Pinar: And well, before I move on, there is a note on the bottom. These slides will be made available to you. Sometime I don't know when i think they will be posted on husky like site. Tony Pinar: But when they are posted. If you are interested in this stuff you'll see there's a lot of links throughout the slides. So everywhere that you see this bluish underlying text I recommend clicking it, following the links and learning some more if you want. So Janet Callahan: He did. He just started like like this. Tony Pinar: Okay, very good. Tony Pinar: To start. So what is machine learning. Tony Pinar: So it is a subfield of artificial intelligence and all AI is is a large collection of tools that allow you to simulate intelligence on a computer to have a computer make decisions as if it were a human. Tony Pinar: The small chunk of AI that is machine learning is a collection of algorithms or recipes that a computer can use that learns stuff from observations. So it'll learn various properties from observations. Tony Pinar: And usually with machine learning. The end goal is prediction. So you want to learn something else. So you can make a good prediction in the future. Tony Pinar: And a very toy example of that is shown on the bottom of the screen here. Let's say that we've got an autonomous robot that we want to travel from this point down to the checkered flag down there. Tony Pinar: All autonomy robots need to be able to sense their environment. This one is no different. And so we've equipped it with at least two sensors. One is a camera so that can capture images of what the robot is seeing directly in front of it. Tony Pinar: And the other sensors and accelerometer that can just capture movement data essentially Tony Pinar: And so this robot will deploy it in the field pretend we haven't really told it much other than please go to the checkered flag. And so the robot traverses this path and throughout these rocks here down to the checkered flag. Tony Pinar: Now that it has done that it has collected data or observations along the way it's been taking pictures with the camera and it's been gathering this accelerometer data or in other words the lumpiness data, the motion data. Tony Pinar: So when it gets there, it can maybe take a nap. But, press the pause button or something and do machine learning. So what does that mean it can take all of that data that it captured all of those observations. Tony Pinar: And after running machine learning algorithms on it, it's going to start to associate rocks or gravel with lumpiness and it will start to associate grass with smoothness. Tony Pinar: And now that it's done this learning when we deploy it again on the same mission or a similar mission, the hope is, it can predict a smoother path because it now can understand Tony Pinar: Rocks and gravel or bumpy grass is smooth. So if you can use this to improve the drain that the robot chooses to traverse Tony Pinar: Now I hit a lot of stuff. Obviously, right. Like, what happens when this machine learning happens. But this is the spirit of machine learning. It's taking observations in this case from a camera and an accelerometer and it's using those observations to learn something about its tasks. Tony Pinar: And then finally, after it learns, it can now predict or it can do its task better. And so now that you know what machine learning is and I'm sure many of you have brought in concept. Tony Pinar: conceptions of it before you got here. This is a very popular question that always comes up when we talk about machine learning. Tony Pinar: And it always comes up very quickly. Doesn't matter what context. It's always one of the first questions that come up. So the question is, Will AI and machine learning take over the world and I'm just want to gauge your thoughts about this. Janet Callahan: I'm not allowed to vote, but I would vote, they will take over the world. Any day now because I'm a terminator fan. Tony Pinar: All right. Janet Callahan: I haven't watched them yet this summer. Again, it's like my summer go to set a movie. Tony Pinar: It looks like you're in the minority so far. Janet Callahan: I think Tony Pinar: So I don't know. Can the audience see this Janet Callahan: They can see the results live. Yes. So we see that Janet Callahan: 44 37% say no 30 28% say there's only a small chance of ever happening and 31% say they may rule the world. But Not anytime soon. And then a tiny fraction, only four people said they will take over the world. Any day now. Tony Pinar: That's actually, that's good. A lot of times people come in a very aligned with Dr. Callahan, they think that Mr or MLM is going to take over the world. Tony Pinar: I was actually surprised to see that a lot of people were saying no here, so that makes me feel a little better because I don't think it's going to happen any day soon. Tony Pinar: Let me Tony Pinar: If I close this. Will that be detrimental to anything. Janet Callahan: I usually just minimize it. Janet Callahan: Or move it off screen. Tony Pinar: I just moved it Janet Callahan: Okay, yeah, we can't see it on your screen. Tony Pinar: God Janet Callahan: We can only see it in our, our land. Tony Pinar: Okay, so we might return here soon. Hopefully I can remember the distribution of that. Janet Callahan: It's about a third, a third, a third and almost Janet Callahan: Nothing about Janet Callahan: I'll remember it. Tony Pinar: So we'll come back to that. But for now, let's keep on going. So we're talking about machine learning, but within machine learning. There's a lot of different types of learning that goes on. Tony Pinar: This talk is all about what's known as supervised learning, learning. So with supervised learning, you have Tony Pinar: Some expert, which might be you. Or it might be somebody else you have an expert that is labeling the training data for the machine learning model. Tony Pinar: And so maybe we have machine learning model that we want to train to discriminate between dogs and cats. Tony Pinar: That means we have to generate a training data set that contains a whole lot of images of dogs. Tony Pinar: And a whole lot of images of cats. And not only that, all of those image images have to be labeled with the appropriate class. So all of the dog images have to be labeled as dog. Tony Pinar: All of the cat images have to be labeled as cat that makes this a supervised learning problem. So we're telling the machine exactly what to look for. Basically, in this case. Tony Pinar: The third thing that I haven't talked about. We've talked about observation that are training data. We've talked about this machine learning model, though. We will talk more about that model very soon. Tony Pinar: We also have this thing called a cost function, what's called a function because it literally is a mathematical function, but it exists for us to tell the machine or for the machine to understand how it's doing Tony Pinar: So, as humans, we have a pretty intuitive sense on how we're doing on our tasks that whatever the tasks might be what a machine doesn't have that sort of intuition. Tony Pinar: And so what this cost function does is it lets it evaluate itself to understand how good it is doing in the learning process. Tony Pinar: Anyway, long story short, everything that we talked about here is going to be under the realm of supervised learning. I just wanted to point your attention to the fact that there's a lot of other learning methods out there under machine learning. Tony Pinar: And so now let's get to our example problem. So we all know that when we take our computer or Tony Pinar: Cell phone outside in the bright sun, it might be hard to see the screen and typically the brighter, it is outside the brighter your screen has to be in order for you to see it. Tony Pinar: And so in this example problem. I want to teach this laptop to adaptive Lee brighten their demands display with the ambient lighting. Tony Pinar: Now this isn't anything new. You probably have a laptop that will do this for you already. The caveat here as I don't want it to do it that is based on my preference. So I wanted to mesh with my preference, not the engineer at the laptop factory. Tony Pinar: And so the first thing we're going to do to do this. Tony Pinar: Sport a little or or any is machine learning, right. So, we first need training data. Tony Pinar: And what this means is I'm going to maybe go on 50 different experiments each experiment is going to give us the blue.on the screen. Tony Pinar: And what an experiment is is me measuring the ambient lighting conditions. So that's what the horizontal axis here as you move to the right. The brighter, it is outside Tony Pinar: So I'm going to record the ambient light level and then I'm going to record my preferred screen brightness. So that's what the vertical axis is showing the higher you go the brighter the screen gets Tony Pinar: And so I did this maybe 50 times and I applaud it all of those data points and I get what is shown in front of you. Tony Pinar: And just like our intuition tells us if it's bright out, we need a very bright laptop screen. If it's not so bright out we can turn the screen brightness down quite a bit. So now we have training data. Tony Pinar: But of course we need a model. And so just looking at these data. It looks like a simple model will work. In fact, if you put these data in front of any human Tony Pinar: I would argue that they would draw this straight line through it, as I've gotten shown here. And so what I've shown is just a simple line. Tony Pinar: highlighting the fact that these data can be described reasonably well with a very simple model or this single line model. Now the humans. This is obvious, but to a machine. Tony Pinar: Which line is actually correct. Right. It has no idea which one of these lines is the correct one to fit that the data. Tony Pinar: This is where that cost function comes in. Tony Pinar: So this cost function takes in our model. And remember, every model in this case is just a straight line. It takes in the training data. Tony Pinar: And then it spits out two things for the machine want it tells the machine, how well it's doing at that moment in time. Tony Pinar: And it also tells it how it can change the model to improve its fit to the data. Tony Pinar: It doesn't tell it exactly like where to put the model to make it the optimal model. It just basically says, which direction we have to move that Tony Pinar: And then when I'm saying model I'm catching myself now say model, model, model. I mean, that line, right. So each fun lines we have fear is a model, how do we push them around so that they are optimal that's how this cost function informs the machine. Tony Pinar: And so we have to define that cost function and for this problem. What we're going to do. And note that I zoomed in on some of the data points. So the blue data points here. We're just zoomed in on Janet Callahan: Here is Tony Pinar: A particular model straight line model and for a single sample. I'm just going to measure the distance from that sample to the straight line. Tony Pinar: And so for that one sample. The cost is the length of that dashed line that show on your screen. And we're going to do that for all of the data points in our training data set. Tony Pinar: So we're going to add up all of these to get our costs and if that cost is a big number, that would mean that our model tends to be far away from the data, it means it's terrible. It's a bad model. Tony Pinar: If that number is small. It means that it tends to be very close to the data. And, of course, that would be the model we're looking for. Tony Pinar: And now how does this work. Well, first of all, we just guess model parameters. What that means is we pick a random line, pick your orientation, slide it around in that picture, wherever you want it just pick a line. Tony Pinar: And then we can go into this loop right here. And when I say we, I should probably say the machine. We're going to be checked out at this point. The machine is going to go into this loop. Tony Pinar: It's going to constantly evaluate its cost and then update that line in the direction of improvement over and over again. And it's going to do so until that line is fit to our data. Tony Pinar: A picture of what's going on here. It played on your screen. I'll play it again. So this horizontal axis, it has the Greek letter theta. Don't let that scare you. All that means is Tony Pinar: A is a particular slope of the line. So think of theta as tuning the orientation of our line model. Tony Pinar: And then what this is a plot of is the cost function. So the height of these dots from the vertical or horizontal line here. Tony Pinar: The farther away. They are or the higher they are means a higher cost. It means a worst model. And so what happens, we pick a random line. Maybe that means status right here. And then, as we're in this loop. Tony Pinar: We can see that that dot starts to descend down this hill and it eventually settles where that line is minimum. Again, that is our cost. So what this algorithm is doing is it's finding the minimum cost to fit that line to these data. Tony Pinar: And after converges, and we have our model fit up the data appropriately. This is what we see it looks very similar if not the same as the line that I showed you, when I first Tony Pinar: presented this example, the one that a human drew right so we basically simulated intelligence using a machine. We've done what a human could do Tony Pinar: Although we had to do some tricks that I showed you in these previous slides to get there. But that's what we did. We learned this model based on these training data. Tony Pinar: And now what can we do with that. Well now let's suppose I bring my laptop out and I see an ambient lighting condition that I've never seen before. Tony Pinar: So what this model will do is it will measure the ambient light right here. It'll look up on this line that it has learned, where the appropriate operating point is Tony Pinar: And it will set the brightness of the display to be at that particular brightness and presumably because I've trained it using data collected by myself, based on my preferences. This will be an appropriate brightness for this situation again, based on my preferences. Tony Pinar: Just a few more details about what we just did that strategy is known as linear regression or at least three other names as shown here. Tony Pinar: It can be adapted to more complicated relationships. So it doesn't have to be just a straight line sort of thing, as you see here, it could be something Tony Pinar: Kind of squiggly like you see on the top right of your screen. Tony Pinar: It can also be adapted to higher dimensions. So in this case, we only had one dimension. It was kind of a boring problem, but this can be adapted to any arbitrary number of dimensions. Tony Pinar: And then the last two bullets here kind of go together and they fall into a common misconception. I'm starting to see Tony Pinar: It's that much that misconception is that machine learning is totally new it's cutting edge leading edge. And while some of that is true for a lot of machine learning algorithms. Tony Pinar: They're all developed using mathematics that was made hundreds of years ago. And so, linear regression has its roots roots and statistics. If you've ever taken a class. Tony Pinar: That has anything to do with curve fitting. This is sort of the same thing. You might have seen there and it was invented in the early 1800s, probably by ghosts, though there is some controversy there I'm Tony Pinar: Sorry about that. So girls, what he was doing. He was looking at orbital trajectories of comets and planets. And so you might imagine in the 1800s, the telescope. So they had probably weren't the best. So there was probably a little bit of air and as measurements. Tony Pinar: Plus, he didn't have printers like very super accurate printers or displays like this. So he was marking them down and is known Tony Pinar: As a little bit of error that might come into play there. Tony Pinar: And so after he did that over and over again for various comments and planets. He probably had a plot that looks something like this, where there's a lot of dots. Tony Pinar: Close together, but they're not on top of each other because every measurement has a little bit of error. Tony Pinar: But he was after understanding the trajectories of these objects are the orbital trajectories. And so what he did is instead of looking at a scatter plot of all these noisy data. He fed a line to it, so he could clearly see that there are those orbital trajectories. Tony Pinar: Anyway, it always blows my mind that some of this math that that we feel is very new. Tony Pinar: In reality has been around very long time. Janet Callahan: Leave a comment. All right, now let's move ahead. Janet Callahan: House was the Husky. How cool Tony Pinar: Yeah, I just found this randomly he he had that logo on there, that was amazing to another misconception Tony Pinar: So, Tony Pinar: Linear regression is great. But like I mentioned, it forces us to choose a model like us as the machine learning. We have to tell the machine which model to you, it'll do the fitting it will take care of that. But it doesn't know which model to you. Tony Pinar: And so we're going to move to the other side of the spectrum linear regression is one of the simplest machine learning algorithms we're now going to jump to the other end. One of the more complicated. Tony Pinar: Because it doesn't make us choose this model. It is completely universal. It can represent either one of these models as shown here or literally any other model. Tony Pinar: Before we dive in, we do have to go back to biology class. And so here's a picture of a single neuron. On the left we have what are known as dendrites and they all have Tony Pinar: I'm sorry I'm not a biologist, if anybody here is a biologist don't murder me if I'm gonna butcher this I'm going to call these signals. Tony Pinar: I hope that's okay. Or maybe we can call them data coming in. So we have inputs coming to the left column x Tony Pinar: They flow through the dendrites down to the cell body, and this nucleus sits there until the strength of all of those inputs is is larger than some threshold and once it exceeds that threshold. Tony Pinar: The output fires and the output goes down the axons to one or more other neurons. So there's there's many neurons connected over here. There's many neurons connected over here. And as you might imagine in your body. There's a whole lot of neurons connected everywhere. Tony Pinar: Now moving to engineering. We don't like to look at those types of pictures. So this is how I view in Iran as an engineer, we still have inputs over here on the left, we still have an output over here. Tony Pinar: You can think of these arrows as the den rights, though there is one little bit that we put in here. Tony Pinar: In engineering these W's. And those just mean weights. So every single signal or piece of data that comes into this is weighted or in other words it's amplified or it's attenuated, if you want to think of it that Tony Pinar: So we can tune. How much of those signals come into the cell body here. But again, this just weights and once the, the strength of these inputs exceeds a certain level, it fires and output to whatever is connected out here. Tony Pinar: And now, how do we go about training. These so this this artificial neurons. This is a model machine learning model. So it shouldn't be surprising that we can train it to do things. Tony Pinar: Well, the training is the same spirit as we've already seen, we need training data. We need a cost function, same as that linear regression Tony Pinar: We would feed it, the training data. We would let it evaluate itself with the cost function, it would Tony Pinar: Update itself, meaning it would update. It's dead right weights here in the direction of better performance or of improvement. Tony Pinar: It would re evaluate using the cost function, etc. It goes through that same loop. And at the end, we would have these five weights tuned to whatever our training data are, it would be fit to our training data. Tony Pinar: So that's great. One problem, a single neuron is very boring. It happens to be as good as a straight line. Tony Pinar: And so we could have used a single artificial neurons to tackle our laptop brightness example. However, if the data look like this, as shown on the right, we could not use a single neuron to do that. So what do we do, but before we do that, I want to ask you this. Tony Pinar: How many neurons are in your brain. Tony Pinar: And actually, I think I found out, just before this webinar started it might not be your brain. It's your body. Well, let's pretend that the same. So how many neurons are in your body. Janet Callahan: So the choices are 250,000 760,000,002.3 billion 86,000,000,250 billion. So my critical skills. They're telling me it's going to be in the billions, because you have three of them that are in the billions Tony Pinar: You might be on Janet Callahan: THE RIGHT TRACK. I'm gonna go at 6 billion. Janet Callahan: And the answers are coming in. It looks like nobody thinks that it people agree with me, it has to be in the billions and Janet Callahan: It looks like the tie for the top two highest need to 6,000,000,200 50 billion with about 37% each and Janet Callahan: Some of them are fewer fewer number of people believe that there's 2.3 billion at 24% Tony Pinar: All right. Janet Callahan: Answer. What's the answer. Tony Pinar: The answer is D at 6 billion. So actually, all the numbers that were here are numbers pulled from other animals. Tony Pinar: There's 150,000 though. That's kind of the order of the aunt or the fruit fly all the way up to 250 billion up to the elephant. Tony Pinar: And so obviously the number of neurons does doesn't seem to correlate with intelligence level totally that would suggest that elephants are smarter than humans, maybe they are. I don't know. Tony Pinar: But just take it with a grain of salt. If you click this link right here, you'll learn a whole lot more about this than I can give you Tony Pinar: And so we we've shown that only one neuron can only do simple things. Tony Pinar: We know as humans that if we take multiple neurons and connect them together, we can do very interesting things. And so why not take these artificial neurons and connect them into larger networks. Tony Pinar: And so that's the idea here, we simply can build a network of neurons to increase the model complexity. Tony Pinar: And in this image. What you're seeing is a collection of neurons every ball that you see red, blue, or green isn't around and every green arrow that you see those are the dendritic weights. Tony Pinar: So with that single neuron that we had a few slides back. We only had five whites to learn in this case I didn't count them. But there might be 20 or so weights to learn Tony Pinar: So the number of whites in your network kind of gives you an idea of how complex of a model, it can represent and we don't have to stop there. Tony Pinar: We can add even more neurons to really increase the model complexity. So now in this picture, all of the black dots you see our individual neurons, all of the lines are the weights. Tony Pinar: And obviously now when we are when we go to train, we have to learn hundreds or maybe in on the order of thousand waits for this one. Tony Pinar: But what can we do if we do that, well, we can do a whole lot of interesting things only one. I'm really going to dive into here. Tony Pinar: It turns out you can train an artificial neural network to recognize faces and that means you could either train it to recognize a face against an elephant or some other animal or you can train it to identify certain people within a group of other humans. Tony Pinar: But what's interesting is how it actually learn and that's kind of what I wanted to show you, using this slide. So here is just an example of a larger artificial neural network. And in this case, it looks like we kind of have layers, right, there's very clear vertical layers here. Tony Pinar: The data or the images are going to come in on the left hand side. Tony Pinar: And then it's going to get propagated through left to right, until we reach your output. And that's where our decision or decision will come from is the output. Tony Pinar: But how does the data get processed as it progresses through here. That's what's shown in these images on the top and the first hidden layer. All of these neurons. Tony Pinar: In that layer are learning to identify very low level detail. And what I mean by that is basically edges. Tony Pinar: So I know it's probably not clear, looking at these, but what you're seeing in this left pane. Those are all edge detecting filters. Tony Pinar: And so, for example, the one that I'm circling with my red dot i hope you can see that Tony Pinar: It's got like black and white stripes and they're kind of at a slant like that. So what that means is wherever we have Tony Pinar: An edge in an image with that slope that neuron is going to fire. And the same thing is true for all of these other ones, but they have different scales. They have different orientations different scales. Tony Pinar: The bottom line is this first layer learns to identified super low level detail, meaning edges. Tony Pinar: Now, the outputs of these neurons are given to the next layer and remember those neurons fire when they detect edges. So this hidden layer number two knows when those earlier neurons have seen patches. Tony Pinar: But they don't look at edges. They look at kind of the next step up and complexity. So the neuron that this is plotting right here. Tony Pinar: waits until it receives edge information that resembles a nose or think of a collection of edges that resembles a nose. So if it sees that it's going to fire and its output will move further down the chain. Tony Pinar: This neuron over here waits until it gets a collection of edges that looks a lot like a human eye. And when it sees that collection of edges it fires its output to the next layer. Tony Pinar: And so what hidden layer number two is doing is it's taking all of those edges that we have and it's assembling them into facial features. Tony Pinar: Now we get to hidden layer number three. These neurons take facial features like noses eyes and mouth. Tony Pinar: And they put it all together. So now we have neurons that are actually taking facial features and firing when those features look like a human face. And these are all different. So every neuron learn something a little bit different in here. Tony Pinar: But just looking at these, it's very clear. It's, it's, without a doubt, we have a network that is looking for faces. Tony Pinar: So to me it's kind of interesting that this learns a hierarchical pattern right we have this artificial neural network. Tony Pinar: Early layers. Learn super low level detail details that us as humans don't care about when I look at somebody's face I don't go, oh, look at all those edges, lots of different orientations. Right. Tony Pinar: We don't do that. Tony Pinar: This learns it in a hierarchical fashion edges facial features. And then finally faces. Tony Pinar: And not only can they recognize faces. They can even generate faces. And so you can go to the website that's on the top of your screen to see a fresh image that has been generated Tony Pinar: At your request of a human that is never lived before is never existed. It's simply taking all of the training data. So all of the images that we fed the neural network to do its training and it's kind of mixing and matching coming up with new things. Tony Pinar: Now there are nine images on the screen. I want you to take a look and see if you can find any faces that are clearly fake Janet Callahan: Now we got a poll going which face is clearly fake in the choices are A through H A LL Janet Callahan: I isn't a choice must have been to me. Alright, and so interesting is kind of a mix across the board. Janet Callahan: 13 nope it don't stop a is dropping all people are changing their answers. I think Janet Callahan: So right now, at this moment in time 13% of the people think is fake 8% be 7% see 10% D 9% II 3% f Janet Callahan: 2% G and 9% ah Janet Callahan: Hmm. Bryant Weathers: If you scroll down, I has 38% Janet Callahan: Oh, that's the one I can't see. It's behind my screen. Oh yeah, I can see why that one's yep I agree with that. Are there more than one correct choices. Tony Pinar: There are more than one and there may be more than identified, so maybe somebody in the audience is looking closer than I did to find these I'm interested to see Janet Callahan: What's the answer, Tony. What's the answer. Tony Pinar: Are we ready Janet Callahan: Yeah, I think so 40% think I Tony Pinar: 40% are correct, as well as the 7% deselected see. So I was pretty obvious. I think Tony Pinar: Over here we see some glasses. But as we've crossed the bridge of the nose that kind of disappear. So there's no lens over here. Tony Pinar: And then in the picture. See the glasses are again and give away the frame of these glasses goes over her hair here, but under there and I don't see an earpiece. So I think see and I are both very clearly fake though maybe there are some others D had 11% and a heads up 12% Janet Callahan: And somebody type who somebody who entered be type in why they think D is fake. I'd be curious about that doesn't have enough eyebrows. I don't know. Tony Pinar: Maybe Tony Pinar: Well, we can wait for those to come in, but I'll move on. Janet Callahan: Yeah. Tony Pinar: I'll keep an eye here and so neural networks, they can do a whole lot of interesting stuff, recognizing faces, just one small piece of the pie, they can do. Tony Pinar: The handful of things that I have on the screen here. These are just fun applications. I thought you might be interested in. But this is the tip of the iceberg. Tony Pinar: Artificial neural networks have become extremely popular a whole new field has popped up around them, known as deep learning and I really don't see them going away anytime soon. Tony Pinar: And now that you know how their strain and what they can do, or at least some of what they can do. I want you to ask yourself how intelligent Tony Pinar: Are these networks, really. And so I have three examples here and they're interesting and that it's it's kind of a trivial way to fool something, but it's highly effective. So what does that mean, let's just take a look Tony Pinar: So on the top right, we have an image of a panda to you and me. This is so clearly a panda right we know that's a fan 100% confident Tony Pinar: If we give it to a neural network that has been trained with image classification. It also says Panda, but only with a 57% competence level and okay, it's still got the correct answer. Bit better than 50% so let's just give that to the network. Tony Pinar: Well, let's take this same image and add a little bit of noise. So think of the snow that you would see on your TV. If your antenna isn't coming in like 20 years ago, I don't think, I don't know if TVs do that. Tony Pinar: So think of that type of noise, but then add red, blue and green color to it. So you get something like this. Tony Pinar: And if you add that noise directly on top of that patent image remembers just a little bit of noise. Tony Pinar: Here is what results we can't even tell we change the image right this is still so clearly a pendant Tony Pinar: But we give this corrupted noise grew up that image to that same network and it now classifies this as a given, which is a type of monkey and then confidence is almost 100% it's 99% confident that that is a monkey. Janet Callahan: That's crazy. Tony Pinar: I don't know. Some other examples. There's one down here. So this picture of a stop sign was fed to a neural net that was trained to identify traffic signs. Tony Pinar: Well the researchers in this case put four pieces of tape on the stop sign to white into black pieces they fed this image to the neural network and it says, I think it's 45 miles an hour. Tony Pinar: And so if you were writing in this vehicle in this autonomous vehicle with this technology you would go past this stop sign it 45 miles an hour, which is ridiculous because to humans, that is still so clearly a stop sign. Tony Pinar: And now finally similar sort of example this research group 3D printing a special turtle. So I'll play the video in a second. This is a special turtle. Tony Pinar: And it's special because when we take a neural network very good neural network and use it to classify what that turtle is it thinks that it's a rifle and it is very confident that it is a rifle. Tony Pinar: So what you're going to see in this video. They're going to move the turtle around and turn it, which is also impressive, which means this neural net classifies this turtle as a rifle, even if we turn it a little bit. Tony Pinar: And over on the right. This is the output from the network. So the height of these bars is that the network's confidence and then a label down here is what it thinks it is Tony Pinar: So immediately when they push the turtle in it thinks it's a rifle. It's very confident. It's a rifle and it still continues to think it's a rifle, even though the cameras moving and the turtle is moving. Janet Callahan: And I think they even put a second rifle. Tony Pinar: Well, it, it does not look like a rifle one bit. Tony Pinar: And so Tony Pinar: All three of these examples. These were these were applied to very powerful neural networks like cutting edge neural networks and they're able to fool them with these relatively simple mechanisms. Tony Pinar: So that's kind of the question I wanted to ask you is how intelligent, are these neural networks and then with that I was going to bring this question back Tony Pinar: To see if I change anybody's mind or shifted the distribution Janet Callahan: All right, let's see. Janet Callahan: I wrote down the answers from before. So, um, let's see if anybody shifted Janet Callahan: All right, it's results are coming in and Janet Callahan: Coming in quickly looks like the most popular feature is still a no with 40% and then Janet Callahan: 27% feel that there's only a small chance of ever happening 32% say they may rule the world or Not anytime soon. And so, Tony. They didn't budge much a 4% shifted to up into the No, they won't ever Tony Pinar: Okay, that's Janet Callahan: A little bit uphill there. Tony Pinar: Well, I'm glad I didn't shift at the other way. Maybe that'll be my victory. I'm glad it didn't shift at the other way. Tony Pinar: I really think you're all kind of onto it. I don't think Tony Pinar: It's going to happen anytime soon, I'm Tony Pinar: In fact, I, that was the biggest risk to me, I think, is just bad humans using this technology for bad things. Tony Pinar: It's not so much technology. It's who is using it. Janet Callahan: Good point. Tony Pinar: Good. So that's it. Janet Callahan: Alright, so we're going to take a pause for a second. And I want to thank all of our attendees for being here. Janet Callahan: Brian, I'd be interested if you can pull up that first poll that I forgot to give. I'm curious to know who is in our audience so you can fill that out while I Janet Callahan: Also brief next week's husky bike. So first of all, thank you. Glenn Archer Chair of electrical and computer engineering for sponsoring and supporting students scholarships Janet Callahan: We do need a sponsor for next week. And so the email to contact is up there. It's Brian weathers, who is also our host or co host and helping with the technology. Janet Callahan: So next week we're shifting our emphasis to civil and environmental engineering and we are. He's good, we're going to be learning about how water gets becomes drinkable. Janet Callahan: Oh, we have a sponsor. That's no a month. That's right, I forgot about that. So I think it's the week after. We don't have a sponsor. Janet Callahan: And so thank you so much in advance, Noah for sponsoring it and so relative to who is joining us here today 13% of us are future students 13% our current students Janet Callahan: 3% or friends and Michigan Tech 12% are Michigan Tech faculty and staff 6% our family of current or future students 6% are friends of friends and 49% are alumni and so thank you husky community for coming together again. It's just so much fun. I've actually Janet Callahan: For the world's biggest introvert. I've been having so much fun connecting with you through this through this medium. Janet Callahan: Alright, so type your Q AMP. A answers. And we've already got a couple people who have who have asked questions. Janet Callahan: You can go ahead and go to the next slide. Janet Callahan: And so on your zoom place if you if you scroll, your, your, your cursor down to the lower edge of it. There's a place where there where it says Q AMP. A and you can type in a Q AMP. A. After you click on it, you can type in a Q AMP. A and so Janet Callahan: An anonymous attendee asks Janet Callahan: I know you said you're not a machine learning researcher, but there is a lot of discussion, especially with facial recognition regarding bias and algorithms. Janet Callahan: Or there are some funny videos that illuminate how difficult it is for Siri or Alexa to recognize accented English all this to say, Do you know much about the work that's being done to make strides in the sort of inclusive side of this technology. Tony Pinar: Um, no, but I can talk a little bit. Um, so Tony Pinar: I don't know of any funny videos about Siri or Alexa recognizing accent accent in English, though you are right there is a bias in our algorithms. Tony Pinar: But I should say it's not the algorithm. Tony Pinar: Or how to, how should I put the algorithm itself is not biased. It is how we train the algorithm. So Tony Pinar: Biasing comes in after the algorithm is trained Tony Pinar: And remember what we need for training. We need training data. So this means that if we have a bias model that bias was existent in that training data. And that's where the problem is. Tony Pinar: A lot of the data that we've been collecting over the past decades has been filtered through humans basically right we think this is the demographic. We want to gather this data from Tony Pinar: These are the things we want to look at, etc. So it's always filtered through humans so that training data just inherently has our own biases in them. And that's obviously going to be pushed into the machine learning model. How do you make it more inclusive. Tony Pinar: I don't know. I mean, you have to, you have to get varied training data. It means we have to go back to the drawing board when we're collecting that data is. Is there work being done on that front. I don't know. I'm sure there is. Janet Callahan: There is there is. Yeah. Tony Pinar: I'm in Janet Callahan: Michigan Tech actually had a speaker in about this and it's, it's, I think one of the faculty we're hiring is actually doing research in this area, one of our new faculty Janet Callahan: I believe Janet Callahan: All right, and so K asks Janet Callahan: Well mentions that we need another option, they will take over the world and things will be so much worse than we can predict it can't be much worse than it is now, where the pandemic. Well, I better take that back. I take that back up and when Janet Callahan: I'm Tony Pinar: Sure, you know, but Tony Pinar: Maybe that's far in the future too far in the future we want to think about that right now. Janet Callahan: Yeah, I don't want to think about a worse world Walter asks, Can you give me your opinion on autonomous driving it sure seems any turtle on the road would be in trouble. Tony Pinar: Um, well, okay, so, so the turtle example that I showed you that was a that was a highly fabricated turtle. That was a very special turtle that that fooled that machine, but there are real concerns, especially with autonomous driving in this technology. I think Tony Pinar: I don't remember when in the last couple years there have been experiments where you're able to fool on autonomous car, either with a piece of tape on a road or a laser planner. I can't remember. Tony Pinar: But think about placing just some benign tape like pieces of white take along the side of the road. I'm not sure that configuration, they had, but that was enough to fool their neural net that was driving the car. So yes, there are tremendous issues that could pop up because of this. Tony Pinar: The good news is, people are working on. Tony Pinar: I guess anti adversarial Tony Pinar: agents that that's part of the reason Tony Pinar: I wanted to show you these because while yeah they are easy to fool the reason that people are working on the this research. It's not the fool the machines as to learn how they're being fooled. And how can we make them stronger so that it's harder to fool them. Tony Pinar: Does that answer your question or the question. Janet Callahan: I think so well and Pamela notes s and says, Thank you, Tony. This was my first husky bite and I really enjoyed it. I work in engineering learning and development at Ford Janet Callahan: And AI machine learning are relevant topics for engineering community. And so what I want to mention we have developed in the College of Engineering 18 different online graduate certificates. Janet Callahan: About five are which are in mechanical engineering and about five are in electrical engineering, if I remember correctly. Janet Callahan: And and they will be available. I'm assuming that they are approved by Senate and within the next month, they will be available. Start starting this fall. Regardless, those online courses will be available this fall. And so if you're interested in Janet Callahan: Learning Janet Callahan: Start looking for our online courses because these are and what a certificate is a is a stack of three courses together around a theme. And so one of the themes could be, for example, Janet Callahan: Machine Learning i don't i don't quote me. I'm not sure that's one of our certificate suite with so many. I can't remember the names of any of them. Janet Callahan: But I'll try to remember to bring a list of those next week to ask you, right. So, so I can mention them to you. Alright our next question is from Robert when training do some techniques include a something else category to try to get away from the failures, you mentioned Tony Pinar: Yes, there are. There are little Tony Pinar: I don't know if you want to think of linear regression is kind of the center of a cluster and then surrounded by a whole lot of other stuff, all that other stuff is is techniques that can help with that sort of stuff, or with those failures that I mentioned. Tony Pinar: One very common issue is known as overfitting. And so Tony Pinar: Let me Tony Pinar: Go back. Tony Pinar: So this is good. So in this example, we had a lot of training data. It was kind of scattered around and we fit a straight line to it. Tony Pinar: And in this case, that was appropriate, but in some cases maybe you want, even though you have data like this you want to use a more complicated model. Tony Pinar: And we can actually it's quite easy to find a more complicated model that can pass through every single point. You see on your screen. It's going to be some crazy wiggly Tony Pinar: Line, but I can find a mathematical function that will do that for you. Tony Pinar: That is actually not a great thing. It's known as overfitting in machine learning. In other words, your machine learning model is basically memorizing your training data where and for any other input is going to do really terribly. And so, I wish I could draw on the screen. I really can't. Tony Pinar: I don't even have any paper. But imagine. So just a wiggly line that passes through each one of these data points, but in between the data points, maybe, maybe it swings up really high, like right here and it comes back down for that data point goes way down here. Yeah, that makes sense. Janet Callahan: Well then, if they ask you, how did you get your cursor to do that. Janet Callahan: To be a red dot with a tail. How did you get your cursor to do that, you have to share that tip for us. Tony Pinar: Can you see Tony Pinar: The bottom half. Yeah. Tony Pinar: You just turn on the pointer. Janet Callahan: Oh for goodness sake. Alright. Tony Pinar: So that's what you do. So anyway, we can we can specify a really complex model that where that line is wiggling all over Tony Pinar: And when we encounter ambient lighting conditions that are exactly what we encountered in training, it will do just fine. Tony Pinar: But when we encounter an ambient lighting scenario, maybe like right here where we don't have any training data in that area. Our model will very likely be way up here. It wouldn't make any sense. And so that's Tony Pinar: That, to me, that always kind of relates to human learning, like when humans learn memorization is not the way to do it. If you memorize what Tony Pinar: You think you should learn when you get to the test. You're probably going to find you miss something that's not how you want to learn. And that's not how you want to learn in this case either you want kind of a smooth line. Tony Pinar: That represents the data. You don't want it to exactly fit. So I know that was a long winded question and it only talked about one other technique, but that's they're out there, those sorts of techniques to get out of these pitfalls do exist. Janet Callahan: But the next question is from my, my good friend Dave who asks if AI is not that good. How is Google making so much money predicting which ads will create the most sales. Tony Pinar: I think it's probably good. Tony Pinar: I think they're doing Tony Pinar: A good job in that domain. So what they're doing. They're learning models of you if you're using Facebook or Amazon or Google or anything when they're training THESE MODELS THEIR model is a model of yourself. And so, like I mentioned early on kind of one of the Tony Pinar: Things with machine learning, you're learning a model to do better prediction, the future. So when they develop the models of view. Tony Pinar: They can predict what you might want to buy next. And so if they give you a link to that item and they're right. They make some money. Right. Tony Pinar: If they don't get it right. Well, better luck next time. But that's what they're doing. I don't know how to fool. Those ones yet, though I don't have any examples of fooling Tony Pinar: Amazon's or Google's AI bots. Janet Callahan: Nathan asks, What is the difference between deep learning and regular neural networks. Tony Pinar: I'm not much Janet Callahan: My guard dog. Tony Pinar: So the image that you see here is technically a Tony Pinar: What would I call it, it would be called a sick, an artificial neural network with a single hidden layer. So this is really Tony Pinar: This is really where artificial neural networks start and stop in terms of that word neural networks. So the field of neural networks. It started with very small networks like this. Tony Pinar: In fact, you might think artificial neural networks are cutting edge. They're not that artificial neuron was invented in the 50s. Tony Pinar: People knew that you could connect them to create more complexity, like you see here on this slide. The problem is we didn't have computers that could Tony Pinar: Do the learning. There are a lot of numbers are a lot of weights in this image that we have to learn that was too complex of a task for old computers. Tony Pinar: And so while they knew they existed. It wasn't really tractable or practical to do and so research kind of stuck with these neural networks like you see on this screen now moving to deep networks. Tony Pinar: A deep network is a neural network with more than three layers. So what you see on this screen. This would qualify as a deep network. What you see on this screen. This would qualify again as a deep network. Tony Pinar: So when people talk about deep learning what they're really meaning is just neural networks with a lot of neurons, a lot of layers in them. Janet Callahan: So Tony, I've actually learned so much tonight. I can tell you we will keep answering questions until the questions are done, but I know some audience. People may need to leave. So thank you so much for joining us. Janet Callahan: I can see that we have a ton of unanswered questions or we have 10 open open questions. So we're going to keep answering questions. Janet Callahan: Dr. Dan asks, How do you see quantum computers affecting the results. Tony Pinar: Thanks George and I have no idea. I don't know much about quantum computers. Tony Pinar: If I had to guess, I would suspect that they would make the training process almost instantaneous Tony Pinar: And so one thing I didn't talk about is the is the actual computation part of the training. So we give this in this network on the screen, we give this a bunch of training images we give it labels. Tony Pinar: And then it goes into that cycle of evaluating how good it is moving. It's what it's in the direction of improvement that might take a long time for a complex tasks like this on a regular desktop computer that might take weeks. Tony Pinar: If we had quantum computers. Maybe we could shave that down into seconds or even less. But again, I don't know anything about quantum computing. I'm just wildly speculating. What could go wrong speculating on the Internet. Janet Callahan: And remember, we're recording this forever. And so it's gonna be Janet Callahan: Posted you Janet Callahan: Can people be quoting you and Janet Callahan: You know, Janet Callahan: Big fake news or whatever. Janet Callahan: Eric asks, Does the layout connection of the of the neurons change or only do the weights change. It's a great question. For example, does the style of the network get created by the algorithm or is it human created Tony Pinar: So the, the layout or the architecture is defined is typically defined by a human. Tony Pinar: So the human would define what this thing looks like. And then after it goes into training. It's kind of set at that point the architecture is set, only the weights are adjusted Tony Pinar: But there are other techniques out there were these networks are built as part of an AI process. And so in that case the human is out of the loop and they'll adaptive Lee build the network until it it is what it needs to be for the task. So it's kind of a both, I guess. Janet Callahan: Okay, William asks, Could you please talk about internet of things and machine learning. How do they interact Tony Pinar: Oh, good question. So the Internet of Things is just this concept that as computers get smaller and smaller, even down to the chip sizes get smaller, we can start putting Tony Pinar: Little tiny computers and basically everything. Everything around us. So in your light switch, maybe even in your light bulbs that can communicate together. Tony Pinar: Maybe you have the chip in your refrigerator and your toaster, just everything has one of these ships that can talk to the internet. So that's the Internet of Things. And if you think about that, if we start putting that sort of Tony Pinar: Or that sort of computation and and sensors on all of these different devices they're constantly grabbing data right machine learning and AI is all data driven Tony Pinar: We need to train these algorithms using vast amounts of data. So the Internet of Things might actually be a good thing in that regard. Right there, increasing the amount of data that's that's Tony Pinar: Available to us. Tony Pinar: Now the downside to that same thing is that now we've got all this data, we cannot sit down and sift through this data as humans and find these patterns we need help. We need machines to understand how to do this. And that is what machine learning and data science in general is all about. Tony Pinar: That's as much as I can talk about the relationship between the two. I've never done any IoT projects and involve machine learning, though they are out there. Tony Pinar: That's all I can tell you at this point. Janet Callahan: Our GD asks, What do you think are the challenges to improve the neural network. Tony Pinar: Oh, Tony Pinar: Training seems to be an issue. Currently, because it takes so long to train these networks. Tony Pinar: So I think there should be some or there's gotta be some strides taken in terms of the training process to accelerate it Tony Pinar: And then another part of it is neural networks are kind of black boxes like we really don't know what's going on the inside. We can't explain their decisions very well and that might be a problem. Tony Pinar: Right. What if we need to know why that decision was chosen it becomes kind of an ethical sort of dilemma. Tony Pinar: So in my opinion. Those two things are the shortcomings of neural nets, though I expect both of those are going to be tackled and overcome in the near future. Janet Callahan: A second question from Dave our my friend Dave is the book The Age of surveillance capitalism claims that AI is already having a huge impact on our lives today. Do you disagree. Tony Pinar: I do not disagree. I think it does have a huge impact on all of us. Tony Pinar: Maybe one example is so so in machine learning. There are there are models that we like to call recommender systems. These are systems that tried to learn a model of you to provide you suggestions of what you might like. So if you've ever shopped at Amazon. You've seen this. Tony Pinar: If you, if you've been on Facebook. I think Facebook might say, you might know these people. That's sort of a recommender system. If you watch Netflix right they're always throwing stuff in your face. You're going to love this. You're gonna love this, please watch this. I think those Tony Pinar: They're really Tony Pinar: They're pushing us Tony Pinar: Around. I'm not in a in a bad way. But oftentimes we'll just fire up Netflix and see what it presents us and we'll choose you know something in the top three or something. Tony Pinar: And so maybe they can steer us down a path we might not want to go right obviously watching one video isn't going to be a terribly bad path, but think of the accumulation. You do that over and over. Now you're letting that recommender system thing for you. Janet Callahan: And I don't think that's such a great thing. Janet Callahan: That's a good point. Janet Callahan: All right, Daniel asks, speaking of training data. If you spend enough time on this person does not exist. You can get some very interesting results when more than one face is produced in one image. Janet Callahan: One of the people may be relatively normal looking while the other is monstrous and disfigured. Is there a difference in impact between more robust training data and stronger, more complex neural networks, what are the pros and cons. Tony Pinar: Thanks for the question, Dan. Tony Pinar: I'm Janet Callahan: Is he one of your Tony Pinar: Good answer. Tony Pinar: Yes, he is. Tony Pinar: A IS THERE A DIFFERENCE IN THE IMPACT between more robust training data and stronger, more complex neural nets, so I will say the more complex, you make your neural net, the more training data you need to do the training. Tony Pinar: Just as kind of a interesting thought our example here, I did 50 experiments. Each experiments yielded two numbers right the ambient brightness and my desired screen brightness. Tony Pinar: And so that was 100 different numbers, right, the blue dots here. Those are represented by 100 different numbers. Tony Pinar: We can represent a straight line with only two numbers. If you remember back to maybe some high school math. You can represent it with a number that means the slope, how quickly the line climbs and the other number is called the intercept. It's kind of sliding and up and down. Janet Callahan: y equals mx plus b. Tony Pinar: You got it. And so really what's going on is we give this machine some data 100 different numbers. Tony Pinar: And it goes into this machine learning process. But think of it as like boiling down some vegetable broth. It takes that data and it renders it down to its essential bits and those essential bits are the two numbers. Tony Pinar: The slope and the intercept that defined that line. So what machine learning is all about is taking information that's in training data and encoding it into, in this case a model. Tony Pinar: And so for a straight line, we really only need two data points to define a straight line, right, I can pick one up here, one down there. We connect the two, we get a straight line model. Tony Pinar: Now go back to a neural network like this. Now this has hundreds, thousands, it could be millions of different weights that we have to learn Tony Pinar: Think of the amount of data that we would have to have to distill it down to a million different numbers, you need a lot of images to do that. And that also happens to be another kind of downside. Tony Pinar: To artificial neural networks. If you want to train a very large network. It's going to take a long time. But you also better have enough training data for the problem that you're trying to attack. Tony Pinar: Well, if he's older than I don't think I've answered, you have I've kind of skirted around your question. Tony Pinar: That's the best I could do Janet Callahan: If you think about how long it takes a child a baby to learn to talk, I Tony Pinar: Right. They have a lot more weights, then when the simple as machine learning models. Right. Yeah. Yeah. Janet Callahan: Interesting. All right, let's see. Janet Callahan: From Z john he says hi Tony, I took your machine learning class last year. I learned a lot from it. Would you like to share some interesting applications and machine learning with us. Tony Pinar: I can't think of any off the top of my head that are not on this slide because I just made this slide. And so these are all fresh in mind. So I would encourage you, once these slot. This the link to the slides is posted to go down the rabbit hole on these links um Tony Pinar: I'm trying to think of some that exists that are not here. Janet Callahan: Well, that's good. It's good. You get some examples for us. And so all of these, um, the video and the slides are posted on the Husky bites website. And that's where you can get to these Janet Callahan: And they're posted as PowerPoints. So you can download them and you click on the links. I believe that's our posting them. Janet Callahan: All right. We've got four open questions one from the guy Eggers does machine learning attempt to distinguish between outliers and purely erroneous data. Tony Pinar: I'm not, not by default, though there are methods that can be employed to to make that distinction Tony Pinar: Is that enough detail for you. I don't know if I can give them much more on that one. These are too hard. This is Janet Callahan: Where Janet Callahan: We're imagining we're taking it as a machine learning expert. Janet Callahan: So, Alexander asks, or states if this is all old news. What's the cutting edge on machine learning now. Tony Pinar: It is really all about. Tony Pinar: Deep learning so deep learning, as I mentioned, is, is this fairly new field that's built around neural networks and it's all about networks that are very large Tony Pinar: So it is this that literally is the cutting edge feel under machine learning. At this point, though there are Tony Pinar: I don't even want to guess the number there are 5050 plus other out machine learning algorithms that exist. Tony Pinar: And for any one of those other algorithms. You can find the state of the art. They're not just they're not dead. They're not stagnated. Tony Pinar: They're always evolving so you can look at any one of the other machine learning algorithms out there and there's gonna be some new bits that have just been developed for that. Janet Callahan: Very good. Janet Callahan: Um, Janet Callahan: Liz asks, What would you say to the attendees who are future huskies who might be interested in studying or doing research and machine learning. Are there any classes or skills or ways of thinking that they might even be doing in high school, or that they could take when they get here. Tony Pinar: So really the driving force behind machine learning is mathematics. So I would say take all the math that you can Tony Pinar: That might be painful to hear. For some of you, but take all the math. You can Tony Pinar: And then, of course, the way that we do this stuff is by programming computers. So another thing that you might want to do is look at just basic programming courses. Tony Pinar: Of which there are many both on campus and even on the internet. There are those Tony Pinar: Mo zhi are Massive Online Open Courses that you find that can help along that front and, furthermore, there's even machine learning classes also that you can find online. Tony Pinar: That are not so much meant for true machine learners. They're kind of entry level courses. So I don't go through a lot of the math, but those might be good for you to scope out as well. Janet Callahan: Well, and, um, I don't know why that made me want to mention, but we have a new approved degree program in the College of Engineering residing in the Department of Electrical and Computer Engineering, which is robotics engineering and I imagine that Janet Callahan: There's a, there's an intersection between this field and and robotics, for sure. Tony Pinar: So now that you mentioned that I'm also spill the beans that we are currently trying to Tony Pinar: Develop some like we're calling them modules. These are just basically think of one or two lectures on a topic and an assignment. Tony Pinar: We're trying to develop these modules that we can insert into some of those robotics engineering classes so that Tony Pinar: I think it says as early as your second semester. You're starting to be exposed to different AI and machine learning concepts and those modules will continue from semester to all the way through your senior design experience. Tony Pinar: And that's not only robotics engineering robotics engineering shares a lot of courses with electrical and computer engineering Tony Pinar: A little bit of overlap there. And so whether you pick robotics or electrical or computer engineering, there's a good chance you're going to see some of this in your undergraduate classes. Janet Callahan: If we keep you guys happen. That's for sure. Um, well, we were mentioning that Janet Callahan: We have one last question. And then I wanted to, I have to remember to mention tips and tricks from three chairs and a dean, which is our July. Janet Callahan: Tuesday webinar series for future students and high school students and even down to seventh, eighth grade but but i think high school, so I will try to remember dimension that to you. The last question is from Nicole and and the question is does Alexa actually learn you Tony Pinar: I don't know what you mean by learn you Janet Callahan: Well, Tony Pinar: I would suspect all Alexa does is Tony Pinar: I'm trying to think. Can somebody else's voice trigger your Alexa. Yeah, right. I can trigger somebody else's Alexa. So what I think is it's just simply a voice recognition software. So if you want to think about it. Alexis kind of the interface between you and Amazon. Tony Pinar: And so when you see or anybody speaks Amazon or, I'm sorry. Alexa, it's just listening to the audio and it's decoding what you want. Tony Pinar: After it understands what you want, then it sends that data to Amazon and Amazon, they are learning you. They want to know what you what your interests are what you like to buy. Right. And so I don't think Alexa is really learning you but it's a piece of the puzzle that certainly is learning Janet Callahan: So do you have, I want you guys to see Abby. Abby was like oh my god dog. Say hello. Andy Janet Callahan: She's taking care of me. Do you have Alexa Tony Pinar: Alexa Janet Callahan: I don't I don't I don't think I do either. But every now and then my computer will will think I'm asking it something and it will talk to me. Tony Pinar: Oh, Janet Callahan: I don't think it's Alexa Janet Callahan: All right, I do we have a last slide. Janet Callahan: To project to remind people about who's speaking next time. Brian or Tony, you might have access to that. Janet Callahan: So thank you again, everyone. Our next speaker is Janet Callahan: Daisuke Mina kata he is in the Department of Civil environmental engineering, please feel free to invite friends to this or two for the links. Janet Callahan: And then tips and tricks from three chairs and didn't attend a dean is going to be our July Tuesday webinar series. And that's focused on kind of like college readiness or difficult course readiness, we're going to be focusing on sharing Janet Callahan: Literally tips and tricks on solving problem solving technical problems. So by technical problems. I mean things with units where it's like, how many atoms are in, you know, 10 grams of copper where you know and or how you know what is the velocity of Janet Callahan: You know, you know, this physics problem. And so I'll be starting leading off. Janet Callahan: So I'm the Dean giving tips and tricks. But, and then the other chairs are the chairman of electrical and computer engineering Glenn Archer will give a Janet Callahan: One of the, one of the webinars, the Chair of civil Otter Morris will give one of the webinars. Janet Callahan: And the chair of Gomez, which is geological and mining Engineering and Sciences john jerky will give the one of the webinars to and we think what. And again, they're gonna be 20 minutes with Q AMP. A. We don't think the Q AMP. A will go too long. Janet Callahan: But you guys might might enjoy us and alumni are welcome to join us to if you want to brush up on your dimensional analysis we. You are welcome. Janet Callahan: Thank you, Tony. I learned a lot. I actually feel like I have a layman's under ability to talk about machine learning now and it was really your outstanding teacher. Thank you. Tony Pinar: Oh, thank you. And thank you to everybody for joining. Janet Callahan: Yeah, I know. And thanks, Brandon. Sue and Kim for the backup team. Janet Callahan: George and says, Thank you, Tony and Nicole says no. Alexa, but many friends have Alexa, so. Alright everyone, you take care. It's been awesome hanging out with you again. And until next week. Janet Callahan: bye to you. 