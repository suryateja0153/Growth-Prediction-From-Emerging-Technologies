 hello everyone I'm Jay Myung I have the honor of giving the first talk in this symposium on optimal experimental design or OED in short. First of all we the three organizers, Philip, Mark and myself, are very pleased to have the symposium at the virtual mathematical psychology conference. We would like to thank the conference organizers for accepting our proposal and also thank the symposium speakers who have kindly agreed to participate in this exciting event. This talk will actually be a joint presentation by myself and Mark. The talk itself is organized as follows we will first give a broad brush overview of optimal experimental design including a historical perspective and a quick guidance to the other seven invited presentations in the symposium. We will then spend the rest of our talk in discussing our own work as a concrete application examples of OED. Experimentation is at the core of a scientific inquiry whether one is interested in studying the neural basis of memory dysfunction in a cognitive neuroscience experiment or in understanding the effects of attention in a visual cognition task. Simply put the main goal of OED is to optimize the joint decision in order to achieve a given experimental objective. This is achieved using computer algorithms that are being applied iteratively during the course of an experiment importantly. OED is a model-based approach in that it requires having a formal models of the phenomenons under investigation as for the experimental objective it can be model selection or parameter estimation as I shown in this slide or any other objective properly defined speaking of the history of the OED. The basic ideas and insight go back to the 1950s originated from Lindley and Kiefer's seminal theoretical work. One of the very first application in psychology was for psychophysics experiment pioneered by Watson and Pelli in the early 1980s. The next major psychological application was in psychometrics especially the computerized adaptive testing. Of course there are many other applications of OED in other domains such as engineering physics neuroscience even systems biology. This popularity in recent years is mainly due to the advance and availability of powerful computational algorithm the lack of which had been a major hindrance to realizing the theoretical insight of OED into its practical application. Obviously there are many other uses of OED given once experimental objective. In this symposium you will see a variety of application examples demonstrating the power and versatility of OED. Just briefly the experiment objective can be to optimize model discrimination or parameter estimation as you will see in this talk but it can also optimize sensitivity and specificity measures specifically in clinical setting as in Lu's talk later. Further OED can be used to induce certain desirable behaviors or brain states. Application of OED does not have to be in the traditional experimental setting it can be applied to crowd sources experiments computational psychiatry experiments and even surveys as you will see in these three talks up here. On the computational front some of the state-of-the-art machine learning tools such as variational bayes, DNN and bayesian optimization can be combined with OED to further improve its performance. Finally in our own lab in collaboration with dr. Ahn's we have recently released an open-source package called ADOpy available on the github. Of course there are other OED packages out there I'm not mentioning here Transitioning from an overview of OED to our own work the remainder of this talk will be about adaptive design optimizations or ADO in short. ADO is an OED system that we have developed for optimizing designs for cognitive science experiments. Briefly the illustration here depicts the three iterative steps of ADO. The first is the design optimization step in which the optimal designs for the next experimental trial is identified. This is followed by conducting an actual experiment which the optimized design to collect the participant response. In the third final step here we then use the observation to update the current knowledge about the underlying cognitive process Specifically this is done by updating priors to posteriors using Bayes rule Repeat this three-step cycle until some stopping criteria is met. Note that ADO is autonomous so closed loop experimentation system that does not require any intervention by the experimenter once it started. Here is the outline for the remainder of this talk broken into two part. Part one Mark will address the why use ADO questions trying to convince you why we the cognitive scientists should care about ADO in particular and OED in general. In part two I will follow up Mark's presentation by going over some of the technical details of ADO addressing the question of how does ADO work. So why use ADO. Researchers want informative experiments and experiments are informative when they allow us to draw inferences with confidence about cause and effect or associations between variables. ADO is a computational method for improving inference in experiments so here's how ADO fits in the context of traditional experimentation so these are roughly the stages but experimentation from theory and model development to testing to data collection and inference most of our statistical methods are applied after data have been collected and in this situation inference is only as good as the quality of the data themselves. To improve inference further we should apply methods before data are collected like a power analysis to determine how many participants should be tested. Similarly ADO is applied before data are collected with the goal of improving inference in designing experiments. The difficulty is that experiments are difficult to design because the consequences of key design decisions are not known in advance of data collection that is which manipulations will be most effective and how do we implement those in manipulations. ADO is a tool that researchers can use to improve design choices. Here is an example that will be carried through the remainder of the talk. Memory research going back more than a century shows that recall of listed words drops the longer the interval between studying that list of words and testing on that list of words but if you were the first person to study recall like Ebbinghouse back in the 1880s what design decisions do you have to make some of these include the the number of study items and the retention interval between studying those items and testing on those items In addition how many trials do you have to collect or perform at each point in order to reliably know how performance is at that particular combination of items tested and retention interval. ADO can automate some of these decisions for you. The workflow under ADO is different from traditional experimentation because of how the ADO algorithm works for those familiar with the staircase method ADO is a smarter version of it. First ADO requires a parametric model of the psychological process your study and Jay will say more about this in a moment Participant responses are used to update design choices of which stimulus or design option to choose next for the next trial and the model that is a parametric model combined with participant response are used together to guide design design selection trial after trial. This is a Jay Myung back again. From this point on I'll be doing the rest of the talk discussing the question of how does ADOl work. Two sources of information guide design selection in ADO. One is participants response from experimental trials and the other is a formal mathematical model for the mental process of under investigation. For a parametric model this would be the prediction for an observed response given the model parameters and design values. In the case of retention memory example suppose we are interested in optimizing expensive designs for the purpose of discriminating between the power and expression models shown here. Each model has two parameters a and b and one design variable t which is the retention interval between study and test sessions. Technically speaking a ADO is formulated within a Bayesian and information theoretic framework that use Bayes rules and Shannon's information theory which are the two pillars of the ADO. In the case of using ADO for model dissemination ADO begins by specifying the current state of knowledge about the candidate models and their parameters expressed in the prior model probabilities and the corresponding parameter priors. Next we need the probability dissipation function for each of the models being discriminated and then we define what is known as the local utility function small U which measures the utility of a hypothetical experiment carried out with a design D when an observation y is made from model M with its parameters theta sub M. From these three components priors probability distribution function and local utility we then calculate the global utility function big U of D which is the expectation of the local utility averaged over the models and parameters and observations. The optimal design D star is then defined as the one that maximizes the global utility U of D down here. The remaining two steps which are actual experiment and Bayesian updating are discussed earlier. I should say a little more about the global utility function and how is it defined in an information theoretic sense specifically U of D is nothing but the mutual information between the model variable big M and the data variable big Y conditional on design D as expressed in a complex multiple integral equation up here. In essence U of D measures the amount of information about the unknown which would be provided by an experiment conducted with design D. Consequently the optimal design that maximizes U of D is then the the one that is maximally informative about the cognitive process of interest. In the next few slides I would like to discuss an illustrative example of ADOl in the problem of discriminating two models of potential memory namely the power and exponential models as is shown on the right. The two mothers can mimic each other very well thus making it difficult to design an experiment that can decisively distinguish one from the other Note that the retention interval t is the design variables to be optimized. So the question is what time interval should be employed. Here are two sets of sample retention curves generated from power and exponential for a narrow range of parameters. As you can see both predict monotonically decreasing patterns but in different ways. Obviously you would not choose the retention interval in the range of 15 to 20 seconds They are bad designs why because these design are not discriminated at all. Both modesl make essentially same predictions so any response outcome would have no or little information value. Instead good designs are in the two to four second range here in which the models make contrasting predictions such that given an observed outcome one can easily tell the underlying mother is a power or exponential. Of course the actual reality is much more complex and challenging as is shown here for the full range of parameter values. This is exactly why you would need a more principled approach such as ADO to finding optimal designs This brings us to the conclusion. To summarize ADO is an OED tool for conducting maximally informative and highly efficient experiment which in turn should accelerate scientific discovery in psychology and beyond. In addition to the retention memory example we have also applied ADO and it's variations to other domains such as fMRI experiments and even material science experiments. Methodologically we have recently extended the ADO framework to hierarchical and nonparametric Bayes frameworks. Last but not least we would like to acknowledge the contributions of our collaborators and also grant support from the NIH and AFOSR. Thank you for your attention 