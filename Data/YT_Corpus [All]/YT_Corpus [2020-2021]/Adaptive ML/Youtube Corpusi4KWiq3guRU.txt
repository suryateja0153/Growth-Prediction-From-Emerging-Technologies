 Dear Fellow Scholars, this is Two Minute Papers with Dr. Károly Zsolnai-Fehér. With the nimble progress we are seeing in computer graphics research, it is now not only possible to perform beautiful fluid simulations, but we can also simulate more advanced effects, such as honey coiling, ferrofluids climbing up on other objects, and a variety of similar advanced effects. However, due to the complexity of these techniques, we often have to wait for several seconds, or even minutes for every single one of these images, which often means that we have to leave our computer crunching these scenes overnight. Or even wait several days for the results to appear. But what about real-time applications? Can we perform these fluid simulations in a more reasonable timeframe? Well, this technique offers detailed fluid simulations, like the one here, and is blazing fast. The reason for this is that one, it uses a sparse volume representation and two, it supports parallel computation and runs on your graphics card. So what do these terms really mean? Let’s start with the sparse part. With classical fluid simulation techniques, the simulation domain has to be declared in advance and is typically confined to a cube. This comes with several disadvantages. For instance, if we wish to have a piece of fluid or smoke coming out of this cube, we are out of luck. The simulation domain stays, so we would have to know in advance how the simulation pans out, which we don’t. Now, the first thing you are probably thinking about, well, of course, make the simulation domain bigger! Yes, but unless special measures are taken, the bigger the domain, the more we have to compute. Even the empty parts take some computation! Ouch. This means that we have to confine the simulation to as small a domain as we can. So, this is where this technique comes into play - the sparse representation that it uses means that the simulation domain can take any form, as you see here, it just starts altering the shape of the simulation domain as the fluid splashes out of it. Furthermore, we are not only not doing work in the empty parts of the domain, which is a huge efficiency increase, but we don’t need to allocate too much additional memory for these regions, which, you will see in a minute, will be a key part of the value proposition of this technique. We noted that it supports parallel computation and runs on your graphics card. The graphics card part is key, because otherwise, it would run on your processor, like most of the techniques that require “minutes per frame”. The more complex the technique is, typically, the more likely that it runs on your processor, which has a few cores to a few tens of cores. However, your graphics card, comparably, is almost a supercomputer as it has up to a few hundred, or, even a few thousand cores to compute on. So why not use that? Well, it’s not that simple, and here is where the word “parallel” is key. If the problem can be decomposed into smaller, independent problems, they can be allocated to many-many cores that can work independently, and much more efficiently. This, is exactly what this paper does with the fluid simulation. It runs it on your graphics card, and hence, it is typically 10 to 20 times faster than the equivalent techniques running on your processor. Let me try to demonstrate this with an example. Let’s talk about coffee. Making coffee is not a very parallel task. If you ask a person to make coffee, it can typically be done in a few seconds. However, if you suddenly put 30 people in the kitchen and ask them to make coffee, it not only will not be a faster process, but may even be slower than one person because of two reasons: one, it is hard to coordinate 30 people and there will be miscommunication, and two, there are very few tools, and lots of people, so they won’t be able to help each other, or much worse, will just hold each other up. If we could formulate the coffee making problem such that we need 30 units of coffee and we have 30 kitchens, we could just place one person into each kitchen and then, they could work efficiently and independently. At the risk of oversimplifying the situation, this is an intuition of what this technique does, and hence, it runs on your graphics card, and is incredibly fast. Also, note that your graphics card typically has a limited amount of memory, and, remember, we noted that the sparse representation makes it very gentle on memory usage, making this the perfect algorithm for creating detailed, large-scale fluid simulations quickly. Excellent design. I plan to post slowed down versions of some of the footage that you see here to our Instagram page, if you feel that it is something that you would enjoy, make sure to follow us there. Just search for Two Minute Papers on Instagram to find it, or also, as always, the link is in the video description. And, finally! Hold on to your papers, because if you look here, you see that the dam break scene can be simulated with about 5 frames per second, not seconds per frame, while the water drop scene can run at about 7 frames per second with a few million particles. We can, of course, scale up the simulation, and then, we are back at seconds per frame land, but it is still blazing fast. If you look here, we can go up to 27 times faster, so in one all-nighter simulation, I can simulate what I could simulate in nearly a month. Sign me up! What a time to be alive! Now, note that in the early days of Two Minute Papers, about 3-400 episodes ago, I covered plenty of papers of fluid simulations, however, nearly no one really showed up to watch them. Before publishing any of these videos, I was like “here we go again”, I knew that almost nobody would watch it, but this is a series where I set out to share the love for these papers. I believe we can learn a lot from these works, and if no one watches them, then so be it, I still love doing this. But, I was surprised to find out that over the years, something has changed. You Fellow Scholars somehow started to love the fluids, and I am delighted to see that. So, thank you so much for trusting the process, showing up and watching these videos. I hope you are enjoying watching these as much as I enjoyed making them. This episode has been supported by Weights & Biases. Here, they show you how to make it to the top of Kaggle leaderboards by using Weights & Biases to find the best model faster than everyone else. Weights & Biases provides tools to track your experiments in your deep learning projects. Their system is designed to save you a ton of time and money, and it is actively used in projects at prestigious labs, such as OpenAI, Toyota Research, GitHub, and more. And, the best part is that if you are an academic or have an open source project, you can use their tools for free. It really is as good as it gets. Make sure to visit them through wandb.com/papers or just click the link in the video description and you can get a free demo today. Our thanks to Weights & Biases for their long-standing support and for helping us make better videos for you. Thanks for watching and for your generous support, and I'll see you next time! 