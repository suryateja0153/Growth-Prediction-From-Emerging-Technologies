 and uh good evening everyone today we  welcome professor Ryo yoshida to give us   the final talk of our geometric  data analysis seminar series   and today his topic is machine learning for  material discovery and if you have any questions   please feel free to comment in the chat and later  after the talk yoshida professor yoshida will   answer your questions and also if after professor  yoshida's talk just stay a while and i think uh   kate from jgi bristol uh will say a few words uh  as a concluding remarks thank you very much for   joining in and without further ado let's welcome  professor yoshida give us uh his talk please thank you for our introduction and also i'd  like to express my great thanks to provide   this wonderful occasion to especially  to interact with the people from the uk   so today i'm going to talk about data  science for the materials discovery   which is related to the research field called  materials informatics the materials informatics   is the interdisciplinary research field of  the data science and material science okay okay okay so in general the parameter space of  the material science is very huge uh for example   let's think about chemical space of the small  organic molecule its chemical space of the   small organic molecule is known to consist  of the more than 10 to 60 potential candidate   the currently conventional database of the chemical compound uh recorded nearly  10 to 8 so that means there is still   quite huge species no one has gone before  and we want to discover the new material   from the such huge universe of the material  especially they exhibit innovative property   and structure and required in their application  in science and industry the question here   is how do we address this big challenge  by using data science as a key driver so okay okay to achieve this goal and we here  by a basic workflow of data analysis   that are commonly applied uh every day uh okay  the input variable here represent the design   parameter such as a structure of input material  and output is uh for example correspond to our   property of our interest here after uh input  is denoted by s the output is denoted by y   okay so collecting the data on the s1 s  and y and we derived the model prediction   model which defined mathematical mapping from  the s to y given such a model we then proceed   with a backward prediction again so that explore  the inverse mapping uh from the white to s again   the question here is the how do we handle the  uh we we handle the complex and diverse object   which is targeted by the material science into  this workflow of data analysis okay for example   how do we handle the input variable as as an  input variable and the molecule and crystal and   complex microstructure of the composite material  and so on the furthermore to solve the inverse   problem and we need a generator to produce such  complex object and how do we generate a molecule   and crystal and microstructure and so on so  this is one of the main topics in this talk okay   so now we consider this is addressed by performing  the bayesian modeling and inference okay the   forward model to make a prediction from the s to y  is a given to the likelihood here and further our   player is replaced here to narrow down the huge  solution space into a promising sub region with   this formula of the bayesian cell ram the forward  prediction from the s2y is embedded to the y2s   then generating the material from this  distribution and this posterior distribution   especially uh using the multicultural technique  in a way and after specifying the target region   of the property of the material is given here  in the conditional and we aims to identify the   new material okay so this is a workflow of the  bayesian analysis in the material data so this is   what we called bayesian inverse material  design now this is implemented into our   python library called genome prime so with this  platform and we can perform the bayesian analysis   for the various kind of the material so which will  be demonstrated here after again and to see this   okay i first showed a simple example taken from  our study okay the target is a discovery of the   new polymer that exhibit high thermal conductivity  okay and using the data from the uh for the info   which is the world's largest database of polymer  property and if the so uh okay so and we uh   so we first derived the model to  make a prediction from the s to y   that predict a set of target property which  is denoted by y from the chemical structure   of the repeating unit of the polymer okay so  target property include thermal conductivity   this is a primary target to our study and also  the target include glass transition temperature   and melting temperature and heat capacity and  so on and by solving the this inverse problem   and we predict chemical structure exhibiting the  high thermal conductivity then after that the   predicted polymer or synthesized and experimental  validation is conducted okay now let's see this okay and in the forward prediction the first  things we need to do is a combustion of the   input chemical structure into a feature  vector which is called descriptor yeah   so one typical example is the use of the  molecular fingerprint okay so in this example   the input molecule the chemical structure is  translated into a vector of binary digit okay   so each element takes value one or zero according  to the presence of the chemical fragment feature   usually of the thousand or more  chemical fragments prepared and constructed the other than this we can  use for example the positive definite   kernel for the molecular graph or more  recently graph-based neural network   has greatly contributed to the to address  this task okay anyway so once this is done   the task can be addressed by performing the  conventional regression the collecting the   data on the s and y we perform the regression or  classification to obtain the prediction model okay   and such a model is given to the likelihood here  okay and prior is set okay we can define the   posterior so conducting the multical calculation  so we want to identify the set of virtual material   with their property uh fall into the desired  target region specified here okay the idea is   very simple okay but the problem to be considered  here is a choice of the prior distribution okay   so our solution space is very very huge so we  need to effectively remove the non-target solution   in a way for example the generated molecular  graph must satisfy the rule of chemistry   and we have to exclude the occulance of chemically  and realistic bond or generated molecules should   satisfy or have a high chemical stability or  high synthetic accessibility in some cases   we focus on the specific types of the molecule  required for the application in the science and   industry for example we aims to generate drug  like molecule and liquid crystal polymer and so on   so let's okay so to see this again for example we  may focus on the design of the specific polymer   which is called epoxy resin on the other  hand in application to the development of   organic solar cell the donor molecule of organic  solar cell should have a highly planar structure   so as to stack in the layered material as  shown here like this okay so making the such   uh prior distribution probability distribution  or generator by hand might be a time consuming   so therefore we will take a machine learning  approach to the automated design of the prior   distribution or generator for the molecule okay  so generator model is a trend to mimic by using   the any given training instance of the such  existing material so this is one of the key   uh component in the materials matrix application  okay so to this end we here use a language model   as an example okay so it's well known that any  molecule can be represented by a string okay   called smiles representation like this so this is  the example of the smiles representation of the   a molecule called binding like this which can be  represented into the small string like this again   so here a ring structure is surrounded by the same  digit okay one and one inside of string represent   a link structure here and the bracket indicates  a side chain with respect to the main chain of   this compound okay so then collecting  the set of the smile string from the   public database or existing molecule  and language model is a trend such as   classical engram or the current neural network  to run the ordering and pattern the frequency   of the token in existing material molecule then  such a trend model is given to the player here   and substructure is fixed and the priors suggest  okay how do we generate remaining component   structure so as to ensure the chemical reality  or to have a specific feature of the our target   chemical cow and then likely would evaluate  closeness to the target region okay so we generate   a molecule from this posterior distribution  which is given to her again the condition   and repeating this condition sampling many times  we aim to uh generate uh to obtain the state of   virtual compounds satisfying the target property  okay so okay so this is the example of the   application okay so two target property here grass  transition temperature and melting temperature   are shown on the horizontal and vertical axis  okay the orange denotes our training data in   feature taken from the public database okay the  target region is denoted by the rectangle okay   higher temperature and higher melting temperature  higher grass transform temperature and melting   temperature our target okay and starting from the  20 uh initial molecule which are taken from the   public database and we repeat the sampling on the  molecule from the conditional distribution okay   and the resulting property uh gradually get closer  to the target region corresponding to the high   grass transition temperature and melting  temperature in this way okay where the no data   are given and created molecules are ensured  to hold a chemical reality or a particular   structure feature encoded into our player which  is referred to as a crisp liquid crystal likely   okay so to do this kind of the backward  calibration for the various application   okay generative model will be the key okay  and generative model that can move freely   around a large chemical space is required to  obtain okay and more recently various kind   of the deep generative model has have been  developed in the machine learning community   for example lstm or variation of the encoder and  generative adversary network were commonly applied   for the generation of the chemical structure and  crystal structure and the higher order structure   of the polymer and the other molecular system and  so on so it's really interesting to me that such   research is originating from the machine learning  community okay so in this study we finally created   10 000 candidate of polymer as exhibiting the high  summary conductivity and finally three new polymer   shown here are synthesized and their experimental  uh property for the thermal conductivity   uh validated by our experimentation and also it  was confirmed the synthesized polymers exceeded   exhibit solubility to organic solvent and also  show the grassy state and liquid crystallinity   okay and some of the uh seaside molecules showed  about 40 percent higher thermal conductivity than   conventional polymer okay so this would be a  one of the first successful application of the   machine learning based inverse design of polymer  and we reach the milestone on the other hand some   big issues still remain unresolved okay so this is  the next topic so one big issue considered here is   okay so we need to overcome the huddle of chemical  synthesis okay here i will briefly describe the   machine learning technique on this task which  is called little synthesis okay the concept   of the and the uh methodological foundation  of the little synthesis analysis was first   developed by the professor corey in harvard  university and he received a nobel prize in the   chemistry in 1990 on this historical achievement  and his first paper was published in 1969   and he proposed a rule-based article intelligent  system for the designing the synthetic group   to a given any given target molecule and after 50  years okay the latest technology of the machine   learning and now overturning the process of  the lateral synthesis so i will show briefly   okay so first the problem is  formulated okay so design target   is given by our computational arrows and we  want to identify the root of chemical synthesis   reaching to this target by performing  the multi-step synthetic reaction okay   this is a problem okay so given the list  of the commercial pump compound combustory   available compound and we need to select initial  compound and reactant and reagent or catalysis   to promote this chemical reaction okay this is  a problem and this is like a combinatory problem   just the usually the number of compounds  commercially available compound is of order 10 to   6 okay then the solution space is defined by  the uh they are all possible combination of the   commercially available compound so quite  huge space should be taking into account okay so the to solve this problem and we  first performed the forward prediction   and backward prediction after that in  the forward program okay the objective   is to obtain the machine learning model that  predict the product of the single step reaction   and the set of reactant and reagent given as  an input okay here we represent our input and   output variable based on the smiles  representation okay the reactant   and the reagent and product are all represented  by the small string and in the middle of the   reactant and reactant to they are separated by  the period and the agent was specified after the   symbol of inequality okay and also product  is also represented by the smile string okay   then the problem is to find the root of combustion  from the strings to strings okay so for the neural   network for the machine translation our  tasks could be used to address this problem   such as a attention-based neural network  including the 626 and transformer okay so   by the recent study such model trend  on the medium of the action data   taken from the public database can reach the  tremendous performance on the forward prediction   for example the transformer architecture  exhibit about 90 percent accuracy in top   1 accuracy in the top 5 accuracy 95 of chemical  structure in the test product can be perfectly   predictive then given such a model again we can  simulate forward read the synthetic reaction okay   here for example the consider two-step reaction as  a template and two reactant s1 and s2 are selected   by using the our model we can calculate the  intermediate product x and by selecting the   further the reactions reactant three again  that we can calculate a final product okay here the target product is fixed to be a target  then we explore the all possible combination of   the three unknown reactants s1 s2 and s3  so as to reach the target specified here   by solving the backward prediction mode task  okay so this is a problem and we conduct the uh   this backward prediction task based on  the bayesian influence using the posterior   posterior distribution is defined as follow which  is proportional to the joint distribution of the   s and y and we model this as a division  distribution like this the temperature is   here and energy function measures the similarity  between the target desired target synthetic target   and also the prediction made by the hour  forward model okay so this is the problem   okay and also uh it should be noted that posterior  distribution is a discrete measure which is   defined over the all possible combination of  the purchasable compound that we used okay   so the number of potential candidate  is of order 10 to 80 if we use   commercially the number of commercially available  compound is 10 to 6 the solution space is   defined by the all possible combination of  three reactants again so this is a very big   uh pro series problem okay the exact computation  of the posterior distribution is infeasible okay   so this is a cons defined over the all solution  space denoted by t and so we need an approximation   to compute posterior distribution and using  the much smaller number of the reactant   pair in an effective way okay and to do this  uh so conventional heuristic approaches are not   applicable and we are thinking so there are many  potential candidates okay not yet discovered to   reach the same target and so we want to identify  the such diverse solution comprehensively this is   our challenge and to achieve this goal  and we adapted a course grain uh course   to find strategy into the sequential  multi-color method so here i show only   the basic idea so details are shown in our  paper again so we first sample the uh okay   so they have a quite large number of the solution  yet to be discovered okay and we first sample   some particle and feature clustered into uh here  in the three crease three three cluster okay and so uh yeah yeah so it's requested and they saw uh we first uh  okay so they are clustered into three cluster   features is a color coded okay in this way and  then their cluster level likelihood evaluated   by using the surrogate model that are trained on  the uh before starting the calculation of the smg   and then i'll remove the unpromising uh cluster  and we calculate the likelihood of the surviving   particle okay then survived a particle removed  from the candidate because the our problem is   discrete uh the random sampling from the discrete  okay okay and then proceed with the next step   and looping this process many times we identified  a set of diverse sensitive groups so sorry details   emitted here yeah so here i just showed the one  example and the result taken from our paper okay   so our algorithm suggests uh in this application  a more than six thousand candidate route   to reach the same synthetic target shown here  okay okay so so the the our algorithm suggests   there exists uh such a diverse uh synthetic  route by using the which can be possible   feasible to synthesize using the currently given  the commercial compound and also they formed 98   different clusters according to the chemical  structure involved in the reaction pathway   and also according to the evaluation made by  our expert chemist decided for 35 to 6 percent   of the proposed synthetic reaction would  be chemically valid and synthesizable and   such candidates are provided to a chemist and they  will make a final decision making for this purpose   and diversity of the candidate will be very  important to enhance the creativity of the   researcher in the organic synthesis okay we are  thinking so this kind of the machine learning   technology will be a groundbreaking technology  in the next era of the organic chemistry and in organic chemistry the recent advance of the  machine learning technology enabled us to automate   the computational design of the chemical compound  and also the their sensitive group as well   the next challenge is to integrate such machine  learning system into a robot to fully automate   experimentation okay so this is the challenge  that has already started and the one uh so which   uh what some of our outstanding study lies from  the for example the university of glasgow in uk   or harvard university and mit okay so we this will  provide a really exciting opportunity to us yeah   okay so now we will move on the next topic  on the machine learning further designing the   manufacturing process for more complex uh more  complex composite material okay so this diagram   shows a flowchart corresponding to the process to  microstructure and microstructure to property okay   so the choice of process parameter and composition  okay control the microstructure of the material   okay each then this microstructure also controls  the property or functionality of the resulting   material and the question is how do we incorporate  to data science technique in this workflow okay   here as an example we treat the microstructure as  an image of electron microscopy for example the   same scanning micro electron microscopy which is  called same okay so material researcher routinely   acquired such microscopic image every day okay  then the prediction task from the structure   to property can be formulated as a  conventional problem of image recognition   and other hand the task of the prediction from  the process to microstructure can be treated as an   image generation task okay okay so now let's see  a specific example taken from this study okay so   the input variable considered here is a six  dimensional really valued vector that consists   of the two composition parameter of the inorganic  material and the four process parameters such as   deposition temperature or deposition  temperature pressure and so on again   for the this is a very important parameter  for the spattering of the thin film material   the output is a microscopic image of the  microstructure material and collecting   the data on the input and output so we here  trend of deep generative model the data set   that we use is originated from the 123 electron  microscopic image and two augments data set so we   generated randomly the 128 parts by using the  random sampling so this is our data set and okay so to be specific and here we use a conventional  condition again maybe so perhaps uh so it's   no longer need to explain about the gyan  for the participant today's uh seminar and   okay so here only the difference of the  conditional gun to a conventional gun is   to include the six-dimensional conditional  parameter into the input of the g   generator and discriminator okay so g is a trend  to fool the d and d is a trend not to be full ig   okay so looping this alternative learning  scheme many times the resulting g can be used   to predict the prediction model of the  microstructure image for the any given   conditional parameter corresponding to the  process and composition so this is used for the   regression model so this slide highlights  the prediction ability of the our model   on the six different condition from the a  to g which corresponding to the different   conditional parameter okay so predicted image  is shown on the top panels and the predicted   image exhibit a good agreement to the real  image taken from the microscopic experiment and   corresponding to the different grain size and  topological feature so even if we removed all   similar image from the training set our model  exhibit a good agreement to the real data   so such a model is a given so we may perform  backward prediction to search for the set of   conditional parameters that achieve the specific  pattern of the grain size and topological feature   so in order to improve the mechanical property  of the material and we want to make our crystals   grain size smaller and more uniform so our model  can provide the answer to such a question okay   so this kind of the machine learning can be  considered as a regression technique for the   multi-dimensional output in the material science  so there are many such a potential application yet   to be explored so in which the uh high dimensional  out should be handled for the regression   in the study of the microstructure in our case the  y is given as a matrix to represent the gray scale   image of the microscopic image or on the other  hand in the study of the optical material we   want to predict the light absorption spectrum of  the like this which is defined over the frequency   on any given input molecule okay in this case  the output variable is represented as a function   okay and also there are things let's think about  the alpha fault okay which is uh developed by   deep mind in order to make a prediction of the  protein folding structure which is a very popular   model and then the neural network was used the  input is a amino acid sequence which is a string   of one-dimensional string types of input and  the output is a matrix called the contact matrix   which represents the distance of the atom to  atom in the 3d structure of the floating holding   okay and so on so in such a case the space of  the output variable is very high dimensional   and making the direct application of the  conventional regression approach unstable   and infeasible and due to the lack of infuse  identifiability in the learning objective and to   enhance the stability of the learning  scheme and the adversary adversarial example   generated and added to our training data set the  feature player role of the regularization okay so now and we will move to our next uh topics okay  so the ultimate goal of the material science is   to realize the extrapolative prediction and  extrapolative discovery this is a very important   goal to our science however the prediction  made by any statistical model is interpolative   in nature so our interest our interest uh is  lying in the uh here is laid on the question   okay how do we overcome the limitation of the  interpolated prediction made by data science okay   so to see this and let's consider example  taken from the study of the organic solar cell   okay so this figure shows a distribution of donor  molecule of the organic solar cell device okay   so vertical and horizontal axis denote hormonal  gap and power combustion efficiency okay in 2012   okay the best performing donor molecule achieves  the 11 percent in a power conversion fcc but here   getting back to 2009 okay the distribution of  the donor molecule was as shown in here yeah so   we are now interested in how do we identify the  best material in 2012 only by using only the data   available until the 2009 indicated by peru  in general it's a difficult quite difficult   this is a very difficult problem because any  statistical model like the ability of the   prediction in the religion so no no data available  okay so okay i'd like to skip and so two uh this   write demonstrator limitation of the interpolative  prediction made by data science method   so two property target property the hormonal  gap and power conversion absence here now   convert it to the homo and lumo okay using  this homo and lumo as shown on the horizontal   and the vertical axis okay by so this has  been made by using the theoretical model   from the physics and this combustion and we  can validate the predict value of the machine   learning model by using the first principle  calculation that is a validation experiment   made by the computer experiment and blue dot  through the denotes the data in 2009 and let's   denote the battery molecule created by our  bayesian method and the target region is   represented by the rectangle which corresponds  to the best performing material in 2012   and note that here all the properties shown here  validated by using the first principle calculation   okay so as you can see from this figure the  created molecule shown by let get stuck around   legion reaching to the ultra extrapolated  the target region okay so our model has   relaxability of the prediction in that division  so we failed to reach the target region so this   is a limitation of the conventional data science  approach okay so to overcome this limitation   and we need to integrate a data production  system or fully automated experimentation   system into the machine learning system framework  based on the especially the statistical method   for the adaptive design of experiments so this  diagram showed our system called spatial okay   so bayesian method our bayesian method is used  to produce the large amount of the and virtual   molecule the each subset is selected according  to the module of the experimental design in a way   in this system we applied beijing optimization  method okay and the selected molecule is given   to the module of the experimentation and in this  case so using the first principle calculation   we measure the target property of design point  to be selected and the feature given to the other additional training instance and so features  are used to enhance the extrapolative ability of   the our model and this process is repeated many  many times such as more than one month and two   months and our algorithm special we gradually  acquire the extrapolative prediction ability   so technical details omitted here because the  time is limited and so if you have a question so   i will give a uh answer to the technical aspect of  our scheme so i just showed the result here okay   so how uh the let's see their uh results okay so  okay so we started from the uh existing material   data and starting from here and they created  the molecule get closer to the target region by   the conduction of the spatial algorithm  and finally around step six and the spatial   maybe successfully uh reach the  target region in this way and   keep the in keep this kind of competition  in the very long time and we can identify   the large number of promising molecules so this  is a really exciting opportunity to ask okay   so here uh the uh yeah uh yeah so the one  of the uh so this is a important question   uh so here uh we encounter the big question  okay so this slide shows a tsne prediction   of the uh the molecule created by  the our algorithms and also they're   recorded in our database so which are made  under uh knowledge on the human intelligence   okay this is the t sne projection of the  old molecule the orange denote our molecule   and blue denote molecule recorded in the database  so what i want to show here is there is a large   gap between the uh material discovered by the  human knowledge and uh created from the bachelor   laboratory based on the machine intelligence so  mike the so that means the spatial could identify   the large number of normal molecules yet to be  discovered on the other hand our method overlooked   a large number of already discovered molecules so  we are always thinking every day thinking about   why such a large gap occur between the human  and machine intelligence at fortunately   at this moment we have no clear answer to this  so we are still thinking about this mystery okay okay sorry doesn't work okay the finally uh i'm so in terms of the uh  extrapolated prediction so i'd like to briefly   give a remarks on the great potential of the  transfer learning okay so most of data in our area   are very small and much smaller than the data  in the other application field of data science   and here we are thinking the transfer learning  or domain adaptation become the key driver   to overcome this big huddle okay so this  is the example taken from the our study   okay so the target is a discovery of the inorganic  crystal with a high thermal conductivity however   when we started this project we only have a 45  data on the thermal conductivity so we decided to   use an alternative target property which is called  scattering phase space here after we call it sps   we collected the data on the sps  312 sample for the sps the feature   used for the source data set for in the transfer  learning and as shown in this figure okay   these two properties weak correlation the  sps and thermal conductivity are shown on   the horizontal and vertical axis okay three  very weak negative correlation are present and to overcome the huddle of the limited amount  of data and if here we apply the commonly applied   transfer learning using the neural network  and using the 320 data on the spss we trained   a three-layered and fully connected neural  network which transferred to the target task   in making the prediction of the thermal  conductivity and to be specific the sub-network   of the pre-trained model as a top layer is copied  okay to the target task and the parameter in the   linear model in the top layer was estimated by  using the 45 sample of the thermal conductivity   this is what we did and we do nothing special  other than this okay we i only use a conventional   workflow of the transfer running and this shoulder  predicted value of the play trend model on the   sps and the prediction and observation are  shown on the horizontal and vertical axis   with and this was transferred to the  model on the thermal conductivity   so this shows the result of the 10-fold  cross-validation that are looped with in the 45   data point and as you can see from this figure  they exhibit a good agreement in this way   and finally so using this model we  perform the screening over the 70   000 material taken from the public database  which include a real and virtual compound and this so we finally discovered 40 crystals  okay some of them exhibit a very high thermal   conductivity as reaching more than 3000 watts  per meter kelvin so this is one of the successful   application and here i will i'd like to describe  the great potential of the transfer learning okay   in the terms of the extrapolative aqua ability  so this histogram shows the distribution of the   40 crystal that we discovered okay as  indicated by uh green and some some of them   reach the more than three thousand uh but per  metre kelvin in the thermal conductivity on the   other hand our training data which is denoted by  arrow are distributed in a much lower region okay   so our model is a trend under this data  set and to make a prediction this material   yeah so these slides show the uh  prediction uh result of the 14   crystal that we identified with respect to  the result of experimental validation okay   as you can see and the except for  the few material and our predicted   value of our transfer model exhibit good  agreement to the experimental observation   even in such extrapolative region of target and  blue dot denote the result of the prediction   made by the model directly trained on the 45 data  point as indicated by yellow okay as you can see   the predicted value of the such directly trained  model saturates around the upper region of the   training data this is a typical result of the  direct machine learning the transfer learning   can be a great have made a great contribution  to overcome the limitation of the interpolative   prediction made by the conventional scheme of  the machine learning and inspired by this great   success of the transfer learning and we decided to  use the transfer learning uh in the systematic way   in this research field and collecting the massive  amount of data from the public domain as a so   we conducted constru uh we constructed a  massive amount of the pre-trained model   for the various property and various material  including the small organic molecule and polymer   and the inorganic crystal and their composite and  so on and so this model library is implemented   into our software and provided as a database okay  maybe so the time is approaching so i should skip   the sum of the results okay so i will i have i  should conclude this talk now okay okay so finally   i'd like to make a position a little bit so i'd  like to introduce the research center in the isn   in 2017 the institute our institute  around the research center called   data science center for creative design and  manufacturing so the name of center is a   little bit long i want to make it shorter that the  mission of this center is to show the real impact   of data science in the field of manufacturing the  one of the target is laid on the material science   and we are conducting the  many study really many studies   that cover the broad range of the advanced  material such as polymer and polymer composite   or sea filmed layered material and optical device  and so on okay so many professional scientist   and engineer in bioresearch field are coming  together here and from the science and industry   so after beating the corbett 19 and you may have  a chance to visit ism i hope you will have an   opportunity to interact with our team in ism and  most important things to be addressed now is a to   overcome the coroner thanks a lot for your kind  attention my talk is now finished okay thank you thank you very much and for very inspiring  and very interesting talk um okay so   when one asked that thanks professor can  the presentation slide slightly shared   um i'm wondering if uh you can share the  slides with us later yeah yeah sure okay   great um so there is another question that  was sent by email so michael wisnom asked the   following question that is some simulation results  were shown with high tg and melting temperature   have these been successfully synthetic that  synthetized synthesized okay so in this study uh   yeah we consider synthetic glue to the design  target by hand based on the expert knowledge   okay so i don't know the experimental detail  about how do we synthesize the yeah but so   our paper provided the experimental detail of the  synthesization to the of the three new polymer so   is it okay to ken right i think uh michael is  not here if michael is here could you comment   a bit more on this or not okay i think michael  is not here you know i'm here yes yeah peace   now i just saw the the simulation results  and it was showing some extraordinarily high   predicted tg and melting temperature i was very  interested to know whether these uh have been any   of these have been successfully synthesized  because it looked very uh very interesting okay so i think um yeah so professor yoshida  do you want to comment a bit more or that's   the answer to the question yeah maybe so i'm  missing the uh point of the question comment   sorry i say again so i can i couldn't hear the  clear okay michael could you say it again please well you showed some experimental validation  of the conductivity yeah i was wondering   whether you had also done that for the  high tg and melting temperature results uh yeah uh yeah primary  target of the our study was   uh thermal conductivity but so at the same  time in order to the ease of the processing   so the uh we specify the specific target  range of the grass transition temperature   maybe so the target range of the grass  transition temperature was around 200 uh yeah   200 uh celsius degree again this is a requirement  from the further industry application okay yeah   and also we have to reconsider several  type different target properties and we uh   yeah so yeah one of the important uh target uh is  we want to uh to to have to discover to generate   a liquid crystal uh polymer okay so in order to  achieve this goal so we use the machine learning   model to make a prediction of the liquid crystal  likeliness a feature evaluated from the uh   chemical structure of the model and  then this is also used for the target   our forward prediction model okay okay so thank you very much for answering uh let's  move on to the next question so vincent asks given   the massive design space can you give some idea on  the time and computational cost of some of these simulations simulation means the first  physical calculation for the yeah yes so the one the the bottleneck of the  our algorithm and for example uh maybe   so the question is related it on this  algorithm i don't know whether or not you are here could you explain a bit more   or you're just asking a more generic question  about the computational cost or time cost   so okay so probably winston is not here but i  think he's asking a very gener generic question   generic question okay right so about this search  space is so big and how do you for example balance   yeah so if if we uh you uh you want to uh explore  the entire chemical space so it's of course it's   infeasible and in practical application and so  in order to reduce the size space in the way we   specify this forecasting reach for example if we  are interested in the organic solar cell material   then we focus of specified focused vision  okay in this way we can reduce we can uh   we narrow down the uh solution possible solution  space into a uh promising target okay so yeah and   also the computational cost of the uh our beijing  adwords is a very trivial not so critical but so   one of the most uh the one other uh the bottleneck  of the competition is uh from the come from the   computer simulation based on the physics okay in  for example in this application in this algorithm   which is called spatial which made the integration  of the machine learning based backward calculation   and also the computer simulation conducted based  on the physical law that is called first principle   calculation so bottleneck of the computational  time comes from the uh the simulation module here   okay so due to the this uh bottleneck so yeah for  example i showed this result so we performed this only the 10 step again so to my uh to my  understanding so computation time for the 10-step   calculation of the hour algorithm takes uh two weeks two weeks yeah so that is a yeah  difficulty of the computation in the current   system okay so i think winston just commented  a bit uh so i was referring to the training   and then the finding of new solutions for  instance when you are trying to get to a specific   region let's say in the tg and melting temperature  you showed how the various generations evolved i   was interested in how long do these generations  take to generate and compute uh yeah so yeah   yeah that in that generation the computation time   is very trivial and for example uh yeah  we conducted uh uh several hundred steps   for the successive modification of the chemical  structure so computation time was about one hour or two hour yeah by using  the conventional uh workstation okay okay um so i have a quick question uh regarding  to generative adversarial network you were talking   about so in gun there is a common issue that  is the performance of gang is really difficult   to evaluate you've mentioned that you use  the gun to generate some microscopic pictures   yes this slide could you briefly comment on how  these performance were evaluated and do you have   a ground truth or measurements error measurement  for somehow to evaluate the performance of of gun yeah so yeah this is just a preliminary result  and we are still the the performance of the   uh generative model from the condition and so  yeah i con what i did in at this moment is just to   evaluate the similarity of the image generated  from the our model and the observation   and they also yeah we have to consider  more uh investigate how more concretely uh   more systematically evaluate the performance  of jan and also in the terms of the application   in material science so we have to investigate  extrapolative ability of the prediction model   this is a prime ultimate goal of our study and  unfortunately the conventional approach of the uh   generative adversary model um network  is uh yeah interp very interpolative   yeah so yeah we are thinking that how to overcome  limitation maybe so the one of this promising   solution is to incorporate the theory from the  physics okay which should be combined into the   machine learning in a way but so i at this  moment i have no angry answer to this game   that's very impressive thank you very much i think  um we have reached the almost the end of today's   talk um thank you again for professor yoshida  and i think kate from jti institute uh have a   few words to say before we finish this session  and kate could you please yes thank you thank you   thank you son great to see you great talk ro thank  you very much um yeah so it falls to me really   just to wrap up this fantastic seminar series  that we've had as many of you know i've just put a   link in the chat there the relationship between  the partnership between gene golding institutes in   bristol and the institute for cystical mathematics  in in tokyo is a really kind of valued partnership   by us all this was initially intended to be  a face-to-face workshop meeting and obviously   life got in the way but i think we should all  agree that there's been an enormous success   getting together in this way over the past  five weeks we've had some great talks we've   had a huge participation probably greater than  we would have done if we'd been face to face um   lily behind the scenes has been counting up  participants and we've got to over a hundred   over the course of the of the talks we've had  really wide ranging talks i've noticed from   the names that i recognize in the participant list  that we've had participation from across faculties   um within the university of bristol i suspect  that's true for on the tokyo side as well so   we've had this this series of talks have had  really great reach and it's wonderful to see   so first of all some thanks thank you to kenji  fukumitsu and for song liu who together we   three kind of organized the partnership thank you  to patrick as well reuben dancing for his support   to patty holly and lily rice from the gene goldie  institute who have worked so hard to support   the events and the all the behind the scenes tech  that we maybe all take for granted and to all   our fantastic speakers over the past five weeks  without who we wouldn't have had a series at all   um in answer to one of the questions yes all the  speakers have agreed to to allow their talks to   be made available they'll be on the jgi website  and we will send an email around to you when they   are available um we will have a feedback form  it'd be great if we could send this to you all   we'll send it out tomorrow to get a feeling for  how successful you thought the format was if the   platform has worked for you if there are any  tech issues if there are other kinds of topic   areas that you'd like us to cover in future future  series like this any of that information would be   really really useful to us so please do fill that  out and a final note um the gene golding institute   every year has a sequel funding call which is to  establish cross-disciplinary connections using   data science and different applications uh for  to get research projects going or to support an   interesting research project we fund between five  or ten a year depending on and how large the bids   are the call for this year um will be launched  on the 12th of october on our website uh we'll   have an information event that you're all welcome  to join on the 21st of october and there'll be   an application deadline on the 23rd of october  of november so if any of the talks that you've   have heard over the last few weeks have piqued  your interest or you'd like to make connections   that might be a mechanism to keep that going  over the next you know a few months um and the   song i guess this is true for you and kenji as  well if and any of our participants have ideas   for how we might want to grow the partnership  between our two institutes we'd love to hear   from you and we will do our best to facilitate  those dialogues and work with you to achieve that   so kenji i think you're there any last words you'd  like to say oh he's he's put something in the chat   you've got a video problem shame like thank you  sir sorry yeah hi i have a video collection a   problem in the video connection today so i  can't show up there well i i just want to   say thank you for the speaker in the audience and  especially bristol people who did a great work on   organizing this online series online meeting  series so i thank them especially yeah thank you   thank you that's great so it  just remains to me to say thank   you to everybody again i hope you've  enjoyed these talks as much as we have   watch this space we'll have some  more activities going on with iso   in the coming year and if you're interested  in starting something new as a collaboration   between our two partnerships look out for our c  core funding call okay thanks everybody very much 