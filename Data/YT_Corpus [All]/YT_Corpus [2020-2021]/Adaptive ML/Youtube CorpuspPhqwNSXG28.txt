 Hi everyone. I am Dongdong She, a PhD student from Columbia University. Today, I'm going to present MTFuzz, a machine learning based fuzzer with multitask neural network. Here is the workflow of a typical coverage guided fuzzer. It starts with a seed corpus, then generates test through random mutation, executes on target program, measures edge coverage. If a new edge is found, the test input will be saved else the test input is discarded. A typical example is AFL. It is effective, scalable and easy to use. But they often get stuck after a while of running and generate a lot of uninteresting inputs which fail to explore new edges. Because the underlying random mutation scheme fails to learn from past experience and the hot byte distribution of input are ignored. To address these problems, a popular approach is to use machine learning based fuzzing. Machine learning based fuzzing would use a NN to approximate certain program property such as branching behavior, then use the NN to guide fuzzer to generate effective mutations or filter unpromising mutations. This graph shows an example of machine learning based fuzzing. Given an input, feed it on a real-world program, we can obtain its corresponding edge coverage. Machine learning based fuzzing use a NN to learn a surrogate of program behaviors by predicting the edges for given inputs. Further, the trained NN can guide the fuzzer to generate effective mutations. Although it's effective in practice. It has three major limitations. First, the input space representing the input byte sequence, is high dimensional and sparse. Second, the training sample of NN model are collected from interesting inputs generated by fuzzers. Since fuzzers normally maintain a limited number of interesting inputs for performance consideration. The NN often lacks of enough training samples. The Edge coverage is coarse grainded. It only records the edges exercises during Dynamic execution while fail to capture other information such as states of calling stack, distance of unreached edges. To solve this problem, we want the NN to have a compact embedding layer so it can handle high dimensional and sparse data. We may also want the NN to include multiple metrics such that we can collect sample training data from different metrics, and they also provide a fine grained coverage than the single one. Then we have multitask NN. This graph shows the architecture of our multitask NN model. It has a compact embedding layer, encoding high-dimensional and sparse input. In output layer, it has three related coverage metrics which complements each other to provide a finer grained coverage information than a single edge coverage. For example, contact coverage encodes the state of calling stack. Approach coverage includes the distance of unreached branches. Let's look at the overview of our approach. There are three stages in MTFuzz. First. We trained a multitask NN to learn a shared compact embedding layer for three coverage tasks. Then we compute gradient of compact embedding layer with respect to input to identify hot bytes and focus mutating on these hot bytes. Is the end, we choose inputs which found new edges and add them into our training coppers to perform incremental learning. Next I will explain the detail of three tasks in our model and how they complement each other and provide a fine grainded edge coverage than a single one. Edge coverage is a common coverage metric used in fuzzer. It records edge transitions between each basic block. The graph shows a control flow graph of program. Say we have the input which executes through basic block 1, BB 3 and BB5 then it's edge coverage 2 and 4 marked in blue. Fuzzer maintains an edge bitmap to keep track of the edge coverage. In a bitmap, if one edge is exercised, it will be marked as one. Else, it will be marked as 0 and we can have bitmap like this. Now let's look at a case when edge coverage fails to capture the distance information of unreached edges. We first define an edge is not taken when it's parent is reached but itself is not exercised. For example edge1 is not taken edge, say the execution reaches its parent basic block 1 and passes along another edge2 We then Define missed edges as whose parent is not reached and itself is not reached either. Edge 3 is an example of missed edges. Intuitively, the not taken edges are more likely to be explored than the misssed edges. Since they're closer to current execution paths. But in edge coverage metric, both type of edges are considered the same. To distinguish them, we proposed a novel coverage to measure the distance of unseen edges to seen edges. For example, the not taken edges are one branch off current execution paths while the missed edges are two branches off. If one edge has a shorter distance from current execution paths, it is more likely to be discovered. So we define not taken edge as .5 and missed edge as 0.25 to capture the distance information as this. Given the new approach coverage. We can preserve distance information and provide a finer grained coverage. Next let's revisit edge coverage. We show a case when it failes to detect the same edge from different calling stack. On the left is a simple code example say we have a input 1 0 we first execute through line 12, then line 2 line 3, then we record the edge to edge coverage L2 L3 in the table. Then we execute at line 14, then we have edge coverage (l5,l6) in the table. finish the execution. Similarly. We execute another input 0 8. start add line 12, we get edge coverage L5 L6 in the table. Then we execute on line 14. We have edge coverage L2 L3 in the table. Then we can find the two inputs actually had the same edge coverage, but they have different program behavior. Now if you take a closer look at line 14 when input is 0 8 like this. Note that the input is 0 8 and second byte is 8 so we go to line 2 and right now a is 8 so we go to line three. Note that the address is a 8-byte long buffer, and we actually try to write 12 bytes to it. So a buffer overflow happens now, we know actually the two inputs 1 0, 0 8 have totally different program behavior, but they have the same edge coverage. Now the problem is how do we distinguish them? The answer is to define a new coverage. We Define a context-sensitive edge coverage matrix by recording the calling context along with edge coverage as shown in the table compared with vanilla edge coverage contacts coverage records additional calling contexts ID as marked in red it can compliment edge coverage to preserve contexts information. After explaining the three individual tasks in our model, I will briefly introduce how we train the multitask neural network A known issue for machine learning based fuzzing is imbalanced data set because the training samples are generated by fuzzer and the fuzzer tends to maintain a minimum set of unique inputs. Here is an example. Say we have two edges H1 and H2 and we have 6 inputs: input 1, input 2, to input 6. If you look at the bit map, you can find for Edge 1, 5 out of the 6 inputs have label one and only one input has label zero. Similar thing happened for edge. Given such imbalance data, the neural network model tends to lazily memorize the majority label rather than bothering to learn the difference of the two labels. So as a result the model will constantly output the majority label. To mitigate this issue. we assign an adaptive way to penalize the majority class when computing the loss. The weight is computed by the ratio of number of negative label against positive label. Now we can train our multitask NN. The multitask NN is trained by jointly optimizing all three tasks. The total loss is computed by linear combination of each individual loos. We assign equal weight to each task. Alpha here is one third. After the first stage of model training, we can use the trained NN to guide mutation. The guided mutation is to focus on mutating hot bytes, which affect program branching behavior. To identify this hot byte. we compute the gradient of embedding layer with respect to input as saliency score for each byte. The bytes with higher saliency score will be mutated more frequently. The last stage of anti-fuzz is seed selection and incremental learning. After identify the hot byte, we choose the input which triggers the rare edges to mutate. The rare edges are those edges with least hit rate, then we add input with new edge coverage, and add them into our training corpus to perform incremental learning. This is our evaluation plan. We measure the edge coverage on 10 real-world programs. We measure bugs detected on real-world program and Lava-M dataset. We also evaluate the contribution of each task in MTFuzz. In the end, we measure the transferability of multi-task NN to a different program. We compare MTFuzz on 10 real-world programs against five state-of-the-art fuzzers for 24 hours. The results show MTFuzz achieves on average two times more edge coverage against five SOTA fuzzers and 10 real-world programs. In terms of bug finding, MTFuzz finds 71 bugs, 11 unseen, in seven real-world programs. And most bugs on LAVA-M dataset. In this experiment of the contribution for each individual task, we evaluate the contribution of each task by performing an ablation study on different task groups. The result shows MTFuzz with all three tasks can achieve on average 20% more average, 20% more edges coverage than a single task model. In the transferability experiment, we evaluate the transferability of NN model learned by MTFuzz. Specifically we use a NN model learnED from source program. and guided it fuzz on another target program. So we compared it against one machine learning based fuzzer NEUZZ and another coverage fuzzer AFL. The result shows MTFuzz can achieve on average two times more edge coverage than other fuzzers. Take away. Multiple coverage complements each other to provide a fine grained coverage. Multi-task NN can sample more training data than single-task NN in fuzzing. Gradient of shared embedding layer is more effective than gradient of final layer. 