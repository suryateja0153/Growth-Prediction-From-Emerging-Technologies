 I hope I can get your attention at 6:30 p.m. this evening for a talk that I hope will inspire entertain and just be chaotic in general we're gonna try and do quite a few things we have a short amount of time but essentially we're going to talk to you about what Google is doing when it comes to arts and culture and for those of you who know what Google arts and culture is great for those of you don't I'm going to keep it really short my name is Amit Sood I work in the London Paris offices of Google and I'm joined on stage here with my colleague damiana Henry da Mia is a head of our experiments team based in Paris and responsible for a lot of the things that I'm gonna show you and so if you don't like something or like something talk to Pamela I'm going to escape really fast after the session but being being very brief Google arts and culture started in 2011 and it's a non profit non-commercial division within the company that essentially focuses on making arts and all types of culture more accessible using technology so we've been working with museums foundations archives and artists for now over 10 years and essentially trying to get more culture out there for everyone to enjoy in different ways and so today I'm not going to talk to you so much about what we do at Google arts and culture in the core I'm going to talk to you what we do with experiments because we want to try and show you a few cool ideas so before I do that I think we're going to try and show you a short video that talks about the main platform which by the way you can all download it's just called Google arts and culture that has now over 6 million artifacts artworks and over tens of thousands of curated exhibitions for museums around the world so it's a short video to tell you what you can do with it [Music] [Applause] [Music] so that's our main job we're not going to talk about it much we encourage you all to enjoy the app and essentially have all the worlds museums and cultural topics easily accessible what we want to talk to you about today are a few of our recent activities in the field of arts and culture and this is gonna go quite fast so you know try and try and stare but if you can't find structure don't worry about it it's just bunch of really important cool stuff they were going to show you so preserving cultural heritage I think this we decided to put this at the start of the session given some of you might know about the recent tragedies that have unfolded when it comes to monuments and amazing amazing you know cultural landmarks I'm not gonna name them but I think we all are aware of what's been going on and so we've been working with a partner called SIA based here in San Francisco Sayaka has been one of the leaders in capturing and preserving cultural landmarks using cutting-edge drone technology and photochemistry and this is by the way called the open heritage project there's a lot of content here more than enough for you to spend a couple of weeks so I don't have time to take you through all of it but the idea is to tell stories about preservation why preservation is important but to also make it easy for developers and anyone interested in the raw data of what it means to capture a cultural landmark to experience it so we're gonna try and show you one story with the Mexico City Cathedral I don't know how many of you know about this amazing building but after the earthquake in Mexico the Mexico government invited Sayaka partner to come and preserve this so that in case anything ever happens there is a high density point cloud photo geometric model that can be used for preservation and restoration so this is a great story you can enjoy it but what's exciting is models like these and we have over 50 of them now have it's gonna load in a second this is all live by the way so we are taking a few risks but hopefully it will be coming on soon that's it so that by the way is the altar in the cathedral that has been captured using drones that have essentially allowed you to get very high-density information on the entire structural nature of this altarpiece and if you want to really understand your perspective and the view that you're getting I'm just gonna ask da Mia to tilt down so that you can see where you actually are this is the this is the possibility now with the kind of digitization to the kind of work our partners are doing that helps preserve but also story tell about these amazing landmarks we also have for example one of my favorites which is the Thomas Jefferson Memorial Adhamiya just goes back to the home page I'll be able to very quickly as you go down here you will see cities you will see the temples of began and you will also see what I've been finding fascinating is the flight through of the Jefferson Memorial which has been now preserved again thanks to CyArk so this is an example of preservation we have a few others on the platform that you can experience dami I can just fly through and you can start exploring this monument like never before here's the main news why we wanted to talk about this area because SIA has now agreed to open source all this data for anybody to download and so essentially you just have to go to the platform apply and you can get the raw data and start manipulating it playing with it we are already seeing examples of developers around the world who are actually finding new insights thanks to these type of initiatives so moving out of preservation and moving into another area which is basically talking about what we do with institutions and we want to take two example that we launched very recently just took a couple of months ago and how many of you know who Vermeer is okay not bad well he was a great artist okay take take it for granted he was okay and you can google it later to verify it but he was also an artist whose works were very limited only 36 I think and were spread all across the world so there isn't one Vermeer museum that you can go and experience these amazing works and you have Sun I hope you all know what CERN is hands up if you don't know what CERN is okay everyone knows what CERN is great so what do these two places have in common both of them deal with the problem of recreating and experience in the physical world that's just not possible so we can you can't go to Sun to experience the Big Bang for now you can't go to a Vermeer museum and so here comes in augmented reality and we're going to show you two experiments that we've launched light that hopefully will work because we're gonna do it live on stage and these are public so you can download it as well so the first one we're gonna try and show you by the way this is the platform the Google Arts and Culture platform and I'm gonna try and go a little fast which has you know daily amazing stories from Van Gogh's and a lot of other crazy stuff I don't know if you know what the art selfie is try it out over 100 million selfies have been taken using this feature but here's meat were made so in partnership with some amazing museums led by the Moritz house in the Netherlands and involving some other great institutions we bought all the Vermeer pieces together on one platform in high resolution but then the challenge was that's great but what if you actually wanted to give the impression that you were walking through a physical Vermeer museum so we try to experiment and this is an experiment we launched the complete works and augmented reality and I'm gonna try and demo it now and hopefully it will not be a disaster so let me try and find my surface and we're just waiting for the model to load so great so that's the Vermeer museum which can't actually exist in the physical world and you can check out the model you can pinch on it and then you can jump right into it and this is now affirm your museum in your house that you can walk up to the girl with the Pearl Earring one of the most iconic paintings and you can get to brushstroke level details you can move around and as you walk around you can start discovering different rooms you can start walking through other galleries other sections and essentially be in a oh that was a bit too ambitious but essentially back to reality now back to augmented reality and as you can see you know you can start going to every single work of his in high resolution and start walking in front of the painting so it's an idea how physical galleries that can't be created can be done through augmented reality I hope you enjoyed and you can play with it by the way you can spend a couple of hours in that gallery the next example I'm going to show you is actually about a project we launched a few months ago call Once Upon a try 115 scientific institutions bought on the same platform telling stories about inventions amazing great fun but no time to show it to you but I'm going to show you one component of that initiative and this was about how do we get people to enjoy and also learn about the Big Bang something we all know the word but we don't take the time to actually delve into it and so this is a app created with CERN and published under sun and you can download it on any of your different stores I'm gonna go back to the beginning you were about to experience the Big Bang the moment a tiny speck packed with energy suddenly expanded giving birth to space and time to see the universe form stretch out your hand Parma in front of your camera make a fist open your hand just a billionth of a second has passed and it's mr. Imlay heart around ten million billion degrees the energy of the Big Bang has transformed into a thick soup of quartz electrons neutrinos and photons quarks and electrons so I have to pause because I don't have time to show you the whole experience but that's a ten minute augmented reality storytelling by Tilda Swinton that really gets you to understand the Big Bang and of course if you are keen on continuing the selfie trend and want to take something called the star selfie to share with your friends you can actually start doing that and now I am a star selfie so you get the idea with what you try to do educate but also create something playful and fun so I'm gonna move on now very quickly to another section which we may have to skip because I'm running out of time but essentially what do NASA and MoMA have in common they both are amazing abbreviations I think but there are also great institutions and what they have in common is they both have used machine learning in a very interesting way to essentially solve the problem and I think we don't have time to show you both but maybe we'll show you the NASA experiment very quickly so nASA has a public API that they've made public which has around 300,000 images or more of all the photographs of missions and many other topics that nASA has made public but one of the challenges is how to make sense of it all how to make sense of such a large visual archive and so we created the storytelling project that essentially allows you to navigate through every single mission photograph that nASA has ever released in a storytelling way using clusters that have been tagged using machine learning and essentially these are tags that allow you to navigate so rather than navigating through the image you're navigating to these clusters so there are hundreds of thousands of these clusters I don't have time to take you through them but let's just search for the moon and when you search for the moon obviously they're going to be a large amount of images but what we wanted to do was create a simple way for you to enjoy each image and the accompanying story so this is a very simple Leanback you just have to sit down and the story will come on the right side on what each image has what role it has played and of course if you want to just see all the images in a visually stunning way that has been categorized you just click on the visual view and then you have a beautiful beautiful you know essentially view of all these images you can also find some very strange words that you would wonder why they are in the NASA API but one of the words that we found was lettuce lettuce you know for all the vegetarians out there it's a very important thing I eat a lot of lettuce and we found lettuce and essentially we were wondering why has lettuce turned up in this archive and it's because it's about astronauts channel grow essential letters to in in space and so you learn more about the archive through essentially tags and so essentially you know understanding of these words so you can spend a year and join this experiment so we're gonna move on very quickly and go to the next section which is to talk about I've taken you through what we do with institutions I've taken you through what we can do with a large photo archive using machine learning and now I want to talk to you about what we're doing with artists with certain collaborations that we've done we have some that we are launching today that's in the next section these are two examples of things that are going to be actually coming to you very soon and I in development but we want to show you about the examples so the first one we're gonna show you is with an amazing artist called Wayne McGregor Wayne McGregor is the current resident at the Royal Ballet in London but he's also one of the individuals who was responsible for designing Harry Potter's movements in the movies and he has done a lot more so Google Wayne McGregor and we've worked with Wayne McGregor to really tell a story using machine learning how machine learning can inform his art rather than the other way around so let's watch this very short video one of the things that's run through all of my practice has been a relationship with technology so when we started working with Wayne we were really interested about movement prediction we found a research paper which was adults and writing prediction and we think what if we do that for predict things dance movements we use the archive from Wayne to Train the algorithm so they can use this data to generate movement when I'm going to dances normally who I'm asking them to do through their own creativity is make iterative versions of an idea that I might have proposed well this tool does for each little moment is do four hundred thousand iterations of that yes of the canvas is way way bigger we had to gift the archive and it was a huge archive you know thousands of hours of video to be analyzed what this tool allows us to do is go okay I'm starting with this phrase I'd like the machine learning tool the AI to invent the next phrase but in the style of Jordan or in the style of Jess and then you can get combinations of those and then it's learning all the time of feeding back and so this iterative version gives you all of these new possibilities you couldn't have imagined so I hope you're seeing a trend in this chaotic presentation which is that I'm trying to show you a lot of different cultural ideas that can all benefit from some of the technologies that we all have been talking about here at i/o and that was dance and I'm going to show you a very short clip because we are gonna screen the actual movie a little later but this was a collaboration with an artist called Jenna so teller and the movie will be screened by Kendrick and ami are later so this is just a teaser of the behind the scenes and this is really something very opposite from the dance example [Music] Mamiya SETI is an audio-visual artwork based on machine learning or teaching the the machine to speak in tongues so my name is Jana sutala and I work a lot with words sounds and living materials exploring biological and computational systems I'm working with machine learning to generate a certain type of glow so poetry based on Martian language by the French medium Helen Smith in the late 1800s and the movement of bacillus subtilis or the natto bacterium that are also known as a pest species in spaceflight experimentation together the bacteria as well as these early Martian scripts will together with the computer shaman will create a new language altogether and their end result will be so I'm gonna end over there because I see you all so entranced the movie screens after this session so just remember the key words a computer shaman that's what she said not me so moving on very quickly now to what do we have new at i/o well we have a exciting next section we are going to go a little fast just so we get everything in but I want to invite on stage actually known for before I'm right on stage we need to do one last demo that da Mia's gonna do we have launched today an application developed with an artist called Zack Lieberman and Momoh a Brooklyn based artists collective and they have been doing some fascinating stuff on education but also when it comes to augmented reality so Zack came and did a residency with us at the lab in Paris and essentially developed this app and this app launched this morning it's available on the Play Store so please go download it play with it it's quite crazy and it's out there so what we gonna do is perhaps show the video very quickly and then maybe try and demo the app life my name is Momo I am artist and educator and a researcher and we have a studio together and my name is Zack Lieberman I'm also an artist and educator and we're interested in using technology that is code and electronics but to create artistic work we're doing a residency here at the Google arts and culture lab our goal was to create an app that allows you to capture elements in the world and then paint with them in space we create a lot of kind of interactive installation that requires so now let's show you the actual app da Mia is gonna try and demo it very quickly so this is called weird cards he's essentially cutting a bunch of weird things not that you all are weird well it's perfect timing and the idea is you use these cuts well you don't do that but you use these cuts to create essentially you know art in any arc and that's the IO logo they're done by da Mia and I record 20 seconds so download weird cuts by Zach Lieberman and mobile it's a lot of fun trust me especially if you have kids it can be absolutely addictive so moving on very quickly to my next guest and the next experiment that we want to launch today here at Google IO is I want to welcome on stage the lovely Pinar who is flown in from Europe to join us and we're gonna talk about what we've been doing with pin our pin are thank you pin our rather than me introducing who pin Aras I'm gonna let Pina tell you why she's at Google i/o and what does she do thank you so I'm pinning our I'm an artist and together with my work partner viola we have a studio together our main mission as creators is to contribute to the progress of social justice and we do this by using the power and charm of visuals normally usually even though we partner with technology and fashion companies to make their products relevant for the contemporary this is the first time we are collaborating with machine intelligence thanks to the residency with it with Google excellent culture yes so Bernard Bernard came to us and in Paris Sudama actually and she she wanted to understand what we are doing we showed her what we are doing and I don't know how many of you know who alex is Alex works and a team here run by Blaise who's gonna join me on stage in a second and Alex is also the founder of the deep dream sequence so if you move to the next slide by quickly maybe you can see these are your works it's insane I mean it's like you cannot understand what I felt at that very moment a year and a half ago when dhaumya we met Tamiya in Paris he showed us the discoveries of Alex that you see on the top floor these patterns are made by machine intelligence by a complex but simple system that can extract images from the way machine can do visualizations future visualizations and the images that you see on the bottom is our 10 year body of work as fashion fashion pattern creators so it's way before deep dream ever came on Bernard was somehow already off the game and that's reassuring that a human you know was already in this in this sequence so we go show the next slide and should we show ya the different types of things that you discovered so what we did is that we met with Alex obviously the genius and I'm not a coder I don't know how to code so Alex had to do something very simple like a tool that that has only few parameters that you basically place an input as an image the input is in the small image that you see in the corner and then according to your quote-unquote aesthetic or parameter you can play with the parameters and control the output so our role here as artist was to curate the ingredients and guide the Machine and iterations and stop and extract images in the moment we found them beautiful and I think if you see the next slide I hope it's the one that yes that's that's a fantastic slide because that talks about the original image yes so let me tell you the images that you have seen before like the big image that you saw on the screen the pattern is actually what you see in the middle what says deep dream the images that deep dream created and what is on the very left is the flower the heart which is the original input image and what you see on the right is the compositions that we made so the images that you see in the middle come back in the original image in the story in the final artwork like you must understand that this is an incredible moment for me because normally it's like quite a lot of an effort for me to create like images that come from different backgrounds and artificial machine intelligence was like an amazing tool first of all it just never gets tired it runs all the time it doesn't complain it doesn't get Fifi like I do and then it's like it creates these nonlinear images like I'm a human you know how I make images I put something next to another thing I think linear but this thing thinks recursive so it creates things that I never seen before and they're really beautiful and what do you think where do you think this will go for you as an artist this collaboration like where do you think this will move towards yes I see I see two options well first of all if I'm giving like a golden ticket I wanna I want to cover space Rockets for them to go tomorrow but I mean print pattern is something really like really beautiful it's a it's a very volatile surface in the sense that all three-dimensional objects carry a surface so you can cover anything a phone cover fashion this and that but what but we want to start with if we work we want to start with actually can we go back to the former one it's with an exhibition because what you have seen so far is only beautiful prints but we cultivated so much knowledge about future visualization through the process for instance when you place a Buckminster Fuller molecule it as an input you know the carbon molecule in one go it created a snakeskin and in another go it created a turtle pattern another example when we place a nautilus this spiral animal and then when we placed a DNA double string it created the same output so so much can be said about the hidden patterns of our universe and then the second wish is to make technology sexy with fashion we recently as the studio we started making our own clothes that I am wearing right now and like about artificial intelligence machine learning I find it the natural next step in the progress of humanity but I'm afraid not everybody sees the beauty that I see in it and as you know fashion has this wow fashion glamour this instant glamour effect and then I think artificial intelligence can make use of it yeah well I think the excellent example will not only have you cooperated but you also think about how to make it more acceptable to the masses you are right it also it's a great conversation opener like what are you wearing yeah I'm wearing a collaboration between artists and machine intelligence and you just black hole interesting yeah I think I think the way is that it is perfect a definite conversation opener okay so now now we don't have a lot of time unfortunately because we have a next section but we are going to tell you very quickly what's launching so this is launching today this story which is available but what you can also see is the actual tool that we are publicly making available thanks to Alex this is essentially deep dream you could say v2 based on the 2018 paper it's not the 2014 version and it's it's a little less psychedelic it's a bit more practical and it has a lot of variations that you can do so this tool is now launched it's available to anybody go input on any image you want and see what you can collaborate with I think we have one image I don't know if we can do it very quickly which dhaumya took of me eating my lunch which I'm not sure that's the only one I could find that was copyright I'm the copyright owner so I'm allowed to use that it's me so essentially if you take that and if you try and you know very quickly live see what the tool outputs it might take a second but so here that's my lunch and me converted into something quite abstract quite interesting but then you can start playing with it with the toggles so the tool is available on G dots to your slash arts experiment yes that's me and my gazpacho so titled me and my gazpacho so thank you so much Bernard for working with us on this and thank you so much to Alex who can't be here who was an amazing collaborator on this project with Bernard thanks a lot [Applause] so now I'm gonna be really quick to introduce someone who requires a very long introduction but I'm gonna try and make it very fast so I welcome onstage blaze blaze aware who has been a kind of like an inspiration for us here at Google arts and culture because he has been doing this work way before Google arts and culture came along and you know I think I have this torch that I want to read out very quickly but basically blaze leads the team at Google now focusing on machine intelligence for mobile devices both on the research front as well as the new products and the group works extensively with deep neural nets for machine perception distributed learning and agents as well as collaborating with cultural institutions and academic institutions until 2014 distinguished engineer at Microsoft where you worked in a variety of roles and your TED talk which is something that any dead aspirant should should enjoy around sea dragon and Photosynth in 2007 and 2012 and of course Bing Maps in 2010 and in 2008 you were awarded MIT it's prestigious TR 35 so we are very happy to have you here we are gonna now get you to talk about some of the work that you're doing maybe you can start talking a little bit about just deep dream and what your team is doing around this area sure thank you so much for having me up here on it so we've we've been collaborating with with Google arts and culture via a sort of sister program called artists and machine intelligence for for some years now and the the the deep dream the origins of deep dream you've already alluded to this was Alex Morgan serve originally doing experiments to try to understand sort of the neuroscience of artificial neural nets when when we first began to use deep nets to understand images they turned out to be much more powerful than than previous machine learning techniques and and he was trying to visualize what what they were doing on the inside to sort of run them in Reverse and those visualizations yielded these these incredible these incredible sort of no there's a lot of other cultural engagements already influenced with it based on the research that your team is actually doing right that's right so so that that really began the process of thinking about about about deep nets as not only being able to understand or analyze media but also synthesize media so you know we're we're we're the Cultural Institute had had been using these kind of technologies to do things like classify media and allow you to search them the the next step was to try and understand you know what happens when when they begin to synthesize media and what kind of new partnerships are possible with with artists as Pienaar was just was just demonstrating exactly what what has been like one of your highlight projects from these cultural engagements have you what and what has inspired you we so I brought a couple of a couple of slides nothing so flashy is what as well as what you've been showing but but there were a couple of really interesting moments I thought you know at various points in a mais history so far one of them was was was this rather rather inglorious looking little bubble camera which Ross Goodwin one of our one of our artist collaborators drove with Kenrick McDowell around in this car that had this this this camera mounted on it and the camera was hooked up to to both an analysis and synthesis neural networks analysis in order to understand what what what images were being seen synthesis in order to generate poetry from from the images that were being seen so the inputs are coming from the image and from GPS and and from foursquare API and this this journey the sort of road trip that sort of references on the road you know went through sort of industrial corridors and in the in the US that that that are suffering a certain a certain degree of economic depression at the moment red and white flags and the stars were like a curtain of paper like a broad stream of flowers you know these these kinds of lines come out or or you know in in in Biloxi Hard Rock Hotel and Casino Biloxi a hotel in Biloxi a high fisherman with a starry face and a stub of a coat on his face and his shirt looking boldly across his mouth these sort of things emerge from from from this network that has been trained on a large corpus of poetry of 20th century poetry and you know you it a little bit like like like peanuts experience you know you sort of start to get a spooky feeling when when when you experience this like there's something going on in the interaction between the the corpora of human art that has been made you know in the 20th century the environments that we've created in the 20th and 21st and and the neural nets that we're now able to partner with but can I ask you a question because now we've shown a few examples where people are co-creating with an intelligent system what does it actually mean for you both on an abstract but also on a practical level well I don't think that we really know yet where this where this all goes and that's one of the reasons that we thought it was so important to begin these dialogues not not only with artists but also with philosophers and critical theorists and all kinds of other disciplines all sorts of other people you know on the one hand art and technology have always been very deeply enmeshed and you know and if we have this idea about art of it being somehow very pure and devoid of technology this is this is absolutely wrong no matter whether you're looking at aboriginal technologies that use dyes extracted from nature or you're looking at on riccati breasts on a photography or the printing press right it's always been a technological exercise and and and often when the new technology comes and photography is a really good example there's a little bit of a moral panic you know of like oh my god what does this mean right but but of course in the end were not really separate from technology I feel like we're all part of part of the same sort of socio technical universe so this engagement is critical right bye-bye like Jo your group apart from you know this this initiative on arts your group is doing a lot of other very big impactful things cross google and i'm just curious like what more what you're very busy you have a lot of stuff going on but you still make time out to focus on this kind of collaboration with artists thinkers etc and i think i don't know what is the benefit to tech companies why should tech companies collaborate with this type of you know entities well we find this engagement absolutely critical to all of our work this isn't sort of a sideshow or you know or a 20% project for us you know I feel like there's an in celerity to to Silicon Valley culture and we've we've seen some of the downsides of that play out in recent years it's it's along every dimension it's Geographic you know companies that are based in Silicon Valley often don't understand what the impacts and the consequences of technology are in other places in the world they don't have their eyes open through the lens of other disciplines and other kinds of life ways and other ways of interacting with with with people and with technology so you know for us I mean I just I just came back Henrik and I were we're at the Strelka Institute in in Moscow for a week last last week in discussion with Benjamin Bratton who is one of one of our artists emission intelligence collaborators and an urbanist an urban theorist and it was an extremely you know this was this was an engagement that that that we're bringing back into into the lab and into our work in a variety of very concrete so you are finding practical nuggets that you can actually take from these engagements absolutely and put it into the actual you know larger technical work that you're doing absolutely okay and so obviously that means you want more of these interactions yes you don't want less of them right because you want your main work to be further enhanced we want to keep going as you keep engaging yes so to do that I heard that you and I and our teams are going to announce something today so why don't you how did you know of it because we working on it talk about please go ahead go ahead yes so I I this was this is what another project and that's that I didn't have a chance but I feel like we've already shown maybe too many of these so perhaps we should skip straight to the well this this was a really beautiful really beautiful project so this is this is Ross Goodwin's the road this is Rafik uh Nadal's archive dreaming which which we were pretty excited by he he first did this experiment in in 2017 with the salt archive in Istanbul so this is an example of another very large art archive similar to the ones that da yen was showing earlier and and he created an environment that that was that consisted of curved screens and mirrors and and let you sort of explore the archive in a very rich interactive way but but also Mike tyka on our team Internet you know sort of worked with him with synthetic networks similar to what Pienaar was showing and so you could both visualize the the archive in a variety of new ways and also sort of synthesize media that that look like they belong in the archive but didn't visually quite intense now I think we should go to the Grants Program yes in 28 seconds the door in so in 20 it's in 24 seconds the doors open so let's go straight to the to the grants program so this is something new introduce it so we're doing six grants over the coming year it's for artists there's there's no it's it's over five months there's no there's no commission there's not a requirement for any specific artistic output but creative technologists from from Google Debian and and Kendrick and an engineering help from Google will work with those artists and their practices to to sort of extend their their thinking with these with these new approaches and technologies yes and this is a formalization of the work that blazes team has been doing for many years with the ami project and you know we are starting your starting small I'm you're starting humbly but we are hoping that these grants will enable artists to come and work with people like yourself and kenric to essentially provide that extra nugget for the work that you're already doing right yeah we've had we've had wonderful engagements for this kind of thing in past years and now we're formalizing it and scaling it up three new things at i/o weird cuts deep dream v2 call infinite patterns launched and machine learning grants so don't tell it was not enough I hope that's enough and plus all the other stuff needs through so thank you so much please for coming on Thank You Tina Thank You Daniel and we are right on time so you guys can go and enjoy your evening bye-bye thank you [Music] you 