 our next session is about human intellect nai and our first speaker is Dan Bohus he is your researcher I sitting next to me bothering me for many years yes so he's gonna be our next speaker hey guys yeah I'm ban like a lot of people here I was also an intern with working with Eric and Tim pack at the time all the way back in the summer of 2003 I became a full-time researcher in in Eric's group in 2007 so I thought it would be be hearing to bookend my presentation with that year and start by showing you guys a little bit from my job talk back in the day my dissertation I was working on error handling in dialogue systems and speech recognition problems so I showed this sample interaction with a dialogue system in that age the texting blue is what the system is saying the texting grey is what the person is saying and the text in brackets is what the recognizer understands I need you to answer the following question what city are you leaving from Chicago traveling from Chicago where would you like to go so traveling to Seoul what day did you need to travel no traveling to Birmingham traveling in the afternoon okay what day would you be departing Chicago flight tomorrow I have a Korean Airlines flight departing a Chicago at 1:40 p.m. arise a Seoul at 5:00 p.m. the next day do you want to take that my destination is Birmingham traveling on Saturday August 12 I have a flight departing in Chicago at 1:40 p.m. arrives also we were miserably failing somehow I got hired and over the next 10 years basically in joining the MSR my research agenda kind of shifted into this area we call now situated interaction where the goal is more to enable machines to open up their eyes and reason about their surroundings a bit more and collaborate with people in physically situated open-world settings and Erich had to do quite a lot and I'll say a bit more with that shift but over the years we're basically studying these problems with be studying these problems we build a lot of artifacts put them around the building the prototypical example is this little guy that probably all of you guys know directions giving robot that tries to understand what happens with its deployed in an open world you know in an open space where multiple people come and go tries to understand you know what people want and direct them the right place now if there's one thing about principles of intelligence and one message that I want to get across in this little presentation is that over these years of work in this space I think I've come to realize that intelligence is actually often social collaborative and actually not immediately visible to the naked eye we do a lot of things that are very very very smart and we don't realize we do them up until the time we try to make a computer to them and then we realize oh my god this is difficult when people come to interact with each other with natural language we coordinate our actions in a very fast-paced very fluid mixed initiative manner we continuously monitor each other and we produce on many different channels simultaneously there's the speech but there's a lot of nonverbal work that's going on and we do that to resolve in parallel a number of different problems a first problem we have to resolve when we come together to interact is establish and maintain an open communication channel you never think of this but whenever you're in an interaction to someone you're doing a lot of work with your body placing yourself the right way looking at the person for the right amount and so on to signal yes I'm still in this interaction so there's this process of engagement that you know in mobile phones and assistants like Siri you push a button and you're engaged but if you have a system that lives in the world and tries naturally interact with people you kind of have to do work to solve it and we'll see an example about that in a second once you solve that problem engagement you need to coordinate with people how you bounce signals from one to the other there's a lot of coordination for instance happening on the verbal channel with turn-taking we don't overlap so much or we overlap in very coordinated ways actually and then all the nonverbals are also coordinated with everything on going on only once you have kind of solved those two problems and they're really challenging you can start worrying about decoding the meaning behind those signals understanding the intention is this is where you get into speech recognition language understanding and then at the higher level you again have to do some more longer-term thinking and planning about pursuing mutual goals and how do these goals shifts over time and plan your whole interaction so in the work that I've been doing basically we've been looking at constructing these commenting of competencies and this is something that has been inspired you know way back like and has been taught by other people like Clark you know the work on grounding all these different levels and papers by Eric and Tim in the late 90s that have laid the groundwork for for for you know for this kind of thinking so in my work I've been a lot driven and inspired by those papers and I've tried to sort of bring into this equation more the social and situational context adding the who the what and the why of the surroundings and building computational models for processes like engagement turn-taking understanding and there are tightly coupled into understanding the scene around and so just to give you a hint of what are the challenges in here I want to show you one quick video about how challenging it might be to maintain engagement which is something again that you never have to think through in your daily life you all just know how to do it getting a machine to do it is much more challenging here's a little example from the directions robot natural interaction happening in the wild the bathroom is just down that hallway and on your right by the way would you mind swiping your badge on the reader below so I know who I've been talking with got it thanks Louise is there anything else I can help you by sorry say that again I'm sorry I still didn't get that can I help you find something else thank you okay then goodbye the robot has a hard time letting go so what is going on here well what's going on here is that we all as humans know when we see this picture that this guy is leading but all the robot sees is a square about where the face is and maybe it knows that his face is a bit oriented that way but it doesn't know that his shoulders are pointed that way in this case he doesn't know that he's waving it doesn't really in this case and that's something we should definitely do put it together with where we are in the dialogue and so on and so because of that it launches into this next utterance that's its next dialogue state after it gave directions to say is there anything else I can do for you but that's pretty long and it happens as the guy is moving away now what's interesting is that just a second and a half or so later the robot figures out that this guy is actually even by then it's too late he's already kind of heard this and stopped and coming back and so this creates this complete breakdown in sort of the fluidity and the interaction and what what should actually happen and so we take a problem like this observation like this in the wild and we think how do we fix this what do we do and what I find really interesting about generally broadly speaking this line of work with these robots and and this situated interaction space is that you'll take a problem and then you'll highlight something that feels pretty cool actually more fundamental AI terms so one construct that this sort of drove us towards is this notion of forecasting and how important are all forecasting plays into our interactions we are able to project very easily ahead what's going to happen can finish each other's sentences we have this ability and machines don't and so can we build that so the idea here was well actually the machine will observe just a second one half later that this person is going away can we make it forecast that can we learn and then if we could somehow forecast if at t0 even if we weren't sure exactly yet that they're staying or going can we leverage a device like hesitations which humans do all the time can I say something like so and that buys me a few more seconds speaking of value of information information computation to get more information and then if at T 0 plus alpha they're going away I can say so well I guess I'll catch you later then or if they're still sticking around I could still naturally say so is there anything else I can help you find right and so the notion of forecasting I think is fundamental in all these systems where you have to do with timing and coordination and in a case like this you can actually grab features that the system has like the location of the face and attention and everything in the kitchen sink and because the robot knows based on some heuristic that at some point this engagement does happen you can roll that back in time and construct a label and build a model that automatically trains by observing just the interactions and with respecting over them without any need for manual labeling to learn to anticipate and learn to predict and you might not do as well as you plan to you might not be able to anticipate this by 5 seconds but you might still gain some time and then in conjunction with hesitations that can give you a more fluid interaction so I just want to show you this is an example of the kind of work we've been doing there's a lot of challenges like I said in this space that I think are fundamentally challenges challenges with timing coordination initiative and this was an illustrative example of that there's interesting challenges in multimodal perception there's a lot of work these days with deep learning into getting perception to be better and better and better I still think there's a lot of open space there for instance in reasoning jointly about people what does one person's attention tell me about the other person attention and reasoning about overtime from videos and trying to understand deeply what's going on and these systems also surface really interesting challenges in integration because they're composed of many different technologies there's fascinating sort of integrity of AI challenges like blame assignment something goes wrong somewhere at the end how do I know where I should place barium in this entire system and so on but to recap in 2007 we were miserably failing this way and these days were miserably failing this other way so you could ask what have we done really and I'll leave you I'll close with this thought that this is a this is a plot of word error rate speech recognition were there rates over time I think this one starts at 90 88 I think I've seen one of these plots first shown by Richard stern at CMU and he might have had an even earlier version but what's interesting to me about this plot is if we quint from a distance at it what you notice is that the word there it is somewhere high up and it gets lower and lower and lower and then all of a sudden gets high again and then lower it more and then all of a sudden it's high again and lower the reason this happens is people switch the problem right so first we've been working on 1,000 this can like disconnected word recognition and then we go to 5,000 words and then we want to do read speech and then natural speech and then far-distant microphones and so on and so what I feel has gone on with my work between the password that I've done and since I've joined MSR is basically one of these shifts and I would like to thank her it because I think he has been instrumental in this and he's been his support has been fabulous I remember distinctly on these conversations where you know I was on this first line in 2007 after I joined and I was still working on improving belief tracking in dialogue systems and I was writing these papers as clobbering the speech research guys and we had some 1% improvement on on some you know on some eff metric or something like that I don't know what it was and I remember Eric saying like this is great but look why don't you you know like instead of 1% improvement on something let's think big let's place a big bet let's do something that's really out there that that you cannot really solve today and I think his support has been tremendous through all of that and thank you for that there again happy birthday so our next speaker I think will be Evie flaw okay hi everyone so a couple of months ago I had a conversation with my piece she stood in Alex Williams I told him that I'm coming to Microsoft Research he's actually interning right now like many of us in the past it's a privilege of interning at drunkest of resources summer and I said you know piano and he asked me why I'm coming and I said Eric is having a 60th birthday party there's some mega celebration and Conference event to which he replied haha really I feel like he'll unveil that he's actually part machine since 1989 it's a secret to not sleeping and I said oh my god you got it he's part AI and part human that explains everything right it explains why he has so much energy explains why as an intern I got emails from him 3 a.m. in the morning talking about research I also explained the human part explains his curiosity about just about anything and everything and maybe also explains why in the past decade he has been a champion of human AI research so when I was a graduate student at CMU arrived there in 2006 I was really interested in human intelligence and machine intelligence any type of intelligence I was set on doing machine learning research and then my then advisor show me the ESP game they show me recapture and I was hooked you know this new idea of human computation how can we leverage human resources on the Internet and accomplish tasks together with supported by machines I did an internship at Microsoft Research with Max TruGreen and at that time there was a lot of excitement about this new idea and we spent a lot of time talking about well there's actually no research community whatsoever in human computation let's just create one and this was back in 2009 with Paul Bennett who is here max triggering a bunch of people at NYU we proposed to have the first workshop on human computation at the ktd conference in Paris and of course we organized many workshops after that there were about four workshops after that and at some point I a bunch of us as approached Eric and said really we need a permanent home for this community and so we wrote a proposal with Eric to make this into a an official conference under the Travoy umbrella and this has become an annual conference that has gone on for six years now and next year is gonna be the tenth year anniversary of the conference and I wanted to say that this was really exciting right as a graduate student as an intern I had the opportunity to work on starting something like this and this is you know this is one part of the amazing thing about my course of research is that it gives interns this opportunity these these big big things that they can actually accomplish and the other thing is that I think human competition was a very young area there was a lot of excitement about it but there was also a lot of skepticism and so I think without Eric's leadership I think this whole thing wouldn't have happened this community wouldn't have grown to the size that it is now so we really thank you for that so the other thing is III at some point in my PhD career I realized that you know he the the machine learning part really ought to be part of the human computation and I really wanted to work with someone who is actually doing work at the intersection of the two fields and there's not many people like that so I basically stalk Eric for a while and when he came to see me to a party I cornered him and I said I really want to work with you on projects and so we at my internship we worked on multiple projects including looking at how do you do human computation which is one person like so how do we actually make sure that we can route tasks to the best worker what if you have web search relevance judgment what happens if you can actually make them choose query to judge instead of just getting forcing them to judge certain queries we with Ho Chi we also worked on a secret project I'll tell you why a secret in a while basically we developed an interface where we wanted to to use it to coordinate a plan that is generated by massive number of people on the internet so imagine a crowd of people that all sudden want to create like an event and they want to create travel I January can coordinate thousands of people creating a single plan we kept this a secret washi we didn't quite keep it a secret which whole Eric that we were working on a secret project can we do it and he said fine and the reason is that we were planning to deploy movie to thousands of Microsoft intern and have them planned their own in tournament and at some point we're like well the police are gonna come after us because there will be thousands of people on the street you know apparently coordinated their own events and I think how she even talked to a lawyer about this at the end we didn't do it just because but it was it was really fun and Eric has also been instrumental in my PhD work which is about how to combine human and machine and a large scale to learn attributes of objects like music and videos and images so I want to say that one of the main I think one of the main contribution that Eric brought at least to my career is that he created a safe space that where we can do research other intersect of HDI and AI I think one of the toughest challenge for me as a PhD student at that time was that people always ask me are you HCI researcher or a researcher and you know to which I think Eric gave us the Liberty to basically answer like why does it matter right the most exciting place to be is actually at the intersection and so I'm now assistant professor at University of Waterloo having an ex-cia group and virtually all the projects that I do has some element of X e aí and aí in it for example we are working on projects looking at how to coordinate people to do these medical annotation tasks that are very unfamiliar to people like like sleep stage classification or heart sound annotation we're looking at also questions about interpretability Trust how people interact with AI systems and robotic system and one of my pet project right now is looking at teachable robots how can we develop robot that kids can teach and learn through teach think while teaching and how can we design these robots so that we can actually use it to enhance human curiosity so I would just want to end with kind of a story I wasn't sure whether I wanted to tell this story or not because it's a little bit personal but Eric actually came to University of Waterloo took it for a distinguished lecture at that time I think it's also around the time where it was announced that he was gonna head the Microsoft Research AI group and we had breakfast together and he told me that oh I have a really really important phone call to take I almost canceled this trip because it's so important and I can't tell you what it is you might know about in a few days but you know can I use your your office for us for Skype or something like that but then during during breakfast we had this really deep conversation about life because my mother had just passed away so he shared a lot of kind of wise thoughts about life and how we should approach things and his own experiences and then he went off and took that phone call and they give a distinguished lecture so this is kind of also what I want to end with is that Eric is like a machine because he can do like all these crazy things in his career and lead this big in AI initiative and Microsoft research but then on the other side he also really care about people and so he's also very human thank you [Applause] the next speaker is my partner in crime during the internship how she Chiang from what Northwestern hear me now can you hear me now okay good so yeah I just I'll say a couple things about my work on computational ecosystems but really I'm gonna take this opportunity to talk a little bit about how Eric turned me into HCI researcher which I'm sure he doesn't want to hear right but using this as a way to showcase kind of three lessons that I learned from Eric in walking together in working together but also in walking together right a lot of times that a lot of what I learned for America actually come on these long meandering walks where I don't really don't know where I am anymore halfway through and he's like okay let's just keep walking okay so I'll get it to these lessons in just a second but before I jump into those lessons I just want to your state for for history sake that actually started as an AI researcher okay so this is actually a picture that Eric took of me a trip away I this is my first conference as a first year PhD so you didn't ever go into trip boy yeah and I was talking to all these amazing researchers who came up to the poster no thanks I appreciate it was very big I could say that yeah and it had all these people coming to me and talking about the poster and I was really exciting and then some guy comes along this wasn't Eric who started critiquing my work and talking about how am I gonna make money off this like how does this you know Avance this and that and I had no idea how to talk to this guy and then in comes Eric and Eric starts defending my poster is there telling this person about my work how it works that and why has these broader implications and I'm like who is this guy like I never met Eric before then and then you know he takes a nice picture of me as sends it to me and my advisor that day after and it's you know really nice and that's how I started meeting Eric and a couple years later I really did turn me into an actor okay so I have the data to prove it so in this graph that I produced last night well I'm showing you right on the horizontal axis is my PhD and my career trajectory right now and my professor at Northwestern um and what you see from this graph is that I used to do AI work right and this is working with Eric in that gray box in the middle I've kind of shifted over to doing stuff in HCI so you know I have Eric to blame for that but actually this is kind of a false representation of what's happened even if you know you look at the problem as components this is what it would look like actually if you think about it more as an integrated whole much like how edith is talking about what Eric helped me do is to learn how to integrate AI and HCI as joint perspectives and thinking about problem solving more broadly using humans and machines okay so in this way one of the first lessons I wanted to share that I learned from Eric is really thinking about designing integrated systems this is a quote that Eric gave in an interview where he said I'm pretty sure that the next leaps in AI will come from integrative systems on rather than wedges we're just being wedges of intelligence we need to focus on building a system where the whole is greater than the parts and I think Dan gave some great examples of this for doing this even with AI systems of how to build integrative systems for my work I've taken it more to mean how to build integrative human machine systems so I've been doing this work on computational eco systems where we've been thinking a lot about designing socio technical systems but where we're designing the process by which people work their ways we organize and the intelligence systems that support it as a coherent whole okay so we're actually not just thinking about designing component technologies we're one way of people doing something and changing that only but thinking about compositions of processes and ways to integrate groups and crowds and problem-solving for example um so using this approach we've been able to solve some really exciting problems in the world to advance the kind of human values that I care about that if you take a human based approach it doesn't really scale but if you take a machine based approach it fell short of really advancing the true human parts of the problems that we care about so these two examples I have are about advancing community based problem solving where on the Left I'm showing some work on community inform planning where we did do more work on facilitating complex planning with thousands of people participating in a planning process for example for planning large academic conferences on the right we've been doing some work on physical crowd sourcing where we're thinking about having people conveniently going about their way helping with other tasks in their local communities in a way that brings people closer together but also solves these local problems and I'll get into some of the principles for that example although later I've also been using this kind of computational ecosystems idea of building solutions to advance the scale on the learning of complex skills so we have all this great advances in AI for example through intelligent tutors for people being able to learn with AI agents but for certain things like for example how to code professional quality webpages it's not something that we could solve with AI alone um so what we've been doing is advancing something we call readily available learning experiences or rel where we're transforming professionally made artifacts on the web so all the web pages and web applications that are out there into an authentic learning resource okay so we're using a combination of AI but also of humans with scaffolds for scaffolding a learner making sense of these examples managing the process of investigating them reflecting and being able to construct deeper conceptual models um how to actually build complex artifacts like this by learning from the artifacts themselves um and on the right I'm showing you a picture of my research group at Northwestern I run a program called design technology and research where I trained a large number of students mostly undergrads but my PhD students as well and I'm doing it to not only train students how to do research I'm bernoulli learning how to lead research projects and complex work more generally so over the last four years have trained 70 students in independent research and with this model this computational ecosystem we have I'm able to train 20 to 20 plus students at a time with a single faculty mentor and scale that kind of training using automated systems together with these organizational processes and structures that we have for mentoring students so moving on to my second lesson I wanted to share this perspective of thinking about using AI to empower human interactions right so I got this quote from Eric's mix initiative paper from 99 and it talks about this idea that the AI could be a way to enable new kinds of human machine interaction and it's a perspective that you know it's kind of taken up in HCI but but I think actually not as fully as it could be in thinking about how AI could enable human interaction so let me just give you some examples here where I've thought a lot about how to empower flexible and opportunistic ways of solving problems within communities so for example on the left for community-based planning and what I'm showing you is an interface that allows a decision maker like a conference organizer for example to be able to use community input machine intelligence and their own test and knowledge to make decisions about how to form a better plan and what's interesting about that example is not so much using the machine just resolve conflicts but it's that the organizer can go into this and flexibly think about what they care about but with an awareness of how it would affect the things that the Machine knows about right so you could actually apply a lot of tacit knowledge and actually do the things you want to do but have the machine in the back supporting you being able to have that flexibility to not mess up the rest of the program um and on the right I'm showing you this example from called decision theoretic head or weight so I've been doing this work in physical crowd sourcing and what decision theoretical oh wait does this gives you this away for people to just do whatever it is that they feel like doing they're just walking around you paint them and ask them hey can you help look for a lost item it's you're just passing right by an area where the item might be lost and what it's doing in the back end it's coordinating indirectly these interactions so that people helping in the moments they feel like helping as they wish um actually produces globally affected behaviors okay so you could actually get to 80 to 90 percent of the opt even if you actually knew what people's routes were going to be ahead of time but you don't right so you're using decision theory in the back end to empower this kind of flexible and opportunistic way of solving problems and where decision theory is not used just for optimization but it's a way to enable new interactions okay so onto my third and last lesson and this one just says be bold and be you so I've been traveling a bit giving talks at different schools and one of the things I realized and I was really grateful for us I was reflecting is how I just been able to to do what I want to do and to solve the kind of problems that I want to solve and I think much like Edith was saying I think Eric gave us a lot of confidence in being able to approach the problems we care about not worrying too much about whether we could solve it today with just the technologies that we had on hand so I wanted to end on this picture where you know for me one of the big challenges often is there's these values that we care about in the world that we think about as being very human and then the technological solutions almost never directly line up with the problems that we care about and the ones we want to solve and the question of course is what what do you do when this happens right so you could just go ahead and solve whatever problems the technology allows you to solve but I think we would all miss something if we don't stick with our values and what it is that we care about and I think this is one of the things that I really learned from Eric is just to be bold and to do what it is that I want to do even if a technological solution doesn't present itself okay and the way to move forward or one of the ways to move forward are these lessons that I just shared that these are three lessons I learned from Eric but the title of this slide could just as well be how to build comprehensive solutions to complex real-world problems right and the three lessons are to design integrative systems thinking about humans and machines working together within these computational ecosystems and then using AI to empower new human interactions and then being bold and just sticking with what it is that you wanted to do all along okay so thank you and that's all I have so next up we have a dish who's gonna talk about his work so hello everyone I'm auditioning a faculty member at Max Planck Institute for software systems in Germany I'm really glad here to here to celebrate this milestone birthday of Erik and in this talk I would share some research directions towards teaching and educating people as well as assisting them in their tasks so let me begin by sharing some of the collaborate collaborations and work that I have done with Erik as well as other colleagues at Microsoft Research to begin with I did an internship at Microsoft Research to admin in fall 2013 so here I was working with Eric Orbitz and Ryan White where we were tackling problems in a multi-user search setting where there multiple users behind a machine which leads to interleaved search histories and here we develop new techniques how to attribute search activity to individual users so that we can improve posture issue we continued some of this collaboration through a work on stochastic privacy where we introduced our new approach to privacy using probabilistic methods and then I did another internship at Microsoft camp which this time but this was also Co supervised by Eric remotely and here we developed new privacy aware techniques to information gathering in social networks and applied it to techniques for decentralized task routing and that's a picture from my thesis defense in ETH Zurich last year and Aleks mentorship has played important role in shaping the research direction that I'm purchasing at the moment so right now I'm leading a machine teaching group at Max Planck Institute for software systems and the focus of the group is towards developing novel AI and machine learning techniques to empower people by teaching and assisting them so in the context of teaching people so the current research is grounded in to complete applications so the first being citizen science project for biodiversity monitoring where we would like to teach people how to identify different animal and bird species and the second motivating application is from educational simulators so for instance simulators for surgical training or car driving are becoming increasingly increasingly popular to provide cost-effective training and so here are basically the goal of a research is how to come up with teaching policies that could provide personalized curriculum to make this teaching process more effective and in the context of assisting people the ongoing research is motivated by applications of assistive AI agents so that could work in partnership with people to solve complex open-ended tasks so one concrete scenario could you could think about car driving where we would like to design an assistive AI agent that could drive the car in an autopilot mode how would provide the control back to human driver in safety critical situations and to tackle these kind of problems we are essentially thinking about this human AI system as a multi agent reinforcement learning system we would like to learn a policy that optimizes joint performance of the whole system so in this talk I would like to give you some research overview of what we have been doing in the context of teaching research theme of teaching so let me quickly tell you what does it actually mean to teach a bit more formally so it's basically an interaction between a teacher and learner to players and so it's somewhat of inverse problem setting compared to a learning setting and essentially the focus here is on developing algorithms for a teacher which is shown on the left here and you could think about that teacher has some target in the mind so theta star which could represent an optimal policy that teacher would provide to train the learner and the objective here is to come up with an optimal sequence of training data to steer the learner towards this target right and the interaction between teacher and learner could be thought of as follows so let's say at some point teacher gets to see and why the estimate of what is the current state of the learners mind and based on that it would provide our next training data to some so that learner can make some progress so what is important to note here is that you know motivating applications so there is nowhere for teacher to directly engineer this target theta star into mind of the learner so basically this transfer of knowledge has to happen through this limited communication that we have and the communication here basically means labeled labeled image for example or kind of demonstration of how to perform an action in a particular state so I typically like to think about the research problems in this space of teaching along these different dimensions and first important dimension is to think about what exactly is the task that we are interested in teaching and we could have tasks of increasing complexity for instance our teaching a task of how to do binary labeling to multi class labeling or teaching sequential policies of how to act in an environment and the second crucial aspect is basically how do we go about modeling the learners learning process and here one simple solution is we could think about some classical machine learning model which is suitable for the task and while it's normally typically easier to design teaching policies for such machine learning models they might perform very badly when we would apply them on human learners and the next step could be one could week these machine learning models to make them little more human-like which are more robust and suitable for human learners and a more practical solution would be to consider some cognitive models of human learning process so that they can actually reflect how human humans are learning in the system what is important to note here is that as we increase the complexity of this learners model it gets a lot more challenging to come up with optimal teaching policies and/or to provide some kind of performance guarantees and the third crucial dimension of the space is how much did knowledge teacher has about the learner right so one simple setting is where we could think about teacher being very powerful and only sane teacher who knows everything about the learner somewhat more realistic setting could be where learner doesn't know the current state of state of mind of the learner or has some noisy estimate of it a little bit more challenging setting would be that would reflect realistic scenarios is where there's some kind of model mismatch between learner and student for instance in educational simulators we could think about that there's a mismatch of state space or feature representation or the perceived rewards between teacher and student are different so what is important to note here in the space is that as we go from left to right the complexity of the problem increases while we are able to capture more realistic and real-world richer applications it gets lot more challenging to come up with teaching policies that we could actually optimize so next I would like to give you a quick snapshot of what we have been doing recently in a group and try to highlight where they fit in this problem space so first is a recent project on maybe have been trying to walk towards teaching a multi-class labeling task and one of the motivating application here is what I mentioned earlier about biodiversity monitoring where we would like to teach people to identify different animal and bird species another motivating application here is to teach vocabulary of a new language for instance why are showing flashcards so more concretely let's say you have four different flashcards for vocabulary words and let's say you could interact with the learner for 20 different time steps so then the research question here would be what is an optimal schedule to show these different flashcards so that we could maximize the long-term recall probabilities of the learner so what is important in this project is how do we kind of think about the limited memory effect of the behavior of the learner so since human learners have limited memory so it's very important to kind of model the forgetful behavior of these learners and for this work what we use is cognitive models of human learning which have basically this effect of limited memory so for this work but we have designed algorithms which basically output produce optimal teaching schedules with some near or near optimal teaching schedules with some provable guarantees for this kind of memory models and we have developed to teaching platforms in this work one is to teach name of the species and the other is to teach German vocabulary which are accessible online so another recent project is about teaching sequential policies motivated by this application of car driving simulator so here but basically we are trying to think what the problem is teacher could provide demonstrations to the learner of how to perform different actions in a particular State and the goal here is to somehow teach this policy shown in the blue by providing some kind of demonstrations so so here we consider basically this car driving scenario we model this whole environment using this simple simulated environment and then we have basically these optimal algorithms of how we can produce this optimal sequence of demonstrations so what you can see below is one thing I would like to highlight is here we are considering more complex teaching tasks so here we are actually talking about teaching sequential policies of hard to perform actions while on the other hand we are essentially considering a simpler learner model so here the learner model is a simple classical inverse reinforcement learning algorithm to keep the problem tractable as a first starting point so that's a quick snapshot of what I've been doing in my group recently and I would be happy to share this research directions in more detail to summarize I would really like to thank Eric and colleagues at Microsoft Research for their mentorship and I'm looking forward to continue our collaborations in the future and thank you everyone for listening so our next speaker is Michael Bernstein from Stanford all right so I started by thinking how should I describe Eric and then I realized I have data on this ten years ago I worked with Eric and des new tan and Meritor Winsky to try and figure out information that wasn't out on the web writ large we created this Facebook game where basically people would all start tagging each other it's sort of like a game of family feud to try and guess what people have yet said about each other so I went back and Eric this is your life at least as of 2008 so there's a bunch of stuff that I think makes sense there others I'm really curious about like yeah I was wondering if you did you Ram a boat or something like this that like this unigram model doesn't isn't quite working for me but I think it really carries a lot to say about how Eric has integrated a lot of different perspectives together you see different sub communities of him saying you know overlapping and somewhat different things about him and I think that and as how she mentioned the mixed initiative paper really captures a lot of how I the the energy and the drive that I take from having worked with Eric now twice just understanding how we can go after really ambitious goals like how would we as humanity go about creating the next oh the next world wonder right let's not try to build suffer let's create something truly imaginative and what I take from Eric is just this really deep understanding of how we should be continuous combination of human intelligence and artificial intelligence because we know that human intelligence isn't very good at this in fact there's an entire field called organizational behavior that says how terrible we really are at it and it's just like we have biases and heuristics that we use for individual cognition that don't quite work so - are we really bad at thinking about how we should design aggregate human endeavors but as Eric would say for the first time we have all of this happening inside of a computer right and because of that we have an opportunity to actually design it just like I would design an individual's interaction with a computer we can design aggregate interactions to think about how computational intelligence might augment us in creating that that next world wonder and I think you know my my work and how I've taken this from Eric has really spanned all the way from the individual level out to the organization to the world and I just want to give a sense of like how that really has percolated through my thinking you know to start this kind of individual work that you see the basically underpinning all modern AI systems here trying to label a man riding a motorcycle yes or no is really sort of boring not that interesting and not taking a lot of advantage of the human cognitive capacity but what we can start to do is do this in a bit more fun way of audience or participation everyone please hold up your hands and what I'd like you to do is clap whenever you see a man riding a motorcycle it's gonna be a little hard here we go ready set go oh come on you can do better than that okay so you might notice that you're not so good at this but in aggregate there's actually some signal here you're delayed there's some error but we can understand that by the take advantage of what the human perceptual processor is good at and what computer processors are good at like dealing with this noise in this error and produce something that actually produces really high-quality labels at an order of magnitude lower cost or higher speed whatever you care about and I think you drive this forward and there are so many opportunities for this integrative opportunity so we do so much work here in organizations and teams my research happens in teams product development happens in teams and we can think of this question like well how what's the optimal way to even work together how should we be doing this should we be flat hierarchical should we be really supportive of each other so would be really mean to each other just to get the facts out should we make sure that everyone's speaking equally or not and you know we come up with these theories about what's optimal and then we create these systems that try to encourage people to and nudge them toward these structures and again the behavioral sciences actually say this is probably a terrible idea that there's no optimal way to organize a team this thing is called structural contingency Theory it says that it depends on the people and the task and worse if we pick the wrong ones the team really really stinks and they're mad and they're upset and they fracture moreover managers who've paid a lot of money to learn how to do this and are then paid a lot of money to do this are actually pretty bad at it so we start to think about how can computational intelligence help this could a team it's sort of experiment on itself and rapidly identify the right set of structures you know you have a team's coming in use this system and get colored differently based on the people and the kind of thing they're trying to do could we do this fast enough that it would be valuable we have hundreds of different combinations but roughly what you're imagining is you start out with nothing you give feedback to the system either autom automated if we can measure how it's going or subjective and then the system makes a suggestion like hey I know this sounds a little silly but let's all try to be extra cheery right now or why don't we try decentralized hierarchy and through rounds of feedback the system quickly tries to identify what's the right set of straw for that team it's this integration of the human reflection and the artificial intelligence of course behind this is a network of bandits I should be talking to most and more my colleague since he's clearly doing this better than I am but one thing that we found is that if you just use a straight-up network of bandits people ignore it it's like basically if I as an advisor tell my students to do 15 things at once they listen to none of them I mean maybe they would do that anyway but especially if I say too many things so we started developing new new models of bandits that are temporally constrained trying to smooth over how much change can happen at once so we can model how many how much change can a team absorb at once trying to change the sort of posteriors in the in the Tomblin set Thompson sampling algorithm to say well maybe we only want a quarter as much change as you might naturally want to do and try to keep everything a bit smoother and we can do this across the entire network of bandits and it has some incredible opportunities to allow us to say alright no more for example then say two changes at a time or certain dimensions we know for example hierarchy should not be changed at the beginning but can be changed at the end and it turns out when we try this we have we bring together these teams we have them play really hard solve hard puzzles and we can have managers try to decide what to do we give them the exact same set of structures we can let Oregon we can let the group decide collectively we can just let things roll as they will we can use a straight-up network of bandits or we can use these temporally constrained bandits and what we find is that these teams that are using the temporal constraints are performing about 40 percent better way better than I'm sorry any managers in the room I should probably not be showing this all the other teams were statistically indistinguishable from each other this integration of the artificial intelligence and the human intelligence produced something way better than the people who are risk averse and not trying enough things or the algorithms that were trying to do too many things at once but could we scale this up even further could we create you know on demand flash organizations these groups that could rapidly assemble and adapt you know imagine how your organization works today but essentially driven and aided by computation to help its adaptation imagine an organization that can adapt much much faster right these roles teams hierarchy of your organization being sort of source code of your organization and if a machine could introspect on that it could do things like identify an opportunity for a role that needs to be hired and a few minutes later have exactly the world's expert for what you need or to help onboard that individual tell them about their position in the organization and how they should be how they should be interacting with the people around them you could allow people bottom-up or top-down to suggest changes to the organizational structures issue pull requests and merge those in so that the organization can change as it gained as it gains new information and if we do this we see some crazy things crowds that can then do product design software development game production in about six weeks imagine again having something that you that you that you a role that you realize you need and then 15 minutes later having the world's expert at your fingertips helping you solve the problem so we have these things we gave this to people who had no prior experience they're building tablet applications web applications they're creating marketing teams that make videos there are teams of poets and a chief poetry officer which I've never seen before and so on so what I really see here is that there's just this opportunity and I think how she alluded to this and Edith alluded to this that by thinking about that integration effectively we can get much further so close with an embarrassing story I'm embarrassed to say it's not actually embarrassing to Eric it's mostly embarrassing to me because I went back trying to figure out how did Eric and I first start interacting and I was expecting it was right around the time that I started interning with him and Disney and Mary and it turned out unfortunately I really should not be keeping my email records as far back in 2006 an email started like this dear doctor Horvitz I am an undergraduate at Stanford writing an honours thesis and my first response was no because as a professor I get a lot of emails that start just like that and it goes on to say I found your work predicting user activities extremely useful was one of the first that I read when I was beginning my project again I've gotten a lot of these emails and I'm saying no don't do it Michael then I say I'm now at the point of having pilot software no cohere in theory I've written a white paper and have made it public no please and I don't even know what I meant by cohere in theory by the way and then I do it I basically say hey person you know famous researcher I'm an undergraduate please read my paper and so I didn't feel very good about this but Eric actually responded which is I think a statement to sort of the care that he provides to people the one thing I'll call out about his response is that he apologizes for being delayed it was one day later so Eric I think you just work on a different time scale than everyone else that's truly incredible so thank you for keeping us all engaged and getting us started even before we even knew we were getting started in this area and I will stop there it really has been a fun time thanks to Eric to sue to Mary to DES knee to Jaime and everyone who has really guided my path here [Applause] 