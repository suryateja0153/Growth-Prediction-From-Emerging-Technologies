 hmm so let me just switch to my slides so the this summer project connecting virginia learning communities funded by icat was centered around developing new modalities for distance collaboration so our team during summer included drink faculty uh uh with me there was jim and deborah and also two students abdel aziz and mark reza joined after summer so technically he's not in the team but he certainly contributed a lot uh also so what was our goal well we tried to look at what what are some other ways how we can communicate and connect learning communities because traditional methods such as zoom and mozilla mozilla hub is probably not so traditional yet are lacking the proper sense of context and connection with the physical environment i think really that's that will be kind of my my main comment or or critique if you wish of all those online terms that there is the disconnect between what you're seeing on the screen and we were replaced in space and i think that's especially important for teachers and educators because we just talked to some educators in some parts of virginia and they have up to 30 percent of students who actually never logged in online so i think those online tools are really not quite there yet and and that's where there is a lot of place for improvement and for the research one technology that is particular interest of interest is extended reality uh and it has been already using education in training to enhance engagement uh also ignore increased knowledge retention so some some indication of validity of that approach is already in literature and that was an encouragement to actually to take this approach and use the technology speaking about the extended reality this is an umbrella term that talks about all possible versions of immersive technologies including augmented reality virtual reality and mixed reality and of course with the mission and everything there is also augmented reality and so on and the reason why why that's important because those extended reality devices use a spatial mapping to place virtual objects into surrounding smart space so therefore we have that connection between the virtual space and physical space so to speak given now the question is how we can use them for embodied interaction where users can communicate not just with voice but also by that sense of shared virtual space which is also provide sense of shared or although distributed physical space for that to work we also need to have some other technology in addition to extended reality we need to have artificial intelligence to uh especially in education we are going to have some kind of uh intelligent agents for tutoring and also of course internet of things to provide that smart physical space where we can where we can then gather data not just tracking the user but tracking environmental data and some other information and use that as a way to to facilitate better connection of the distributed physical spaces in a single virtual space a little bit more about how extended reality is used in let's say in k-12 uh student engagement already mentioned was 30 percent no show for online classes in k-12 at least in some part of virginia uh how we can use uh those new capabilities to provide situations for students not just explore create problems or ex you know find problems find solutions and also to connect that learning to real world there are a lot of problems with experiential learning for example training for nursing students for vocational where online doesn't simply does not does not provide sufficient capabilities to properly learn um what needs to be learned for those skills in higher education if you look at against literature there is empirical evidence of the efficacy of extended reality and not only that you can also use that to foster student interest and extend the reality make them not just user of extended reality so to speak but also extend the reality developer and and content creators so if you kind of look at the challenges uh when we will use our computer keyboard and screen this is one of my favorite figures uh uh and i give to have to give credit for to mohammed mendoza one of my phd students who um who brought this this figure to my attention and that's the way how computer sees us is that finger coming down on the keyboard uh eyes looking at the screen and here's listening to the sound and that's uh that's what you have with zoom and other online communications some of the uh shared virtual worlds such as mozilla hub or for those of us who are a little bit uh say less young less younger so to speak uh we still remember second life and the initial excitement when it started so you can also create those spiritual communities but i think again the important thing is that that you are not uh using your sense of embodiment you are again using your finger to or to or for mouse or navigating that environment so therefore there is a gap between all the interaction and new interaction it's one example that i always like to show is this example of light switches in my house actually uh ten years and the cows still don't know all the switches what they've been for why because there is a disconnect between what the light switch does and what that light switch and the light that light switch turns on and off so one way to look at that is to simply forget about switches specifically forget about any input device and use human body as a way to control switches so here is an example of of uh using hands to control lights that was from the future house project this is uh muhammad i mentioned before and the idea is can we simply provide some alternative interaction again embodiment and now what we have we have the disappearing user interface the space around our glasses display our body is is an input device or one can argue a collection of input devices so now that's in single place situation how we can then a distribute and b how we can enhance it to truly be an immersive virtual environment with let's call it the higher resolution graphic list we all seen kingsman movie and that scene where you have that meeting so if we have this technology today we were all sitting around the table see each other as we are in the same same room and sitting on the same table so that'll be kind of the ideal and what i found always that looking at movies especially some science fiction movie can can really be inspirational because you have not only idea but at least some kind of uh these are the horse implementation if you wish and and that can then lead you to our better uh better design so as i said first of all how to do it distributed how then connected and then how to increase embellishments so here is another another example that we can use existing technology such as kinect to uh to simply track users and relatively with rightly minimum delay um provide uh provide the virtual present in decent places so we did experiment uh uh between vmi virginia military lexington and virginia tech in blacksburg and it actually was fairly fairly uh real time i think delay was maybe around 200 250 milliseconds a little bit over 150 milliseconds magic and a number for proper human in the loop interaction but people were able to visually take shape hands between blacksburg and lexicon also to provide kind of the spectral capability that we have we are we are between real environment and visual environment and everything for the whole spectrum so that's actually where extended reality fits into that real reality virtuality continues so in order to be in that spectrum we need to transform physical world by using spatial computing tracking user body and then using that to project uh or generate the computer of a computer generated object into physical space an example that we have here is a nurse aid experiential select skill inspirational learning uh that we develop for previous nurse skill training and what it does it starts in a regular classroom then transform it into hospital room using mixed reality it has a very well defined set of skills so therefore a student can can follow those skills put the gloves on um and although of course it cannot really replace the physical tangible uh uh training it does help student uh remember the sequence of stack there is a you know well-guided uh sequence of steps instruction for that and again interaction devices human body hand and what is the display displays his physical space augmented by computer generated objects another version of that is to use that for exhibition so certain departments or let's say certain programs are really big on bringing smith's together and have them presented for example architecture interior design so what we have is simple example how we can use that to create a virtual poster session where you can have a student uh present content and have posters on the wall explore what it what it does perhaps uh select different uh different poster grab 3d objects explore what is the architectural concept that is there so again it is it helps students better explore what has been designed uh it helps user uh uh retain knowledge or learn easier so in this case you can print the object so now you can explore it something that you not you cannot have in that 2d session so uh and then you can move forward and put multiple posters uh that now you can actually see uh in whole space you can go around and place those poster automatically and walk around in your physical space other students walk in their physical space yet they share the same exhibition so finally let's get to what we have done this summer so we use uh well i mean we use all that experience to put it in in a situation where we now create a virtual classroom where we can create that common virtual space for all those physical spaces that we have seen so far so this is a short video and then after that towards the end we are going to have uh an example sorry so what we're looking right now looking at you know basic classroom scene if you move a little bit forward we can actually have very large classrooms so therefore that's that scalability or adaptability if you wish you can have some smaller situation more meeting like setup and then the next thing that what we can do we can actually use tracking so you can see in the lower right corner actual camera view of the user and the corresponding avatar representation so now with that we are and of course we can combine several users together um if need be so so with that uh i would like uh uh reza and mark to to share the screens and show give us a brief demo so let me stop sharing on my part all right so i'm going to go ahead and share on this screen can you all uh can you all see the screen yes okay and i'll just go ahead and start this and it should be good and while he's doing that explanation is there there are two computers two students and they are both being tracked one is mark although it says res this is mark and rezay on the other uh in front of the other computer so now in the in the real time you can actually track both students they interact with objects in the classroom and again we actually have a setup that works for reasonably well we also have a web-based version we just need to also integrate properly integrate connect or some other tracking devices so therefore it can scale up and now we can in that in incorporate some props for particular content mostly for experiential learning students can walk in the classroom exhibit that in in other words they have the common reference the common visual space that they can refer to in their communication so with that let me go back to my slide thank you mark and thank you reza so in conclusion again although this technology is fairly uh you know involved uh there are already a lot of effort how to move it to mobile devices from well-known pokemon go to some of the newer tablets and applications that leverage extended reality not only that even relatively affordable uh uh devices such as nintendo switch do provide extended reality with the car so you can create a race track uh in your own living room uh thanks reza for pointing that to me so with that uh uh at the end what are some of the remaining challenges actually a lot of challenges not just remaining challenges how to test and deploy that system given the score closures we are working with ronald kyle education center with virginia military institute deploying on low-band platforms again we are developing web-based version how to facilitate engagement i have actually this teacher from southwest virginia coming on saturday to discuss that and finally how we can integrate existing application and with that i'm this is the end of my presentation thank you very much for your attention and i'm ready for questions great thank you dennis um maybe you can unshare your screen and we'll be able to see you better um great thank you um so thanks so much for that presentation what a great set of um of technology and and being able to do all these things that we've not been able to do before um so i'm going to start with that um with an easy one i think um so when you went into the classroom uh when we saw the the real-time classroom where where raza and mark were you flip the table does it have to be fixed after that what happens next well um so so hopefully uh no let me put it this way uh the problem you are not the problem the i i know it's kind of easy question but it actually has some some deeper bitter meaning the problem is that you have very different heterogeneous physical spaces and therefore you want to have that visual space to become a reference point what you can do and especially in smaller setup you can have you can try to have tangible props in your physical place for example this meeting is stable maybe not the same size not the same shape and then uh having the situation that you can flip the table in physical space that's actually an idea that we are working on like moving furniture like reconfigurable spaces but we are not quite there yet because there are also some legal issues to be addressed first in terms of responsibilities but it is it is great question and we are working with that cool thank you um another question is uh what kind of hardware and network requirements would you would be necessary to make this kind of widely available for everyday use okay as far as hardware we what you need you need a good camera and it's and corresponding processing power so what we are using right now is connect azure which is approximately 400 however it does require fairly good graphics cards nvidia 970 well 960 probably if you are and however for the network capabilities because what we are using we are connecting with the internet of things by using uh uh law of overhead protocols such as mqtt and amount information if you share the same kind of assets etc the amount information that you send back and forth is actually comparatively small so even a lower bandwidth uh can work well the real challenge is not so much about the bank and the challenges about latency and that's really where where the problem will be you can have i don't know 10 uh huge bandwidth download for 10 megabit bytes per second but if latency if that go to satellite your latency is one second it just won't be right okay um so in related to that you know as we think about how this can be used in schools um uh ben's asking are there are there studies that show any differences in learning or in connection connectivity to when students are or learners are using embodied immersive environments versus like a two-dimensional connection like a zoom and is that something you're you're studying well there's certainly something i'm studying and uh you know user studies we know how that works these days however in literature you can find empirical evidence for that so i'll be happy you know to provide the links to those papers so as both for the k-12 and for higher education what we did before we actually had uh had student tested nurse aid in school and if nothing else i think they all found again this is just empirical evidence it is not strict scientific study from from the server they provided they all preferred that not only because of the novelty factor because they were doing like for four or five weeks an hour departure was was gone it was really indication that that's better way to do it just because it gives you more flexibility you don't have to have a lot be in love and do it great so the affordances actually allow you to do things that you couldn't do with zoom so you can be in your living room recreate your nursing uh lab or hospital bed or things like that you can just see yeah it is fascinating and a bit mind-blowing to think about all the different ways we can use space at this point exactly and that's i think that's we have a lot of opportunities there to explore and you know it's really how to come up with crazy idea and you can do it so that's why i'm watching all science fiction movies to come up with for the rock uh still those great ideas sure um we have a question from brandon um you know at a kind of cautionary or questioning tale uh you know uh technology can companies excuse me technology companies continue to exploit users data to make money from them um what can we do or what can you do in the design of this to make sure that users body data is not going to be exploited for profit okay so first the comment about that uh oculus quest is actually a really great standalone virtual reality device however oculus too now in order to use it you have to log into your facebook account period so you have that limitation imposed by hardware manufacturer because of facebook bought oculus quest the only way for you to use software's quest 2 is to log into facebook account and i i don't know i hope you know my my choice of words i find it creepy let's put it this way however in terms of providing security uh the advantage of using iot life without protocol because that also provides security features that are embedded and because they are relatively simple you can really verify that work so you can either have password authentication you can even have certificates so therefore you can protect you can have encrypted data our network without really sacrificing performance in terms of latency what kinds of ways are you so you talked about you know kind of putting this in k-12 schools and and working with learners what are the next steps is this going to to is it and is it in schools now who are is anyone trying to use it in this kind of coveted space where everything's weird no so as i said right now what we are doing we are putting in the roanoke higher education center we actually have collaboration with the company commonwealth learning systems and so we will put it there also we have collaboration with abingdon virginia and we are going to put to try to put that there and finally we have a collaboration with virginia military institute and they have this reason to receive a grant so they are in process of buying the people so hopefully by thanksgiving well i don't know it's hard to think but let's say hopefully sometimes this year or this semester we'll have four nodes blacksburg uh lexington roanoke and abingdon okay great i look forward to hearing how that goes yeah i don't need to have to be honest yeah um so how can this is a mess a question from chris williams um how can xr be used in a hybrid classroom that has participants who are both virtual both in the virtual and physical space and could you use like a hololens like tech um to provide users a way to see the whole classroom at once oops okay so um go back to your science fiction okay no no no no no i don't think against valid uh questions and it comes to this situation how distributed is physical space so we have collocated user in the same space if if they are using mixed reality headset they are going to see the same thing uh that that the demodule saw in that case so it's that particular scenario that you have a classroom what you're going to do you're going to model your your virtual world to mimic a physical classroom so therefore in that case there is one-to-one mapping between a physical space of students in the classroom in visual space and therefore using mixed reality device that can easily do the things so what you can do even with some some better camera if they move objects in physical space they are going to move in virtual space we already said that vice versa does not work yet right so yeah we can do certainly do that great well i'm looking forward to my first class in that situation with um that sounds exciting um with that we are at time so i just want to thank you so much for sharing the technology and the the projects with us this morning and and answering questions and we're just so glad that you and your team are part of icat thank you and again thank you for opportunity and i could support for this project great bye you 