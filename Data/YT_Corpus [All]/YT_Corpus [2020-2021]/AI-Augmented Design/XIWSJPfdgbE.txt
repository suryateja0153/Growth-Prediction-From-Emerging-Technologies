 I was on holiday with my husband discussing an idea for a novel but I was writing and he suggested that it should be about a world where by killer robots were real but they only didn't kill black people like because they wouldn't recognize black people as being human and I thought it'd be ridiculous right now humans are the only in telophase of a plant and that means that we have to do a lot of work because essentially all intelligent actions require a human to be involved with it but we want to do have free time we want to be able to get intelligence on time the one way I in our society is to do the things that we don't want to do to do the things that we find difficult or tedious all the things that are dangerous I want to see robots built that can drive cars more safely than people can and that's imminent that's something which is going to happen at some point in the next couple of decades machines that can diagnose heart conditions or tumors with greater reliability than human experts can and when that technology finally fully works it will save a million lives the year I mean that's for me that's the excitement of of what a I can do we need to be careful not to try to delegate too much humanity to machines I think the empathy and the kindness really should lie with the people that's what people are for it's us that should be empathetic and kind it was CAI as an enormous gigantic growing powerful reservoir of agency the ability to solve problems without an intelligence but under the guidance of individuals who have a clear sense of what needs to be solved how why at what time for whom well then the role of these huge muscles in our society could be extremely positive or negative it will be up to us to direct this enormous amount of shall we say energy to solve the right problems me what motivates and excitement is going back to how does the technology that we create change how we think and how we perceive where design and art is important in the context of science and technology is really you know understanding how do you create that dialogue where technology's enhancing our perception our cognition - to be able to see more understand more and discover more rather than allowing it to copy the world which it really wants to do actually the default AI parameters means it just wants to reflect what is there and like that for me isn't necessarily good enough because you're still picking up the biases that exist in society the critical aspect is really that we have to see this technology in conjunction to our own critical thinking my feeling though is that AI can be used to augment not replace human judgment it can be another voice in the room but I would be nervous about it being more than another voice in the room the truth of the world is aggregation of palaces fundamentally and any anthropology sociology is worth their salt knows that in many ways you are describing the unique proclivities and inclinations of any culture when you're doing any research fundamentally we are building our models to recognize this because there is no unbiased model in the world but there is a recognition of what stories of the culture were feeding into a model and this is the problem when you want to teach in machines because if we just give them explicit rules they are going to miss out on a lot of common sense and it's important because common sense is what tells us that if I'm designing a car it should be possible to leave in the car that's not something anybody explicitly have to tell a car designer but if you have a machine design of a car that would be very useful but we have this idea that often if a machine does it there is some kind of rational reason and that always is better than anything else the thing about machine learning which is one of the cornerstones or carat artificial intelligence is that it's all based on taking data of past experiences and when you train the machine to do the right thing based on this data we have reality and we have aspiration we can only teach it on reality we cannot teach it on what doesn't exist what we can do is we can watch it fail constantly and then use that failure as a point of optimization human bias is quite of an infiltrator data if you take language data from society just what people post on the internet and was written in newspaper that contains sub-2 biases about genders because men and women are mentioned in different contexts which reflect differences in society and how we are culturally if you feed that into an AI system it's going to learn the pattern it doesn't truly understand it but it just repeats it so the problem might be that this software you're acting out of pure statistics now embodies various gender biases in our case when we are accessing the credit risk of the company one data that we had was the gender of the directors present we could say okay I have this data should I take it into account in my model so at first we tested and we found that it was actually not related it was not statistically irrelevant now you have more and more people use the AI models in a few weeks you can go online and start to be junior data scientist and if you are not critical about your mother's or if your data's are bad you might end up with a model who would actually give weight to the gender everything will be the development of AI I think people need to think about think a lot about it you need a fix and you need the regulatory bodies otherwise is gonna be the wide West we've done this before we've been here before technologies they often have an initial moment of trial and error see what happens can we do this can we do that and then slowly I hope this time not too slowly we come and as a society that we are with the people and we regulate to make sure that things properly done and all the major risks are either avoided mitigated or they don't arise in the first place I think the important thing is for the relevance for the relevant professional organizations and groups that set Professional Standards to look at how AI is and might be used within their professions and to make a judgement on what's acceptable and what isn't acceptable in the area of healthcare there are signs that that this is happening already if it wasn't one interesting example where a system was trying to diagnose whether people with pneumonia could stay at home or neither to be brought to the hospital and it was misdiagnosed in people with asthma pneumonia as being totally safe and they could stay at home the reason was of course but the survival rate of having asked pneumonia in its training data was really high because all doctors know that asthma pneumonia is bad news you must go to the hospital and you get a lot of treatment and since we always went to the hospital and got a good treatment they survived really well now in this case since we viewed what was going on inside the system they could say okay that's really bad we need to fix this [Music] with respect to issues like Pollux predictive policing and there is a danger that the technology runs ahead of the regulators and starts to be used before people have really thought deeply about how it might be used responsibly and safely we decided to do a project on the use of live facial recognition because the Metropolitan Police were trialing it in London facial recognition is decision support mechanism it's to help decision making on the ground which means that if the Machine tells you this person looks like a person on the database the officer still has the responsibility to ask themselves is this person the person that I'm looking for or the other the main area in which the police have been you know developing their use of artificial intelligence or algorithms is in the area of predictive policing Kent Police Service was trying something called pride poll which is a program developed in the States they used it for a few years and then decided not to continue with its use and the reasons for that were that they found broadly speaking that their human analysts were just as good at predicting the likely crime hotspots but also that their police officers didn't necessarily follow the lead of their of the findings of predictive policing now the difficulty is if you have officers who are biased towards action they may well just do what the Machine tells them equally if they are using their discretion there's further scope for bias because it may be that they do what the Machine tells them in some circumstances and not others and then there's a question about well in what circumstances do they follow the machines instructions is it when they see a young black man walking down the street but they're more likely then to not question and I don't education one of the experiments which has or trials which has been done in the UK was by the Durham Constabulary who were using a predictive album algorithm to risk assess people who were in custody those algorithms need to be transparent we need to be able to see where an algorithm has come from what's in it what the data points are it needs to be intelligible to us we need to understand it not just see it we need to understand it there needs to be accountability there needs to be a form of audit so that we know when algorithms are being used and what their impact is many decisions we make we say that's a gut feeling my intuition tells me this and we kind of proud of that and when we say it's a very bad thing that machines are black boxes and cannot tell us where recent but we say that bank executive who did the right thing because he felt that in his gut that that was the right thing oh he's very experienced because in humans of course that experience turns into this knowledge about the world which is implicit and hidden and as inaccessible as the neural networks of a machines it's just that we tend to trust you must a little bit more partially because we can hold them responsible the black box well if it acts badly doesn't know that and doesn't care the bank executive is at least going to be a bit embarrassed if you loses a few billions using predictive methods to assess people's likelihood of future behavior it does raise ethical questions which i think are quite serious about how far you're justified in treating people in the present on the basis of hope what they might do in future they're not remotely at a stage yet where we know how to be able to reliably build systems that are going to make such sensitive decisions algorithms have the scope to be unfair in many many areas you know if you're choosing employment your employees through algorithm that can be incredibly unfair the big difference in policing is the kind of powers that the police have means you have to be really really careful to get it right Society has been institutionally racist basically for as long as we can go back and if we were to wait in each space for society to correct itself before we corrected different kind of professional or cultural areas then nothing would ever happen [Music] technology issues of control surveillance to sell us things and eventually it would be used to automate jobs as well and this change is happening really quickly [Music] the fascinating thing is of course but even defining a bias is tricky for a long time people didn't think that the successor was a thing it was just the way the world worked people complaining about different treatment of men and women were regarded as slightly odd gradually people realized they actually had good argument and gradually it was seen as a big problem the really optimistic possibility might be that we can use machine learning to detect boxes that's kind of how I treat working with an AI so as opposed to kind of thinking of it somewhat my embeds and copies the world and reproduces the categories that are already there what I try to do is think of the AI as kind of a defecting element so you put your data set in I'm rather than trying to just get it to copy for data set in one way every other and therefore the categories and the biases that are already in the data set you kind of create new forms formulas how lots of public spaces or designs will be using kind of AI systems right now inevitably the people who are making that kind of work are white men I talk about efficiencies we talk about economic vs. and abilities but we should also remember that people come into a burn environment with a notion that they really believe in combined human effort do you believe in this momentum that comes from the concentration of a population and yet all these cities become more and more segmented create more and more elation so why not explore dynamic systems physically that would allow for more interaction that allow for the sense of presence and belonging if we think about life crime you'll hear police officers in London say we can't police our way out of life crime that we need to use different approaches that we need to use a public health approach so rather than arrest young people who are carrying knives we ought to create an environment in which they don't feel they need to the smart Satan also needs to be possible to change every program by the people it's a bit like an open society open societies allow anybody to point out that something is wrong and with enough other people think that yes this is indeed a problem then you can fix it they can always be changed the fact that the data is brought in from a very narrow group of people there is a cultural that rock to meaning and you have to build those any-to-any systems that you desire if you wanted to build a model to recognize drive for example and you did it without taking the people into account you would probably get a bunch of tracksuits and strong civilians but if you get the data from the culture itself not from me or you and see what sort of imagery locals associate with drive what sort of clothing the locals themselves associate with crime what kind of my know cuz I mean the practitioners in that in that subculture and use that as a training set so it's really a ground-up training set of information then fundamentally you've created a dry model that is designed by the people for the people and other people biased maybe they are but you cannot replace people I'm using mistake fake technology that's been talked about quite laughed unusually deep fakes are used either for like comedy memes or a lot for sort of shaming women so I was taking this technology and trying to think about like how you could use it to the imagined narratives and reimagine histories I'm proposing how it could create these new forms from it we want to build out a system that fundamentally allows you to open a computer type in anything a question and about humanity a question about history a question about psychoanalysis and using the tremendous machine learning models that are existing all coming into existence be able to be served up an empathetic insightful answer but you can actually use presently information has been indexed that people and culture has not been indexed and only a machine can do that or you can have the access to not only books but also the insights from books are we understanding from books and reports and journals and movies and videos and people at your fingertips [Music] the press has essentially two responsibilities here satisfaction and simplification it tends to simplify too much in a pattern izing way the number of times I've been told that the message has to be simpler because they will not get it are you sure I'm not quite sure people are expecting difficult things because are difficult times and the other thing is an excessive amount of I call it satisfaction targeting of every single need giving people what they expect what they want in a way it's almost like semantics pornography you really tickle and satisfy the the worst essentially interest that we all have the gossip the the extraordinary claim when in fact the real business happens with the boring the difficult the the hard stuff they are sort of amplifying the distance it's really I think it's in their hands to educate and there have been so many movements of education amongst the cultural and journalists glass whether it is LGBTQ rights women's rights animal activism environmentalism etc we have as a species society being able to teach complex ideas to people who don't know them as we move forward and and machines nei we've done the opposite where we have scared people that they're going to be locked up for big black which is really a very very frightening scenario 99% of the world is running and actually progressing and thing quite powerful because of us and those stories don't come up so I think the fault lies in us more than anything else because it's easier to do that it's much more boring to say that essentially it's an optimization system that's making things more smoke another thing I think is important is kind of dismantling some of the myths around artificial intelligence in the sense that like the big tech companies call it artificial intelligence and that sort of has a certain connotations around it I'm used to thinking of it in terms of statistics and correlations and if you called this whole area creative statistics over whatever people wouldn't think get so sort of worked up about deferring all the sort of responsibility to the AI [Music] every society has an implicit maybe silent maybe not immediately visible but very present human project in mind it develops along lines of deaths where I would like to be if I could now this human project is something that can either be simply inherited from the past passively absorbed like a legacy or it can be a more conscious more explicit effort thinking in terms of but what society do we want to live in what kind of ideal world we would like to step towards now when I normally ask this question to politicians I ask them in a difficult way say imagine you don't have any crisis you don't have any problem inflation is okay employment is okay there is no or there is no terror imagine for a moment that everything is doing okay what's your project and they have no words it's not a one-stage thing where this is going to be created we're all gonna get around the table and it's gonna be created and we're all gonna decide together how it's gonna be the social engineer worker with the scientist the AI scientist with a designer with the artist it's about within how the models and the systems which we implement and the process we create opportunities at every stage for this to be opened up criticized understood and seen as a tool rather than as an autonomous construct and understood from all these different perspectives as is this tool working in the way to enhance our capability to me that the 21st century should have as a human project globally speaking the special marriage between the green and the blue the the green of our world of our environment but also of our economy sharing circular economy and the blue of the technologies AI internal things the digital technology we have everywhere if we were to get that marriage right then there would be something we could really be proud of future generation could look back and say they had a project it was a good project and thank you for realizing that project we owe you [Music] [Music] [Music] [Music] you [Music] 