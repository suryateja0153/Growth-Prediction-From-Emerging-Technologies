 hey guys and welcome back throughout this video we'll cover the intuition behind some of the main techniques used in object detection as well as segmentation we'll also cover how the implementation has evolved over time in particular we'll cover Regional CNN or R-CNN along with its descendants Fast R-CNN and Faster R-CNN finally we will cover the main model called Mask R-CNN which extends such object detection techniques to provide pixel level segmentation let's discuss first how it all started you can join me on discord Instagram and Facebook check out all my advanced courses on udemy teachable and patreon and please don't forget to Like subscribe and share and click this bell icon to stay on top of AI and AR to enroll in the full mask R-NN course when it launches and check out the links down below this video was made in partnership with Geeky Bee AI a company that is transforming the world through AI technology Geeky Bee has expertise in computer vision machine learning deep learning and data science check the links below to learn more 2014 R-CNN an early application of CNN to object detection before we get into the history let's quickly define object detection which is the task of finding the different objects in an image and classifying them Ross Girshick et al found that a CNN can lead to dramatically higher object detection performanceon PASCAL VOC as compared to systems based on simpler HOG-like features understanding R-CNN so the goal of Arsenal is taking an image and correctly identify where the main objects via a bounding box are in the image so the inputs are the image and the outputs are the bounding boxes plus labels for each object in the image but how do we find out where these bounding boxes are? well well R-CNN does what we might intuitively do as well propose a bunch of boxes in the image and see if any of them actually correspond to an image R-CNN creates these bounding boxes or region proposals using a process called selective search at a high-level selected search looks at the image through windows of different sizes and for each image tries to cluster together adjacent pixels by texture color or intensity to identify objects once the proposals are created R-CNN wraps the region to a standard square size and passes it through to a modified version of LX net which at the time was the winning submission to image net 2012 that inspired our scene in on the final layer step four of the CNN R-CNN as a support vector machine or SVM that simply classifies whether this is an object and if so what object check out my lecture on support vector machines in the link attached to this video to learn more how to improve the bounding boxes? now having found the object in the box we can tighten the box to fit the true dimensions of the object R-CNN runs a simple linear regression on the region proposals to generate a tighter bounding box coordinates to get our final result so to summarize R-CNN is just the following steps generate a set of proposals for bounding boxes run the images in the bounding boxes through a pre trained alexnet and finally an SVM to see what object the image in the box is and three run the box through a linear regression model to upper to set the coordinates for the box once the object has been classified simple right 2015 Fast R-CNN speeding up and simplifying R-CNN, R-CNN works really well but it's really quite slow for a few simple reasons it requires a four pass of alexnet for every single region proposal and for every single image which could reach up to 2000 forward passes per image which is really crazy and two it has to Train three different models separately the CNN to generate the image features the classifier that predicts the class and the regression model to tighten the bounding boxes this makes the pipeline extremely hard to train in 2015 Ross Girshick the first author of the R-CNN solve both of these problems leading to the second algorithm called Fast R-CNN let's take a look at its main features Fast R-CNN and solution 1 region of interest GUI for the forward pass of the CNN Girshick realize for each image a lot of proposals for the image invariably overlapped causing us to run the same CNN competition again and again around 2000 times again his solution was simple why not run the CNN just once per image and then find a way to share the competition across the proximate 2000 proposals this is exactly what Fast R-CNN does using a technique called ROI pool or region of interest pooling at its core roi pool shares the fourth paths of the CNN for an image across its sub regions so all it takes us is one pass of the original image as opposed to approximately 2000 Fast R-CNN solution 2 combine all models into one network the second inside of Fasr R-CNN is to jointly train the CNN classify and bounding box regressor in a single model where earlier we had different models to extract image features the CNN classifier with the support vector machine and titan bounding boxes with the regressor Fast R-CNN instead uses a single network to compute all three in one go 2016 Faster R-CNN speeding up region proposal even with these advancements there was still one remaining bottleneck in the fast Arsenal process the region proposal as we saw in the very first step to detecting these locations of the objects is generating a bunch of potential bounding boxes or regions of interest to test in Fast R-CNN these proposals were created using the selected search a fairly slow process it was found to be the bottleneck of the overall process the inside of faster Arsenal was that the region proposals depended on the features of the image that were already calculated but a fourth pass of the CNN first step of classification the solution was to reuse those same CNN results for region proposals instead of running a separate selective search algorithm over here you can see how a single CNN is used to both carry out the region proposals and classification this way only one CNN needs to be trained and we get region proposals almost for free all termed cost-free region proposals how regions are generated let's take a moment to see how faster arson and generates these region proposals from the CNN features Faster R-CNN as a fully convolutional network on top of the features of the CNN grating was known as region proposal network the region proposal network proposed by passing a sliding window over the CNN feature map and as each window outputting K potential bounding boxes and scores for how good each of these boxes is expected to be for each such anchor box we output one bounding box and score per position in the image we then pass each such bounding box that is likely to be an object in too fast  R-CNN to generate a classification and tighten the bounding boxes and now finally 2017 Mask R-CNN extending faster R-CNN 4 pixel level segmentation so far we've seen how we've been able to use CNN features in many interesting ways to effectively locate different objects in an image with bounding boxes we can extend such techniques to go one step further and locate pixels of the image instead of just bounding boxes this problem known as image segmentation is what gaming a at all explored at Facebook AI using an architecture known as Mask R-CNN in Mask R-CNN a fully convolutional network or a sin is added to the top of the CNN features of a faster R-CNN to generate a mask segmentation output notice how this is in parallel to the classification and bounding box regressor network of the faster R-CNN model Mask R-CNN does is by adding a branch to faster R-CNN that outputs a binary mask this is whether or not a given pixel is part of an object this branch is just a fully convolutional network on top of a CNN based feature map with the following outputs but the inputs which are CNN feature map and the outputs is a matrix of ones on all the locations where the pixel belongs to the objects and 0 elsewhere this is also known as a binary mask however the Mask R-CNN authors had to make one small adjustment to make the pipeline work as expected ROI Align, realigning ropu to be more accurate when run without modifications on the original faster R-CNN architecture the most R-CNN authors realized that the regions of the feature map selected by roi pool was slightly misaligned from the regions of the original image since the image segmentation required pixel level specificity unlike bounding boxes this naturally led to inaccuracies the authors were able to solve this by cleverly adjusting the ROI pool to be more precisely aligned using a method known as roi aligned once these masks are generated Mask R-CNN combines him with such classifications and bounding boxes from faster R-CNN to generate wonderfully precise segmentations okay so now you know about Mask R-CNN and where it came from if you would like to learn more on how to implement Mask R-CNN from scratch in Python and using Windows 10 then check out my course on udemy where we'll show you everything you need to know from execution to training to re-deployment I'll also give an example of how to create your own Road pothole detector and how to quantify it based on the pixels within each segmentation so looking forward to see you there this video was developed with Dhruv Parthasarathy wrote an article on a brief history of CNN in image segmentation from R-CNN to Mask R-CNN you can check out the link to his page and blog and the link attached to this video thank you for watching and we'll see you in next lecture you 