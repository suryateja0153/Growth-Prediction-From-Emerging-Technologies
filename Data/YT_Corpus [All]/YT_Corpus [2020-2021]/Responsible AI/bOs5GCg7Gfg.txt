 thanks for coming like usual I have lots of slides so I'll just get started I want to make a point I actually this is a totally different talk for me you might recognize one or two slides but I really feel that a huge transition has happened there's a lot of people complaining now about people who like crank out new new ethical frameworks and this and that we we did stuff we've actually done stuff look 42 world governments have endorsed a set of principles I'm going to fit on this slide this is great right and it's the OECD the OECD is a think-tank of you know rich basically companies companies countries right that it came up with the data ethics that we use which was actually pretty good for the last like 40 years so now they've done the same kind of thing with AI they've gotten on top of it they've got people to sign up to it and there's five principles all right the first one is the AIA should benefit people and the planet right thinking about sustainability as you've seen all over here I know the COG accent abbath are very into the sustainable goals AI system should be designed in a way that respects the rule of law human rights democratic values and diversity look and with appropriate safeguards right to ensure a fair and justice Society sorry just society the point here is we already have law right we've already figured out pretty well how to deal with each other we all focus on the mistakes but by and large we've got 8 billion people sitting on one planet it's impressive AI is something we design and so we can make sure that we fit it into the existing practices right we are engineering AI all right third there should be transparency and responsible disclosure all right that doesn't have to mean open source it can mean that when something goes wrong then maybe you let government regulators come and look and see if they can understand what went wrong and you provide them the documentation right but there's transparency responsible disclosure disclosure around the I systems to ensure that people understand when they and now this is confusing this this is the people that are understanding when they engage with the AI systems sorry that oh you see D is a lot of French people so I think there was a little but bye-bye it's an important idea and I systems must function in a robust secure and safe way throughout their lifetimes all right and potential risks should be continually assess and manage that means you don't just release it especially in the age of cybersecurity the Internet of Things we have to make sure that everything that we put out that we maintain it it has to do upgrades or it has to cut out right or it shouldn't be on the Internet right and then finally organizations and individuals developing deploying or operating AI systems should be held accountable for their proper functioning so a lot of this has been about what the responsibilities are of us as developers right as organizations but once you've sold it and if you've sold it in good in good condition then it becomes the the province of the owner/operator and again the people who develop it need to make sure that they can help us hold accountable anyone who's misusing their software but we hold accountable the users if the users of the problem are the hackers with the hackers of the problem right okay so this is the OECD principles but going back to this what we do matters sometimes people say what can we do right these are the UK principles of robotics right and they're incredibly similar the only thing here is that the third one and the fourth one are flipped right but the first three we're actually as much law is fixed right it's not there it's not the robot that is saving the humans life it's us they need to make sure that we save our own lives all right and then the last two are as I said the owner/operator responsibility okay but I'm not saying that nothing changed in the intervening six years and we should for those of us who are British and despite my accent we should be proud of the fact that we were the first country that had AI ethics off law right we that was the first national level South law but all the stuff in orange is improvements it's on what was in that original system right so massive work has been done in the last five years it does matter that all these other people have been chipping in bringing their own stuff to this stage and yeah this is just two of the things the I Triple E initiative huge and it you know obviously this thing is like 300 pages line it's all the different kinds of things that you might want to think about if you're thinking about you know having emotional AI or you're thinking about law it's a set of challenges so it's still worth going and looking at that if you need to look at it and similarly the the EU I think they were a little cheesed off because their release is like two weeks before the OECD release and they got trumped but but what they are doing is setting the law for the main body the main transnational international body that is actually helping us control what's happening at the transnational stage right there it's a it's a collection a large collection of really affluent individuals and when they do something like the GDP are it matters so all these things matter and they all have been feeding into getting to the place we are now but where are we now I feel like we're it's a situation where we can stop building new new new principle systems and really start moving forwards okay so I think we should consolidate some of the conclusions that have come out of those kinds of principles I think we should be building infrastructure up so we can enforce those ideas and I think this is not really the thing we need to stop anthropomorphizing AI all right and and I'm concerned about this not just because you know the people on the street still think robots need help or something but more because a lot of the initiatives that were predating these more recent statements are using words that bothered me for example hello responsible ai ai is not responsible hey its makers owners and operators are as AI isn't its self accountable right and it's not going to explain itself we have to explain what we're doing with those AI systems that's what these rules are saying value alignment there's a big discussion mostly in well the in in the continental Europe about making sure that the machines are value aligned that doesn't mean that we have a robot that wants the same things that people want it means that we are the operators and the machine should Express the operators intentions possibly with limits put on by the people who constructed it because they're worried about liability right but it's not about the machine itself AI should be made transparent or explainable so it's makers can demonstrate due diligence and where necessary be held to account right it's the makers they're held to account hey I should promote accountability right so when diligent makers can improve it when stakes are made oh I see that oh yeah that somebody has switched my keynote into PowerPoint sorry that was a beautiful build before oh and finally a I should promote accountability right they so that yeah sorry about that that was something terrible with PowerPoint just happened sorry annoyed all right so humans are of necessity responsible okay and just wondering what other builds are not going to work now oh well why injustice are more about dissuasion than recompense right it's not that you that you people think sometimes that if they have law then that means that somebody did something wrong to them they can get something back but you know if you have someone you love that was killed nothing will bring that person back right law it's about making sure that other people don't do that and so it's not about revenge it's about the future it's about persuasion all right software systems don't do that okay so safe secure accountable software systems are modular suffering from isolation or loss and such as incoherent no penalty of law against any artifacts including a shell company could have efficacy humans are the accountable moral agents right we had a book paper so no but come on about this in 2017 this far and then final thing I'll say about this is if corporations are held to account then they're going to want to create appropriate levels of transparency because they have to prove they did the due diligence all right so where are we yeah I am the one thing I haven't talked about and I'm gonna keep that where's my time keeper that somebody somebody was going to keep time for me oh well oh there yeah so am i halfway through now yeah I'm about halfway through ok good ok so the second half of this now I'm going to change change streams and talk a little bit more about building infrastructure and here's another really beautiful transition that presumably is not going to work because it's been switched into PowerPoint but robots are proactively determine their own routes yeah this is oh yeah sorry about this well yeah okay but uh alright so a lot of stuff is last year sorry anyway but the point of this is supposed to be that that when people talk about autonomous systems they usually talk about things like robots that can make their own choices right but that's not the best definition even humans don't get to choose exactly what they're going to do right oh who knows what just happened there all right ok so anyway I'm just going to skip the slide ah I I'm sorry always use your own laptop it's such a disaster I have no idea it's happening with the builds now ok right so this is like completely screwed up so yeah you guys alright so ignore the bottom half of this sorry you weren't supposed to be able to see this at all it says autonomy is the capacity for a geographic political region to control what happens within its borders so I've obviously lost all my autonomy by letting by not using my own laptop here right so this is the best definition of autonomy I've found ever and I'm supposedly one of the experts in autonomy right and it it makes sense in the context of rillette international relations because you can understand now this is going to do something weird too oh that was pretty much like it would have been in kina ok right so autonomy is never absolute it doesn't make sense you don't have humans that can do things without other humans it just does that never happens it's always relative right so right and now let's see now this is when the bill comes so it's fundamentally entangled with the notion of security right so when you talk about war it's when you assault your enemies institutions right and that's when reducing the autonomy so that means that another country is stopping your country from being able to have that much as much influence as you would want within its borders is this making sense I'm sorry that I'm freaked out about the slides being run all right so ICT compromises the third autonomy I'm completely terrified now about what those are gonna work in that all right so we can recognize how people will vote from Facebook Likes right there was a paper that came out in like 2014 telling us that you only needed about 50 Facebook likes to better predict how someone is going to vote than their own partner can write also the connect that this hasn't been talked about as much but Microsoft itself put out papers in 2014-2015 the papers care about 2015 but they are showing them in conferences in 2014 showing that just by the way having this thing sitting on your television set watching you watch the commercials the advertisements meant that you could predict how people were gonna respond into the ads and whether they're gonna get engaged and go out you can also predict things like divorce alright we can easily recognize personality which is what the Facebook Likes thing was about right from things like Natalie likes but also Twitter right when you have people's tax so you can get enough information and then we can encourage action by individuals with targeted beliefs so this is what Chris Wiley has been alleging was actually originally constructed in order to help try to dismantle terrorism they would find people that had set beliefs that were obscure in their own little region but that were the ones that say the British government wanted them to have and then they would go and get all those people who thought that way together in one coffee house and when they found a hole of other people that thought the same way they'd feel empowered they say this is great you know now and they would go forward and actually take action we thought that was great when it was other people's countries right and that's why quit slightly became a whistleblower but I don't even want to just focus on this so people argue about K I have had that much impact on the elections and there's more detail and probably a time for at this point but look at the Brazilian elections this is an amazing article it's about weaponizing whatsapp which was supposedly not even a broadcast thing but you can turn it into a broadcasting by either having sock puppets or actually AI BOTS to propagate information from one group to the next right it's just incredible every single group that they that was at all accessible even the ones that were for the opposition but also like gardening groups and everything we're all talking about the guy who won the most recent Brazilian election right all right so yeah money compromises autonomy which was a big concern of Americans fund funding fathers sorry a little pitch for the musical here which is you know one of the things that can maybe help us finally understand what hath was World War one a century later right that was the last time we had in equality at the same levels as we have it now and when I was growing up in the 70s the history books were saying nobody really knows what happened with World War one right but when you have escalating inequality than smaller and smaller numbers of people have more and more power and that again reduces autonomy because individuals can have more influence than nations right so we don't know exactly what caused the inequality but I'm working now with this guy Nolan McCarty he's one of the global experts in inequality and political polarization we're thinking that when technology reduces the cost of distance then naturally not by cheating just naturally fewer people have more money because they have a larger area that they can sell to right so in the in the late 19th century that was stuff like oil Telegraph rail that meant that you could get your products out further now it's ICT right now there's a there the Google is like Boeing they can get their product anywhere not free it's incredible infrastructure right so the problem once you get inequality even if it was from completely legitimate means is something called regulatory capture and that leads to these spiraling events but I want to point out there was some people going around saying oh what happened 1978 this incredible great decoupling of wages from productivity but if you look at with a little longer with a little bit longer framework you realize that there was actually a great coupling this was a decision that after one world war and one financial crash the proletariat and a few of the elite got together this is American data and the end they actually said okay we're going to reduce political polarization we didn't reduce inequality and they stabilize things for a while all right now I'm thinking burning through time but if you could ask this in Q&A if you want more about that some people think now that we ICT geography doesn't matter anymore all right but it matters it matters whether your neighbor's house burns down whether their kids have vaccinations air pollution and is killing lots of people in the world right water supplies all these things matter with space and so does international security all right I had a different scale we need it you it just our problems in Britain are not the same as the problems of Switzerland or is the problem of the Netherlands or is the problems of Korea right because your neighbors matter and your geography matters right the interesting thing is that the EU s GD P R is identifying personal information as part of a person which makes sense because of that stuff I was saying about damma to influence people it's like you're nudging right it's like physical nudging so defending citizens persons is the duty of this nation-state okay national governments or other geographic executive authority it's are going to though have to adapt because of the the differences with ICT and the transnational companies we expect that coverman small have the same kinds of influence that they had or trains as well as a strange slice okay right so we do need to expect the things I didn't go somewhat differently and then finally what things that we are going to have to do so the governments are gonna have to change but so are the rest of us intact we need to death by paying enough tax to allow people to set up the infrastructure we need to keep our societies stable right so we've got to pay tax and we also have to expect that people are gonna figure out how to license us into and to inspect our products right that I already helped in some buildings they have the cars it happens with planes and it happens with I store right Apple already does this it's not something that's confusing to us it also happens with our software when it's in cars and planes so don't react like we can't possibly function this way we can okay so oops oh there that lets my person was over there that are supposed to be talking to you right so I'm gonna skip over the data thing but we'll talk about regulating humans here and again you should recognize this stuff its DevOps okay all right so the questions for governments are what's the law or a treaty deliberately violated write a special case are we going to persist an attack where citizens or visitors harmed right had something fundamental change in the world that requires a new resource to help citizens flourish because that's what governments do they take resources and they apply them to problems that's how we solve problems with governments right it's something we do so the answers are we need to be able to present information that was that DevOps slide set up the logs so governments can tell whether or not something bad has happened and that same mechanism allows us to tell if it was song accidentally the policies should be different it was deliberate or accidental right but humans are the ones that build AI and we're the ones they have to be regulated had something fundamentally changed yes not only do we have to just follow good DevOps and keep our logs around and things like that but also the government is going to have to set up regulatory bodies and again the UN has already agreed to this I'm not even starting at the yarn the EU has already made this a requirement that every EU country should have a regulatory body in it and then finally transnational cooperations need for transnational redistribution all right so thank you for your attention and I want to encourage you if you want to see my slides actually in keynote you should come to University of Bath we have a PhD and if you already have PhDs this is funded for five years by the British government we are as far as I know the only ethics oriented doctoral training centre but also we have all this resource to help you so if you are an NGO or a company or a government organization or any of these things come to us and we are happy to help steer our PhD students to solving your problem okay thank you you 