 de discussie van oké we hebben a hier hebben samenleving en en en dan gaat het wel of niet toepassen rijen beslissen of u die technologie of de zelfrijdende auto morgen gaan invoeren of dat we daar nog 5 jaar meer machtig technologie en filosofie wat kunnen die twee van elkaar leren en kunnen ze elkaar ook versterken daarover ga ik het hebben met jeroen van de hoven professor hier aan de tu delft hallo jeroen dat zijn 2 dingen technologie en ethiek dat doet delft aan ook al heel lang met die combinatie met wordt eigenlijk steeds belangrijker dat is ook wat begrijpen die technologie die je of we nou informatietechnologie is een andere technologie neemt zo'n belangrijke plaats in in de samenleving heeft zo'n grote invloed op het leven van mensen omdat wij onze ingenieurs die hier een opleiding volgen dat we die werden voorbereiden op die grote verantwoordelijkheid en regen dus dat ze moeten leren nadenken en ook net zo goed als een technisch onderwerp helemaal kunnen uitzoeken ook echt gewoon zich kompetent kunnen kunnen verdiepen in die in die ethische en maatschappelijke dimensies het gaat dus niet alleen maar specifiek om het ontwerp van het product of van de service het gaat ook over mogelijke implicaties zo voeren te levens veel mensen raakt zeker ja en de probeer je zo vroeg in zo vroeg mogelijk stadium te doen als je nog het verschil kan maken eigenlijk op de tekentafel de ze eigenlijk een soort ethiek op de tekentafel waarbij je ook je ethische afwegingen en overwegingen probeert te zien als een soort requirement en dus ingenieurs kun je niet blijer maken dan te praten in termen van require mes maar zijn natuurlijk ook hele andere requirements dan technische requirements in dit zijn maatschappelijke of ethisch requirements and dat het mensen bij elkaar moet brengen dat het mijn privacy moet respecteren dat het mogelijk moet zijn om je verantwoordelijkheid te nemen als je met die producten werk en nu maak je praktische want als je alleen tegen ingenieurs in zegt en het moet ethisch verantwoord zijn dan is dat veel te vaak dat is veel te vaag en daarin en dat is juist het aardige van de tucht van zo'n omgeving en zuur met je technische collega en die die die verwachten dat je net ook inderdaad heel praktisch markt zodanig dat er ook een verschil kan worden gemaakt in de praktijk en en daarom hebben we eigenlijk al een tijd lang gewerkt aan een aan een soort methode of een manier van van ethische vraagstukken in een technische context conceptualiseren en dat doen we dan in termen van values and design dus die waarde in morele waarden waar je de burgers zich zorgen over maken waar bewindspersonen over praten maar beleidsstukken over gaan waar de media over schrijven al die dingen dat zijn eigenlijk eisen die je aan of verwijzen naar eisen die aan producten en diensten zou zou willen stellen en aan technologie meer zijn algemeenheid dus dat is een eigenlijk de brug tussen die twee werelden dat is eigenlijk de crux van ethiek en techniek doen is een soort en tussen wereld conceptuele tussen wereld scheppen waardoor die twee met elkaar in contact komen en niet als maar op grote afstand van elkaar bewegen laten we dan nu inzoomen in het vakgebied specifiek kunstmatige intelligentie of data science zijn er principes of frameworks als het gaat over verantwoorde kunstmatige intelligentie ja die zijn er zeker althans je er zijn je moet altijd kijken naar waar gaat die technologie enorm verschil maken in het leven van mensen wat voor soort effecten kunnen we daar van hen wachten hoe wordt het gebruikt waar kunnen mensen schade ondervinden wat voor soort nadelen of schade zijn er en dan ga je kijken naar hoe je dat in het ontwerp als waren kunt accommoderen dus als we het hebben over machine learning of deep learning dan is dat heel tragisch maar is een krachtige technologie super krachtig maar naarmate die krachtiger is lijkt die wel ondoorzichtiger te worden dus je dus en dat men heeft natuurlijk enorme grote teen sokken snel aan en snappen niet hoe die er nu precies hoe het werkt en dan weet ik ook niet van een raket of van van de motor van de auto weer mij toch rijker best fijn mee ja dat dat dat dat is ook wel zo alleen we hebben natuurlijk in de loop van de tijd hebben we normen en en en standaarden ontwikkeld en praktijken ontwikkeld en ook zeer ingewikkelde instituties ontwikkeld om om te gaan met de veiligheid van auto's luchtvaart farma voedselkwaliteit door schade en schande hebben wij geleerd hoe wij daar op een veilige en verantwoorde manier mee om moeten gaan en we hebben inspectie en behouden er toezicht op en en al deze deze dingen maar voor haar indt science is dat nog niet ontwikkeld we hebben een voedselwarenautoriteit we hebben dus die gaan voor ons al druk de al die dingen checken zodat wij veilige restaurant kunnen binnenlopen en in een vliegtuig kunnen stappen en weten wat de probeer bilities zijn dat het dat het fout gaat en kan er vanuit gaan dat het ad los gereed precies een heilig is dus iets en daarin zie je als het ware dat dat dit een tamelijk ingewikkeld probleem is en dat de versimpeling daarvan ons niet altijd op weg helpt en want je moet het dus echt zien als je me moeten daar de instrumenten maatschappelijk juridisch en institutioneel voor opbouwen om ervoor te zorgen dat die samenleving veilig is in een hele brede zin voor die geavanceerde technologie die we op dit moment in aan het loslaten zijn want sommige mensen zou misschien denken dat dit ging over de avg er is wettelijk geregeld over over privacy maar daar het eigenlijk over hebben is dat computermodellen soms onbewust discrimineren wat niet oké voelt maar wat heel lastig is om ergens om iemand aan verantwoordelijk voor te maken of een als je er achter komt dat is stuk ja jullie iemand moet dat moet dat aanhangig maken en dus je een en er zijn nu ook al wel mensen die bezig zijn is collega's computer scientist ndt analytics experts die gaan kijken naar hoe je dat voor mensen in de gaten kan houden en of je ergens zou kunnen zien dat er data gebruikt zijn om dingen te doen die je eigenlijk alleen maar kon doen als je data gebruikte die je niet had mogen hebben dus dan kun je kun je laten zien dat er een swords dat er bijvoorbeeld postcode zijn gebruiken en financiële beslissingen over mensen te nemen die ze niet hadden mogen gebruiken dat kun je dan weer statistisch bekijken een manier om er zeker van te zijn dat als bedrijf of organisaties omgaan met met met daten is dat ze bepaalde principes gebruiken of frameworks ik heb wel eens gehoord dat dat feit is echt aan thema waar staat dat voor fairness accountability and transparency ja en er zijn ook andere acroniemen hen maar ze gaan eigenlijk allemaal over de die transparantie accountability and accuracy and confidentiality dat zijn de normen die voor een deel ook in de privacy wetgeving verankerd zijn maar dat zijn alle dingen waar we ons zorgen over maken als die zeer geavanceerde technologie wordt ingezet en over mensen gaat en beslissingen mogelijk mee de neemt over mensen of andere mensen beslissingen nemen op basis van de uitkomsten van dat soort systemen en ja dat zijn de vraag eens eventjes kunnen we daar nu ook echt voor gaan ontwerpen kunnen we nu echte explainer bullseye maken waar wordt dat is een een nieuwe trend het onderzoek naar x play elena kunnen we inzichtelijk maken welke principes er aan het werk zijn geweest en dat is een echte een hele lastige opgave en daar moeten we onderzoek naar doen ja [Muziek] [Applaus] [Muziek] [Applaus] [Muziek] 