 [MUSIC PLAYING] Machine learning is being used more and more today in the real world making decisions that impact our lives. It's influencing health care by recommending treatments. It's becoming increasingly important that we make it easy for us to control the behavior of those machine learning systems to make sure that they behave how we want them to, to make sure that they're safe and that they're fair. There are systems that decide whether somebody should be interviewed or whether somebody should get a job. There are systems that decide whether somebody should get bail. There are systems that decide whether somebody should get a loan. And again, and again, and again in the media we've seen examples of these systems discriminating against minorities, discriminating against women. And also, there's examples of it recommending really deadly treatments to patients. The main difference between what we're doing and the standard methods right now is that we're trying to make it easier for the people using machine learning algorithms to control the behavior of the algorithm. And specifically, we're shifting kind of the burden of making sure that the algorithm is well behaved from the user of the algorithm, the person applying it to their data, to the person that created the algorithm in the first place. And this is important when the person using the algorithm is an expert in their own field. For example, a medical expert or a geologist who knows all of the domain details, but they may not be an expert in machine learning and statistics. Seldonian algorithms make it much easier for the users to make sure that bad behavior doesn't happen. Our work on the Seldonian framework was published in a journal called Science. The main contribution of the work is a framework for how to design machine learning algorithms. Our framework essentially creates a set of new algorithms that allows people to say, I don't want the system to hurt humans. I don't want the system to have bad medical outcomes. I don't want the system to discriminate against women. And then the algorithm itself enforces that kind of behavior. And so it's critical now that we create methods such as the Seldonian framework for addressing these kinds of issues so we can actually going forward reduce instances of bad behavior in these systems. For machine learning to be applied responsibly, we need to give safety guarantees. These new Seldonian algorithms open the door to new applications of AI where previously it would've been too risky to use a computer learning system. But they also enable us to have safer and more fair solutions where there could already be an existing AI approach in place. It's a new area within machine learning with many open questions that are just waiting to be solved. [MUSIC PLAYING] 