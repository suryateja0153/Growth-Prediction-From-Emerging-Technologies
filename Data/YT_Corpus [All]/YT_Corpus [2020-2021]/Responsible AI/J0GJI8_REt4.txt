 [MUSIC]  Innovation hinges on our ability to see things differently, breaking boundaries and looking between the lines in an effort to solve some of the world's toughest challenges. [MUSIC] Working together across disciplines and pushing ourselves to see the future from an alternative perspective. [MUSIC]  Hello and welcome. I get to do one of my very favorite things today which is to share exciting breakthroughs and innovation that we're working on. Our future is often discovered in the unexpected, and our goal today is all about inspiring you and sparking your imagination about what's to come, and the opportunities it creates to transform and re-imagine not only your business but even the world. The very nature of innovation is that every time we reach a new frontier, we realize that we can go even further. In that sense, innovation is a journey. Today, we invite you to take this journey with us. Our approach to innovation at Microsoft is anchored in three fundamental tenets. First, our work is focused on creating meaningful innovation for lasting impact. It's also about how quickly we make our innovation available for customers and partners to innovate on top of. We believe breakthroughs will come from companies across every industry, not just technology providers. Second, it's all about the applicability of the innovation, how it's put into action, whether it's being used to transform an entire business or tackle some of society's toughest challenges. It's about making that innovation real. Third, we believe technology must be developed responsibly in a way that earns trust. Society is speaking loud and clear demanding innovation that improves lives and can be trusted. It's not just about what technology can do; it's also about what it should do. Today, I'll show you how we're applying those tenets across four key trends of innovation that we believe will help shape the next generation of AI and have significant impact on business. Now, I think the only thing better than getting a peek into the future is getting the opportunity to experience it. So we've designed this session for you to have the opportunity to play along with the interactive version of my talk. Some of the cool stuff you'll be able to do is control a robot, ask a supercomputer what it thinks about pretty much anything, and go on a virtual tour of one of our state-of-the-art research labs. We've also hidden a little Easter egg for you to find. For the full interactive experience, use the URL highlighted on the screen. If you prefer to follow along in the non-interactive version of my talk, you can use our companion app to get deeper information. Let's dive into our first area of innovation, AI at Scale. We recently shared our vision around a new generation of AI that's a game changer in terms of how AI is developed. The latest breakthroughs and algorithms and computing are enabling the development of massive scale models that will jumpstart a whole new breed of applications that are hard to imagine today. We're moving from traditional AI models that are designed and trained for one specific task in a particular domain, for example, having one model to predict a sales forecast and another for image classification, to this new world where these massive models are now able to take on multitudes of tasks across completely different domains. Think about the exciting combinations you can have. I'm excited to share how this vision is becoming a reality. Earlier this year, we announced Turing which is our own family of massive scale models that use the latest advancements and have enabled the size of these models to increase from millions to billions of parameters. You can try out one of these models for yourself using our interactive experience. Different teams from across Microsoft are already using the Turing models and applying their own domain expertise to improve language understanding tasks across a variety of products like Bing and Outlook, and enabling new experiences in Dynamics 365 that weren't possible until now. But behind these massive models lies a remarkable engineering challenge to build a highly scalable, distributed, and powerful AI supercomputer that can manage the amount of data and computation required for training these models. At our Build event in May, we announced our new AI Supercomputer as a part of Azure to provide the advanced supercomputing infrastructure along with the software systems that are needed to manage such highly distributed computing. We're already seeing amazing innovation is being built on top of it. In fact, OpenAI just recently released a new model called GPT3 trained on the AI supercomputers infrastructure which has reached a whopping 175 billion parameters. As amazing as that is, it's not even the most important thing. What really matters is that we continue to see these models increasing in quality and performing tasks never possible before, like learning new tasks just by describing them or by providing a few examples. Today, we're making additional announcements that support the vision of AI at Scale. Let me share a video where Luis Vargas, our Partner Technical Advisor here at Microsoft, shares more details on these exciting announcements.  Thanks, Mitra. In the next five minutes, we'll talk about our progress on AI at Scale, check how we're making our technology assets more broadly available, and look at a few examples of how we're using large models like Turing in our products. Let's start with infrastructure. The work that we have done on large-scale clusters and leading our design is making Azure better at supporting the AI needs of all of our customers irrespective of their scale. Last month, we launched a private preview of AI supercomputing capabilities with the Azure and Dv4 VM series, our most powerful VM series for AI. This is using the latest NVIDIA 100 GPUs and the fastest GPU to GPU interconnection. All these results in three times higher performance than with the previous series. Beyond this, the series can scale from eight GPUs on one VM to tens, hundreds, or even thousands of interconnected GPUs in one cluster. Each GPU gets a dedicated 200 gigabit per second InfiniBand connection. That is 1.6 terabits per second of bandwidth per virtual machine, 16 times more than any other public available Cloud offering. With regards to system software, to be able to use this infrastructure effectively, we continue innovating at a fast rate with DeepSpeed or Python's library to distribute and optimize the training of large models. This month, we open-sourced the latest version of DeepSpeed which further accelerate distributed training by five times through more efficient communication algorithms. In addition, by combining three types of training parallelism; data, model, and pipeline parallelism, DeepSpeed now enables training models way beyond the current limits crossing one trillion parameters. In the coming months, we'll bring this innovation to the ONNX Runtime, our framework-agnostic and hardware-agnostic runtime for AI. That brings together all of the innovation in Microsoft for training and inferencing of models. With regards to models, we continue evolving our Turing family of models, improving on their architecture, data, and size. Remember, these models have been trained on large amounts of web data to understand and generate language. They can be fine-tuned for any task involving language, from analyzing the sentiment in sentences to answering questions, summarizing documents, and even generating product descriptions. Let me show you one example. In this example, we'll fine-tune a Turing language model for a sentiment analysis task using the popular Stanford movie sentiment dataset. Using a Python notebook in Azure Machine Learning, we will create a workspace to work in deploying just one virtual machine with four GPUs for this simple task. We'll load the Stanford dataset, and finally, run the fine tuning of the Turing model for 15 epochs. After just a couple of hours, you can see state-of-the-art accuracy at 95 percent. Let's now evaluate a sentiment in some statements about movies. The model will return one for positive and zero for negative. The first one, "This was worth spending two hours of my life." It's a one, means it's positive. The second one, "I would really love to have two hours of my life bak," has a typo in "bak", but thanks to the language understanding, the model can still understand that the sentence has a negative sentiment, or zero. For "This has a nice plot for a horror movie," the model understands that horror is the genre of the movie but that the sentence has a positive sentiment. Unlike the next sentence, "This movie was a horror," where horror is just to describe the movie, and therefore the sentiment is negative. I'm happy to announce a private preview for our Turing language models to make them available to others. The preview will enable customers, partners, and researchers to request access to the models and to collaborate with Microsoft on implementing their own scenarios. Got to aka.MS/AIatScale to request access today. Through this private preview, we will learn with you about other applications of the model and develop guidelines and tooling for the responsible use before making this generally available. At Microsoft, we're already using our Turing models behind many of our features in Bing, Office, and Dynamics. Bing has been using Turing for the past year to empower research and question-answering capabilities. Let's now look at how we have innovated the Find feature in Word in the same way. This is very useful for complicated words, for example, cryptosporidium, something like that. That's the one that I was trying to find. Now, Word can even answer questions about the document,. Ror example, how often is water tested? The answer is here, between 10 and 100 times per day. You can find information in the document. We think of our latest models and infrastructure and systems that enable them as a new type of platform, one that enables faster innovation and better collaboration. We believe that this platform needs to benefit everyone, and so we'll continue making all of our tech access more broadly available. We're very excited to see what you build with this. Back to you, Mitra.  Thank you, Luis. This new generation of AI will enable a vibrant ecosystem that takes AI to new levels but also serves to democratize it for every company through a full AI platform stack. Foundationally, the stack starts with the AI Supercomputer in Azure and includes Azure Machine Learning, which will enable the fine tuning of these models as Luis mentioned, to Azure Cognitive Services, which will also be able to leverage these massive models. At the top of the stack, most products in Microsoft will be taking advantage of these amazing capabilities helping to bring this new generation of AI to every employee. I encourage you to try out the previews we announce today. Whether you're interested in creating a massive model from scratch or even looking to use it on a pre-built application, you can start exploring this new generation of AI for yourself. The AI Supercomputer is a great example of breakthrough innovation in the Cloud and we're also seeing AI getting even more powerful on the edge. This power is enabling a new revolution in the core operations of our customers, moving from static, automated operations with fixed rules to truly dynamic, autonomous systems that have the ability to perceive their environment and react to it in real time. This new revolution means engineers, the mechanical, industrial, and chemical engineers who create these physical systems now need to have AI added to their toolkit to help them design these autonomous systems. At Build, we released our Project Bonsai preview service to empower engineers and domain experts for this AI transformation. We believe domain experts shouldn't have to know the inner workings of a neural network to be able to teach these systems. Everyone has something valuable they know how to teach, so it was important that we find new ways for systems to learn that go beyond data. We've been pioneering technologies like machine teaching that combines human expertise with AI. In the case of autonomous systems, we're giving engineers the ability to train physical systems using their domain expertise without having to learn data science or have a data science background. We're working with organizations today that are using AI to solve real-world industrial control problems, and PepsiCo is one of those companies. You may already know that PepsiCo makes Cheetos, which are fabulous. Actually, Flamin' Hot Cheetos are my favorite, so this project has been super close to my heart. PepsiCo's engineers have been using our Project Bonsai service coupled with their domain expertise to teach AI agents the optimal ways to control the process for making Cheetos. Let's hear their story. [MUSIC]  What makes the perfect Cheeto? Precision, the right ingredients, the right size, shape, flavor, air coming together to make the perfect crunch. It's really important that our Cheetos are in specification each time. We partnered with Microsoft and Neal Analytics to deliver the perfect product to our consumers. Our engineers know how to make a Cheeto. They understand the day-to-day, what the machine looks like, the vibration, the pressure. They take all their knowledge and train the AI. Then they assess how the AI is making decisions through millions of simulations after we've trained it on all these different parameters. It's continually tracking the performance coming off our extruders. It flags real-time with their issues so we can intervene very fast. What's great about the autonomous systems is that it up-skills our workers. It's actually the perfect combination of human and machine. Our trial runs have all been successful. So, now we're starting to scale. Innovation is such a core value for PepsiCo and Cheetos is so integral to that. We wanted to make our consumers happy with every experience and autonomous systems are going to help us raise it to the next level. We're just getting started. We're ready to rock and roll. [MUSIC]  It's been fascinating to partner with PepsiCo on their AI innovation journey. And it's exciting to see how this technology is already being applied to solve complex challenges. Now, a key concept you heard from PepsiCo was how a digital twin simulation of their process played an important role in enabling their AI agent to quickly train. Digital twins and simulation technology will become the backbone enabling future autonomous systems for everything from validating and certifying solutions, to training AI agents and monitoring their operations. Digital twin usage will span from individual pieces of machinery or processes like you saw with PepsiCo, to whole manufacturing plants and entire companies. But really, why stop there? Earlier, you heard about Microsoft Flight Simulator from Satya, which is essentially creating a digital twin of the entire planet, including landscapes, buildings, roads, all based on real-world data from Bing Maps and even live weather data. With Azure Digital Twins, we're already making it easy to create digital representations of machines and environments. Our research teams are pushing the concept of digital twins even further with simulation technologies like AirSim to make it easier to create and test intelligent, autonomous agents at planetary scale. Let's say you want to build, validate, and safely operate a fleet of drones to do deliveries. The example you're seeing now was developed using AirSim, and it's showing a drone autonomously lifting off, flying, and landing at the Sydney Opera House. By bringing together precise, real-world mapping data, weather data, physics engines, and sensor models, you can create a high-fidelity virtual playground to train your AI agents. The drone in this demonstration senses the world through its vision and depth camera feeds that you see in the two windows at the bottom of the screen and it navigates as if it were in the real world. But even training these agents in a virtual environment is not enough. At the end of the day, we need AI agents to work in collaboration with people. We want to train agents to understand our behavior and augment our capacities while making it possible for any developer or engineer to do this. Microsoft Research has been working on Project Paidia, which is looking at new ways to advance reinforcement learning to collaborate and respond naturally to human actions. If you're in the interactive version of my keynote, you'll be able to move a robot around the stage that was trained using Project Paidia and play a game where you can collaborate with it to accomplish a task. With Project Paidia in partnership with Ninja Theory, we're using video games to address fundamental questions like how AI agents can learn more human-like behaviors, and how they can better model human players' goals and preferences, and to collaborate and quickly adapt to evolving situations where a human player is involved. Having AI that can collaborate with us has value way beyond gaming. By developing AI that learns and knows how to work with us, we can empower everyone to innovate. We believe the full potential of AI can only be realized when it's put in everyone's hands making it accessible and approachable to all roles in an organization, not just the technical functions, so that all employees have the ability to both consume and create AI in ways that are meaningful to them. Behind every technological innovation is a person with an idea, a dream, or someone who has simply asked, 'What if?' Innovation in your organization will be fueled by individuals with purpose empowered with the right tools. Kelvin [inaudible] is one of these passionate, purpose-driven people. After Kelvin's beloved grandmother and father both sadly died from complications resulting from falling at home, Kelvin gave up his successful career in smart city technology and took a year to work with senior citizens to determine what kind of tools they needed to help them continue to live independently. Kelvin and his team developed MeCare using Microsoft AI technology that acts as a companion to the elderly so they can live more safely at home. Since the outbreak of COVID-19, MeCare has been extremely helpful in protecting seniors while enabling them to remain in precious contact with their families and helping to ease feelings of loneliness and isolation. I'm also inspired by the innovation coming from individuals here at Microsoft with a passion to make things better. Hadas Bitran of Microsoft Research is a great example. Her work to help reduce the burden on vital frontline healthcare workers and overwhelmed health care systems is driven by a deep desire to help others. Let's take a look at her story. [MUSIC]  My biggest aspiration is to create technology that helps humanity. I've been passionate about technology and medicine since the age of 12. When my twins were born, within one month, my mother died. It was a very soul-searching time for me. I realized I should have become a doctor. But in Israel, you can't get into the medicine school after a certain age, so it was too late for me. When Microsoft got into the healthcare space, I had to be part of it. I was working in my regular job. Nights and weekends, I laid the foundation to create a team that drives health AI technology. When coronavirus hit, we saw there were many frontline healthcare organizations overwhelmed all around the world. We worked to power the COVID-19 symptom checker that could help people assess themselves and relieve the burden of the healthcare workers. Within just three months, we've powered more than 1,700 healthcare bot instances in 23 different countries. This really helped reduce the anxiety of patients, but also helped reduce the burden from the healthcare systems. When we learned that plasma donations of coronavirus survivors can help treat other patients, we joined the plasma alliance to help power a healthcare bot to screen potential plasma donors for COVID-19. There is so much more that we can do using artificial intelligence to help take healthcare forward. We feel humbled and fortunate to have this technology that can help people. I don't know if we've actually saved lives, but if we've helped even one person, I'll be happy.  We'll be sharing more of these inspiring stories of the people and the motivation behind their amazing work as part of our new series called Humans and AI where we celebrate the heroes using AI to make the world a better place. The next exciting frontier of AI is about helping us augment our powerful reasoning capabilities. This is especially relevant for knowledge workers, people with domain expertise, whether it's in product design, construction, or marketing. Taking the health domain as an example, in the 1950s, medical knowledge doubled over the course of 50 years. By 2010, medical knowledge doubled every three and a half years making it that much more challenging to maintain deep domain expertise. Now, it's projected that today's medical knowledge will double every 73 days, which is just fantastical, until you realize that over the past few months, over 50,000 medical papers have been published on COVID-19 alone. How can any researcher read all that information, much less retain it? Subject matter and domain experts will need to increase their ability to reason over vast amounts of expanding knowledge beyond what's considered possible today. This is right in the sweet spot of where AI can help. A great example is work that Microsoft Research has been driving on a new AI breakthrough for biomedical research called Biomedical NLP, or natural language processing. These advancements are revolutionary for the medical research community in helping them advance their pursuit of precision medicine. If you're watching the interactive version of this keynote, you can experience the power of this model for yourself. The true value of a model like this is in the optimization of its specialized domain. The Biomedical NLP model has been specifically trained on millions of medical papers, so, it can understand biomedical texts and extract knowledge from it. Researchers can co-reason with AI and leverage the vast amount of knowledge that exists in the medical community. It may feel like science fiction, but we're already working with a number of customers on this vision to push the boundaries across many subject domains from science, to engineering, manufacturing, and health. I'm particularly excited about the partnership between Microsoft Research and Novartis in the pharmaceutical space. Novartis is now using AI to expand domain knowledge across their company encompassing 50,000 of their employees from research to manufacturing and distribution. Novartis researchers are using AI to augment their expertise and domain knowledge to help accelerate discoveries that have the potential to become life-saving medicines. Let's hear their fascinating story. [MUSIC]  Every person contributes something unique in their job. In a pharmaceutical company like Novartis, the important aspect is finding more targets, more molecules that could eventually become a lifesaving medicine. We generate data at every point of our value chain. In our alliance with Microsoft, we're innovating at the intersection of AI and life sciences, building the elemental blocks of AI such that every associate can put them together in exciting new ways. This will allow them to reason, innovate, and ultimately augment their expertise and creativity.  As a researcher, our co-work is to develop new drugs. But the amount of information in the world of medicine is constantly growing. Using AI, we've been able to bring together critical information across data sources. By using our scientific knowledge and reasoning on top of AI models, we can accelerate our discovery.  We can navigate each other's data, make all this accessible, exchangeable so that the next colleague can add his piece of work. We will be able to make connections which impacts the patients, but also us as researcher.  Every field, every industry is becoming a data-dependent data-driven field. AI has a fundamental capability as a compliment to the human expertise. If we infuse it at every single step of the workflow, we can empower our people and bring the magic of AI in a meaningful way.  Now, bringing these first three trends together, you can envision the huge transformation that's coming. These trends will bring AI to every facet of the business and every employee in the organization. It's really a seismic level transformation. Of course, transformations of this magnitude come with associated risks and challenges, and this especially holds true with AI. There are challenges that enterprises need to address quite seriously. Responsible AI encompasses three core aspects. First, it must start with a set of principles that reflect your intentions, your values and goals, and guide everyone creating, using, and applying AI in your organization, and that's just where it starts. To make these principles real, you need to put practices in place that instantiate the principles and bring them to life. It requires tools and technologies that help you follow your established practices to develop and use AI responsibly. Our goal is to help you on this journey. At Microsoft, we established six principles in 2016 that include fairness, transparency, and privacy. We also share our practices with you in our Responsible AI resource center where you can find things like the AI fairness checklist or human AI interaction guidelines. We've developed tools and technologies to help any organization develop AI responsibly. Many of them are already available today as a part of Azure Machine Learning. Responsible AI itself is an important area of innovation and a space where we're pioneering tools and technologies. Let's take privacy for an example. Microsoft Research is leading the way in advanced techniques like homomorphic encryption which allows AI to run on top of encrypted data keeping the user's data private, or differential privacy, also pioneered by Microsoft Research, which limits the disclosure of public information and datasets. Privacy is critical, but it's part of the equation. We all realize our personal data has tremendous value, but we typically don't have visibility or control over how our data is being used. On top of that, we're not able to participate in the value chain generated by that data. But what if we could? This is the notion of responsible data collection. Responsible data collection goes beyond privacy to consider the entire lifecycle and value chain of your data. To help make this idea of responsible data collection real, today we're announcing the release of a new tool called Project Trove. Trove is a new mobile application that connects individuals with developers who are working on AI projects. The power of this app is that it enables anyone to contribute to the creation of meaningful AI projects in a fair, transparent marketplace while providing developers with higher quality, more diverse data to train their AI models. With Trove, we're taking a people-first approach in which participants have control through the licensing of their data and transparency into how it's being used and compensation for its use, even across multiple projects. Project Trove is currently being used by teams across Microsoft, Bing, Azure, and Research. We're also working with a number of early customers. Today, we're making Project Trove available for organizations to collect and use data in a way that's even more responsible from the start. We hope you'll find this to be a useful tool in building your own approach to responsible AI. By building on a strong foundation of responsible AI, our focus is to empower people around the world to positively transform society through AI. Societal change requires an even greater scale of innovative ideas, technologies, and partnership. But, immense scale and impact can also be found in the smallest of spaces. When you consider some of our biggest challenges, such as human health, and societal and economic health, very often, the thing that tips the scales depends on the smallest of species and organisms. The good news here is that we're well underway on this critical work. I'd like to introduce Dr. Peter Lee, Corporate Vice President of Microsoft Research and Incubation, to share more about this. In his video, through our interactive experience, you'll have the opportunity to visit one of our coolest and most advanced labs and even guide mosquitoes towards a trap.  Thanks, Mitra. I'm really pleased to be with you here today, even if only virtually. About four years ago, we formed Microsoft Healthcare NExT. Our mission and our desire was to bring together Microsoft's trusted technology platforms, advanced research, and deep collaborative partnerships to make a positive impact on human health. Since then, we've seen Microsoft's products evolve to speak the language of healthcare. We've also been launching new efforts with our partners. For example, we're working with Novartis to use AI to accelerate drug discovery. We've been envisioning next-generation health networks with the Walgreens Boots Alliance. Meanwhile, we've been involved in several multiyear efforts grounded in Microsoft's amazing 30 years of advanced research. You might call these moonshots. You've already seen a glimpse of one example with our biomedical NLP effort. I'd like to talk about another one, Microsoft Premonition. This moonshot has been developing new sensor networks and they're continuously and globally monitoring the environment for potential pathogens. The hope is that this will give us a chance to stop them before they harm our societies and economies. Now, since our first pilots of Premonition back in 2016, the world has seen numerous unexpected outbreaks; Zika, Ebola, Dengue, COVID-19, and several others. It's so important to detect and stop these in their tracks. So today, I'm excited to announce that we'll be expanding Premonition technologies to a select number of partners through an upcoming early access program. This is the next phase in this moonshot, understanding how to make human impact in careful collaboration with the world's best health experts. Harris County Public Health in Harris County, Texas, manages to help over 4.5 million people through their innovative approaches. I'm excited to announce that Harris County Public Health will be one of our early access partners. It was back in the 2016 Zika outbreak that first brought us together. Now, we hope to show that Premonition can make an impact on mosquito-borne diseases that today cause over 600 million clinical cases of disease every year. We also have academic partners; Johns Hopkins University, the Institute for Health Metrics and Evaluation at the University of Washington, the University of Pittsburgh, Vanderbilt University. All will be working together with us to study the larger implications of these types of technologies on engineering, the life sciences, and public policy through the National Science Foundation's Convergence Accelerator program. Microsoft will continue expanding its collaborations also with Bayer. Together, Bayer's and Microsoft's research programs will cut across public health interventions, sensor networks, and AI with shared missions to reduce the threats of infectious disease. With that, I hope you'll enjoy this video for a closer look at Microsoft Premonition. [MUSIC]  If you divided all the species on the planet into a pyramid, vertebrates would be at the top. That's you, me, birds, anything with a spinal cord, tens of thousands of species. Next down is invertebrates, millions of species; bees, spiders, and other arthropods like mosquitoes. At the base, we have microorganisms. In fact, bacteria and viruses alone consist of tens of millions to possibly billions of species. Science doesn't even know for sure. Humans occupy only a tiny sliver at the top of this pyramid. But, our biggest challeng, human health, the health of our societies, economies, and ecosystems depend on the smallest of species. Insects pollinate the food we eat, microbes invent the antibiotics we take, and viruses generate the epidemics we fight. If we can monitor the small life all around us, then we can predict the big. Innovation hinges on our ability to see the world differently, breaking boundaries and looking between the lines in an effort to solve some of the world's toughest challenges. [MUSIC] More than ever, the world is realizing the urgency of monitoring viruses in the environment before they cause outbreaks. In just the last few years, new threats emerge every six months. COVID-19 is the most recent example, but unfortunately, it's unlikely to be the last. The good news is that the biome generates almost unfathomable number of signals. We just need to read them to keep up. For us, it starts with arthropods. These humble invertebrates; mosquitoes, beetles, bees, comprise most of our terrestrial animal biodiversity. Bees pollinate trillions of dollars in crops. Mosquitoes cause over 600 million clinical cases of disease per year. Each day, millions upon millions of arthropods interact with plants, animals, and ecologies across the planet. Essentially, what's missing is a global sensor network and data platform for monitoring the small things; arthropods, microbes, and viruses in the environment. The sensors in our sensor network are robotic platforms; Smart traps. They continuously lure, identify, and collect arthropods. This smart trap design can identify a mosquito species in a few milliseconds and then make an autonomous decision about whether to capture it for further analysis. This all happens in the split second that a mosquito flies past one of its sensors. The most number of mosquito encounters this trap saw in a single night was around 10,000. For each one of those encounters, it took notes on the exact second it happened, the species of mosquito, ambient light levels, weather conditions, parameters that we can use to build entirely new models. Using the genetic code and Cloud-scale computing, we'll ask trillions of questions about a sample to build a genomic picture of this content. To date, we've analyzed over 80 trillion base pairs or genetic material from environmental samples. We've been able to find a cow infected with a virus and all this information was carried in the belly of a mosquito. Several years ago, we thought technology could help us monitor the biome in important new ways. It took time to get it right, and now, our goal is to get it into the world. And we're just getting started. [MUSIC]  I hope you've enjoyed coming along with us on this innovation journey and that we've inspired you about the exciting things to come and the real opportunities it creates for you to transform and re-imagine your business, society, and even the world. For more innovation stories and deeper technical dives, please visit Microsoft.com/innovation. For a closer look at Microsoft AI, I encourage you to check out our highly popular free online AI Business School as well as the Responsible AI resource center. Both can be found on Microsoft.com/AI. Also, don't miss our digital session, AI at Scale: Behind the Scenes, where you'll get a fascinating insider's look and hear from the people behind the innovations. We are honored to have you join us on this journey. Thank you and happy innovating. [MUSIC] 