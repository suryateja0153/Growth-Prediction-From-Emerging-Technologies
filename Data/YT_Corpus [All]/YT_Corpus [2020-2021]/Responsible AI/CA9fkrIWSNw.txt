 Hi my name is Nikita Lukianets I am a founder of Open Ethics initiative I want to talk about the concept of "self-disclosure" and the governance of AI decisions As humans and machines start to work together increasingly more the question of regulation becomes a cornerstone What should we let machines do? What can go wrong? Who is responsible? Well first we can bring some accountability Think "food" We all consume food and we've used to know what's inside the package Proteins, Fats, Carbs... We have even got GMO labels! So what about data and decision tech? Do we know what's inside? A "black box"? What if every technology product that we consume could carry a set of useful information Like description of the data that was used for training description of algorithms and of the rules that govern the decision space A possible answer is "self-disclosure" We already do this in Creative Commons licensing today where every creator can design his customized licensing label Likewise, labeling AI-powered solutions can improve the algorithmic accountability using bottom-up approach Every company or a government can do that The purpose of the Open Ethics initiative is to help clearly communicate goals of any AI system and its essential ingredients in a standardized and explicit way Let's build trust and protect users Join Open Ethics initiative now and power up the movement for openness at openethics.ai 