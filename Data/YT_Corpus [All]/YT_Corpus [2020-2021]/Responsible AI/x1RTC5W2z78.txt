 [Music] hi how's everybody doing I know I'm standing between you and dinner so I appreciate everybody being here if you're interested in coming in please come on in I'm really excited to be talking to you today about responsibility I so I just want to give you a quick sense of the setup for today so I want to give a quick overview of some of the things that we've done at Google and then we actually have two different conversations that we're gonna have so eva is going to come up and and moderate a panel with some customers and partners and then we're gonna come back and have another conversation so we've got a lot of exciting things to talk about today and of course we really want your feedback so please if you don't already have the app please download it and give us your feedback because we always really want to make sure we are improving so when you sort of step back and think about where we are with AI today you know it really feels like and I think we can all probably attest to at this point that we're in the midst of what many people feel like is a second Machine Age and this has really been characterized by massive advances in compute and things like artificial intelligence when you look at what this means in practice so there are actually over 90 machine learning papers that are published every single day this is now outpacing Moore's Law so the amount of innovation that we've had over the a relatively short period of time is quite dramatic so much so as an example if you think about computer vision computer vision in 2011 had a 26 percent error rate humans had about a 5 percent error rate in five years by 2016 computer vision had about a three percent error rate that's an incredible amount of change in such a short period of time which really leads to the space where we are today this change has been transformative for Google when I started at Google about nine years ago we never heard the words machine learning it wasn't a thing that was talked about but you can look at now the number of products who are built on machine learning at Google has just skyrocketed and this will continue to happen and this is that a transformation that we've undergone that we are now also working with a number of you as you are undergoing the same kinds of transformations for yourselves there are tremendous number of examples of where AI can be incredibly beneficial for the world one of my favorite examples this is one in the upper middle these are some very rural farmers in Japan who use the tensorflow model to sort cucumbers on there they're little mini production line inside their greenhouse we've been able to build models that can find manatees from very high heights from aerial photographs and when you look at those pictures there's no way that that a human eye would be able to identify what a manatee is but a machine learning model can which can help tremendously with things like endangered species and there are places where we've seen AI can really help to create more fairness in the world so this was work that we did I joined Lee with the Geena Davis Institute on media and gender and we took all of the films released in 2015 200 films and analyzed them for both screen time and speaking time and you can see the results which are fascinating so in 2015 women LED films made 16% more in the box office and yet men were both seen and heard twice as much on screen as women were that's if you think about what what could have been made by the media industry if there had been better balance this is not only about creating examples and opportunities for young girls and women to look at and see themselves on screen but it's also very much about the bottom line for an organization and you can start to see places where those kinds of biases are really pervasive in ways we might not appreciate an understands this was a fascinating study done of three million English words from public news sites and it was set up on these he-she analogy statements so if I said to you King is to man as Queen is to you would expect woman or if I said Paris is to France as Tokyo is to you would expect the answer to be Japan and you can measure the distance between words and then create that same analogies and it comes up with things like she is two registered nurse as he is two physician perhaps that's not a surprising bias that we know exists in society but some of these are quite surprising she is two cupcakes as he is to pizza she is to interior designer as he is to architect ms all based on just distance between words these are things that are pervasive across all of society as we know it today and machine learning can both help bring that to the light and if not done carefully and responsibly can help propagate these biases in unintended ways for that reason we really believe in cloudy i that all of our efforts around responsibility i are our part and parcel with the way we think about what is going to be successful for AI it's critically important that that all organizations be thinking about what does it mean to deploy AI how do i think about all of the possible impacts of the work that i'm doing because the reality is if organizations don't think about that the potential for trust to be broken can really stop the progress and stop the benefits of AI from being realized around the world and that would be a terrible outcome because the benefits are so big and so powerful we and we all really want to make sure that that is experienced in world so within Google we've done a couple of things about this the first is we wrote AI principles that stretch across the entirety of Google and these are seven things that we believe a I should do and four things that we said we would not directly pursue but as you can see these are quite broad it would be hard to make decisions as a product area when you're evaluating an individual product or an individual use of a product just based on this because what does it mean to be socially beneficial how do you measure that how do you know you're not propagating unfair bias is that even possible to fully achieve if if there's no real definition of what that might mean and so in order to support these principles we've put into into practice two processes within cloud that help us operationalize those the first is we evaluate our customer engagements that are using our machine learning tools that we've created and and look for how those engagements will align with those AI principles the second is that we evaluate every product that we build in a really deep robust way with a cross-functional across Google group of people who come together we're intentionally multilevel from quite junior an organization to very senior we pull in the relevant stakeholders we pull an external voices we pull in folks from the human rights community civil rights community to make sure that we're continually opening our frame of reference and evaluating each product in a unique way so that we are doing everything we can to ensure that we are aligning with our own principles it's important to us that this process is rigorous that it's engaging it's actually I can say in my nine years at Google it's the most inspiring thing that I personally take part in those conversations while sometimes really challenging I always walk out of the room having learned something I didn't know before and I find it incredibly inspiring and helpful and they've really opened that frame of reference for our entire organization we want them to be efficient that's important they have to be effective which means that we actually put those things into practice and we can measure them to the best of our abilities and they have to be balanced because we have to make sure that we're looking at the needs the business as well as our as well as the responsibility we've launched a few things today that I want to touch on briefly because there are really exciting efforts to help organizations with this the first is around explainable AI and this gives the human observer insights into why a model behaves the way it does it can help really create information around what were the factors that led to a particular outcome and in what proportion this information is really hard to find today it's a way of building trust with explainable AI because it's important to design interpretable AI and then to be able to deploy it with confidence this is incredibly challenging when you don't know exactly both how a model was built and how it's making those decisions and you have to think across that whole range of stakeholders all the way out to the business user or consumer who is going to be on the other side of that model to help them understand as well this can explain why an individual data point received a prediction can help creators debug that model can help refine it verify that the behavior is acceptable and then can help with a general understanding of that model we're really excited about this I hope everybody gets a chance to try these tools are part of our a AI platform it gives analysis with every prediction you can choose an explanation method we've also integrated this with our what-if tool for model inspection that can help you test well what if I looked like this what if I try this way what if I take on this persona and give you more information that way the second thing that we've released are something called model cards this is built off of research that we released last January and it's a proposed framework for better understanding how performs their short documents that accompany trained machine learning models and we've released two four components of our vision API both face detection and object detection our goal with these first model cards is to provide practical information about their performance and their limitations in order to help developers make better decisions about what models to use in what context this is a really exciting area for us we not all model cards will look the same we have these two available today we're looking at how we might create more for other parts of our technology as we're as well as where this will go in the future you can think of these like nutrition labels for machine learning and they have incredible potential to help address issues of fairness and bias along with just general explain ability and transparency and we're really excited about this we often talk about how technology is most powerful when everyone can use it and really at the end of the day it's even goes beyond that because really when technology is most powerful is when everyone can benefit from it and that's what we're aiming to do with our cloud AI products I wanted to give you that short overview as a set up to the conversations that are going to happen and with that I'd like to invite Eva and Sims annually and andreas up to the stage to have a conversation thank you very much [Applause] so good afternoon everybody my name is Roger and I'm product obsolete for cloud artificial intelligence in California and I have a pleasure to welcome our guests over the past years within Google have worked with numerous partners and clients in deploying and fostering the adoption of AI in business context and everything that Tracey talked about unresponsible III I think that wouldn't be possible without our partners or clients so that's why we invited some of them today to to our panel to share their experience with working with us and with with our clients so welcoming since who is the program manager at the deep mind she has dedicated her career to the beneficial use of artificial intelligence and things that this is the key to enable the next generation of knowledge for the humanity then we have Oliva linger who is machine intelligence research group head of Siemens era he has deployed numerous projects with simens on deep learning and artificial intelligence and in 2017 funded the Siemens AI lab in Munich welcome thank you for joining us and last but not least we have an receiver who is a managing director of internal mental and co-founder of apply di initiative in Munich that fosters and enables the application and adoption of AI with industry government and startup ecosystem so thank you very much for for joining that session I will maybe kick off with a simple question in your organization's what is the role of AI and how beneficial that is and in the context of responsible I how are you deploying that so ladies first male alright I'll go first hi everyone thank you for being here so deep mind is a research organization our mission is to solve intelligence and then use that intelligence to make the world a better place so we have teams devoted to core research science engineering ethics and society applied artificial intelligence as well as an amazing operational structure to kind of help all of those teams work efficiently together and we also take part in many partnerships and collaborations across the industry my my team specifically works on the application of machine learning and AI to challenges in the energy sector that contribute to climate change so we have right now two projects one of which is working and operational in Google Data Centers that is improving energy efficiency right now by about 30% and another project that is running on Google contracted wind farms that we are seeing about a 20% improvement in the value of wind power which we think is really important to making it more competitive with fossil fuels on energy grids so the look of my team is that our success translates into Carbon Reduction which i think is really important for the use of AI continuing with Siemens yeah hi everybody I work for one of the oldest German startups I would say which happened to scaled up to 380,000 people in the world where we obviously have a multitude of sub companies and domains we are in mobility and health healthcare and energy sector in grid space and energy management space in marvelous marvelous application areas where digital technologies have a vital impact with that we undergo a huge what's called the transformation you may have that the three entire day and maybe for a certain aspect where we see how and what is the role of a meaningful impact with AI technology enabling our transition through the journey we have happened to be that our management will decided and we're very happy to see that AI is so-called company core technology and with that it's seen as the writer backbone of of the transformation of Siemens we organized in and we funded from top-down and with that my team focusing on applied research in AI machine learning a deep learning research together with partners and the ecosystems at the same time making a difference individual products whether it's in mobility whether it's in computer vision on healthcare or whether it's the internal processes and with that loss team applies Regis contributes to the open source movement but also want to makes it different with a movement hours with ones of industrial and you have been breeding actually between industry working with numerous corporations governments and in the startup environment what is the AI role is playing AI in those corporations and where what do you see the biggest impact yeah so from what PC in German industry but also European and worldwide is that there two three streams so one is that the companies really need to think about or are thinking about what AI will mean for them to differentiate themselves against competition so that's really at the core of what they're doing and that's mainly research driven right now so we don't talk about applications here but we talk about industrial AI use cases it really how this will make a change for their core business and then we will see where we see AI applications in support functions and functions quite a bit in in sales in sales support in customer service and like virtual assistants but also predictive maintenance like these are areas where there are products out on the market and companies are readily can readily apply it internally as a product and as a service from someone else that's helpful for scaling it while for the topics they do for themselves it's really really challenging for them to get it to a global scale but that is mainly research on their core functions you mentioned challenges exactly it's challenging what are the challenges that you're particularly seeing that in the context of responsibilities I may be just continuing since you just are so what we see is or what what why we started is actually AI is not a technology topic if it comes to adoption of AI in society in the industry it's a culture topic it's a trust topic it's a transformation topic for like really every one of us so this explainable topic is so important if it really comes to adoption at scale and companies and so there's so much time spent on explaining people to really use these tools and to accept using these tools liability issues competence and capacity capability issues so then all these like very human topics like when it comes to into action between AI and humans that's the most challenging part in companies and that that keeps them away of from really scaling it in inside the companies like it's it's very easy to have it as a small prototype but when it comes to real adoption of the cases it's it's a trust topic and I like acceptance topic from for the employees yeah and really Snowden I know we've talked a lot and interacted a lot we need a bit of differentiate between an industrialization which was always about gaining efficiency and productivity and the consumer space which in in current times pushes hard on attention and predictable behavior let's say personalization right the main idea of the I is is turning input into an action or will world right and and this action in the real world have failure modes we know that we can measure them accuracy precision recall right so if we can measure them and we know they are filler modes how do we make sure that these systems that we deploy in a large scale nowadays reflect those kinds of values that be represented and want to represent as an ecosystem as a company where it's a digital person and this is somehow really tricky it's not a why the bad thing it's really tricky because if you in the domain for you it's clear some process some applications some maybe it's not that clear if the black box is the input and the output and the black boxes in the middle how do you explain the model yeah in that we know that you know we all have failure modes and we all have blind spots and some of algorithms right and we know from from the innovation drive-ins and the excellent that diversity in terms of in terms of people domains and and broad set be more inclusive - that helps not only pushing innovation but also reducing buyers in these kinds of abusive stats and that is why it's so important to open a discourse on responsibility and position on bias unfairness in a broad set not only on techniques because AI has such a vital part in our lifecycle on the product so it's not only about training models but deploying how to update how to organize how to impact that and that's a tricky tricky tricky question and that's why you know you have to be more inclusive and you have to be more cautious about the entire lifecycle of machine learning flows right I absolutely agree with you in mind I think you know that best I absolutely agree with your points on diversity and inclusion I also think a really important aspect of responsibility is reliability and for AI obviously the recommendations and the output that you're going to get is only as good as the data that you're putting in and one of the things that we've seen in the application of AI in the real world is that the real world's data is quite messy so it takes a lot of time to clean that data and actually even get it ready for training and so one of the things that we can do to address this challenge like data quality and data quantity it's actually doing this pre work you know ahead of time having conversations about standards and there there's some folks in the UK who are doing excellent work on this in the energy sector specifically EDT for energy data task force for anyone who's in the energy sector and is interested their recent report in July was fantastic but I think it's a really good example regardless of focus on energy industry or any vertical really that this discourse needs to needs to be happening more and more often so that's kind of how we're thinking about addressing those challenges even going beyond the okay I know Andres has been engaging with the policymakers and on regulation on how to make the governance structure adaptable to the changes that we are now encountering in responsible Iife can you comment on that a bit yeah so if you talk about responsible AI from a like national international perspective you need to like look at this whole topic a bit differently and the one thing is where companies intrinsically motivated to work on their own and the whole trust part the hood transparency part is something they want to work on like there are legal reasons for that you need like an insurance in banking it's auditability so you need to be transparent of that what we saw before is for testing purposes to making it more robust but also to gain the trust of your customers ultimately you need to be transparent and explainable of what you're doing so that's something from my perspective where we need some maybe some push from from the government or policymakers but overall it's a topic where companies really push this forward and then we have topics we talked about fairness or we heard about fairness before and fairness is a very interesting topic because it's a cultural topic so what is fair is it fair to give a loan to someone who has highest likely to pay back that would motivate us to like have very individual solutions and maybe each person gets what he deserves but is it a from a societal perspective is it something that we want or should everyone get the same loan to the same conditions to make it as a fair condition to everyone and that's a cultural topic and there is no clear answer to very individualistic well societies or a society with a larger social sense or community sense and in that to give directions in that way is a policy topic because it is impossible for each companies to decide on their own and to find the reasoning on their own it needs to be like the need to be at least clear guidelines in which the right you should go in one way or the other the same for for liability issues and the whole like responsibility in a legal sense also there we need to have certain standards and structures which which are given in a way that we can work with these types of structures so we have these these two aspects of of responsible AI that ultimately helps us all to be better and to really use these types of systems yeah but but we need these both sides of things policymakers it's for them it's really hard because we suddenly start a discussion which we like implicitly had for the last 20 30 40 a hundred years and we had these topics of fairness and this was a like a personal decision made by one person by a judge saying like this person is more likely to go to commit to more crimes and therefore it's more likely to arrest this person with a specific background and race or gender or whatever and now we have this data-driven and that gives us more responsibility in doing that so suddenly we get these discussions which we should have had a couple of years a couple of decades ago but now with full force we need to answer them because we have the power in these systems to give us recommendations and to start answering these questions and that's exactly where our next panelist will touch upon on on exactly those topics but I want to finish a bit you touched already about the past presence what is about the future and what are the recommendations you would give as panelist and experienced in responsibility in to that audience that sits here from demons from the mind from from applied AI perspective and then we hand over to the next panelist so from outside we're currently working on the framework is called Siemens responsible AI Industrial responsive AI it has mainly three pillars one is you mentioned already policymaking so what kind of best practice and guidelines are there if you had access the capabilities of the eye we differentiate between three impact factors one is the transparent world about profiling about computer vision technologies about sensing the world the second is about human augmentation tools that help somehow our customers about as well as our employees to improve on certain tasks and then help in the in the in the complexity of the world and the third is about autonomous aspects how we ship more autonomy in our machines in controllers in robotic systems with that capabilities that we have also risk and responsibilities coming ahead and for that we believe that in other policy-making on a governmental level is sometimes a bit handing off in times you know behind there and therefore we want to focus on guidance and best practices how to use it second pillar is technology also with partner there's marvelous technology out there federated learning safe acts robust AI explainable there I what if tools you have seen it these is something about what's right and also to push how it's with technology make an impact and the third pillar is focusing what we call co-creation trust is not necessarily about transparency it's about interaction and interaction means that we jointly create certain products and solution and being aware of what kind of capabilities we entering and what kind of needs we get in in with scale over people scale of assets comes the scale of responsibility and this needs to be reflected inside yeah and I think similar things have been engaged with implemented we have been partnering on those as well yeah I think that from our perspective one of the most important things that we done is and what I would recommend that anyone in this room does is Center the voices of those individuals who are impacted by the technologies that everyone's building we've learned so much from engaging with other community on ethics and responsible AI things like citizens juries and even surveys and that has been incredibly important for us in helping us understand actually how app algorithmic technologies are shaping the lives of the people who use our technologies and so I would say please Center those voices I think that's the best piece of advice that I could give and I think Andres who has been deploying that knowledge to the industry and to the policymakers in comment on that yeah I couldn't agree more and I think like if we accept that this is a topic that everyone here like is responsible for and it kind of working on sharing this information like really exchanging and getting these best practices overall because ultimately it helps us all if we find good standards if you find best practices here and that's it's not a topic of one single company it's a topic of us all to create general trust in AI and it like it can be ruined by single companies by single individuals and and therefore it's so much more important to work together on these topics and I think that's like the main main point for my side excellent thank you very much and that's an excellent bridge as well to our next panelist and exactly working on those topics and applying that in real life ask their Tracy to come back on stage thank you so much thank you so much and I just I just want to call out something that Asim said because I think that's so important in terms of ensuring that you're bringing in the voices of people who might be impacted by the technology because it's important to recognize we don't necessarily have that information even us on this panel we're not a representative group and I want to recognize that about when you sort of look at this group and so making sure that we have that we engage in that conversation we recognize our own limitations of our own knowledge and that we invite that in so with that I'd like to introduce Kirsty Everett who is the compliance chief of staff and head of digital at HSBC and we're so excited that you could join us today so thank you and you know I would love to start by asking you a bit about HSBC's approach here and in particular in terms of developing and accessing these new technologies like AI and great to be here it's been a fantastic day so I mean look HSBC like you know a lot of companies is been thinking about how we can apply AI to improve our business and and across a really wide range of areas from how can we improve our customer experience to how can we get better at fighting financial crime and as we go on that journey you know we keep coming back to that underlying principle of it really isn't around whether we can do something you know whether it's legal it's really for us about whether we should do it where does it stand from that ethical perspective how does it stack up and I think you know we're almost inundated at the moment with think tanks and agencies and governments and peers releasing ideas on frameworks and what we should be thinking about and you know we're taking those all on board and and and thinking about what it means for us and I echo some of the comments from earlier because this is this isn't a one-off tickler boxercise this is an entire framework from you know we have principles but what does that mean in real life you know how do we what are the controls we put in place what are the questions we ask ourselves how do we check that we're making the right decisions how do we train our staff what governance did we put around whenever we're thinking about using these technologies what approvals do we want to get so it's it's very broad and it's something that you can't just say oh ethics done tick it's in every single part of that journey and every time you're thinking about using big data or AI thinking about really what it means in every stage of the journey and I think we look at you know all the things we've already talked about today so you know really important one for us is how do we protect our customers data and and what does it mean from a data privacy perspective how do we think about explain ability and transparency you know are we really sure that we understand why we're doing it and and what the benefit is that we're looking for and then lastly around the point on fairness and and and you know unintended bias how do we manage that so it's not a short answer I'm afraid well it's not a short problem you know new technologies new challenges I think just being open and understanding that it's very holistic and it's not something you can take and say done move on yeah yeah I can't stress that enough I think you know from our own experience and what I've seen in other journeys it's very desirable to want to create that big list of here and all the things that are fine and here all the things that are not fine and at the end of the day that list it's not possible to create and and that can be a hard realization for an organization to have that it's actually much more complex but at the end of the day that leads to much better outcomes and it isn't something that you tack on at the end that won't lead to success is something that you have to think about at the beginning and at every stage and so I'd love to hear a little bit more you know as an organization like HSBC with the with the global footprint that HSBC has what forms what kinds of issues around unfair bias in particular do you feel like you spend the most time thinking about if there's anything you could tease out yeah I mean unfair or unintended bias we've pretty much done like any of them so we we don't have a favorite you know it's it's for us we are obviously a customer driven organization and we need that trust with our customers and we need we're accountable to them so you know we do spend a lot of time thinking about this and we are conscious that we may have bias in our existing you know datasets which can then lead to us encoding bias into some of these solutions that we're looking at so we really do kind of challenge ourselves and the point around you know think about the data that you're starting with don't just think about how you may bring it in through the journey is key but but you're right I think as a as a global organization we have customers and staff all over the world and they have different characteristics different perspectives different experiences and and one of our main corporate values is diversity and inclusion so anything that you know puts that at risk anything that starts to suggest that we may be looking in bias in that space is is a big problem it's a complex challenge for sure so you know even obviously we think a lot about explain ability I know you do it's top of mine for many particularly as AI systems start to be more commonly deployed so can you talk a little bit about what that means for HSBC in particular and how you would describe the needs of the bank with regards to explainable AI yeah I mean I think andreas said it earlier financial institutions and banks it's absolutely key you know we we are we're accountable to our customers and anytime we make a decision or there's an outcome that impacts them we have to be able to explain that it's it's it's it's pretty black and white having said that I think there's always a balance right so you know as banks we're used to thinking about things on a balance of we take risk what is the risk offset here and and I think when it comes to explain ability quite often we see there's an offset between performance and explained ability and that's really interesting for us because then you're back into the ethics of where on that line should we be and there's there's some situations you know I'll use a non banking example but if you had a life-threatening disease and I said to you well I can give you an AI treatment but I've got no idea why or how it works when I guarantee it will save you you would probably say okay I'm gonna take it you know we don't deal with things quite like that but there is that balance around how much do we need to be able to explain do we need to be able to explain every single going along the model or do we need to just be able to explain the key drivers for an outcome or a decision that we've made you know if we've turned you down for a bank account you deserve the right to know why so it's not just about what we think is appropriate from an explained ability perspective but it's also what we think our customers will think is appropriate and what our regulators will think so and it is very key for us one of the things that you know I've been thinking about a lot in this in this we often talk about the creation of AI from beginning all the way out there deployment as a team sport because there are so many different roles and functions that that need to participate in that as you move from creation and development all the way out through deployment into an application or into a workflow and into them the impact of that out in the world and I I think explain ability needs to also be thought of along that scale because it's it is important to think about what kind of information is actually useful or helpful to the the different stakeholders who are impacted or have to understand a model because it isn't the same what a data scientist needs in terms of understanding while they're building is not the same as what a doctor would need in terms of understanding does this eye scan for diabetic retinopathy does it how did it make that decision what factors led to that and that's a very different information yeah and that's the same for us you know our data scientists need one thing as you say but our frontline staff that need to have a conversation with the customer and say this is your credit decision or you know you've had a payment stopped for financial crime purposes they need very clear black-and-white English this is exactly what has happened and why yeah so we have to get to that level that's right and that's about trust as well because that Trust has to be with it within your employees as well as with your customer I mean the last thing we can have is is anyone at the bank saying to a customer or yeah I don't know the computers yeah the computer says bad freedom yeah you know we need to own the message yeah so either about explain ability or anything actually if you could direct our engineers to do anything what Allen what what would it be what would it what would you need yeah um maybe scope it to responsibility i but just antenna I was often yeah so I'll bring it back to a business context not just me personally yeah I think what you were announcing earlier in terms of explained ability is key and I'm fascinated to kind of get under the bonnet a little bit because I think if you'd asked me that question before this had come out really that would be it you know how can we I don't want to end up with an AI pyramid but how can we use AI to help us explain a oh yes yes that's how Auto ml works it's machine learning models I create machine learning models yeah building it up so explain ability is key and and and then one of the other points that you know we've touched on a little bit today around monitoring so and I don't just mean after deployment but almost through the entire spectrum of development and deployment of you know how do we check from an ethical perspective that we're not bringing in unintended consequences bias drift that we're not what we thought was fit above us and we've gone through that process isn't moving away from where we were so they're really starting to help with that continually watching how things are evolving and moving and changing over time good well I'm glad we were able to help with the first already that's great so and I'll be excited to hear your feedback so I want to spend the last part of our time talking about an experience that we we had recently together and as as I spoke about earlier we have this process that we use to evaluate all of our work and we recently had what I thought was a great experience of actually doing that jointly with HSBC and that was the first time we've done that and and it was really exciting for us to be able to have that kind of conversation with a customer which you know in many ways is a very vulnerable space to be because you are that is having a conversation where you're really asking yourself about what could the possible intended or unintended and in particular the unintended impacts of you work be and having that conversation with a customer can be can feel a little unnerving but it was quite exciting so I'd love to hear from you what what did you expect when you joined that conversation and was the outcome different from what you expected it was fascinating actually and we were invited down to your office to talk about some of the work that we're partnering on and and and how we all thought about it from an ethics and responsibility perspective and I'm I'm not sure I've went in with any specific expectations but firstly it was really great for us because you know we work with Google on you know a number of projects innovating and trying to make life better for our customers and and we do only really want to partner with people that have a similar kind of focus on responsibility and ethics in this space so getting involved in your machine and seeing a little bit more about about how you work on it was was really fascinating I think if I had to take away one point it would be that having a number of different people who are all talking about the same project actually coming from such different places so you know we had the bankers and then we had you guys but then weren't even within those teams we had different specialisms and and what I found was the range of potential issues that we needed to think about just grew and grew and grew more than I thought it would and that makes it sound bad but it was that the point mentioned earlier about having diversity of thought you know in this space getting everything out on the table and then being able to say right now let's address it let's think about what serious that was really invaluable and there were lots of things that came out in that debate that I don't think either of us kind of expected to see and so that was the one thing that I took away was you know it's Sookie and in your own little world you're not necessarily going to get all the answers and engaging different people and getting more thoughts on the table was was fascinating that's great to hear I and truly you know I mean I think we've been we've been doing these for well over a year and a half and I can't think of one of those conversations where we didn't encounter new things to think about or have new ideas of how to address them in the room and because of that that group and so for us the experience of expanding that to have you there was it was really wonderful so I hope we get to do it again yeah and I thought one of our most interesting points of conversation was actually we spend a lot of time talking about unfair bias and potential pitfalls but actually we had a great conversation about a positive yep because we were saying you know it's not all doom and gloom with some of the things we're working on you know we may actually be able to tackle unfair bias that exists at the moment at right and turn it round and we were talking about that in the concept of financial inclusion and saying if we can build these systems right so that we can really identify legitimate customers and legitimate customer needs we may able to might be able to offer products which are outside our risk tolerance at the moment and actually that starts dealing with a you know a really serious issue of financial exclusion so when you start throwing around the ideas we haven't necessarily thought about that from an ethical perspective we've just seen it as a benefit but when you start throwing the ideas around we were like you know this is key as well we mustn't always go down the yep let's always look for the the cons let's look at the pros as well yes and I also think that's in such an incredible outcome of these kinds of conversations is that you start to realize that there are ways that you can tackle these challenges that can provide incredible benefit if you end the idea of being able to work with customers like hsbc so that you can then really transform your industry is such an exciting opportunity and you know it's one that we we're just endlessly excited about and I know this is something that HSBC is been thinking about for quite some time and we've had lots of conversations but it was really exciting for us and hope we we get to have lots more so we are at the end of our time I hope everybody has enjoyed this conversation I certainly have thank you to all of our panelists for joining us today on this incredibly important set of topics and I hope everybody has a great evening and we'll see you tomorrow thank you so much [Music] 