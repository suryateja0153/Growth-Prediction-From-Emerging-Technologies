 Hello and welcome. I am Caglayan Arkan, Global Lead for the Manufacturing and Resources Industry at Microsoft. In this episode of Digital Empowerment, we are continuing our discussion around the potential of AI to help us build a better, more responsible and more sustainable world. Microsoft's Indranil Sircar and Ted Way joined us last time to demonstrate just how powerful AI can be, when it comes to enabling intelligent manufacturing and a sustainable future. Today, we will look at the important questions around ethics and trust when it comes to AI. This is Digital Empowerment. I am joined here today by Nick Tsilas, our Senior Attorney for Manufacturing and Growth Industries here at Microsoft. Nick, welcome to the discussion.  Thank you Caglayan, it's my pleasure.  Nick as useful as AI is, we at Microsoft must be realistic about the challenges that AI will also raise. We do not believe that we can afford to look at this AI future with uncritical eyes really. Microsoft has spent a lot of time thinking about how to design and deliver AI in a way that is responsible.  You are absolutely correct Caglayan.  Essentially with AI, we're now empowering computers to make decisions that have previously been made by us humans, and so as computers behave more like humans, it is important to think about the impacts they will have on people and the ethics that should underpin AI, because every ethical question that has ever been faced by humanity is now an ethical question that we need to think about in relation to computing. Can you tell us more about what Microsoft is doing to guide the development and deployment of AI around the ethical framework?  Ultimately for AI to be trustworthy, we believe it must be human-centered, meaning designed in a way that augments human ingenuity and capabilities. Designing AI to be trustworthy also requires creating solutions that reflect ethical principles, that are deeply rooted in important and timeless values. As we've thought about it, we focused on six design principles that we believe should guide the development of AI. Specifically AI systems should treat all people fairly, they should be inclusive to empower and engage everyone, they should perform reliably and safely and be transparent, they should be secure and respect privacy, and lastly, they should have an algorithmic accountability to prevent unintended harm.  These principles are really critical Nick to addressing the societal impacts of AI, and building trust as the technology becomes more and more a part of the products and services that people use at work and at home every day.  Yes. Ultimately these six principles need to be integrated into ongoing operations, if they're to be effective.  Indeed. The more we build an understanding of these or similar principles and the more technology developers and users can share best practices to implement them, the better served the world will be, as we begin to contemplate society rules to govern AI. Okay. So, in addition to these six AI design principles, the other aspect to our leadership agenda is trust. To help us deliver products and services that customers can trust, we've established a set of principles across our engineering, our legal and our compliance work. So, tell us more please.  Yes. To earn the trust of our customers, we have pledged to build Microsoft cloud services on several foundational principles: security, privacy and control, transparency, compliance and reliability. I'll touch on just a few. First, we take security very seriously, we spent over a billion dollars a year on security practices and technology. For privacy and control, we invest heavily in technology development and practices to ensure we actively protect our customer's privacy and provide the necessary tools to control both the privacy and administrative aspects of the data they put in the Cloud. GDPR compliance on Microsoft cloud is a great example of that. Transparency also plays an important role in developing trust. We work tirelessly to increase not only our own transparency, but the transparency of the industry and its regulators.  Another key differentiator for us Nick is in terms of trust, is our IP sharing program, customers love this from us. Every company today is becoming, in part, a software company, as they create new digital products and services that run on our platform. This program has really accelerated how we co-innovate with them to help them transform their businesses.  Yes. AI and digital transformation are only accelerating this phenomenon. We call this our Shared Innovation Initiative, and it's based on a set of principles designed to address co-created technology and intellectual property issues that give customers clarity and confidence, regarding their work with Microsoft.  These are all very important principles and ones that we hold ourselves accountable for every day. We feel very proud and very well differentiated here, but we know that we cannot do this alone, no company can do this alone. Continuing collaboration between government, business, civil society, and academic researchers will be essential to help us shape and develop a trustworthy AI.  Yes. Ongoing dialogues among these stakeholders will help identify and prioritize issues of societal importance, enable further research and development of solutions and sharing of best practices as new issues emerge and where appropriate, shape policy that can more readily adapt to these rapidly evolving technologies. AI technology won't be created by the tech sector alone. The tech sector will not necessarily know how best to address the role AI should play in society. So, we all need to come together to help shape this future and increasingly, we need to do this not just in a single community or country, but on a global basis. Each of us has a responsibility to participate and an important role to play.  We also need to look at the way that AI will change our workforce, another vital topic. Will AI now create more jobs than it will eliminate? How do we think about the new education and training that people need to be prepared for tomorrow's jobs? How do we help businesses to get access to the talent they need to succeed?  All great question Caglayan. To enable people to thrive in today's economy and prepare for tomorrow's, we believe it's critical to help our workers gain skills that are relevant in the changing workplace, as well as prepare today's students through equitable access to computer science. As jobs increasingly require technology skills, companies compete for the employees who have specialized skills supporting digital capabilities such as robotics, augmented reality computations, cybersecurity and data science. To help companies find qualified employees and enable workers to find jobs, will seek credential-based workforce systems emerge that use qualifications, that are widely recognized and valued by employers. To enable innovation and to protect workers, legal certainty must be created so that workers and businesses understand their rights and obligations in the new on-demand economy. Lastly, business leaders have an opportunity to play a significant role in reshaping employment policy in the emerging economy by setting their own standards for on-demand engagements that include fair pay and treatment for on-demand workers.  It is very clear that there's a lot of work to be done to really open up a new societal mindset in terms of how we think about preparing our future workforce in the year of AI. So how do you see AI laws and policies evolving?  That's right Caglayan. We're living in a world where the skills we all need to be successful are constantly changing. From a regulatory and legal perspective, AI feels a lot like privacy law did in 1998. Some existing laws already applied to AI, especially tort and privacy law, and we're starting to see draft regulations in some new areas such as, connected and autonomous vehicles. We don't have all the answers, but we're fortunate to work every day with people who are asking the right questions. As they point out, AI technology needs to continue to develop and mature before rules can be crafted to govern it. A consensus needs to be reached about societal principles and values to govern AI development and use. We will then be in a better position for governments to create legal rules and regulations. We'll need to learn together and with a strong commitment to broad social responsibility. Ultimately, the question is not only what computers can do, it's what computers should do.  Very well said Nick, I'd like to thank you for this thought-provoking discussion today. Indeed, AI is the defining technology of our time, impacting every industry and every business. In this short series, we shared a few examples of how deep and transformative the power of AI is today, not only in manufacturing, but within our society at large. I believe we have just scratched the surface of what is possible and what is to come.  It's really exciting Caglayan.  Thank you very much for joining us here today. 