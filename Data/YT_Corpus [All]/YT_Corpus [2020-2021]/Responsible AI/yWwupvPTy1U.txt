 Hi everyone my name is Alentina. I'm a PhD candidate at the University of Cambridge researching organizational behavior, artificial intelligence, and the future of work. Today's video is on AI hype. Often when we hear about artificial intelligence the narrative tends to be slightly exaggerated, to say the least! We either hear about how AI is going to help solve the world's most pressing problems or how it's going to destroy humanity as we know it, cause mass unemployment, and threaten our existence. But the reality is very different from what is portrayed through media. So then we have to ask ourselves, what's the deal with all this hype? Why has this narrative been pushed forward? And more importantly, why are we prone to believing it? If you've been following research on artificial intelligence, then you're quite aware of all the progress that's been made in the field. But the problem is that a realistic view of progress tends to stay within small academic and industry circles. And what's portrayed to the general public is an exaggerated version skewed for likes, clicks, and attention. And this is a major problem because 1) it creates unrealistic expectations and 2) it's a major disservice to the field. So let's look at these! When we create unrealistic expectations it often leads to disappointment and we don't want that. Because when we put too much emphasis on what it could do we take the conversation away from what it actually does do, and so our expectations of AI and the reality of AI are no longer aligned. And when I say overhype leads to disappointment it's not just on the micro level of how we'll be disappointed if we don't have our own personal robots but it's much more complex and the consequences more severe. We don't need to look too far back into history to see how similar technological hype has led to not only company loss but economic crashes as well, as was the case with the 90;s dot com boom. The problem is that media is so pervasive in promoting hype and getting our attention, bombarding us with the latest and greatest, that we don't take a moment to step back and see how the last over-promised technology actually underdelivered. And this gets us to our second point of how over-hyping and overselling AI is a major disservice to the field. For those who may be familiar with the history of AI you'll recall the winters that it's gone through in the 60s 80s and early 2000s. For those who may not know, the gist of it is that these AI winters refer to the years of decline and defunding that followed initial years of great investment and enthusiasm, kind of like the excitement and hype that we're experiencing today. I don't remember the details from the last AI winter but seeing how AI is currently being marketed and promoted, I often wonder if perhaps we hyped it up to this level and that that was a contributing factor to the decline and defunding that ensued. Of course, it wouldn't be the only factor because since then we've had significant advancements in hardware, software, data, and cloud storage. And whether or not an AI winter is coming, the premise of creating unrealistic expectations of a tech utopia and the consequences of unrealized expectations remains to be true. Now let's turn to the human side of things to understand why the overhyped narrative has been successful. We have to ask, why are we so susceptible to it? Humans are drawn to stories, especially ones that are a bit outlandish, stories that allow our minds to wander into a place that's different from our current reality. It gives us something interesting to think about, something to fantasize about. And especially in a time when social media has disrupted our dopamine levels, we've become a bit desensitized and seek for things to give us the dopamine spike we so desperately crave. But even if we're just looking for something novel and cool, couldn't we decipher between what's real and what's a far cry from reality? We should, but there's a bit of a complexity bias here. When something is difficult to conceive and jargon-heavy, we tend to accept it as correct even when we don't fully understand it. And we tend to give undue importance and value to complex things because complexity equals sophistication, right? And even if we wanted to, our limited cognitive capabilities make it impossible for us to process all the information that's fed to us and especially not at the rate that it's being fed to us. And because we simply don't have the processing power to assess all this complexity with full rationality our brains operate within the limits of bounded rationality. What bounded rationality is is this process of creating simplified mental models so that we can think and behave within those limits so that we don't become overwhelmed or paralyzed in our decision making. I've personally experienced this whole notion of AI being overhyped and exaggerated at conferences, talks, and meetings. When socializing with people, what I'm often told is "our company is an AI company" or "our start-up uses AI." And being a PhD student who is particularly interested in researching the use and implementation of AI, I get super excited and start asking all these questions. And if i'm completely honest, the more specific my questions get about what techniques or algorithm or data they're using then it tends to be more like "well, we're still working on our AI models," and it turns out that they're just using standard computational models. And there's nothing wrong with using standard models but this current societal trend of exaggerating or misrepresenting something to get more air time or sales or approval is a problem. And of course it would be a lot easier if everyone was a bit more honest but we don't live in an ideal world so we just have to get better at spotting it and building skills to tackle it. I was recently speaking to a VC about this because I was curious to know if this is across the board or if this was just something that I was experiencing because maybe I wasn't asking the right questions and it turns out it's quite common. Reflecting on this has been a great learning experience and has taught me how to spot it more quickly and how to better approach it. Drawing from my research and experience, I'm creating this channel to share these findings so that you too can become more aware of not just the topic of AI because I think we already hear about that everywhere and constantly, but more so in the nuances of AI and to know how to ask all the right questions whether you're interested in creating AI, researching AI, investing in it, or just simply keeping up to date for personal and professional development. So now that we've covered why there's so much hype, how it's a problem, and why we still get fooled by it, let's end this video touching on some things we can do because essentially, in one way or another, we're all responsible for it. The first step is to have a better understanding of what the capabilities are. Will our jobs be replaced by artificial intelligence? Sure, some will. But definitely not all. Because even though AI has come a long way and it's automated more tasks than before in more domains than before AI is still very specialized. So the question we should be asking ourselves is, which part of our jobs can be automated? And then knowing this information, how can we build better skills and resources so that we're prepared for more job stability. Because if we think through these things in advance then we're not only better prepared but also more mentally calm and aware. And in this state of mind, the unnecessary fear-mongering articles and news reports won't phase us. Thank you so much for spending a part of your day with me. If you learned one new thing in this video, then please consider liking and subscribing and most importantly sharing it with your friends! Wishing you a wonderful day! Goodbye :)  