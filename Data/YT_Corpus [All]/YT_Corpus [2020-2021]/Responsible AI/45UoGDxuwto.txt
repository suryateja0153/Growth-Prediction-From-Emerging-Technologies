 [Music] hello everyone okay this is the last session right after the session you may go back to home what I may have a some drink with my prayer nice to meet you my name is Terry a customer here from the cloud team it is the early honor to introduce our respectable-looking use-case Sam saw people I introduced our customer I will briefly introduce logging itself and stackdriver okay let's start so what is logging logging is catering event and the information to see the state of the system just appears ago we just used logging for the troubleshooting and the debugging and we collect the log into the single PI and the majority by using the tailing comment right but logging can be used for the multiple purpose for example for developer low can be used for the debugging and code optimization for the system engineer it can be used for the health check and the system monitoring protocol changing it can be used to protect the system to find the abnormal behavior and nowadays data engine is being more important so the data are complicated through the row to find the inside from to find the inside in this listen we need to collect more logs from the Piraeus layer for example we can collect the CPU and memory status from the infrastructure and waist level and we can get us web access law from the web server or database also we can collect a load from the usual application this globe which can be used for the multiple purpose like business analytics auditing filling sums right there because of the we need more footy terminal okay until I until ow it may be okay but the power means system is being moved to the distributed architecture like a Microsoft right cause of that it may have a lot of loci so with a single motor we cannot monitor the horror blow so what is the solution the solution is we can use more and more more multiple monitors right but actually it is another technical solution so I will introduce a technical solution to monitor the distributed architecture here is the general architecture of the local system we can collect a log from the system and the send it into the message queue like a cop car and appear in the message queue we can consume the log the collected log will stored into the lower storage system for the archiving purpose and the log will be indexed by using the index for the social purpose so user can search he and the buter law but the problem is as I mentioned the law can be used for the multiple purpose like data analytics or the system notification and nowadays machine learning is more being imported so the log data log data can be concerned by the machine learning system to train the model right this system can be implemented by yourself whether you can implement this system by compositing multiple open source but the problem is it takes a long time to learn build and you can also bring operation of overawed so what is the solution Google has a stack tribal structure IVA is operation and the monitoring system it combines logging monitoring debugging trace etc if you didn't have a chance to investigate structure of I strongly recommend you to be get demo boost I saw that there are a lot of state driver demo it is the only real awesome tool in addition so stock driver can learn over the multiple cloud infrastructure including the Google cloud and our modern recipes today I will just focus on the logging on the in the state tribal or logging you can suppose the logo collection post it can collect a logo by using the SDK or some agent the collected log will be stored and it can be searched and the butte in the poutine sector i will login console and collected law can be laude to the multiple destination state level can be worked like a low growl router for example it is very similar to the cop kind open source from the logo pie we can extract the metric for example we can count the number of the error whether we can extract the overall response time of our service with de pint is nightly we can also define the notification for example if we have a some number of an incident you can send us a notification message to the system operator by using the email or the SMS or pager to change line and the last thing is a local management for the multiple project now this as I mentioned the system architecture is being changed to the distributed way so the plication can be deployed into the multiple cloud project in case of Google and the multiple account in case of Amazon if we have to monitor the all over all in different project and the different cloud console it may be very very painful so the stack driver can collect all up log into the single place and you can monitor the all log in a single player of plans okay let T type each of log it's your picture the first thing is how we collect a log the sector I will provide the SDK the SDK can be easily integrated with the well-known logging frame for example you know in case of Java SL puja and the logo bag is usually used this is such a valid answer as you can see okay as you can see you know there are no code changes you just simply change the maven dependencies - injects a stick driver looking library it is really easy but unfortunately sometimes we need a collector load from the beauty in solution like a database or the web server or sometimes you're looking Prairie mod cannot be supported by the stock driver in the case we can use the stick driver agent which is based on the flow into the open source agent so you can collect a load from the PI by using this agent after you collect a log you can easily search here and the view the logo by using the spectral log impute in concern is still the easier and you can also support a coronary directly so after Luke has been collected as I mentioned for the multiple purpose users it can be loaded to the multiple destination like Google Cloud through G it is photo log archiving proposed and the pop so can be used for the low streaming so the behind the pop so you can put the real time in our system were some transformation system for the data formatting were you can export a login to the bakery for the data analytics you can export the law to the multiple destination based on the cue trainer so it means that you can selectively export a load to the multiple destination in addition basically stick trouble logging pricing is based on those stored alongside if you have to throw a lot of low it can bring a cost issue so the structure of also property exclusion filter which means that you can selectively store the law based on the filter and you can save the cost nowadays the logging has more meaningful I mean that a few years ago we just looking for the troubleshooting so the text message was enough but the developer tried konchem doesn't era like a user ID and the transaction ID price from the log in the case the structure logging permit is more effective like JSON from Edward CSV Pune secretary will support our JSON formatting but this is a note that is example if we you write a log with a simple net it is automatically mapped to the JSON payload element in the structure below entry and if we exported this JSON log into the big query each element in the JSON payload will be mapped to the column in the pakora table so it helps you to more sociable and a little from the strode over we can define the metric we already have a some pretty panda metric which is called as a system a tree we can get a data like a byte count toward a number of logo entry but if you want to collect a specific information from the your log you can define a custom log in two ways the first way is the contem a tree it is the simple contem a tree but it you can define the sum condition for example I want to collect a number of laws that latency is over than the 1.0 second and the other way is distribution metric it occurs the statistical distribution like a standard deviation some averaging it can be used for the for example you can collect the average response time of the your service and then is the exam how you define the metric religion and with the T symmetry you can visualize the metric by using the Kraft through the state tribal monitoring console it is one of the example of the web response time and this is a hit makrand you can get a some insight about your system status register after we define the metric we can make us a loading system with predefined the road sector evolve ascend doesn't notification to the paralysis destination from the emails SMS and you can send a notification to the your application through the pops up q last one is a centralized logging as I mentioned in Microsoft's architecture ET service can be deployed to the tip on the system and different project in google and the deeper and Amazon account so the collecting the log into the some centralized system is very very important so sector eyeball can collect oral log into the one ccp project and the can provide the single plane of the glass for the long winter okay until now we quickly look through the logging system with a strict driver but logging system can be extended for pariahs purpose like a potato in our case it is a way how we can extend the logging system in the other world when we try to use the load data for the big data analytics actual there is be a little tea I mean that it doesn't follow the format and it doesn't follow the tight sometimes and sometimes the fluid is no so we need a data validation and the transformation inspector over we can export the logging into the topsail behind the sectarian and the commissioned by the data flow data flow is open-source version of the Apache which is very similar to the Apache stock streaming and you can be used for the PT tonalities so you can put a some validation and the transformation logic in the Google data flow but unfortunately data flow is require some coding by using the Java and the Tizen it because a little bit tiny learning curve however instead of the your manual coding stick driver provide a template picture it means that you don't need to code by clicking by a number of clicking in the Google Cloud console you can make all data ingestion pipeline in addition if you need as some transformation logic you can simply implement it by using javascript which is named the UDF user-defined function so the user-defined function can be unloaded to the TGS without any packaging like cherry pie in the Java so you just simply unload it and point it out from the theta proconsul during the dataflow run it will pull the transformation logic and converts the data format by using the tape stackdriver login we can collect a log from the server side but in big data analytics world we wanted to collect all of user journey from the advertisement marketing mobile lab poetry Google provided a solution for mobile firebase varieties can gather to all of user event information and ascended into the picori and the pro web you know Google energies can collect all of user event from the website in addition the quarry is served has a lot of data connector you know we can collect the advertisement network tailor Google Play and YouTube data as I know the in this week Google announced that Pico the additional connector through the partner so now we can collect over than 100 data source across SNS advertisement and the legacy system so all over data can be stored in the pit corriander you can analyze the user behavior from end to end it is really cool isn't it no thank you ok the other problem in the microservice architecture is correlation of the logo LeConte the problem is let's say that the usual a send the request to the user service and they either write log into local PI system and the you do send the leakage to the other service like a service item service usually also called same thing but the problem is I want to track a sleek Estonian so how can we do correlate the user service and the items of its law the way is we can put some correlation ID which is trace ID so when usual calls the user service it will automatically generate the trace ID and the soil into the log together and the user service and the record to the items of it this tracer ID will be propagated together and the right into the logo pad so by using this trace ID you can correlate the logo entry from between the different services you can implement it by yourself but fortunately there are open source named seeking if you are interested she can open source into your login system it will automatically create the trace ID and the propagator ID to the other system and the trace ID also will automatically return to the Europan together I'm sure the chicken is not a logging system it is originally designed to support the distributed system trace it means that you can trace the latency in history bill system by in trouble provision by call the service usual service and I item service but I don't know where is the butler how long time does it take spa DT service after utk integration state terrible also support the chicken by using stick driver trace stick toy boat race will collect at least Leighton's in Drayton's information and the visualize by using great like this one this is really good but the problem is to use a cheap King you need to inject your chicken suits code to your application but I wanted to collect the other system latency which cannot be injected by the simple example database web server but I want to check the trace in the case we can resolve this problem in the infrastructure area instead of fixing the code we can put some proxy in front of the service which is my proxy it is very much a she and she proxy but in the micro service world we need to develop a lot of fraction in front of each of service instead of that is to use mainly service mainly the amboy service it can automatically indexed or m'boy in front of your service so the livery the list of the application program language you can collect all of trace log and this trace log can be integrated with the state driver service monitoring as you can see you know that in the Microsoft circuits the topology and the service dependency is really really complicated but it shows the topology like this one and it also provides the important information like all response time I raise sheep utilisation that's right okay final thing is of personal information personal information is very very sensitive right if we - it will store the personal information to the store it is originally designed for the personal information handling email a type of trouble but sometimes unexpectedly the PII while user information can be stored in your logging system it is critical to prevent that we can use the DLP API data loss prevention which is based on the Google motional in technology it can automatically detect the user information like social security number or some other information and you can anonymize what has she make it as a hash table hash value so the you can prevent the personal information to be stored in the logging system okay from last year by using the stackdriver logging Sansa started to move to the innovation to a sari and the Devas Fort Davis Devas practice so today I we introduced head over Samsung mobile operation system synonym to stage is you thank you all right it's great to be here it's honored to be actually present on my presentation you know Google next coming to this large of tech conference for me is really a treat for me and I remember my first big conference was about nine years ago and I was infrastructure engineers of this engineer with the big software company and at the time this was about the cloud conference and I was really it was really eye-opening for me because as a infrastructure engineers whenever an engineering team asked me to deploy provision news over in the traditional data center it takes about three months it's I think like its industry standard whenever you try to deploy news over in a traditional data center it takes about three months but then you know in a disc conference they tell me I can provisioning you know number of servers in a ten minute less than ten minutes right and it was like you know this is what where I need to be right with my courier I want to be in a cloud and I'm trying to do more of work you know makes my life easier and helping our engineering team as well I that sort of feeling I had with the Google next this year as well I when I hear about Antos you know it was like you know new war from you as well because I've been trying to move over some of our legacy system into a container lies it and be more efficient more flexible and you know it was really hard to get a you know a lot of time from our engineering team asking code changes right but in this end hose were able to do that without code changes and it's free right so it's really great to have those kind of future coming to industry as well but uh let me okay so uh have you guys heard company names Samsung Electronics right okay good I'm pretty sure you guys know about Samsung electronic we create or bill pre awesome consumer electronics including handset devices right very you know innovative and you know we have a list of business inside of Samsung Electronics but then a Samsung back in Korea Samsung it's not only about you know consumer electronic manufacturer we are in business of construction insurance and theme park hotel and you know many more of a business really Nana's in Korea so it's they Sarah it's easier to list out the business that Samsung is not in compared to you know we are in this huge technical a technology company is has a tremendous value in the their name and for the most of the college graduate it is dream job to come in into a Samsung and work for the company because one of the reason is you know good pay of course and you know provides job security the reason is that such we have such a big Pro folio of you know business sector that if there's a downturn in on one business we can ship those people we don't have to lay people off what that mean is we ship those you know some of those people moving into another business sector so you know with your Samsung with the big company you have a pretty good level of a job security as well and support or some of the folks it'll be great opportunity to work in a global environment you get to talk to a lot of a global smart people and you know try to learn your way in a career trying to understand from the global environment so that's another advantage you know those college kids wants to have as well but then I'm pretty sure it was only reason that Samsung is also starting to be known as a service company so I have a list of this application service that we are running trying to add more value to our smartphone devices for example Samsung pay is you know for in my opinion most innovative service that we ever created in a samsung electronic providing digital eyes a credit card or a bank card into your phone and you can virtually pay using this phone you can pay anywhere that you want to pay including you know if this point-of-sale device only accept the MST which is a maganet Ogoni you can still use some some pay devices and some some pay services to pay with it it's huge success in the Korea and some other of the country as well we have a Samsung Account where Samsung past which is a biometric authentication mechanism where you know as long as you have a thumb and you know what first you know when you act trying to access an you know network resource with your login information and password after that information safely into the phone you don't have to memorize that anymore right so that informations securely safe into your devices all you need is a thumbprint to access any of your network resources and we are also in a b2b business and we provide ad like activity tree like you know solution for Android devices trying to work with the our partner in the different business sector let's I'm gonna show you a little bit more about the samsung AI system call or Bixby say hi to the new Bigsby Samsung's intelligent assistant hi big speech what's all my schedule this afternoon you have one event scheduled today at 1 o'clock p.m. meeting with pattern maker change this event on to 2 p.m. I'll set I save the events [Music] hi pixy fine italian restaurants nearby here are some italian restaurants nearby give me a table for three today at Luciano's at 1 p.m. you're all set for lunch [Music] vixie give me an over to work the fair for this ride will be twenty one dollars and 72 cents ready to request right perfect [Music] Isaac speaks its runtime okay turning on Bluetooth starting a run in samsung health clean run playlist [Music] alright that's about the fix P today about 57 millions registered users are utilizing bixby services and with the latest version of the big city service we are supporting a Korean English and Chinese and only this year we added five more languages that most of European uses it today and this year next year we're going to keep on expanding supporting different languages on the global and now with 2.0 changes that we made with the big huge change is we are trying to open up our AI system to our partners we provide the same tool machine learning tools that we are using in our internal and we're providing out to our partner to utilize that as well and not only popular is partner as long as you are developer and as long as you know how to use our tool you should be able to integrate with the depicts be sort of like you know a player Play Store that you can upload your app into a place or you can do the similar thing with the Bigsby the Bachmann portals so to find out mobile from the exhibit department portal if you wanna reach 57 million or users before your business and including is not only the handset device you will be TV and refrigerator any you know consumer electronic device can connect to our network we will you know integrate with your picks be in the future you know next my colleague Joe Gyung will be explaining about the what what are the challenges we've been having managing big CB you know big size of lock with the 50-plus size of micro services we are learning today and then how stackdriver help us to addressing some of those problem hello everyone my name is giorgia and i'm the devops member in HP project it's really honored to present my experience here I hope that our small the experience can give you that they could the opportunity to understand how we are overcome that situation about the logging and it will be a good technical reference for you yeah let's get into the background actually we have the the new of Pixma services now and previous it means that previously we have another a big service usually when we call about the logging system the logging system is usually for the debugging and the monitoring and also the analysis purpose too but with the small size of the project or the services can consider that maybe just to use the e lk for the logging system or some kind of this open source of solutions to overcome the situation however the some services that is for customer service or the large scale services always use try to build their own logging system that is for the reliability and scalability - and currently the pics be new pics be the log data is almost a 1.5 terabyte per day and we have to think about that how much how we can satisfy that at the real-time monitoring with using that our current internal logging system and also we have to do guarantee that the reliability and scalability - for the customer services so when we think about the previous day log previous logging system in XP services the major key point was that logging for debugging and the other one is the cost saving point actually the previous internal logging system was developed by ourselves and that that means that that is not as you are the known solutions in their market it was a designed in our side and developed in the our development team and that is a deploy to the or the clouds cloud infrastructure and mostly all requirement was as driven by the our internal users so it is more easy to satisfy the old requirement when we develop ourselves for the logging system however when we want to add new features like the tracing or equally testing then we have to change every infrastructure under the design concept of the logging system but that system was not designed at that time and simply they log that all log messages into a logging system and simple monitoring was only supported by the graph on ax so we have some challenges how we can provide that the tracing and mechanisms to the developers to give some the health how they can debug their issues when some issues are detected in their own applications and indeed when we are adding the new logging system into our cloud infrastructure and that goes the more complex that complex complexity of the system goes much higher than we expected and it is not easy to adding new features to the newer logging system as well as the cost is also cause of high and that the cost was the one of the big challenges for us to reduce the infra costing fee so that is the major ly truly quest for the dab of scheme site and we have to change or we have to find out any solutions available in the market so we get a some suggestion from the other team and that was not the from the Google actually we searched that the Aztec driver in the Google at the web site and we found that we have to check that what is our key feature for providing that a new logging system so firstly we have to think about the real-time monitoring stack drivers default that real-time monitoring is based on the log based on metrics so as well as the login system as using this truck driver it also can support it the real-time monitoring but it is also is provided easy ways to integrate with the other monitoring solutions we in the pics be one at all we have another the internal monitoring solution and that is also helped to be continuous continuously to use for our operations so we have to check that whether this tech driver can support that the third party integrated party monitoring solution integration and we can guarantee that that is impossible and the second the most of the important thing was was the on the login system is the experience of debugging so now a free vyas login system when the developers want to search the any logs only the application driven logs can be searched at the time the one problem was all the developers cannot make the standard log format at a time and huge number of developers in samsung was involved in this Bixby development and they made their own style to remain love messages it doesn't show any related love messages for debugging purpose so it means that developers want to check that whether his new detected issue is belongs to tear for problem or to another another another modules problem we have to provide any tracing mechanisms to developers to eat for a provider providing the easy ways to search the the love messages for debugging so when we check that this tech driver it also can support that the tracing mechanisms as using the automated trace however it cannot be applied to our internal the requirement actually if we want to add that the auto created the tracing ID we have to appreciate all the developers to apply that requirement through the pair source code it is not easy I think the as some of you are the work in their big company the big company have the several the organizations and even though that organization is only belongs to the development development team have their own strategy and the policies it is not easy to adding the new code for only the tracing did the tracing purpose into their code because they just worry that any side effect and any the performance degradation due to the adding the new the mechanisms to their own code so we have to make sure that tracing is also need to be adding the news the logging system and the we made a new standard love format to apply that the stack driver and secondly previous logging system also provides that the analytics of the system it means that some of the log messages should be gathered and that is sent to the another analytics platform and that platform is gathering all data and providing that analysis data we have to make sure that the stack driver have to support that and we had a check that whether that is available so after checking that all requirement we can go with the stack driver without any building the internal logging system internal logging system usually require too much report to develop and also we cannot satisfy that all the project milestone to go forward so now we could do that we have to do that about that the love form and standardization to to satisfy that the tracing purpose the other one is that usually when we built a new logging system always we have to think about the user management so when we use this tech driver all the user the authentications or user management is under covered by the I am policy and the stack driver loves logo pure is basically supported so that every users who are cats and career are the permissions to access the log of Europe pages then they can immediately search that the log messages from the console excessive by the access in the console and mostly important thing is that some of the the whole the infra related system metrics is automatically that they created by the stack driver agent and it is sending to the sect driver services but we also need to other another the custom metrics to for from which is generated from the application side so detect one of the big child or big things about the stack driver is that they can support at local based metrics and they even if we can communicate with the other application developers and we can define that any metrics in two metrics in that log messages then it can gather it by the filtered the log base in metric and it is the one of the materials for the operation and monitoring so now we have the simple diagram so all those which is a stored in the each modules is like gathering by the servers and it by from the spec driver logging agent do that all the data is gathering and the transfer that data to these the stack driver service and then we can integrate with the data one of the our major or the monitoring solution and that is gathering there all the love based metrics and it can show that the one unified format of the dashboard it is the currently we are not going to the a solid practice yet so we have the transitional operation practices now so that every tier 1 and tier 2 and even the order 3 is using that to get us some the any issue detection by the our own dashboard also we also use data stack driver monitoring tool to because the that dashboard also providing that any custom the dashboard creation and that is also related with can be integrated with the other solution like the open source graph Anna and we have used this latch channel to notify every warning or the the complication for convenience and and if we can define that any some alert india's stackdriver and the data row then it can automatically send that the sec drive as select channel and then it can goes to the stakeholders to investigate any issue or for notified at any operation process basically the debugging is also can be available when we access to the log viewer and for analyst analytics purpose we are gathering that all the log messages and the filter them into the cloud storage google cloud storage services and it is going to the analytic system by pops up so finally we can say that after applying that the stack driver for logging system we can have enough for a number of the effectiveness after using data stack driver firstly we can talk about the cost saving we can say that more at least three times lower than a cost saving is possible when we open when we use this deck driver so it means that we don't need to think about any in changes or the maintaining maintaining the system only that we can give the any and all Apple to service reliability and scalability and it means that secondly we can the minimize that are all the workload so we don't need to think about any maintenance about logging system we can fully give the energy to service reliability 3 we when we use this deck driver we also realize that unified at this logging system can be applied to another project if we the data requirement is really similar with the Bixby project so that our in our operation team has much number of the services as which in mentioned so that if it is possible we can add in that the stick driver to the other services as the using the as the unified platform of the logging system finally we also even though we integrated with the analysis Texas system internally in Samsung but more better scalability and the another purpose of the data analysis is also it possible when we use in the bigquery so this is my the last the pages so I will back to dear Jean thank you [Applause] all right I know this is the last session and I know you are eager to go back to your you know home and so on but I will make it quickly as possible but this is my talk that I wanted to do practicing s re trying to make that happen in our environment as well so so some of challenges as in Samsung's life training we had I joined the company in 2013 I came from the large software company in base in Redmond Washington spent about 10 12 years there and I got hired by Samsung and move my family to a Korea and back then there's some other guys like me who came from a you know global esoteric software company and then Samsung wanted to make an environment where the software department management is kind of normal to our company because the company is not came from yourself their base and core business their core business is manufactured right so are they trying to create an environment try to create the you know culture of a software development but then you know as company put more investment on a software development we create more surface has go on as every time we add more service obviously there are more people to operate those services as well so as you know so but more being more add/edit to the production environment we need more people to operate and support those services the problem is we feel that we're not gonna able to justify ourself of growing rate of operation team any longer so we need to think about new way of operation still able to support a number of services coming into a production as I being with the Samsung I kinda lucky enough to witness all the changes being done in the software management inside of Samsung as well as you can see you know pops product right so we ship we release a flagship devices every six months like we have a series we have note series it takes about six months waterfall methodology off with development lifecycle kind of make sense and box product you know manufacture or system and we have all the important decision is being made by executives and since we have enough time of lifecycle of these products and you know obviously back then we have Yuri utilize a lot of traditional data centers who host our servers and all the system is sort of like a monolithic architecture system but then over the year we know we can you know do this type of many most management anymore with the service development so we change ourselves to a shelf coming from the waterfall where you know we break down all the tasks we're going to create a backlog and we're trying to fulfill back I'm going to give him the right engineer to actually responsible for those backlog and we run every spring and trying to ship out at the end of the shippable product to a production and all the decision is now made being made by a Pio or you know every key feature in production whether it needs to be going live or not being decide by our product owner and obviously some of our right now majority of our server are being hosted in a cloud unless there are compliance that to a server has to be you know a traditional data center and you know why going with the oddest pattern of the making break down each feature in the production it makes sense to architect ourselves as a micro services instead of the monolithic still in an old way of the department life cycle it as I mentioned we have six months of time on waterfall and we have we could have all the time every time we have new service coming in we can as an operation we can you know find ourselves to ask engineer team create an operation guide kb article and do the right training what's coming into a production environment and it all makes sense but then in a with the project managed by a gel and sprint we don't have that luxury anymore we don't have time to ask them or engineering engineering team does not have a time to provide all those information so we also have a conflict between business and the engineer and operation where our primary is providing in a stable service to our customer where engineering team trying to push new value to a production environment environment so we continuously having this conflict while we trying to solve this operation conflict and organizational challenge we were came close to chance to work with the Google engineer Google srid engineers and trying to learn more about SRA practice in in what how Google does their as our I practice in their in and we went through a lot of meetings and seminar with the Google engineers but then we realized that Samsung is not Google so what I mean is there we'd not we didn't came from you know software development company we came from the very you know process driven manufacture culture in our back of our mind so next thing that we did was okay so we understand what sre can give us what kind of benefit but then we need to answer how question how can we implement this practice to our environment so we start learning from other industry leader in practicing as already we learned from the Netflix LinkedIn Hoover and many others and they all have something in common too right so they break down to each kind of you know separate their what's putting into a production and separate the wolf who is should be responsible for addressing those issue they have a notion of you built it you run it so if there's a table who tried to push into a production and that person supposed to be know how to troubleshoot those issue not operation engineers so we really like those notion of the movement there as well so we came out with our own version of a sorry we we call it ourselves as a global service real our engineer and we break down to a different area of implementation what so so before pretty much every service that we are running today does have SLA we do have a key index of availability but then that's not enough for SRA practice we want to make sure we kind of break down to each function within their service and making sure each function does user impacting function does have a SLO SLI and also we want to make sure the error budget is being communicated with the engineering team so if you exhaust all your SLO there we will focus on you know making the reliable system instead of pushing new idea into a production these are the one of example above SLO document we have as I mentioned you know big sub is like such as a big CP have a different functionality capability within the service one of capability is a chart which translate the alterans to text so we create this template where we break and break it down to an application level as a ownership of that as a low is primary ownership of SLO is depth we have underneath primary ownership of operation which is us managing infrastructure libero SLO and one of the key point is infrastructure SLO is much tighter higher than application as a law obviously in application SLO could not be made if the underlying you know framework is not there yet right so that's why we're trying to kind of differentiate between operation primary responsibility and engineering primary responsibility with the help with the stack driver and data we were able to create the - bored just for that SLA so based on this SLA if there's a SL a SL or threatening event it is happening we can integrate with your data dog and slack and some other alerting mechanism we can give the order to write engineers and also that comes into a incident management as well in before we take traditional multi tier escalation path rights we have a Tier one tier two tier three which is you know essentially developers if you should happen to one can set and escalate the tio2 if they don't have enough information to how to troubleshoot and here to in operation side supposed to know you know most you know how feature is running in a production in the production environment but if you know name of the agile and the service you know as I mentioned there's always lack of information what's are running in a production in application level so we ended up you know calling developer or pretty much every time so if you think about SL all of three nine five for our bill ability you have only twenty two minutes of allowed a downtime so in the middle of night one of the incident happening like this it's easier it's easy to you lose about thirty minutes so for that month if we have a single instant you're violating it alone so you know we needed to take the different approaches in sree right so we try to pinpoint the actual error and do a better job in on logging we may not have to go through that here 1 and Q 2 if system generate the right information and go push into the push those all out to a right engineer it could be a developer because it's about you know even to is trying to violate the SLO for application you could go to infrastructure engineers if is violating some SLO that will prevail for a network rights for example so we can pinpoint the a a lot and we can finish up the doing you know the pipettes that it wanted here escalation there because I need to finish up with a quick deploy management we you know same idea we operation team used to own deployment of products and environment we call ourselves as as a production engineer right so we have ownership of making stable and color is therefore business looking and customers looking but then as we separately have with the SLO for developer and operation engineer now we are making the infrastructure as a code configuration as a code operation have ownership of pushing new changes if is a configuration and infrastructure diverse development team have ownership of pushing new code into a production in a that way you know we don't have to stop development to deploy new code into products and asking for bunch of kb article to how to troubleshoot thing because this is all loading when they push a new idea and there's if there's a problem the older team will go straight to a developer not to operation who has nothing knows nothing about those change in the code cultural changes the last thing but it's not listing this is the hardest thing to do right so we kind of communicate this to our leadership and they all get the idea and you know first comment was the of cultural innovation you need to talk to make sure all peoples in consents right so we starting to do a lot of ground back seminar with the different engineering team making pushing this idea and make sure they're on board and you know we ask for what we it needs to be happen and you know what help we're gonna be needing from them as well and some other thing that we did was we create a task force right so we create a task force or dedicated team to create your toolset right if we don't do a tion deployment we provide the pipeline the icd pipeline that a gradual change is embedded into a pipeline risk management is embedded as a pipeline that you know it's no brainer for a development team that if they've trying to push a new idea but if it's starting to having problem it's easier for them to rollback as well so we've trying to create a team providing this type of a tool to engineering team as well so say that same goes to with the logging and monitoring and a QA automation we don't have the QA automation security automation yet we have this multi plan organizational change and trying to fit into this model of sree and while we've prompt trying to provide all cross your same tool set for our sree we also have a service SLA who are actually working on the project trying to plug in those platform solution into actual services as well I can't really say all the benefit we are having right now because we are still only stage on the adapting asari but then you know we are kind of expecting to have a page of matter of visibility of our service with the measuring everything that what's happening in a production and reducing the mean time to recover obviously right so I'm trying to meet aslo and reduce the release time with your CI see the pipeline automation and optimize operation resource as well so I think this is my last session thank you for joining us and you may go to your family now [Music] 