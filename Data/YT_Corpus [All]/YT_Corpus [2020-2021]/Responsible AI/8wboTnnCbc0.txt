 Traditionally the constitutional position is that every individual is free to go about his or her own business without interference by the state and it's only if a police officer has reasonable grounds for suspicion that an individual then can be subject to police intervention of some kind. But the use of live facial recognition in my view fundamentally reverses that presumption it means that everybody is under suspicion and then it's up to you to justify that your behaviour is benign.  These technologies have the capacity to cause real harm and real adverse consequences it's absolutely vital that we have legal structures systems and legislative frameworks in place that can ensure that there is proper responsibility and accountability. As a lawyer and an ethicist, I am especially concerned about the unintended effects of these technologies particularly when you think about the scale at which they can be used and we now have global platforms that operate instantaneously around the world. If we don't attend to those implications I'm really concerned that we may discover that we're living in a world that's not quite the one that we would have wished for had we thought carefully about it at the time the technologies were starting to emerge. In relation to the criminal justice system we see in the US in particular the increasing turn to machine learning based data-driven predictive system so for predicting where we should send the police and increasingly to make predictions about whether or not a particular individual is a risk to the public and that's understood in terms of whether or not a particular person is considered likely to offend in the future within a particular time period. Although this sounds like a fantastic idea and if we could manage it I guess it would be fantastic, the problem is of course that in fact we don't have a reliable data set concerning where crime has actually taken place and by whom, instead what we have is a very flawed set of arrest data which will tell us who has been arrested for a suspected crime but it doesn't tell us who in fact has committed a crime because people who are arrested and not necessarily charged and those who were charged are not necessarily convicted and on top of that lots of crimes are committed for which no arrests are made so if we make predictions from a very sophisticated system that drawing on arrest data we have to be very very careful about what it is that these machines are actually predicting. Lots of public concerns about the increasing use of these powerful digital technologies have been captured in the phrase 'the need of AI ethics' but one of the real weaknesses of ethics is that it has no institutional system of enforcement. The law on the other hand is a very advanced established system for holding people to account to hold them responsible and without an institutional system for monitoring and enforcement then AI ethics will not achieve very much in providing real-world protection and that's why the role of the law is absolutely vital and needs to be a central part of these debates and discussions. 