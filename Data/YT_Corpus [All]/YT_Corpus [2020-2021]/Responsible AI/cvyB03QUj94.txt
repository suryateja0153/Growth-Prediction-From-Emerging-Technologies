 Unknown: The goal is to solve technological problems. And when we have to think of our values at the same time, it makes us more creative in the way that we develop our solutions. How did you train engineers and computer scientists in ethical reasoning, when that has not been a part of their discipline? I think kind of just taking a step back from you know, in terms of coming to the actual engineers, I think the way we think about you know, AI and you know, as we know that it has kind of really transformed from vision to reality. But with any technological innovation is always a challenge that comes up with new technologies. And so to realize that these are actual challenges and need to be implemented in the company, you know, you kind of have the framework there. And some of it is very much aligned to you know, like what you just mentioned, starting with the top down kind of sponsorship around really understanding what is the company values and then building ethics principles around that. The second down level is, you know, the business unit leaders need to kind of really push back into their organization, whether it's products or people or engineering or process. And then that the aspect about, you know, responsible AI is is that has to be a subject matter expertise and capability within the organization where you have subject matter expertise. folks coming in, looking at the principles looking at the products that are impacting customers and consumers and making sure that those principles are being operationalized into actions when it comes to releasing those products. At that level is when the engineers kind of start to kick in. And so going to your question around, how do you drive that kind of the culture there is obviously starting with the top down sponsorship, the overall climate and the challenges that we face with the AI systems, but also looking at the, you know, the entire software development lifecycle. And in each of those phases, the engineering team involved need to be aware of, you know, what it means to have ethics in AI. So, whether it's kind of writing the specifications or the requirements to getting the data sets which are trained by the AI, or which the AI systems are trained on to the AI in our testing it out validating the deployment and monitoring. So these phases, it's important to think about AI ethics in AI and make sure that the engineers just as part of their regular workflow and product lifecycle development is thought through. So it's not like a different workflow or something that they have to go do differently. But more in terms of the natural workflow when it comes for testing and validation the  ata sets, for example, is there ias in the data sets? Where di  it come from? What's the documentation? How do we  ake sure that it is tested fo in terms of the fairness of  ias issues or what have you. S if you do that upfront in the  ife cycle, then you save a lo of headaches later when AI sys ems are deplo 