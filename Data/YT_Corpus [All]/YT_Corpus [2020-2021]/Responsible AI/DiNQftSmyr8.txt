 [Music] hello and good morning thank you for joining us today I'm nisha sharma I'm a managing director in Accenture I've been in an Accenture for just over 20 years and worked on all sorts of different technology implementation projects for clients across several different industries I am currently part of our Accenture Google cloud business group which we formally launched last year at next and I oversee all of our offerings and offering development for the partnership and I based out of Miami Florida hi so I'm Deb Santiago and I'm based in Chicago I am the cool lead of our responsible a I practice at Accenture as well as a managing director in the legal department and so the way that it's gonna work today is we're gonna be she's gonna go and walk through our tech vision document and I'm going to respond provide some I guess some thoughts with respect to what we're anticipating for the next five years and what can we learn from the past five years that can help us navigate and manage our entry into these new worlds all right so every year Accenture publishes a technology vision this is our view of the top trends that we are seeing impacting our businesses today we talk about technology trends as well as business trends and how the use of technology is impacting what power clients and what businesses are doing we've been publishing the tech trend the tech vision every year for the past 19 years and we just recently published this year's 2019 tech vision in February so you know we thought we'd anchor this conversation around the responsible use of technology and the considerations of ethics around the future trends and what we see and where we're going because this gives us an opportunity to consider these as we deploy our our technology solutions so I'd like to start by asking you two questions just think about these questions first question is is technology good or bad I think about all the different technology that you've come across all the technology that you hear about is it good or is it bad and the second question I would ask you is what is your role what is our role what is our company's roles in influencing and determining whether technology is good or bad so let's take a look at some examples to kind of set the context for our discussion here today technology can be very scary to people there's a lot of negative news around technology and advancements in technology right who should be trusted with this technology who shouldn't be trusted with this technology is it ethical is it not ethical right it can be quite controversial even though we think there's some really advanced advanced implementations and advancements that we're seeing in technology we're still questioning the ethics and the and the responsible use of that technology so there's some examples here just to kind of you know show what we're actually seeing in the news right so over three billion identities were stolen online last year right we're questioning the the geopolitical forces and the influences that we're seeing in today's world right who which countries do we trust with our technologies which countries are we willing to share our technologies with right lots of questions around who we trust again and who we don't fake news is in the news every single day right there's a majority there's a survey that says that the majority of people around the world don't think that they have a single source of truth for news these days right I just came back from a vacation in India and they're getting ready for their elections and there's a lot of concern around fake news being spread and really influence in and affecting the elections right even after what we saw in our in our own elections here in the US we're seeing questions around the use of technologies like facial recognition technologies again you know we're constantly scanning everybody all the time and we're identifying who these people are and who they are who do we trust with this who do we trust you to see and from this information the bottom left there is about researcher in China that was using gene editing tools like CRISPR to modify human embryos right sounds really advanced but it's that ethical right there's a lot of questions around this we hear stories all the time about bugs or or you know software gone wrong or something you know that we've discovered in our applications like like the the recent FaceTime issue right where you know you'd make a call through FaceTime but the camera turned on before there the other the receiver actually had an opportunity to turn it on right we're question you know we've got apps that are constantly requesting access to our photos to our contacts to our you know to our call logs and text messages right so we're just constantly asking the questions of what's happening with my privacy and my data we're talking about inequality and inclusion many many questions and then we're seeing this tech clash right against all the technology companies whether they're in the Silicon Valley or whether they're in China but you know they're constantly being asked what are you doing with my information what are you doing with this data how are you using it what are you you know what are we what are we really doing but there are also some really amazing things that are happening a lot of positive news around technology right so there's an example here of work we're doing on a program called ID 2020 which is about us helping refugees all around the world establish their digital identities so that they can get access to services that they might not normally have had access to because they can't demonstrate or prove who they are we're seeing advances in the agriculture industry where we're using technologies like drones or you know IOT sensors and such to improve the quality of the food that we're producing and to help reduce food waste and and so on advances in healthcare and medical services this is an example you know one of many many examples but using IOT devices and technologies to provide seniors and disabled people with new ways of getting exercise some fascinating advances in robotics right which we're teaching robots how to do backflips and to dance better right so we're not gonna be doing the robot anymore they're dancing like us right pretty cool stuff and then and then the other example there with with Rockets so traditionally we we've launched Rockets up into the air but they're kind of like these one-time uses of these rocket technologies but companies like SpaceX for example are figuring out how to launch those rockets safely back down to earth so we can reuse them it's so some really fascinating and really positive uses of technology out there as well how many of you had heard about the the 10 year challenge that was was you know recently all around social media was where we were basically taking a picture of us 10 years ago and comparing it to a picture of us now right to show how much we've changed well Bill Gates posted the world's 10 year challenge and this was showing how you know how social factors and social things have changed over the past 10 years life expectancy extreme poverty child mortality youth illiteracy we've seen really really positive improvements over the past 10 years and technology has definitely had a role in all that so technology can be good or bad and that's based on how it's used and it's really as 2 up to us to determine whether it's good or bad and the thing is is change is constant this isn't as though we didn't have technology changes in the past but there's something very different right now about the pace the scale and the velocity of change that we're experiencing right now many of you have seen that s-curve slide around the technology adoption of the U in the US over the last 100 years one of the often cited examples in that slide is that it took about 45 years or so for the telephone to achieve mainstream adoption where as smartphones only took about ten years and before societies had time to kind of observe the impact of technological advances but we don't have that luxury right now because we are living in this time of rapid technology adoption regulators are playing catch-up but they've also indicated that in the next five years that they will be catching up with us all and I think that what we're seeing is in this gap that the society at large is responding responding we've got enormous public scrutiny and real-time feedback and in some respects forced transparency of the activities that companies are doing today and as new tech like AI becomes mainstream it's important to consider that the ethical implications right at the beginning is a central aspect of how we develop and deploy new technologies as recent events have shown it's really hard to get right and the thing is technology alone cannot deliver on the full promise of new technologies like AI an important conversation is going on right now with respect to external advisory councils etc and it's facilitated by community the community at large and I would say that it's helping the tech world understand how the public views the way that companies should be interacting with us engaging with us and what they expect companies to to represent what communities are expected to represent but in the end everything should not hang on one company one person one team one regulation one government rather companies should be creating resilient and sustainable governance strategies that can help them act in an agile way to deploy technology responsibly so let's take a look at the technology vision this year's technology vision what it's all about is about this post digital era and we are now entering this post digital era in 2018 company spent one point one trillion dollars on their digital transformation projects 94% of organizations say they're doing digital transformation work today I don't know if I believe that but that's what they said that they're doing 58% of those organizations say that they're comfortable with where their tech their digital transformation programs are going so everyone says they're doing digital right and we need to figure out how to differentiate we need to figure out what's next and in this post digital world we're not saying that digital is done not by any means in fact it's just table stakes now it's required to be there it's just the cost of doing business and you know I like that our and at some point we're going to say that we're gonna stop using the word digital even right I like how our CTO has said that you know we don't say we're in a post electricity world anymore or post Internet and world anymore they're just there right and so very soon we're going to we're gonna see that digital it's just like that as well so now we've got a new set of characteristics that are defining what it means to be successful in this this post digital era so we're gonna just touch briefly on what some of these characteristics are and the first one is individualization now individualization is not personalization we're talking about hyper personalization right it's not just about knowing what your preferences are and what you like and those kinds of things but it's about really understanding what you want and what you need instant on-demand is about being able to respond and deliver services to a customer exactly when they want it right they want it now and we have to be able to deliver that and then momentary markets are these pop up like services where we are able to respond to a customer's needs at exactly that particular moment in time right and these are again these these markets that form very quickly they provide an opportunity right then and there but then they go away very quickly as well and if you can't serve a customer's needs exactly when they want them then you've lost that opportunity to engage with them so now you can imagine all the information that's being captured in order to provide these types of services right and and customers expect trust and responsibility right they expect that all the data that they're putting out there you're using it responsibly and that they're able to trust that you know that you're doing that so I'd like to do a little experiment with all of you so take out your phone you know you all have phones just take out your phone right okay got your phones got your phone now unlock your phone okay it's unlocked right everyone's phones unlocked now hand it over to the person next to you go ahead hand it over and do something on the phone right where's your camera here I don't know where your camera is ghostly I'm gonna send you email let's take a picture here I'm gonna take a picture where's your selfie mode all right they give the phone back now all of you laughs all of you pause to think about oh my god I'm giving over this phone to the person who may I may or may not know think about all the things that are and we're friends yeah I know that but but who I really trust her or do I really want her to see all the messages that I'm exchanging with my sisters on whatsapp or all the photos that I've taken in her stored on my phone right there's access to my banking applications there's access to my emails there's just so much information that I know is on this phone and you know we're all pausing and hesitating to exchange those phones but we do this every day with data that is online and services that we use right we just publish things we have companies that have access to these things and we don't even think about it right we just trust that they are using this information responsibly right it's quite fascinating yeah so I am and part of my responsibility I work I had a client reach out to you and say have you ever done anything with like robots as an employee like where is this question coming from and they explained that they had taken a robot and introduced introduced the robot to the workplace and so the robot had had eyes and was roaming the work floor and they thought it was going to be enjoyable but actually it completely backfired people got very angry and they said one of the things that they said was this thing is recording me and it's invading my privacy and as we were kind of brainstorming about this we were just pointing out I'm sure you guys have CCTVs all over the place recording your employees activities all the time and it just was that reducing it to physical form that makes it come to life where people really understand what is actually happening so over here you'll see these are the principles that we use internally in terms of our use of artificial intelligence at Accenture whether it's from an HR perspective a CIO perspective these are these are the principles that we've been using they are based on the common principles of fate so it's fairness accountability transparency and explained ability so I'm not going to go into it you could see here it stands for trustworthy reliable understandable secure and teachable the one thing that I wanted to highlight is the item around understandable and we were very intentional about taking it a step further from transparency why is that well privacy policies are very transparent pages and pages of transparency nobody ever reads them and people don't really understand you don't say eff you know that these privacy policies can establish trust with the end-user so we really wanted to think about how do we stop putting the burden on the user to decipher what's going on how do we take responsibility for our actions and make the things that we're creating understandable to the user because when we when we prioritize and understand ability we're able to allow the the user to understand the import of the actions and to enable trust quickly and that this will be a very important point as we talk about momentary markets later on in this discussion okay so we talked about these characteristics of the post digital business now let's take a look at the five trends that we've established as part of our technology vision for the post digital era and then we're going to discuss how we can apply those principles of responsible use and ethics that Deb just talked about so the first trend is what we call the dark power and this is about the technologies that we are now seeing companies use in this post digital era the d stands for distributed Ledger's right and this is technologies like blockchain and cryptocurrency that we're using to you know to have these more secure and protected and trusted transactions so we're seeing examples of companies using technologies like blockchain in their supply chains to make sure that they're establishing that trusted you know set of supply chain activities we're seeing car makers use these technologies as a way to protect cars from getting hacked we're seeing the delivery service companies like DHL for example who are looking at blockchain technologies to to make sure that you are receiving for example medication or drugs that you had ordered and they're not counterfeit and that they're really the ones that you had asked for the a is for artificial intelligence right 67% of businesses say that artificial intelligence is being piloted or adopted at their organizations today and 41% of executives ranked artificial intelligence as the one technology that they expected to have the most impact in their organizations over the next three years so and you'll see all sorts of great examples of artificial intelligence hopefully here at the conference as well as you walk around and and see what some what other companies are doing the R stands for extended reality this is augmented reality virtual reality mixed realities assisted reality so on and so on these are all about new experiences right we're looking at new experiences in terms of new ways of training right we can use a virtual reality to simulate training environments or simulate actual environments so that workers can have a safe place to to try and to learn and to and to test out you know new capabilities new ways of shopping right new ways of interacting with products or gaining information in our you know in a store environment perhaps or things like that and new ways of just exploring places right we can virtually visit a national park or a museum or any other such facility like that the queue is for quantum computing right quantum computing has brought about so many new advances and and they're really allowing businesses to explore new ways of solving very difficult problems or perhaps problems that they weren't able to solve before right we were working with a company called one qubit and we had collaborated to identify over 150 different use cases for quantum computing to help us solve for example drug discovery we can use quantum to to quickly discover new types of drugs or fraud detection or route optimisation or so on there's many many examples of how quantum can help now individually each of these technologies provides an opportunity to differentiate right and we've already seen that 89% of businesses say that they're already experimenting with one or more of these dark technologies but then imagine that together right these are going to open some really new pathways and some unimaginative to dark technologies is built on the digital foundation that companies have invested in and been investing in over the past several years and we have you heard of the term smack before right since Mac is what is traditionally you know called the digital technologies that's social it's mobile that's analytics and cloud right and these are considered to be the foundation of our digital solutions and we're building upon those now right as we move to the dark technology so as an example augmented reality and virtual reality solutions run on mobile devices right that say the big data and the analytics capabilities that we have been setting up over the past several years well now we're extending those to artificial intelligence and machine learning those quantum computing services that are now being available they're being made available through the cloud right so we're building on top of what we had had already been establishing and this now provides a foundation for companies to start to explore these dark technologies which are really still the early stages so not only does it give us a head start but it allows us to create new value from these previous investments and to extend our digital business into the future so we see enormous promise that extended reality can have so for example training as you mentioned can really increase the ability for people to empathize with the plight of others a really great example I encourage you to go look for this on youtube is the NGO People for the Ethical Treatment of Animals decided to change their communication campaign actually Accenture helped them with this but they use the extended realities technologies to help people to engage with a rabid aitai it's called the eye to eye experiment and it really had a profound impact on the public in terms of understanding and helping animal rights come to life but when when I think about you know also the promise but what are the things that we're thinking about whenever there's a huge institutional shift going from smack to dark what are the things that we need to protect against and what are the things that we need to maintain so what shifts are we seeing we're seeing a shift that's going from watching a video on your phone to having these very intense immersive experiences and when you have these intense immersive experiences it becomes very easy to come to a truth truth from me conclusion that can seem at times unshakable and permanent and what we're what we're shifting from is not just data being collected but also data that can be possibly used for manipulation there's there's a senator and Virginia who just today introduced a bill that ban would like to propose banning the use of dark patterns for online platforms to prevent kind of the use of manipulated activities where people volunteer information about themselves without realizing how that information is going to be used so we're we're shifting from data collection to possible data collection for manipulated experiences and we think about the regulatory scrutiny that is that is coming the combination of extended realities and for example deep fake technologies and will the public start asking for guardrails not just on fake news this morning I counted there are about 13 countries right now that are either proposing or or have on their books legislation regarding fake news but at some point will will the public also start asking for guard barrels around not only just online safety for children but around the creation of fake memories okay our second trend is called get to know me and this is all about the consumer how do you reach the individual consumer how do you provide the right services to those consumers right it's all about how we engage in interact and you can think about all the smack technologies that we said we've been deploying right social the mobile and so on and we've collected so much information about each of us and all the users who are using these these technologies so you may have seen some of those those charts that talk about what happens on the Internet in a minute in 60 seconds well 3.7 million google searches are done every minute right 4.3 million YouTube videos are viewed every single minute 2.4 million snaps right 38 million whatsapp messages exchanged every minute and 187 million emails are sent every minute right so you can imagine now all of these interactions all of these activities they all say something about us they all provide information about us and companies are able to use that type of data to provide new types of services to individuals right so as an example share there's a company called slice pay they're a financial services company in India and they serve unbanked customers right so these are customers who don't traditionally use banking services or anything like that but what they mean what they did was that they were able to use the pictures that people were posting online or the messages that they were sending or their other social interactions and create a financial profile of these individuals and now they can provide services or offer services to these individuals using this profile that they were able to build based on that information so you know keep in mind that customers are making this information available to us to our businesses and they are relying on us and the businesses to use that information responsibly so again when I think about the promise of individualization it is the promise of instilling a sense that you are not only known and recognized but also understood and so we delight whenever a recommendation comes and it's correct we delight whenever it's thoughtful or insightful but when data is being scraped or being used in ways that the user didn't originally intend as a society we should pause are we creating systems that are learning to penalize people based on activities and data that they're providing that they never intended it to be used in this way are we making inferences on users that are just not reasonable again we're seeing increasing scrutiny in this paper in this space so the state of New York the Department of Financial Services in January just introduced a set of guidelines to insurance companies based in New York saying that if you're going to use non traditional data sources like social media posts here are the the gut here are the guiding principles that should apply but importantly you need to be able to show the burden is on insurance companies to be able to show that you are not using this data in a discriminatory way so against protected classes of individuals race gender etc and just by the way just removing race and gender doesn't eliminate that problem there are in indirect ways of discrimination using proxy variables like zip codes that are going to get caught up into that so how how companies should anticipate and think through using those non-traditional sources of of data the city of Los Angeles recently filed a lawsuit against the Weather Channel alleging that you know claiming that The Weather Channel had collected user location data on users who did not know that it was going to be sold to advertisers in the state of Utah recently in enacted a law that requires police to have search warrants before they can use and collect any kind of electronic electronic personal data like social media posts people are worried about everyday behaviors being penalized and criminalized and they are especially concerned when the data sets by which these inferences or conclusions or recommendations are being made are either false they're faulty or simply incorrect and I'm not even going to go into the whole bias discussion we could spend like a whole hour just talking about how some of these systems are built with bias already embedded in them our third trend is called human plus worker this is about the workforce our research shows that more than 90 percent of jobs that we have today will change as a result of artificial intelligence robotics and other technologies jobs are changing fast each individual worker is empowered by not only their skills and their knowledge but also by the new capabilities that technologies are providing as some examples here though in the oil and gas we have an oil and gas company whose workers are now able to troubleshoot an issue a mile underground using game-like visualization tools we have workers that are being trained as drone delivery pilots these are jobs that didn't exist before and we have factories where humans are working side by side with robots and we're using artificial intelligence tools to help determine which jobs the humans should be doing and which which jobs the robots should be doing right so the workforce is evolving and companies do need to keep up with ticket to support these human plus workers and there are three areas of focus that we have been exploring and working on on improving and one of those is around hiring right so the speed and the constantly changing nature of these human plus careers are making it harder for businesses to acquire this talent within their workforce so they're moving away companies are being forced to move away from the more traditional reactive skills based hiring you don't just put out a you know an ad for you know I need someone who has six plus years and you know accounting skills or something like that right so you know we've got companies for Unilever as an example who are now using games to to screen candidates right and they're they're using these games to to assess your memory they're using these games to understand your acceptance of risk they're their understanding whether you take more contextual cues or emotional cues right and so it's a very different way of screening candidates and then they're using again artificial intelligence tools to match these candidates with open roles it's are just new ways of hiring is also training right so you know we can't hire people necessarily to do the work of that we require them to do now they're people just don't have those skills and you know what we've seen is that 43 sorry but 43 percent of businesses and IT executives say that more than 60 percent of their workforce will move into new roles over the next three years and that's gonna require substantial rescaling right we need to invest in rescaling and offering on-demand training opportunities for these employees and the third areas around knowledge management right we have more information available up to us than ever before but it's also harder for us to access and to to find this information and we're you know exploring new ways to to make that all right we're using technologies like natural language processing to be able to capture and assess you know information and insights we're using we're looking at indexing of unstructured documents like incident reports for example as a way to collect knowledge and insights we're incorporating knowledge graphs to be able to find information across a wide variety of different types of data sources right so just new ways again on hiring on training and knowledge management so as new story was late rather recently about a certain Seattle company that had AI tool that was screening Seavey's and if you were a woman you were immediately downgraded and there was enormous backlash about what happened etc but when we looked at it we actually said hey actually they had a really strong governance structure they looked at this for two years they recognized that there was going to be bias in the system and the bias and their existing hiring practices today they tried and mitigate against it and tried to figure out ways in order to to fix and adjust for that bias and at the end of the two years they couldn't fix it and they decided to dismantle that program and that story to me just talk told me about how important it is to really establish those governance strategies at the beginning as you start experimenting with artificial intelligence at Accenture we we spent a lot of time looking at some of the some of the tools that we use internally but we also put a high level of importance on retraining and rescaling our workforce last year we spent 900 million dollars on retraining our people and we use the money that we save from automation and artificial intelligence to upskill people and for us that really is important because we think it's important to democratize AI learning and from an ethical point of view making it accessible to those who may have a hot there might be a high bear to entry for some of these skills our trend number four is called secure us to secure me right security is no longer about just protecting us as individuals it's not about one person it's about protecting all of us and what we need to you know what we've seen is that a lot of companies still think that security is an individual effort and you know if they can just secure their own information and their own data that they should be safe but that's not the case at all because what we're seeing is that businesses are rapidly entering these ecosystems right they're working with technology partners and industry partners to create new services and new products and new experiences for for their customers and attackers are really seeing these ecosystems as this ever-widening attack surface from which they can you know try to do bad things only 29% of executives in our survey actually know that their technology partners are taking security and being just as diligent as they are in in you know implementing security processes and solutions so you know what we continue to have the traditional risk that we always have well you know we one of them has always been around the misuse of data and we've always thought of it as a misuse of our own data and how you know that would how could provide access to our systems but really what we're seeing is that you know we can take we can see misuse of other data to impact us as well right so for example data from business wires has been stolen for illegal stock trading purposes right there's a risk around aggregated data as well we think of aggregated data as being kind of somewhat anonymized or that you know it's not able to identify us individually but you know what we found is that agra agra gated data was found on Strava and used out of context to identify secret US military sites right and so you know we can't just assume that we can't make sense of some of this other data and in today's connected an ecosystem dependent world the impact of cyberattacks is exponentially amplified there was the wanna cry crypto worm he might have heard of that one that exposed an operating system vulnerability and infected over 300,000 computers across 150 countries in just a matter of men of days right and this brought down businesses and in fact it impacted you know work that was being done and so on there was a marine malware that was used to hijack over a hundred thousand I owe t devices and then use those devices to launch an attack on a domain registration services provider right so as hackers can also we've seen right I mean they can spread fat fake news much faster than how good news and real news traditionally gets gets spread so leading businesses are recognizing that just as they work and collaborate with their partners in the ecosystem around these new products and new services and new experiences they also need to collaborate on security yes so I think for us it's really critical that we're building resilient and sustainable innovation and this includes making sure that we're building systems that are secured by design I think I really love this point around making sure that the whole ecosystem and the supply chain is actually secure given how increasingly networked and connected all our world is and I think it was the designer Bruce Mouw who said something like everything is connected so for better or worse everything matters and so to me that means it you are only as strong as essentially and as transparent and as secure and as and you are vulnerable as your weakest link and in the chain and we've seen regulators in the past kind of put liability not just on you as an individual in terms of yours cyber security or your secure environment but also in your your supply chain and we're anticipating that trend as well okay our last trend or fifth trend is called my markets and this is all about those momentary markets 85% of executives agree that the integration of customization and real or new near-real-time delivery is going to create the next big wave of competitive advantage right so again customization and real or near real-time delivery and that's all about capturing moments right so whether it's real time views of operations whether it's instant price quotes based on inventory or scheduling or pricing data whether it's the ability to immediately adjust and respond based on customer feedback that you're getting right or these pop-up services that we talked about it's all about capturing that moment and as we get better at capturing those moments people and businesses are going to expect more convenience and immediacy from our technologies and companies can capitalize on these moments by providing personally you know tailored products and services that go far beyond just customization so the example I'll share with you is what Carnival Cruise Lines is doing right they're transforming the entire ship experience right the cruise experience and what they do now is everyone gets everyone will be getting a what they call a medallion it's a wearable device and it knows your preferences it knows you know it's able to know where you are on the ship it allows you to make purchases right there's all these things and what and and they're also adding IOT sensors and cameras and analytics and just all this information all around the ship as well so that for example they might identify that there's availability at an upcoming attraction that maybe your child might like and that they would be really interested in and then it sends you a message and offers you the opportunity to to be part of that attraction right it's a very momentary opportunity it comes you know is made available to you and then it just goes away and so given the criticality of these momentary markets what I would say is that companies need to really think about how do you establish just-in-time and how do you establish that you have the responsibility so that trust can be established and exchanged seamlessly and quickly this necessarily means that trust needs to be in corporate incorporated in the very early stages of designs the these systems should incorporate for example for us at Accenture we want to incorporate the the principles of trust and deploy responds the technology responds responsibly so I talked about trustworthy reliable understandable secure and teachable working through this beforehand really matters and in our global responsible a survey that we conducted last fall twenty four percent of the respondents indicated that they had to go undergo a complete overhaul of an AI system due to either inconsistent results a lack of transparency and or biased results and so what so what what do we do and what what does deploying responsible technologies look like and I just put together some of these points and I think it's really critical that we're building agile multidisciplinary ecosystems if you're if you've got it a group of individuals that are that look like you act like you do the same things that you're doing it's very likely you're gonna have some blind spots we think that companies ought to be looking across the board you may need to be engaging with human rights organizations for the first time academia for the first time use good data hygiene I can't tell you how many times it it's really important for people to really understand the way that the bias can creep into into systems how do you build a governance strategy that anticipates downstream impacts how do you create systems of constructive dissent and incorporate diverse perspectives and how do you use this whole system to enable informed decision making there's no one tool I wish I could say I've got a checklist we've got this great thing and it's going to stamp you like organics and you're gonna be ethic certified there is no one magic solution that will solve everything instead companies really need to invest these governance strategies when we started this presentation we we said that we wanted to apply what we learned in the last five years because in the last five years we've had this immense push forward the old models of disrupt or be disruptive or move fast and break things were were commonplace at times this mindset just served as a justification to innovate without implications without a desire to to take into prospective compliance trusts or ethics and if I may for a moment just use the e use general data protection regulation as a watershed moment because things are being mirrored in California for example we are at a meaningful transition right now I've talked a little bit already about some of the increasing level of activities that we're just seeing in the United States in Europe and in other countries there is even more activity and some some some are also being demanded by the public the next five years we think is about trust and responsibility and how do we create sustainable innovation but in the end we cannot as we said at the beginning go at the set alone instead of separate businesses trying to go their own way I think we've really got to work together and collectively to try to get this right and pull in the different community interests the different perspectives to make them at the heart genuinely at the heart of the discussions that are happening today okay so we've given you a glimpse into the future and we hope that this presentation has provided you with some things to think about when it comes to defining and deploying responsible technology if you'd like more information on our technology vision you can visit our website Accenture comm such technology vision and you can also connect with both Deb and myself on Twitter and LinkedIn so feel free to reach out to us with any questions or you know conversations you'd like to have and you know what I'd like to to end with is the same question that I started with at the beginning right we've talked about how technology can be good or bad based on how its deployed and how it's implemented and my question will come back to you what is your role in influencing whether technology is good or bad so thank you for your time I hope you found this useful and Deb and I will be here in case you have any questions but thank you again and enjoy the conference [Music] 