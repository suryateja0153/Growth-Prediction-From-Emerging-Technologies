 all right good afternoon everyone my name is Ian Bailey I'm the assistant deputy minister in the justice and public safety sector and it is my great pleasure to introduce this afternoon's speaker Ashley Casavant Ashley has recently joined a nonprofit company called AI global she previously in fact very recently worked in the federal government as director of data and digital and she's here today to talk to us about AI ethics so please join me in welcoming Ashley so I did what I did want to explain that if my introduction was short it's because the notes they gave me I actually don't match Ashley so that was that's why we were over on the side here laughing I think you thought you did actually it was perfect and actually the very first thing is actually gonna be a timeline of what I've done to explain my role and how I got here so thank you so much for having me as Ian mentioned I have recently left the federal government so the timeline is accurate I was part of Alec's Benes team working with your new chief digital officer Jamie Boyd as well up until two months ago in that capacity I was responsible for open source technology well strategies and policies related to open source technology everything to do with anything innovation so we've been hearing that word a lot today and then also enterprise data so I wanted to kind of put this together to try and understand how I got to where I am right now most people I talk about my current role and then I kind of reference a whole bunch of other things and their head is start spinning and it gets very confusing so this was an easy way to kind of break that down and then so I start kind of my public service journey I had the opportunity to work on several campaigns in Canada but in 2008 I got the opportunity to work on the first Obama campaign which really got my me thinking about how are we making data-driven decisions and it was a stark contrast that campaign I'm sure everybody's fully aware of it now to what we were doing in Canada and we were seeing this more and more in all of the campaign's that we have now but I couldn't believe how accurate these outcomes were and so then when I went back to Edmonton which is where I'm from I started working for the municipal government and I'm like super petulant annoying and I'm like why aren't your database is connected why don't you make database decisions or data-driven decisions and they were like I don't know go talk to the CIO so I did he was a man named Chris Moore who I'm sure that many of you have actually encountered I mean some of the work that you've been doing and was definitely visionary for thinking about where does government need to go in kind of this digital era we were the first government to move to Gmail or Google for mail and calendar which in 2009 2010 was kind of a big conversation to be having at in addition to taking on the open data activities there I also had the opportunity to act as this chief of staff which allowed me to see kind of how government actually works so I got to be responsible for coordinating budgets and audits and that was such a good understanding of then where things really worked and why certain processes are important but then also where things could really be improved so then because we had done a lot of work with open data and had made sure that we were working both with provincial governments so I had the opportunity to work with the government of BC at that time we also got recognition for the work that we did and I got asked to go lead the open government program at the federal government so in that capacity I developed open Canada CA which was a super interesting opportunity again to be able to see how government works and then also where there's some opportunities for improvement and that really allowed me to see okay if we want these objectives of open and transparent government and some of the the things that we're talking about today innovation and transformation and how we provide better services we need to have the policies and processes to make that actually happen so we need to look at those foundational pieces which then led me to moving away from the open government team and I assumed the role as director for data in digital and in that capacity I really looked at what are those policies or strategies or conversations we just need to have about the importance of our foundational components having been interested in data as you can see from the beginning of the timeline I really thought that that was an important aspect that we needed to tackle and that then made me interested in a whole bunch of other ways that we're using and talking about the up talking about data and so part of my mandate then became to look at what we were doing with artificial intelligence so fortunately for me there was another person on the floor who many of you probably follow on Twitter he's known as super governance on Twitter but a name I will never let him always tease him about but Michael Carlin is one of the most interesting public servants I've had the chance to meet because he had the foresight to think through what are these different types of tech oh geez that were kind of categorizing as AI and how are we starting to use them in government and so because of my work in data we kept talking and then finally I kind of assumed that that work and we set off on our journey to write a white paper and then ultimately be the first national government that started to address how are you going to deal with the use of artificial intelligence and data being a strong component of that in a responsible and ethical manner through that work and thanks to Alex Benes work trying to make these international collaborations happen we actually launched a lot of this at the d9 most recently in Israel which he spoke about a little bit in his speech this morning so one thing I didn't mention on there was just the community organizing piece of it that though has been the most important lesson learned I had throughout all of this I'm sure any of you that have done work whether it's community organizing in a political aspect or otherwise recognize the need for people to be able to work together sweetly who huge kudos to organizing all of this conference her and her team have done an incredible job we were talking yesterday and she said that this conference was actually more of a tech conference previously and just IT people would come and now it's gone from 600 people to a thousand people this year because it's in recognition that we need all of the different players from all different types of areas of government to be able to work together and so that's been something that I've thread throughout all of the work that I've done I'll speak in more detail about the policy that we created in Canada but everything has been done in an open way which is why I mentioned that was part of my portfolio in Canada so we've been hearing tons about kind of the opportunity as I in terms of having digital government and obviously AI is a big component of that I I i I'll just go through some of these quickly there government examples just more familiar with them but I had an opportunity to do a workshop yesterday and it looks like you guys are doing some really interesting work as well that is related to these so the first one is an example just of benefits if there's ways that we can kind of expedite any sort of services that's it's really great it makes things a lot easier for us we can get through more claims a lot faster well what's actually really interesting to me about benefits is that when we're using tools like AI we have to figure out our criteria at the beginning and then we're a lot more consistent with how we're delivering those services and so that allows us to be more objective than subjective when we're looking at this and so whether it's a claim for an employment insurance benefit or whether it's a claim for somebody that's looking to get a visa to come to Canada and study here or work here we can be more objective about those activities so there's lots of opportunities from that perspective looking at Rail Safety Canadian Pacific or CN has actually done a lot of work at putting a lot more sensors onto their onto the wheels so that they can actually see when they're degrading and so that they can change them and this has avoided a lot of train derailments and just overall safety of their systems I don't know if any of you guys used Charlie the chat bot for filing taxes this year anyone no not a single one Oh quick taxes are really good too so the people have lots of questions I about how to actually file their taxes it can be a really complex and confusing situation I just keep giving it to my my dad's accountant okay please just do my taxes for me one day that's gonna stop working so it would be advantageous to have a chat bot that will actually help me kind of navigate that system a lot better and the thing that I really liked about this chat but is that there's no intelligence was built into it at all it was just ottoman 'td and so it took all of the content that was already on the website and it put it into a database that then you were able to ask a question to and so we think about these things as being able to well we think of AI is just machine learning and that it's going to be interpreting your question and providing an intelligent response back but there's a lot that we can do well in advance of the technology being able and capable of doing that and then last thing actually on the chat bot is that what's nice about that one of the activities and I understand that you guys have gone through a similar exercise but that we did in Canada was consolidating all of the different web pages into a single site if any of you worked on that for BC you'll know that it was a really really difficult process to be able to even come up with an architecture for that but then also actually synchronize all of that data and make it be representable in an understandable way to people and so we actually came up with different themes and it was super super confusing there's so many different sub menus and so something like a chat bot allows people to just navigate to that information a lot easier and then last but definitely not least we're using there's lots and lots of examples that we're using predictive and analytics for and so suicide prevention is one of those and it's really interesting because it creates awareness that there are actually lots of opportunities that we can improve ways that we're actually providing services but providing services that are saving lives and we don't often think of the federal government as having control over that we don't deal with education or health care or kind of any sort of those types of critical services but in a capacity like this if we're able to do more analysis and see where certain keywords that people might be calling into crisis lines would be a signifier of someone's States then interventions can be made a lot more readily so the nice thing about all of these examples is that again while their federal government examples they can be situated in any other type of government or any other type of service and so when I talk about open and why I made a point of that is that a big piece of open is just not that transparency angle it's also the reusability aspect of it so that's the positive that said and actually Ryan and his presentation this morning I see Ryan he was also studying this study and I was like nah he's scooped me but you didn't show this slide but I think it's great because both of us know the importance of doing types of awareness polls like this and trying to get a sentiment of how people actually feel about these changes so yes there's tons and tons of opportunity but often the the conversations that we're having about what AI is doing are often to the extreme and we'll kind of we'll get to that in a second but you can see and what I really love about this particular slide within this if so study is that the more that it matters the lower support and the more fear that people have about these systems and about these changes that are happening to them and you can see if you go all the way to the bottom this concept of jobs being replaced yeah it's it's incredibly challenging but often these types of things are are not completely accurate and so we had a big challenge to overcome when thinking about how do you actually create a policy where you're trying to not only make those better services happen and balance like innovation but then also balance people's fears and then also protection of the public and then as I've mentioned kind of media associated with these things there's a lot of stuff that is actually happening and it is contributing to that fear for very very good reason we're seeing a give cognitive technology that's really looking our affective computing story that's being used in the education system and it's discerning people's emotions and we don't have thresholds yet for like what degree of accuracy this is actually operating at and the challenge is that when a lot of these systems aren't interpretable explainable you can't see within that black box how they're rendering that output and so it becomes a bit difficult to say yeah go forth and use these technologies in a completely blanket statement we've seen also in healthcare how there's been miss diagnosis does that mean though that we shouldn't be using it of course not because by using it in a way that's augmenting doctors and nurses and health practitioners then it can definitely get us to a more expedited outcome or discernment of what the problem is that said we have to have an understanding of when we're keeping a human in the loop for these types of interventions and those through certain thresholds are being flagged we've seen all of the challenges with predictive policing I'm not going to go into details of that and then as I mentioned I'm just kind of a fear of the workforce being replaced entirely by robots from the experts that I've talked to in all of this we are years and years away from that and a lot of what I've seen we we should really be thinking about focusing on retraining programs because we've gone through these different types of evolutions previously so there's been a massive response to to both quelling some of these fears but then also coming up with solutions for how you can kind of combat some of those fears or challenges that I've just mentioned we have things like the Montreal Declaration that's looking at really thinking about people that are designing and developing any types of AI tools and systems to think through clearly what they're doing and get them to understand things like what does well-being mean in your circumstance and just make sure that overall you have the power as these designers and developers to not do any type of harm when you're when you're implementing these systems we have a great example I Triple E I'm not sure how many of you have read it it's a really big paper called ethically aligned design if you don't have time for 247 pages pages 11 through 35 are super good that is kind of just the summary and it gives you the principles of what they're proposing but that what's come out of that work is for those of you that follow standards they're p7000 series has 15 working groups if you are interested in joining them they're always looking for government experts on that but that's an approach to some of the some of the challenges that they've outlined which are consistent with what I've shared previously through that paper it is a it's definitely a good read I won't going through detail with all of these but what you can see from this is that there's a lot of organizations that are thinking through these things and quite a meaningful way and the bit of the challenge though we'll get that is just now how do you take that and how do you actually make public policy out of it so we in the Government of Canada decided that we needed to do that as I mentioned we wrote a white paper and we we started with this premise of how is AI going to be used well really Michael did I was just there at the beginning okay then I got my nose in it but he started talking to a whole bunch of people he has developed an incredible network online in terms of thinking through these implications for public policy and he really determined that we're along with a group of people because we just put it out on Google Docs and said who wants to contribute to this that really where this was being used or where AI was being used in government was for automated decision-making systems and so then that's why we wanted to not focus on the technology but we wanted to focus on the outcome so we created and drafted this directive on automated decision-making systems again out in the open more on that in a second but there's been I just wanted to note that there are other jurisdictions that are looking at different types of aspects of AI and kind of varying different degrees of competencies but so California for example is interested in kind of that privacy aspect following things like EU GDP are and then we have other think tanks and organizations that are also kind of putting public policy agendas forward in this space that said one of the things that I wanted to share with you and going through what kind of the response was and then also now how we got to building these things at first we realize okay there's tons and tons of information that slide that I showed you was just a sampling I have subsequently tried to do a mapping of all of this work I'm at 75 different documents that are really ranging from principles to policies to standards to just scientific reports to statements from really important people that say there should be some standards around this so it really spans the gamut there's lots of experts of lots of people especially on LinkedIn Rai experts now and so we were like okay well who are the right people who do we trust there's tons and tons of ideas and different types of insights and how that works within certain contexts but when you kind of dig like one layer deeper a lot of that information is just general and it's not really fit for any particular purpose and it was really difficult even from a public service perspective to find really authoritative information that helped our cause most importantly it hadn't been tested and so a lot of this still lives within the theoretical realm and I guess our biggest challenge then was that we didn't really have a thing that we could go to and just implement we really had to build a lot of this from scratch and I just want to be clear I mean by building it from scratch is we really didn't want to we didn't want to reinvent I I'll bring up open source a bunch of times throughout this but so what we did was we approach this from a stance of legal defensibility so we thought okay what are the laws that already exist that deal with these types of problems with the decision making is what we're dealing with once we put automated in it then we're saying okay well how do we apply that law to a human or sorry from a human to a machine so if a machine is making a decision in part or in whole what are those implications so what we did was we took a look and I took a bunch of different I will just go back to oh no I'm not going to because these are each individual things we took back to that response page we took a whole bunch of those and we tried to ascertain each of the kind of salient points along with all of our existing kind of laws and rules around these pieces and we came up with a way to be able to make an assessment one of the things that we didn't want to do with this policy was treat all of these products in the exact same way so we really wanted to balance innovation and use of them with protection of the public and so we created this a dramatic impact assessment and the algorithmic impact assessment actually just doesn't it's not a standalone piece what it does is it tries to verify what level of risk or validate what level of risk is associated with any of those different types of tools and systems one being low for being high and then we tried to say okay policy compliance you have to look at things like peer review training monitoring testing throughout that process the challenge with that for us became again back to there's lots of information and it's general and not fit for purpose is that even though we put it in a public service context it still was too general it's a one size fits all our government does tons and tons of things your government does tons and tons of things in so many different types of domains so back to my timeline if you can remember from the beginning I was like I don't think that government is the right place for this anymore so then I through my journey especially with d9i I encountered Manoj Saxena he was the first general manager of IBM Watson and also the founder chairman of a nonprofit called AI global and he asked us at the time how he can kind of help and I had said well we're trying to share these best practices with other countries we were doing that through the d9 and d9 just for your reference is a group of digital nations if you didn't hear Alex's talk this morning it's now 10:00 sorry it was denied when we were doing this work though Denmark's recently joined and it was really helpful because we have a lot of these different activities like the g7 in the g20 where we're sharing things diplomatically but there's very few times or instances at least that I've seen where there's opportunities for a lot of countries to get together and share best practices at a working level and so this gave us the opportunity to do that but we didn't actually have a digital authoritative in pendant workspace for those things and it made me realize that there wasn't really anybody that was doing that work and so I I was getting frustrated at going into meetings with different organizations for example economic and social development Canada I mentioned the benefits work they they were like okay great we're on board were for doing your policy so now who is gonna help us with understanding what does good peer review of data look like what does good quality of data look like and while there are standards for data quality on the iso 8000 is back to my previous slide not applicable to a certain context so one of the things that we also saw in all of this work is there's a ton of different organizations that are doing stuff in thinking through this theoretically but a guy not actually thinking about them and a way to implement so that's why I really wanted to Manoj likes to call it a do tank not a think tank but it's really important to partner with those think tanks and actually figure out ways to apply those and if you can decipher from the work that I've done I've always tried to take policy and put it into implementation and so or coming from a problem statement and so that's what I've tried to do with this work I am two months in but the organization's existed for two years and kind of with a really similar mandate so it aligns really well and also I've been thinking about this for a really long time so it's been really good to be able to kind of move forward in a good way and think about or in a quick way but then think about it just in terms of containers that we can use to collaborate with a whole bunch of people so there's three things that I'm focused on I'll come into those in a second but really for the purposes of educating so creating knowledge and awareness about all of this work is really step one if you want to make this type of change then putting that knowledge together in one comprehensible place is something that I've done over the course of my career and it's been I found it really useful the second thing is one of the lessons learned that we had from the creation of the directive was that it was actually really useful when we created the algorithmic impact assessment to have people go through it from the beginning of the presentation or from the beginning of the work that they're doing so it actually helped with design and so then in this work I'm working on or thinking about it in terms of how can we assist those designers and developers to support doing things right from the beginning similar to what I mentioned about the Montreal Declaration and then finally it's having those types of standards in place so that there can be an authoritative place that's providing these types of assurances to the public and as a person that also uses these tools I've found it really difficult to be able to understand what is good and what has gone through a lot of validation and testing and has thought through kind of these ethical pieces versus ones that haven't so as I mentioned aligned with this activity AI global had already created a responsible a a framework and so it's really similar to kind of the lessons learned or the sort of requirements that we had put into the directive so thinking about things like data risks the robustness of the application thinking about those compliance pieces and then also bias and fairness and then explain ability or interpret e of the system so what we are setting out to do through this I mentioned education because I built portals for a living I thought that we should have one for Responsible AI um but really as I said I think that having information in one Thorat ativ place really helps practitioners at least it did with us find that information be able to analyze it better and then more importantly be connected to those subject matter experts in a more easily to identify way I mentioned the design assistant what we did with the automatic impact assessment is we actually instead of just putting it out as a policy which is in HTML on a website typically we actually built a tool that was a fillable form online and because it's a dynamic questionnaire it's going to change for your different context that said we really wanted to make it it is open source we want to make it applicable to different types of regions that was what our workshop was on yesterday and we've seen how that's been done with WorkSafeBC to a certain extent but they've taken it and made it their own that said in order to do that there's still a lot of work that needs to be done and so this design assistant would ideally allow people to be able to again have that fit for purpose and then finally for me this all really results in the creation of of a check and so having something that's an easy to understand mark so that people can be able to more easily navigate what products or tools they're buying and whether that's for procurement within government or just you as an individual user these things are often helpful and do I actually think that this is gonna be a perfect solution i I don't but I think that it's a lot better to start these conversations and create awareness of the challenges that we have with ethics and what be is a responsible approach to artificial intelligence and so this helps us to get there these are just some of the principles that were following as part of this work we want to make sure that it's actually meaningful and so we're actually solving for the challenges that we're currently facing some of which I mentioned before but there's there's a lot more that we need to tackle if you read those reports you'll know all of them we want to also ensure that we're doing this in a way when I say it's not in a way that we're gonna continue to grow and develop so when I say that I we're we're not gonna get it right the first time or it's not gonna be perfect it's still important to do it and start this now as opposed to waiting for perfection we're never gonna be able to get there so that's why we want to make sure that we're ongoing doing maintenance of it so we're testing it early and often and so the the design assistant and the check actually work really well together for that reason to be able to test those questions out there but then if it actually goes into a check then people will be able to to see that or to be assessed against it in a more authoritative way and then I kind of gone through a lot of these things and other aspects but you can see how still transparency and collaboration run through all of my interests and how I approach all of this work so this is just quickly it's a lot for a slide but the heart of the design assistant and the check is really building off of what we did with algorithmic impact assessment and for those of you that are following the standards work it's not to replace any of that work it's to reference it and also identify where there are gaps what we tried to do when we tried to implement some of those standards is that again because they weren't necessarily fit for a purpose or they weren't they weren't done yet then there was nothing kind of comprehensive and easy that we could just figure out so what I'm doing is I'm working with a lot of other organizations nonprofit for-profit government and industry players and other civil society members to bring the best of breed questions together for that evaluation and then also methodology some of these things we can also start to automate so that it's not a manual questionnaire and it's taking tons of time so and that allows us also to think through what are the different types of domain and regional specific ways that we need to be looking at this work so I'll leave it there I think we have a few minutes for questions if you have any one of the concerns I've heard talking about is the fear of AI replacing jobs as many previous waves of technology had like industrialization and so on and so forth what kind of recommendations and frameworks do you use to protect people's livelihoods from the potential you know job market impacts of the advent of AI well I think again I - from what I've seen and a lot of research that's been published is that it's the job replacement is not happening immediately and also they're looking at certain sectors where it is and so focusing on job retraining in those or shifting what the role of that technician for example would be so as I mentioned kind of even with the example of a doctor we wouldn't normally think that okay a doctor is gonna be replaced but it's actually some of these high-level positions like a doctor like a lawyer that are being replaced more immediately and that's we're looking at where those are intervention points and there can be greater depth of knowledge in those areas or those domains so things like that that would be what I would would suggest but there's lots of people that are looking on that that topic yeah yeah hi my question is just I guess regarding a bit of what was alluded to regarding ethics in AI I'm aware that recently there is talk of the United Nations about nation-states utilizing artificial intelligence in essentially military equipment and essentially trying to create automated defense systems personally this really concerns me quite a bit and the United Nations I think is also quite concerned about this as major nation states have already stated their intent to pursue these technologies so my question is really how do we ensure that we maintain strong ethical standards and protections in the deployment of artificial intelligence throughout the world yeah so my response to it I think by stimulating the conversation early so while this is being raised and as opposed to having a bunch of white papers and reports we're actually putting some policies parameters and standards around these types of things I think that the more people that are educated and aware of those issues and are able to talk comprehensively about them is really important that's why I think for me having a certification mark is something that's really important so that people know to even ask well why doesn't your system have that again I'm not these things are gonna happen either way so I think by being informed and being able to do something in response to it is really is really really essential I do think that the conversations that are happening around military are particularly terrifying I do think though again what we've seen with the technology were still ways away from that I think what's even more scary to me is all of the incremental behavioral changes that we're seeing in our consumer products that were not really aware of and so those are the types of things where I think we just as I think EU GDP has a really exact one example of this where while just looking at one aspect of data the privacy aspect it's a super-important one by setting that that example or policy or standard what they were able to do was change the behavior of companies so they're ensuring that companies are now putting notifications on websites that they're making sure that in their terms and conditions that it's easy to understand simplified consents and so things like that I think that by by doing these types of activities were able to actually change the incentive structure of those companies doing it so did you have a question okay excellent well thanks I'll be around if you have any other questions thank you [Applause] 