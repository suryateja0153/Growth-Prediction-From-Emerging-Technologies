 welcome everyone and thank you for attending our webinar on 10 tips for Responsible AI how graphs at context my name is Marilee and I'm part of the webinar team here at neo4j and I'm joined by Amy Hodler analytics and AI program manager we're super excited to have you here with us today to talk about this important topic a few housekeeping items before we get started we invite you to submit any questions you have throughout the demo U or throughout the presentation using the questions tab located at the top of the screen I will answer as many as we have time for at the end of the session and if we don't get to all of them someone from the neo4j team will reach out to you directly and I also wanted to point out that up in the handouts tab next to Q&A there is a PDF you can download and that has links to some of the resources that Amy will be referencing in a presentation so feel free to download that with that I'll go ahead and hand it over to Amy hi everybody thank you for joining this morning or this afternoon depending on where you're at as Marilee said I work on the AI and graph analytics area for neo4j and a little bit about me here's how you can get a hold of me I'm also really into network science in general and love research and writing which is why I co-authored the book on graph algorithms that's available through O'Reilly and I also loved the bike so if any of you can guess where I am in that picture that'll uh that'll be fun so that's me in a nutshell and one of the things that kind of led to this topic area about responsible AI and just looking into it is a colleague of mine who asked me to look into how graphs may assist with AI and AI standards in general and so kind of a big of you know a big kind of lofty statement is you know how might we be able to help with you know AI standards I've kind of led to the thought of you know how we can we can actually help with being more responsible about our AI and what I noticed when I when I started researching and you guys can do this as well is there's just there's a lot out there if you just look at the data if you just look at what's available today and some of the issues so of course the first thing you do when you you start to think about AI ethics responsibilities is you google and you you probably have done this and have seen some of the same these same stories and I think they they fall into three categories of AI not doing well one is just biased AI so the first example here on the page is a example from Amazon recruiting which they shut down their tool as soon as it was realized that this was happening but it was it was providing some recommendation theists against women and it basically looked at current resumes current LinkedIn profiles current profiles of employees and trying to match while these are good employees these employees work well for us who is similar to that that we should recommend so classic training training scenario and training issue and on the upper left here you can look at the male and female proportion of employees and technical roles for Apple Facebook Google Microsoft we don't have the Amazon numbers but you can see just in technology in general the excuse more more men in technical roles at major technology companies and so you can imagine this AI is learning on what it sees and what currently exists and it turns out that there are differences in the way women and men describe their accomplishments the kind of hobbies they choose and the AI was picking up on these differences and training to create an environmentally like the environment they had so so that's an example of bias and AI based on training the other one that's on this screen as well is recognition in particular facial recognition so the gender shades project looked at three main ways to three main software's that are used for facial recognition can paired them and so how do they do on men and women and how they do people different shades you can see the numbers there that you know if you are a later skinned male the accuracy rates are really quite amazing 99 to 100 percent accuracy in the in the evaluation if you're a darker skinned female you could be down to 65 percent accuracy and this is important because you know facial recognition isn't just used for games it's used for accessing to buildings instead of your keycard it's used in policing as well and and so that has a lot of implications and that's one of the reasons why last year Amazon actually spoke out in favor of having u.s. regulation of some sort on facial recognition technology so two examples of trying to do the right thing but because the data itself was skewed that your AI becomes pious another area that that isn't is prominently known but this is the idea of unknowable software unknowable AI this example is a inmate Victor Rodriguez who actually had committed and participated in an armed robbery when he was very young was in in the system for 10 years I had model behavior he helped other inmates he was expected even by the parole board to actually get parole because of his background and how he participated in various programs but was denied because he had a high risk assessment from a piece of software called compass now this software is interesting and that there's you know over a hundred different factors weights a lot of interdependencies they give you your score and the score was also you know was it's also varies by inmate and they found some questions within it and some of them subjective actually that would have changed the score from an eight a very high-risk eight out of ten down to a one so so some of those questions you know a little bit of you know debate as to whether you whether those you know those or what caused his his parole to be denied what is really terrible to me is that when his lawyers requested to have the logic explained of those factors and those different elements that gave him his score a judge denied their request because it was commercially proprietary so whether we're talking about AI that is just so complexed or it's just unknowable we don't understand how it makes a decision or that perhaps it is protected for commercial reasons that we can't tell you what our logic is this is another form of AI in my mind AI going bad because it's unknowable and we don't have the right to know Victor Rodriguez was eventually allowed to have parole but not on his first attempt so he did he did get parole in a subsequent attempt but we still don't know exactly why his assessment was so high in that first round another area that we think a lot about or I think a lot about is AI working absolutely properly but not appropriately an example for me of that is the Chinese Social Credit system where it looks at citizens behavior for both social and creditworthiness and in the u.s. we don't usually put those two things together but it will score things based on your financial habits which you would expect for a a credit worthiness score but also on social behavior so in this picture we have recognition and trying to do it looks like in one case maybe facial recognition of people are walking you know through the streets so it can if you walk if you J walk in an area and you you're captured with facial recognition doing that that can affect your social creditworthiness of same thing with smoking if you smoke in an area that's a non-smoking area so there's behavioral things that also go into this and it's going to affect by the end of this year they estimate it to affect 1.4 billion people will be in this by that time quite a few already in the system but it affects not just their economic rights but also social rights so things like how fast Internet you're allowed to get effects expect your your credit reading which would impact you know maybe if you're trying to buy a house or rent an apartment but also as I said things like even you know the speed of your internet and in other areas as well and so this is an example for me of it it's working as designed but in my opinion not really an appropriate use for for AI and so these things together the idea of bias nai because of training unknowable AI and what I would call inappropriate AI reading these stories doing that that research is is what led me to the idea that we need to be responsible about the way we implement it AI so I think any of us that either create train deploy AI systems any kind of an intelligent system actually that we have a duty to guide the development and the application that fit our social values now that will change and vary depending on where your systems are implemented but in the u.s. I believe that has a lot to do with and I I think a lot of us would feel accountability so that we can have not unknowable AI that we actually has some accountability when things happen that it's fair and operating to the way it was expected so the intent of the AI system is actually you know can be seen and applied in the outcome and then in a way that the public can trust as well and so the public can have trust so that it's reliable and doing things in a respectful manner so I think those things are important and I hope most of you you know thinking about this can can agree that being responsible about our AI is something that that we have to do we can't say that it's hard and we're not going to do it so working for a graph company you can imagine why why I see things through a lens of context and you know having that love for network science kind of understanding how context can help us do better and I do believe that AI needs context in general um to do well in all different areas and it's it's understandable if we think about as humans we use context to make decisions you think about the driving scenario we're not just thinking about the lines in the road we're thinking about the signs the other cars that we saw go by the drop in temperature that might indicate that it's going to be icy the temperature changes how many trucks what time of day what's rainy I mean there's all these things that we use to contextualize the decisions that we make and it's unfair to say AI doesn't need that context as well or to not give it that context and so not just raw data but what's the context of that data coming in and it's really required so the AI systems can learn from this information that's around them they can make judgments and refine judgments as they change so they can be flexible to a drop in temperature and the fact that you're approaching a bridge because bridge is always freeze first right and then adjust to you know other circumstances around them maybe traffic and things of that nature as well and so AI requires that context too and there's a there's an example that I that always makes me chuckle we saw her duck just sounds simple if you were to see a picture you would know exactly what what what that meant but AI has a really tough time with this if you can imagine it could mean that you saw my pet waterfowl or possibly it means that somebody named we saw my rubber ducky or and maybe a little more morbidly you've come over for dinner and duck is on the menu so we've we've got to take care of getting the duck ready so we're making potentially very different interpretations ai has a hard time with something like this and without context it has a tendency to be very narrowly focused so it only understands a narrow aspect of what has been trained on so not so flexible your predictions aren't optimal because they don't understand the context in which we're talking about this duck and you have limited the transparency thinking about that unknowable AI if we if we don't have content we don't know how the decision may have been influenced so so many different potential problems and AI is all often limited without context and graphs have a fantastic way of adding context and the reason for that is that graphs are contexts they are built for relationships they were originally invented to understand and they use relationships to actually build out graphs graphs are nothing but a mathematical representation of a network which is context and so that's why they add value and they enrich data with more usefulness and as we know it most of us you know there's there's really no data that's completely isolated in nature I've got one picture of a star here but stars in and of themselves exist in context and you can you know is if you think about about that and star or income context gives us a constellation and we can navigate by that and if we're thinking about navigates Maps you know adding in that context of what's next to what how far you know how long does it take me to get somewhere what's the best route somewhere and then if you add on more context you get things like navigation systems okay that's a lot of more context but if we keep layering on we even get whole new industries I think about what lyft is doing the context of navigation timing wait you know who wants to share a ride versus have a ride on their own what's the best route and so graphs allow us to add context to what either otherwise would be isolated data points and every time you do that you layer on more meaning and more usefulness to the data as well and this is bread and butter for neo4j we actually invented the property graph model in 2002 the lore is that it used it was the back of a napkin they start good at all it's a very simple idea if you think about it we've got notes those are the nouns in our network or whatever we're trying to understand employee company city and you've got relationships you've got pointers to things I sue in relationships in the o4j have direction so the CEO has a start date or the company excuse me has a CEO that started on a particular date and that's actually an employee and these relationships and notes can also have attributes you can see the start date name employee ID whatever that might be and this really simple model is actually extremely flexible it's what we use to add value at that context so that we can then innovate on it and we can do this with millions of data connections per second or billions of nodes if we're talking about analytics tens of billions have nodes actually and so the simple building block allows us to add context to whatever it is that we're trying to build their analog nice and it's not just in business that we're seeing graphs add context and graph accelerating innovation it we're also seeing it in the AI world as well and seeing it in the AI research world this is just a simple illustration looking from 2010 to the end of and actually creeping into to 2019 just the acceleration of graphs in AI research as well and so that's as you can see we're looking at close to a four-fold increase all kind of really kicking off sometime in 2016 as well and so we're seeing it happen in a business world we're seeing graphs actually enter in the AI world as well and if we think about how graphs add context for responsible AI I believe there's there's four ways and very substantial ways that are important they focus around robustness of systems and trustworthiness of systems but adding in that context to give us more accurate predictions accuracy is really important if we want to have a fair system flexibility so if we think about flexing two different situations that's important we talked about driving you know being able to flex two different scenarios is important as well and graphs can add that by adding in more context of fairness so again if we want to have a you know responsible system we have to have a feeling that has spent based on information that's fair that it represents how we're how we're implementing it and the the group that we're implementing it into and then reliability on you know elde the system and explained ability as well if we can't rely on it if we can't have any kind of explained ability it's hard to trust the system as well so I have a couple I have couple examples to kind of help illustrate that this one very important example you know just last year they're estimating a hundred billion in cost for opioid the opioid crisis and that's non fraud cost but you know even more important that just a couple years ago they were estimating 47,000 people in the u.s. died from opioid overdose as well so a very critical problem there are ways that we can employ machine learning and graphs to help combat some of this there's a couple examples looking at fraud detection actually in opioids there where you can use graphs to more accurately predict things that may be indicative of fraud and the opioid insurance and they're there by track down and try to cut down supply there's an example on neo4j comm if you go there and do a quick search on opioid you'll find some work that a colleague colleague of mine mark queensland did looking at prescriptions the provider and prescriber the pharmacy the patient and looking at these complicated relationships and trying to use various different algorithms and queuing including community detection algorithms to reveal these tight unusual clusters of behavior and then there's other research as well using graph algorithms to look at multiple different communities and then doing machine learning on top of that to try to predict what might be a inappropriate prescription as well and so being able to be more accurate about what is and isn't appropriate for prescriptions can also help with just cutting down on those inappropriate opiates out there in the in the world as well so just one example about predictive accuracy and graphs providing more accuracy in predictions we see that over and over again because relationships which are was what graphs are about are very predictive of behavior and currently and in the future another area that is of concern is manipulating data and so it's not unusual that you would get criminals trying to misrepresent information what is a very scary to think about is sometimes they do that for quite some time in a way that we can't detect so flying under the radar we see that in fraud and we also see that in cases like a recent u.s. attack on our cyber a cyber attack on our US electrical Gratus system as well where no damage was actually done but manipulation of data was there an infiltration of the data is there and why that's important when we think about it from an AI standpoint if we're thinking about reliability and explained ability if we can't prevent or we can't be sure that the data that our AI is relying on has it been manipulated it's going to be very difficult for people to trust the you know the results and the monitoring imagining an electrical or energy grid standpoint if we have alerts going off and shutting down things because of you know some kind of a warning if the data underneath it has been manipulated it's going to be hard to to trust that and do the right thing this visual is from a a risk management actually scenario with with neo4j and financial but I think it shows how graphs can bring together data in various different silos so that we can then track ripple effects so if if something's changed so this is classic data lineage which doesn't sound sexy they if you can't tell if a data point has been manipulated and if even if you know it's been many you can't tell what the ripple effect is you can't trust your systems and when I think about the scenario in a little bit of an expanded form imagine that in something like a voting scenario and that's something that's coming out for us all in the u.s. very soon we want to be able to trust this underlying data graph and data lineage is just a really easy way to do that another area that I think goes to fairness and this goes back to the bias in data itself in understanding our data this compass software that I mentioned briefly earlier is still used in the US and Canada and it still does risk assessment scores I threw up a couple visuals of some comparisons that were done in a a report called to predict and serve where they were looking at different risk scores based on the compass software just one example Vernon Peck Prater here on the upper-left had a really low score Umbria had a high score where they both had committed an offense Vernon had done some shoplifting at Home Depot Rita had borrowed her neighbor's bicycle and and they were given very different scores interestingly enough Vernon actually had committed prior offenses of that same nature he went on to then commit armed larceny and Brisa never recommitted again she only had a few misdemeanors in in her in her younger days as a juvenile never never reoffended and the compass software is has been shown as you can see down below that it tends to underestimate the recidivism for Caucasian white offenders and overestimate the recidivism for african-americans and so this has been shown to happen over and over again the compass software is the soft 4 I was talking about when it was deemed to be proprietary to show the logic of how things happen the assumption is that demographic information what zip code you live in what kind of gang activity might be going on in your neighborhood may impact your scores and the reason why this is important not just from a fairness after you get convicted standpoint but as before so these scores and in case of Vernon and BRE sure these scores were given to them before they were actually convicted so even when they come in and they have bookings and this impacts and your whole experience through the system whether you get parole or not whether you get offered you know different programs instead of jail time your judge may see it ahead of time your your lawyer may see the scores ahead of time so the ripple effect of having this score up could be quite significant and at being able to understand what data it was based on is in my opinion really very important graphs can help with that because we talked about knowing your data and data lineage like what are the actual elements of the data but there's also possible bias in how the data was collected what we chose to train our models on if you choose to train your model on zip code that may not be a very fair way to train your model so understanding what was used in the model not just the data points but how is collected and how it was trained is very important and grass can help add this context so that when we do our machine learning that we can understand the relationships of how the data was collected when it was collected and what was used what was the the training features that we decided to choose as well because that can really impact the outcome so just a few examples there to show how graphs and can add context and help with more responsible AI but if we think about what's what's next where are we going I think most of us can kind of see how our human values are really going to impact AI in general there's a couple examples where the the European Union is putting out recommendations on how to have more explainable unbiased guidelines there was a call actually from the EU to some people were actually thinking about banning facial recognition in public places and the you they walk that back that didn't happen but it just gives you an example of some of the things people are looking at the Google the head of Google actually was calling just recently I think a couple weeks ago for more AI regulation and to do it in a balanced way and then even the the White House asked NIST the National Institute for Standards Act them to look into how the government should engage for AI standards development they've actually put out a plan I would call it a plan for a plan but these things are becoming influential to to how AI is going to be developed and the more we can trust ái the faster we're going to have adoption as well within within different markets and different uses so the the other area that I think is going to become standard is just context for AI so we talked a lot about how AI needs context how graphs can add context we're seeing from a graph technology standpoint we're seeing graphs being adopted in data science and machine learning first and foremost to improve predictions because they're very good for that and it's very much low-hanging fruit but I think think we're going to see that expand to having context you know whether it's using a graph or some other type of technology it's just going to become standard for how we look at our AI and how we try to do better with with a AI in general the third area that I think is really interesting and those of you into into technology will understand why it's exciting is a graph native learning and so about a year ago a little over a year ago Google as well as some other researchers put out a paper of where the current shortcomings in machine learning and how do we overcome them and they walked away and in their paper that you can you can look at they walked away with this concept that graphs because they have this ability to abstract and generalize structures we're going to be the next big evolution in machine learning because they allow us to understand structures better and better than any one individual kind of neural net approach and so that's a mouthful and trying to kind of walk back of what that actually means it's basically implementing machine learning inside of a graph depth a structure and the idea is that you can start with a graph and as we know all our data is connected to something and so it's naturally in a graph you format and you can start with that format and have an output that that's format all while preserving your transient States why that's exciting two reasons one is is first if you can preserve your transient state and you have a graph as a starting point of graph as an endpoint that allows that you that allows your experts your domain experts to look at how decisions are made and in deep learning in particular we all know that it's very difficult to know how decisions were made and being able to validate decision points and trackback is a big part in the future - - to be able to understand how decisions are made and whether they can be explained the other area that's really exciting the other thing that we get really excited about is this idea of being more accurate with well less data and that sounds that it's much less data that may not sound exciting on the on the front end but if you can imagine doing things like whole graph learning so that you're you're learning on the entire graph with multiple things at the same time that allows us to do much more learning without having to go through as many iterations that we would normally do to go through a machine learning model it may even help us understand what features what we should be training on so remember when I talked about even choosing your features is important if you train a model to predict the perfect sock match and you pick color as your main item that's a somewhat arbitrary our colors having the same color sock the best sock match that is a choice that we would make or maybe it's fabric or maybe it's size i whatever it might be for an optimal pair of socks but your choice of your features is also very important and we believe this may help us bubble up significant features as well and the whole idea here is that we're trying to go from a more rigid black box type of approach to something that is more accurate and more flexible and has more transparency this type of technology isn't there today there's nowhere you can go out and just buy some graphic learning off the shelf it is in the research Google's published a couple papers around this area I'm so so I assume that they are they are actively looking and researching this we're very excited about this we're watching the space very carefully we think it's the future of grass and AI coming even closer together so speaking to those of you who actually have hands on keyboards what are you're a coder or a data scientist you have immense value right now you have immense power in shaping how we go forward and so I wanted to provide a couple tips for you guys so that you can do better in and be more responsible in what you're already what you're already working on if you're in the planning stage and you're collecting data right now I'm first and foremost know what's in your data that is so so important you can use graphs to do that graph data lineage is something like I said it doesn't sound sexy on the top but it is so so important it's just foundational I've threw up a couple a couple examples here that you can look and these are going to be in that these are in the handout so there's some videos you can look at at neo4j as to you know to kind of look at what that means and then also doing things like G biasing your information very important IBM did a lot of support for the AI Fairness three system/360 toolkit so that if you have information know what's in it and then try to D by us it try to make sure that it represents the the network that you're trying to predict for that it's representative of a population you're trying to predict for and the other thing is to just ask for help and to learn more so as you're starting to you know do more work look at places like the algorithmic Justice League they've got videos tutorials they have places you can ask her questions if you're not sure if you're being responsible about or you could be more responsible with what your you're doing it in in your in your machine learning or your AI area the other thing that I can't stress enough is involve your domain experts so one thing that I am disappointed actually in in in the software industry in general is the excitement over what we can do with predictions and AI and believing that that means that all we have to do is throw more data and we're going to get you know better results at it you might get more accurate results but are the results that you get actually predictors of what you are trying to estimate is the data appropriate yeah what does success look like what does failure look like it's your domain experts that understand fraud they understand insurance that understand you know your recommendations for different patient profiles those are the people that can really help you tune what you're doing so don't don't leave those people out if you're in the training phase again you can add graph to that you can add relationships to be more predictive relationships are very predictive of behavior so adding that in with graph feature engineering is a simple way to be more accurate I actually threw up an example here again and the handout handout where they're looking at spammer detection adding in different graphi type of features you can also use graphs as a counterfactual so if you believe you have a nice model you can use graphs and knowledge graphs to search and say can I prove myself wrong here is my model really yeah I completely accurate in what I should be predicting the other thing you can do is look at model exchanges so two examples here onyx MX what model exam exchanges help you do is have a way this is not maybe not completely you know tested for your exact scenario but have a way to have models that have have some vetting if you're just googling and grabbing a model from somewhere and and you know going with it because it you know it's easy to use you may not have you you may not know the underlying logic of that model and have any kind of vetting at all or anybody looking at it so just a way to get started with a little bit of a safety net if you will the other thing that I that I recommend is if you have an interpretable model so maybe not something that's super sexy maybe it's based on traditional statistics but if you have if there are interpretive models out there that perform just just well and there's a black box model use it it doesn't it may not seem sexy if it's if it's on statistics but if you can interpret why a decision was made and it's just as accurate there's really no reason not to to use those kind of models there's a researcher Cynthia Rudin I've got a little picture of her here again links to some sessions that she's done recently this year that makes some of her work on interpretable models freely available at the predictions lab at Duke University so finally if you're actually at the point where you're looking at results and you're thinking about implementing your models try to add context for for for the AI itself you can ask knowledge graphs it's a common thing to do to use knowledge graphs to med to have more speed and accuracy for heuristic AI an example of that would be a chat bot for first shopping let's say I am looking for a I asked a chat bot for a bat for my husband's 50th birthday I it can add the context of who I am and my actual requests to know that it doesn't need to send me to a zoological option I'm not trying to buy a furry flying nocturnal animal that I'm actually looking for a sporting good and also because I said 50th birthday perhaps it should not show me just any old bad it should show me some more expensive you know maybe special edition type of bat as well so you can use knowledge graphs to make your heuristic AI better as well and the other thing is to use formal risk assessment and independent from the people actually building the tools so there's a lot of different things you can do when you think about risk assessment you could have a committee there are companies that do that to review everything I've talked to insurance companies that have committees that look at every potential risk when they are implementing a new model including potential PR issues if something bad happens or you could do something simple like a checklist and I would say there's no excuse to not doing at least a checklist if you're implement implementing new models and if you don't know where to start with the here comes the EU again they have a some guideline lines they have their formalizing their guidelines in February but they already have a checklist of I believe around 85 questions that you can use internally and to just make sure you've thought about the different risks in your AI or your machine learning systems the other thing is to insist on ik explanations in high stakes decisions if you're predicting what flavor of chewing gum that I might like I'm not as worried about how you know the data that was based on and whether that's a hundred percent accurate if you're predicting whether I should get parole or what my insurance rates should be I would say that's a high-stake decision that we need to not just be accurate we don't not just need to be 90 percent accurate because we could just predict everyone have a high rate that we need to be faithful to what the model is trying to predict and we need to be complete about about our explanations as well so we're not cherry-picking our explanation and leaving out other indicating factors that were involved so very important especially for high stake decisions so again this is in the handout you can look at some of these links I think I may have added a few more links and then the handout but definitely there are practical things that you can do today to do better and to make our AI not just more accurate but also more faithful to what we're trying to do and just overall more responsible as well Oh and so if thinking about those things I hope I hope if you remember nothing else that that a lot of times what were we're having angst at are the problems we're having an AI aren't really technical issues there are actually human issues and if we're not thinking about them from a human perspective we're not going to really solve them with AI we might get you know something that is better to you know a couple more decimal points but that doesn't necessarily solve other problems than it may be that it may be bringing forth so we have a question-and-answer time right now and also just a quick note that the book that I co-authored on graph algorithms it does talk about graphs and machine learning towards the end is free until April 15th and so you can download that at neo4j so with that I'm going to do a live look at some questions here and we'll get started oh thanks Amy that was such an insightful presentation okay and we do have some questions and the first one you mentioned graphs and context for more flexible AI can you give us an example okay yeah no that's a great question yeah good good catch so if we think about graphs and contexts for more responsible AI if we can understand the context by with which not only something was trained but by how it's applied so an example that comes to mind is a chat bot that was used I believe it was in amia in in Europe where it didn't understand the difference between a seven-year-old speaking to it and a forty seven-year-old it didn't take that context into in to view when it was having conversations and graphs can help us kind of flex to say if the person if you go if you've know their age you you know respond differently to them but also take cues from the language that they're using from the time of day that perhaps they're on the system from you know maybe the location that they're there you know IP is you know so that so they're taking all those different things into contacts can help the AI adjust its response and hopefully be able to respond differently with different types of language and different types of users so let's just one at one example oh great thank you and another another question this is interesting one what's your stance on government regulation of AI okay that's a big question it is very much so you you might yeah yeah so you like it is and I believe that we are seeing a collaboration start which i think is appropriate which is public private to look at regulations I think I think the question is not whether we should do regulations but what they're going to look at at what they're going to look like and who should have a voice than that and I think we should all have a voice in that both the citizens but also as businesses and organizations that operate in this space and we can see this collaboration start with things like the the US NIST organization of looking for feedback on what kind of regulations there should be and how the government should approach regulations we can see this in the call by the Google CEO to look to actually say we need regulation but we have to be balanced about them and so being balanced about them means understanding you know all the different opinions so I guess the stance is not so much whether we should have any or not I think that I think that ship has sailed I think we will have them it's a matter of what they look like and I've had very interesting conversations with some thought leaders out there that are looking at things like having different guidelines depending on the types of decisions being made so I talked a little bit about more explained ability for high stake decisions we could very much be looking at things of rating systems where we rate the implementation of AI and different different scenarios as high medium low risk or you know something else so I don't know what the final answer is going to be I think we're on this journey and it but who's any of us that really cares about this to to be involve and be part of that collaboration excellent thank you so I know we're running a little bit over time so we have I'm gonna throw out this one last question and if we haven't gotten to the question that you asked someone from the over day will follow up with you and after the event but here is here's one and my managers are sensitive to extra work on time aren't they all do you have any suggestions on how to bring this topic back oh gosh all right so not an easy not easy in all scenarios but I think there's a couple different things you can do you know one is you know definitely show them you know some of the some of the guidelines and checklists I think I mentioned the and it's in the the handout which Marilee some people are saying they're having trouble seeing the handout so if if you don't get that if you don't see the handout we'll make sure to email that as well but there's the I think a really nice easy way to have a conversation is you know that you use a little bit ahead of us they're already coming up with these checklists you know with hey it's really simple to just look at these checklists see which questions apply to us and use those why not it's an easy way to get started I think the important thing with these conversations especially with buses worried about extra work and time which I totally get is to let them know that this is happening that these you know these responsibilities is something that the marketplaces is going to continue to pressure companies to be more responsible and that there are ways to get started that our onerous a checklist is not onerous so that there's just a good way to get started and then you can tailor for whatever your needs are so I think Marilee I think we're if I understand correctly we need to wrap this up so I really appreciate everyone's attention and detail and we will definitely I get the the information all right thank you everyone for attending thank you Amy for your time and the insight everyone have a great day thank you right 