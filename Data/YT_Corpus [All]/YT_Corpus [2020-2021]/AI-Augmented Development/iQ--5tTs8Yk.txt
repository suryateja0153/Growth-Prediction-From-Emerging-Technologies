 thanks everyone for coming I know as well as I'm going to talk about research on adaptive mented reality workspaces so if we look at how our systems have evolved like analyze like 50 years we see that how technology has to be making these things more wearable and portable like lighter and you're already reaching the point where we have something like a regular glass that we can just stick in our pockets right and maybe even where it's the whole day right like I do and the question becomes what we are going to do if this device which all this technology well first thing is we're going to chase pokemons around right because that's so much fun right and this is a type of application where the content we just becomes part of the environment but we also be doing something else like like writing papers for IUI and looking at our schedule right and look and webpages and the point that add that will happen is that we use the AR device you just replace all the displays we have in the world right so monitors their displays you have no pocket right and just bring some interesting questions for interface design you need to think that is something like being able to carry or much monitor set up anywhere you go right so Imagineering how may have all the interface layout rights don't have windows anymore so if you have like all your workspace around you and then you decide to go somewhere else what should happen should we take this winners with you you should like address them and carry them manually instead of easily become very impractical to do right and what also happens if you decide to actually walk around if this right some people go from one place to another and check the schedule apart the only way right and this also adds another challenge because and it should deal with interface while you actually trying to navigate the world and our solution for this thing was what if you could think about interface they could adapt the things that you do know when you start walking and he is able to understand environment around you and adapt so that it's always out of the way so to give you an idea of how this would work before we go into more details I'm sure a little clip of how this actually works right so now the windows are on the wall and then the person decides okay I'm going somewhere else so they can detach from the wall and follow you around and react as you change your trajectory from one place to another place so the methodology we use those first make an analysis of the design space right for the different ways that we can do this and then we followed by design and implementation or actual implementation in ER and followed that by a context or uses study so our point of start was the framework from Brazil of you know which try to come up with a structured way to understand how to build adaptive interfaces and what we did in this case was also consider the context right so instead of just looking at what the user is doing we want to use what is happening you should look at what is happening around you right how the environment is changing as well so we have information from the user environment user what the user is doing the information about the environment information about layout so we know how things are being displayed in the environment and the point here is that besides being able to look into explicit commands like gestures and button clicks right we also have information about the user where the user is looking and if it's moving or not so to give an example how this could you could work think about like using body position body orientation as features for adaptation so we could build an interface that knows that you start walking and follow you around and those when you turn and is able to keep the same relative position to your head right but you can also stab look instead of looking at the body orientation you can also look at surface position and surface orientation around you so you can build an interface that as you walk around on this cord for example it follows you but not in front of you but rather on the wall so they don't block your way so what we did was to implement like 18 different behaviors like scatter along algae's design space and we look into this like user information gap from the user from the environment from the layout and also from company of this so you can think for example have an adaptation to like the Wow to the environment but only making that happen when you get close enough to the wall and to be able to run geez if I actually use this study we reduced this to the four more promising behaviors and I'm going to show each of them now so the first one is adaptation to position so basically as a user walk around the inter interface can adapt and follow you around but it ignores any kind of rotation from the hab or from the body the second one is the rotation behavior so I'm just behavior we can order position but we react to any changes in rotation for the head or body the third one is adaptation to the environmental surface so basically you move the interface elements to the walls and interpolate both like position and orientation and the last one we call Auto centering so just the combined behavior where it works like as follow but it adapts do your change in trajectory as we walk around so we thought of centering you can look around while you're walking because it's not attached to your head but at one you change the trajectory also adapt that change in trajectory and we also build an interface that allows participants to choose from out just four behaviors whether they wanted they it on all the time of all the time or they can also choose to assign each behavior to a button so that they can would be activated only when you press the button so this give the participants change chance to activate on when it makes sense to them so we run a study with like 14 participants and our goal was to identify the strengths and limitations of this type of adaptation and investigate how participants could use the system in real setting right and our another goal was to generate like new ideas and directions for this kind of spatial adaptational research and we run the study into scenarios so in the first scenario it was our work scenario the would pretend to be an interior designer so and the experimenter would be the client so they would walk around and trying to discuss things about like renovating an apartment and the second one was a vacation scenario so two of them would pretend to be friends and talk about things in daily life but what are the news and can we go to the beach at one day or not so this is the layout of the actual environment we tried for the first one which is the work scenario it was an inside environment with a lot of obstacles and tables and chairs and for the vacation scenario we did an accord or longer long corridor with a band in their hand so in the first scenario is important to note said that there is a task in the end that record the users to interact with items in the real world so we asked them to draw in an actual board with an ecto marker so for the first scenario the works in area the the participant had like three windows available to complete the tasks one had like notes about what was decided in the prior meetings a list of furniture in prizes and also a floor plan so the experimenter would ask questions like Oh what we decide about doing in the kitchen and oh we're just expensive furniture they cost $1,000 we actually go and the participant would then need to check out these windows and be able to answer while walking around in space in the second one as I said was like two friends talking to each other so for this one the test the interface used was weather forecast calendar and also a web page with news so in this case the talk was more about oh you know what has happened in science recently and do you think we can go to the beach on Thursday so we need to coordinate and check information for all these windows while walking and talking the measures we used was basically observations and semi-structured interviews and we also record the log for participant interaction so we could review it later and see where the winds were going and what where the person is looking and what combination of behavior the person is using at one specific moment so going to the results when you look at the combinations of behaviors used the two most used combinations were follow one in outer centering yarn and the second one was follow one in rotation on a button so let me explain what that means so in the first one the window would follow automatically the user right and adapt to any change in trajectory in the second one they would follow the user but not adapt to any changes in rotation so it should be able to actually make the window move back to the original position they needed to press a button we also did that a dimensional analysis to try to figure out what are the main characteristics that are desired for this sort of adaptive interfaces the first one has to do with a trade-off between usability and expressiveness so basically participants are preferred when our behavior was useful in multiple situations in which context and it was a stable and easy to use the second one has to do with the compatibility between vision body coordination involved in walking so when you're walking you try to look around and see where you want to go and looking for obstacles right so interfaces that require you to look in a place that we would not actually be looking we're not that desirable as well as interfaces that actually occlude and block the review and the third one has to do with the compatibility with like real world activities for example in that last task that record users should draw something on the wall they need to be able to look and see the other face and look and see where the marker is and then be able to look at the board and see what they're doing actually in the board right so this has to do not only be able to see things we'll be able to position the interface at places in the world that we actually want them to be right another thing that we did was an analysis of how the behavior actually used right because one thing is as we as designers right you oh I think it would be used in this way but we also interested to see how novel and different who uses people would make from this behaviour so we found out like four main ways that this interface the first one of us to organize information so even though each behavior on each scenario only required purchase one should look at three windows all the windows were there the whole time so participant would use for example attraction to the walls to organize information okay that's the word information that I need that's the calendar where the calendar is another reason was to obtain information so sometimes when we walk any once you quickly check your calendar they would like press the button and bring the interface over here here check the calendar and then just miss it another one but should compensate for lack of awareness about what is going around when you're walking so a traction what sort of behaves what was used for that matter because you can just clear this space around you sending all the windows to where there is actually a natural occlusion in the world and the third one was to harmonize AR with the world right so we never see for example things that are half inside the table or half inside the walls right so participants also use these different behaviors to make things being coherent to the way they expect the world to function so in summary we found out that this adaptive behaviors can be effective to support AR and walking and the behaviors will be designed end up being kind of easy to use and easy to understand but this final behavior is only represents like a minimum useful set of abilities and things that you want you have an areal actual interface that's it thank you very much very intention [Applause] hi so I was curious about in your studies did you find any correlation between the density of the layout and the behavior that the user adopted because I see a lot of behavioral things that is discussed but you know if you have a lot of priority content but how much content you have and did that affect whether they choose to follow or rotate yeah that's interesting question Thanks so one of the thing is that in the beginning of each each scenario we ask the participants to lay out the the interface in the way they wanted so they could just look and drag them around before doing the actual desk so then you see that for example the limited field of via hololens my I have like in fluids influence then she adopts specific layouts right so if they knew that oh I will want all this information and then in the next test they would like put them together right and then they found out oh there are two closer I'm going to have them block in my environment so certainly we saw a lot of like just relationships between like the field of view right the the amount of Windows that we actually have and we required for the task so we have like just three windows which were the ones that were actually required the other ones were not so some people would just drag the other windows that they know they wouldn't be used very far away so that they could have the environment cleaner for walking hello nice presentation I was wondering when they were dealing with the physical world and the virtual one and they had some kind of obstacle so if they were going to crash into something because of a screen in front would they rather at just the virtual things and make a rotation or the attraction features so that everything goes away from the feel of you why would they adjust themselves physically and move back just reorient themselves yeah we've couple of interesting like solutions too especially like dealing with things in the world right so for this last test that are we required people to to mark the position of the furniture on the actual board some people for example used attraction to make the virtual map align with the real map on the board so they could exist the fact is and Mark right some people prefer to put it on the side so they have a clear view of the board and we just checked like this and mark it there and regarding like interaction of other things in space for example when you're walking and you see oh there's a chair here right and I want you to go over there they were actually like stop or reduce the speed so they could actually see through the windows but most of the things we notice is regarding like doing the task and walking around was more related to lack of attention then actually because of like real occlusion from the AR windows thank you 