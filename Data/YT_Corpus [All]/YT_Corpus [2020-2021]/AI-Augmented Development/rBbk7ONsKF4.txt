 On today's special build edition of the AI Show, we get to hear from Liam Cavanagh, Principal Program Manager on the Azure Cognitive Search team. This demo is pretty amazing, he takes a bunch of COVID-19 research papers, and applies several machine learning techniques, which can help first responders and medical professionals make sense of the research they need all using Azure Cognitive Search. Make sure you tune in. [MUSIC]  Hi everyone. Thanks for joining me. My name is Liam Cavanagh and I'm a Program Manager with the Azure Cognitive Search team. As you can see, today what I'm going to be arguing about is the topic called using AI to mine unstructured research papers to fight COVID-19. So to give you little background on this and why this started. A while back when we started hearing there is a lot of challenges from researchers, practitioners to be able to really effectively search and find relevant information to help them in their COVID-19 research. So what we did is we thought let's try to see if we can use some of our AI and search technologies to make it easier for people to find the important information that they're looking for. Along the way we learned a number of interesting things, we also met a number of interesting companies that helped us to enhance this application even further. So my goal today is to really walk you through the background on why we did this, help you understand the AI capabilities that we've enabled in this both from Microsoft, as well as, our partners, and actually go into a little bit more depth as the technical capabilities. So that if you wanted to build something like this, or something around a similar data set, you can go ahead and do this. Now, although this session is going to be a little over 20 minutes, I won't be able to go very deep into this. But what we'll be doing is we'll provide a GitHub repository so that you can fully recreate any of these components or even subsets of them if you wish to do that. So let's get started. So the first reason, to expand on what I was saying earlier as to why we did this is that, there was just an overwhelmingly large amount of information coming in on this virus. It's really hard not only for the researchers and practitioners to find relevant information, but it's really hard for them to keep up on the continually growing piece of information as things are changing from time-to-time, day-to-day and so that's a big challenge. The other thing is around misinformation. Even the general public, there is a lot of things coming from social media, information news, that may or may not be completely accurate. So having one source where we can go to to get proven validated research is a critical aspect to this. So what we tried to do is try to see, can we start bringing in some of these AI capabilities to allow us to unlock some of those capabilities, and that's what we did. So although the primary product that we leverage is called Azure Cognitive Search to power that search experience, there's definitely a lot of technologies that we plugged in to enhance that. For example, what we first did is we took a set of open data sets provided by the Semantic Scholar. This is a part of the Allen Institute for AI, where they are continually providing up-to-date new research papers, so that we can then use that as a source of information. We wanted to not only take that text information, but we wanted to enrich it. So what we did is we take all of the text, all of the titles, the abstracts, the bodies from these papers, and then enriched it using a new private preview technology from Microsoft called TA for health that allows us to extract out, all the important medical entities like signs, symptoms, treatments, genes, body parts, you name it, all of those important entity types that are discussed within that content, and then tag it with it. So we're enriching it that way. We wanted to make it so that you can really find what you're looking for. So that even if you search for a very specific term, we wanted to use some AI capabilities to help them understand, based on what we know of that content, here are some other terms that you could consider using to find more relevant information, call that Semantic Search. We use contextual summarization, which was actually provided by a partner of ours called Agolo. What we want to do is make it easy so that once you find a potential document, you can click on it and actually see a summary of it, a critical snippet of it, so you can decide quickly, is this important information or not and go back to it. Finally, using knowledge graphs, so that you can visualize all the correlations between the various different entities we've created from TA for health. As you can see here, there's a link here that you can actually go if you want to give it a try. So although I'll be going through the demonstration quite a bit, and it's very likely if you look at this now, it may not look quite the same. That's because we're continually updating this application based on new information, new insights, new requirements that we're hearing from the community. So it's very possible that it may change. So in this demonstration, I'm going to go through a couple of things. One of the first things that I'm going to show is something that was brought up to me by a colleague of mine, Jennifer Marsman. So she mentioned to me that she looked at this site because she was seeing in the social media all of these discussions around ibuprofen, and at the time there is a big concern. You shouldn't take ibuprofen because it makes it easier for you to get COVID-19, it worsens the effects of it, all these other things. So it was unclear whether this was true or not so she actually looked at this website to try to understand that. So let's actually go to this website and see what she saw. So this is the search app that we built, and I'm definitely going into a lot more depth on how it was built and technologies that at Howard. But what you'll see here is if I actually type in "Ibuprofen", first thing you'll notice is that it actually is recommending some terms. So type and search, that's just Azure Cognitive Search suggesting important information. I can actually say "Ibuprofen issues". Let's try if we can do that and see what comes up, ibuprofen issues, and search for that, and let's take a look. Here we have this very first document, and you'll notice that through the scoring, one of the things that we learned from practitioners is, since information is changing so quickly, it's typically more important to get relevant information from the most recent articles because it is changing so much. So we gave a little bit more of boosting to ibuprofen related articles that are in the recent time frame. So if I actually click on this document, let's see if this is interesting. This is actually the document that she clicked on, and you'll see here, as I mentioned, through the thanks of Agolo, they came to us and they said they wanted to participate and help make this more enhanced. So what they provided is, although I could definitely read through this huge body and get a general idea, what they can do is through the fact that I searched for ibuprofen issues, they use that context to actually identify the key sentences, snippets from that. As you can see here, it's pretty quick to see that, based on this proven research article, it's turning out that, it looks like according to them that there is no significance to the issues around using ibuprofen. So this was allowing her to quickly see maybe some of the things we're seeing in social media may not be completely accurate, so going to proven articles. Some of the other things that you'll see here is, you'll notice here, this idea of semantically similar terms. I'm going to show you a different search query.  As you can imagine, there's all kinds of different ways that you can refer to terms, and words in medical. This is true in virtually every industry. So I'm going to put it in one word called "Hemorrhagic", because hemorrhagic is actually often hard to spell. But its also a term that you can see here. If based on our learning through our AI, we analyze in a purely unsupervised way that there are a lot of semantically similar terms, including this one where, hemorrhagic is often spelled H-a-e-m. So even though they are a good number of articles, if I click on this, we'll see that there are actually significantly more relevant articles just by including some additional variations to this. In fact, you'll often see oftentimes people slightly misspell it, such as this one, to get even a little bit more. So it helps you, as a researcher or a person finding content to really get the real key aspects of what you're looking for and narrow down to it. As you can see here, we added dates because sometimes people want to just only see the most relevant information. I can actually choose. Let's say I'm only interested in information and I'd say the last month. If I go down, not only do we have facets for journals and contributors, which is part of the data. Remember I was telling you about the TA for health container where we extracted medical entities and tagged all the documents. You can see with body structures, diagnoses, examination names, genes, medication classes, treatments, symptoms, all these other things. You can actually start seeing here some interesting trends like for example, over the last month, since it's only April the 4th, we can actually see that there are treatment names. These are the most common ones that are discussed or medications that are very commonly discussed in relation to these topics. So it allows me to quickly filter down on the relevant information and find what I'm looking for. Finally, one other thing that we added is we wanted to help people visualize relationships, a little bit better. So what we added is we added this graph capability, where you can actually search for things and let me just actually search for hemorrhagic here and search for some results. We can see here all of the different contributors, all the people that have written about this topic and how they relate. If I choose one or the other entities, maybe I'm interested in the medication names and how they correlate, so we can actually see how things link together. It's all of the visual way to actually start seeing terms and aspects and how they link. So you can see here penicillin seems to be talked a lot in comparison to Ribavirin. So I can actually dig into that and go back to the content to see it. So hopefully that gives you an idea of where we're starting to build. All powered through a combination of AI capabilities, as well as, Cognitive Search to be able to explore and search and find that relevant information. So let me go back to my PowerPoint here. I'll just keep on going. So now that we've seen what it can do, what I want to do is jump more into the technical aspects as to how it was done. Now, like I said, I'm not going to be able to go through every aspect in the short period of time. We'll have that GitHub repository so you can dig into more detail if you like. But let me show you some of the key aspects. So what I'm going to do in this reference architecture is, I'm going to start on the data prep and ingestion. This is just about getting the data from Semantic Scholar, from that data set into Azure Cognitive Search so that the application can use it. So if I start on the right hand side here, what I do is on a regular basis, and what they do is they typically update it about once a week with new articles, what I do is I take that new content and I put it into Azure Blob storage. What I use is I use Azure Cognitive Searches capability to take and parse that content and push it into Azure Cognitive Search. Now in this case, what Semantic Scholar has been nice enough to do is they've actually formatted into a JSON structure. So it makes it very easy for us to just map that structure and bring it into Azure Cognitive Search. Often, you might find your content, say in PDF or office documents, or maybe in various different data sources. So you might need to not only say get that PDF, but use Cognitive Search to crack it open, extract the text, so they can send it in. But in this case it's a little bit easier because it's in JSON. But as I mentioned, just because we have the text and there is some metadata like authors and journals names, which is really useful, what we want to do is build out a better refinement. Because remember on that's the left sidebar, there was the idea of refinement based on no symptoms, treatments, genes, medication names. So what we did is we use what's called a custom skill. I will show you what this looks like in a few minutes. But as the data is coming in, what we did is we called an Azure Function that was hosting the text analytics for health container, so that it sends in that text from the article and what you get back are all the medical entities that I can then apply to the search index. We also created a couple others. Like for example, I didn't like the way that the JSON formatted the author names, so I combined them into just a single name. So I had a simple tools like that skill for that. Then you'll see at the bottom here something called the Data Science VM. What I wanted to do is, if you recall when I searched for hemorrhagic. It gave me a bunch of other semantically similar terms. So what I did is I use a Data Science VM to go through that large amount of content from blob storage, do an analysis and use a combination of things like fast text to actually create the term embeddings. What I did is I took that in and I hosted it into an Azure Container Instance. So that when I called it with the terms it would send back here are the terms that are semantically similar based on the AI that was purely done once again unsupervised. So those are all the steps that I needed to prepare the data. So let's actually take that and actually what I'm going to do is go in and show you some of the different technical aspects of that. So what I'm going to do is I'm going to start in the portal. This is my search service right here and here, as you can see, I have quite a few different indexes that I've created. You can actually see as I've learned over time, I've created multiple new versions of the search index to enhance it and make it better, to support the different requirements and capabilities. But if I click on this "Period Index" that I have live, the version 4, you'll notice here against the index, I'm just going go do a search so you can see what it looks like. So this is my search index that has been already set up. It has the title, the abstract and the body, which Semantic Scholar provided for me. I'm going to go down a little bit more and see if we can find.  Here are all of the medical entities that our TA for health container had identified are being discussed within that document. So we link that, we enrich it, we add in the additional information so that the application can then filter and refine and group it as needed. Now, if I switch over to Postman, let's take a look at some of those custom skills. The first thing, what I did is I had a custom skill, and actually I think maybe it'll be useful if, before I actually run this, I'm going to show you what the original data looks like. As I said, I have it in blob storage, and here's all the data that Semantic Scholar provides. If I double-click in here and choose one of the folders, you'll notice here, there's a whole bunch of different JSON documents that it has. If I open up that one, this is what it looks like. It's got the title, the authors, and remember I was saying, I want it actually combined, merged into a single name. So let me just take all of these authors so you can actually see what it looks like. I'm just going to take that, and I'm going to paste this into my requests. This is exactly what the custom skill is going to do. So I'm going to paste this in and hit "Send". What the custom skill does is it takes this format and it sends it out, and what it'll do is it'll send back the format. I actually merge all the names into a single name. So you can see here that it allows us to customize, do different things to the original data to enrich it or change it. If I looked at the TA for health container, here's an example where what we do is we actually search and send the title, the abstract, in this case, there is no abstract, the body, and it just sends it in. It says, "Hey, based on that data you provided, here are the treatments that are discussed, here the examination names, all the different medical entities that are discussed within it." I going to say, "Great. Thank you." Cognitive search will then apply that to my index, so then it becomes part of it, as you just saw earlier. The third thing I want to show you is the Semantic Server. If you recall my Data Science VM, what it was doing is it was actually taking the search query and it was sending it in, and it was trying to find semantically-similar terms. So let's just take, say, hemorrhagic fever, which was the search query, search terms that were put in. Here, what we get back here are all the terms that are found to be semantically similar. This is all using what's called term embeddings to find what is semantically similar to it. In fact, I can actually change it. So let's say I don't want that word because it combines those together. If I send that in, you'll notice that it will be slightly different hemorrhagic and all the different variations, so that it can help that investigator, that user, find that relevant information. We actually have a lot more that I don't show in the UI, such as how similar it is, other aspects, but it is just a really simple machine learning technique that we applied into it. The final thing that I'm going to show through the API is what we added from our partner, Agolo. As I mentioned here, we've been lucky enough, as we went through this, to not only be able to leverage some internal Microsoft technologies, but talk to various different other organizations that are interested in participating in and adding their capabilities into this. So what they'd been nice enough to do is provide an API endpoint to their tech so that I can, not only send the search query that comes in, but also the text, so the title, the body, the abstract. What comes back is based on that search query, here are the sentences, the top sentences that best represent that query, "COVID-19 treatment". If I want, I can actually see a ranked order. So it turns out the second one, is actually the most textually relevant based on the context of that search query. So this was a nice addition so that, as you saw in the first demo, when I clicked on the document, you can actually see and summarize it very quickly. There's a number of other things that we're adding in through different partners and groups as well, that you'll see over time. Hopefully, that gives you the idea of ingestion and the custom skills that we use as part of it. Let me go back to the PowerPoint and show you a few more things. So that was the data preparation and the data ingestion, which is through the cognitive search ingested on a regular basis. So as we get a new data from the Semantic Scholar, we can just take the incremental data and apply that in. Now, let's take a look at the actual search application and the components that were used for that. One of the big aspects of this is the App Service, Azure App Service, where we're just hosting in ASP.NET MVC-based application. I'm not going to dig into this very much detail, but basically this is the web interface for the user that you saw, they had the UI to query it. As you query the web app, what we do is we say we're going to take that query, and we're going to send it to Azure Cognitive Search and get the most relevant results, which you saw in the results. We can also call this container, so that what we do is we take that query, those terms, hemorrhagic, and we find that semantically similar terms. If you click on a document, you can actually then or you actually call the Agolo REST API, which you just saw. Get the most relevant sentences, and then populate that in the UI as well. One of the things that you didn't see, but one of the things that I find to be really important in these applications, is to get the User Feedback. What we use is we use a technology called Azure App Insights. So as a user is searching and clear querying and clicking, we're actually gathering that information and learning, so with that, we can get that system be smarter and smarter. So that as we gather that data, we can get those insights and we can continue to enhance the search index. We can take the feedback that, based on these types of queries, these types of documents are likely more or less relevant. We can actually use that to help tune and rank the search results in a more appropriate order based on what we're learning from users. So that whole feedback loop is often very important. If you're looking to build something like this, even if you're not going to start by optimizing the ranking, it's really important to start gathering insights from users so that you have that ability to make it more relevant in the future. If we put this all together, you can see this is the Full Conceptual Reference Architecture of all the pieces that are in there, as of today. We continue to enhance it and based on our learnings, but this gives you a good idea of how it all comes together. So with that, what I wanted to leave you with is a couple of links for you to look a little bit more. Obviously, there's the online application, which, as I said, might look slightly different as we continue to enhance it. There is this GitHub repo. So if you want to replicate or reproduce any or all of the things that you just saw today, you can go here to do that. If you're interested in the Text Analytics for Health Private Preview, here's a link where you can actually register to get access to this container so that you can do make those same calls, pass the text, and get the medical entities that you saw before. There's the Azure Cognitive Search documentation. As well, I included a link to Agolo, thanks to them for their help in providing the Contextual Document Summarization. Finally, if you're interested in learning more about Azure Cognitive Search, we have a number of different sessions, as you can see here. Highly recommend these ones, if you want to get into more depth on the underlying technology to power of this. So I really appreciate you taking the time to join me today. Thank you for watching. I'll hope to talk to you more, soon. Thank you. [MUSIC] 