 Hey guys and welcome back, so in this little tutorial that you are seeing right now is an app that is demonstrating how YOLOv4 can be used for social distancing monitoring. So, in this tutorial, I am going to show you how you can implement your own social distancing app using YOLOv4. So how the app works is that after we perform detection with YOLOv4, we calculate the Euclidean distance between all the detected boxes and filter out or flag the people that are closest to each other indicating that they are at risk. So before we get into the tutorial, let’s take a look at our road map Tut 1 we spent setting up the pre-requisites Tut 2, we installed darknet & implement YOLOv4 on images and video Tut 3, I explained the darknet output code for video and webcam execution. Tut 4 – Which is this one, where we will creating a Social Distancing App Ensure that you have completed the previous tutorials before attempting this one. Okay so let’s get right into the tutorial Another thing, please don’t forget to watch right till the end, to find out about how you can win one of 20 free enrolments to the course of your choice including this one. And, if you like this video, please give it a thumbs up, comment down below if you have any questions or any suggestions for future videos. Subscribe so you get notified when the next AI/AR tutorial is out. Feel free to share this video with any of your friends if think it maybe helpful. So let’s get right into it and Roll Intro! So the full YOLOv4 course will be available as a comprehensive course on Augmentedstartups.com. I’m pretty excited for it because we are going to be covering a lot, From Execution of a pretrained model on images, video and webcam Labelling a new dataset in YOLOv4 format Creating custom dataset from other datasets but in YOLOv4 formati We then train our own custom detector natively on your PC, We also Implement on a MultiGPU Develop some real world application We also going to how you can create a nice PyQT user interface for object detection using YOLOv4. I really hope that you are excited by this course as I am, because if you are then you can enroll down below. Remember that I will not be publishing this course anywhere else and will be exclusive to AugmentedStartups.com Okay so if you are ready to get started with AI, Computer vision and YOLOv4! Click the link down below to get started. 1. Social Distancing Monitoring App Okay so first go to my GitHub repo, github.com/augmentedstartups/yolov4tutorials. Just not that I have updated my GitHub from reigngt09 to augmentedstartups so if the previous link didn’t work, its because of this update. So, moving on. We are going to be working with App1 Social Distancing App. While we glance at it, click to clone or download the code. So over here we have 2 files. They are both the same file, except one is the base script in which we will code the functionally of the social distancing app together within this tutorial. However, if you just want to skip the coding, then you can just download and run this file, if you do, then this tutorial will be explain how this app was coded. We’ve also heavily commented the lines of interest for reference. Coding Okay so once again you have downloaded and opened up the base code. You will see 4 sections that we will need to code in order to get our social distancing monitoring app to run. The rest of the code was explained in the previous video. Euclidean Distance Code So lets get into the first section, and populate the function that calculates the Euclidean distance between two points. It’s very simple. dst = math.sqrt(p1**2 + p2**2) So dst or distance = the square root of the sum of the squared points. And we return distance or dst. Next we have the convertBack function that we’ve seen in the previous tutorial. And this converts our center detection coordinates into rectangle coordinates. I shall explain this in the later part of this tutorial. cvDrawBoxes Code Okay so this is where the meat of the code will be. There are 3 sub modules each with different goals. We are going to start with the first 1 which is 3.1 3.1 Person Filter Lets type in if len(detections) 0: So if we have at least 1 detection in the image. It essentially checks for detection presence within a frame. centroid_dict = dict() If the above condition was met then create a dictionary and calls it centroid_dict objectId = 0 So this is we initialize a variable called ObjectId and set it to 0 for detection in detections: In this if statement, we filter all the detections for persons or people only name_tag = str(detection[0].decode()) So this Checks for the only person tag of the Coco file which has strings of all the names. if name_tag == 'person': So if the tag is a person, then we need get the coordinates of the detection. x, y, w, h = detection[2][0],\ detection[2][1], detection[2][2], detection[2][3] So what this does, is that it stores all the center points of the detections xmin, ymin, xmax, ymax = convertBack(float(x), float(y), float(w), float(h)) Now remember we spoke about the convert back function which Convert from center coordinates to rectangular coordinates. We also use floats to ensure the precision of the BBox. Now we Append center point of bbox for all the people detected. centroid_dict[objectId] = (int(x), int(y), xmin, ymin, xmax, ymax) This Creates a dictionary of tuples with 'objectId' as the index center points and bbox. So we gonna go back to the convertback function, and If we visualize a bounding box, we normally have our center point with the coordinates x, y with a width of w and height of h. Now when we pass it through the function, where we want to obtain these rectangular coordinates xmin, xmax, ymin and ymax. It will make it easier to enter in the parameters for drawing the rectangle for the bounding box 3.2 Social Distance Criteria Okay so next up we are going be creating 2 list red_zone_list = [] and red_line_list = [] So these are Lists containing the Object id that is in under threshold distance condition. So for (id1, p1), (id2, p2) in combinations(centroid_dict.items(), 2): So this gets all the combinations for close detections, So it looks at the List of multiple items - id1 and id2 which are the index and p1, and p2 the points 1 and 2 dx, dy = p1[0] - p2[0], p1[1] - p2[1] This Checks for the difference between centroid x: is 0, and y denotes 1 distance = is_close(dx, dy) Rememeber earlier we saw the is_close definition, well here we call that function to Calculate the Euclidean distance. So if distance &lt; 75.0: This Sets our social distance threshold to a constant - If they meet this condition then.. if id1 not in red_zone_list, then we say: red_zone_list.append(id1) This Adds the Id to a list, and then we have red_line_list.append(p1[0:2]) so this add points to the list, and then we do the same for id2 in red_zone_list: red_zone_list.append(id2) red_line_list.append(p2[0:2]) In the last section for this module: for idx, box in centroid_dict.items(): So here we search within the dict with respect to index which is the key and box is the value if idx in red_zone_list: So if the index is in red zone list then cv2.rectangle(img, (box[2], box[3]), (box[4], box[5]), (255, 0, 0), 2) Print our image (box[2], box[3]), (box[4], box[5]) and then we set our color to red which is (255, 0, 0) and with our point size of 2 else: cv2.rectangle(img, (box[2], box[3]), (box[4], We create another rectangle but we make it green, and here we have our color which in RGB which says (0, 255, 0) which denotes our green color 3.3. Risk Indication In this final module, we indicate how many people are at risk text = "People at Risk: %s" % str(len(red_zone_list)) So this basically count People at Risk We want to put the location of this text at (10,25) Which as I mention Sets the location of the displayed text And then we have cv2.putText(img, text, location, cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2, cv2.LINE_AA) and essentially this entire line just display Texts in red for check range(0, len(red_line_list)-1): So here we tell the app to Draw lines between nearby bboxes and iterate through redlist items start_point = red_line_list[check] end_point = red_line_list[check+1] check_line_x = abs(end_point[0] - start_point[0]) Here we Calculate the line coordinates of x, then we do the same check_line_y = abs(end_point[1] - start_point[1]) and again we Calculate the line coordinates but for y if (check_line_x &lt; 75), which is the threshold that we specified above and (check_line_y &lt; 25): So this is our if statement to check that the lines are below our threshold distance. Next we have cv2.line(img, start_point, end_point, (255, 0, 0), 2) So if above statement is true, then Only the line below the threshold lines are displayed. Okay so if you typed everything correctly, then we can go ahead and run the app. Open up command prompt. Make sure that you have a bunch of test videos, which you can get of the net or if you prefer, you can use your webcam. Type in Python App1_social_Distance.py. If you are using the base file then just add_base to it If you want to change your input video, then you can change it here. Ensure that your Input directory matches the directory of your video. And then run again. So using a GTX 1080, I am getting more or less an average frame rate of 18 fps. If you got this working, post down below a link to your video or image of social distancing working in action. let’s take a look at our road map Tut 1 we spent setting up the pre-requisites Tut 2, we installed darknet & implement YOLOv4 on images and video Tut 3, I explained the darknet output code for video and webcam execution. Tut 4 – Which is this one, where we will creating a Social Distancing App Dataset labelling and developing a custom YOLOv4 objection detector and training will be a part of my YOLOv4 course, I’ll have a link to that below. And, if you like this video, please give it a thumbs up, comment down below if you have any questions or any suggestions for future videos. Subscribe so you get notified when the next AI/AR tutorial is out. Feel free to share this video with any of your friends if think it maybe helpful. Okay, so earlier I mentioned that if you are interested in winning one of 20 free enrolments to any Augmented Startups courses, then all you have to do is like and comment on this video and sign up at the link below. Winners are announced every 3 months. You can comment on anything or provide suggests for upcoming video and ideas as I’ve mentioned earlier. So the full YOLOv4 course will be available as a comprehensive course on Augmentedstartups.com. I’m pretty excited for it because we are going to be covering a lot, From Execution of a pretrained model on images, video and webcam Labelling a new dataset in YOLOv4 format Creating custom dataset from other datasets but in YOLOv4 formati We then train our own custom detector natively on your PC, We also Implement on a MultiGPU Develop some real world application We also going to how you can create a nice PyQT user interface for object detection using YOLOv4. I really hope that you are excited by this course as I am, because if you are then you can enroll down below. Remember that I will not be publishing this course anywhere else and will be exclusive to AugmentedStartups.com Also check out Geeky Bee AI who are expert developers in AI, Computer Vision and Deep Learning. Thank you for watching and see you in the next video. 