 welcome to we count's webinar on ai powered mobile assistive technology apps risks and benefits a conversation with dr roger melco before we begin ocad university acknowledges the ancestral and traditional territories of the mississaugas of the credit the haudenosaunee the anishinabe and the hiron wendat who are the original owners and custodians of the land in which we stand and create for this webinar we will first go through group presentations where five groups will present their overall findings from previous sessions part one and part two next dr roger malcolm will present and further explore this topic followed by an audience q a after closing remarks will follow we kindly ask that you input comments in the chat box and questions in the q a feature before speaking please say your name so that we can identify you more easily and we ask that microphones are kept on mute unless you're speaking this webinar will be recorded our captioning booking today for today was superseded by other major events that are happening today so we have a volunteer captioner um you can turn captions or subtitles on in the menu at the right of your zoom window and many thanks to rachel for bravely taking on this task of typing at superspanic speed so before our presentations here's a brief video to tell you a bit more about we count we count a project of the inclusive design research center at ocad university was created to address barriers to participation and employment for persons with disabilities within data science and data-driven systems as data becomes the main source for truth and value persons with disabilities are becoming increasingly marginalized because their needs are not considered within the data ecosystem many systems are designed for the cluster of people at the center for those people the design works well as we move away from the center the design becomes more difficult for people to use and may even be unusable we count addresses barriers throughout the data ecosystem a data ecosystem is the complete cycle of pieces of information as well as individuals and organizations within that system this cycle includes individuals who generate data or information systems that collect and analyze the data individuals who build or use the systems collecting analyzing visualizing and generating insights from data and the decisions made from this process and training hiring and working within data science fields the goal of we count is to create an inclusive and balanced data ecosystem for persons with disabilities and others who are excluded a data ecosystem that increases participation addresses exclusion and bias ensures community input increases employment and decreases vulnerability to data abuse and misuse to achieve a fair data ecosystem we count as focused on sharing current views in inclusive data science gathering resources data sets and inclusive data tools and involving the community through design challenges workshops and events as the data ecosystem continues to evolve we count is working closely with the disability community and our established network of partners to identify and solve key accessibility challenges to learn more about we count visit our website or follow us on social media we count is funded by a grant from the william and flora hewlett foundation and is supported by innovation science and economic development canada's accessible technology program thanks uh now without further ado let's move on to the group presentations super suns will be going first followed by mapping hood ava seeing ai and lastly envision okay let's begin good morning everyone thank you for attending our presentation on the artificial intelligence app supersense this is an app that is geared to assist those with low vision and that are completely blind with reading materials such as documents barcodes and currency as well as deciphering objects within our environment when we are navigating we would like to talk about discuss the risks and benefits as a group around this app through our experiences one of the challenges or risks is there's a privacy issue with personal data sharing so what is our data being used for n1 such as utility bills credit card information etc there's a lack of privacy data sharing policy which is also an issue one of the benefits is the trade-off so we are sharing our personal data in order to improve and enhance the app itself another risk or danger is the fact that supersense can misread or mislabel objects or information such as misreading a radiator for stairs uh and not uh sometimes being unable to read coins change canadian currency as well as foreign currency which can be an issue as a completely blind member working in society i don't feel that this app is safe to use at this time and can definitely use more testing and improvement um which should have happened before it was uh released into the hands of those with with uh blindness and that revision impaired uh but i am optimistic for the future that artificial intelligence will develop more apps uh that will enhance our quality of life and now i will hand it over to when hi everyone can you all hear me yes lin go ahead okay thank you tammy your feedback is important and should be taken into consideration by supersense app designers and developers my name is len i am a ui ux designer i'd like to start by saying that our criticism is meant to be constructive and we do understand how far technology have become in order to make it possible to create a cmai app so in my opinion i'd like to second what tammy said super sense appears to still be in the testing phase and perhaps should not be available to the public yet due to many safety concerns i'm not aware of the exact uh measures taken before launching supersense but moving from a prototype towards a functional product is difficult and in this case should have required large-scale user studies overall the app does not seem to understand exactly what a human user with visual impairments might really need and now to speak briefly about the effects on the community i wanted to relate to the pandemic that's going on today so today it is perhaps less acceptable for a visually impaired person to make physical contact with a stranger and request help for example in navigating a public space so i believe that this is the time for seeing ai to offer the visually impaired and blind community a new sense of mobility independence and on the other hand some additions to the seeing ai apps like super sense can improve the overall user experience and maybe uh help make it more enjoyable for the user like for example the use of multi-dimensional ear cons or audio icons to indicate exactly where a certain object may be uh another thing that could be added is maybe offering more elaborative descriptions of uh objects for example instead of uh saying there's a cat the app can say cat sitting on a couch or for example a table instead of seeing a table it could say a table with a lot of items on it and i will pass it over to sean good morning hi uh thank you group members i'm i'm from an active ontario my creativity specialist in performing arts and small business improving startups and closures the story of how we came to be we theorized and documented the wave patterns in our brain to give ourselves deeper understanding of the environment that's in front of us and how to go about transforming that environment not only to suit our comforts within within it but to further seek out new challenges for necessity and comfort history taught us that through the direction of others we can learn to better conduct ourselves effectively to better those directions plus how to maintain our experience within the augmented environment and that included the differences in wave patterns of persons with physical disabilities today we've learned instead to adapt to our environments around us based upon our very individual complex needs we cannot afford to lose grasp of inclusion before it really understands the value in what is now the awareness that supports our inclusion ai in the classroom is not the end of humanity it is the evolution of our species moving in its natural direction we like the idea of an eye in the sky society but we strongly caution the disabled community that we do not exhibit the same state of brainwaves that we are a community among ourselves the correct professional in any one certain area of medicine or disability are the required persons for hands-on involvement with the creation of official credentialed approved rehabilitation tools the digital world like google play store was created by a modern mainstream idea in a complex modern civilization as overpopulation and economical corruption the effect of our environmental footprint begins to interact with these quantum data input devices doing our part is to maintain a standard of awareness meaning inclusion is what where we have the option of using an augmented environment so that inclusion does not mean i must adapt to using an ai quantum functions parameters for of what happiness means to me thank you everyone thank you so we're a little shy on time but i'm wondering if uh roger if you had any comment you'd like to make at this point um i myself noticed a an important emphasis on options um how about you yeah one one thing i think which uh was interesting um interesting point raised by tammy was the fact that um you know you're sharing data with super sense you know in order to improve and enhance the app itself um as you use it and a couple you know a couple questions which you don't have to answer but which is i think interesting to consider is number one uh presumably in the terms and conditions of using the app a user agrees uh to do that and i wonder how we as a community decide how to balance the fact that you know we might be protective of our data that's that's being used to enhance the app but also we want the opportunity to shape the technology right when you feed it your data whoever you are as a user you're shaping that technology and it's not a question it's more of a comment but it's something i'll return to perhaps in my presentation thanks very much thanks super sense and now i believe map and hood is going to take the floor so hello again what's everyone my name is chris and i'll be representing our group today so our journey through this workshop is being rewarding and informative and our group has definitely been better educated in the use of ai in our everyday lives through this process so i'd first of all like to acknowledge our team and thank them for their hard work and dedication to this project uh joseph minnette sabal lisa monica karen or as we like to be called the group in the hood we would also like to talk to thank dr malcolm for his work with ai and his keen desire to make assistive technology better enhancing the lives of those within the disability community so our group strongly believes that if all the work time money and effort invested in this technology is able to benefit just one member of our community then of course it's all worthwhile so thank you again for your efforts our group was chosen to evaluate the ai powered assistive technology mobile app called map and hood mapping hood is a personalized pedestrian navigation app for the gta and surrounding areas it's very similar to other apps like google maps accessnow and waze to give you an idea the app is intended with the use of ai to aid persons with disability and safe navigation of streets pathways parks and accessible features the app uses crowdsourcing to collect data now our group focused on five specific areas of the app it's function its benefits its potential its impact and of course the safety fairness and ethics surrounding the app our first discussion point centered around the app's function and whether after several days of trial did it actually work for us we know as a group we need to change slides right we need to flip the slide karen we think that if you go into presentation mode first and then share your screen you'll be able to select the correct window we think that zoom is on the wrong window and that will that will help things along i think i will do that while you continue christmas like yeah okay i'll continue on for the sake of time absolutely but the visuals definitely do add you know so as a group we found that map in the hood it did not fit the lifestyle of a person with a disability we found that it was slow to react it wasn't very intuitive and some of us actually found it difficult to physically access and use the app itself was unable to correct or make changes it was sometimes very disorienting and confusing it uses only a graphic visual presentation and it definitely needs a full textual option for someone with navigation challenges the app amplified those challenges rather than reduce them while it did speak directions which would be useful to a visually or spatial impairment they were spoken after the turn was made so for example it might say turn right on here ontario street three meters ahead but was actually spoken three meters too late so our conversation then proceeded with the app to discuss the possible benefits of the app the app was designed to enable people to identify hazards amenities points of interest and path features in theory this could potentially help people meaningfully navigate their environment in real time you know for example finding things like benches garbage cans drinking fountains washrooms healthcare facilities crosswalks stairs seasonal hazard construction and even an escape feature or a quickest way home finding these landmarks and alternative routes is extremely useful for persons with both visual and invisible disabilities disabilities can be intersectional the environment the experience of barriers for people with multiple disabilities can be compounded or cumulative and amplified so as a result our needs are layered for example identifying temporary construction sites and roads around them can be especially helpful for those people who have been who have respiratory conditions and difficulty navigating changes to their regular routes so what is the potential versus say the privacy and the bias so the app was designed to collect our personal information for example our travel routes places of interest time of our daily travels and tags we as a group were concerned about how our data is actually being collected and it and how it will be used now and in the future and who actually has access to our information there isn't really any transparency within the app as to why the information is being collected or how it's being used and how it could be used in the future the more i tag the more data they collect this poses several questions for us and concerns who can access what people tag both now and in the future could our personal information be shared with police or other authorities are some populations more at risk than others if they use the app is this at if this app is more accessible or usable for some populations more than others how will this distort the type of tags that are being placed and who will be left out from further use and does this problem of dominant voices amplify over time what are we trading off what are we compromising to get our needs met what then is the impact of a quality of life for individuals within the disability community if the app worked as intended it could improve the autonomy of people with disabilities and meet us where we are it could reduce the friction of barriers by helping people navigate around them and therefore improve predictability which could in turn reduce stress and anxiety and improve the safety and quality of our lives however this can be a double-edged sword when we seed control to an app that uses artificial intelligence including machine learning to meet our needs we are vulnerable to the implications of hidden decision making the decisions while while in town intended are founded in historic and systemic bias for example how infrastructure services and authorities have responded to certain neighborhoods without participatory engagement in the decision-making process are we letting the app decide for us how we connect within our own communities ai is a black box and uses algorithms to analyze data and make predictions in unknown ways who's behind the curtain and pulling the strings who actually is the wizard in the wizard of oz so then so what then are the safety fairness and ethics of the app our group concluded this app can be unintentionally unsafe unfair and unethical if the risks are recognized and mitigated it is not only about the construction or coding of the app but what it uses or favors and for what purpose and how it is used to amplify social bias and discrimination for example unsafe if someone else accesses the information and uses that information against the person or group unfair if some neighborhoods may have a more robust database unbiased more than others about unethical who are the third party users and where is our information being used both now and in the future who is accountable and what mechanisms are built in to cover the ethical fair and safe use of collected data that informs ai our group discussion raised a lot of thought-provoking questions and concerns surrounding the use of ai and its use in assistive technology mobile apps so in conclusion i'd like to now turn it over to another one of our group colleagues for our closing remarks good morning everyone in conclusion the app does not seem to work as it should therefore it is not beneficial as intended we find it disappointing and frustrating at the same time usage data is automatically collected when using the app we find collecting personal data such as internet protocol address the type of mobile device device used the mobile device unique id the iap address of the mobile device the device unique identifier how one interacts with the app and other diagnostic data whatever that means alarming it feels like stalking even more personal data can be collected when one signs up through a third party social media account we don't see what or why collecting personal data such as someone's activities and contact information has to do with an app that is supposed to make people feel more independent we do believe that ai and collecting personal data is unsafe unfair and unethical we believe that the individual should have control over how much information he or she is willing to share who knows whether all data that is being collected is for improving the app or other uses it is a scary feeling knowing that every time we interact with the app personal data is collected stored at use for multiple reasons and that we have no control over the data that is being collected persons with disabilities are a vulnerable group of people striving for equality and independence we try to be independent we may try new new ai in the innovations that promise independence by only thinking about the prose and completely neglecting to think about the cons there should always be an option to share or not to share personal data through ai and this option should not exclude anyone who chooses not to share that data producing the ai or app application thank you very much thank you uh group mapping hood or group in the hood uh that was excellent uh enjoyed that roger did you have any comments you wanted to make before we go to the next group just a quick comment it's it's great to hear uh all the participants and pres presenters so far uh you know being aware of security and bias issues surrounding data chris said something important which is that there's there's a historic and systemic bias in data sets that have been used to develop ai and and this is one thing that i'll also focus on uh in my in my presentation i'll show some examples of historic data uh that displays a systemic bias which has been affecting the technology to this day so thank you very much for this presentation and now i'd like to uh suggest that the seeing a i group unless i've got my order incorrect someone tell me if i'm wrong okay so i'm going to assume i'm right so seeing ai are you ready to present sure uh give me one second to share my screen and i'm going to let the other groups know that we're perfectly happy with you taking over the screen while we discuss the previous presentation so you're able to get set up and i see you're ready to go okay sepi yeah good morning everyone um our group is reviewing the app seeing ai from microsoft it's a well named app if it's architectural it's targeted for blind and low vision users to use artificial intelligence to understand their environment cepeda is our facilitator our group members included anthony leslie ortiza christine who will be presenting our recommendations for companies that create these apps and government to help govern these things at the end and myself david so on our first slide about seeing ai it explains it how it uses the camera on your phone to gather information from the environment and it has nine different modes so this app is fairly mature much more mature than super sense and it can do a lot of different things or attempts to do things shall i say because it's not very accurate yet it needs more data more work to make it better so it's got can short text so you can look at like household products to get gather information and it can use ocr to do that it does document recognition bigger documents it seems to do a little better job on that it has barcoding scanning reading for upc codes although it doesn't always have all of the canadian products in there and it's sometimes hard for a person that's totally blind to actually find where the upc code is to start with it has facial recognition and you can teach it to recognize people and friends it has ability to do scenes these are all different channels that you need to select in the app by the way and sort of modes so super sense tries to do it all in sort of one mode so this is um it has a currency mode which does okay and bill is not so great for coins um it has light sensors so if you're totally blind you can point your camera and tell where a light source is or if there's light coming in the window it has the ability to tell you different colors if you point it to clothing although it's that's pretty dicey it doesn't do the best job depending on the lighting conditions so we don't recommend it for fashion coordination and it attempts to read handwriting and once again these things are somewhat immature and with a lot more usage and data they may improve but they seem to have some limited capabilities currently so moving on to the benefits of the this app one of the main things about this is that microsoft has made cai free a free app so it's easy for everybody to use but it's widely available it works on an iphone which most blind people use and it's backed by you know all of the power and might that microsoft has behind it so there's lots of resources and help that you can get for it so one of the things that in the scene things that we noted that if you're totally blind you can point it at a deciduous tree in the fall and if it's got different colored leaves it can actually say oh a tree in autumn so it does have some smarts behind it and can give you some valuable information that if you're totally blind you wouldn't otherwise get so in the next slide these other benefits is it does enhance the quality of life for people that are low visioned and by helping them be more independent they can read products in their house documents maybe their mail and various other things to give them more information and be more independent and if and if they can do that then they can be more independent and feel like they're more part of society and contribute helps their self-esteem so moving right along didn't the sake of time to to some of the cost slash risks of the product and the app one of the things we noted that there's terminology that's used by the cnib another thing is that the target for this app is an at-risk population so this service or this app you know targets this at-risk population and so that there's certain things that need to be precautions that should be taken the they use this app because they need to it's not like it's a recreational netflix or some other application the the like chris said previously you know we are giving freely up of our data and information in the hopes that you know it'll help the database and the ai to improve but we know you know we are giving up our data even though there's disclaimers at the beginning after a while you kind of forget the disclaimer and you have to really spend a conscious effort on what you're pointing your cell phone at to be careful on what data you are sending to microsoft because you could give these giving you know personal pictures of people or personal sensitive documents so on to the next slide um there was really very little information up front even though there was a long disclaimer um on exactly how this data that you get sent off to microsoft is going to be used and and how and who could use it what could it be sold to third parties um it could be given to the government and just generally you know how this data can be used how long it can be used who it can be used for and by whom so that we have a lot of concerns about the usage like the other groups okay and now i'll pass it on to christine to go over our recommendations hi my name is christine malik um some of the recommendations that we came up with um disclaimers are uh you know we should all read them but we don't always read them and sometimes they're so verbose that they're not accessible in sort of the general societal sense so we talked about the ways that um disclaimers could be embedded in the process instead of being one document that you have to read so that as you go you're being reminded about how data is being collected and used um as you as you go so um for example the the facial recognition when i tried to label someone and said oh you should check with them and uh make sure it's okay which is a great reminder and reminders like that would be helpful um when you're say pointing your your camera at your mail or your documents because those are uh even more personal uh to yourself these apps are looking into your home and so it's a bit of a trade-off because we understand that data is necessary in order to develop artificial intelligence but these uh the data that they're getting from us as a vulnerable population is a bit unique i don't think there's too many other populations that are pointing cameras at personal information uh or the inside of their apartment and sending it into the cloud so it's it's a bit of a it's a bit of a a special case so slide eight um it would be good to have an easily accessible uh option to opt out of the data collection um and to inform inform users about how the data is being used a little more specifically uh how is it is being shared is it being sold um what is the what is the fate of the data that we are giving um we wondered about who else gets access to the data and so if it is lent or sold or shared um and how long do those uh those stipulations stay in place for so is there is there a time limit on on those uh and slide number nine we talked about um recommendations for government so the thing is technology's moving so quickly that we worry that government is um perhaps not able to keep up with how rapidly things are changing and so we hoped that there would be policies in place to enforce protection of the data collected through seeing ai and to prohibit the release of the data or the spreading of data our personal data to other organizations um uh we'd like to bind companies to uh trent be transparent about how the the data is is treated um and just to have a general sense that this is a trade-off and so it is a free app and it does give us unprecedented independence but we are also giving something back which is access to data which will help to develop ai so i think an awareness of that is something that we all wanted to keep in mind thank you thank you very much uh groups seeing ai roger did you have any thoughts you wanted to share it's a very uh interesting contrast uh to do a case study on seeing ai versus super sense because super sense is a spin or a spin out of i think it's mit it's like a startup whereas seeing ai is part of a huge tech giant microsoft and so it's interesting to hear your concerns around data privacy and to think about how data might be used by a small startup versus you know really a tech giant where these tech giants himself have a power that really rivals government right and so i think it's uh i think seeing ai really brought up this interesting point thank you all right and now uh we're going to hear from uh group ava and i believe sandra is going to get us started good morning and uh thank you for including me in this project um so we had our application was ava and what is ava ava is a voice to text and a text to voice app that transcribes in real time um your conversation if you're not connected to data or you're not connected to the internet it's it doesn't work as well ava promotes itself as an accessibility app that helps the deaf and hard of hearing community and um ava has a free version and a pro version that allows access at the pro version i love access to which add digital um additional tools and better accurate act better accuracy um and we have a short video this is a demonstration of ava gives live subtitles as we speak this is a demonstration of ava it gives live subtitles as we speak you can see that there's a little bit of changing sometimes to our text as eva thinks well sometimes she thinks we found um with uh with ava that the app infantilizing i have trouble with this word i'm very sorry infantilize uh the disabled um and the disability community it means that treating us treating us like children or less intelligent um because of our disability ava automatically censors curse words and the setting uh to turn it off are difficult to find her default is um no like it's the default is no cursing like it it censors out um and the default is also a male voice and even when even in the um in the free version even when you change the default to female you still get a male voice so we're dealing with again systemic design problems here and we have another video hey what the just a demonstration folks i don't usually swear it's fixed yeah not so much ava puts the onus on the person with a disability to create the accessible situation for themselves the app asks the person with disability to ask their their friends and their colleagues to download the app as well in order to for the app to work at its top performance level and in order for them to be included um and considering the social model of disability where disability is created by society a service that was available freely in public places would be greatly would greatly serve individuals like we would like to see like when you go into um a restaurant a shopping mall a hospital center and you have free wi-fi these kind of applications are made and made available to you for free that's the ideal ava was designed and i think a lot of these apps are designed with with assumptions um we are concerned that ava and many other apps are designed for the user user using assumptions about about them rather than design designing with the user and their first-hand perspective um and here's some some of the assumptions we discovered with ava people that people will be able to speak loudly and enunciate with no accent so someone with a a francophone accident speaking english ava would have trouble picking that up would ava recognize uh a deaf accent um someone with a severe speech impediment um she would not she would not be able to pick that stuff up um and you have to rely on also and and it's assuming that others will be willing to download the app to create a better experience for the person with a disability the clean language um assuming that oh no no no no we're not mature enough or we're not adult enough to to make our own decisions rather on the wording we use um and that people will prefer to have a male voice speak for them um it might be a platform issue um the iphone with the professional version um enabled the female voice but it's the same voice that's used for voice over technology on the iphone um only spoken words are important they don't document any any other sound like you could be communicating with someone and it could be raining outside and it won't notice it won't recognize the ambient sounds uh needs for exclusions are defined very narrowly and and using these assumptions with result with using these assumptions will only result in exclusion i think i said that right now how does how does aid of ava work um user data and other people's data train ai systems the user data and other people's data train iii systems to recognize predict and transcribe language ava sends the user's voice or text data to the cloud and uses machine learning to best support speech to text and text to speech in real time what happens to our data that's that's a concern where does it go ava does not make it clear about where our data is going and how it's going to be used the terms of service do not disclose whether the conversations are being stored how much the microphone act how much microphone access ava has and what the collected data if any goes toward um they don't the terms of service and and the agreement is very hard to find after you've in the after you're in the app and it all in legalese it's not in normal simple easy to understand language and it was very confusing for our group to understand and figure out where the data was going in what permissions were needed and whether our personal information would be scrubbed from the data and they would just be using the bare data so for us with with five or six minds together trying to figure it out how is one individual going to figure it out um and there doesn't seem to be a way to change the access or control what's being done with it um and we wondered also if um pipeda does cover the apps and pipeda is the personal information protection and electronic documents act it's the federal policy law for private sector organizations in canada it doesn't it's not clear if ava's an american app does our laws cover it you would think that they're marketing it to us and we're paying possibly paying for it so it's not it's it's not clear at all um the app privacy is too confusing for the regular user we think uh that where apps are are asked we think that where apps are for accessibility then the app producer should go beyond the minimum to for transparency and ease of understanding so minimum code minimum expectations no longer play in this they have to go above and beyond so our summary um we see the benefits and the potentials of apps like ava but there's so much room for improvement um the infantelizing needs to be removed from the system placing the onus on the person with disability needs to change we need policy and social change to build a culture of inclusion so that accessibility levels like this are built into our systems we need to remove ableism we need to figure out how to do this and protect privacy a better balance needs to be represented in the ai driven products with co-design and representative representative data privacy security and ownership of the data data needs to be clear and customizable for each person more control over data uses must be given to each individual they have to stop taking our rights away and allowing us to make the decisions that was our findings that was what we discussed and we feel that there's a long way to go there's a lot of work to be done thank you thank you very much group ava roger very nice sandra thanks so much just one uh kind of quick thing which uh struck my mind uh since we're talking about voice to text and in ava you're inputting uh you know you know literal um audio voice voices yes what what the app currently does is translate it into text but in in the meantime what as you demonstrated it also does a lot of interpretation and so on and what what you might not be aware of is it's provided enough data uh you from from voice uh you know we can uh take those conversations or our artificial intelligence can take those conversations which are being stored and actually use them to generate new conversations and i'll show you a text example in my talk but isn't it frightening in a way to think that you know if you speak enough into an app the app can later after being trained on your voice generate new conversations that didn't come from you but you know could fool sort of the average listener so i think it's something really interesting in terms of privacy that that your presentation well i don't i i just just to add one more thing i don't think people realize when they say it's a smartphone it's a smartphone okay um my nephew and i were talking about this because i was ordering over the presentation with him and he said he never told he has an iphone he never told siri where he worked okay but siri automatically like she tracks his route and tells him he's leaving home and going to work knows exactly that home is here and work is there so the ais in our phones our smartphones are actually learning constantly certainly and and one point is i think the you know it's as you've demonstrated the iphone um has the ability to take i think take ava and use siri's voice over top of what abe was giving you but since you're speaking into your phone all the time what's stopping siri from using a replication of your own voice but it's not siri's voice that they use it's actually the voice over technology within the iphone for um for someone who is blind got it okay yeah it's a different the two different voices thanks so much for that great and now our our final group um i believe is it envision it is okay yes and i realized um before you begin doug i'm just gonna in the chat drop the names of the group because we didn't include that in our presentation so it's doug who will be presenting today richard cecilia sahang who couldn't be with us today rob and myself take it over to you okay so we've got the screen we can see the screen ai powered mobile assistive technology apps envision ai this app uses your camera and ai to scan read and describe items in your environment benefits of envision ai easier access to information identifying objects scenes people and documents increase increases independence boosts confidence concerns security of the servers of the servers where personal data is stored for example people's faces and identification privacy of sharing images of your surroundings lack of privacy and discretion while holding your phone up to use the app not identifying things accurately which could pose safety issues for example misidentifying or not identifying stairs or a curb the app is quite slow it is manually activated and can take several seconds to provide information government policies and regulations need to catch up with ai technology development ideas want to be able to have the app on all the time provide real-time information on an automated ongoing basis example scanning your surroundings as you walk down the street ability to voice trigger the app and ask it questions being being able to more discreetly use the app for example using the app with glasses where possible information should be processed on the device itself leveraging the built-in technology this could be faster and improve privacy integration with human assistant with human assisted apps such as ira or be my eyes now we have a couple of questions for dr malcolm in what direction do you see these amps developing to further support people with disabilities that's question one question two how can we how can we ensure that the data the app collects and learns from is representative of diverse needs and groups thank you thank you very much thank you uh group envision ai uh now roger we're going to be hearing from you shortly i don't know if you would like to respond to those questions uh now or if you're going to integrate them in your talk why don't you let me know what works for you um i can do a little bit of both um so regarding the first question i believe you know further development of the apps will sort of go hand in hand with further augmentation of reality or the development of augmented reality tech and i'll talk a bit about that but you know it's interesting that you mentioned say glasses or you know i'm wearing earbuds or we can imagine wearables and and i'll talk about how we interface with technology but i gather from your presentation that discreteness is important and that's something that i've taken away from it you could imagine that you want to have say uh you know discreet interface with the apps but say imagine that you're collecting images through something like glasses you also have to balance this with the privacy of the shared images which is something else that you mentioned um doug and and you know you have to be aware that people in shared images you know for example can have their faces detected even now these days through masks so it's an interesting point the second point is it it's all about data and the um you know the inclusiveness of our data and the fact that we need diversity in the data sets that are being used to train these apps and i'll talk about that i think during my presentation so thanks very much for this one okay and celine i'm gonna move it over to you thanks vera so thank you everyone for presenting um it's really interesting to see what all groups have accomplished over the past weeks um you can see you really dove into the risks and benefits of ai so next we'll be moving on to dr roger malcolm's presentation so let me introduce dr roger malcolm he's a professor in the department of physics and astronomy at the university of waterloo associate faculty at the perimeter institute for theoretical physics canada research chair and computational quantum many body physics and faculty affiliates at the vector institute for artificial intelligence his areas of research include quantum matter and the development of efficient algorithms for stimulating quantum mechanical systems on classical computers and the relationship of these methods to machine learning in quantum information science so this workshop was inspired by dr roger milko's cpc ideas podcast about ai and machine learning allowing computers to learn think and dream near the end of the cbc interview dr roger malko says science and technology progress much faster than policy in many areas and much faster than our ability to keep up with the ramifications of what's actually being invented dr roger welcome talks more about how technology may advance and affect societies now in its future he raises an important point and this inspired the focus of this webinar and a question that we asked groups to think about which was how would ai impact society and the way that we live work and interact with people how would it increase or decrease occlusion inclusion or equality in this podcast we're really interested in dr malcolm's take and enthusiasm to study and question these technologies and how he can further explore this topic um so now dr malcol you have the floor to present thank you celine let me share my screen hopefully this works and i hope everyone can see that and i'm just going to press play here selene maybe you can tell me if this is going to see it great so thanks again celine very very gloria and everyone who facilitated uh this workshop it's actually been very um educational for myself so again thanks for the nice introduction i'll just skip over um the first slide that shows some buildings and get right to kind of i believe it's the you know really in some sense the topic of of conversation now and i pulled this from the description of this workshop artificial intelligence is rapidly advancing to think like us and to deep dream through machine learning how can we leverage this technology to improve accessibility and it's the same time keep up with the ramifications uh so this is this is uh the words of the workshop organizers and i think this is a very sort of wise set of questions and you've all explored these uh these set of apps and and what i'd like to do is uh dig a bit deeper into some of the concerns raised by the presentations along these two lines and i want to particularly emphasize this point of deep dreaming later in my presentation uh which has some analogies to i think what some of you uh presented today and then we'll close with a brief discussion of the ramifications so as every presenter i believe amongst you uh emphasize the key you know to artificial intelligence is very much the data that artificial intelligence is used to make itself intelligent so it's it's you know we are used to computer programs being blocks of code and there's certainly our architects who design artificial intelligence systems but as you rightfully emphasize and in my opinion it's it's much more consequential in terms of um this this sort of behavior of the artificial intelligence systems with regard to which what data they are being fed rather to the actual code architecture so focusing on data is is the key and i want to address two points first off how is data used to make computers intelligent intelligent so i want to sort of do it's not very technical but hopefully a slightly technical explanation of of machine learning and neural networks and how they use data to learn and then the second point i want to address is how we humans produce and consume the data that is used for part one so i'll get back to that but so let me focus on how data is used to make computers intelligent and i think for all of you who interface with these apps for a week or longer you got a great sense i hope of that your data and the data of people that have come before you has really been leveraged to train the apps that you are using so for example when you take uh one of the apps like i don't know maybe super sense and pointed out a dog you know what what the app can produce is what in in artificial intelligence research we call a label so for example i'm illustrating uh sort of a phone uh you know which is held up to a labradoodle and you know the this one in particular is google lens but google lens is labeling uh you know inside the phone the dog breed and the phone of course could also uh you know instead of text could also say speak that to you through siri and i i've i want to use this example of cats versus dogs and i've used the emojis at the top when i say dogs and cats because i want to emphasize that this is a label and an emoji is is a really nice uh sort of way of of concisely saying that this is a representation of [Music] of um of some object in an image that i can assign a distinct label so of course that image of that the labradoodle is many pixels so it comes in from your camera so all these pixels somehow go into this artificial intelligence system and they produce a label say cat or dog so how do we just how do we teach artificial intelligence systems to distinguish between two different labels i illustrated on the screen a very simple type of neural network and i'll just describe it quickly for those of you that can see it on the left hand side i have square pixels which i'm imagining can take binary values or maybe you know black and white values or maybe a grayscale value or they could be colors and and what i'm imagining is that that picture of a labradoodle or any dog or any cat is kind of decomposed into its constituent pixels on the right of these pixels is i've illustrated a deep neural network which is edges and nodes or it's lines and little circles which in some sense represent the signal or us signal which propagates through this deep neural network and we what we do in artificial intelligence is we encode this neural network virtually in a program but it's not a static object it changes based on the data that is it's exposed to so when i train a neural network with the data that you upload you know to facebook to instagram to any of these apps to microsoft to google to amazon really what what you're doing is contributing to the training of one of these neural networks and typically what happens uh in this training is thousands or millions or billions of pictures are forced into the left-hand side of that neural network along with labels on the right hand side and so the labels are sort of the the bottleneck in some sense in this case of the neural network and i imagine a signal that's propagating through from the pixels of of the of the actual camera image to the labels and if i if i reinforce pictures of dogs with the label dog and pictures of cats with the label cats over and over what i do is i strengthen uh some of the uh you know i strengthen the pathways for the signal propagation in the neural network and so what i've illustrated here is some of the lines are thicker than others and so this is the learning procedure this when we when we talk about machine learning this is really what machine learning is it's taking all that data and it's taking curated data data where i might have had humans assign labels cats and dogs and it's used to strengthen those pathways okay and how do those labels get attached well it's by you every time you tag somebody on facebook or or instagram or something like that you're assisting in this labeling of of the of the pixelized data so then after this uh these these network connections are reinforced some are thin and some are thick uh we can show the neural network new instances of data okay so here's a picture of a dog that the neural network has never seen before and if it's trained properly the signal will propagate through the neural network through this myriad of pathways and hopefully it'll fire that last neuron an analogy to you know human brain which is associated with that label and similarly if i fed in a picture of a cat a picture that the neural network has never seen before if it has been trained correctly on previous images it will fire that neuron that's associated you know with the cat label and so in this sense you're discriminating between dogs and cats you know using the neural network and most of the apps that you used most of the functionality is sort of sort of this discriminative uh functionality where you're you're sending in a camera image or you're speaking and and what you're doing is you're associating either a photo or a word you know with with a label or its equivalent text and and so these pathways that are strengthened in the neural networks which are massive machine learning architectures typically housed on the cloud your phone has some local neural networks inside of it but some of these things are very large especially the ones that microsoft and the big tech giants um you know you're basically participating in this machine learning uh infrastructure so what is what what what these apps partially do but not fully is is something we call generative so i've discriminated between cats and dogs or trees and houses or english and french but i can also generate with neural networks and this is a you know something that we have to be aware of going into the future so imagine i have this neural network that i've been illustrated i've been illustrating and instead of using it for discrimination i quote unquote run it backwards maybe i put a signal in the right hand side neuron that's associated with the dog label and i ask it to generate what it thinks a dog should look like okay and you can do this there's lots of examples of codes and and and uh algorithms that do this you can do this on the internet and depending on the sophistication of the neural network architecture but also how much data you've trained it on uh you can get images that look like kind of you know hideous images of dogs and so on my my favorite example is a neural network that's trained to discriminate between both dogs and plates of spaghetti this is the one i used in my cbc lecture and if i deep dream with this neural network which sort of means running the thing backwards it'll output images like the famous dog spaghetti which if if you can't see it you're really not missing much because it's a hideous mashup of sort of dog faces in a plate of spaghetti but what's remarkable about deep dreaming is that these are new images you know generated by artificial intelligence uh that are very you know very good at fooling sort of a human a human eye it seems fun when we're looking at pictures of dog spaghetti but you know this technology is also very um very advanced in in the realm of what we now call deep fakes and so deep fakes and i i can i can show you an example uh but i i don't know if any of you have seen the movie step brothers there's a new deep fake out on the internet uh where will ferrell and john c reilly are replaced with silver sylvester stallone and arnold schwarzenegger okay and i just want to i want to try to play it i don't know if it'll work but i'll just play it with some audio just for a few seconds here and let me share screen and let me share my safari and let's see if the audio comes through i can't believe you hit i know did you see the expression on his face yeah that was cool do you want to see something super cool that only three people have ever seen in their lifetime okay open your eyes whoa see that black smudge right there on the blade yeah look at it closely pretty recognizable signature no randy jackson from american idol why do you have randy jackson's autograph on a martial arts weapon because i bumped into him and all i had on me was this samurai sword and you're not anyway i just wanted to illustrate that because you know the the technology of deep fakes which is very similar to deep dreaming has has it superimposed sylvester stallone and arnold schwarzenegger's um faces onto that video and it's done it in a seamless way and it's got a comment here it doesn't seem like they deep fake the voices i think you're right although i can't yeah because arnold's voice is very uh uh very uh unique but there are there's another deep fake with obama that i i believe you could google and see uh a an actual voice uh deep fake but so that's a concerning technology you know it's it's concerning that um you know a a a deep fake can be used to essentially you know fool people uh regarding the content of of something like that movie i mean it really goes to show us how fragile our sort of information uh is so deep fakes um are really a type of generative or you know deep dreaming technology so all that data that we use or that we sort of give to these apps into these uh these giant corporations can be used for uh all sorts of purposes like that beyond what you may originally envision your data being used for and and that comes to the second point um of my talk is is you know how do we interface with the you know the computers with uh with the devices but also with uh these massive artificial intelligence systems which are being built uh on the cloud and this leads to the important kind of topic of um of bias in data sets which many of you pointed out so as you're aware you know artificial intelligence systems themselves are coded by i would say a certain community or sort of demographic of computer scientists and and uh people like me you know stem practitioners engineers scientists physicists things like that and we have to ask when we develop this technology what kind of bias leaks into uh the systems and and in in the case of artificial intelligence you are all right in pointing out that it's really data which uh propagates a lot of the bias and it's not just current data it's historical data so this is an important study from a friend of mine uh i've i've linked i put a link on the bottom which shows uh bias in historical data sets and so the there's a chart uh that i'm showing that shows the percentage of uh mislabeled images so you think of mislabeling as if if that neural network was shown a picture of a cat that it labeled it as a dog by accident that would be a mislabel and historically starting in 2012 largely driven by uh you know jeff hinton and groups at university of toronto uh there was a revolution in uh in the accuracy of deep neural networks and so this chart lists some of the uh state-of-the-art neural networks uh starting in 2012. so what's interesting about the development of these deep learning models largely done at the university of toronto but elsewhere is that they relied on a set of standard quote-unquote data sets and you can access these on the internet and imagenet i-m-a-g-e-n-e-t imagenet is one of these standard data sets which was used to train and develop our current generation of deep learning technology but what people have discovered is that you know these data sets which include of course pixelized images and also labels so think of it as you know the pixel pixelated image of a dog and then the label say labradoodle these data sets themselves which form the basis of the training technology or the training data sets were mislabeled and a lot of the labeling was done sort of um by farming this out to you know there's millions and millions of images so they were formed out to a large proportion of the population and i've shown an example uh three images one that says basketball one that says ping pong ball and one that says hairspray and if you look at basketball you'll see i think it's a picture of obama throwing a football uh if if if you uh look at a ping pong ball you'll see a chinese gentleman who is easily recognizable and it looks like part of the communist flag and hairspray appears to be um some sort of i guess it's a guy that may have hairspray so i'm not sure if that was mislabeled or not but you it's fairly easy to argue that these labels which occur in the historic data sets imagenet is one of the important historic data sets from which all of our artificial intelligence algorithms have been developed have a bias in them and there's a lot of research uh currently going on to address uh these biases and i encourage uh those amongst you who are interested to check out that paper so these are famously biased data sets and i also want to point out that data you know bias can leak in not just in labeling images um which you know which is or videos which is one concern which was raised but also in also in uh generative uh sort of generative neural network regenerative machine learning uh that is based on language like natural language or text so i've put a website here for text completion so what this uses is a neural network called the transformer to complete the text i i encourage you i can do a demo but i think i won't i'll just encourage you all to play with this on your own time uh so what i've done here is i've just cut and paste uh an image from my web browser where i've i was prompted to enter uh the start of a sentence and this technology which is like a deep dreamer or a generative neural network for for text uh it completes it for me so i wrote toronto is the best city in the world for and then i stopped and i clicked the blue button it said generate and what i did was complete my text toronto is the best city in the world for and this is what the computer generated your investment in the digital economy it is a vibrant hub for innovation bringing together a globally renowned community of experts entrepreneurs innovators and innovators okay it's not perfect with our support we will make your digital investments greater than ever before for more information on the great things happening in toronto's digital economy click here it seems fairly benign but you have to remember that the transformer or the neural network that this is based on was trained off of data that was scraped off the internet and so all of this data on the internet also has all sorts of in sort of intrinsic biases in it and if you can see that there's you know the bias towards you know toronto being the best at has to do with something in terms of you know economy digital economy the fact that toronto was perhaps a hub of uh you know innovation startups uh you know tech companies world-class universities you kind of see that this is the type of information that's out there and freely available on the internet but you might also say isn't toronto you know the best city in the world for lots of other things and and maybe those other things just aren't represented in the data maybe the data that has been used to train and strengthen those connections in the neural network you know just wasn't available to the automated programs which train the transformer and so you know as we move forward into this brave new world i you know it's it it makes sense to kind of pause and think about how we uh both consume and produce data which is sort of the topic of the second half of my presentation and as as we look at what the big tech companies are doing uh they're certainly encouraging us to interface our human you know bodies and actions more and more with the devices which can upload data into the cloud to be used for these training purposes so for example uh you know i'm interface with my computer through my earbuds which provides you know audio signals almost directly to my brain but you know into my ears i can imagine an apple watch which is used to take data of your location your heart rate i think now your oxygen content of your blood uh you know your location via gps the rate at which you're walking and and provides all that data you know to these to apple or whoever the app uh manufacturer is uh images like you you rightfully raise concerns about images and and backgrounds of images and and home pods again you know these uh apple homepods or amazon whatever theirs is called was it echo which it sits essentially sit in your home and listen to your voice uh as you give it instructions these are all streaming data sort of constantly up up in these large neural networks i just saw a question pop up and i'm willing to take it so just go ahead and unmute yourself no if not i'll keep going i'm gonna save questions till the end um so just to continue so you know these tech companies are are you very much interested in in in kind of encouraging us to interface more and more with the the artificial intelligence which lives in the cloud and things like smart glasses are just the next iteration of that evolution and you can really ask you know since this is progressing so rapidly you know how far will this technology go how long until i can surgically implant my earbuds or hub instead of true north you know focals by north or whatever they're called um which is i think a waterloo toronto based startup uh have you know heads up displays on my contact lenses or you know you know similar things like that and you know it seems like the distant future sorry i'm just gonna skip over one but really uh you know companies like elon musk's neural link are really trying to get data you know directly out of you and not just your uh you know voice or your your thumbs or or your position but really directly out of your brain and it again it seems like science fiction but there is a large you know uh you know well-funded uh you know very highly organized operation which is trying very hard to normalize the idea that direct brain interfaces for the purposes of uploading and downloading data and it's you know it's nothing that hasn't been experimented with before we're talking about eeg signals and and and stuff like that uh you know uh uh is under active development so it's fair to ask you know well maybe this this type of technology can uh address issues of inclusion um uh and barriers to people that maybe don't have the ability to type or the ability to speak uh but you know what are the consequences that come with uh lowering some of these barriers to inclusion all this data shapes how we see the world even now and i'm not talking about visually seeing but i'm talking about interfacing with the world so recommendation engines if you use youtube and you click on the next suggested video that has been tailored to you by your data usage any of the searches you do in amazon has have been tailored for you based on previous searches and previous um uh purchases any ads that you see google anything any search bar you know the world that you interact with virtually is really been shaped for you personally by your data and the you know the artificial intelligent recommender systems which have been trained uh you know haven't entirely been trained on your data so they've been developing biases based on either historical data or current user data from other you know demographics and other communities and so we have to be aware that you know the the ais that we interface with um are really products of the data you know they're as good or bad as the data that they've been fed for the last year you know month day maybe longer shorter so i'll leave it at that and we can have a discussion and i just put up the two points that um the organizers emphasized you know science and technology has progressed faster than policy certainly and and some of the big companies the big tech companies even rival the policy makers i mean they really make their own policies for how they use your data and good luck ins you know in getting the government uh or any other policy makers to sort of keep up with some of the innovations coming out of these companies and that that makes us wonder how much can we trust them ourselves right we trust say our government and our regulatory bodies do we trust big tech and of course there are risk risks involved and but the technology somehow doesn't stop you know and so how do we best mitigate these risks to maybe improve inclusion as much as possible without sacrificing things like privacy in the end so that's it thank you for paying attention and i'm happy to take any any questions i did have a question actually um i have been involved with um security in computers since back in 1997 when when we were integrating ntfs into windows um and and clouds were being created um i my question is in regards to intellectual property and um the coming of ideas and in in discussion groups and ai um piracy people that are out there that are trying to steal information and steal ideas what about things like intellectual property that can be released uh such as like music that can be released beforehand before to end get away with it we file is too late intellectual property is a very interesting um sort of topic so a lot of the underlying technologies are covered by patents and and commercialization agreements um which aren't necessarily honored by all you know all parties involved or aren't always litigated by all parties involved let me put it that way um so it's an interesting question about what counts as intellectual property for example mathematical algorithms i found out recently do not count as is a patentable kind of uh ip uh however you know in ins implement instances or implementations of algorithms into code or or or even pseudocode may uh does data is a data set count as intellectual properties it's something that can be protected by patents um these are all interesting conversations that i'm not sure are sort of um mature you know understood in a mature way that's been been keeping up with technology and let in the classroom it's that aha moment at the discussion table you know who's listening in absolutely no it's when i talk to intellectual property experts at the government in the government level they're very concerned with sort of nationalistic policies about how you know we develop a lot of this technology in canada and how is it you know released to the world um you know who's using it and for what purposes for what purposes might china be using deep neural network facial recognition technology that's developed in toronto certainly things to think about i can look at the chat and answer questions um actually this is yuta um thanks so much roger one i i have just uh a few questions um one of the things you talked about or alluded to right at the beginning was this notion of of the data impasse without our data being part of it we aren't recognized and uh understood by whatever smart systems we wish to make use of but um within and and that is of course uh one of the the biggest concerns with ai ethics issues but uh something that i think is fairly unique or not i mean it's more unique or intensified with respect to disability is the additional bias towards the majority and against minorities and outliers so even if we have full proportional representation then there will still be that certainly in population based decisions and also in recognition systems ai systems are doing the same thing that any quantitative data analytics is doing it is decreasing diversity and complexity and reducing that and so um in in any situation if you are far from the norm far from the average then the the systems won't serve you as well and um in many cases you might be the uh false positive and therefore collateral damage or um within a security situation but also uh the systems won't work very well for you and the decisions will be against you um we see that quite a bit in health a.i um especially now uh covid triage systems and health monitoring and many other scenarios do you see any um advancements in uh ai systems that can address that um and then i have one other question to follow up with sure so i i probably believe that the best way to address um the decreasing diversity of ai systems is for uh sort of an inclusive community or a diverse community to actually offer up data sets and and i i would point towards these standard or standardized data sets like i can give you a couple names you know uh c410 mnist or the one that i showed imagenet um uh you know which are used as benchmarks to typically test new ai technologies so you know it would be nice to have uh a sort of more inclusive community uh volunteer a data set a standard data set uh that could be used you know to to to train and benchmark uh ai systems as they're being being developed because the alternative is that doesn't however address the whatever happens i mean we would over represent then um i mean the only way to push back against the overwhelming of the majority of the minority would be to over represent the minority and which then again takes us away from this notion of being able to address diversity uh the the one issue with respect to disability um within the data any data representation is that there is no common cluster of data points that identifies disability people are highly highly diverse you there's no common data element other than potentially uh self-identification as having a disability but in many cases people don't self-identify as having disability and so the the types of biases towards the majority i think will happen even if the as microsoft has put it we quench the data desert um with respect to um outliers and minorities that have disabilities no i not to be pessimistic but i think the the the data which is currently being trained i mean amazon recognition aws recognition trains on billions of images and videos a day it's it's very hard to counteract that you know with with with kind of hand-picked data sets and you know i i so i on one hand i a proponent for diversity and standard data sets used for benchmarking but you're completely correct on the other hand i think you called it the data impasse you know the others the other way that our data interacts is is you know it's voluntary because you sign the terms and agreements to use the app but really we have no idea how that data that we as a community upload is being used to train data and i mean maybe one point is that we you know going into the future uh it's gonna be very hard for us to really control uh the amount of data that's that's being uh being or the type of data that's being used uh by these organizations i have already i don't have a great question all right this is um this is gloria i just want to mention we do have a couple of raised hands in our attendees so i have another question here from david the u.s justice department just filed an antitrust lawsuit against google in your opinion does this augur well for future containment of ai male ethics and ignoring uh persons with disabilities i i hope so i think it's kind of the first you know uh shot fired um maybe by these two uh adversarial uh you know interests now one you know the tech giants which have their own real profit driven interests right and that's one thing to keep in mind is that um you know the main business model of a lot of these drivers of technology is really profits and delivering ads to you and and and me and so this is balanced by you know you know governments you know and and other organizations that uh that that sort of have different incentives but i think this is a a good you know possibly a good sign um uh for maybe regulating and and these these tech giants uh but i think it's also a probably a very long uphill battle let me put it that way the there's a lot of power on the tech giant side and i think like we're talking about here um the technology moves so fast compared to regulatory sort of you know bodies that uh you know it's it's kind of hard to stamp out a fire that's racing far ahead of you so i'm optimistic but we'll see i have a question for you um my question is the the government app okay for the covid okay and government the government can suggest you download it and even um premiere lego our prime our premiere uh in quebec he said to download it um knowing what you know about data and how artificial intelligence works and how the data is collected and what would you use the app and would you download it so i do use the app yes i did download it um as much as any mere mortal like myself can understand how the data is is sort of being used um you know i i personally made the decision to trust that app but again a lot of that has to do with trust you have uh sort of in in the government in the fact that the government has done a due diligence on on the data sharing and the technology within that app so really what i'm doing is saying i trust the canadian government to know what it's doing when it issues this app or when it recommends usage of this app now as a technologist uh and i don't have the skills but somebody could you know look at perhaps how this this app you know transfers data and tries to really understand uh whether or not you know patterns could be detected in this data that can be violate privacy um but in this case i think the benefits outweigh you know the risks just from a public health standpoint that's what i thought too but i wanted to hear yep absolutely not another opinion thank you thank you there's a hand up by the way i just want to bring up before we go to mark's question just want to bring up a previous question in the chat there's a question about i'd like to know if there is a realistic balance between user privacy and progress a realistic balance between user privacy and progress yeah you know i think um i i think we don't do a good job on on privacy and i mean when i mean we i mean technologists sorry a lot of it comes down to you know when we um uh when we click on approve proving terms and conditions as some of you pointed out these are very opaque they're like legalese they're really not written in a way uh that is meant for us to understand and so what we effectively do is is sort of trust you know the the party that we're giving up our privacy to to kind of treat our data with respect and to not do anything uh sort of malicious with it so i think a lot of um you know a lot of this balance uh you know a lot of this is out of balance and it'd be nice to sort of see you know a more transparent uh you know user terms and conditions for all of these apps and and and to have sort of uh um you know a user bill of rights uh that that's maybe more universal that that really lets us know what's what what's being done with our data but in absence of that you know unless you read every single one of these user terms and agreements it's really hard to know what's going on with your data um and and that data is definitely used to accelerate progress right now let me put it that way thanks roger maybe we'll jump to mark now who has his hand raised thanks can you hear me now i can hear you okay um america montreal um san diego my question is about universal uh uniformity in terms of uh in for example with the use of english braille there is an international braille union uh with respect to technology are there anything formats or regulations in place to govern the use of how the artificial intelligence information is once gathered and used is is formulated in such a way so that there are agreements between you know what microsoft can can gather from canada as opposed to the states a lot of these apps that we use on on the iphone with voiceover are not even canadian apps and so [Music] i'm not usually concerned about privacy what i'm more concerned about is uniformity of the app and how how that information is extrapolated and either shared to us or shared to the users and how user friendly it is say with voice over or with the folks using android and talks on on their phones as visually impaired people and how we can make that better rather than facebook saying just two people standing with trees and snow in the background and that's it and we know there's more there because i can show sandy the picture and she can tell me hey this is what it actually actually is that somebody posted so i guess i have a few concerns uniformity being one of them i think the uniformity question is difficult um different jurisdictions um like canada versus the u.s you know treat the data of their citizens different but oftentimes data you know traverses these jurisdictions you know clearview ai is a good case study so you know for example there may be many laws in place that prohibit um you know police forces from you know sweeping up data about it about the country's citizens citizenry so you know police generally don't walk around with cameras filming you on the street uh and then and then sort of like um you know searching the you know these these these images and just to build sort of databases of its citizens but clearview ai i believe uh got around regulations by us you know selling by collecting data and then selling it to police forces so there's no there was no laws that's in canada and i believe in the states that said uh you know law enforcement could not buy data from a private company and so you know don't be naive when you upload your data or you interact with data through an app you know you really don't have much idea where that data goes afterwards and uh if there's no assurances of am anonymity and admin i can't say that word and so on you know you could easily find yourself in a position where these apps sell your data to law enforcement's even spy agencies and things like that i don't want to sound paranoid but i think a little bit of paranoia will help us all in the uh in the long run thanks roger mark we have this i want you to share time on here i really do appreciate it i appreciate it thank you we just have a couple more questions we appreciate you staying late um do you want to go ahead and ask your question hi sorry i was muted hi savelle i have a question i'm more of a technical question just that something i've heard about um ai that i'm not sure i fully understood so maybe you could explain to me how it works and if this is true and how it could be used and what the risk could be so my understanding is that you can if you're looking at like a a data plot that there's like you know there's sort of let's say a cluster here and there's like little i don't can you see me there's like smaller clusters around the bigger cluster and then some of those there's even smaller clusters sort of towards the outside is trying to be able to like actually instead of focusing on what's the biggest cluster and trying to get the data sort of within these categories is to actually start to look for the smaller and smaller and smaller and smaller clusters further towards the outside and not only to identify what those smaller clusters are but how they may overlap or intersect so is it possible that the one that's a tiny cluster on the upper left corner of a page might be related somehow to the cluster that's on the uh upper right maybe they're the opposite they're like people who are never the same population maybe in some circumstances they are the same population and so actually in a way sort of looking at data from intersectional ways too not just populations intersectionally so are there techniques like that that can be done that actually specifically go towards the edges um try to identify what those kind of common traits are i think for example within neurodivergence we know now in 2020 things that weren't known in 1990 about certain patterns even across whether you're talking about like dyslexia or autism or edd or non-verbal ld or all sorts of ones that there are certain common things that tend to be more true among populations of folks who are neurodivergent than others uh for example um issues with executive functioning is that something that one could like almost uh use data to actually try to identify what those kind of outlying patterns are or for example with autoimmune disorders things that might trigger autoimmune disorders that are really outlying uh by but actually trying to find those patterns and the relationships between them you know it's a great question because i believe um a lot of our knowledge derives you know in in the past before artificial intelligence derived from the ability to sort of take an image you know you segment kind of what you're talking about in which image segmenting you know maybe i'm in the foreground and people in the background you remove these three people say and look at each one individually but ignore the correlations between them and with artificial intelligence the ability to sort of ask questions about the correlations is is certainly increased so you could ask all sorts of questions about correlations between you know images in the background text you know that that isn't part of the main theme of a document uh and and and maybe you know you know voices in a room and things like that but what you sacrifice uh when you when you look for these higher order correlations between you know objects or words or or so on uh is the ability to interpret a lot of times those correlations and so you can easily build predictive models you can think about generating uh or discriminating as tasks that take into account correlations between larger groups of objects but when you go to interpret you know maybe as for example maybe you're part of a community that you know is flagged by law enforcement for example so not you personally but the fact that you have been you know targeted or by data maybe images or geo-location data as being part of a community that's a higher order correlation and so say you were targeted by law enforcement and you could ask a judge you know why was i targeted and they can say well you know it's really hard for us to say specifically why because all of these higher correlations which artificial intelligence systems are clearly you know adept at identifying can't be interpreted by humans and so the big danger of i think moving forward and maybe it's a benefit but also a danger we have to balance is the fact that higher order correlations uh that emerge in artificial intelligence systems are very complex and are difficult to interpret or or explain so it's you know it interfaces with explainable ai thanks for watching it's a great point thanks um we have time for one last question we're going to make it really quick um richard please go ahead so thank you for your presentation was it was quite interesting i i just wanted more of a common and short question but one of the things that what that it was kind of initially fearful of her or and then also impressed with was how the ai works within applications we use on a daily basis for accessibility issues as well reasons as well like for instance powerpoint if you're adding photos to slides if you're running powerpoint with with a screen reader or a large print screen reader it'll identify the contents of the folder using ai and and a lot of times the the content the descriptions are really quite accurate and something they're not but definitely more accurate than say what facebook generates as mark mentioned as far as the youtube kind of no but it it is quite impressive but i was just wondering how do we if we as people with disabilities want to contribute our individual examples to the data sets like if i'm just seeing ai it'll tell me uh something like there's a dog on the table which was a dog on a mat and the one time that i had but how do i like i don't know if there's a way unless you're a beta test in the app if there's a way do you correct in in those kinds of situations with apps specifically for people with disabilities for for the apps yeah i think you would either have to beta test or you would have to like be part of the community that agrees to let your data you know be uploaded into the app itself um down lower at a base level you know the when i mentioned these standard data sets there's certainly communities of machine learning researchers who do who do foundational research that you know could be approached like by an organization such as this uh to to include a more diverse data set so i mean again data sets for that are used for benchmarking of basic you know functionality of of of new ai systems are available online in sort of standard huge databases cfar 10 you know the ones i mentioned mnist imagenet so those things can just be volunteered voluntarily given out to researchers but also he kind of raised an interesting point that different apps behave differently and some are better than others and largely it has to do with access to the cloud i believe for example the neural networks available uh to your phone when you have a data link and and you're using an app are much different than if you say had the data shut off or you were out of cell phone range and the reason is even though neural networks can be programmed onto your phone they're much smaller and less impressive than the massive ai that are being built by the tech giants and so if you notice performance differences a lot of time it has to do with the sort of size and sophistication of the artificial intelligence system the largest being up on the cloud but also the amount of data that is being streamed through those ai systems in real time and i again point to amazon web server web services you can you can go on to aws and and fool around with with some of their uh say image recognition programs and so on and these things again are trained by billions billions of images and videos a day and so it's hard to compete with these massive cloud ais on individual apps very good point thanks thanks for your question you're welcome well thank you attendees for your questions and thanks roger for sharing your valuable insights um just want to ask utah our director to say a few words before our closing comments for today thank you and thank you so much roger and and the amazing working groups and thank you for our audience uh with respect to the very provocative questions um i i think one one of the things that certainly we are focusing on and we count is the fact that inclusive and accessible data science requires culture change and one of the issues is that data is from the past it ai amplifies and automates the patterns of the past and uh part of that pattern is in decreasing diversity and complexity which has a a disadvantage of course for people with disabilities but also for society as a whole and um one of the the goals here is to increase the understanding of diversity and complexity which is where anyone with lived experience of disability resides at the moment and so um we hope that disability and the opportunity to guide any of these technical systems that are emerging to address both the opportunities and the risks that are felt by the disability community is going to result in a more humane and innovative ai and we'd love to continue the conversation with you roger and uh recruit you into this effort uh as well as everyone that has been um doing the assessments of the apps and anyone within our audience so thank you again certainly i'd be happy to and thanks so much for the opportunity yeah um thank you dr roger malcolm and thank you everyone participants attendees and facilitators for presenting and joining this webinar it was really interesting to see what the groups have accomplished in all three parts of this workshop and hear your thoughts on the intersection of ai and assistive technologies and the impacts of ai in society for inclusion and for people with disabilities so this webinar was recorded and it will be available on youtube with captions for you to view in the near future and we'll also be taking the findings from all three parts of this workshop and presenting them on our website so stay tuned for that you can follow and connect with us on our social media accounts as well we're on facebook linkedin twitter instagram and youtube and again thank you to all attendees um participants dr roger malcolm facilitators um tara karen vera sapide and dana and special shout out to glory gloria lord and david for your hard work in organizing this you cannot have done this without all of you so thank you so much everyone thank you thank you you 