 the phrase machine learning brings to mind complex algorithms that use lots of computations to train a model but computations on embedded devices are limited in the amount of memory and compute available now when I say embedded devices I'm referring to objects with a special purpose computing system so think of things like a household appliance or sensors in an autonomous vehicle today we'll discuss the different factors to keep in mind when preparing your machine learning model for an embedded device different types of models require different amounts of memory and time in order to make a prediction for example single decision trees are fast and require a small amount of memory nearest neighbor methods are slower and require more memory so you might not want to use them for embedded applications another thing to keep in mind when determining which models to use on an embedded device is how you will get your model to the device most embedded systems are programmed in low-level languages such as C but machine learning is typically done in high-level interpreted languages such as MATLAB Python or R if you have to maintain code bases in two different languages it is going to be very painful to keep them in sync MATLAB provides tools that automatically convert a machine learning model to C code so you don't need to manually implement the model and C separately so what if after converting a model to see you find out that it isn't going to meet the requirements of your system maybe the memory footprint is too big or the model takes too long to make predictions you could try other types of models and see if the code meets the requirements maybe start with a simple model such as a decision tree alternatively you could go back earlier in the process and see if you can reduce the number of features in the model you can use tools such as neighborhood component analysis which are useful for determining the impact that the features have on the results if you see that some features are weighted low you could drop them from your model making the model more concise certain types of models have different reduction techniques associated with them for decision trees you can use pruning techniques where you drop nodes that provide the smallest accuracy improvement depending on your use case any of these tactics may be appropriate Hardware considerations network connections and budget are all key factors that will influence design decisions this was just a quick overview of embedding machine learning models for more information on preparing models for embedded devices see the links below 