 you [Music] so the next session we were given by how Chen he will cover about the algorithm that we need to build more complex algorithms using homo' encryption we have been giving very basic examples things that you can easily use the function to build well in this talk it will be like non ear functions or like linear operations with larger dimensions they require some algorithm or optimizations to work so that's given me welcome and let's started session okay thanks everyone hear me in the back that's good thanks for the introduction and I wanted to start by thanking the organizers here for organizing this event and importantly for all of you for participating I think it's really great I know lots of you have travelled long distance and maybe some of you are getting some jet lag for the last talking in the day I'll try to keep it kind of relaxing and feel free to stop me with with questions if you have any and we can go at at any pace you want so I I wanted to talk about some of the techniques that we use in the privacy-preserving machine learning and I wanted to focus on homomorphic encryption so but let me first start by doing some introduction of our group I don't know if we have done that formally but I think you guys all did a wonderful introduction of yourselves in the morning and I think this event is more for us to also connect with you so that we get to learn more about each other and potentially in the future we can have some opportunities to to collaborate so we are the cryptography and privacy research group at Microsoft Research in Redmond and our task the major goal is to research on the new cryptographic methods and applications and we have developed several focuses along the years and right now we have these several areas of focus where which includes the homomorphic encryption multi-party computation and some other protocols and primitives we are interested in zero knowledge proof or M's attribute based encryption and etc and we also like to work on things like compiler and hardware accelerations for the cryptography primitives and currently our group consists of I think it's seven members it's a Christian Way jung-sook in myself medicine asha so you can learn more about our group on MSR web site and also it feel free to chat with any of us okay so and also maybe just to motivate the the talk I wanted to talk a little bit about why I think that we should work on Hg well I don't know if you need such a motivation because you're already here but I guess for me I think it G is the interesting area to work on for various reasons but just to highlight two of the possible reasons first of all it is still a relatively new research area and there are many open problems that there are still to be solved just for example right now the most efficient hg techniques are based on the latest assumptions and latticed assumptions right now the people believe that it's a post content but we actually don't have any efficient constructions that's not based on analysis that I think that's that's some interesting question to think about and also for the practitioners in the audience I think it she has this reputation of being inefficient but actually I think over the years people have proved that at least it can be efficient for certain computations so even though maybe you're thinking of building an end-to-end solution which has some privacy guarantees HT might not be the the so solution to this problem but you can somehow use it as part of the solution so and for example there's this if we use this currently best lattice paste HD technique for the linear operations as a substitute to the classical additive morphic encryption systems then it is already very fast and overhead is kind of low so actually it can be used today as an efficient solution so ok and I do have an overview of the talk so I will talk very briefly about some of the different techniques of doing the PP ml but I would just pass through that very very quickly because I'm not a expert in those field and then I'll go to the HC specifics maybe just kind of go through some examples of how would how we would go about building some applications which does some machine learning over encrypted data and what are the challenges and what are some of the algorithms were improvements that we made and then in between the these topics I'll try to make some additional remarks were like short tips about what we should think about when we are building these solutions ok so I thought a little bit about when we talk about leakage in the machine learning what are we talking about and roughly I think we can classify these leakages in two categories but if you have some other opinions let me let me know so so there's this explicit leakage in the machine learning where for example if some company is collecting all its users data to train certain machine learning model then this data is supposed to be known to this company so you you're in some sense just directly contributing your plaintext data to whoever is running the machine learning algorithm and when you're doing a inferencing for example if I'm submitting my whatever kind of data for example it could be medical data it could be genomic data or it could be something like what kind of movies or books I like and that kind of data for inferencing is also directly learned by the service provider and there's also kind of the model leakage where for example in some of the scenarios for machine learning for example federated learning you might have heard that the the service provider actually deploys a model to the user's device so in this case you must ensure that the model itself is not leaking too much information about the training data for example and in a lot of the cases also the the model is considered kind of a valuable asset so you may not want to leak it to to anyone else and there's also implicitly Koosh in the machine learning where I can give two examples first of all is that I think many of you also have worked on or heard about adversary or master machine learning so in those cases it's possible that the the final model leaks some information about the training data so this is not explicit in the sense that the model doesn't just directly output part of the data but you can often kind of you can infer some information about which data is used in a training process and another kind of implicitly cages when you think of inferencing and someone is making a lot of queries to a certain machine learning models and you know that if the model is simple enough them by making enough queries you can actually just reconstruct the model so these kind of leakages is not explicit but it's implicit in a sense that every time you you make such a request you are learning some function of the sensitive data and with these types of leakage in mind we can talk about the different kind of kind of protection mechanisms so we have listed differential privacy federated learning and some cryptography techniques so for the differential privacy we can think of it as a meaningful notion of privacy for large databases and for kind of coerce type of computation for example it could be that the database is is a long list of numbers and we're trying to get some kind of histogram or the top ten of the earth all the numbers so in this case is the technique is to kind of add some noise in the structured way so that the final result of the computation doesn't let you identify whether a given individual is in this data set or not so this can happen in training for example I can deploy a differential privacy which makes the guarantee that just from the trained model nobody can identify whether a certain person is data is used in the training and also for answering kind of some kind of simple queries where the guarantee now is that from the answers to the query I can not learn too much about the underlying database and there's also federated learning which turns this explicit leakage of a user's data into some implicit leakage where if you think about how the data contributes to a machine learning model in the training you actually use this data to compute some functions on them and then you use these may be gradients to update your models so for the federated learning you take a lot of users and then you average their gradients in some way so that only the service provider only sees this aggregated gradient which supposedly doesn't leak a lot about each individual user Stadium but put it in another way it kind of turns this explicit leakage into a implicit one but it doesn't like close the door of all the possible kind of inferencing attacks and then the the techniques that I'll be focusing on today will be the cryptography techniques so this includes the multi-party computation and homomorphic encryption so these ones well limit eliminate the explicit leakage where when you're doing training or inferencing you can encrypt your data or you can do this secure multi-party computation so that the data is never leaked to each party barring the output so notice that this doesn't solve all the problems because you could still have some some poisonous training algorithm or you can still like ask a bunch of queries but it's a way of ensuring that other than the leakage of the what's supposed to happen you don't have any extra leakage okay so with that talk about homomorphic encryption specifically in a PP M L so homomorphic encryption can allow secure inferencing and secure training in a semi on this model here the semi honest just means the parties are supposed to follow the protocol but they are trying to learn more about your private data so a simple workflow in the two party case goes by having the client encrypt its query and send it to the server server which is holding a model we'll evaluate this machine learning inferencing function and generate an encrypted result finally this encrypted result is sent back to the client who can decrypt and get the final the final inferencing output for the training let's suppose that you have two parties each holding a a part of the training data set it could be split either horizontally or vertically but you can have any arbitrary party encrypt its data set and send to the other and the other party does all the training on the encrypted data maybe just throwing in its own plaintext training data and generate a final model and then we have some mechanism of sharing the model between the two parties so this is roughly like how HG has been used in this PP ml domain so and talk a little bit about the literature so it actually starts in 2012 just three years after the fully homomorphic encryption invention where there was a training algorithm for simple polynomial model and this is done worked on inside our group and also in the 2015 we have used homomorphic encryption to do secure inferencing for specific kind of newer networks so here the color coding is that the blue ones are for training and red ones are influencing and the green ones are influencing with hybrid solutions so in 2017 there's some work about using homomorphic encryption to train logistic regression models and there's also more and more efficient ways of doing inferencing on your networks and the 2019 sees like even some incorporation of these automatic compilers which takes input a neural network and output a program which you can just directly evaluate using for example Co or any other homomorphic encryption library so and obviously I think there's a lot of room for going forward improving this kind of work for example if we look at the training and there isn't a lot of efficient solutions going beyond the logistic regression so for the neural networks I think these current state-of-the-art results still doesn't evaluate kind of very deep neural network with perhaps more than 50 layers so those are things that I think it's interesting for the future work and ok so I'm just gonna take logistic regression for example so if we really simplify all the machine learning training process into a single gradient descent step then it looks somehow like this equation where we have this weight vector W which is encrypted and we will evaluate this update function which consists of a bunch of linear operations so here we're multiplying W is a matrix and some subtraction and some evaluation of this sigmoid function so and so in particular we will need this matrix vector product and we will need a homomorphic evaluation of sigmoid so this these two doesn't seem immediately obvious how to do them efficiently so well we'll come back to these operations later in the talk but let me go forward and so you may have heard of this notion of multiplicative death of a circuit so I'm just going to quickly recall the definition of that since that it is crucial to the later discussions of efficiencies in Asia and in Co so the depth of a circuit is the maximum number of multiplication depth patients on the path so in this case we have a path which has to multiplication gates and the depth is 2 and so with that in mind we can talk a little bit about the cost models of using this leveled version of homomorphic encryption so I'm just going to fix on discussing the ckk schemes from now and in the CK care scheme you need to set this modulus as you have seen in previous talks and this modulus grows linearly with the required depth of the the circuit so if you need more depth you need to set this modulus to be higher and that will increase the overhead of HGT because when you do the homomorphic evaluations the complexity actually grows with this modulus because you're dealing with larger and larger numbers and so for efficiency reasons it's very natural to reduce or try to reduce this modulus and reducing this modulus comes down to reducing the depth that's required for evaluating your function so the reason for this at least for C KS is that we need to do this rescaling operations kind of like a bookkeeping operation after every multiplication and rescale is a is a simple operation but it will consume your ciphertext modulus so it will go down the level after each multiplication and when you achieve level less than or equal to zero the decryption is not correct so what we need to do is that we need to set the initial ciphertext to a high enough level so that after all the evaluations you will still end up with some positive level so so then a natural question to ask is that this this approach works but it's not going to scale very well like for example if I have a very large depth circuit if I want to train a neural network which has a hundred layers and who knows how many epochs I will be running my training algorithm so then we can't just increase this modulus indefinitely I think well theoretically you can but it's going to be inefficient so the question is that if once you have this deep computation what can you do so we already covered that the overhead of morphic encryption grows with this depth so we have kind of two different options one option is to have an interactive solution where you can think of it as once your cipher text reaches the level where you can't do any operation anymore then you can send it back to the secret key owner who can decrypt it and encrypt a fresh one for you so this often works with the additional kind of complexity of having to having to interact with the party whose data owner and that party needs to execute some decryption circuit then that opens the door of to some kind of malicious attacks so we need to be a little careful but this is actually a valid solution and another option is to use the so-called bootstrapping procedure and in that procedure you will just send the encryption of your secret key and the server will homomorphic we do the decryption so it sounds great but it's after after so many optimizations right now is still a little bit inefficient and but the benefit is that now you don't have this interaction between the party who's doing the computation and the party who's owning the data so just one slide about bootstrapping and I'll go forward so as I said bootstrapping is computing the decryption circuit homomorphic Lee so the the workflow is that you start with a safer text and the encryption of the secret key and then you perform this evaluation of the specific circuit which is the decryption and then you will end up with the encryption of the message but possibly with more more rooms for further computation and if you have just like one sentence comparison I think the the SHC or level that she is kind of like rockets so if you want to reach further away you need to kind of build higher better rockets but they probably kind of also have more weights and it's more costly which corresponding to that corresponds to changing the parameters fhe is kind of like a car I mean our car is not as fancy as a rocket but you know the analogy is that if you remember to to fill the gas before you run out of gas then you can go indefinitely like many there's no limit of how far you can go and so so this one just explains that once if you have a kind of simple computation than using sh t is often much more efficient but if you are really considering a computation which can run off even like depth thousands or hundreds of thousands then there so at some point there is a crossover point where you want may want to consider the the fhe but for the this talk will just solely focus on the sh e okay and now for the second part of the talk I wanted to mention some algorithms that we want to build on top of the existing HT schemes so the motivation for this is that we thought about the you have maybe seen from the previous talks that HT can be used in this sim D fashion and it's very efficient so what he supports is kind of these operations where you can add two vectors you can coefficient wise multiply two vectors and you can rotate vector but a lot of the computation you want to do doesn't consist of these operations so there needs to be some efficient translation of your computation into what's efficiently done by the HT schemes so that's what I will talk about in detail ok so first of all what do we do for for nonlinear functions or more narrowly what do we do for the non polynomial functions so here the example I'm taking is the sigmoid function so it's scaled by 10 a little bit just for the picture to look nice but it's basically the the sigmoid that you use in logistic regression so because this involves this exponential and divide which is not amenable in aichi what we need to do is to approximate it with a polynomial and what we know is that for any given interval and any function we can approximate this function pretty well as long as we have a polynomial of a high enough degree so this means two things so first of all we need to have this knowledge of what is the interval that we'll be approximating our functions so let's say we always know that if we're evaluating this function this input is going to be between minus 1 and 1 once we know that then we can design these approximations and computing these polynomial coefficients then once we set some threshold for tolerance of error we can have a good polynomial approximation so usually people take this measure of infinity norm to measure the goodness of approximation and but oftentimes it's not necessary to output the best approximation but I think at least a lot of times I use this chebyshev interpolation to find a good polynomial approximation and it's usually sufficient so here in this picture I have the function itself in blue and the three different color curves are the chebyshev interpolation of degree three five and seven okay and that's the first step once that's done we need to efficiently use a chi to evaluate a polynomial so suppose we already know these polynomial coefficients these AIS there are multiple ways of evaluating the polynomial if you think about it so maybe like in the plain text you can have many efficient ways different ways of doing it but in aichi because the cost model is different we should think of how we should evaluate this polynomial in order to make it the most efficient in aichi so the first method is the classical Horner's method so we can write this polynomial evaluation as a bunch of additions and multiplication by X but this requires ten levels as every multiplication by X will consume one level and as we have seen having a lot of levels it's not good for the efficiency and the second idea is to use this kind of tree wise computation where we forget about these coefficients AI for now but just focus on computing all the powers of X remember that right now X is encrypted so we can compute all the powers in in a tree where the highest power of X can be computed using only log n levels so this is good because then after we have all the powers we can just do a dot product with all the coefficients which is supposedly in plain text and then we just need login levels and this doesn't require much more computation so it's good and with the smaller level sometimes they even allow us to go to smaller a cheaper a meters and it's much better efficiency and the reason that this works is because this level notion is not multiplicative but rather it's kind of like a max construction where you have to ciphertext and you want to multiply them the resulting ciphertext will have a level the maximum of the two input plus one so and before I go to the the third method let me talk a little bit about the operation costs so in HG I have a few of these operations which have very different cost structures so I think this is useful for thinking about when we look at the particular computation how should we optimize our algorithm so this is a specific example of a specific parameter N equals 32,000 so I should note that these multiplications are done on this huge vector so if you want to compute the amortized cost all these numbers should be divided by for example 16,000 so efficiency is actually good but we still want you to keep this in mind because if you have a chance for example to swap or substitute the ciphertext eyford hex modification with a cipher text plaintext modification then that's often a good idea okay so with that in mind I think we can talk a little bit about the how to improve the polynomial evaluation method so remember that in the tree method for evaluating a polynomial we still need to do n ciphertext notifications for a polynomial of degree N and this is because you need at least one multiplication to generate each power and as we see the ciphertext notifications are much more costly so it's not natural to think about whether we can optimize this by using potentially more ciphertext plaintext operations that evaluates the polynomial so actually it's possible and out in the next slide I will talk about this baby step giant step method which reduces the number of separate X modifications to a big of square root of N and there's some more advanced method which gives you another save of constant factor but it's too complicated and we can we can look it up but it doesn't fit in the top so in the baby step giant step method let's assume this degree is a perfect square and it can be written as n1 times n2 where the 2 may be similar or equal and then this evaluation can be written as a double somewhere you only have a some sub sum in the inner summation with degree root N and then this is multiplied to a big power of X but if you count the number of multiplication it's it's small so the and the reason is that notice we only need to compute the multiplication between the X to the J times n1 and all the sums and we only need to compute all the powers of X to the K also to Big O of square root of n so in this case we just need to make sure that the level it consumes is not much more than the tree method which is log N so but there's a there's a simple calculation but we can actually show that in this case the level is just maybe one more than the tree method so the baby step down step is a good method in the HG case for evaluating these polynomials and if you think about it I don't know if it really makes a big difference in the plain text case where you don't have the Hg everything is on plain text maybe you don't even worry about these evaluations but in aichi let me show you in in some code examples that it actually could make a difference okay so I have some code examples and I think this repository is public so if you go to that website you can download their code and maybe play with it and see what you get but I'm also going to go over the this code so yeah I was I will show the link later okay so now I already cloned the code let me just just do a poll and make so if you have cloned the code and I think you just need to do C make and then make it will generate two executables one of them is called poly eval in this bin directory let me just assume it's done and then it will say that I want to do this example of polynomial evaluation and you should enter a degree so I think if you enter every anything that's other than 15 it will crash but it's just just because I only coded it for this degree okay and once you enter this degree it will let you select a method so there are there are three choices one is horner and the second is the tree evaluation the third one is the tree evaluation plus this baby step giant step and we'll take a look so I choose this Horner's method it didn't freeze I think it's just generating the parameters okay it's done so I will explain a little bit what this code is doing so it's selecting this input X which is fixed to be 1.1 and it randomly generates a polynomial of degree 15 with these coefficients and then it will use the Horner's method to encrypt X and evaluate this polynomial to generate the encrypted version of the P of X so it requires about two seconds if I'm correct and here I print it out because this is using the ckq scheme we understand that there could be some error in in the evaluation and here I printed out the difference which is about point zero zero one so the accuracy is okay and now let's go to the second method which is the tree evaluation so it just finished and this is much faster about six times faster than the previous so notice that this is true because due to this tree method requires much less level we can select parameters which are smaller and smaller parameters means that usually you have much better performance and now let's do the tree evaluation plus the baby step giant step so it's even a little bit faster than the previous technique so remember that the degree is 15 so if you work out the math you roughly get like half of the required ciphertext multiplications which is dominating the cost so yeah feel free to play with the code but I will right now I will go into the code to show you some of the the implementation details of how you do these things okay so the first one is the Horner's method so in this case I set the parameters and generate some keys and sample the the polynomials encrypt this input here this is common to all the three methods but then what I did was so remember that the Horner's method is a for loop so in each iteration in the loop I do this multiply of the current evaluation with the encryption of X and then there are some bookkeeping operations other bookkeeping operations and then I have this addition which adds the plaintext coefficients to the temporary sum so the reason that this is so costly is because every time I do this iterations in the loop I need to do the rescaling operation and that requires one level and this is the reason that I have need to have at least 15 levels for the initial encryption and although the levels kind of peels down when I'm doing this evaluation you still start off with a quite large ciphertext and that contributes to the inefficiency and now let's go to the second method so the second method is kind of much better and we can already see it here so here we don't really have to select that many Prime's in a coefficient modulars where the basically the level required is only logarithmic in a degree and for this reason we can also select a smaller ring dimension which is called poly modulus degree here and the rest is almost up to here it's almost the same we're just randomly selecting a polynomial but the interesting happens where we compute all the powers first and then we do a summation which is kind of like a dot product which is also present in Kim's talk so the the reason that this is much faster is because that of the smaller parameter so I think this is interesting and for the interest of time maybe I'll just leave that leave it to you to check out the third method which is the baby stamp giant step it actually kind of requires some some effort to implement it's now completely trivial but I think it will be interesting to to take a look and see what so what's going on there and how would you go about implementing it okay and so that's that and another exercise I have for you is that the ciphertext size is for these three different methods are also different so you have learned maybe from Kim how to serialize and save a ciphertext to a file and maybe you can just check out the size of these files for these three different methods I think this one will be the biggest and these two will be similar basically the size is proportional to how many levels is required for this application okay and for the last topic I will talk about is this linear operations in homomorphic encryption so if we go back to this example of logistic regression we're computing some sigmoid which we approximated and we have some good with good algorithms but what about this kind of matrix vector product or even matrix matrix product so we only have these three types of operations but none of them directly gives us matrix vector product for example so we need to have algorithms for these linear operations using as fill native operations as possible and let me let me go back just for a second to this cheat sheet where you can see that it's it's possible that if you can use these cipher text rotations then a lot of the functionalities can be achieved but we need to keep in mind that this is kind of like a expensive operation so what we want to do is to reduce the number of cipher text rotations also as much as possible so now let's go back to this question of doing this linear operations so oftentimes also a observation that we made is that if you have encrypted vector x encrypting matrix that's often more costly than encrypted vector x plaintext matrix and in the latter case you can somehow design your algorithms by just arranging the matrix in a good way so that the operation is even more efficient so might be good to think about whether you have that kind of ability so okay so let's talk about what we would do when there is a plaintext net matrix multiply to in a vector so just for simplicity we can think of the case where the matrix is square matrix in that case there's this diagonal method which basically operates in this way so you have plaintext matrix and each of its diagonal is encoded into a vector and the reason of this procedure is because later we will try to multiply this vector to an encrypted vector in a coefficient wise multiplication way and notice that if you consider the first the main diagonal then actually the the first element of that main diagonal is going to multiply by the first entry of the vector and the second one will be multiplied to the second entry of the vector so then you keep the structure of the multiplication by not wasting any effort in this coefficient wise product so if you have a four by four matrix times the four by one vector this naturally just involves and ciphertext plaintext multiplications and in rotations because we need to rotate the encrypted vectors by the 0 1 2 & 3 so in this picture you have this vector encrypted starting with the red and when you need to rotate it by 1 it starts with that orange so seems like a pretty good algorithm because we didn't even waste any multiplication but in this case we needed to end rotations but remember that if you were to implement this algorithm in a plaintext then you don't need to do any rotation because you just simply do your multiplication and that's it so kind of this additional in rotations is additional overhead that comes from using this Hg so and actually we can do better to reduce this number of rotations and let's talk about that but before that maybe I'll give an old example of that diagonal method so it's the same repository but if you do I think it's called MV product so what this one does is that it will it will generate randomly a matrix and a vector and they will encrypt that vector and compute this encrypted version of M times V and it will decrypt that and compare that with the plaintext result so also I'll I'll show you that the code so the code starts here so this one is not super sophisticated because what you do is basically you set up this plaintext which supposedly in encodes the diagonals of no matrix and what I'm doing here is basically setting the the entries of this plaintext to the corresponding diagonal elements and then finally to encode to encode them into this CKK as plain texts and then I encrypted this V vector so the the action just happens here were in each step of the iteration I rotate this vector by I steps and then I will multiply that with the corresponding diagonal and there's there's a song so this one I think is also in the repository so you can check it out and okay so now let's talk about the optimization so it's kind of surprising that we can also use this simple baby step giant step technique to reduce the complexity of this operation so remember what we're doing is that we're computing this of different diagonals of the matrix times the different rotations of the vector so you can also factorize this as a double sum when the number of entries in the vector can be written as n1 times n2 and then we can actually pull out these rotations to be applied to a kind of like an inner sum so now this rotation only needs to be done once for each of these items in the inner zone which means that we can just use n1 plus n2 rotations to do the whole computation without having to use any rotations and that actually saves a lot so I don't have a concrete code example for this but I think it's a it's a nice exercise to try to to code this up and I think it's another example to illustrate that with a lot of this H sheet computations it comes with some overhead but it's possible that by some some interesting arrangements we can remove this or at least reduce the overhead okay so the the previous method works when the matrix is square so you may want to ask that what happens if I have a general rectangle matrix so I think right now the situation is complex because there isn't one algorithm that works and it's the optimal for all the possible matrix sizes that you can come up with and this is also partially due to the limitations that also the ckk scheme for example and the particular parameter choices in c l-- gives you only powers of two vector lengths and but fortunately I think in a special case where you have a matrix which has more columns and rows and suppose that the number of columns is a multiple of the number of rows then there's a hybrid method which kind of like uses this diagonal method a little bit and gives you good efficiency so let's look at that so so now suppose you have a matrix times a vector and instead of a four by four matrix you have a two by four then what we could do is to kind of extend the notion of diagonals and encrypt for entries inside one of the sorry not encrypt encode for entries in this one vector and then we still doesn't we're still not wasting any of the multiplications by just doing one rotation I can compute all the necessary products but now the problem is that I got these intermediate results which is some kind of partial sums and then these partial sums needs to be aggregated further in between the slots in order to get the final result so the difference here is that now the result is only a vector of size two here it's represented by the two numbers a and B but right now I have four slots so each of this slot contains some partial sum about this a and B so I what I need to do further is to do a rotation and summation and fortunately because you have this power-of-two structure you can do this summation of kind of all slots in log number of rotations so it will be interesting to work out the details but this is actually much better than the naive implementation of a matrix vector product and notice that in all these cases the primary goal is to reduce the number of rotations which is supposedly complex ok so I think these are all of the the the algorithms that I wanted to cover and I wanted to use the final a few minutes to talk a little bit about some some side comments so first of all is the remark on the circuit privacy so this is not a meaningful notion if you're only using the homomorphic encryption for outsourced computation because then the computation is kind of known to the secret key owner already so for example if I'm the only data owner I just want to offload my machine learning computation to some server and not to doing that computation myself then it's ok because the the the function that I supposedly want to evaluate is known to me so even though in the end it's leaked it's it's perfectly fine but it could potentially be a problem if you're designing applications using homomorphic encryption that involves sensitive data from two different parties for example in that case you might be thinking that it's possible to just let the other party perform this plain text after text computation but then the resulting cipher text might contain some information about the plaintext even beyond what you are supposedly learning so this is interesting problem both in theory and in practice and I think there are no very satisfactory solutions to the there is kind of like efficient solution of just adding some noise if you add the large enough noise then it you can prove that this other part is sensitive data isn't leaking through this additional noise but it's it's kind of a weaker guarantee only statistical so that in the future if we want to you use this for two party kind of applications we may want to think about how to manage this issue so and then I think I can conclude by identifying some of the yes microphone for the previous case if we transform the whole computation to be oblivious we still have the same problem so the question is that if your computation is oblivious would you have the problem so yes in some cases because even though you can say structure your computation as a circuit sometimes the circuit comes with certain constants and that those constants can be sensitive data of the other party so it's important that the final ciphertext of the evaluation result doesn't leak anything about these constants other than the output of that circuit okay so the the I wanted to identify also some further research problems of H II so some of them some of these questions are kind of far-reaching goals but because I know also there's a lot of people working in this area so I wanted to just single them out so first of all is that is it possible to have a XI beyond the semi honest model for example we could think about adding some guarantee where even you have a malicious evaluator you can still make some guarantee about the final ciphertext doing a reasonable computation and second one is that in the case of privacy-preserving machine learning usually in the machine learnings there will be some kind of preliminary steps where you you decide which model to use and after the training you will try to validate the model using some of the test data but this is not it's not clear at least 100% how to interpret these into the aichi framework so I think this was also briefly mentioned in the Aaron's talk that if you want to do some kind of retraining it's not entirely clear that how you would go about doing that using the Hg because HG is kind of you have you need to specify the computation and B in the beginning so if you're doing some training then you need to specify the step size and how many steps you're taking and these things are often decided at least in the plain text case you decide that after you have taken some look at the data and another question is whether we can have a deeper integration with MPC so I think there are some works in combining HD with MPC to design fast end to end solutions but whether I think there could be some some more efficient ways of interpreting them like providing the good connectors of these two primitives and I'll skip that faster fhe part and the last one is what I wanted to talk about more which is right now all the HD and MPC and I think even some of the zero knowledge proof primitives deals with the circuit model which means that we have to structure our computation as a circuit whether it's binary or it's arithmetic so that's great but I think also a lot of the computations that people actually do in ml at least it's it's not so much of a fit into a circuit model or if you fit in in a circuit model maybe there's a big expansion of the cost so I'll say one example where so there could be kind of a lot of algorithms that training a decision tree or a random forest or there could there could be like a lot of training algorithms in ml which has a stopping criterion so the stopping criterion usually can be expressed as you have a model after several steps of training and you check some criterion holds or not if it holds then you will stop the training and if it's not hold then you will keep going possibly modifying some of the parameters or not but doing this branching is hard to do in a circuit as we might know so it doesn't actually if you want to preserve the full privacy of the data it doesn't actually save you anything because you have to evaluate the both branch so so this one I think it's a interesting question to think about also so I will stop here and have this slide up for some references to certain papers and some links and happy to take questions we'll publish the slides online anyway so you don't really have to take the picture those are in small phones anyway do you have any questions so this semi honest threat model it seems like a bit weird to me at least because like how would you distinguish between like say say the server for example how would you distinguish between a server that uses a good model versus a server who simply act like or sorry how would you distinguish between a server that simply uses like a bad model and a server that like deliberately uses a bad model yeah so that's a good question I think in at least that's not a question specifically for itchy it's kind of an issue also for NPCs well where exactly you you can check that input data is valid which means that it's between certain range but you can't check if that is a is a valid model or it's some random data right yes I'm sorry so so for example like an MPC at least like you don't really deal with in input substitution which is like it seems like that's the only attack you can do as like a malicious like evaluator or say in in the fhe setting so I think we can separate two cases one case is the attack that you mentioned by just I can just input random data to the computation and the other one is that suppose the computation is kind of expensive then the malicious server can just not do any computation so by doing this it has motivation to do this because they save some costs right okay so you're saying like just encrypt you know this is a cat or something and then sent this back yeah yeah where you can just like not do any evaluation but encrypt 0 or right right yeah but that seems to be like sort of the same thing right because I could have a model that is just like terrible and just says like this is a cat - to everything yeah yeah it that's true so I think what what could be done is that after you get their result if there is some way to use use a different channel to validate the result then it kind of can help with that but first of all I think we should have a way to ensure that the server is evaluating kind of executing certain given computation so this makes sense for example in the outsourced scenario where the server doesn't have like a private model as input so suppose I just have like a huge computation that I wanted to all source then I want the server to be able to verify to me that it actually does that computation instead of just returning some kind of garbage data isn't there also an setting talking about threat models where if you have a lot of interactivity an active actively malicious server could recover the key or something of that nature right yeah so yes so in the case where you have a lot of interaction and those interaction involves some client decrypting and sending back stuff then if the server is malicious it could possibly try to kind of forge some ciphertext where it can learn about the key through the decryption so yeah so I think that's another that's another valid point where we also need this kind of defend against a malicious servers so if you can prove that the cipher text you send to this secret key owner is generated through some authenticated or like some valid evaluation then the risk of leaking the key is is smaller or you can even reduce that risk to zero going back to these threat models if you consider the the evaluation of a machine learning model in the cloud by some powerful server who might also want to keep his model private to the client not just a client's data so at least you leaked the the levels of the computation because the client kind of needs to choose the input parameters in a way that the computation can finish on the server side right so is this a problem in the ml community if you leaked the meta parameters essentially of the machine learning model is this fine ah that's a good question and I think I was asked one of my machine learning colleagues and he said it's fine so I just I just take takes eastward as s granted but I think at least for the neural networks oftentimes the structure of the neural network is okay to leak because they often have very similar structures so the sensitive things is the the actual weights in a neural network so you can say okay the client can know for example this neural network has 50 layers and it can even know for example some more fine-grain things about what these layers consist of but I think what's really going to the training the model and is the the final weights all right let's thanks how again sorry is one more question [Applause] 