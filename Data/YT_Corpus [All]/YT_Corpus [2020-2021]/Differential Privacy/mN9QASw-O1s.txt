 hello everyone my name is jeffon from university today i am introduced our paper k maf our privacy preserving human mobility prediction framework for federation learning mobility problem to the network is knowing the historical mobility directory sometimes it also require to predict the corresponding building time here we focus on predicting the next location following the recent successful practice from community and that model with better performance will also require more concentration between data 10 years ago they built one model for one user and now it builds a centralized deep learning model for all users by changing based on the data the performance of previous models become here and here the centralized requirement of data becomes a risky choice because individual mobility directories are sensitive and they have many private information of individuals thus when you attribute a privacy-preserving mobility prediction model and it should achieve competitive performance of current state large mobility protection model but also it protects the user privacy running stability prediction model here present is framework it first attacks accepts a discrete sized spatial temporal point as input and using binding table to translate them into vectors then we conclude them together and use sequential models like stm to capture the sequential transition in the character finally they use a linear layer to project the height vector into the final predicted location based on this basic prediction model we apply several techniques to protect the user privacy and improve the prediction performance here here are another step apply learning framework to preserve the private user data in the local device at last figure shows in the conventional workflow each user uploads their data into the cloud center and then obtain a well-trained model from complete the prediction task after using learning framework no user data uploading most of the training procedure is executed in the local device they only need to exchange model weights when the cloud cloud server during several training epoch this is the first step for protecting the privacy by preserving it preserving the raw data in the local device uploaded to the cloud center the english uploaded model weights to the class center their risk of uploading weights is smaller than uploading the raw data it also introduced large risk for linking the visiting location list of users in the scenario attackers can pretend to participate participate in the whole procedure as normal user and then observe the changes of the location event table of target users during the training in this way attacker can obtain information ability locations of target user to protect user from random proposed use virtual gravity to add a noise in the normal data for each user then the training of the whole model is divided into two steps first step training inviting table is noisy data while freezing other components and second step is to training is to train other components with the normal date of phrase freezing the embedded table in this way the changes of the table is not deterministic and attackers cannot easily find the right location edited by them [Music] to learning the cloud operation the performance of our model is reduced further improve the prediction performance and make it competitive to state-of-the-art model you introduce a personal adapter in the local device for personalized fine tuning after normal training procedure it works it works as an additional vector before the final output projection or correlation query and is trained as executed in the local device to capture the personal pattern we use three mobility evaluated performance of our model including two checking data and one that's genetic data here are the basic information of this data here is the result you can find that is the model which protecting performance protecting the privacy our model achieves better performance compared with the joint model without protecting privacy our model can also achieve competitive competitive performance while our model can protect us privacy represent the result of protecting family like that compared with directly with gravity the performance of our model is more stable by increasing the privacy requirements it means that every model achieves attitude of the performance of privacy protection by the conclusion in this paper they navigated the privately preserving mobility prediction problem and proposed several effective strategies to protect this privacy they are preserving the prediction performance in the future we need more works of developing efficient and effective optimization measures for the whole system to further improve performance while protecting user privacy that's all 