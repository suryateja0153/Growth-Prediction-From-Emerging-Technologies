 we're going to talk about the programming framework for the differential privacy library and I'm thrilled to have today we should all be thrilled to have today Marco gab gabor D who's professor of computer science at Boston University and Michael hey who's professor of computer science at Colgate University Marco it's all yours so actually this is Michael I'll start the talk and then Marco I'll jump in the second yes we'll be presenting an overview of the framework so this framework is described in a white paper that was co-authored with Salil but we also wanted to acknowledge the valuable info we received from the other members of the design committee so I think she'll already kind of covered the basic timeline I'll just sort of and highlight the end of it which is that there is this white paper available on the open DP website and you know we'd love you to look at that and give give feedback we also want to acknowledge that there's a lot of work that's been done in the community on building differentially private systems or designing languages for differentially credit computation and our design certainly borrows from from this prior work in particular pink and fuzzy Knechtel oh but no doubt there's other ideas that are out there that are not yet incorporated to the framework and so if you have suggestions or insights you know we'd love to hear from you and as a reminder there's a breakout session tomorrow where we'll be discussing the framework so these are the desiderata that the design committee developed for the framework there's there's many I won't go through them all but I did want to highlight the importance of modularity you know so modularity is a useful feature in just about any software project but I think it's really vital for this one and so as actually bryant alluded to in the previous talk you know implementing DP algorithms can be quite tricky you can it's easy to make mistakes and so what you really want is that the core subroutines are implemented once reviewed carefully you know vetted closely and if they're sort of don't appear to be vulnerable to any other known attacks you know then you take those components and you use them as widely as possible within your your project so certainly want the code be module but it's not just the code that you want to have a module where you want modularity we also want the privacy statements to be expressed in a way that's modular and composable so that way ideally it's possible to build you know a complex differentially private program using library components and yet you know avoid at the end of it having to sit down and write a proof that the program you just built is differentially private ideally that proof will sort of come with the library and some of the other data will be alluded to throughout the talk and in fact throughout the workshop so in the rest of the talk we'll kind of do a technical dive into some of the components of the library starting with measurements and transformations and building up to interactive measurements and then we'll turn to some practical considerations things like the implementation language and how people might use and contribute to the library okay just a few sort of assumptions to get started these will be relaxed later but for now we'll think of the private data is just you know a table of records or formally a multiset each item in the multi set is of some type X and a person you know will contribute at most one record to this data set and our goal is to support the kind of purity piece epsilon differential privacy but we'll talk about other variants later okay so measurements and transformations so starting with measurements so a measurement is really essentially just a differentially private computation on the data in terms of the implementation of a measurement we think of it as like an object although we're not committed to object-oriented programming design per se so an object or a struct that has that's defined by certain attributes so concretely for a measurement it has the following attributes and and as you'll see throughout the talk like the set of attributes is going to get larger and a little bit more complicated but but for now a measurement you define an input input domain and so that is the type of data that the measure is expecting to receive as input the function that's the the randomized computation itself and then the privacy loss which is just the epsilon that would be spent when this measurement is invoked on the data so here's a you know a small example so we have noisy sum which takes as input a multi set of bounded floating-point numbers so they're bounded to lie between L&U where those are user specified parameters and it computes the sum of these numbers adds Laplace noise and where the the noise is appropriately scaled based on the parameters L&U and and the desired privacy loss of epsilon so one sort of detail to note here is that the privacy promise that comes with this measurement object is conditioned on the input type so in particular if you were to if you were to pass this measurement function a collection of unbounded floats then you would not this this privacy loss of epsilon would not be guaranteed to hold okay so those measurements transformations these encapsulate all the things that you might do to your data to kind of prepare it for measurements so filtering out rows or columns or applying these are defined functions to each to each element in the data set and so conceptually a transformation is a function that takes in a data set and produces a transform data set in terms of the implementation it's defined by four attributes so the kind of the type data type or the domain of the input in the output the function itself and then this stability parameter and so stability is a promise that the transformation is making which is that inputs that are similar so say two inputs that differ by D records that when you apply this transformation you're going to get outputs that are also similar to each other and so they can differ by at most C times the records where C is this stability constant so an example of a transformation is clamping so you might take a data set so so clamping expects a data set of unbounded floats and what it does is applies a clamping operation to each to each float in the data set so it will clamp the float so that it is guaranteed to lie between lnu and it has a stability constant one okay so measurements and transformations are the kind of core building blocks and if the goal is to build you know complex differentially private programs from these building blocks then to kind of continue the metaphor we need the the cement or the mortar that's kind of that's going to stick these building blocks together and in this framework this this comes in the form of operations like chaining composition and post processing so I'll talk briefly about all three that I'll start with with chaining so chaining is the the name that we use for function composition it's just composition is kind of an overloaded word so we wanted to have a specific term to distinguish it but it the basic idea is when you chain two operators the output of one Operator becomes the input for the next so you can chain two transformations and that yields a new transformation you can chain the measurement with the transformation that yields a new measurement so concretely this M Prime is a measurement that consumes the transform data set that was transformed by T and so chaining as an operation is responsible for doing a few things so you need to kind of check compatibility between the operators so particularly the output type of the first one should match the input type of the second one but also derives the privacy properties of the resulting operator that you're that you're building so if we kind of revisit the tools we have so far we can consider training them together so we can chain noisy sum and clamping and what we get is a noisy clamp some so here the input is a multi set of unbounded floats but what the function now does is it clamps them and then and computes the noisy sum of the clamp values the privacy loss of this resulting transformation is C times epsilon where C is the stability constant that you get from cramping and epsilon is the privacy from the noisy son so that's chaining post-processing you can think of as a special form of chaining where basically the idea is that you're passing the output of a measurement function to any arbitrary function you want and it doesn't diminish the privacy guarantee so another way of thinking about that is the sort of chained operation M Prime enjoys the same privacy that the original based measurement M M has there's also composition which is the idea of just taking multiple measurements this comes in different flavors so the simplest is sequential where you're just taking multiple measurements of course you can have adaptive measurements where subsequent measurements are adaptively chosen based on the outputs that you receive from from earlier measurements so here M - you'll notice takes as input Y where Y is the output of m1 and so I'll defer the details about composition until later when we get into interactive measurements but maybe one parenthetical remark I'll make here is that there is subtlety around using composition primitives because they actually behave somewhat differently depending on which variant of differential privacy you are using and so we want a framework that can support different variants of differential privacy and use the appropriate composition tools for them I'll skip this example but really the take-home message here is just using the tools we've already introduced of noisy summon clamping we can also compute noisy counts as well as averages I mean in the point paper we have more in depth examples such as fitting a linear model using gradient descent so in a minute I'll hand it over to Marco who will continue a discussion of kind of the components of the library but I want to pause here and talks or briefly about verification so so what do we want what we want that all of these transformations and measurements that are going to exist in the library or that can be built from from components of the library we want these transformations and measurements to be valid and by that I mean that the measurement or transformation respects the privacy loss or the stability bound which is promised by the attributes associated with that measurement of transformation and so we need to verify are these are these functions which are constructing the measurements or transformations so functions like make noisy some are chaining those require proof and so you know that proof should say things like you know for all inputs that we supply to this function either it'll raise an exception because you've supplied bad inputs and sort of the operation you're trying to do doesn't make sense or what it'll output is a valid measurement or transformation object I think we should you know we need to make other statements like it shouldn't modify the operators that were passed in as inputs or do any other weird things like modify other parts of the library code these proofs can be supplied by a contributor to the open PP library and then verified and vetted by the by open DP or they could be derived automatically and you know we believe that if a functions built out of library components like existing measurements and transformations and they're combined with the the chaining and composition tools I described earlier it's it seems possible that we should be able to verify automatically the privacy properties of these kind of constructed measurements and transformations and this is where an implementation language can really help because we can by providing things like strong types and immutable immutable structures okay so I'm gonna turn it over to Marko so he's going to take what I've just described which is kind of the library as restricted to pure DP on multi sets of Records and introduce enhanced functionality and the framework that makes it possible that makes it more flexible and extensible to so you know richer data types but also other variants of differential privacy let me stop sharing my screen Marko you can take it from here thank you Michael hi everybody I'm Marco gebardi so as Michael was saying the next step that we want to present is how we want to generalize the basic framework that he just presented so is the natural to think about generalizing it because we want to for contr it application we want to deal with different data types not only month results we want to deal with intermediate data representation some example our table graph stream for input data types we may want internal data or tensile representation so we need to generalize a different work that we have so far and and here is an example of how we can try for instance to generalize we can relax the need for the input to a measurement to be a multiset and we can allow a single float so that we can rewrite the noisy sine function that we saw before as a control as a chaining of a bounded Sam which still depend on the input Ln U and the base Laplace function which are just at the noise we want to support this kind of generalization we want to make sure that the different component of the right type so that we make sure that we combine an only object that match the right type and to do these away enhance the design we presented before by adding some matrix ax to measurement and transformation in particular we will we add input matrix to the measurement attributes in the input and output metric to transformational we don't need that word output me a trick to measurement because for the notion of privacy we use we don't generally in the de metric on the underline in space so as an example we can have now a datatype for the output a metric of bounded salmon or the input metric of business which is on floating the natural a natural metric is the difference in absolute now chaining will work as before but it will also check that the input metric of a measurement is matches the output matrix of a transformation and that they type in general image we also generalize the notion of privacy laws from a privacy laws to a privacy relation the reason why we not need the privacy relation is because we want to address a different notion of privacy for instance that we want to capture approximate differential privacy any differential privacy or concentrate the differential privacy which are all relaxation of this standard notion of differential privacy into these we a single privacy laws parameter is not enough because we need for instance for approximate differential privacy both a value of epsilon and Delta and the usually there is not only one value of epsilon and Delta which we may choose and so we want to relax two relations so in particular if we build again on the measurement structure weird before now the privacy laws turn into a privacy relation so in particular let's see this and with an example if we want to introduce a Gaussian component a Gaussian mechanism like standard in an approximate differential privacy we we can define a relation which is the usual relation that we need between epsilon and Delta for this mechanism and also we add an output measure which describe that we are using approximate differential privacy another component like Laplace we may want to use a standard differential privacy or we can use a different privacy relation with another measure like differential privacy a similar generalization can go into transformation so we can generalize from a single stability component to a stability relation the stability relation allow us to have more flexibility on the kind of transformation that we can implement for example we can implement join and join as the transformation by using a relation which allowed possible different possible values of stability now because of this generalization we also need to generalize a chaining and composition and now the interesting part is that chaining and composition can use this relation on the components to derive the relation of the chain transformation or measurement so here the general I show an example of the generalization of chaining of a measurement with them transformation and what happen is that to check the the privacy relation of the component of the composure measurement we need to check the stability relation of the transformation in the privacy relation of the underlying measurement so these kind of privacy calculus or privacy relation calculus and stability relation calculus can be done through chaining the composition another way we need to generalize is to address not only static measurement but also interactive measurement so what is an interactive measurement the way we structure it what we want is something that we can to which we can ask a multiple queries in an interactive way and the way we think about structuring it is an interactive measurement is something that created wearable object and we think about wearable object as a state machine consisting of an initial state in the evaluation function which evaluate the query and evolve at the state so in particular the interactive measurement has attributes which are similar to the one we described before for basic measurement but in addition it also as creates a variable which is composed by a state and an evaluation function this may be more clear through an example which showed how we can use this query border to you to hundreds were actually query ism so an example is a form of the example I want to show you is a form of adaptive composition and here I didn't show you all the possible code and they couldn't tell me to be taken as setting stone is just an example of how we could such a interactive measurement so the interesting part here is the evaluation function which take a query which is a measurement in the state and the return an updated state and the result of the query and the way this is implemented we check mainly that the privacy laws of the query is less than the epsilon that is in the state so that we know that we can perform the query if we pass this test then we return the result of the query and we decrease the privacy laws now that we introduced interactive measurement we need also to generalize in generalized chaining post processing and composition so for chaining more or less the situation is similar to the one we had before now the interesting part is that with post processing we can assume that the function f that before was just a post processing the result of the measurement now need to post process variable and what the function can do is to produce a new variable so in this way we can use a function to create to combine different kind of post process [Music] analysis on the variable some example of these are for instance if we want to implement a gradient this and procedure we can define this as a post process of a composition like the one we saw before another that we need to generalize is a composition and here we have a different alternative on the kind of composition we can have for interactive measurement to you how to use interactive measurement to design a kind of adaptive composition but we may want to have a more general form of compositions and two forms that we and one may want are a sequential composition where where maybe all of the queries in the first inner query ball must be completed before another inner query ball is generated and concurrent composition where we have a multiple inner query ball that can run in parallel so these are things that have been already done in the differential privacy literature at least some of them but what we want is a general framework general design that can support all of them so with this I conclude the first part on what are the different library component but let me in the Europe and we gave you the feeling that the library look for flexibility modularity let me go on to in some practical considerations so first the library would provide by design is the idea that we produce on the pallet measurement and transformation as Michael said before we want that everything that can is a built out of the library can with an automated privacy proof or anything that is added to the library can with a proven and of course this is an important part of our design but in addition we we need also to prevent other leakages like the cache is created by timing channel by implementation of arithmetic for instance of floating-point number and by use of pseudo randomness these are some of the the privacy ligature that have been exploited in the differential privacy literature so the way we think about a presentin channel is by you in standard mitigation that have been designed and by use a specific mitigation for component that are based on user-defined function for implementation for the arithmetic part we plan to use as much as possible fixed point number and healed and integrated mythix into a dresser randomness problem we plan to use a cryptographic strength random generator in addition to in order to guarantee to ensure really the privacy as Michael oriented before we will try to use as much as possible feature from the implementation language and some desire feature that we have memory safety and encapsulation mutability immutability of data structure these are component that make the analysis the primacy analysis is easier and also the contribution the current checking the correctness of contribution easier in addition we want some general form of data type and that type safety because we want to make sure that the different components stitch together without creating any problem in for these in the choice that we we committed to is to use a combination of the raster programming language which is a low-level programming language which provides some of this feature with some additional binding with Python and R so the main idea is that we want to use a rest for the core libraries so that we can guarantee the correctness of the different component and we still have a good efficiency but at the same time we want for easy of contribution we want to have the possibility that Kandra can contribute in python now I will briefly sketch how to use the library and how to contribute library and then I will conclude so to use the library mainly a user need to determine which data set they were to use the type what are the component that they need the kind of privacy notion they want to use and the granularity and then they can select some interactive measurement from the library and then present we arrested a query and to the variable that is created by the measurement this is the basic usage but of course user can also contribute new components to this design now they use the library also some exposure of the underlying systems needed like that access model water the color ability that we have and then also some kind of interface for the contribution to the library what we expect is that there are different kind of contribution from the new measurement or transformation combining existing component which should come with an automated verifiability we prove two new type of atomic measurement or transformation which instead they need to be provided by user with proof of correctness in for all of these we will have different way of betting and agreement on the contribution what we have so far is what idea what we show you is a framework that support many different data type ibis imager and transformations and what we don't have yet but hopefully in the future we will add some more advanced feature of a differential privacy like privacy odometers or a mekinese based on local sensitivity or support for randomized or interactive transformation I ran out of time and let me conclude by just saying again what we try to give you is an idea of the different component and different component of the library in some of the practical consideration on how we plan to implement the library and tomorrow we will have a breakout session and easier more you are all welcome to come with your question and sharing your thoughts about this design thank you thanks guys we have a question that just came up from Adam Smith what if any is the intended scope of measurements is there any inherent limitation on the type of differential privacy algorithm that fits the framework yeah I mentioned some of the limitation for instance in I went a bit fast on this slide so some of the limitation area in the is the last bullet point for instance and the moment we don't deal with local sensitivity but we expect that the framework itself could deal with it by adding more attributes to the different measurement and transformation and make sure that we capture the notion of local sensitivity and then we can use some of the standard tool like a smooth sensitivity to the design so there are some limitation but we don't think a limitation of the general design is just that we wanted to design a basic core and then go from there so software can't can't do everything not only in measurement but but in general so what are the applications or types of differential privacy that were sort of explicitly not attacking now so for the kind of differential privacy we want what I think at the framework is generally enough to address all the unknown privacy differential privacy related measures or like I was in before approximate appear immediately and so on maybe one thing that the framework is not yet designed for the reasoning about explicitly about different adversarial models so there are variation of differential privacy like computational differential privacy where there is some assumption about the computational power of the adversary and that is a notion that we don't support yet again we open in the future to be able to deal with them but so far one more from muratcan tar co glue whose name is definitely not pronounced that way will there be any support for privacy budget allocation in the programming framework for complex tasks it's not a consumer will there be any support for privacy budget allocation for allocating epsilon in the programming framework for complex tasks yes so the the idea is that yes there will be support for complex privacy budget management so the idea of interactive measurement and generalizing to relation these two ideas come exactly from the need of giving flexibility for the management of the budget so yes there will be 