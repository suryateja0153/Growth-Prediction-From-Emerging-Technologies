 [Music] hi everyone thanks for joining us today I'm Emily a software engineer on Google's federated learning teams and I'm Dan I'm a research scientist and the team lead we'll be talking today about federated learning machine learning on decentralized data the goal of federated learning is to enable edge devices to do state-of-the-art machine learning without centralizing data and with privacy by default and with privacy what we mean is that we have an aspiration that app developers centralized servers and models themselves learn common patterns only that's really what meeow meeow privacy in today's talk will talk about decentralized data what it means to work with decentralized data in a centralized fashion that's what we call federated computation we'll talk a bit about learning on decentralized data and then we'll give you an introduction to tensorflow federated which is a way that you can experiment with federated computations in simulation today along the way we'll introduce a few privacy principles like ephemeral reports and privacy technologies like federated model averaging that embody those principles all right let's start with decentralized data a lot of data is born at the edge with billions of phones and IOT devices that generate data that data can enable better products and smarter models you saw in yesterday's keynote a lot of ways that that data can be used locally at the edge with on device inference such as the automatic captioning and next generation assistant on device in France offers improvements to latency lets things work offline often has battery life advantages and can also have some substantial privacy advantages because a server doesn't need to be in the loop for every interaction you have with that locally generated data but if you don't have a server in the loop how do you answer analytics questions how do you continue to to improve models based on the data that those edge devices have that's really what we'll be looking at in context of federated learning and the app we'll be focusing on today is G board which is Google's mobile keyboard people don't think much about their keyboards but they spend hours on each day and typing on a mobile keyboard is 40% slower than on a physical one it is easier to share cute stickers though G board uses machine learned models for almost every aspect of the typing experience typing gesture typing both depend on models because fingers are a little bit wider than the key targets and you can't just rely on people hitting exactly the right keystrokes similarly autocratic Corrections and predictions are powered by learned models as well as voice-to-text and in other aspects of the experience these all these models run on device of course because your keyboard needs to be able to work offline and quickly for the last few years our team has been working with the G board team to experiment with decentralized data G board aims to be the best and most privacy forward keyboard available and one of the ways that we're aiming to do that is by making use of an on device cache of local interactions this would be things like touch points type text context and more this data is used exclusively for federated learning and computation cool let's jump into you federated computation federated computation is basically MapReduce for decentralized data with privacy-preserving aggregation built in let's introduce some of the key concepts of federated computations using a simpler example than G board so here we have our clients this is a set of devices some things like cell phones or sensors etc each device has its data in this case let's imagine it's the maximum temperature that that device saw that day which gets us to our first privacy technology on device status s each device keeps the raw data local and this comes with some obligations each device is responsible for a data set management locally with things like expiring old data and ensuring that the data is encrypted when it's not in use so how do we get the average maximum temperature experienced by our devices let's imagine we had a way to only communicate the average of all client data items to the server conceptually we'd like to compute an aggregate over the distributed data and a secure and private way which will build up to you throughout this talk so now let's walk through an example where the engineer wants to answer a specific question of the decentralized data like what fraction of users saw a daily high over 70 degrees Fahrenheit the first step would be for the engineer to input this threshold to the server next this threshold would then be broadcast to the subset of available devices the server has chosen to participate in this round of federated computation this threshold is then compared to the local temperature data to compute a value and this isn't going to be a 1 or a 0 depending on whether the temperature was greater than that threshold cool so these values would then be aggregated using an aggregation operator in this case it's a federated mean which encodes a protocol for computing the average value over the participating devices the server is responsible for collating device reports throughout the round and emitting this aggregate which contains the answer to the engineer's question so this demonstrates our second privacy technology of federated aggregation these servers combining reports from multiple devices and only persisting in the aggregate which now leads into our first privacy principle of only an aggregate performing that federated aggregation only makes the final aggregate data those sums and averages over the device reports available to the engineer without giving them access to an individual report itself so this now ties into our second privacy principle of ephemeral reports we don't need to keep those per device messages after they've been aggregated so what we collect only stays around for as long as we need it and can be immediately discarded in practice what we've just shown is a round of computation this server will repeat this process multiple times to get a better estimate to the engineers question it repeats us multiple times because some devices may not be available at the time of computation or some of the devices may have dropped out during this round so what's different between federated computation and decentralized computation and the data center with things like map reduced federate computation has challenges that go beyond what we usually experienced and distributed computation edge devices like phones tend to have limited communication bandwidth even when they're connected to a home Wi-Fi network they're also intermittently available because the devices will generally participate only if they are idle charging and on a none metered network and because each compute node keeps the only copy of its data the data itself has intermittent availability finally devices participate only with the users to permission depending on an app's policies another difference is that in a federated setting is much more distributed than a traditional data center distributed computation so to give you a sense of orders of magnitude usually in a data center you might be looking at thousands or maybe tens of thousands of compute nodes where the federate setting might have something like a billion compute nodes maybe something like ten million are available at any given time something like one thousand are selected for a given round of computation and maybe fifty dropout that's just kind of a rough sense of the scales that were interested in supporting and of course as Emily mentioned privacy-preserving aggregation is kind of fundamental to the way that we think about federated computation so when you compose this set of differences what does it actually look like when you run a computation in practice this is a graph of the round completion rate by hour over the course of three days for a G board model that was trained in the United States you see this periodic structure of peaks and troughs which represent when day versus night because devices are only participating when they're otherwise idle and charging this represents the the peaks of round completion rate are when more devices are plugged in which is usually when they're charging on someone's nightstand as they sleep rounds complete faster when more devices are available and the device availability can change over the course of the day that in turn implies a dynamic data availability because the data itself might be slightly different when from the users who plug in phones at night versus the day which is something that we'll get back to when we talk about federated learning in particular let's take a more in-depth example of what a federated computation looks like the relative typing frequencies of common words in G board typing frequencies are actually useful for improving the G board experience in a few ways if someone has typed the letters H I high is much much more likely than hieroglyphic and so knowing those relative word frequencies allows the G board team to make the product better how would we be compute these relative typing frequencies in federated as a federated computation instead of the engineer specifying a single threshold now what they would be specifying something like a snippet of code that's going to be running on each edge device and I've in/out in practice that will often be something that's actually in tensorflow but for here I've written it as pythonic pseudocode so think of that device data as the each devices record of what was typed in recent sessions on the phone so for each word in that device data if the word is in one of the common words we're trying to count will increase its count within a local device update that little program is what would be shipped to the edge and run locally to compute a little map that says that perhaps this phone type the word hello 18 times and world 0 times that update would then be encoded as a vector here the first element of the vector would represent the count for hello and the second one for the count for word which would then be combined and summed using the Federated aggregation operators that Emily mentioned before at the server the engineer would see the counts from all the devices that have participated in that round not from any single device which brings up a third privacy principle of focused collection devices report only what is needed for this specific computation there's a lot more richness in the on device data set that's not being shared and if the analyst wanted to ask a different question for example counting a different set of words they would run a different computation this would then repeat over multiple rounds getting the aggregate counts higher and higher which in turn would give us better and better estimates of the relative frequencies of the words types across the population awesome let's talk about our third privacy technology of secure aggregation in the previous example we saw how this server only needs to emit this sum of vectors reported by the devices the server could compute the sum from the device reports directly but we've been researching ways to provide even stronger guarantees can we make it so the server itself cannot inspect in affect individual reports that is how do we enforce that only an aggregate print privacy principle we saw from before in our technical implementation secure aggregation is an optional extension to the client-server protocol that embodies this privacy principle here's how it works so this is a simplified overview that demonstrates the key idea of how a server can compute a sum without being able to decrypt the individual messages in practice handling phones that have dropped partway is also required by this protocol see the paper for details awesome so let's jump into this through coordination by the server two devices are going to agree upon a pair of large masks that when summed add to zero each device will add these masks to their vectors before reporting all devices that are participating in this round of computation will exchange these zero-sum pairs reports will be completely masked by these values such that we can see that these added pairs now make each individual report themselves look randomized but when aggregated together the pair's cancel out and we're left with only the sum we were looking for in practice again this protocol is more complicated to handle dropout so we showed you what you can do with federated computation but what about the much more complex workflows associated with federated learning Before we jump into federated learning let's look at the typical workflow a model engineer who's performing machine learning would go through typically they'll have some data in the cloud where there's start training and evaluation jobs potentially in grids to experiment with different hyper parameters and they'll monitor how well these different jobs are performing they'll end up with a model that will be a good fit for the distribution of cloud data that's available so how does this workflow translate into a federated learn word flow well you the model engineer might still have some data in the cloud but now this is proxy data that's similar to the on device data this proxy data might be useful for training and evaluating in advance but our main training loop is now going to take place on our decentralized data the model engineer will still do things that are typical of a machine learning workflow like starting and stopping tasks trying out different learning rates or different hyper parameters and monitoring their performance as training is occurring if the model performs well on that decentralized data set the model engineer now has a real good release candidate they'll evaluate this release candidate using whatever validation techniques they typically use before deploying the users these are things you can do with like model validator and tf-x they'll distribute this final model for on device inference with tensorflow light after validation perhaps with the rollout or a be testing this deployment workflow is a step that comes after federated learning once they have a model that works well note that the model does not continue to train after it's been deployed for inference on device unless the model engineer is doing something more advanced like on device personalization so how does this federated learning part work itself if a device is idle and charging it will check into the server and most of the time it's going to be told to like go away and come back later but some of the time this server will have work to do the initial model as dictated by the model engineer is going to be sent to the phone for the initial model usually zeros or randomly initialization is sufficient or if they have some of that relevant proxy data in the cloud they can also use a pre trained model the client computes an update to the model using their own local training data only this update is then sent to the server to be aggregated not the raw data other devices may participating in this round as well performing their own local updates to the model some of the clients may drop out before reporting their update but this is okay these server will aggregate user updates into a new model by averaging the model updates optionally using secure aggregation the updates are ephemeral and will be discarded after use the engineer will be monitoring this the performance of federated training through metrics that are similar that are themselves aggregated along with the model training rounds will continue if the engineer is happy with model performance a different subset of devices is chosen by the server and given the new model parameters this is an iterative process and will continue through many training rounds so what we've just described is our fourth privacy technology of federated model averaging our diagram showed federated averaging as the flavor of aggregation performed by the server for distributed machine learning federated averaging works by computing a data weighted average of the model updates from many steps of gradient descent on the device the other federalization optimization techniques could be used so what's different we have between federated learning and traditional distributed learning inside the data center well it's all the differences that we saw with federated computation plus some additional ones that are learning specific for example the data sets in a data center are usually balanced in size most compute nodes will have roughly equal sized slice of the data and the federated setting the each device has one users data and some users might use G board much more than others and therefore those data set sizes might be very different similarly the data federated computation is very self correlated it's not a representative sample of all users typing each device has only one users data in it and many distributed training algorithms in the data center make an assumption that every compute node gets a representative sample of the full data set and third that variable data availability that I mentioned earlier because the people whose phones are plugged in at night versus plugged in during the day might actually be different for example nightshift workers versus day shift workers we might actually have different kinds of data available at different times a day which is a potential source of bias when we're training federated models and an active area of research what's exciting is that the fact that Meador ated model averaging actually works well for a variety of state-of-the-art models despite these differences that's an empirical result and we started this line of research we didn't know if that would be true or if it would apply widely to the kinds of state-of-the-art models that teams like G board are interested in in pursuing the fact that it does work well in practice is great news so when does federal learning apply when is it most applicable it's when the on device data is more relevant than the server-side proxy data or its privacy sensitive or large in ways that would make it not make sense to upload and importantly it works best when the labels for your machine learned algorithm can be inferred naturally from user interaction so what is that label a naturally inferred label look like let's take a look at some examples from G board language modeling is one of the most essential models that power is a bunch of G board experiences the key idea and language modeling is to predict the next word based on typed text so far and this of course power is the prediction strip but it also powers other aspects of the typing experience G board uses the language model also to help understand as your typed app typing or gesture typing which words are more likely the model input in this case is the type in sequence so far and the output is whatever word the user had typed next that's what we mean by self labeling if you take a sequence of texts you can use every prefix of that text to predict the next word and so that gives a series of training examples as a result of people's natural use of the keyboard itself the G board team ran dozens of experiments in order to replace their prediction strip language model with a new one based on a more modern recurrent neural network architecture described in the paper linked below on on the left we see a server trained recurrent neural network compared to the old G board model and on the right a federated model compared to that same baseline now these two model architectures are identical the only difference is that one is trained in the data center using the best available server-side proxy data and the other was trained with federated learning note that the newer architecture is better in both cases but the federated model actually does even better than the MA then the server model and that's because the decentralized data better represents what people actually type on the x-axis here we is for the federated model we see the training round which is how many rounds of computation did it take to hit a given accuracy on the y-axis and the model tends to converge after about a thousand rounds which is something like a week in wall clock time that's longer than in the data center where the x-axis measures the step of SGD where we get to a similar quality and about a day or two but that week-long time frame is still practical for machine learning engineers to do their job because they can start many models in parallel and work productively in this setting even though it takes a little bit longer what's the impact of that relatively small difference it's actually pretty big the next word prediction accuracy improves by 25% relative and it actually makes the prediction itself prediction strip itself more you full users click it about 10% more another example that the G bore team has been working with is emoji prediction its software keyboards have a nice emoji interface that you can find but many users don't know to look their or find it inconvenient and so G board has introduced the ability to predict emoji right in line on the prediction strip just like next words and the federated model was able to learn that the fire emoji is an appropriate completion for this party is lit now on the bottom you can see a histogram of just the overall frequency that of emojis that people tend to type which has the laugh cry emoji sort of much more represented so this is how you know that the context really matters for emoji we wouldn't want to make that laugh cry emoji just the one that we suggest all the time and this model ends up with a 7% more accurate emoji predictions and G board users actually click the prediction strip four percent more and I think most importantly there are 11 percent more users who have discovered the joy of including emoji in their texts and untold numbers of users who are receiving those wonderfully emotive old texts so far we've focused on the text entry aspects but there are other components to where federated learning can apply such as action prediction in the UI itself G board isn't really just used for typing a key feature is enabling communication so much of what people type is in messaging apps and those apps can become more like lively when you share the perfect gift so dis helping people discover great gifts to search for and share from the keyboard at the right time so about getting in the way is one of G board's differentiating product features this model was trained to predict from the context so far a query suggestion for a gift for a sticker searcher emoji and whether that suggestion is actually worth showing to the user at this time this model that is is an earlier iteration of his models described at the paper linked below this model actually resulted in 47 percent reduction in unhelpful suggestions while Inc simultaneously increasing the overall rate of emoji gif and sticker shares by being able to better indicate when a gift search would be appropriate and that's what you can see in that animation as someone types good night that little G turns into a little gift icon which indicates that a good gif is ready to share one final example that I'd like to give from G board is the problem of discovering new words so what words are people typing that G board doesn't know it can be really hard to type a word that that the keyboard doesn't know because it'll often autocorrect to something that it does know and G board engineers can use the top typed unknown words to improve the typing experience they might add new common words to the dictionary in the next model release after manual review or they might find out what kinds of typos are common suggesting possible fixes to other aspects of the typing experience here is a sample of words that people tend to type that G board doesn't know how did we get this list of words if we're not sharing the raw data we actually trained a recurrent network to predict the sequence of characters people type when they're typing words that the keyboard doesn't know and that model just like the next word prediction model is able to be used to sample out letter by letter words we then take that model in the data center and we ask it we just generate from it we generate millions and millions of samples from that model that are representative of words that people are typing out in the wild and if we break these down a little bit there's a mix of things there's abbreviations like really and sorry missing their vowels there's extra letters added to haha and you often for emphasis there are typos that are common enough that they show up even though G board likes to autocorrect away from those there are new names and we also see examples of non English words being typed in the English language keyboard which is what this was English in the US was what this was trained against those non English words actually indicate another way that G board might improve G board has of course an experience for typing in multiple languages and perhaps there's ways that that multilingual experience or switching language more easily could be could be improved this also brings us to our fourth privacy principle which is don't memorize individuals data we're careful in this case to use only models aggregated over lots of users and trained only on out of vocabulary words that have a particular flavor such as not having a sequence of digits we definitely don't want G board to be able to memorize that the model we've trained in federal earning to be able to memorize someone's credit card number and we're looking further at techniques that can provide other kinds of even stronger and more provable privacy properties one of those is differential privacy this is the statistical science of learning common patterns in a data set without memorizing individual examples this is a field that's been around for a number of years and it is very complementary to federated learning the main idea is that when you're training a model with federated learning or in the data center you're going to use appropriately calibrated noise that can obscure an individual's impact on the model that you've learned this is something that you can experiment with a little bit today in the tensorflow privacy project which i've linked here for more traditional data center settings where you might have all the data available and you'd like to be able to use an optimizer that adds the right kind of noise to be able to guarantee this property that individual examples aren't memorized the combination of differential privacy and federated learning is still very fresh Google is working to bring this to production and so I'm giving you kind of a preview of some of these early results let me give you a flavor of how this works with privacy technology number five differentially private model averaging which is described in the ICL our paper linked here the main idea is that in every round of federated learning just like what Emily described for a normal round an initial model will be sent to the device and that model will be trained on that devices data but here's where the first difference comes in rather than sending that model update back to the server for aggregation the device first clicks the update which is to say it makes sure that the model update is limited to a maximum size and by maximum size we actually mean in a technical sense the l2 ball of print in parameter space then the server will add noise when combining the device updates for that round how much noise it's noise that's roughly on the same order of magnitude as the maximum size that any one user is going to send after with those two properties combined and properly tuned it means that any particular aspect of the updated model from that round might be because some users contribution suggested that the model go that direction or it might be because of the random noise that gives a kind of an intuitive notion of plausible deniability about whether or not any change was due to a user versus the noise but it actually provides even a more stronger formal property that the model that you learn with differential privacy and with differentially private model averaging will be approximately the same model whether or not any one user was actually participating in training and consequence of that is that if there's something only one user is typed this model can't learn it we've created a production system for federal computation here at Google which is what I has been used by G the G board team to in the examples that I have talked about today you can learn more about this in the paper we've published at the smell this year towards federated learning at scale system design now this system is still being used internally it's not yet a system that we expect external developers to be able to use but that's something that we're certainly very interested in in supporting awesome we're excited to share our community projects that allows all to develop the building blocks of federated computations and this is tensorflow of federated tff offers two api's the federated learning or FL API and the federated core or f-c api the FL api comes with implementations of federated training and evaluation that can be applied to your existing Kerris models so you can experiment with federated learning in simulation the FC API allows you to build your own federated computations and tff also comes with a local runtime for simulations so earlier we showed you how federated computation works conceptually here's what this looks like in TFS so we're going to refer to these sensor readings collectively as a federated type or as a federated value and each federated value has a type both the placement so this is at clients and the actual type of the data items themselves or of float32 these server also has a federated type and this time we've dropped the curly braces to indicate that this is one value and not many which gets us into our next concept is distributed aggregation protocol that runs between the clients and the server so in this case it's the TFS federated mean so this is a federated operator that you can think of as a function even though its inputs and its outputs live in different places a federated op represents an abstract specification of a distributed communication protocol so tff provides a library of these federated operators that represent the common building types of federated protocols so now I'm going to run through a brief code example using TSS I'm not going to go to in depth so it might look a little confusing but at the end I'm going to put up a link to a site that provides more tutorials and more walkthroughs of the code so this section of code that I have highlighted right now it declares our federated type that represents our input so you can see we're defining both the placement so this is that the tff clients and that each data item is a TF float32 next we're passing this as an argument to this special function decorator that declares this I federated computation and here we're invoking our federated operator in this case it's that tsf fighter I didn't mean on those sensor readings so now let's jump back to that example where the model engineer had that specific question of what fraction of sensors saw readings that were greater than that certain threshold so this is what that looks like in TFS our first federated operator in this case is the tff federated broadcast that's responsible for broadcasting that threshold to the devices our next federated operator is the tff federated map that you can think of as the map step in Map Reduce that gets those ones and zeros representing whether they're local values are greater than that threshold and finally we perform a federated aggregation so that tff federated mean to get the result back at this so let's look at this again in code we're again declaring our inputs let's pretend we've already declared our readings type and now we're also defining our threshold type this time it has a placement at the server and we're indicating that there is only one value with that all equal true and it's a TF float32 so we're again passing that into that function decorator to declare this a federated computation we're invoking all those federated operators in the appropriate order so we have that tff federated broadcast that's working on the thresholds we're performing our mapping step that's taking a computation I'll talk about in a second and applying it to the readings and that threshold that we just broadcast and this chunk of code represents the local computation each device will be performing where they're comparing their own data item to the threshold that they received so I know there was a fast brief introduction to coding with TFS please visit this site tensorflow org slash federated to get more hands-on with the code and if you like links we have one more link to look at all the ideas we've introduced today about federated learning please check out our comic book at federated with google.com we are fortunate enough to work with two incredibly talented comic book artists to illustrate these comics as graphic art and it even has corgis that's pretty cool right so in today's talk we cover decentralized data federated computation how we can use federated computation building blocks to do learning and gave you a quick introduction to the tensorflow federated project which you can use to experiment with how federal-aid federated learning might work on datasets that you have already in the server in simulation today we expect that the you might have seen the TF flight team has also announced that training is a big part of their roadmap and that's something that we are also really excited about for being able to enable external developers to run the kinds of things that we're running internally at some time soon we also introduced privacy technologies on device datasets federated aggregation secure aggregation federated model averaging and the differentially private version of that which embody some privacy principles of only in aggregate ephemeral reports focused collection and not memorizing individuals data so we hope we've given you a flavor of the kinds of things that federated learning and computation can do to learn more check out the comic book and check and play a little bit with tensorflow federated for a preview of how you can write your own kinds of federated computations thank you very much [Applause] [Music] 