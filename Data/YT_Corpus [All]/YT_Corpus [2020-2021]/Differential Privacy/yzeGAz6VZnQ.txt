 (upbeat music) I'm Furong Huang, I'm a system professor from computer science. I also wanted to advertise center for machine learning which is which belongs to UMIACS, but is recently formed. So I'm a member of that. My research is mainly focused on spectral methods with provable guarantees, but my recent research also focused on theory in deep learning. So, my the thesis of my research is trying to establish a feedback loop between the two right. Proven methods in classical machine learning algorithms and hoping to apply those provable guaranteed methods into the guaranteed learning of deep learning. Okay. So, under that process, my research also focus on non convex optimization. So some applications of my research includes representation learning, anomaly detection using a generative models Or I care about fairness in privacy and machine learning. So my research involves interpretable, machine learning and robustness in machine learning. So most of my algorithms that, you know, our lab develops, focuses on some kind of distributive computing, we wanted to make the algorithms scale to big data and also be very fast. So lastly, some of recent work has been touching a little bit on reinforcement learning, domain adaptation, and so on. So I'll give you a very high level of these projects. And hopefully, if you are interested in any of them, talk to my students. You know, my students are in the audience. We have posters today, and you're welcome to send me an email. Okay. All right. So the first See of the of my research is Deep Learning Theory in Nonconvex optimization Learning With Guarantees. So, I choose two representative projects here, one is understanding generalization in deep learning and the other is escaping from saddle point for a nonconvex optimization problem. So, the left hand side one is understand generalization deep learning so, we basically develop like a new architecture, a new model to improve the compressibility and robustness of neural network with provable guarantees. That's like a very high level, you know, description of this work. But essentially, we get a tighter generalization bound using some kind of principled compression using some tensor methods. So, I believe we have a poster today, although I don't know exactly when the poster Robby. So the other project was for a general nonconvex optimization. So, we figured out some kind of condition under which using first order methods such as gradient Stochastic gradient descent can be provably escaping from those saddle points in time. So, this will help us to understand in general, if you're given a neural network which is non convex, what would you do? Alright, so, some of the applications so, my research, for example, representation learning is a big theme of my research and anomaly detection is the application you know, I focus on generated models, for example, a convolution of dictionary learning models, right. So, we use some kind of tensor decomposition with certain kind of structure. So, we can learn these dictionary models when the data has some invariance, right for example, shift in variance, rotation in variance and so on. And the other project which is I call it mixed membership detection is probably very, is can be applied to a lot of applications for example, you know friendship network, right so you can learn some common communities from your Facebook friend network. You could also use those kind of information for targeted marketing or you know, recommend a systems and so on. So, the idea here is there's some provable guarantees for learning these underlying communities. Alright, so as I said before, I care about fairness and privacy. So, one of the projects in my lab is differentially private latent Dirichlet allocation, which is a popular topic model, right. So LDA, so we introduced the first differentially private algorithm this guaranteed to recover high quality estimate of the LDA. So it's basically figuring out what, where, where is the location to add some noise so that your outcome becomes differentially private. But it's also the amount of noise that you add would perturb the outcome in a beast sense, right? So you wanted to make sure that the mechanism suffered at least from utility loss under some level of privacy. So the second project, which is actually going on right now is to learn the fair representation of any generative model. So we know that when we care about fairness is usually you know, in the sense that you have labels, and you wanted to have fair machine learning in supervised learning. So here we actually introduce a framework for unsupervised learning. So you would want to correct the bias in the data so that the bias is corrected and you can use that D bias data for all the downstream tasks. Alright, so, lastly, as I said, I care about distributed distributed computing and spectral methods. I don't wanna go into details here, but the main message is that you know, we have some projects that are trying to implement these kind of tensor methods spectral methods or hierarchical model learning in a very fast manner essentially like sometimes pair you know, a sync book is synchronous parallel algorithms. And, you know, you we implemented on CPU, GPU and in the cloud. So, the idea is that our research is not only has theoretical guarantees, but also can be implemented in a fast manner. So, lastly, the last topic that my group is working on is reinforcement learning or kind of online decision making. Right? So we have a project, which is called off policy evaluation in contextual bandits under distribution shift. So we know that contextual bandits has been like a well studied topic in online learning, but people haven't really talked about what happens when there is distribution shift, right, what you observe in the summer might be different than what you observe it in the winter. So, what do you want to do? So, for these kind of tasks, we established a off policy evaluation scheme for this non stationary world. And essentially, we propose some kind of intern shift model. And basically, we can guarantee learning of domain shift and the distribution shift. So I think this is a very cool work So the other work that will also be presenting today is the Spectral Model-based Reinforcement Learning. So reinforcement learning is really hard because it is a sample. The sample complexity is usually very high, so usually requires a lot of exploration before you reach to some good policy. So the idea here, we don't want it to, we don't want it to randomly explore things to reach to a certain kind of optimal policy, we want it to do something to utilize some kind of underlying structure. And essentially spectral methods plays a very important role here. So we basically proposed something that's like so called tensor our max. So beating the state of the art model based our max algorithm. So that is a recap of all my research. Most of the research I presented here will be presented during one of the poster sessions. You're welcome to Come back next. (upbeat music) 