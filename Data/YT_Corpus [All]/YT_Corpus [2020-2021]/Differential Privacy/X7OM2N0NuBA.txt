 Hi! This work is addressed towards practical differentially private convex optimization. Nowadays, sensitive data is being used  for a variety of learning tasks. Convex optimization techniques have proven to be very useful for such tasks. However, many recent works show that trained models can leak information about sensitive data. Differential Privacy has been the standard notion used to prevent such leakage. Although several DP algorithms exist in the literature, deploying these techniques remains challenging in practice, in part because they require either a custom optimizer, or obtaining the minima of the loss function, which is never guaranteed in practice. In this work, we design a new DP algorithm called Approximate Minima Perturbation. It has many advantages, including being able to leverage any off-the-shelf optimizer. We also perform a broad empirical study evaluating 6 state-of-the-art techniques on 2 models over 13 datasets, 4 of which are high-dimensional. Thank you, and see you at the talk! 