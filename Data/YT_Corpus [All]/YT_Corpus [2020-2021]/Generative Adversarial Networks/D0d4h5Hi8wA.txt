 [Music] so so far what we have seen now I'm going back in history and back in the past and starting as a scientist finished model 23.2 so so far what we have seen is that an intuitive explanation of Gans you had this generator a discriminator you had this minimax objective function which you minimize with respect to the parameters of the generator and maximize with respect to the parameters of the discriminator and then we saw this overall algorithm for training then which alternates between the generated parameters and the discriminative parameters okay now we want to look at some math behind this intuition right so all we have done is you have set up an objective function and just assume all of that will work we are not even defined what does it mean by saying at the end the gaen that we trained actually works what does it mean so let's start with that right so we'll delve a bit deeper into this objective function and see what it implies so suppose you have this clue data distribution right so you are given this training samples right and from these training samples these are all the amnesty images each block is 1 mm list image now these training samples and this samples actually come from some distribution right on the other hand you have this generator which is also generating images and I can say all of these images are coming from the another distribution which is P of GX both these distributions are on top of X where X is your images 1 0 2 4 dimensional or n-dimensional so both these distributions are over the same set of random variables but one is the to distribution one is the generated distribution okay if everything works fine what do you want to happen at the end P GX is equal to P data X right that's what we mean when we say that it should work okay but is this the object if that was the case we should have said this as the objective function right we should have said that minimize the KL divergence between these two or whatever other probability distance function that you know how right but we didn't do that we use some other cryptic objective function which depended on some cross entropy or some score and so on right so what we need to show is that and the reason we did that is because we did not have a gee x-rayed we did not explicitly model P G of X unlike Auto regressive models or RB aims or VA s there was no P of X in this generator right we never came up with the formula for P of X that's why we couldn't have that as the objective function all you can hope for is that whatever this pseudo objective function we have set up that eventually leads to this condition even though we have explicitly not computed P of X or P of G X does that make sense is it ok what we need to actually show is that clear nothing right so so what you want to say is that so here's let me state it this way you want to show that if the disc emitters loss function is at its minimum value can I guarantee that that can happen only if P G is equal to P data is that fine is that a good statement ok so we'll try to prove that ok so here's this theorem statement right this is from the paper that the global minimum of this training objective rate and this max V of Gd is nothing but that two-part objective function which I had written it so this V of GD is just that two-part objective function which I had written where you have an expectation over the true samples and an expectation over the generated samples right and I am trying to maximize this with respect to the discriminator and I have to show that so actually yeah so here's the theorem and I'll just explain what it means so remember that the goal of the generator is to minimize the maximum of this value wait it's a first you have the discriminator you compute some loss function with respect to that and the goal of the generator is to minimize the maximum value of that right fine because it's minimize or maximize is that fine heavier is okay so now the theorem states that this minimum will be achieved if and only if P G is equal to P data right so what it means is that whatever objective function I have set up if I'm able to achieve that objective function then I can be sure that PG is equal to P data which would have actually been my true objective function is that fine is a statement of the proof clear if I prove this then you'll be fine that I mean we have gone back to our original goal and proved it now any theorem which has an if and only if part can always be split into these two parts right the if part and the only part so they've part is that if PG is equal to P data then the global minimum of the virtual criteria would be achieved right and the only if part is that if this is achieved then PG has to be equal to P data there is no other way that could have been achieved you get the difference between the if and only if part so if if PG is equal to P data then this will go to its minimum that's fine but if only if part is the reverse of this which means that if I know that this has gone to this minimum value then I can be sure that PG has to be equal to P data right so I have to prove prove the F part as well as the only if part okay so here's the outline of the proof we first look at the if part and then we look at the only if part okay so the if part to show the if part I will show the following first I have to find this value of DG when P G is equal to P data because that's what the if condition says okay so I'll find what this value of v DG is or rather actually CG is okay then I'll find the same value when P G is not equal to P data okay so I know what the values when P G is equal to data I know what the values when P G not equal to P data for any pitch any other PG now what do I have to prove to prove the if part first one is always less than equal to right minima is that fine so when P G equal to P data whatever value you get that's always less than equal to the value when you get when P G is not equal to P data is that fine so that's the third step that I need to prove that show that is less than equal to less than B or less than equal to is also fine is that okay avian gets this three parts I'll show what the value is when P is equal to P data I'll show what the value is when P G not equal to P data and then I will show that a is less than equal to P if I can show that then I can show that the minimize are chained only when P G is equal to P data is the outline of the proof pier does that make sense anyone who does not get that please raise your hands if you get this okay now the only if part is that when this minimum is achieved I need to show that P G is equal to P theta that means if someone tells me that I have achieved the minimum then it has to be the case that P G is equal to P ditto is that fine they've pardoned the only part okay so let's start with the F part and we look at the first step of the F part so this is the objective function now what I'm going to do is I'm going to replace the expectations by their integrals okay and now I'm going to observe that first of all observe that this is nothing but X this is the generated X right so I know that this G Phi of Z is a function of Z so by this some cryptic rule actually I can replace the second integral which was over Z by an integral over corresponding X's is everyone okay with this the first integral has been copied as it is but the second integral has been replaced by a different integral instead of Z now I have an integral over X why does this make sense what is the rule that I've used here I've used change of variables that's a valid answer but there's a slight problem there when you do change of variables you have to assume that the function is invertible we don't know whether g is invertible or not right okay so I'll give you an interview to explain intuitive explanation for why this makes sense this actually comes from something known as the law of the unconscious statistician I don't know who named it that way but I'll give you an intuitive explanation for why this is okay right so we'll try to understand what this integral tried to tries to do and then say that it's okay if I replace it by this integral okay so the first integral is actually over Z so these are all the sets that you have okay now given as Z is G Phi of Z a deterministic function or a random function a deterministic function I'm going to pass it through the neural network for a given Z I am always going to get the same X no matter how many times I pass it okay so from the Z domain to the X domain what kind of a function do I have many too many one too many one to one or many to one can two different sets give me the same X in two different sets give me the same X that's possible think of a simple neural network with just dust classification right you could give it to Apple images for both of them it can give you the same output right so for two different inputs I can get the same output but for the same input can I get two different outputs No so then what kind of a function is this many to one okay so there could be many Z's here which correspond to the same X here okay is that fine now this integral is actually over the Z's I am integrating over these sets based on their individual probabilities is that fine but now if I look at the X's their probabilities are actually just a function of these two because these if I just sum up these two Z properties I will get the probability of the given corresponding X does that make sense if all of these are say point one point one okay and only these two Z's result in this X and what's the probability of that X going to be point two does that make sense okay so now instead of summing over these sets I can just sum over the x's and replace the probability of Z by the probability of X right because whenever summing over the Z's I was summing over these five terms but it turns out that these Phi term just collapse two three terms in the X domain so instead of summing over these fighters I can sum over those three terms and replace them by the corresponding probabilities does that make sense please raise your hands if it does so that's the intuitive explanation for why this works and there's actually a law behind that you can go and prove it more formally but you understand the intuition that's fine I don't care if you don't really know this law because even I don't know it okay so that's how you will replace the Zed's here by X's here and the reason I am doing that is I have and already have one integral with respect to X I wanted the second interval also to be with respect to X and the second thing was I wanted P data and PG so I now have P data in PG does that make sense okay and remember this PG is actually a function of PZ you can write it as that is it okay so now this is our revised objective function okay now when will this achieve the inner thing right if I look at this when will it achieve its maximal Maxima when for every given X the term inside the integral is maximized right so instead of integral just think of it as a sum so you have a sum of some terms you want to find the maximum of this sum so the sum would be maximized when every term in the sunless maximize does that make sense okay so then I just look at the quantity inside the integral and I'll take its derivative with respect to D and set it to zero okay so I will take the derivative with respect to D and set it to zero okay can you help me in working this derivative what will be the first step P data upon 1 by period upon D X into 1 plus PG over okay I'll just write it is that fine okay now I can just do some simple I'll take one term on one side okay and I want an expression for DT tags completely sure it looks like it matters but I am not completely sure of the implications of that right whether it matters to this achieving its final objective or not I am Not sure that I need to work out okay so we will come back to that let's not confuse the others about that okay so for now just see that this thing right so you get the optimal discriminator what is this DT of X is it a distribution is it a score what is it it is cool so what does it mean that I will give you an X the score the best score that the discrimination assign it is just take P data of X and divided by P G of X plus P DT of X right that's the optimal discriminator is that fine okay now for any given generator if I give you the generator then the optimal discriminator is given by this okay but what is the condition that we had in the if part of the theorem P data is equal to P G so if I substitute that here what do I get 1/2 right so that's why when you end training your discriminator should actually irrespective of whether it's a true image or a fake image it's so confused that it just assign the score of 0.5 to both I can't really distinguish so I'll just say with half probability that this is real or half cloudy that this is fake okay that makes intuitive sense okay so now this this quantity right that we were interested in or rather the max of this quantity I'll just substitute the max for each of these guys inside that's the one which we have computed here so I'll substitute that and this is what I get okay is that fine what is this integral what is this integral one right integral over power D density function what is this integral one so what's the final out answer that you get oh wait so this should be plus all I think this should be minus so what you'll get is minus 2 log 2 which is minus log 4 so this is the value you achieve when PG is equal to P data so I have computed the value that you will achieve when P is equal to P data that was the first part or the first step of my proof is that fine now what do I need to do when PG not equal to P data what happens right so that's why we will go to the second part we have done the first part now you look at the second part so we will throw away this assumption that PG is equal to P data okay so you look at PG not equal to P data so let's see what happens in that case so I am NOT going to suited half here because half is only when P is equal to P data so I'm going to work with when PG is not equal to P data okay so now since I know that sound where I need to compare with a log for so this is some trickery that I'm going to do I'm going to add this term and you see that what I'm adding is just a zero right because it's log two minus log two I'm just adding a zero so this is a fair thing I'm only doing this because I know where I need to reach and just trying some manipulation so that I reach where I want to reach okay so this is not something which you can come up with this is because you know what the answer is so you have added this string I'm sure all of you have done similar proofs and different high school courses okay is that fine I've added this effectively I've just added a zero now what I'm going to do is I'm just going to rearrange some terms here and there okay so first note that I can take this minus log two and this part has one integral okay is that okay and then each of these other log two is I am going to split it between the remaining two integrals don't try to really squint and try to understand this this is very very simple I genuinely mean that is just some rearrangement of terms and once you do all this right what you will end up with okay let's not go there so you will end up with minus log four plus some quantity can you tell me what this quantity is first what is this it's a distribution what about this distribution what does this term look like KL divergence between p data and the term inside the bracket and what about this KL divergence between PG and the term inside the bracket everyone gets that right so you can just think of this as P and this is Q so you have integral P log or sorry P log P by Q and integral Q log Q by P or whatever right so you can just write it as sum KL divergence okay so it's actually the KL divergence between P data and this other distribution is it okay so you have minus log four plus two K L divergences okay so when PG is equal to P data this value is minus log 4 when I don't assume PG is equal to period I get minus log 4 plus 2 K L divergences so given to these two statements what can you tell me what do you know about KL divergence always greater than equal to 0 now can you tell me something ok so let's look at the steps so now at this point what I have done is I have done the step two of the theorem of the proof I have shown you what is the value when PG is not equal to P data is that fine okay now what I need to show you is that the minimum is attained only when PG is equal to PT okay so the general term is this when for any PG any p data okay now what do we know about the KL divergence greater than equal to 0 so what then what can you say about CG it's always going to be greater than equal to minus log 4 that means minus log 4 is the lower bound it's the minimum value that CG can take and when did CG take that value when P is equal to P data so water which proved now we have proved a part if PG is equal to P data then CG takes its minimum value is that fine avian gets that okay so that's the end of the if part now for the L or the only if part what I need to show is that if CG has taken its minimum value someone has told me here's the CG and it has achieved its minimum value then it has to be the case that PG is equal to P data okay now what's the minimum value of CG minus log for we know that okay so let's start with that so the general formula is minus log 4 plus this now someone has told me that CG has attained its minimum value that means what do I know CG is equal to minus log 4 that implies that two other terms are 0 so KL divergence of this and KL divergence of this is equal to zero okay so you can now prove that since KL divergence can only be greater than equal to zero so these two terms cannot cancel each other so they both have to go to zero and you can easily prove that this will happen only if PG is equal to P data in fact you don't even need to prove that whatever I have written here is actually the symmetric version of KL divergence and it is known as the Jensen's Shannon divergence okay so this is actually the Jenson Shannon divergence between P data and PG and the Jensen Chen and divergence would be zero only when P data is equal to PG okay so whichever you want to prove it you can prove it either prove that this is equal to zero I mean this equal to 0 implies that P is equal to P data or just assume that this is equal to Jensen Shannon divergence not assume that that's the actual relation and that will be 0 only when P is equal to P data ok so have you proved a if and the only if part so what have we effectively proved that whatever objective function we have chosen this minimax problem that we had chosen actually optimizing that that is the same as optimizing this other objective function which is PG should be equal to P data that's what we have proved this guy will attain attained its optimum value only when PG is equal to P data is that fine all right so that's the more formal proof about why the particular objective function for GATS okay so with that I finally end the lecture and eCos so thank you and I hope you guys enjoyed it and I hope you guys learned a few things and I hope you guys do well in the enzyme and on the remaining assignments also so this enzyme will again we have the same flavor as quiz 1 it will not be of the same flavor as quiz - okay thank you [Music] [Music] 