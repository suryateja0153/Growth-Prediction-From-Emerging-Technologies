 this is all a conspiracy no you know that is a conspiracy yes yes yes good evening my fellow Americans fakes or pain but the men who went to moon with war and peace will stay on the moon rest in peace that President Nixon video you just watched is a deep fake it was created by a team at MIT as an educational tool to highlight how manipulated videos can spread misinformation and even rewrite history deep fakes have become a new form of altering reality and they're spreading fast the good ones can chip away at our ability to discern fact from fiction testing whether seeing is really believing some have playful intentions while others can cause serious harm people have had high-profile examples that they put out that have been very good and I think that moved the discussion forward both in terms of wow this is what's possible with this given enough time and resources and can we actually tell at some point in time whether things are real or not a deep fake doesn't have to be a complete picture or something it can be a small part that's just enough to really change the message of the medium see I would never say these things at least not in a public address but someone else would someone like Jordan Peele a deep fake is a video or an audio clip that's been altered to change the content using deep learning models the deep part of the deep fake that you might be accustomed to seeing often relies on a specific machine learning tool again is a generative adversarial Network and it's a kind of machine learning technique so in the case of deep faith generation you have one system that's kind of create a face for example and then you have an adversary that is designed to detect deep fakes and you use these two together to help this first one become very successful at generating faces that are very hard to detect and they just go back and forth and the better the adversary the better the producer will be one of the reasons why Ganz have become a go-to tool for deep fake creators is because of the data revolution that were living in deep learning has been around a long time neural networks were around in the 90s and they disappeared and what happened was the internet when the Internet is providing enormous amounts of data for people to be able to train these things with and armies of people giving it annotations that allowed these neural networks that really were starved for data in the 90s to come to their full potential while this deep learning technology improves everyday it's still not perfect if you try to generate the entire thing it looks like a video game much worse than the video game anyways and so if people have focused on just changing very specific things like a very small part of face to make it kind of resemble a celebrity in a still image or being o to do that and allow it to go for a few frames in the video deep fakes first started to pop up in 2017 after a ready user posted videos showing famous actresses in porn today these videos still predominantly target women but if widened the net to include politicians saying and doing things that haven't happened it's a future danger and a lot of the groups that we work with are really focused on future dangers and potential dangers and being a breast of that one of these interested groups has been DARPA they sent out a call to researchers about a program called media forensics also known as metaphor it's the DARPA project and that's geared towards the analysis of media and originally it started off as very much focused on still imagery and detecting there's someone insert something into this image this morning move something it was before deep fakes became prominent the project focus changed when this emerged at SR I international Aaron and his team have been working across disciplines to create a multi-pronged approach for detecting deep fix the system they've developed is called savvy so our group focused on speech and in the context of this savvy program we worked with people in that artificial intelligence center who are doing vision and put our technologies together to collaborate on coming up with a set of tools that can detect things like here's the face here's the identity of the face it's the same person that was earlier in the video the lips are moving okay then we use our speech technology and say can we verify that this piece of audio and this piece of audio came from the same speaker or different speaker and then put those together as a tool that would say if you see a face and you see the lips moving the voice should be the same or you want to flag something however there is always a worry that making these detection systems more available could unintentionally provide deep fake creators with workarounds if released the methods meant to catch the altered media could potentially drive the next generation of deep fakes as a results these detection systems have to evolve in its newest iteration Aaron gave us a run-through of how various aspects of the system work without giving too much away this is an explicit lip-sync detection what we're doing here is we're learning audio and visual tracks what the lip movement should be given some speech and vice-versa and we're detecting when it deviates from what you would expect to see and hear while some techniques can work well on their own most fare better when combined into a larger detection system so in this video you'll see Barack Obama giving a speech about Tom Vilsack one of his departing cabinet members and we're running this live through our system here which is processing basically to identify two kinds of information the top on where it says natural is a model that's detecting is this natural or some kind of synthesized or generated speech essentially deep fake and the bottom is detecting identity based on voice so we have a model of Barack Obama and so it's saying this continues to verify as Obama this will continue like this until now we get Jordan Peele imitating Barack Obama we're entering an era in which our enemies can make it look like anyone is saying anything at any point in time and that whole section here was Jordan Peele he's natural but he's not Obama I would say for detection of synthesis or voice conversion we're in the sub 5% error rate for what I would call laboratory conditions and probably in the real world that would be higher than that that's why having these multi pronged things is really important however technology is only part of the equation how we as a society respond to these altered pieces of content is as important the media tends to focus on the technological aspects of things rather than the social the problem is less the deep fix and were the people who are very willing to believe something that is probably not well done because it confirmed something that they already believe reality becomes an opinion rather than fact and it gives you license to miss belief reality it's really hard to predict what will happen you don't know if this is going to be something that five years from now people actually nailed down or if it's 40 years from now one of those things that's still sort of exciting and interesting and new and you don't know what the limitations are yet you [Music] 