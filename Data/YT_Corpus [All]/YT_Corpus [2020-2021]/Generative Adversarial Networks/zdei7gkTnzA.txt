 When I prepare this video, I ask some of my friends what do they think when they first see my title. Most of them say they heard about what is machine learning, it is very popular nowadays; some of them ask what is P/S wave separation, and many of them just not don’t notice the VSP as it is too far away from them. Let me give you a first impression of P- and S-waves from a wider view. It is definitely not the first time you heard about earthquake. when big earthquake comes, things around you begin to shake, roofs may fall, communications break down, lots of damages occur. This all directly starts from the quake of the earth. The quake, seems like the wave you see in water, lake and ocean. However, it has something different traveling through the solid earth. You see our earth being cut off in the center of your screen. The wave of earthquake can be simulated under the simplified physical assumptions. This is a demo of how earthquake waves travelling around the earth, produced by IRIS If you look closer you will spot that there is a red curve and blue curve travelling through the earth in the center, and the seismogram is labeled also by this colour. The red one travels faster is what they labeled as P-wave, and the blue one travels a little bit slower is S-wave. Recognizing P- and S-wave is a very important work in seismology. We work on P- and S-waves, though not with the seismograms of this kind. There is a branch of people inspired from earthquake. They use artificial sources to generate elastic waves, the waves travel through the subsurface of earth and, received by receiving instruments, such as geophone and hydrophone. We call these waves seismic waves. The figures you see here are diagrams on how seismic surveys are exploited onshore and offshore. This artificial source seismic survey nowadays is a significant tool to explore the resources underground, as you know gas, oil, water and so on. So how does seismic waves function? How can seismic waves help us discover the earth. Well, signals talk. A better way to understand complex thing is to decompose it and understand every part of it. Remember the pick of P- and S-waves in seismograms from earthquake. When it comes to seismic surveys, the dense of signals increase, these seismograms need even delicate analysis. P- and S-waves are not only required to be recognized in vision and pick up in time, but desperate for being separated into single mode seismograms. Then let’s jump right into the data I face every day. Can you figure out which part of them is P-wave and which part is S-wave? Maybe a little bit hard right now. You even want to ask, How come they look different even with the seismograms you show us before? Well, because these files, named vertical seismic profile, are from a different acquisition system. Here, you drill a borehole deep down to the earth, the depth of it usually from meters to several kilometres. receiving instruments such as geophones are set near the walls of borehole. When you generate an artificial source on the ground, the signals will be received by the sensors in the borehole with the time going. Then we got these seismograms. It’s just in this case, what you see are not the data recorded in real field survey, but what we simulated by computers. This is a two component vertical seismic profile. Two component, you get it obviously that the two seismograms show in front of you, one is the vertical component, receives vertical particel motions, and anther is the horizontal component, correspondingly receives horizontal particle motions. What does particle motion link with P- and S-waves? Here we borrow diagrams from Michigan Tech to illustrate. This describe the relationship of direction of propagation and the direction of particle motions on four different kind of waves. We have the direction of propagation all the same as the long red arrows. The small black box, highlight the particle motions. Let’s focus on the difference of P- and S-waves. Pure P-wave has its direction of particle motion parallel to the direction of propagation, while pure S-wave has its direction of particle motion perpendicular to the direction of propagation. Most of situation is that the main propagated direction of P- and S-waves are almost parallel, that makes the two components have contrastive proportion of P- and S-waves. You see most of P-waves are in vertical component for this case, and most of S-waves can be seen in horizontal component. This leads to a group of wave separation method that separate waves from single component of seismic data. Not only use the motion features of waves, but other discrepancy such as the difference of velocity between P/S waves. And unfortunately these are based on the approximation that P/S waves travel nearly parallel. Signals would be ignored or even worser, being classified wrongly if they not obey to this assumption. We really need more accurate separation. As the separation methods grow, more vector or tensor based methods come up. they can fully utilise all components of the signals. These kind of methods mainly based on the mathematical and physical theory that P-wave can be derived by calculating the divergence of elastic waves, and S-wave can be derived by calculating curl of elastic waves. However, this method can not be used on record data directly. But why? Let’s make clear about the current situation. We have an equation to simulate the seismic waves, we have mathematical method to separate P- and S-waves in their propagated space during their propagation. If we record sufficient signals cover the whole space of the research area, we could do the separation just like what we describe. but the reality is we can not record all of the signals from their whole propagated space, we can only record where we set geophones. While divergence and curl calculation really reply on vectors or tensors in space, such that we can not perfectly derive P- and S-wave by this mathematical method directly. That is to say the vector based separation method used in record data have the following limits, One, not complete signals cover their whole propagated space and Two, not accurate information of their propagated space (that is the characteristics of subsurface). If we conclude this separation problem like that, it seems rather appropriate to have a learning based solution. What can we do? We compose many different combination of possible characteristics of subsurface, this free us from a very accurate undergroud information, and we do the wave propagation, derive P/S wave by helmholz decomposition, this helps to use signals from whole propagated space to do the separation. We then build up suitable machine learning tools, here we use deep convolutional neural network. We let the neural network to learn from the data, that separates P/S waves from seismograms. When the network is trained well, it has ability to separate P/S waves from seismograms that share similar distributions. Now let me show the detailed approaches we used and how our result goes. Actually we are trying to make this idea come true step by step. I will quick go through the former two experiments we did, summaries how these experiences lead us to our latest work. Ok. The First experiment, we tried to separate not the two kind of waves, but only P waves out, from one component synthetic data. We made lots of subsurface models, here this figure present one of the characteristics to show the difference of theses subsurface model, this one is the P-wave velocity. And this model you see here has four flat layer. We modify the number of layers, the value of velocities, and the source positions. Then apply wave propagator and vector based wave separator to the model, and generate seismograms like showing here, with a number of datasets over 22 thousand. We use part of these data training and testing through our neural network, the network shows its ability to learn wave separation. And we make further test on more complex subsurace model, just like what I show you here. it owns more layers, even inclined layers rather than flat layers. The network trained on flat layers can still separate these waves as we want. The second experiment, instead of extracting P waves only from the single component, we tried from multi-components. We use open synthetic data from SEG. The subsurface model has more colourful structure in it. And the data, different from the huge volume of training datasets, this case we set only one independent variable in the dataset, that is the source position. Each source contributes to one piece of data. We have 151 shots of data in total, and one third of them are used for training. What does one piece of data look like? You can feel it in either of the grey figures on the right. The one on the top is our target separated P-waves, and at the bottom is our result predicted by well trained neural network. Detailed comparison also presents that the difference is just subtle as we feel between the grey figure of results. And thanks to the small volume of data, we have chance to work on how the chosen of training datasets influence the testing results. We sample the location of sources from the whole dataset with different sampling rate. And Each red line on plotting stands for once testing results after training on different choice of sources. The X-axis is the position of the sources, and the Y-axis is the testing score. Score higher, the separation results better. It is very obvious which ones are included in the training datasets, these are the high scores. From this contrast, we get that As we decrease the sample interval of training dataset, the testing results get better in wave separation. By the way we name the method that sampling the dataset for training as interpolated based learning. Because this situation is rather common seen in geophysical training strategy, and we will recall it in my following experiments. Then finally we come to separate both P- and S-wave simultaneously from multi-component seismic data. This time we still use synthetic seismic data well in the meantime we think how does our neural network show its ability to separate waves in a real seismic survey. So we makes this problem a target oriented work. Now we have a target dataset to separate, imagine these data are from this subsurface model. Well indeed , the characters of subsurface is unknown. What we got are some approximating velocity models. The model from geological survey, models derived from surface seismic investigation , and model from analysis near offset VSP first arrivals. None of them are 100% correct velocities. Even though, our method does not fear it. We have benefits to make the data tolerate the errors in the velocity model. How? If you remember the first experiment we make, to change the position of layers and the value of velocity. For this time, we come up with a new data building strategy that can not only involves the variables of subsurface model, but dramatically saves our computational cost. Instead of changing velocity model, we change the synthetic data acquisition geometry. Just like I am about to show you here. Now focus on the up-coming red and blue part of this diagram. Let’s have a close look at our training data building strategy. First see the acquisition system of our target dataset. Red triangles below the red dash line presents the distribution of sources, and the vertical blue dash line points out the position of borehole, where sit our receivers. Based on target dataset, we build our training dataset with two steps, One, sampling the number of sources.It is an efficient way for choosing training data we learnt from our interpolated based learning strategy. Two, adding more receivers, and because these receivers have different surround velocity, we involve the variables of velocity potentially. And we also get more training datasets with a very low computational cost. To compare the effectiveness of our training datasets, we extract the intersection of our training datasets (dataset-B) and the target dataset (dataset-A). The intersection of them is just the training datasets of interpolation based learning strategy. We call it dataset-C. We train two networks individually on dataset-B and dataset-C, then test on the target dataset-A. The testing result is exciting. Compared with the separated results using interpolation based learning scheme, results of our method are more close to the reference. It extracts most of the events, especially the waves with large amplitude. the continuity of waves is better, and results look not that noisy. Here is from another perspective to evaluate the separation results. We apply reverse time migration to the separated P- and S-waves. PP-images on the left reflect P-wave’s quality, and PS-images on the right reflect S-wave’s quality. Also compared to the reference on the top, images using our method is better than the results from interpolation based learning. Most of structure remains and not be blurred by the separated error. The robustness of our training is also strong, in some extent. While training we make it convenient to not modify subsurface model but acquisition system, claiming that our data building strategy tolerate some small velocity errors. So how would results go when we add these errors into the subsurface model. Here we give out the new subsurface model and the difference between them with the original model of training dataset. The results refresh us. In general, separated results get worse, but not that worse as interpolated based learning. And what interested us is that it seems that the all of results of P-wave are better than that of S-waves. That may involve some intrinsic properties of P- and S-waves. So next step, we are going to examine why P-wave separation performs more robust than S-waves, and make a closer step to apply what in synthetic data to field recorded data. That’s all my presentation. Thanks for watching. 