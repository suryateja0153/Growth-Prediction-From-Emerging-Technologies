 you [Music] all right so it's my great pleasure to introduce Pollard shall to Microsoft today he's gonna talk he's a associate professor at Georgia Tech guys PhD at Carnegie Mellon and it's got some famous papers the polonium papers like when the whens I know I've read definitely in detail and today he's going to talk to us about mining research papers and patents and descriptions for great ideas okay yeah thanks here Thank You Jay and everyone in attendance and also joining us remotely so today I'm going to talk about two really the topic wanted to how to McKay I'm more secure and the other is how to make a I'm more interpretable so that the first glance human thing that may not be directly related but hopefully through this talk you'll see that they're highly related and I will first begin with a little overview of what we do for our group and I like to name things out of myself before this talk so I named my group the Polo Club of data science and and at the bottoms of my students current students and recently graduate students and at the core what we've been working on how to combine two kind of intelligence if you wouldn't want to say ID stays very big and then also the human intelligence side of things so you can think of it more about combine how to scaleable automated methods and also the flexibility of human beings and the goal there is to develop scalable interactive tools to make sense of large-scale data set and model so these days argue that these are essential for any kind of analysis that we want to do and there's a number of resources that we have a Georgia Tech and so five of them are summarized them one is human standard yeah how do people interact with AI system sound make it easier security who have been working in a long time and a cyber security but these days we also care about security of AI which is why they have an adversary machine learning and starting with my PhD and also some of my students working and have been working on large graph mining graph data and network kind of data how to visualize them and also application in social good and health and of course also security as well so today we're going to focus a more two of them particularly how to make AI secure how to do for example look at that defends protection of AI and also relatedly how to make them more interpretable so why do we focus on them or how are they related right so there was a secure AI part I think I don't need to convince you too much because now a is often using safety-critical applications so it's very important that we study the threat and countermeasure right so you have power Agustin probably a lot more than you won't want and examples and the news there are all these accidents and people don't really fully know and too after a lot of incident investigation and somebody even ask the implication you still don't believe fully you know so they're gonna bring us to the need to really go deeper and understanding when you say you have like an accident or maybe you need to say someone say I now have a protection you can actually help avoid those accident how does that really work right so and as you know like these days often AI when people mention a I often they think about it black boxes and especially these days because they I often kind of mean using deep model while deep learning models and often uses black box not really that good right so ideally instead is we want to open the black box a little bit maybe not fully maybe too much details but at least make it easy for people to understand what is really happening and when something goes wrong we know how to fix it so and our way of doing is through scalable interactive user interfaces you cannot just say let's just tell you all the details you didn't provide the right interface to help people understand these complex large-scale systems so that bring us to out today's agenda like so for each of these - a big topic security I interpret or AI gives you a few example of projects that we have been working on recently I really excited about and also I'm going to say some of the latest worth a try to start to combine these two so I start with the secure AI side so we'll talk about some of the recent work that we do both on the attack and defense side of AI and you may say why do we need study attack and the reason is that we wanted to develop strong defenses so we need to know how the bad guy thinks so that's why I also be the bad guy and think about how to do that attack so I will give two examples now once called shapeshifter and she both of them are with Intel pretty recent into a collaboration and then in the second subsection I will focus on two system one is called a dojo in an MMO voice so those are tools that make a researcher students practitioner more easily able to test these attack and defense methods you will you if you have been working in the area you notice that a lot of interest recently that also means a lot of work both on detecting difference so how do you allow people to easily test all these are taken offense instead of them kind of writing everything on square so for that we'll show you two examples and on interpreter where a is I will talk about some of the recent collaboration with Facebook for example development activist system that helped them Facebook scientists understand the models and and datasets and also very recently with Google with develop gang lab and to help people understand this generative adversarial network so very hot that kind of deep learning models but also very very hard to to train and understand even an expert so we look at how do we do that and then lastly we wrap up we've come more high-level like a survey of this day of the art and also work that that the my students with Microsoft Research at last summer yeah so start of the secure AI outside so specifically the attack and defense so begin with a cartoon so you might have seen it is that in the not so distant future everything become smart including a toaster so toaster got hacked and thinking it's a blender and you might say okay well that's just making it up but it turned out that's true so you have smart toaster I can smart anything you want and actually and all these devices anything can imagine now is just having all these summer kind of learning capability or AI in it so AI Security's become an increasingly important and there's a lot of these numbers and from the popular press we probably seen that is just more and more of them and a lot even more and and also that unavoidably or naturally is in an AI now it's also using safely critical application where the stick is really high so what our goal is to study when they might break down run the royalties and also then develop secure I've met the way I met for these high-stake problems so give you some example like I said the first verse to collaboration with a were Shinto the first one is about tech cost shapeshifter attack how do you launch them physically realizable attack and then the second one because shoe is for defense so we start with the first one so I'll tear and it was published pretty recently our epic ad 2018 and as I mentioned in collaboration with Intel and this is also the very first we call a target to physical attack on object detection so that's a quite a number of technical terms here so what does that mean so often when people study of our machine learning problems as in machine anymore they want to attack it what it's really doing often is image based so as in attacking an image classifier and where the usual task is you have an image and then even though there might be many things in it but you just want one single label for example but the summation is looking at you said oh okay the label is probably a car but for human being that may not really make sense or in view this is really a part of a larger image you will see that well there's not really only a car there's also people that's building so why don't we also label those things so that's the inherent some security there so on the other hand if you're studying this as an after detection problem well then is it's probably more matching what people were really thinking when they are looking at an image well not only a car but also have people people all these things as a building and so on so what that means is when you're doing after detection is very different image classification is trying to recognize and localize multiple object at the same time right so that's important distinction between there because our attack is to attack these object detector so meaning attacking the machinery model that can do these recognize recognize as Asian and localization so it will break that not just like one image and they'll change the label so a little bit of information in case you're not familiar adversary machine learning so now it's pretty well established that not just machine learning model but just even deep meal Network models are very vulnerable vulnerable you may have seen many of these examples as in a bit image and I say image of stop sign and you can change the pixels in some very human imperceptible way changed because it slightly darker is like the brighter and that would get misclassified do whatever you want actually so in this case again misclassify into a speed limit sign and very easy to do digitally we return out that well because a lot of work is done in research in research academia so we often come up with what I call like pretty impractical threat model as and we assume the back I know a lot of information about the system so as in Purdue this they were assume the bad guys know everything they know how the model parameters they have access to data and everything but in practice you will imagine what the bad guys may not know as much information or may be much harder to do it for example if you are building a self-driving car and you want your car to be able to recognize the outside so think about you building a car what are you will do or need a system that able to capture the image you are using some color camera and unlikely you need to process a process of image image your video and they do recognition right and all these so what's really academic folks have been focusing on state through what I call the digital time as in they they assume the bad guy would have access to all the whole pipeline they have access to the data their access to the model have access to even to a pre-processing step so if you think about it like all these things are in the automated car system and if I really know about everything then I probably don't even need to I need to attack them model I can actually do other thing I could just change the label in it as it right so but nonetheless that's often what we we assume the bad guys would know so what we want to focus on some more I would say maybe more practical kind of threat model as in call the physically realizable adversary attack where we don't really mess with the system we don't even assume that the bad bad guys will be able to hack into it but now instead we manipulate physical environment as in we maybe we do something into the student stop sign without really going into the car so that's the kind of attack that we're interested in looking at so we hope it's more realistic and also we want to study can we change the stop sign to whatever we want so if we're going to the detail we'll show you the outcome they kind of like doing cooking show well show you the cook chicken before we go into the details about the recipe so there's a video a short video and where we have the real stop sign on the left on your left and then the fake stop sign there were all technique shape to the techniques they Pro to generate so it's printed out on a printer and our student my student Sean so he would drive his car closely towards the stop sign they will see that right there the real stop sign correctly classified almost all the time and a fake one as you go closer closer and originally it wasn't detected at all but it's go closer and closer and become a detective person it turned out that you can want you can make it to be the data and with anything you want but that's just so yeah example of how you can do these we call physically realizable attack you don't really need to hack it into the system you just need to manipulate the environment so this kind of what we call physical attack it's not new they're not new as in they all have been focusing on attacking image classification where you give a whole image you just give one able for example Desco acid second for phase classification you can print something like a 3d object and get misclassify image classifier are you getting doing sticker even on stuff side but all these are for image classifier focusing on attacking it go image classifier yes and some reasons work SSL well if you apply this I need to attack image image classifier and then now you you run your object detector on it actually those technique would not be able to fool the the update detector as in here on the left and on the right the sticker attack that work for image classifier could not fool the image of the object detector and similarly on the right hand side so that led us to our technique very well so how do you attack the object detector right so in particular we attack may stay up the our object detector called faster al CNN how it works is that they have like an image and then you try to detect what potential region of the image that might have some object in it we call they figure out the region proposal so in particular stage 1 January region proposal what are the potential regions around the stop sign you will see many potential region and a rich potential region then each others figure out like Oh what might be in it so if there's enough region that says oh this is probably a stop sign and they all those regional overlapping there's a this is actually and stop sign so that's also done through what the localization classification step so that means if you want to attack this update detector faster on CNN how what are the challenges that that there would be one is that because of the step and multiple region proposal your if you want to attack any kind of like attacking and ensemble right if you want to make this stop sign to be mislabeled esta at let's say a person right since there's many overlapping regions you can fool all the regions just fooling one regions not enough because the other region would compensate and say hey wait you say it's a person but I say it's a stop sign and many of them are saying stop sign right so that's one one the challenge and the second is that since we now we're dealing with physical objects so we need to care about distances angles lighting of example when there's a cloud that go past would it actually break the that detection right so all those we do care about so so how do we saw these like our technique is to well if we need to fold a whole ensemble well then that's so be it so so what we do is then we tried to minimize we're doing the optimization set right so a lot of these are based on optimization so instead of really optimizing for region by region by region now we we optimize over the sum of all the classification allows it so that means now we say well a manipulation or changes to the color and we only accept that change when it's able to for all the regions and and then we accept it so so you say I'll take that let me call ascend yes that yes after the fact yes it took a long time to try that and the second thing is that we don't just want the the stop sign to to change whatever you want right so we still want it to look like a stop sign and two human beings at least so then what we do is then we to a constraint on what are the part that the technique the shapeshifter technique can change so in this case we only protect the red area so we'll either stop the white text there alone and that's the reason for it doing it is because like for color rather using our human perception recognition and that it's better to or the human eyes is less sensitive to changes in the darker color for some a darker red you can do quite a lot more there and people can still cannot see that see that changes so that is the one kind of challenge that we saw and then their second challenge which is these distortions like due to real world right so and how do we solve it so as in light in different environment if in lighting so I do how do I care for it so we adapted technical expectation over transformation that was originally applied for the image classification in this case we extend it so that it will also work for attacking after detector so specifically how it works is you can think of it we try to similarly many of these scenario where we say we have our adversary generated stop sign we overlaid it on top of this images we can do the other rotation we can do the scaling you can do the different lighting some of their lighting and then we run the optimization over many of these simulation so after doing this many many trial opposed and then you are able to generate whatever you want so now if there's a target pass that say I want to turn it into a person it's more school or even on target that you want so here you'll notice that these perturbations are a lot more conspicuous right so so generally if we wanted to survive all these a physical perturbation or a manipulation then the pattern would need to be more conspicuous and if you want to lower it that's fine so I show you an example that video of an untargeted and in this case that means we want they stop something disappear so again similar setup so serine driving a car to what this stop sign and in this case it would just not be detected at all pretty scary there's only only go to the very very end and IP on a bird so so human eyes with this sense you can't really tell apart so and this is scary yes scary enough that darker green so they have a new program called car defense specific defense on AI and they highlight shape there as a stay of the order so the black ones where they show the the video and the program is centered around including developing defences for these physically realizable attacks so so that that there's a 1:1 I think we are really happy that there's like no support for this kind of line of research and it's all lit the least student Xiang so he because also this work is part of his thesis so we'll be starting as an assistant professor and I should know sign that Taiwan University in the spring I'm so even more impact hopefully and then his career so that's about a attack and I also want to mention a little bit the defense so that we must say Oh hopeless now yeah so we only have all the attack know that we're with doom so there are defenses so we also work on defenses including a system called shield and where the focus here is that how to develop practical defense and you'll notice that a lot of work in our group is a very empirical we want things that works and for sure one the kdd 218 audience appreciating the war down show some pretty pretty nice video because those people this is an interesting problem study so she'll focus on defense and impact in particular fast and practical defense so of course there's a lot of work on attacked a lot of work on defense our focus here is we want things like work so and when we say we want things like work that means we want things that are fast so we don't want to say oh wait forever and then now you deploy it so we want things that were real time at high speed so you're probably seen remember this right so currently how we attack these image classifier object detection is to manipulate the image for example you have a cat typically if this correct anyone says I can't if the dog is that it's a dog and how the attacker duty devise a perturbation is they take advantage of the graining information from the model so when I say AHA so I know all these how the other dog all the pixels used by the model and reach the dot and in through the gradient information you can say well now I change the gradient so that whenever I have the perturbation those pretty bit perturbation would be sufficient to change the output and now a become the Kent so naturally that means you ideally want to prevent this the attacker from using that great information and that's the core idea of shield technically we call stochastic local quantization or smq a little technical I'll explain what that means shortly and the very high level is really try to kind of destroy all the to to make bit that their gradient information much harder for the attacker to use right so kind of denying their the access and how do we do that in the high level we are using JPEG compression so actually everyone knows about it it's a great compression so I know why how the stripper compression when coming so dribble compression is specifically targeting everyone has used it right you have an image you want a smaller size I put it on the web and what it's really doing is removing information removing information that people cannot see so at a pretty high compression level you can really tell difference and we're using it because that's exactly targeting what the bad guy is trying to create for the perturbation where they say oh I'm going to introduce something that human eyes cannot see well if that's the case I would just use JPEG compression they will remove that and specifically we don't use it like just one kind compression level we use multiple kinds of compression level because I'm a lower compression level to a higher compression level here you see a lot more artifacts and then there's less odd-even and also we that's where the randomization come in right we don't want the attacker in to know exactly what level we're using so then that means for an image we divide it into blocks and for each one kind of randomly use that sample some compression level and together that still become me overall image so that is the main idea don't you yeah think of it as the middle part where you use this real-time compression and to protect the neural network so and this can be applied to both benign and and fs0 image actually we don't even care whether it's good or not whatever it is it just passed through the middle so it does attack hopefully she would be able to correct it is already correct hopefully it doesn't really damage the the image cause so at a high level this is a multi-pronged approach that combined the randomization and ensemble length through the many models and also this another pod to Evan talked about it's a model vaccination so that means you can actually train the model or retrain your model with these JPEG compressed models so that the model should be a compressed images so the model is used to seeing these Japan artifacts so how well does it work so if you apply our technique on resonant 50 model so the dotted line the bottom there is when there's no defenses so accuracy drops a vertical axis here is accuracy and horizontal axis here is participation strength so more to your right that means they're more change in more pixel changes more to less changes so you see more changes well the accuracy drop a lot where for shield in orange here still pretty good and if you look at individual JPEG level we see it's not as high as the combination or the ensemble so Tiny's here we were looking at after yes mm and I have GSM so those are some common attack method for manipulating the images yeah and as I mentioned so we care about practical how practical it is so just why that's all the reason why JPEG so I look at the running time as well that campaigned to other competing methods for example you can say removing noise of course you don't think about median filter and we think about total variation G noising so J pass is significantly faster no orders of magnitude faster and also doesn't hurt the benign accuracy so for sure there's some limitation so one limitation was that we didn't study what we caught an adaptive adversary as in the bad guy with no our approach and then they kind of tuned their methods right so so we extended to also look at that to about that so you sure whenever you look at a definite of attack that also means that bad guys kind of know have all access to your model so usually you will see that accessor is pretty high so the great line here is our original shoe model where you will say that as if all the models we used like JPEG 20 40 60 and 80 right if all the models are known that accessory attacked success rates about 60% but we I found that well actually we can lower the it further by training all these jpg 20 60 80 model from scratch so don't using information from the other model and then we can lower that a Texas sir a success rate even further so this work just appeared I can kdd you now 2019 workshop so the idea of compression not only helpful for images so you can also apply on audio as well so there now some audio attack so dogger is a system where we allow people who applied that defense using compression on audio so a Mercer audio very similar to two images but in this case it kind of changing the the audio instead of saying open in telecom like open epode calm again you can do whatever you want but this again is digital attack so it doesn't really survive once you play the video in the Wow and then get recall it actually those noise are gone okay so but we still study it's interesting for curiosity academic reason so adversary again used a similar gradient information like an pepper right back propagation to attack the model right and here where again we apply compression so that means whenever you have an audio you do the compression compression techniques and here compression you can imagine that different different method to do it and Adagio here is focusing on develop a usable front end so a lot of people to upload their own sample audio and then you can choose whatever I'll text you want and also apply whatever defense you you might like and then even better you can play the audio look at the different that here difference right so that very right quick video here you can say create a car upload a audio like your sample audio and now you can do the transcription like using deep speech and and that's the correct benign transcription and now you can choose an attack and then you can choose whatever what you want to change it to whatever you want this method often really really slow so we need to speed it up and 20 times okay so now you see okay they got manipulate it to your target then now they okay so we can apply to the defense and be free let's see so I was coming good also to AMR and so so on so of course mp3 is much faster so it kind of can fix it so there's a very yeah a cool way to try it and this is actually part of what I consider that do-it-yourself ever so much in earning as in as you saw we all - a structure and shoe and that's actually tons more out of technique so how do we know which ones working how do we pit them against each other so Adagio is one of the example are we setting where we want to make it easy for people do it and as a bigger effort we also develop that system now open sources called MLS Floyd to allow people to try even more so it's doing interactive experimentation with FSA machine learning research so now it's only open source and presenta am black and asia and we Katie the u19 showcase and the go is very high-level go there it's as I explained so it make it easier for students practitioners researchers to try all these so in the way that we can encapsulate these research as modules and that hopefully research I can contribute and also to try pretty easily allow easier comparison about tech and defense and also importantly we provide user from then that easy to use and allow people to to try these pretty easily and currently there are a number of modules some including shoe which we just showed and also have all these are tech and defense technique on images and also some are on them aware for example a V pass is bypassing enjoy me aware we have like Linux malware and attack and defense and so on so and at a very high level a MLS boy with allows user upload a sample that's that one I'll go to ms boy and then they can choose what they want to try want to attack what a defense they want to try and then they can compare the result and the architecture we also try to make it simple because we want researcher to contribute to it so I web portal as the front end and then through the RESTful API you can schedule a lot of these jobs which are the attack and defends computation that you want to run which are run on worker instances and currently installation is pretty easy one-click oops then you can run your yo check so won't go through no detail yeah so this is a screenshot of how the system will look like so each row here on your right is what we call a pipeline so as in if I want to try now tech techniques you create a pipeline you upload data you pick what you want to run each little box here is one of the operation you want to try and you can also see of course all the technical details that a research module what output and I am most right now we also want to teach you in classes and also have a more impact where what impact so now is also integrated into or being integrated into AI Intel Academy course so that's what some of the recent project on a secure AI so not like not just switchgear a little bit to the interpretable AI side so one thing about all these Chinese that have talked to you so far I show you some accuracy numbers right and I convince you even video contains to you that they working but then the dirty secret is that even for people working on them they have no idea why they work so they just okay numbers looks good it must be working but they cannot answer you which part of the model that they are attacking what's the extent was the footprint how do you stop it like when do you say you have protection was really protecting so that means for the interpretive array is really important you need to know how what's they're doing so that you can read it he really and for that I will give you a few example work out that recently we did our company like Facebook and Google and including also Microsoft as well right so how to how to make that hopefully these model more interpretable and so that we don't know what's going on so if you're talking to practitioners often you don't really need to convince them too much they are already because of that job they're already very interested in knowing how and why a I work and how do we do that as easy to say that you want to do but how do we do that and the general medium that we use is through scalable interactive visualized and we think the visual way is a very powerful method to achieve that and the reason that we can we would want to do it is that for machine learning is great at finding patterns from data but it's not very easy to digest and we're for visualization that is a very effective way to amplify humans connection sorry cognition so it's using our our very effective way of identifying patterns and now in the combination through interacting with the visualization then users can incrementally make sense of the AI so one common perception that people might have when we show visualizations what will you make a pretty picture and then that's it so not really so a visualization it's a medium and through interacting with the visualization the user can ask question so they see something and then they they want to ask about it and then there's showing some more so for the visualizations incremental is very important so we'll show you a few examples of how do we do that the very first one is work that we did with Facebook and helping their internal data scientists to understand their large-scale model and data set right so activates and was published in this 2017 this is a talk visualization conference and active business now deploy by Facebook on their machine learning platform right so the all the motivation come from data scientists at Facebook needs to visualize signature to interpret the context model so I agree that all of you now and make yourself so you probably have those kind of knees again whenever you look at machine learning model so you want to know wait when does it work what does it not work or doesn't work what's really happening so practical design challenges as you could also imagine thanks to industry is a lot of deep my models arch data set and also many feature many different kind of data set cover images text and so on and how activists activists started from a participatory design sessions with a number of researchers and engineers and data scientists I go quite a long term projects over eleven month and activist is a quick screenshot - oh yeah I can show you some video about how it works now after development so now it can visualize the industry scale model that used by Facebook so the number of challenges that activists aim to solve the first thing as I mentioned is that the many model parameters are large models large model so many new around so many layers and they're particularly interesting Network so so many of them what do we do about it right so the nice thing about talking to practitioner and through the observation we found that wall there are many of it but we don't really need to spend the energy on every single one of them so in particular we can find out which other ones that the practitioner is a researcher care more about and then just focus on those right so for example this is a front end user front end of activist and what we do is we still provide an overview of the full model like we call the model architect I can check your overview view and but then we allow you sort of zoom in through the tutor graph and then pick the one that they're really interested in and drill down to that right I said I click on it and then they can show that show the details at the bottom right so a very simple way but then that that's off the mat the important problem right so instead of overwhelming people with everything we give them an overview that's actually a pretty common design technique in a week of your interaction overview first right detail submit filter details on demand so we're using that here and the second challenge is about how they are interacting with these models and data so through talking to data scientists we also learned that well there are many different ways that they want to do the understanding and at the very high level we categorize those tasks we call instance level understanding in some subset level investigation instance level here we mean looking at individual instances so as in you're doing programming right so are you writing a model that's when you pass specific individual example through a data point through it and then look at how it works so as you imagine is very very helpful for debugging as in like unit test if you you would and that's one one very common way the other way and that the practitioner notice is that there are instance level is great you can get a very deep understanding but it's also not scalable this is why there's a subset level also very common which is more scalable as in doing a high-level categorization of the data so it could be that you're doing classification so that means your subset level would be at a class that for the whole class of image o class of Docs or classes can but then subset it could also be a smaller granularity as in you're looking at human data you may want to look at okay maybe people in southern country people circum level and so on so you can actually define this subset in different way so that means instance level and subset level is actually really covering a spectrum of analysis all the way down to individual examples and then all the way up to a super high level so Easter know as you may expect to be complimentary so data scientists researcher they really want to they really need to do both right so how do we support this and the activist user interface so at the bottom of the lower left corner of activist is we call the your activation view right so here each column is a neuron in this matrix as our H column yeah neuron and each row here we actually combining both things so we it could be instances like oh and also could be a class it's for example the first six those are classes high-level classes who are looking at text data right so so that means we had six category of of text you want to let's say these are Facebook feet so we want to classify them instead of feet about description is about entity about brief creation about number and so on so each role here is one class and the dot here is the neural activation string so that means what particular class that's say for a description so it is activating a new one number one six and so on and so on a lot so darker higher-level activation but it's not limited to just the the classes right so the roles doesn't need to be class it can be other thing - it could be user defined subset so again we're looking at text data so that means you can say why don't we pull together together all the text phrases that contain the word how right so that become one role or how about all the feet that container what how many that's another so that means the user or data scientist in in this gate can define a subset that interested in and again we can put them into the same matrix right and even better well no limiting ourselves on doing a subset we can even add individuals instances so on the right hand side that's the instance view where you can actually click some instances and that get added as the additional row to the matrix right so for example this particular sentence where it's Prince Edward Island right so that's 1994 and then you add it to there as well and the nice thing about it is really combining putting everything together much easier comparison for comparison and you can add a few more right yeah you can have instances you can subsist of that could be very high level icon sets or user defined instances and the nice thing about doing all those at the same time is that you can now change the sorting order of the column which are the neurons and it allow you very easily to Co so for some of the core classify instances how well does it match a particular class is meant to be classified work and for the one that misclassified now at the very bottom how would they change you just visually you can immediately see although it's the right one then match really well for the wrong one you can actually identify which are neuron that contributing to that missed classification so design wise here you'll see that we're not using any fancy thing it's more about a conceptual idea of how do we actually unify everything and combining them in an effective way during categorization and doing the right interaction to allow people to add everything in there and also providing the right sorting order so that that's what really aiming to do as in what we don't aim for it crazy things like a very fancy by sophisticated we actually want people maybe it very easily use it so the first thing challenges that I mentioned I don't have screenshot to show but I also want to mention is the buzz scalability like any industry and any company and scalability is very important actually it is under the first thing that the group discussed so how do I achieve scalability is through a number of techniques one definitely we leverage at Facebook computation platform to scale up the matrix consultation which is number three and also we do selected pre-computation so through talking to your Facebook scientists and also looking at their lock data we know which layers which neurons are more likely to get use so that means we can do selective pre-computation beforehand and also each data scientist might care about different things so that means for each user they can actually say oh I care more about this particular kind of data set and so that means we can do the user guided instance sampling as well so that again we can do it beforehand so they're in real time when they have all the model train this is the internal system phase FB learner and after they do the training if all the pre-computation done they can just do one click and the activists were launched so Facebook's machinery platform is used by over 25% of the engineer so now we make it really easy for them to try activists so something you might notice as an activist here we're focusing on a single model so it's not very easy to come compare multiple models but in practice we do want to compare models or even compare data set or comparing classes right so we'll have this system called summit that's going to appear in this 2019 that help people do the comparison more easily class comparison model comparison and also we allow people to dig deeper into the model as in well let's say I have other images from imagenet 1000 classes you know the prediction is white wolf how do you reach that conclusion in the network that the label is white group so particularly if you have a whole network there are many many layers many neurons how do we know what are the features right in the end we know why will why how do we reach that conclusion so submit is they take that tiny and also the system that generate this kind of graph representation to not only tell you hey this is the final prediction but also show you the paths and the specific neuron in this cake could be legs could be white fur could be point a year and all these connection and important neurons that contribute what to the final ones so in other words we're creating an attribution graph where you can attribute the final outcome to individual neurons and country connection so I show you very briefly a video of how a summit works so this is the user interface in this case I will show you a scenario where we use summit and attribution graph to discover very interesting or say kind of faulty but a scenario so so on the right-hand yes on the right hand side that is the attribution graph extracted for a class of images caught tench so tange is yellow fish so we know accuracy pretty high 92% but if we look at the features you will notice that's no fish there are people there's a lot of faces actually basis spaces each neurons so here showing some example pull from real data and the only after may be closer to the end and then start to see some fish right some scales some fish so that was surprising and still some people so actually maybe that thing to be a question for the audience any guess why there are people in a tange class one guess is because facebook data all the data is Facebook's I have people and great guess so it turned out that yes so it's tearing out the attention to kind of fish that you often will want to catch and the whole in your your arms and then kind of a trophy okay it's trying to most of it is that so that means what's really detecting very accurate accuracy right so an eighty percent is great it's really first detector faces the fingers your fingers okay then they're good then it's probably change so that's surprising right if that leads you to really think about okay so detection just looking at the accuracy not really sufficient you want to really know what's happening because data could change in the future you might get new data do not happy then musing under Brecht probably actually so so that was the quick example activists and also submit though that related to that and a lot of these models and often is that we are all these tools we build the tools and then they're already a in audience we're in data scientists but often before people we can pay the science of work in industry often they need to learn these things so I learned this model and often we cannot assume that they know about it but in practice actually learning this model may not be easy for example for a most recent some one of the most recent very popular kind of networking of as generative FSL and network one gang for shot short turned out to be very hard to learn and training even for expert so we built a tool called Gann lab in collaboration with Google Google AI at the pair group specifically based in Cambridge and to make that learning effort easier so in other words we want to help or use visualization interactive visualizing to help with education machine learning education right so they're actually quite a number of recent work on going indirect direction so quite a few including like tens intensive old playground and also other earlier work on visualizing in your own network but more than deep learnings are actually quite complex right so many layers many many components inside it and specifically for forgetting generative fs0 network the one that that your personal example like big faces that generated all like this Airbnb doesn't exist or something like that that realistic looking images but I actually think so this technique is very powerful wave was generating synthetic data for variety of users and also for improving a accuracy but very very hard to to understand and to Train even for expert so I'll show you some math we're not going through that math let's just show you yes some some equation there and now you need to turn all these equations in actual like the actual implementation and then CNN training putting in data and saw a lot more harder so why again so hard right besides there's some math there they're the reason it can be attributed to that is using two competing networks I will show you you see understand example first and before going in technical detail so mythical are using to newer network one we call it just generator and the other discriminator to produce the realistic looking data we call generator think of it as in the arrow where we want to make fake bills right so generator in gang would be like counterfeiter and the real world will try to make fake bills the whole goal is to make realistic looking bills well the discriminator component is kind of like a police you want to a spot the fake bills right so as you imagine in the beginning the counterfeit is not very good they generate some bill but that kind of doesn't look like real bill the police is is doing a great job in just angry shout okay this must be fake right and of course the police know the real thing so I have access to it or green want the real thing right so can tell a difference and counterfeit I get caught and now I improve ok ok well you you call me I'm gonna make the bill better so and then at the same time the police also updates out so I get knowing ok well so you're getting better I'm also getting better and so you can imagine that this process repeats every Pete and repeat so that means in the end a generator is able produces fake me so well that the police have trouble distinguishing between what is good life or not so at that time this gang can the training can stop so because now the generator can produce realistic output like by you so they only get like some of the data and a highly biased render the data that's correct so so they kind of gonna do some really actively probe then police in there say hey you didn't do this so that the police kind of like looking at whatever they have and also comprehending and kind of update the internal is actually up dating we call it decision boundaries or the more information they have but you're right yes yeah so this is very high level right so but now you can imagine we're not really talking about counterfeit or police but actually these are two neural networks so that training and also even from this for example you'll see there quite a few loops are quite a few connection and those are the interaction that actually come back so hard for people to understand so we show it show you shortly yes why is that thought so just conceptually we already know that well there is the kind of component interaction conception conceptual understanding of gang that might be tricky the other is the training right so iteratively we show already many iteration but internally actually each of the network the candid the kind of video generator of discriminating of the police so those are newer now extreme you train in the same at the same time and I thought one we want this tool if we're a success I want it to be accessible by anyone we don't want it to be a research tool that only a few people use it when it's easy to access easily accessible for anyone so how do we solve all these challenges so so grandpa back to our scenario right so you want to explain this now in a more technical way right so that is training looking at data how do we go about it so the very first thing you might imagine well okay so a component with some bills so that means we have the models we have the data so what kind of data do we visualize or help people understand understand this we consider a high dimension data in cell use and bills at higher dimension data we return out that that is not really the main problem it's more about whether you can successfully explain to people the distribution of data so in this case how well does the fake like the big data in purple match the real thing that's more important so that means we don't really need to go to high high dimensional our dimension as an image images so does high dimensional data even 2d will be sufficient so that we can focus more on the the main concept and at the same time also very easily visualized a distribution a 2d more than them so in version one of our to a gamete then we have the color coding set right to 0.1 and also we show the animation through training so the purple one you'll see that is eternally become better and better the real one is what the user want what you want to generate and that over many iteration then the real thing of the fake thing will look like the real thing so that it's really interesting to like during the iterations it looks like um I don't know much about these networks yeah yeah that there's an overall bias I can see it in each iteration like all the points to the left or right yeah so there there's some randomness also depend on initialization and also iteration there there also some some randomness involved as well so yeah so sometimes that actually training would fail so there for example is something called a moat collapse where it just for you completely and even Express don't know what went remote collapse happened so which is why it's so tricky yes but data this is for data path seems okay 2d 2d may be sufficient because a more important thing to explain in actually which is the second part about the the interaction but before that so I want to look at the individual component so what do we do about that so how do we explain the generator so generator as the component or the new network that I created the big bill some basic data so how is really happening in generator is that it takes some initial random usual is random it doesn't be random but usually people said it random and then a generator on a camera filter with manipulate it and then turn it into something that hopefully looks real so more technically you can think of it as giving an input initialization now you do kind of a mapping or Wapping and then change it into your target right so in other words you can pop it over a lay overlay a grid on top of your your input and then figure out how to each of this grid cell that manipulated with precision or stretch or scale to you to the output that's technically was really happening so that means a counterfeiter is actually I function I function that that get updated again and again and again with the goal of changing whatever initialization you have into what you desire which is fake but real and this that means we are really creating a meaningful so how do we show this we this is the time that we think animation is really helpful where we use the animation the warping in the middle that the user can selectively replay and play again so then you know how do a point in the original space get twist and and to the end so that's so this together forms the visualization for the generator counterfeiter and similarly you were in the thing to think about discriminator right the police the police is actually easier because police is kind of like classic classifier so you can use that he met in looking at looking at the distribution which often region likely will be classifier you which it would be would be fake right so now putting together like all these we know how to racial are real data big data as put poll we know how to be sure on a generator you know how to visualize discriminator has a heat map now I can overlay all of that into one composite visualization and I'm originally we thought okay that our job is done version 0.5 all done and they said well the only thing left you see it's newer network just add in some sliders and it's done right so new network change the number of layers you know this is two one five and the reason there's there's a reason why 0.5 because it's totally doesn't work to show even expert is that okay it's super confusing I have no idea what's looking at the main reason in the end is because people have this mental model in their head that we are totally not capturing so what we really want to say is the first slider correspond to changing something in the generator there are slight acquaintance to something changing the gen discriminator but there's no such visualization in 0.5 so that got us to add to well there's actually really important to actually capture the flow you want to have a landmark mental anchor in the head so they know okay what is really the internet generator doing was really a discriminator doing and then we showed a composite so the end this is what we're showing we have the data we have manipulation to generator you know something that looks for you and all these are updated so everything combine so we'll show you a video of how that works so in this case the user is a I I want to generate data that looks like a ring record listing so that becomes over one and you can set the parameters all the parameter interactively for all the network you can change the learning rate and everything and now it can start training so I press the training alright and now you can see the flow of the interaction you can see how everything can update it how the generator that can update it become better how the intermediate sample get updated become more realistic you can turn on and off all the layers look at all those and can hear this game play the animation of the manifold of the warping and for the understanding and really see how things get twisted and you can change the parameter on the fly so one thing about training gang you could ever use it the dirty secret is that it takes forever so that's why we play 15 times faster and after 2000 almost 3000 iteration now you get it so so in the end is pretty good so this is this is a big thing but look really real yes so that's an example of Kalin and typically when you are deploying this kind of interactive visualization tool you often have a gap back in in particularly when you talk to someone you want to visit to a visualization for deep learning they often were think about okay well we used a pretty beefy expensive backhand and the front end is something that you can run in browser you show you develop a script but then we think that that that's really a problem because that mix that means is much harder for people to use the tool so instead what we do is we leverage some pretty recent development and you can actually do in browser on laptop or on a device by computation using it the attentional Jay as the library which is essentially doing deep learning using javascript and that's accelerated by WebGL that means using your graphics card if you have one it doesn't use CPU and so that means now everything is in JavaScript well of course that also means now everything can just run in your library and actually again I was very not dangerous so you can just try it on your browser you can Google or Bing I should say again lab and then that should come out the first result yeah so fortunately also went viral so when we release it they've had some many many like two thousand likes and that was 800 retweets so really really exciting project so I think I'm going to wrap up with some of the high level thinking about like for the interpreter and also for security I like so we'll show you some examples so far about where where we are and so where we want to go right so and if you're interested in visual analytics or visualization particularly for deep learning and you've ever be working more under machinery inside so how do you recommend a pretty recent survey that we did with the I think this is a great surface the community is a looking at what human community in the action and also visualizing research can do to help people advance these AI research and the reason I thing is it's like of course I'm selling to you but I think it's really nice and nicely written survey is that it has done a lot of work for you and particularly is summarized a lot of the recent a visualization research using these like five wnh kind of categories so example each paper will tell you died why they're doing visual I said why they are doing the explanation like what is really explaining so you can get potentially many many things you can explain like when they my doing this visual I say explanation who are they doing for like we in there for ideas for model user experts domains users developers how they are doing it what is it technique so all these and also I summarize some of the the key category authors they take away from analyzing all those like 1516 papers and currently a lot of the tools aim for experts and so a similar domain knowledge but at the same time they think more and more that their user who might be students who might be beginners I want to get in feel they want they're using these technique but they want to gain deeper insight so we think that it would be really helpful to have tools that design more for for beginners and novices often due to ease of design of a lot of tools are instance base and now instance you may remember that means looking at individual example it's great easy to design but and access expression for industry often we're analyzing things as scale so that means we would like to see more work they're focusing on scalability one very nice thing observation we have is that the communities are really working together so now we are machining people working visualization and we just hope that that will continue and we believe it will continue number four is this think we need a lot more work is the lack current lack of action ability that means we're building a lot of tools that help service some of the problems and that people may be seeing from their data and model but then we don't really tell people how to fix them so that means it will be even better and I'm not only saying hey you said the problem but also say here's a solution want to sweet then we want to try and a first thing kind of is really hard to get away with this evaluation in practice very hard to evaluate a visualization tool main reason is because you need to find all the user find the right data find a right task but it's important so we see more comment yes important so we there do more of it the Mystics are current time back to our secure a I focus is that a lot of these tools currently not focusing so much on helping people understand from the ability of I and we think that's a big meat and because of this model are not robust and we hope that there's some focus that people would have we want to develop so lastly I want to point everyone to work coming out from Microsoft me and also I'm a I'm a student if I hold my who in turn here last summer and I working with rich and Robin Steven and MSR is to they look at a very important problem and actually I would say we don't really have a full understanding of its what do data scientists really mean by interpretability so I've been talking the whole talk interpretability if you talk to different people that give you different answers you better watch community here right I call you all we're visualizing my explaining the internal we're looking at the map we may be looking at input output mapping maybe you're looking at representation visualize actually that's not really a Korea point definition so what the team is doing I build a system called gamete you some of you have seen it already in demo its how to build this tool through the tool to figure out what data scientists really need for when they say they want to interpret something so that means the to itself is not with the angle but using the tool they want to use it as a design probe to understand interpret ability so that was what they're doing and there's a lot of very interesting discovery and particularly they use a scenario where let's say using that tool and suppose these are the problems that their scientists would like to address so how do they translate these kind of questions into interpretation and capability so for example if someone is asking looking at housing data here they say why does this house cause this certain amount money what what are they really we're looking at they actually looking at local instance explanation or let's say they are interesting asking what is right so that's actually the counterfactual that they want to do or if they are really trying they're asking how do we find similar homes prize similarly what they're really looking for the kind of interpretation task they have is actually looking at the nearest neighbor know what what is similar other things right so these are the kind of capabilities are actually the other science that gaming for so what that really means is take away and is interpretability often people talk about it and know well define and is actually natural and I don't I'm not sure who really want to really force it into a one box very rigid things is not really rigid concept and interpretability it's more like a collection of things that you want to consider and often when people say they want to interact or interpreting things is really not depending on the audience so depending on if you're a domain user you may want to know a lot more information but then you don't want to know the technical details and the last part I want to emphasize is the interpretation often people think of it as oh I'm going to show you some visual aesthetic visual or later text and then my job is stuff so through this research with Microsoft research colleague is that they're now interaction is the key so actually you can almost impossible to to really do interpretation without intact interactivity the main reason is because during interpretation inherently is hand kind of question and answering you see some result you need to probe further and how do you prefer there if you're ecstatic just like on a piece of paper you can ask those questions so through interaction that allow the user to ask those questions right realizing interpret ability and also understanding so that means you remember someone ever they from now on you can say okay so we're interpretability explanation the first thing you want to ask them do you support interactive Jay do you support question the answering right so or are you just showing me to the result and desert so that was work that just published at the PI 2019 really really great and I look forward to more collaboration with that and Microsoft colleague so I'm gonna wrap up it's like the overrun and or not overrun I want to know I'm not going okay I'm good on time so I'll talk about two category of a research that we have been working on and I secured AI and also interpret of it yeah so it's not to see some connection between them we're doing a lot more and starting this semester for example the summit tool that you you've seen creating an attribution graph to can really dig deeper into the techniques and that's what we plan to do to apply to an all these many many attack and defense Chinese so that we really know when someone say I have attack technique I have a defense method what is it really protecting is it protecting particularly a particular component of the your network or not really doing anything right so so that is very the connection that we have that was why I say tor secure interpretable yeah and a lot more work to do and I think we have some good foundation and look forward to all the things that we do and also collaboration that we have with Microsoft Holly yeah thank you you had you talked about these these physical attacks on AI system we're like it printed this stop sign that's the background is slightly wonky but to all of us it's obviously that fine and then you talked about these defenses for what what seemed like more of the digital attacks have you tried applying them so the physical is high right so if I take the pictures you took that are physical attack which then I apply these compression defensive these compression defenses what a great question very much for their pressure was whether we tried out defense as a shield defense compression based on the physical texture so to attack there we actually did and the compression is small compression it doesn't work it could not overcome their the the attack the reason is they as you saw in the shape shorter one is actually pretty conspicuous the overall semantically you will say that this that is still still like a stop sign hasn't this one and but then those perturbation is strong enough that compression alone cannot overcome and so which is why for the briefly I mentioned for the the dropper project which we yeah we're in negotiation so we hopefully will work on it it that programs purely based on defense or focus on defense for for this kind of attack where we will need to explore more than compression so one idea that we have is to look at how to incorporate or they add in what what humans would take for granted as in we have the sense of the temporal consistency as in if if you're showing a video showing video driving towards it you will not expect that the human being wouldn't expect one frame is a stop sign that an explained is the person the next frame is a bird so so that kind of can broken then for example this would not make sense now why would you order that and have a lot of people like kind of floating in the air so we want to add in some of these into the defense but to answer your question that compression the compression alone is not sufficient to overcome that yeah so in practice we do expect usually combination we will certainly keep in mind for compression as well because internal compression often it actually helps increase the act model accuracy to because our model currently they're not trained on any compress images yeah sorry yes okay this is sort of related to this topic so if you don't mind so I'm a previous life I did a lot of study biography and stegun Alice's work so this is hidden information images since you know idea as well and I feel like there's a lot of similarities here that is a electrical engineering perspective you know what I'm thinking about it because the compression at least JPEG standard JPEG compression is about cutting off the high frequency DCT compartments but where the research was going steganography was that more effective steganography efforts or algorithms compressed FET spread-spectrum embedding surveil del in bed across low medium and high frequencies instead of just wearing out the high frequencies and then inspired by this question and it seems like the physical thing that you generated actually has a lot of low frequency information and therefore your compression algorithm didn't defeat it because it's only eliminating a high frequency stuff and so I know finally the question is have you thought about spread spectrum sort of adversarial defense I yeah so so there they one example I related it that is their audience many I've seen is there's an image as a composite image if you look really closely is I think Einstein if you pull it really far away pick a Marilyn Monroe so that's using the low frequency and high frequency kind of thing so so yes certainly that that's in online that I think the tricky point kind of going into why we do interpretation is because actually right now we don't know why it's during the detection only okay it looks like low frequency but low frequency is exactly how detected how in the model we don't No so but but yes so we do want to look at the kind of frequency spectrum and also throwing other other things to for example here the human beings you can say oh there's a shape and then there's a text right so a lot of times for this model they don't even consider that it's just okay so end to end so in the image sometime yes so yeah so that those are kind of like a semantic meaning and also like a good that a lower frequency the component in its own so yes it's working they want to do it so we don't we don't know how yep yes so like a lot of times the mole collapse happens it just never craters but like I don't know if there's any like a visual interpretation front like why sir why not what happened I don't know from about where you guys did you guys try to explain if certain things oh yeah great question so we do see that what that is happening interface but we did not did not that we didn't we still don't know how to explain because even when we were creating his heart because of randomness I mean unless we accept have exactly the same setting like currently no we don't we don't know how we don't know how to explain yeah we talked to some experience on that and will collapse and one one use that they have oh yeah this is great so I can I can visualize that kind of progress at least at least for that particular setting initialization I know vocalist is going to happen but it's very hard to how to yes still it's so hard to know what are the four sequence of actions that lead to it yeah so here there's no way we don't know yeah yeah you could use less you can use these left for that other has higher level dimensions right so how are you projecting do they mention is here yeah so actually currently again a support up to two to two dimension so it doesn't go higher you can do 1 G 2 pi we then and go to 2d the deliberate reason for doing intentionally reason for doing that is is that because for two DS actually already hard enough instead for understanding so we want to just keep it simpler so if you want to use for high dimension you do need to project it down first dimensional reduction down to 2d and certainly will be a lot of information loss but that's possible I want you to turn in 2d you can you can you can use it message truck regarding the interpreter but letting you know tools that you've created and specifically the one for Facebook you mentioned that it's mostly for model developers to understand their models but then what about communicating those models for example with product or project managers or UX designers are these kind of visualizations or results helpful to communicate models or is it only for advanced users like model developers great questions yeah for activists also it is as many femoral developers and engineers if you would and so for communication I think this might be too complex like too many moving parts so some are certainly helpful for the for the multiple developer because for example here they would want to see all the individual instances while for for communication maybe you don't know or maybe you do but definitely not that many so activists currently is is not not for that when I would imagine if you want to be a more communication tool than it need to be significantly simplify and so to be much more focused so to be more distilled from from this visualization but we're currently active as doesn't support that any attempts in the research community to target those kind of audience as it goes to model developers oh yeah yesterday I'm even here at Microsoft users like Salima mercy for example I met with yeah and yes and also Steven Drucker which also have collab that that's that the mentor of my students and so they have a lot of human Center a eye effort and I think now they're focusing a lot on the other end user and also as I understand it says they also during providing advice to like at your product groups on on how to how to like through their introducer interface I do so all more of these explanations and communication yeah so so so yeah I think that's great work coming coming out and and I read a lot of them and but you notice a lot of the tools I would develop currently as more gear to worth like maybe oh and it's an expert expert but at least like who will know about familiar with some of the techniques but we do want to bring it or to have more of the this tool available to to novice at for example thanks for again laughs that's the direction that we go to where it's very accessible into a clump layer that it's great for students it's already using some classes and so there's very very low barrier entry yeah so I imagine that that would be the kind of direction Oh what's my favorite JavaScript toolkit I always think javascript is an unfortunate coincidences that happened before which I think it's true actually it's true and and but then now of course I'm all my students are doing Python and JavaScript so and yeah so so we do use a lot of d3 for the visualization because it's programming so you can do whatever you want we do use a tester so yes a lot recently whenever we did more scalable using GPU way to do to that and then there's also them a library and a couple more framework will react how will you do it and partially because of Facebook that's why we got started and I went to work at Google they have their own similar things so yeah so those are their common ones that were used Oh Open Sesame a yeah so they all of these are open so except activists and yeah so activists because it's on Facebook but like some medicine so a shifter yeah Oh actually you might go over to my mouse query thank you for all your contributions that's really helpful for the rest of it yeah we're lectures also all the for here and open source here everything except activists even now surveys open so so you want to add more papers to it yes you can yes [Music] okay thank you [Applause] 