 Good morning everyone! I hope you're all doing well in these trying times. In 2017 Nvidia invented a GAN called the progressively growing GAN. Like the name might suggest during the training of this GAN, the architecture progressively grows to produce larger and larger images. It may start producing images which are 8 by 8 then progressively scale up its output to eventually produce HD images. The reason for progressive growing is to increase stability in the GAN by starting with the simple task of producing 8 by 8 images then slowly scaling up to more complex tasks like HD images, the GAN can learn in a much more stable environment. This prevents the GAN from collapsing. The original StyleGAN also used this progressive growing technique StyleGAN 2 however aims to replace this growth with something more effective. This is what I'll be going through in this video. Let's begin by talking about progressive growing. Like I said before during training the GAN starts off producing 8 by 8 images but grows until it produces HD images. The biggest concern with this is how should we transition between producing one resolution of images and the next. Let's look at an example going from 8 by 8 to 16 by 16. Here both the 8 by 8 block and 16 by 16 block produce RGB outputs. The output of the 8 by 8 block goes both to an RGB image and as input to the 16 by 16 block. To transition we would decrease the weight of the 8 by 8 RGB image while simultaneously increasing the weight of the 16 by 16 RGB image. Eventually our output is 16 by 16 where before it was 8 by 8. In our generator architecture we can continue doing this, scaling the output up until we reach our desired size. It's important to note that each To RGB layer here maps from the respective number of channels to just 3 channels using a 1 by 1 convolution layer. The discriminator works in a similar way it first receives an 8 by 8 RGB image as input. The from RGB layer maps from three channels to the desired number of channels using a one by one convolution layer. Then the weight of that input is lowered while the sixteen by sixteen convolution block is faded in. This is done in sync with the generator. While progressive growing does fulfill its goal of stabilizing training it can be detrimental in other ways. In this video we see what the authors of StyleGAN 2 called phase artifacts. When a face moves from the left to the right some features like the teeth or eyes remain in the same place. This wouldn't happen in real human faces. The authors of StyleGAN 2 attributed these artifacts to the growing in StyleGAN and thus set out to find a replacement for it. They tried various techniques attempting to replace growth, having 9 combinations in total. However in this video I'll only talk about the techniques which were using the official StyleGAN 2 model. In the StyleGAN 2 generator they use skip connections instead of growth. This is similar to growth in that each convolution blocks output can be both the inputs to the next block and map to an RGB image. However instead of fading one out while fading in the next, all RGB outputs from all layers are added up to reach the final image. This has a similar effect to growth as at the beginning of training the generator can choose to output larger values from its 8 by 8 RGB layer, meaning it's 8 by 8 layer will have more influence on the final image. As training goes on and more detail is to be added the influence of larger resolutions can be increased. The Discriminator in StyleGAN 2 replaces growth with residual blocks. The residual block allows for the image information to skip over some blocks. By doing this the discriminator can choose to skip some image information downwards towards the lower resolutions. As training goes on more and more information can be processed at higher resolutions utilizing less skipped connections. A residual block adds up two representations. The first is the output from the convolution block. This image representation may have a different number of channels than the skip connection so the Skip connection uses a one by one convolution to map to having the correct number of channels. I'll leave you with this. This is a graph of the relative influence of each of the image resolutions throughout the training of StyleGAN 2. As you can see near the beginning of training many of the lower resolutions had more influence on the final image, meaning the outputs looked like a small 8 by 8 or 16 by 16 image. By the end of training nearly half of the influence was coming from the 1024 by 1024 layer. Thus the new techniques to replace growth did what they were intended to do while also fixing the phase artifacts as you can see here. Thanks for watching this video. If you enjoyed feel free to leave a like, if you didn't feel free to comment. Stay safe and wash your hands. Thanks! 