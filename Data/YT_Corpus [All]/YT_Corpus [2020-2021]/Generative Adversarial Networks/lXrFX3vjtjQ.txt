 [Music] so let's start module the next module where we will talk about what is a latent variable how many of you have had exposure to latent variables in some course or something before okay okay a few very few okay so let's see so earlier what we said is that the neighboring pixels in an image are actually dependent on each other that's what our mark of network was and we kept the definition of neighborhood to be vague whether it's just the left right or top bottom or diagonal or even two rows and two columns heads that's all up to us to decide what kind of neighborhood we want to choose okay so why is it so why do we say that the neighbors of a pixel are dependent on each other because we expect the color texture etc to be the same for the neighboring pixels that's the idea so let us probe this intuition a bit more and try to get some reasoning into why this actually happens right so we'll take an example that suppose we ask a friend to send us a good wallpaper and he or she thinks that things about it and then sends us this wallpaper okay this image so why are the pixels in the top portion of the image blue why can you think on the friends perspective because he or she thought that would be good to send us images which contain a sky as opposed to mountains or green fields or maybe various other possibilities right why is the sky blue and not black because he or she thought that it's good to send an image of daytime as opposed to nighttime okay okay fine then why is it not cloudy I mean it's a bit cloudy but not why not completely gray or when you can't even see any of the blue color why not that way it's fine to send images of sky it's fine if you want to send daytime images but why not cloudy well again he or she made this decision that I want to depict a sunny day and a clear sky as opposed to a cloudy sky or something right are these decisions known to us what do we observe just them right but these are some inner end decisions that the friend would have actually taken right that I want to send and these decisions could differ and we will there could be a very different explanation for why this image was sent to us but there was some underlying decision which led to this image and we don't have access to that decision we just see this image and what we observe is just the pixels we don't have access to this underlying decisions that were taken and I think all of us agree that there was some underlying decision which was taken and decision could be as simple as randomly pick out an image that could also have been there where there was some decision which led to this image being generated right so that's what that's the idea that I'm trying to emphasize all right you only observe the images and these decisions are hidden from us we do not really observe them so what exactly are you trying to say here so we are saying that there are certain underlying characteristics which not only determine the pixels but they also determine the interactions between the pixels right so now suppose instead of this a clear sky if a friend had decided to send us that image of Taj Mahal which we had seen in some of the earlier lectures right then the sky was not so visible that the Taj male was covering most of the sky right so the background was very little in that case so in that case the interactions between the pixels would have been different the dome would have interacted with each other it wouldn't have interacted with the sky yet so all right so these latent decisions actually determine how these pixels are going to interact with each other right and what we could do is we could think of these additional these latent decisions right as additional random variables in our joint distribution so what do I mean by that is that someone decided that of the two possibilities sunny or cloudy I would set the value to sunny it was a random decision right someone decided that instead of daytime versus nighttime I would pick it as daytime is the same as high-low high-low kind of examples that we are doing right again someone decided that the color should be of certain type and so on right so these are additional random variables on which certain decisions were taken then we saw these observed images which again contained random variable sorry because I have decided I want to plot a sunny image but still there are several ways and I could which I could have arranged the pixels to get a sunny image rate I could have not just a sky I could have a sky with something in the foreground and so on right so these in despite taking these decisions there's still a randomness in what you will observe and you could see different images of say sunny sky with green fields and so on it there could be so many images of this particular description okay so these are these are latent because we do not observe them what we observe is only their effect which is in turns but in terms of the pixels that we actually see or the images that we actually see right so more formally what we have now is earlier we just had these observed variables which were V we have been calling it X but now I'll just change it to VN hv4 visible and H for it right so we had these observed variables 1 2 1 0 2 4 because it was a 32% eetu image and now in addition we are seeing that there are some hidden variables H 1 to H M ok now can you think of a Markov network to represent the Joint Distribution P of V comma H first of all is this question valid can I ask you to think of a Markov network yes right because this is irrespective of whether I call it V comma H or just collectively call it all of them as X all we have at an abstract level is a bunch of random variables and I am interested in learning their Joint Distribution right and since this was images and we have already made a case that a name in the case of images there are no directions it's just the affinity or the interactions so that's why I am asking for a Markov network as compared to a Bayesian network that's again a modeling choice which I have made I've assumed that these are not the pixel interactions are not dependent on each other in the sensor there's no direction there they're just interactions ok so this is a valid question now can you think of a Joint Distribution for this and what I'm asking for you is think of a factorization all first let's think about the graph if H was not there and what was your graph if H was not there what was the graph all the neighborhood in pixels depending on each other right so this is the graph that we had right and again the neighborhood is a bit vague we can define it the way I want and Here I am considering the diagonal neighbors also okay now since that you have H and I was trying to make a case that these pixels are what they are because someone decided or made some decisions on these latent variables right now convert that first to a probabilistic argument that what does what depends on what and once you convert that then tell me what the diagram would be or what the graph would be how many if you get the set up like what how many forget the question that I'm asking you isn't that a bit over specified you said something plus something right or both those things required think in terms of parents or Markov blankets or things like that right think of it this way if the first two pixels are blue and I know there was some latent variable which was sky or sunny do I need to make these two pixels dependent on each other given the latent variable so he said that your clicks would be that's one way of answering this question the clicks would be these nine pixels that you see here and in addition you'll also have all of these nine pixels connected to the hidden variables that's what you meant right and I asked him that isn't this over specified you said that it's click plus something do you need both these terms and then I sort of gave a hint or I just made a statement so now concerning all of this tell me what the mark of network would be so he said bipartite graph what are the two partitions I'd say me that's easy to answer so what would you have now given that's the answer can you reconcile with everything that we have discussed does that make sense that what does it mean for since it's a bipartite graph what does it mean and you said the two partitions are H and B so do you have connections between the vs so do you have the cliques that is you see here no we have connections between the edges no so what are the connections that you have visa Neches so some matches connect to some V's or all edges connect to all V's or what's the Assumption all edges connect to always right even if you look at the example which we were discussing the toy example where there were only three latent variables it was sky sunny and daytime every pixel depends on all these three values right if I change any one of these the pixel will have to change right so in that case it has to be a fully connected yes so then you could think of additional random variables there could be one random variables which says that how many clouds are there and what's the size of each clouds big or smaller so this is a bit vague at this point because see again and I'm going to come back to that point there is a reason why we call this as hidden variables because we are not going to observe them in practice right these were decisions taken by our friend and I'm going to make the assumption that you can't even asked her friend right so that we will never know what these decisions were this is only for the purpose of explanation and later on I will come back and say that okay all this cloudy sunny and all was just for explanation in practice we don't really know what these hidden representations were and I'll also make a case that something like this we've already argued in the course before that we don't know what these hidden representations okay so then probably the story would become clear okay but that's a fair doubt and ask me again if it's not clear after the tendon slide-in extends later so okay so this is what remark of network would look like of course from some pixels I have not drawn the edges it would just become too complicated but just imagine that all these edges are also there right so every visible pixel is essentially connected to every hidden pixel so that's the correct answer it's a bipartite graph and the reasoning is that once you know the hidden variables that completely determines the interactions between the neighboring pixels so you don't need to capture them again so I mean just try to visualize is the way you are comfortable either in terms of a Bayesian network we are given the parents you are independent of the siblings are independent of each other or in terms of a Markov network we are given the Markov blanket which is all these hidden variables you are independent of all the other visible pixels in either reasoning it should be clear that the visible pixels are independent of each other how many of you get this okay and this is the intuition that we are trying to build on the previous slide that these are some decisions which have been taken by someone it doesn't matter that we don't have access to these decisions it does not matter that we don't know what these decisions are or we don't even know the definition of these random variables right I don't know whether the first random variable is actually sunny or May Day or cheerful or happy or what I don't know these it's just that there are some latent variables and my final observations are based on these latent variables okay so let us probe this idea a bit more and we will try to talk about this idea in terms of two concepts one is abstraction and the other is generation so let's see what that means first let us talk about abstraction the suppose we have learnt the Joint Distribution P of V comma H okay and this should be obvious that given this Joint Distribution I can compute this P of H given V in particular I could compute for a given V I could compute the hidden state which maximizes the probability of P of H given area what's the English way of saying that in terms of the decisions made by a friend right given an image I can actually assume that the Joint Distribution is given to go right so if I can compute the Arg max of P of H given V what am I actually computing the most likely hidden decisions which the friend had made to give us this visible observation right okay so here as I said that most likely decisions that were taken and at this point I'm keeping all the computational problems aside right whether this Joint Distribution struck table and all those things I am keeping aside I am just assuming someone has given to you and you have infinite compute power to compute this then this is what it means so what does H capture now try to relate it to other things that you have done in this course what does it capture H should give it away right what does H capture it captures some abstract representation of the image right fine and still there are some things missing here but we get there it captures an abstraction of the image now under this abstraction what would happen to images okay so let me ask you this so this abstraction is capturing the important properties of the image right so what do you expect to happen to images which look very similar the abstract representation would be very similar to each other right so for example right if you were to describe this image to someone you wouldn't see say that I am looking at image whose pixel one is blue pixel two is blue all the way up to pixel 1 0 2 4 is beige this is not how you are going to describe it how are you going to describe this image I can see everyone imagining and dreaming and so on but yeah let's assume that you're not going to get there anytime soon but still describe it it's a sunny beach with an ocean I don't know why it's an ocean but in the background and beach sand right instead of white sand that's an abstract representation of this image that's how you would abstractly describe this image the 1 0 to 4 pixels are too dense right that's a very over specified description of the image you're not interested in that I just insist interested in this abstract representation and this is the kind of abstraction which we expect edge to capture ok again I am building this up saying that it will capture all this and then I'm going to play it down later on but I'll do justice to it when I play it down it I will relate it to something that you have already seen ok and now under this abstraction what would happen to all these similar looking images they will all have a very similar representation on a poor pixel basis are these images similar to each other they're very different orientations of the beach and like they are different even let's not just get them they're just different right now in the per pixel basis if I take the squared difference between them they would be different but under this abstract representation what do you think they are they are very similar and we are always interested in these abstract representations because that captures the important properties of the image that we are interested in or the data that we are interested in have you done something like this before the correct answer is throughout this course right I mean deep learning is deep representation learning right the right term is deep representation learning so we did this in auto-encoders we did is a multi-layer perceptrons site we said that every layer captures a different abstraction of the image we did this in convolutional neural networks where every layer of the convolution your network captures a different abstraction of the image right and so now let's this very similar to the idea behind PCA also right now that is where now I'm going to play it down a bit so we still need to figure out a way of computing this P of H given B right we still need to find out that if I give you an observed image how do you compute the arc max H which is the most likely hidden configuration which generated this image which is the same as saying and what's the most likely hidden representation for this image in the case of PCA this boiled down to learning the eigenvectors of X transpose X in the case of auto-encoders where you again learn this abstract representation what did it boil down to what was the learning that you did there what did you learn there nothing these sudden blackouts are completely inexplicable what did you learn in order in collision hidden representation but what so in the case of PCA you learn the eigenvectors of X transpose X in the case of auto-encoders what do you learn the parameters of the network the parameters of the encoder and decoder come on aw encoder and W decoder and we still but now the analogy here would be what do we need to learn here in this case the - of the joint distribution the parameters are the factors of the Joint Distribution and we have still not seen that we are far from it but we'll get there eventually once we know that we have the answer to the first bullet we can compute P of a and that is again the motivation for learning a joint distribution because once you have the joint distribution everything else can be done from that right all sorts of questions that you want to ask about those set of random variables you can compute from the joint distribution right so we are still not seeing how to learn that but there's an analogy you have seen it in PCA you have seen it in Auto encoders and we will see it soon or in a few lectures before this course ends how to learn this joint distribution okay I'm going to drag this a bit more so in practice we have no clue what these random variables are what these latent variables are as I said you're not talking to your friend you're not really asking him or her what was the decisions which led to this particular image right and in fact there could be many explanations for that but this is not something new this is exactly what we saw in PC also in the case of PCA the original dimensions of the data had some meaning that the first dimension is weight the second dimension is hide the third dimension is salary and income tax and all those things but once you transform the data into a new space those dimensions had no meaning right you cannot say that the first time mention corresponds to a certain thing or the second dimension corresponds you cannot attach labels to these dimensions all you know that these are dimensions which are independent of each other and they have a high variance along these dimensions those were the richness that you had for PCA the same thing is true for even auto-encoders when you learn an abstract representation for the auto-encoder your original data hide certain semantics but once you get the hidden representation you just know that it's a hundred dimensional representation you don't really know what each of these hundred dimensions are there and the same thing applies here you don't really know what these latent variables are you just know that there are some latent variables just as in those two cases you knew that there is a certain hidden representation which is able to represent my data better even in this case you know that there's a latent representation which actually gives them more succinct representation of the image but you don't really know what are the semantics of this latent variable so all you know that maybe all images come from a hundred dimensional space instead of a one zero to four dimensional space once I have this 100 dimensional values I can capture everything that is there in the image and that was the idea behind pca that was the idea behind auto-encoders and that's the behind this particular structure this latent variable is capturing the essential semantics of the image right even though we can't really identify what these variables okay so this is not something new to this this is what we have been dealing with throughout the course okay only for illustration purpose I've been saying that this is sunny this is cloudy and so on but that just for explanation none of these variables have any meaning okay that fine and actually it does not even matter it because it could have happened that even though our friend did not tell us his or her decisions he could have thought of something very different maybe the image was of a beach or sunny or so on because they wanted to convey something which is cheerful or romantic or something else so these dimensions could have taken some very very different values and what we thought they are but it doesn't matter as long as there are some latent variables such that under this latent space similar images become similar or have a very similar representation then we are fine with that we don't really need to actually define these latent variables I know I'm repeating myself it's very important that you understand this concept you can't say things about visible variables that this is pixel one this is pixel two and so on you can't make these arguments about hidden variables you can just say that there's a latent space which captures the semantics of the data okay and again I emphasize is not something new which I am just throwing up at you this is what has been a dream theme throughout the course whether in auto-encoders all convolutional neural networks or any kind of multi-layer perceptrons right okay so how do we learn this so what is the question that I'm asking how do you learn this right so I'm going to keep track of all these questions which I'm going to say that we'll get there eventually and all these questions would essentially be saying the same thing that how do we learn this Joint Distribution H comma V I'll keep asking these questions and I will say that we look at it eventually you will find that there are many questions which I am saying which we will see eventually but this all boils down to one single question which is how do we learn this to end distribution so you already saw one question when I say that we are far from learning it and that was how do we learn this Joint Distribution this again when I'm asking how do you get the hidden representation again boils down to how do you learn the Joint Distribution and once you have the Joint Distribution inference is straightforward now this was about abstraction now let us talk about another concept related to latent variables which is generation okay once again assume that we are able to learn the Joint Distribution P of V comma H now from this distribution I can find the following thing I can find R max V given H now in English what is the question that I'm asking here given a hidden representation generate a image which are there as to this why is this interesting just think about this for a minute I'll give you a few hints here a large amount of data and let's say all this data what about scenic pictures right and mainly say skies and oceans and green fields and so on from this data you have been able to learn P of H given B right that means for a given image what was the abstract representation that led to that image okay from this data you have been if I give you any image you can give me a chat the vector H for that image now I'm asking you the reverse question that you can also do this you can also do P of V given H now given that you can do this I want you to be creative enough to give me a good use case for this yeah that's probably okay but I ask you to be a bit creative reconstruct from a distorted image yeah that's fair for some other other ML problem no I mean I've given that skies and beaches and so on now my other ML problem is I want to classify cats and dogs the hottest problem how would I do that from here so suppose this image which is not visible right you have done training everything is or somehow you have figured out how to learn this Joint Distribution now you can actually compute an H for this image right wouldn't you be interested in knowing that if I perturb this H a bit what kind of an image you like it you want to generate this is a image of a sunny beach say you want to generate other images of sunny beaches you take the hidden representation of a sunny beach just perturb it a bit and see if you get a different kind of a sunny ways does that make sense does that make sense how well you can do it depends on how much data you have how effective your learning was whether you actually learnt the parameter as well let's say you can't give me 100 images of sunny beaches and say that okay now I'm going to go and generate thousand more that won't happen right I don't even know what's the right number right it's 100 or a million or 10 million or 100 million I don't know but asymptotically right if you had enough data can you actually do that right that's what people are interested and that's one of the pipes around AI right so this creative AI that can you create and now I can extend this to many things right suppose I learn a joint distribution of poetry's right now you can imagine hidden variables for poetry's also right it could be tragic romantic or it could be about nature philosophy or so on and whatnot right now given a lot of poetry's if I can learn a Joint Distribution between these hidden variables and poetry's now take some poem get the hidden representation of that poem and now trying to generate other poems which look like that they're all still slightly science fiction is it's not that this has been solved and people are doing this very very well but people are doing it to a certain extent which is appreciated right so it's not that it's been solved but at least there is a scope for being creative by doing these things once you'd learn a joint distribution so essentially we're trying to learn how do people create images or how two cameras click images and so on and now given these things can I create more images can I create more text and so on it's so that's the one of the goals which are being pursued right now okay so that's the overall context of why you need this generative model lights or generative model actually tells you how was the data generated so that if needed you can generate more data of that right so that's the overall bigger picture that you have here so this is what I can say now right create an image which is cloudy has a beach and depicts daytime this is in English in the vectorial sense I would say that take the Sidon representation and give me another image which could have generated from this hidden representation or computer identification from a certain image perturb it a bit so that may be cloudy becomes slightly cloudy or more cloudy less cloudy or something like that and then generate new images from even without actually knowing what these hidden variables are can you still do this yes you can right because you have the visible image this is the hidden representation for that all I'm asking is to generate more stuff which are these two this hidden representation right without actually knowing the semantics of a certain resolution avyon gets this evidences idea that you don't need to really know the semantics of the hidden representations please raise your hands if you do that okay so this is what I would give it I'll give it a vector not the text description I would give this vector to it and I will ask it to generate so again we'll come back to this later it's again the same question once we answer what we can do with P of V comma H how we learn this all these questions will be answered you can keep a tree track of these things which I'm saying we will do later if you want if I forget something let me know but I'm pretty sure we will cover everything so okay so the story so far has been that we have tried to understand the intuition behind latent variables and how they could potentially allow us to do both abstraction and generation right and both these are interesting concept abstraction we have been doing throughout the course and we have kind of convinced ourselves that it could give us better representations for the data which could eventually lead to better predictions on that data right that's one thing and we will now try to concretize these intuitions by developing some equations or models which allow us to capture all these things and the corresponding learning algorithms but whenever we introduce equations what are we going to introduce parameters and then once you introduce parameters we need certain learning algorithms to learn right and of course this is a course on deep learning you have to tie all of this back to neural networks right we have just completely deviated from that just talking about random variables I will stop this randomness and get back to deep learning right okay so for the remainder of this discussion we'll assume that all our random variables or the visible variables take on boolean values right so V is a vector from 0 to 1 raise to N and similarly all our hidden variables also take on boolean values again it's 0 to 1 extreme so we have invisible variables instead of this one zero to four that I've been talking about and M hidden variables for the remainder of this description right and at some point I'll also say that X I'll use X to denote V comma H together right so when I want to refer to them collectively I'll just call them X so X is again a vector of random elements [Music] you 