 we had a tweet recently suggesting we do  a video on aloha net which i think we've   had brief discussions about before but it's  some really early form of kind of um network   is it was it something to do with hawaii i  mean you know you're the hawaiian shirt guy   yeah so um yeah no aloha is probably the sort of  grandfather of pretty much all networks that we   use today i think it was 68 the norman abramson  started to work on this technology along with   others and the technology that was used has  influenced ethernet it's influenced gprs   satellite communication is still in use today  in various forms so it was based in hawaii he   was at the university of hawaii and they had a  big expensive ibm mainframe that they wanted to   provide access to but because hawaii is a  series of islands they couldn't just run   cables everywhere and so they decided that  they would build a wireless network in 1968 this wasn't off-the-shelf equipment right yeah  they had to develop this all themselves you   couldn't just go and buy a cisco wi-fi access  point and stick it up on top of a tower because   cisco hadn't been created yet that was still 12  years in the future if not more 15 years in the   future and of course cisco only existed because of  the technology that was developed as part of aloha   so they were literally developing all this from  themselves and so what they had is that they   had two radio frequencies that they'd use they  used one to transmit from the ibm computer out   across all the islands of hawaii and then they had  another radio frequency that they used to transmit   back from all the terminals that people were using  back to the central computer now they had a sort   of a simple situation because they had a very  definite model that they had one computer the   ibm mainframe it was at this point they had data  going from the ibm mainframe to all of the other   machines and they were receiving data from many  machines transmission was a one-to-many problem   and that's great because you then only have one  computer that's sending anything so that computer   can break its data down into packets which is what  they did and then sequence them so they get sent   out and there's no sort of corruption as that  data is transmitted actually what they did was   that they had another computer that sat in front  of the ibm mainframe they had a hp computer they   bought an hp mini computer and they dedicated  that to doing all this processing and splitting   data into packets reassembling it passing the data  back on to the ibm mainframe they refer to this   hp computer as the menu hewn and i apologize if  i've mispronounced that name which is a hawaiian   word for elf they sort of played on the word elf  because it was based on some of the ideas that   were being developed as part of the arpanet for  the interface message processor so they were sort   of imp elf you can see how the sort of train of  thought moves along so they have this secondary   computer the menu that was sitting between the  ibm and everything else so it got data from the   ibm and could then transmit it out as packets to  all the terminals wherever they are over the radio   frequency in a serial fashion modulating it deep  as it needed to be and they just transmitted it   out so sending data from the ibm to the terminals  was fine the terminals could then receive the   packets see if it was for them if it wasn't  displayed on screen if it wasn't you just ignore   it and so on they didn't worry about security in  those days i'm sure it was just clear text and   receive it but they had much more of a problem  getting data back so when you type something into   the computer you need to send that data back to  the ibm mainframe so that you can deal with things   and so what they realize what the sort of key  contribution that norman abrams and and the   others who are working on this sort of realized  was how can we send that data back to the ibm   computer via the menu in as simple a way as  possible and the problem you've got is that   you've got several computers  dotted all around the islands   and it's potentially possible that two of them  might transmit at the same time and if two of them   were to transmit at the same time it's the same  as two people speaking at the same time they would   interfere with each other and the computer at the  other end wouldn't be able to receive the signal   and so they would corrupt each other's messages  so they were trying to make sure that any computer   could transmit at any point but that you didn't  have corruption of the messages as they were sent   what they realized was that they didn't need the  data to be received correctly necessarily the   first time they received it that it would actually  be okay if it could be eventually received that   you might transmit it and it wouldn't get  received so then you'd have to transmit it again   and so what they realize if you relax things and  say okay we want eventual packet delivery as it's   called we want to be able to receive it at some  point you can actually start to say well okay we   can transmit at any point to make best use of the  bandwidth i mean you could use say time division   multiplexing where you break your channel your  radio channel up into segments that are some   percentage of a second long and you say okay this  computer can only transmit in that point of time   and then this computer can only transmit at this  point of time but if you do that you find that   you're not actually using the bandwidth that well  because most of the time particularly on something   like a terminal people are typing and they'll  type something then they'll read the response   and then they'll type something else actually that  doesn't use the bandwidth you've got available   that effectively what they realized was they could  make best use of the bandwidth by just saying okay   you can send the packet whenever you like so any  of the terminals if they had some data to be sent   you type something into the keyboard it would then  just attempt to send that data to the ibm via the   menu so it's modulated into the radio signal send  it out over the radio transmitter it'd be received   by the menu and then it'd be sort of decoded  and passed to the ibm computer to do whatever it   was you wanted it to do and if you were the only  thing transmitting that would be absolutely great   you could send the data out and it would be  received but what happens if there's two of you   transmitting at the same time so you're typing on  your computer i'm typing on mine and we send the   data at the same time well of course the data is  received by the menu is a mix of the two messages   so it won't make any sense it'll be corrupted but  they realize that this was okay because what they   got the computer to do is that when you receive  the data correctly it sent out another bit of   data back to the machine that sent it saying  i've received what you sent correctly so you   would send your data from your terminal it would  get sent up and the menu you would receive and   you would send a message back saying yep got that  acknowledge and then you'd know it'd been received   and what they realized was if you just  send it out and you don't get that response   that means the menu didn't receive it and if the  many who didn't receive it you just send it again   and then hopefully that time he gets through  and then you get the acknowledge response and   if you don't you send it again until you get  the acknowledged response and your terminal   does exactly the same thing it gets the doesn't  get an acknowledged response so waits a certain   amount of time and the key thing is you need  some sort of algorithm in place to sort of decide   who sends after what sort of time if everyone  just waited the same amount of time you'd get   the same sort of problem and things and so  it just waited for a short amount of time   pick it randomly use it based on the station id  various approaches they could use i can't remember   exactly which one they used in the low car it  doesn't matter and then you resend your data and   eventually it will get through and what they found  was that this actually provided really good use of   the bandwidth most people could transmit when they  wanted to but could also detect packet collisions   when two people tried to transmit at the same time  and recover from them by resending the packets now   it meant that the terminals had to have a little  bit of intelligence to them to be able to sort of   keep track of the packets and check whether it'd  been received or not but you could implement that   relatively straightforwardly and so it produced  a system that could work and this was operational   by about 1971 and used all over hawaii and then  as they were developing it they did some sort   of later improvements one thing they realized is  that if you just allow people to send at any point   then you could have a packet collision  which could destroy two packets   if only a single bit collided in between them  both packets would be destroyed um you wouldn't   receive them correctly that's a better way of  putting that and so you'd have to resend them   so what they actually did in a slightly later  variation of it which is known as slotted aloha   is that they said okay you can transmit at any  time but you must align it to certain time points   and so you have all the machines synchronized and  so you can either transmit say that 0 seconds or   0.001 second or 0.002 second for example and if  you do that you then either get a packet collision   where the whole packets collide because they're  transmitted at the same time or you don't get   a packet collision because if someone starts  transmitting something and someone else wants   to transmit say about halfway through it it has  to wait until the next transmission point to   which to do it at which point they won't collide  whereas if you can say transmit at any point then   you can sort of start transmitting and then i  start transmitting and it destroys them and that   could just sink that could just be as simple as  a single bits get corrupted at the end at which   point you've destroyed the whole transmission of  two packets when if you'd waited one bit neither   packet would have been destroyed so that was  the sort of improvement that they developed   now i said that aloha net was sort of the  grandfather the granddaddy of all the sort   of different networks and that's because when  people were developing things like ethernet and   xerox park in the sort of mid-70s they'd heard of  the work it been published and they'd heard of the   word that norman abrams and his team had done  in hawaii and they sort of took the same ideas   so ethernet for example run originally ran on  a single piece of wire that stretched around   the office and the machines were literally  physically clamped onto the ethernet cable   so they but they still use the same ideas they  still said okay anyone can transmit at any point   um if the data doesn't get received then we'll  retransmit things but because they were on a   physical piece of wire they could do some extra  things to sort of for example they could see   whether someone was already transmitting and so  they could sort of say okay someone's already   transmitting i'll wait until they've finished  so they could sort of get better performance   but they were sort of very much aware of  the work that norman and his team have done   and we're building on top of that and that's  followed through into things like gprs   satellite communications they're all still using  this sort of idea you still get straight aloha   networks out there i think laura wan the sort of  iot things at times can work in that sort of a   fashion that you just literally send things  out wait for acknowledgement if you don't get   that acknowledgement then you send it out again  after a certain amount of time until the data is   eventually received so yeah really great piece  of work it provided wireless networking for the   hawaii community of the hawaii academic community  of computer scientists let's limit this to the   people who are actually using it probably way back  in the 60s 70s and yeah has really influenced the   way that sort of networking technology has been  developed diagram i'm drawing very badly here and   so on so you'd have two sets of pulses one delayed  from the other it's what we call quadrature   encoding we can actually derive from that which  direction the signal is moving in so yeah they're   very different to the originals and the important  thing is that we don't know what went into here [MANUAL PUBLISH] 