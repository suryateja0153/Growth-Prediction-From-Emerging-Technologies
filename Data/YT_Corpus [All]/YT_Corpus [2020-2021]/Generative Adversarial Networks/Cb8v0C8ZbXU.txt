 [Music] thanks to CGI people are used to seeing something that looks incredibly real but is actually fake like Captain America's body there's no way that's real the computer-generated images from TV shows and movies and video games require millions of dollars and months of work by trained professionals but that could be changing thanks to deep fakes you'll probably already know about deep fakes they're based on machine learning and artificial intelligence and the beginning to give amateurs the power to doctor footage quickly and on the cheap deep fakes aren't perfect quality right now but in the future they could be pretty convincing maybe even indistinguishable from reality and if that happens well people are already preparing a deep fake video is one where artificial intelligence has been used to make it appear that someone is doing or saying something that they didn't actually do or say like a face flop putting one person's face on another person's body you can use this for fun and enjoyment like the person who changed clips of famous films that they all starred who else but Nicolas Cage but there are also more sinister uses out there for instance in 2018 director Jordan Peele created a convincing proof of concept video of Barack Obama saying a bunch of funny swear words the video was obviously not real and it said so in the video but it was an important PSA about how easily political videos can be faked also unfortunately we can't not mention what around 95 percent of deep fake videos are right now pornography that's been non-consensual ii edited to feature celebrities and even ordinary people so bad stuff deep fake technology is really new but it's evolving quickly by one measure the number of these videos almost doubled in 2019 and that's likely because they're becoming pretty easy to make deep fakes take advantage of new powerful computing methods called generative adversarial networks or gans to make one you start with neural networks a type of teachable AI inspired by the connections between the neurons in your brain you take two of these networks and you give them lots of training data which in this case means lots of pictures and/or videos of the person you want to fake and you your networks to compete with each other one network is tasked with using the training data to make a deep fake to take some person's face and animate it onto a template and the other network is tasked with watching that deep fake comparing it to the training data and guessing whether or not the footage is real these are called the generative network and the discriminative network respectively as these two sides compete with each other over multiple tests the generative network gets better and better at creating convincing deep fakes eventually it reaches an equilibrium where the discriminative network can't tell real from fake of course your deep fake is only as good as your neural networks and just because the computer is fooled doesn't mean a human would be these days you can make it cheap amateur deep fake video using about 250 images of the target and about 2 days of computer processing time but those won't fool a person they're not perfect forgeries and are only good for like the Nicolas Cage party trick or faking really low-quality footage the best videos like the Obama one still involve professional touch-ups still spotting deep fakes is getting harder like you used to be able to spot one by looking for someone who wasn't blinking enough but lately experts are saying that you can't rely on that anymore like the games themselves human programmers are improving their algorithms over time so what works for detecting fakes today may not work tomorrow so how close are we to deep fakes that are indistinguishable from the real thing that is still up for debate but one way or another faking the video doesn't seem to be the biggest hurdle here it's the audio we're getting pretty good at pasting faces onto bodies and it's only a matter of time before Ganz can generate something that really fools us making a person say something is a whole separate challenge generally faking voices does work in much the same way with machine learning and Ganz you just need a few recordings of a person but the state-of-the-art voice faking software isn't fooling anyone for now likely because people just haven't studied it as much still that could change in the future and while it would be really cool for movie makers it could also make identifying trustworthy information that much harder this is enough of a concern that some companies are already preparing for this for example one called true pick is trying to combat deep fakes by focusing on the metadata of photos and videos for smartphones that means things like the GPS position of the phone when the video was filmed and the hard to fake things like the phone's pressure readings and orientation the company has made a camera app that reads that data as you film the video and immediately sends it off to the company's servers that helps prove that the original is real and makes it harder to produce forged versions after it's taken additionally one group that makes fake audio clips has experimented with adding a watermark to their content an artifact that will always identify the clip as being made by them unfortunately though no matter how many safeguards people put in place there will always be those who don't want to play by these rules but honestly that's true for many kinds of content and it's been possible to edit clips and make misleading videos for a very long time so no matter when the perfect deep fakes arrive it's probably worth brushing up on your media literacy skills anyway if nothing else it cannot hurts if you want to learn more about media literacy we recommend checking out crash course media literacy it's produced by complexly the same studio that brings you scishow and it's a 12 episode series that talks all about understanding analyzing and accessing information you can find it at youtube.com slash crash course [Music] 