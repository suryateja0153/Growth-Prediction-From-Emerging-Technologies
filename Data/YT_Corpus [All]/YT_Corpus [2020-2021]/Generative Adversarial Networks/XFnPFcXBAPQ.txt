 Catherine Zaller Rowland: Next, we are going to turn to a foundational discussion of AI and copyright. We are -- I'm sorry, I'm switching this up a little bit. We are having a foundational discussion about AI and copyright with the international discussion at play. So we are going to be talking about -- I'm getting it all confused. I'm sorry. Excuse me. We are doing a foundational discussion of AI, and technology, and the law. So I'd like to welcome to the stage Rob Kasunic, who is head of our registration program and practice and an associate register here at the copyright office, and Professor Elgammal, who is at Rutgers University, and is involved in both computer science, and art, and AI issues, and runs a very interesting lab over there in Rutgers. So thank you so much. [ Applause ]  Ahmed Elgammal: Hello, everybody. Thank you for inviting me. I'll try to give you an overview about how AI is used in making art, in particular visual art. Let me start by --  It's really cool.  Ahmed Elgammal: -- this video.  A machine.  Ahmed Elgammal: The audio doesn't --  It's actually the first work of art made by AI to be sold at -- sorry I'm late, Dana [assumed spelling]. I got caught up.  Ahmed Elgammal: -- all right, so what you see is a clip actually from the HBO "Silicon Valley" show. That was aired back in April 2018. It's kind of a joke showing an actual AI art on the wall, and the two guys are talking, one of them asking who is the painter, and the other guy answering this is a work of -- done by AI. It's actually -- and the third guy's coming and saying it's actual -- actually the first art made by AI ever sold at an auction in Sotheby. So that's a fictional scenario. The AI work is real, but that fiction is -- into a reality six month later, when Christie actually auctioned a piece of AI art, and was sold for almost half a million dollar. So let me give you a brief historical overview of where we are now compared to -- in the context of history of making art. So art have been evolved from cave painting to painting on canvas, like Caravaggio, and Renaissance, and then in the 19th century came photography, which changed the way making images -- artists making images. And photography itself became an art form in the 20th century, and then came digital photography in the 20th century. Late 20th century came digital manipulation of images, like PhotoShop and these softwares, and in the '90s came graphic rendering, with all its amazing abilities. And now, we are entering a new age of the machine using AI can actually create an image, not just taking a photo like a camera. So however, the use of AI in making art is not new. It is as old as AI itself, from the '50s. So are two of the pioneers who have been experimented with using AI in making art work. At the left is Harold Cohen, an artist -- which artist who use AI in making works of art for a long time, and at the right is Lily Schwartz, who -- actually Lillian Schwartz, who actually pioneering computer graphics scientist, who also experimented with AI. This is one example of Harold Cohen work. The difference here is that this was what's called rule-based AI systems, where you actually have to write lots of rules about what to do, what the AI is supposed to do, or the machine is supposed to do. Here, the AI actually make drawings with some flexibility or irregularities, and then the artist painted over that. Okay, so move to the last five years -- a lot of buzz has been around what's called style transfer, where basically you start with a photo, like that amazing photo in the top left, and then you can stylize it by Van Gogh style, or Munch style, or any style you like. And there are many apps available that you can do that, and there is another version of that that's called Google Deep Dream, where basically you start with a photo, and then hallucinate some objects on top of it. And this comes from a machine that are trained for different purpose of recognizing cats, and dogs, and other things. So you end up with something that looks like -- say in light of Van Gogh, but has lots of dogs over it. And people liked that, and if you search Google Deep Dream, you can find so many things that people have done with that. However, these two example of style transfer and Google Deep Dream are transformative AI, where basically you transform one image to another, adding a style. It's not a generative AI with a -- generative AI. Generative AI is really the topic of what I want to talk about today, which is really the important issue when it comes to today's topic. So what is generative AI? So the breakthrough actually came about five years ago, by a work by Goodfellow and others. It's called Generative Adversarial Network, or use GAN, G-A-N to describe that. So what is GAN, and how it is work? So it's an AI algorithm that basically try to generate images. So we give it some data -- for example, images of cats, or images of flowers. You want to generate more of that. So -- and the way it works is, you have two component, two players. One is a generator, the one in the right there, who would have no access to these data. It never sees data in the whole process, and the other player is actually a critic, or a discriminator -- that's the term -- technical term -- who actually have access to these data. So in case flowers, it has access to images of flowers, and basically, the generator will start generating totally random image, totally random image, because it doesn't know anything about what flower is. And pass these images, random images to that critic, and the critic will obviously say, okay, this is not basically flowers. And this signal go back to that generator, and the generator then has to improve, have to think out what to improve in that random image to make something that please the critic. And after so many iteration, hopefully that generator will be able to do something that looks like a flower, that can fool that critic, and the critic also try to get better and better in telling whether that's a fake image coming from the generator or an actual flower image. So here's an example. After few iteration, this what show up, and then after few iteration, the form has -- is evolved more and more, and more and more -- and it come up with something that reasonably looks like a flower. That's a fake flower, in that case. All right, so these are the process that kind of make an evolution on how art is made using AI. These are examples of actual artworks by different artists using AI art, like Mario Klingemann, Tom Brown, Robbi Barret, and others. So there is something -- actually, if you look at any of these example, you can now think out -- what are the data that came behind them, like nude paintings in one, a fan in another. So -- but it -- this has transformed the data into this, a new visual form. So what is the aesthetics exactly of this process? At the top here, you see examples of what the machine generated when we give it lots of images of classical portrait from Renaissance until 20th century. So you give it lots of classical portraits, and what it generated, you see, is kind of failed attempt to make a portrait. It try to make a portrait, but it fails. And from that failure come the aesthetics. So I call the aesthetics of machine failure, not machine learning, but actually machine that didn't give a portrait, but give -- but exactly remind of Francis Bacon portraits on the bottom, with a very fundamental difference. At the bottom, Francis Bacon intended to make these deformed portrait, while on the top, the machine's actually failed to make a portrait, and from that comes interesting portrait that an artist would like, maybe, and put it in an exhibition. So that's -- you should keep in that mind of understanding the process here. However, AI generation have evolved a lot in the last five years. At the right here, you can see NVIDIA -- what's called face -- fake faces, where it generated lots of claimed fake faces. By fake here, it means that it is not anybody that the machine have seen in the training data. It can actually be some -- looks like very similar to somebody in reality, because basically, a human face is a combination -- any face is combination of other faces anyway. So -- but this show you how good is the rendering of these machines are now, in really photorealistic images. At the left is an example of painting birds and flowers just from text. You give it a text of what you want to generate as a flower, or a description of the bird you would like, and the machine actually generate a good quality photorealistic bird, which also can be a fake bird, not necessarily a real bird. So that went a long way. So who is the artist in the process? So in this process of using GAN, the artist would feed the machine some images, in the case of flowers, and the machine will generate lots of other examples of flower, not necessarily copying the data, because as I said, the generator doesn't see the data. It just generates things that are from the same distribution statistically. So what is the role of the artist here? So the first thing is, the artist actually pre-curate the inputs. The artist choose what data to feed to the algorithm. You want to create something based on faces, or flowers. What kind of faces? What flowers? What paintings? What's the inputs? So that's one of the roles, and then, the artist actually tweak -- most artists are not technical people. So basically, take an algorithm off the shelf, and maybe change that a little bit, or just run it as it is, or change some parameters. Or if the artist is technically savvy, he actually can change the code or write his own code. So that's another role. And third part is post-curation, because the artist -- the machine would give thousand and thousand of possibilities, and the artist choose few of them to show to the world, exactly like a photographer would take 1000 photos and show 10 or one in a show. So the artist's role is pre-curation, tweaking, and post-curation. So it's totally a conceptual art process, where artist is totally involved, and the AI is a tool that can actually create something with the artist. So in October 2018, Christie's sold that artwork at the left here, and here's the problem. Because that artwork was a result of a machine -- that GAN machine that was trained by another artist, who is -- another artist, who is Robbie Barret, and his tweet on the right, who trained that -- he took that off-the-shelf -- and he tweak it and train it on portraits, classical portraits. And then give it -- or the other authors take that algorithm and basically generated from that algorithm after being trained. So basically, you're coming to that diagram here. The algorithm was created. It was already pre-curated and trained, and you just select -- pressing a button, and selecting an image, and sell it. So who is the author? And that create a debate at that time. I have a whole article on Artsy [assumed spelling] on that if you want to know more about -- of that. But that raise a lot of issue about authorship of this kind of processes and outcomes of these processes. Another issue is that what you generate here is a very rich generation. You can -- this video actually will, for example, show going through what the machine learned after trained on flowers. As you see, it can really generate lots and lots of forms, and flowers, and intermediate forms, and combination of forms. And that raise another issue. What if you train these kind of models, and take away some of the results out, after being trained? Who owns that? And for example, there are apps online, like Artbreeder, who actually do that. You can actually combine any images. This actually takes millions of images and train them, train the AI on them. That include animals, objects, cars, many things, and train the machine to generate these kind of things. And once you do that, you can actually navigate in that representation, and generate lots of combination of things, amazing combination of things. For example, that video here will show an example where I combined -- I just do this to combine a cat, a panda, and a hamster. And what you generate here -- all possible combinations of these three animals that you -- this doesn't exist in reality. So if you go to this amazing website, and you create your own image out of that, another person can actually get the same image accidentally or eventually. Then that is the authorship and ownership issues. So in that particular process, the artist's role really here is just basically the post-curation, because the algorithm is already trained, and has ability to generate infinite amount of images. And as an artist, or as a user, your role is really searching for something interesting to you -- out of there to show to the world. So that's a very limited role. So moving to autonomous generation -- can AI generate art by itself, and can the role of human become minimal to that? So what if you take this GAN and feed it, for example, all of art history, for example? What it will generate? That's an experiment we did at Rutgers. So basically, we took 500 years of art history, and images of art history, about 107 images, and feed it to these GANs. By definition, by construction, GANs will not make anything creative, as I showed. It will just basically try to create something that looks like the data you give it. So the outcome will be more like what you see in the bottom here, where basically emulation of what you have seen in art before, and mostly it's failed emulation. So how can you move from being generative to being creative? And that's basically our contribution, that are which was called creative adversarial network, or CAN, where basically we try to push a little bit further in the autonomy, and becoming more creative. So what is that? We call that artist AICAN. So basically, we based our algorithm here on a theory from psychology by Professor Martin Dale [assumed spelling], who was at the University of -- and the theories basically can be summarized at this. Imagine you are an artist living in the late 19th century. So impressionism has already happened, and you already have seen lots of impressionist work by many artists, and impressionists have really -- every possible facade of a building, or a street, or amazing landscape. As an artist, you're already bored of that, as a new artist. And so, basically, if you keep doing that same kind of art, what's called habituation -- you kind of get bored with it as a viewer, and as an artist, avant-garde artist, we basically got bored very early about -- from that, not like the general public. So as an artist, your role really is to come, create something that's really innovative, to push against habituation with the least effort. Because if you push too much, that can be totally innovative, and can be shocking, and that is exactly what, for example, Picasso did in the latest art book that later sparks the cubism movement. So pushing innovation against habituation is right where you will drive the art forward. So how can we implement a machine that do that? So what we did is, we take these GANs and modify in a way that we want to create something that are innovative. So if the machine creates something that's -- repeats, for example, Renaissance, or Baroque, or impressionism, it has to be penalized. Otherwise, it's not going to be creative. That's how to push it forward. In the same time, it generates something totally random that will be not copying any of these existing schools, that's totally -- this is totally shocking. It's not really interesting as art. So that will put the machine into a dilemma. In one hand, it has to follow the aesthetics. It has to follow the distribution of what art is. In the other hand, it shouldn't generate anything that's identified as existing art movement. And by doing that, the machines have to generate these amazing forms for us that was really very interesting. And when we surveyed and showed these mixed up with actual art by human artists from recent contemporary art fairs, we were surprised that people thought that these art were made by a human artist 75% of the time, compared to 85% of the time when they're shown art by abstract exhibitionist masters, and 48% of the time for actual art by artists from Art Basel 2016. So that really put the machine at the level of generating visual images, interesting forms that you cannot tell whether done by a machine or human. And what is the role of the human here? For me, nothing other than developing the algorithm that process, and feeding all of history. So I had no control of what be generated next. All right, so let me finish here. And also, we will associate what is, like, intentional, inspirational, communicative, has human visual structure with these arts. Let me finish by this social variation of AI art in society. So the first one in the top left is an L.A. Gallery showing back in 2017 that show AI art. I think it was the first Barret show, then the Christie show in '18, art -- was showing art fair in Art Basel, and SCOPE Art Fair. It was shown in galleries in New York, in Chelsea, in another auction by Sotheby later. The Barbacan in London had made a show about AI art. It was just an exhibition in China -- in The National Museum of China in November -- one million people showing art and art technology, including AI art, and obviously, many coverage in the media from top news coverage. So I'll stop here for the time, and I'll start with the discussion topic. [ Applause ]  Rob Kasunic: Good morning. That was fascinating. Thank you. Well, as the director general thoughtfully discussed earlier, we are at a time now where artificial intelligence is really forcing us to reconsider and question some of our foundational assumptions. And one of those would be just looking at the question of what is art. I thought it'd be helpful to look at some dictionary definitions of that, just as context of where we now stand on that issue. "The expression or application of human creative skill and imagination, typically in visual form, such as painting or sculpture, producing works to be appreciated primarily for their beauty or emotional power -- works produced by human creative skill or imagination. And the conscious use of skill and creative imagination, especially in the production of aesthetic objects." So that is a -- certainly, art is not the question. There's a difference between what is art and what is copyrightable, but to get into the realm of what is copyrightable, we've had several Supreme Court cases over many years that have looked at this question, looked at the constitutional provision of works -- of what constitute works of authorship, and what constitutes originality. And in the Bleistein decision, Justice Holmes did look at that question of what is originality, and stated that it was -- wrote that it was the personal reaction of an individual upon nature, or expression of the author's unique personality as the key to satisfying the constitutional requirement of originality. Similarly, when we get to the case of Burrow-Giles v. Cerrone dealing with the photograph of Oscar Wilde that you see there, the question of authorship was raised, and in -- and the question of whether photographs could be copyrightable. So it also was addressing what constitutes a writing under the copyright clause, and the court said that an author is the person who effectively, or as near as can be, the cause of the picture which is produced. That is, the person who has superintended the arrangement, who has actually formed the picture by putting the persons in position, and arranging the place where the people are to be, the man who is the effective cause of that. The author is the man who really represents, creates, or gives effect to the idea, fancy, or imagination, and also said these views of the nature of authorship and originality, intellectual creation, and right to protection confirm what we have already said. More recently, the Supreme Court stated in the Feist decision v. Rural Telephone Service, in an opinion written by Justice O'Connor, that the sine qua non of copyright is originality, and to qualify for copyright protection, a work must be original to the author. The court defined author in the constitutional sense to mean he to whom anything owes its origin, originator, or maker. While the word "writings" may be construed liberally -- may be liberally construed, as it has been, to include original designs for engraving, prints, et cetera, and photographs, it is only such as are original and are founded in the creative powers of the mind. The writings which are to be protected are the fruits of intellectual labor embodied in the form of books, prints, engravings, and the like, and that, again, reinforcing that originality is a constitutional requirement. So some of the questions raised by works created by artificial intelligent -- artificial intelligence art -- can machine learning produce original works, or is the produce of such software inherently reproductive, derivative, and/or the result of a system or process devoid of that personal reaction of an individual upon nature, or expression that is devoid of the author's unique personality? And also, it can be asked, "Can a computer program be the author in a constitutional sense?" And part of that question then answers, "Does Congress have the constitutional authority to provide copyright's incentives to computer programs themselves as authors?" Furthermore, if such authority does exist, should Congress exercise that? I think we heard earlier that this is a time to be deliberate, and to not rush into answering some of these questions, but to see perhaps how this situation evolves. Also, if authorship or ownership of AI output should be protected, is copyright the proper vehicle for such protection, or perhaps is sui generis protection, or some other form of intellectual property protection preferable to -- preferable to that? Some of the types of uses -- you've seen certainly a lot of examples, but just to more broadly look at how software may be used, and a very high-level overview of how software can be used in the creation of works is that computer program itself that is the tool to create other works. In that case, the programmer of the computer program can unquestionably be the author of that computer program. So computer programs of artificial intelligence are protectable themselves. Furthermore, software as a tool, as we learned from the CONTU Commission many years ago, when computer programs were incorporated into the copyright act -- that, at the time, viewing software primarily as a tool for others to use. So the programmer may own the software itself, but the user of the software owns the works created with the software as a tool, much like a photographer would own the copyright to the photograph, rather than having the camera manufacturer as the owner of that photograph. Software can also be used as a template, a sort of Mad Libs-like use, where the software can complete the template, and this seems to be the case for use in such -- types of work, such as factual news articles, sports articles. Weather articles can use this form of template, in which certain facts fill out the remainder of that, and this may entail some authorship by the author of the computer program, in terms of creating that template that is going to be used. But the question is software as the creator of works based on machine learning, or the output of random or process-driven expression is really, I think, the question that we're -- questions that we're looking at today. So where we currently stand in the United States Copyright Office is that the office will not register works produced by nature, animals, or plants. Examples that we've used in the compendium of copyright office practices include a mural painted by an elephant, a claim based on the appearance of an actual animal skin, a claim based on driftwood that has been shaped and smoothed by the ocean, or a claim based on cut marks, defects, or other qualities found in natural stone. Those are objects that cannot be copyrighted, because they're -- the result is not the result of human authorship. Similarly, as you heard, also another example is that a photograph taken by a monkey may not be protected by copyright, and we took no actual -- any position in the actual case involving the monkey at issue, Naruto here. Although the Ninth Circuit did decide that although the court found that the -- the court's precedent required the court to conclude that the monkey's claim had standing under article three of the United States Constitution. That the court did find that, with respect to the copyright infringement claim, that the monkey, as with all animals, since they are not human, lacks statutory standing under the Copyright Act, and therefore, could not -- the court could not affirm the judgment -- affirm the judgment of the district court, that there was no standing to bring a copyright infringement action. It is a wonderful photograph, though, although there are some lingering questions about the degree of originality. I think when you look at the comparison there, and the pose by Naruto, there are some lingering questions. Another example of -- in the compendium that has been addressed is the office will not register works produced by a machine or mechanical process that operates randomly or automatically without sufficient creative input or intervention from a human author in the resulting work. And the example of the pictures that you see there were actually counter tops that were produced by a mechanical process, and for which there was no human that actually had sufficient input into what the resulting work was. So those were refused for registration, and generally, those kind of processes will not be sufficient, unless there can be shown some showing of sufficient human intervention or creative input into the actual result. On that -- the question of process also raises questions with respect to the decision in Baker v. Selden, and ultimately, what is now section 102B of the Copyright Act. Which states that in no case does copyright protection for an original work of authorship extend to any ideas -- any idea, procedure, process, system, method of operation, concept, principle, or discovery, regardless of the form in which it's described, explained, illustrated, or embodied in such work. So in many of these cases, it does sound like the algorithms or the software that creates artificial intelligence could fall under the category of being a process itself that is creating these works, in some cases. There's also some question that I think needs to be considered, at least, in terms of -- typically, in the merger question, it would be not wanting to allow a -- the way that an idea can be expressed in only a limited number of ways to allow that -- those limited number of ways to basically protect the idea itself. And I think when we're looking at the question of the computational power of computers, as opposed to the human mind, and human ability, that there are some concerns as well about whether computers could fix so many variations of expression in a very short amount of time that there is basically no room left for human expression, or original human expression from that. And at least one court had said that copyright should not be viewed as a game of chess in which the public can be checkmated. So it is a lingering question. There -- as was discussed earlier, and I think is very obvious, is that -- the question of, "Is a non-human work distinguishable from human author works?" And along with that, "Are machine-generated works creative?" I think the answer to the first question, is a non-human work distinguishable -- in many cases, that answer is no, but I think that is not necessarily the relevant question. Artificial intelligence can create creative works, but the question is whether the creativity is the output of artificial intelligence software maybe considered authorship without sufficient creative input or intervention from a human author in the resulting work. Another question is whether AI creative output itself is derivative, requiring authorization of the works used in the course of machine learning, and again, this was something discussed by the director general in terms of the data or the works that form the basis of machine learning. And so, there are significant questions about access to those works, and authorization for those works. It's also important to consider that not all creative works are copyrightable. Certainly, under the copyright act, under federal law, a creative unfixed work is not protected by federal copyright law, and a creative work that is not within congressionally-designated copyrightable subject matter is also not protected by copyright. That picture there represents a claim that we received for a genetically-altered fish, in which we did not find a section 102A category that was sufficiently -- in which that fell, and so could not be registered. Should a creative fixed work created by a non-human be within the scope of federal copyright law? That's a question. Another consideration with that question -- it may seem unfair. I think there are similarities to this quote from Feist. It may seem unfair that, with these works being created, why should not somebody be considered the author of that work, or also be considered -- should not somebody be considered the owner of that work, and be able to reap the rewards from that work? Well, a similar question was raised with respect to the concept of "sweat of the brow" and industrious labor, that the money, expense, and time, and effort that went into creating certain factual works. And the court said, "It may seem unfair that much of the fruit of the compiler's labor may be used by others without compensation. As Justice Brennan has correctly observed, however, this is not some unforeseen byproduct of the statutory scheme. It is, rather, the essence of copyright, and a constitutional requirement. The primary objective of copyright is not to reward the labor of authors, but to promote the progress of science and useful art." So a significant question is, "Does artificial intelligence require copyright incentives? Do we need to, or -- and again, if it does require some kind of incentive, is copyright the proper vehicle?" Thank you. [ Applause ] 