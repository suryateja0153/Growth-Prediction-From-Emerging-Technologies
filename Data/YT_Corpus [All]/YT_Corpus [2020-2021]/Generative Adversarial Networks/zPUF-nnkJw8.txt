 I'm really excited about this project and it's something I've been working on for a couple of months and so I'm just really happy to share with you guys so my name is Victor DBA I'm a research engineer at Cloudera fast food labs we have an office at Brooklyn New York and essentially I spend half of my time research in deploying technologies and the other half helping clients build machine learning solutions and then at night I spend my time pretending that I'm an artist and I and I'm a god and so it turns out that if you do have neural networks it can really help you do anything and so the title of my talk today is artist art plus AI am generating the Vil African mask he's in generative adversarial Networks cool so uh so just to give you a little background why combine art Sandia and so for me it's a little bit personal I grew up in a West African country and something that was really interesting when I was a little boy was that every year at the end of the year in December I extend this family we'll all travel to our village and we'll spend about two weeks together and so it was a fun period and one of the highlights of that whole experience was that it was something called the masquerade dances and so what will happen is that we all in this square or like the equivalent of a park and you'll see interesting dressed individuals like this and they danced really fast and they have all these acrobatic maneuvers and they jump around and more importantly they had this really interesting elaborate masks and so that was the first time I actually had some encounter with this mask and since then I'd be really really fascinated by them and so fast forward to today 20 years later I am a machine learning engineer and I really really want to connect you know to that aspect of my culture and my identity and my roots but you know what I'm not an artist I can draw and so what can I do I guess I can I can create a create artificial neural networks and leverage data as an assistant to kind of like really explore and kind of find new interpretations of what African masks could be and so to give a really fast primer on what African masks are here you see two pictures on the left you have a bronze mask is from a tribe and from from Nigeria and on the right you have another mask example and it's from a tribe in the Congo and one of the things if you look at more examples one of the things you'll find is that they have some interesting characteristics and so immediately you find that they're fierce and one of the reasons for that is because they're supposed to be representative of deities they're supposed to be the spirits of the ancestors mythological beings or other beings that are believed to have power of a humanity another characteristic of this mask is that they're pretty sophisticated and so they're complex both in art design and the range of materials that are used and so you see sometimes wood really complex with patterns I used to create this mask sometimes it's clay sometimes it's brother sometimes it's iron and so there's a really range wide range of materials that I used to create this mask the third interesting thing about them is that they're surprisingly ancient and so archaeological discovery shows that some of these pieces did as far back as the ninth century and then finally they functional and so they are not just artistic pieces that are created too because young for their visual excellence they actually function also much like you would wear a dress and you would like you to reflect your identity that's pretty much in a similar way people would don't mask and it will be a really important expression of the identity and so what did i do what did i do and how did all of this come together to inspire this project and so first of all it's a way for me to kind of explore engage with my culture identity and the way for me to bridge AI arts and technology so that's one of the motivations for this project and um another thing we probably have noticed is that there's an uptake in this area of generative art and art inspired by AI but one limitation in this area is that most of it is characterized by a classic European art and so I thought you know this might be an opportunity to diversify the conversation in this in this in this space and then finally if any of you work in the domain of generative modeling you will find that some of the datasets you find there are things like adding a fashion M nice and nice and Seaford 100 and so there's opportunity to contribute more complex datasets that really help us push the limits of what generative model and can do as a part of this the goals of this project is to at some point contributed data set that enables more complex generative modeling and so these are the the main motivations for this project and so before I go ahead I'd like to show you guys some results and so the entire panel you see here examples of not this mask are actually real and so everything you see here all generated images and representations of what the neural network that I trained thinks an African mask could look like and and I could could be and I have a lot of favorites here and I'll show you a couple of them as the presentation goes on okay so just to give some background information on the process that I walk through as part of this project so the first thing is that this project falls within the broader domain of efforts that have been termed as computational creativity a generative art or even code art and so it's a pretty old field since an old area and some of the incredible contributions here have been in terms of tools that are used in this domain so how many of us have used p5.js okay cool processing cool so yeah awesome and so for most of these tools the intuition here is that you know you have an idea of some art you want to create in your head and you write some code and they bring it to life and so some of the patterns you see at the in the background these are all generated by procedural code that seems good at Bizness structions basically generates a bit of part but neural network kind of changes this paradigm just a little bit and so neural networks are a class of software that allow machines to learn rules directly from data and so as a pair - - tools like p5 GS of processing imagine if you wanted to draw some circles in p5 GS you would write a few lines okay and so if you want to do the same with neural networks rather than writing code you actually go and gather images and so in this case your image data becomes the code I actually the image data becomes a source in PT and network and their network generates generates the code so why would we want to do that and so if we wanted to generate a simple stuff like like the patterns we see at the back it's easy to actually write code to do this but if you actually want to write code that generates African masks and not just that you want stuff that's kind of love L on you how would you go about writing code like that you probably can't and so for this you actually need in your networks that help you kind of imagine this process and so when I started working on this project I cannot split it into three simple parts which is the the basic data science process and so the first interesting part is curating the datasets the second part has to do with training the model making decisions around what kind of gun architecture to use how do you set your hyper parameters what kind of resolution do you want to generate and then finally there's some work couldn't put into evaluating the results and then interpreting what the neural network has come up with and so for dataset curation I guess like one of my previous speakers mentioned this is the most interesting most amazing most delicious part of the process right and so I started with you know data scraping code manual image downloads and so I started with at the end of this process had about 20,000 images and then I went through the process of careful hand curation so this is involves removing vector images because we want to be realistic images this involves removing incorrect content and masks that have nothing to do with Africa then finally removing a bunch of duplicates and at the end I was I was left with about eleven thousand are curated image and so this is this process takes a bit of effort it took a couple of weeks actually carefully curate and kind of like get the data setting in the condition and the manner that you know I was comfortable going ahead and using to train my mind your network and so once I had all my neural network data once I had all my data available the next interesting thing was to identify was identify the right model to use for this I I used something called the generative of the Seven Network and so which which are also called gans and so again it's a really interesting arrangement of two neural networks so on one hand we have something called the generator and on the other hand we have something called the discriminator and so on the right you have an image that kind of describes what the generator looks like and so what it does is that it's a feed-forward Network it takes in a bit of fixed noise and the output of that process is that it generates an image and so the goal is that as the model is trained you want it taking this noise vector and generate an image that actually looks like an actual mask and so the second part of this model is something called the discriminator and it has a simple task and so here its goal is to taking an image and tell this image is actually real or it's fake fake in this sense being something that was generated by the generator something that really didn't come from a training dataset and believe it or not it turns out that if you structured these two networks together and you get them to play a game at the end of that process you actually have a generator network that has learned to come up with images that look plausible they look like they're actual masks and you have a a discriminator network that has learned to become really really good at telling our fake fake from real and to describe this whole process I'd like to tell this really funny story of the police and the forger and so the stories like this first the forger starts as an amateur and so his task is to create art that you know looks like let's say if I go around Brant and he wants to sell it and make profit but because he's really not good at this process once he tries to sell the art the police comes and says hey that's a fake you know you're going to jail and so this guy's caught he goes to jail all day he meets the girl father and the girl father tells him oh you know this is the reason why you were caught and then he gets better and he gets out of jail and he makes even better fix and at the end of this process the forger gets really good at creating stakes that the police can't can't detect the end of this process if the police does his work correctly it becomes even better at distinguishing fake from real so this is pretty much the process that you know again actually goes through and at the end of the process we want to actually were really interested in the generator switch that when we're done with the training process we can actually give it some random noise and it gives us some new mask image that that looks interesting that looks like it's a part of the training data distribution okay okay and so I have I have a little video and left looks like if it's not loading up right now but what it was gonna show you was a an example of what the training cycle looks like and so initially what you would see is that each of the boxes starts out as random noise and so the generator has very little skill at that process but as the training as we go through various epochs you will find that that it actually starts to come up with stuff that really looks like masks and so there are a few a few processes I went through in order to actually train this model and so I started out with a sample this again tensorflow implementation and so this again stands for deep convolutional generative out of serial networks and so if you're working with images in this case I'm generating images of masks it's really important that you use your generator and yet this committee actually have convolutional layers and so this again is just one formulation of of Ag and that allows you to generate images along this process one of the challenges that I faced was that you know I had to write my own custom that data input pipeline and one of the issues that came up was you know there were some differences in which in how I had generated my my dataset compared to how the code was actually expecting expecting the the image data to look like and so when when each of us here process images how do we specify that length height width and channels or channels height and width which one do we use channels at the end or channels in front any preferences okay so typically I usually forgiving image I specify the height the width and then the number of channels however at some part part in the sample code I found it was actually channels first height and width and so what that just meant was that the weighted model was consuming the data was wrong and all of the first 100 experiments around just and so one thing you really should do is to validate your your your data formats and so that would really save you a lot of pain right and so the other thing I did was that the sample could I I found was it was designed to generate 32px pixel by pixel images so I just had to modify the generator and discriminated such that it learns to generate higher resolutions that's 64 px and 128 px and then finally you wrap all of this into an experiment a couple of files Python files in this case I I trained with the TPU and I'll get into a a bit of rationale for why teepees work well for prop a problem like this so you set up your teepee instance and then you get your data into a DCP bucket and then finally you you run your training and so it turns out that you know setting up a TPU is a fairly straightforward process there are two interesting things that you need to do but the first thing is you know set up your project set up your zone data you need to enable TP use for your DCP projects once you do all of that you use the CPU command-line tool essentially you run CTP you up and essentially what what it does that is sets up GC g compute engine virtual machine and allocate some TP resources where you can actually run your training and so once you're done with that you could in this case this is the the code I just used to spin up my training process and so here you set an environment variable that Nations your GCP bucket name and then the name of your TPU and this again name is name of the file that actually runs my training so it's a fairly fairly straightforward process and it's kind of easy easy to implement and so whitetip user the first the first value here is that it's easy to set up it's fast and it turns out that GPUs are available it turns out that GPUs are available and so if you're here in the room I knew would like some guidance and how you can go ahead run in training jobs and GPUs I'm happy to discuss with you a little bit more on that and it turns out that they're really fast and so you could use them as individual TP use or you could use them in the pod formation where it is 8 or 16 or TP use the main limitation here is that you need to rewrite your code such that it takes advantage of the TPU the TP architecture so this this process is it's it's not always it's not always obvious to a lot of developers because your basic tenets of Lakota a Karass code might not run just just as is on the TPU you actually need to write some code that gets your code your application to write to run on GPUs and so right now the way you do that is to use TP estimators which are a little harder to work with you're less friendly than Curiosity F 2.0 it's why another there's some work in progress to allow GPU support for TF 2.0 and chaos but the last time I checked I don't think that's available yet and so at this point I should be really happy I have some results I'm able to generate some some images but one thing that I I actually did notice was that because of because of instabilities and training again some of the best results I got where we just the 64 pixel pixel configuration so for 128 pixels there's an on problem with training games called mod collapse where your gang just doesn't generate a variety or a lot of different different images and so what can we do to actually to actually address this issue so it turns that we can use something called super resolution guns and so these are another formulation of guns where you have your generator rather than taking in a random noise vector and then generating an image what it takes in is that it takes in a lower resolution version of an image and it learns to generate a high resolution version of the image so the question is does this work and so I'm going to show you some of my favorite examples and so on the left here we have a 64 px image something that was generated by the model and then we pass this to a super resolution gun in this case it's it's AG and trained within the product called to pause labs gigapixel I'm on the right we have a 378 pixel output and so you will notice here that actually there are some details that just don't exist in the 64 px image but now they actually available in the 378 pixel images it's pretty much like magic and so the neural network here has kind of performed another stage of interpretation wait it has have stages on details that look like it did they fit into to the to the to the result in super resolution image and so this is another example super low resolution on the Left high resolution yes our gun is all to the right so this is one more example one more example of my favorite examples created I guess the only thing I haven't done at this stage is to name them what would be a good name for this guy sad face yeah I'll take out some time and name them and so this is some of the interesting things and so at this point I'm I do have now I have high resolution images and so the researcher to researcher in my head is you know how novel are the images that were actually generated by this mask did it did it really come up with stuff that's new or did he just copy some some stuff from the training dataset did it mishmash stuff together I really want to know and I want to find ways to actually explore you know what what the gun has actually learned and so to do this one thing I did was that I built the tool that helps with algorithmic art expection and so basically what I do is that I use concepts from semantic image search and for each of the generated images I use a pre trained model to extract some features and then using the same pre-trained model I extract features from all the images in the data set that way for each selected image I can then go ahead and say or you know for the for the image that I have selected so for this image that I have selected which was generated these are all the other images in the data set that looked the closest to it and so the good news is that you know I didn't see cases where you know the neural network has done verbatim copy and it actually generated substantially different just not as smooth as clear so what we have in the original data set and so this sort of you know algorithmic algorithmic inspection also enables enabled other things and so it enabled me find you know specific types of modes that the gun had learned and so the in this case it's a blonde mask images so the gunner blends to generate masks that had this oblong shape in some other case it had learned to generate masks that had had like hair hairlike projections and it's in some other places that learn to generate over mass and so this is towards the end of my presentation and there were some reflections on things that I thought were interested in open questions that the right arose as I worked on this project so the first thing that I I think is that you know as algorithmic arts generative art becomes more in popular I think we need more tools that allow us to actually inspect novelty our visual quality of what's being generated and so yes we have AI as a partner that's helping us create art but it's also important that we have metrics and tools that help us evaluate is this stuff really novel if Picasso was alive today would he be disappointed but what we're calling arts not I guess that's that's a discussion for another day and so the second thing that arises frequently is who has agency right and so the stuff that's generated is it mine or is someone gonna sue me some days down years down the line and say oh you know this dog belong to the Machine the generative adversarial Network and so there are a lot of conversations around that my thinking is that the process of curating the datasets is some form of arts and so that only comes from the artists which turns out to be me the process of identifying the right type of parameters that give this really nice cool images that also comes from the artists which turns out to be and then finally who names the arts I I named it and I also kind of interpret and explain what the meaning is to the rest of the world and so I think in this way the artist retains some kind of artistic contribution and the Machine well it's just an assistant and so there's also ethical issues that arise it's important that you know artifacts generated from this project that using the way that's inclusive of its origins the source is where it came from in West Africa it's important to think of best practices around the distribution of these datasets and every other emerging concerns and so for some next steps conditional generation can we say oh you know give me a mask that came from Congo or give me a mask that's from North Africa so there ways to inject this kind of information to the training process so that we can perform this kind of condition generation how can we improve the quality of generated images there's some papers specialty paper on the relativistic guns and so that's one potential approach there and then finally I'm working on an interactive tool for navigating the latent space of all the images that have been learned by this gun so that could be a potential interactive installation and so if you're really interested in this sort of work I actually have some sample code if you go on on github you you can get your images the code will actually help you generate TF records from the images and it will help you generate a 64 px or 128 px again that generates these kind of images and so I've written some blog posts and also this already all algorithmic art inspection interface and you can find a lot that day thank you [Music] 