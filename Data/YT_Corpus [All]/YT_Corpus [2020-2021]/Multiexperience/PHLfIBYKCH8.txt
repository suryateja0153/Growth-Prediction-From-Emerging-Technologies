 Good afternoon Good afternoon Pola Borkiewicz Piotr Maj we would like to welcome you to our presentation AI in XR and the Human Aspect. Firstly, we would like to explain what we refer to when we use terms such us AI or XR and why we used them in the title. Then we are going to clarify the crucial difference between human and machine vision Next, we are going to concentrate on the issue of biometric data in its ethical aspect in the context of immersive environments. And also why the matter of biometric data is pivotal in the process of building a new XR ecosystem The final part is going to be devoted to the guidelines developed by the Centre For Humane Technology for designing technologies with special regard for the needs of people rather than users. Aritificial Inteligence plays a key role in the global cultural ecosystem. as it lies at the core of the majority of applications that we use. AI recommends what we should see, listen to and buy. It determines how many people will see our shared content. It helps us make aesthetic decisions when we create media. It's been used to produce movie trailers, music albums, fashion items, product and web design, architecture, and so much more. Historically: the term AI was introduced by John McCarthy in 1956 as the science and engineering of creating intelligent machines. However, AI remains just a concept, and the term mainly plays a cultural role. AI broadly covers a number of domains: Machine Learning, Computer Vision or image recognition Robotics, Deep Learning, Algorithms, Neural Networks Data Science, Chat Bots, Natural Language Processing. Let's take a closer look at the myths related to the concept of AI: AI has Agency Essentially we tend to antropomorphise technology AI is shiny humanoid robots Since the 20s culture has offered us visions of robots from Maria in "Metropolis” to Sophia Superintelligence is constantly just around the corner Silicon Valley evangelists would have us believe that AI is coming soon These claims are unsubstantiated, just as those that AI will solve all of our problems. The term AI has a clear meaning In fact this term is merely a concept, it is blurred. Ethics guidelines will save us and regulating AI, both issues will be elaborated on later in the context of XR Yet another myth is that AI can be objective or unbiased while it is as unbiased as its creators We should bear in mind that AI conveys the values of its creators. A recent metaanalysis of 170 000 publications from 57 prestigious computer science conferences revealed that since 2012 there's been an increase in the number of publications and presence of large technology firms and elite universities at major AI conferences The two main strategies are: an increase in firm-only publications, and firms collaborating primarily with elite universities ranked 1-50 in the QS World University Rankings. Furthermore, the research shows that institutions representing Afro-Americans and those Hispanic-serving are underrepresented at top AI venues. One of countless instances of AI bias is the issue of Twitter's photo cropping algorithm. It generated a lot of controversy recently when it was revealed that the algorithm prioritises people of white complexion, males, but also animals with light fur. XR conveys the concept of a merger of virtual, augmented and mixed realities, all in one experience. Technologies within the scope of XR differ in the degree to which they modify the reality that surrounds us. This is best illustrated by Milgram’s concept of the continuity of human experience from 1994, which takes place on the spectrum between Reality (the physical) and Virtuality (the synthetic). In 2018 Steve Mann and Tom Furness published XR Taxonomy They defined it in the broadest sense as a concept of Cross-Reality or XR. In XR we refer to X as a mathematical variable, which describes potential realities where you replace x with any reality. VR replaces the real world with a virtual one through a simulated experience and detaches us from the surrounding world. AR allows us to experience both the material world and the virtual one adding a layer to the physical reality. MR enables mixing virtual, augmented and physical realities in different proportions. Let's take a quick look at the progress from the flat screen ecosystem to the medium of space and XR experiences. We are now experiencing another systemic change The Gartner Report sketches out the evolution of the last 20 years from the web, through mobile devices to multiexperience. This year, as a result of a number of intersecting factors related, among others, to the covid-19 epidemic a hyperacceleration of technological advancement is taking place which initiates changes in the systems we are operating in. Each of the trends listed entails the implementation of diverse types of algorithms. Top 10 tech trends of this year, according to Gartner, are: Hyperautomation, Multiexperience, Democratisation, Human augmentation, Transparency and traceability, The empowered edge, The dispersed cloud, Autonomous things, Practical blockchain and AI security. One of the key trends among them, Multiexperience, relates directly to the XR ecosystem and immersive media. In multiexperience the traditional concept of a computer evolves beyond a single point of interaction incorporating multisensory and multitouch interfaces such as wearables and advanced sensors. In the future this trend will become a so-called ambient and continuous experience, but currently multiexperience covers immersive experiences that employ Augmented Reality, Virtual Reality and Mixed Reality as well as multichannel Human-Machine interfaces Top 10 strategic technology trends for next year were grouped in three categories: People centricity, Location independence, Resilient delivery Human oriented technologies are: Internet of Behaviors (IoB), Total Experience, Privacy-Enhancing Computation The report predicts an advancement of Multiexperience towards Total Experience We can also observe a shift in the design cycle connected with people centricity. User Experience Design is gradually evolving towards Human Centred Design. The human is perceived more broadly addressing their needs rather than treating them as a mere User. Gartner shows the evolution of multiexperience towards the spectrum of continuity of experience (Ambient & Continuous Experience), which Milgram postulated in his Continuity Experience. The report predicts that by 2025 a systemic change will take place, a shift to a whole new ecosystem called Neuromorphic Computing, a concept developed by Carver Meade in the late 80s. It describes the use of systems comprising circuits that mimic the neurobiologic architecture of the nervous system. Naturally this systemic change is connected with the development of AI and the implementation of dispersed networks such as Blockchain In order to implement large scale AI operations, organisations will need AI engineering, which rests on three pillars: ModelOps, Composite AI, Generative AI The systemic change we are referring to has been evolving since at least 2018, through its current acceleration, and proceeding to its later stages in 2022, ‘25, ‘28 when an immersive Ambient and Continuous Experience based on a collaboration of man and machine is expected. Returning to the key concepts in our presentation, we are now going to turn to the Human Aspect. We will introduce the relation between the human and technology. We are now in a period called the New Normalcy, where we must swiftly develop means of dealing with the crises. It happens frequently with disregard for the procedures we developed earlier. The accelaration of technological progress in the current circumstances is not subjected to critical consideration or a broader social debate. As a result of the restrictions imposed on society we're constantly on-line the Web is our window to the world outside, it fills most of our days. Operating simultaneously in physical and digital realities is our first-hand experience. The term Digital Dualism was first introduced by Nathan Jurgenson in 2011. It refers to the fallacy that the internet is a separate, virtual or digital, space. Jurgenson states that, although digital dualists believe that the digital world is „virtual” and the physical world is „real”, the digital and the physical are inextricably interwoven. What eludes our human perspective is the fact that the digital is founded in the material, which means it is embodied and real. Digital dualism is, in essence, the hybrid reality that we exist in on a daily basis. The entire XR ecosystem is a hybrid of different realities on a spectrum from the physical to the virtual, as we mentioned earlier in our discussion of the continuity experience. An instance of hybrid reality is the Spatial platform which enables a form of discussion that more closely resembles office environment thanks to the use of such features as spatial sound localisation as well as the ability to work in a common space and use the same tools. The key feature of this platform is that you can use it on a variety of devices. You can use it on a VR/AR/MR headset as well as a smartphone or a PC. It is a truly cross-platform solution. Infinite Office, despite having a number of functionalities similar to Spatial, restricts the experience of a workplace to just one ecosystem – Oculus which in reality means only to the Facebook platform. Having introduced the key concepts, we will now turn to the misconceptions surrounding human and machine vision. Outlining these differences is an essential starting point in designing a new ecosystem. Computer vision, or image recognition, is the ability to process images using machines. It allows for classification of images using calculation methods. How does it work in practice? In order to correctly recognise what an image shows, some basic „knowledge” is required. People acquire the knowledge necessary to recognise and understand images throughout their entire lives. The process of machine learning consists of compiling databases that contain the necessary rules and object features, which is expert knowledge and empirical data. A good example of machine vision is Google TeachableMachine where users can help the Google algorithm differentiate between objects in photos and videos. Antonio Somaini, a film studies scholar and a researcher of the cultural role of the differences between human and machine vision outlines in his text Machine Vision in Pandemic Times the transformation that the meaning of the words „seeing” and „image” have undergone in parallel to technological advancements. What is “seeing” when the process of vision is reduced to the acts of identifying and labeling, and when such acts are entirely automated? And can we still use the term “image” for a digital file, encoded in some image format, that is machine-readable even when it is not visible to human eyes, or that becomes visible on a screen as a pattern of pixels only for a tiny fraction of time? Machine Vision in Pandemic Times analyses the political and social aspects of machine vision via the optics of media archeology tracing the entire history of the „mechanical eye” from daguerrotypes to the heat sensitive cameras deployed during the current epidemic. The author posits that many novel forms of „algorithmic gaze” are still waiting to be discovered, but he also advises resisting the temptation to perceive the deployment of machine vision systems as yet another step towards mass surveillance. One artist whose works Somaini frequently references is Trevor Paglen Paglen traces the ways in which the convergence of aesthetics, industrial design, and politics influences how we see and understand the world. He tries to de-naturalise the assumptions built into these systems, and prompt us to consider what—or who—they’re serving. In his own words: "The majority of images are made by machines for other machines, with humans rarely involved. If we want to understand the invisible world of machine-machine visual culture, we need to unlearn how to see like humans. Going back to the subject of XR, this year clearly indicates that film production is undergoing virtualisation. The virtual production process of immersive and film media is currently undergoing unification and democratisation. The production of films and new media is starting to use the same tools to manage projects and the production processes at each stage: pre-production, production and post-production. Game engines such as Unreal and Unity are being used to generate content in real time. They're becoming the basic work environment for film and XR production. Here we can take a look at the technology used during the production process of the Mandalorian, a series which - despite the restrictions caused by the epidemic - effectively employed the potential of new technologies in production process. When Steven Spielberg was filming Ready Player One in 2018 he was already relying on a game engine to create the environments in which he used a virtual avatar to plan shots, but he also used VR headsets to help actors perform scenes that took place in virtual reality. Technologies such as AR Wall democratise access to technology and are becoming available to people outside big Hollywood production studios. Another element of the new ecosystem is GAN. Generative Adversarial Network technology was created in 2014 by Ian Goodfellow and his team. GANs help create images of people, objects or scenes that did not exist before, or modify images with features they did not have. GAN essentially uses the architecture of a neural network more its structure than its architecture where the generator is connected the discriminator. The generator is penalised for generating fake data and the other model is penalised for generating quality data by the generator In a way, these models are pitted against each other as they perform their distinct tasks. The developments in the field of GANs can be followed on the Two Minute Papers channel. Here you can see an example of a network trained to generate human faces from sketches. And here, you can see an example of pictures being generated from sketches, using a network trained by NVIDIA. Within the range of tools employing self-learning algorithms we can also find algorithms that generate text/language, such as Generative Pre-Trained Transformer 3. Using an initial input sentence, GPT 3 generates text in a given style or genre, and can mimic the style of specifif writers. In the context of film production these algorithms have been used to create scripts and literary text for movies. One of the threats resulting from the level of complexity of algorithms such as GPT-3 is their ability to generate misleading news or messages (fake news) Since people are not able to recognise machine generated content as well as other machines can, a new algorithm was created called the Giant Language Model Test Room (GLTR). Here you can see an example of how the algorithm predicts the probability of a consecutive word from the context applied to David Foster Wallace’s „Infinite Jest”. Green words are the easiest to predict, purple ones the most difficult. Another example of the use of deep learning algorithms in creating media are algorithms that compose musical pieces, such as AIVA. This algorithm is able to compose a piece in a selected genre, but also analyse an uploaded track and create a new one with a similar emotional impact. It also has a plagiarism-checker. Three features that the creators are working on are: a musical ear, the ability to compose directly for a full orchestra, and the ability to analyse a script of a film or a videogame, extract thematics and emotions evoked in a player or participant, and create a track enhancing required emotions. AIVA is also the first algorithm to be recognised by SACEM, a French organisation that protects the rights of composers. The public has been slowly recognising that the world is a complex system and that we need new tools to understand its complexity. New technologies are able to provide us with such tools so long as we are able to recognise and take advantage of their potential. A person whose name needs mentioning when discussing representations of complexity is Hartmut Koenitz, professor of Interactive Narrative Design at HKU University of Arts Utrecht and the president of ARDIN Assosciation for Research in Digital Interactive Narratives He posits that the traditional narrative forms that we rely on to understand the world around us are no longer able to convey its complexities. In his words: Interactive Digital Narratives are systemic representations of complexity that can promote critical thinking and are a key element to have a discourse on the complex issues that we are dealing with. Koenitz proposes the use of Interactive Digital Narratives that combine the comprehensible form via narrative while preserving the complexity in a bigger dynamic system. To quote his words again: "Traditional representation provides an opening for populist/extremist propaganda in its inability to contain competing narratives. Let us now turn to the matter of ethics. The Social Dilemma tackles a number of acute problems caused by the design of the technologies that we rely on in our daily lives It sheds light on the positive and negative consequences of using social media. However, there are certain simplifications the responsibility seems partly to be shifted to the users, no conclusions are drawn from the addictive mechanisms of the design Most importantly, it fails to tackle the issue of the oppressive business model, the monetisation of the activity of the platform's users, the unpaid work that we do under the guise of entertainment. Using social media inevitably involves leaving a digital trace. A selfie taken today can tomorrow become a part of your biometric profile. We are living in the times of surveillance capitalism, as Shoshana Zuboff writes in her book by the same title. In this system the prevailing business model is monetisation of the time spent using technology. One of the most famous researchers dealing with human behaviour within digital environments is Michal Kosinski. Kosinski in 2013 published a paper in which he proves how accurate algorithms are at predicting a range of highly sensitive personal attributes. This research was based on a Facebook patent from 2012. Your biometric data is your personal information that is a result of the specific technical processing of your physical, physiological and behavioural features and can enable or confirm your unique identification. It is also referred to as your digital fingerprint. The range of personal characteristics that qualify as biometric data includes: posture, gait the way we hold and handle devices, our vocal patterns, our pattern of typing on a keyboard or a phone, the unique way we operate a mobile device, or move a cursor Research shows that we can identify people based on their unique patterns of body movements and interactions within virtual environments with very high accuracy. We refer to such unique patterns as your kinaesthetic fingerprint. One of the people who have played an immeasurable role in the discourse on ethical issues in technology is Thomas Metzinger, a German philosopher who researches ethical issues in designing new technologies. In 2016, together with Michael Mandary, he developed Recommendations for Good Scientific Practice and the Consumers of VR-Technology which shed light on the potential but also on the threats that VR environments might pose. Thomas Metzinger was also a member of the EU High-Level Expert Group on Artificial Intelligence where he developed ethical guidelines for Trustworthy AI. Metzinger proposed the term ethics washing to describe the practice of organising and cultivating ethical debates to buy time, to distract the public and to prevent, or at least delay, effective regulation and policy-making. Another example of ethics washing is Facebook's policy on privacy in developing XR ecosystems. Nathan White, Facebook Reality Labs’ Privacy Policy Manager for AR & VR, claims that what matters to him more than the legislation is the decision of the community as regards what is going to be considered sensitive data and how it should be handled. The problem is that most Facebook users are unaware of the significance of data that will soon be at the disposal of FB. Furthermore, with no legislation in place, nothing is going to oblige the tech giants to comply with good privacy practices. A splendid instance of grassroots activity in the face of inaction on the part of tech giants regarding issues relating to centralisation is the Real Facebook Oversight Board. Comprising members of academia, researchers, and human rights activists, the group was formed to criticise and discuss the role of the platform in recent US elections. The RFOB was set up in response to the complete inactivity on the part of Facebook Oversight Board formed by Mark Zuckerberg last November to address the issues of content moderation. Facebook declared that its Oversight Board would not act on any content-related matters until the end of the elections. The Real Facebook Oversight Board and numerous other activists and thinkers such as Douglas Rushkoff approach the issue of ethical technology as a requirement of the New Normalcy. Let us now take a look at the guidelines of the Centre for Humane Technology and try to work out how to employ new tools at our disposal to design humane ecosystems of immersive media. To cite the humantech manifesto: „We envision a world where technology is realigned with humanity’s best interests.” The Centre for Humane Technology works at the intersection of human nature, technology, and systems transformation. Their goal is to shift the mindset upon which persuasive technology systems are built. The purpose is to use that process to support crucial parallel shifts in our larger economic and social systems. We recommend that the designers rely on the elaborate guideline developed by the Centre, a set of recommendations and suggestions while designing solutions for the new immersive XR ecosystems. The humanetech guidelines identify 6 domains in which human nature is most sensitive to the impact of new technologies. The first category is human emotional needs in contact with technology. What is analysed here is the relation between the physical and emotional. Factors that have a detrimental impact on our emotional state are: stress, sleep deprivation, anxiety, exhaustion. Applications constantly monitor us and send us notifications. They are designed to make us stare at our screens for as long as possible This happens to the detriment of our rest, sleep and attention span. The question we should ask ourselves in the design process is whether the project provides peace, balance and safety and whether it supports our circadian rhythm. The next category is attention: how and what we concentrate our attention on. Every day, countless stimuli compete for our attention. It is overloaded and fragmented, inessant notifications break our concentration. Switching between activities, contexts and plots comes at a high cognitive cost. It takes about 23 minutes to regain our concentration after a distraction. Current technologies compete for our attention. Their design is based on research into human perception and it is meant to hack it. Recommendation algorithms absorb us, trigger endless scrolling through content, creating a behavioural addiction based on a reward pathway. Algorithms promote emotional reaction by positioning content so that the information landscape is rife with extreme emotions. Does the tech you design encourage concentration and mindfulness? Another category is making sense of the reality that surrounds us. How we integrate what we feel with what we know. We are surrounded by information based on extreme emotions. The content is simplified and sensational. Information is out of context, misleading and manipulative. Recommendation filters effectively restrict our perspective. Virality equates credibility. A lie repeated a thousand times becomes the truth. We are unable to differentiate between meaningful content and ads. Does your technology promote analysis and critical thinking? Is it directed at encouraging education and knowledge acquisition, development and expression? The next category is decision making. How we align our actions with our intentions. Intent and agency are not supported by tech designers. We are stalked by ubiquitous ads and user-profiled notifications Push notifications are designed to attract our attention and elicit a reaction. Our needs are secondary to mechanisms prioritisng our previous choices. Does your tech promote a sense of agency and purpose? The next category is social reasoning or social inference. How we understand and navigate our relationships. Our status, relationships and self-image are manipulated and imply obligations. We quantify our social status. Technology facilitates hiding behind profiles or avatars and impersonation. Information is virally shared within our filter bubbles. Does your tech allow for the creation of safe and authentic relationships? Group dynamics. How we act within larger groups, how we perceive our status and share understanding. We are excluded, polarised and mobilised through anger and fear. Nuance and subtleties are drowned out and suppressed. Ad hominem and hate speech are omnipresent. Technology facilitates viral spread of hatred. There are no commonly agreed-upon norms. Does your tech promote cooperation and allow for a sense of belonging? We hope that we have managed to outline the role of the humane design of immersive technology. We would like to thank you for your attention. We want to thank the organisers of the conference for the invitation. We’re hoping that more and more people will join the cause of ethical design of tech in the times of the New Normalcy. Links to the materials used in our presentation can be found in the description below. Translation/subtitles: Piotr Maj Correction/naturalisation: Artur Barys 