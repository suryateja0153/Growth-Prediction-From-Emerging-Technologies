 good morning everyone and welcome to all  of you were connecting to our debate on   emerging technologies artificial intelligence and  supercomputing after yesterday's debate on the   european data strategy which many of you joined  today we'll discuss the state of play of ai and   its applications in europe also in the light of  the pandemic and not the state of play of super   computing which seems to be what will empower  a new generation of ai and position europe in   the global tech race today's debates co-hosted  by mep's pilar del castillo and eva kaili both   leading meps in digital policy welcome to both of  you as you know pilar is the chair of eif an mep   with the epp group from spain and a member of the  etre committee among god things eva is an mvp with   the s indy group from greece she's a member of  the etre committee as well and among other things   the chair of stoa the european parliament's  science and technology options assessment body   today we're also joined by prominent speakers  um who are experts of ai and super computing   i give a warm welcome to all our speakers  starting with lucci lacioli director   of artificial intelligence and digital  industry at digiconnect european commission we're also joined by dr rubin cto at the ascent  computing business of huawei to dr alessandro   curione head of ibm research in europe and  director of the ibm research lab in zurich and last but not least dr jacques bougain  professor at the salve business school ceo   at the macaon advisory advisor at fortino  capital and venture cap venture partner at   antler i hope i didn't forget anything  thank you all very much for joining us   this morning we expect over 80 participants  connecting with us today including members   of our forum of course but also representatives  from eu institutions as always after listening   to our chairing meps and to our speakers there  will be an exchange of views with the audience   which will take place in the q a session  you'll only have to click on the button   that you will find on your left hand side to  join the q a session when the time will come   or otherwise uh click on the link  that will share in the chat box   when when it's time we're now ready to start pilar  rene but the floor is yours over to pilar first   say dear colleagues and eif members and members  of the panel which we have as we used to have a   really outstanding panel in this occasion as well  thank you very much to you all for being with us   in today's debates on ai and super computing  and we are all very much aware that artificial   intelligence is not an entirely a new concept  and that it is due to the current massive set of   digital data together with today's sophistication  of processors that is economic the economic   potential of ai has never been bigger from this  perspective it is clear that europe must move up   again and ensure that data can flow across sectors  within u-wide common and interoperable data spaces   however europe must also promote investments  in next generation tools and infrastructure   to store and process data this is precisely the  objective of this morning's debate to stress   the link between ai and computing capacity  obviously we can not have one without the other   and consequently we must focus on reinforcing  capacities in high performance computing indeed   it must no longer be acceptable  that while the eu currently consumes   one-third of high-performance computing resources  worldwide it provides only around five percent uh   of it uh pushing them there's a miss scientists  and engineers to turn massively to computing   resources outside europe uh this is why the  recent european council conclusions of the 2nd   of october are very welcome not only because  at least 20 percent of the funds under the   recovery and resilience and facility we made be  made available for the digital transition also   because the european council expressly indicated  that these funds should help advance objectives   such as for seeing supercomputers in this  context my expectations for today's debate   it is to highlight the importance of super  computing to fully exploit ai and to take stock   of what is happening at the global level as well  in this debate we have as i said excellent panel   very interesting uh people working on this  sector from different perspectives and i am   absolutely sure that will not be disappointed  and thank you very much for your attention thank you pilar the floor is yours eva over to you  thank you so much i want to thank you first maria   for managing to work with eaf so well besides the  the challenge that we face with the pandemic and   also um my colleague pia castillo because we were  we managed actually to top the the digital policy   in the parliament and i think this is because  we also have the understanding and we connect   to what's happening in the market what citizens  are scared of or worried about at the same time   we'll try to translate that into into politics  and legislation so we have um excellent   speakers to discuss i think a bit more on the um  different sides on the technical and operation   how the how the commission is going to work and  actually they've been working quite hard during   the summer that we have um i think an analysis  of the ethics that we need to um to understand   and all the social challenges that we might face  and of course we do have the geopolitics of new   technologies because after the pandemic we realize  that these global challenges that we face we can   only respond to them again globally with of course  decentralizing um the solutions um i see the info   and the biotech now are being accelerated this  pandemic has been a catalyst and we have to   invest both in software and hardware in order to  achieve the maximum capacity and capability to use   these technologies to produce very fast treatments  because we will use the proper data in order to   understand the pattern of a disease and i want to  start with an example of of the problems we face   so you know ac dc is the the european center  for disease control and prevention of the   european union actually having in their hand 80  percent of the data of what happened with covid   from from eu the problem that they had was like  we didn't have common standards so the data   they gathered they were completely different  all the data sets they could not be combined   um there was like not not enough time to be  able to set the standards from the beginning   um they have data from uh the media different  different kind of sources so in the end these   data are not super useful for scientists and this  is why actually it's taking too long to understand   how this disease is working um having also super  computers uh in place would mean that we would   have the capacity to um to get more data and move  more fast into understanding uh the solutions   with different metrics with plenty of metrics like  environmental um if we had health chronic diseases   and also even the dna of each person that managed  to overcome or not this disease so what we're   trying to do now in um in 2020 and 2021 um would  be um to develop a strategy holistic strategy   on ai and you saw the white paper and how we can  set ethics by law and by design secondly we have   to decide about the data governance which actually  means and then i like the commission's approach   high risk and low risk high risk we need  extra safety guards because we don't want   access to our private data um we definitely need  smes and startups to have access to low risk data   in order to create like innovative solutions  and and create like a better ecosystem where   competition can actually work and we just don't  just have the big ones taking over and and finally   we have digital finance because cross-border  payments were was also a big challenge during   this pandemic we saw the problem with supply  chains we saw the problems inside our digital   single market we still have shortcomings to um  to manage to overcome and barriers to remove and   of course we we have the um we have the industrial  strategy this means we have to definitely invest   into hardware made in eu so these are the main  challenges trying on the same time as i said   to go and follow the the principles and the  fundamental values that eu has so we cannot   compromise privacy to have safety if you remember  the discussion about contact tracing apps we saw   that people were ready to give up their  privacy in order to remain safe so the   location their health data everything i think  that our responsibility as european politicians   and also what differentiate us from us and  china is that we don't want to compromise   privacy in order to have safety we can have both  gdpr was our compass to the to the right direction   so in the end um i'm i've started the understood  the sensor technology committee the center for ai   so we're going to try to work with oecd ieee  even yuan to develop data standards because   imagine if we have access to good quality  of data uh not just in eu but beyond   i think um basically we're following what g20  was trying to do and we don't want to um we don't   compromise actually we want to be the ones  leading by as i said by our european values   how we want to design our future and what are the  uh by default aspects that we want to have inside   the algorithm so an algorithm is just an equation  where you decide the metrics uh and you decide   how many how much data you will put there so  the quality is very important in order to have a   solution to a problem but if you manage to achieve  super intelligence then you might even have   an automation of the decision making process so  you understand that we we have definitely to avoid   having harmful ai getting out of control and  this is what people are worried mostly about   so finally we are investing we are  ready to invest a lot i worked on invest   you file also on ai infrastructure and i  think we have a very good understanding   of what we have to overcome as i said we have  we have to harmonize our market and we have to   develop furthermore the ecosystem with digital  innovation hubs um skills uh uh for for everyone   and to attract also talent and this would help  us also create create jobs and um we need to um   to be able to move really fast because this is um  again a global race and what we want to achieve   is to influence an impact with quality so  i think these are the things we we also   discuss with our excellent uh speakers very strong  industries uh quite controversial discussion the   last time and uh with an excellent uh world-class  thinker i i would say zac so uh maria said i want   to take more of the time because i think we  can have a very interesting q a to follow thank you very much uh eva and thanks to both uh   yourself and pilar for taking the lead on these  uh issues as mep's and for opening with the   very clear messages i would like now to  bring in the european commission with   the floor is lucilla thank you thank you for  inviting me to uh to this event on ai and   and super computers and i think it's  very important to to notice this um   let's say um fusion or um uh you know getting  together of this uh two technologies now it's   not new because uh this generation of ai has  really merged because of the improvements in in   computing power on top of you know many more data  being available but the computing requirements   are very very important for ai and are very  important also for the next generation of ai   which is going to be increasingly uh based  on maybe very large sets of unstructured data   so um nowadays supercomputers are used for ai in  particular when it's about making simulations or   making model based approaches to very very  large databases with many many variables   and this not notably happens in particular  in the area of healthcare or in the area   of environment because the meteorological datasets  for example are also very very large it can be   used for example for for cities for making urban  life much more sustainable and managing traffic   and and managing many other aspects that are  relevant to to our urban life so i think that this   you know the capabilities of running ai  on on super computers is going to bring   increasing benefits of course you don't need  super computers for every application of ai um but   i think that even if we will not need a super  computer computers certainly we will need   increasing faster uh processors also for other  applications that are not necessarily super   computers but if you think of ai embedded in the  car or ai embedded at the edge in manufacturing   companies these ai will need higher computing  capabilities and therefore processors with   higher capabilities and certainly also more  energy efficient because all this processing of   data is very useful but it is also uses a lot of  energy and so we have to come up with more energy   efficient approaches from this point of view i  want to remind that you know sometimes people say   but maybe ai didn't really help in the kovid and  we have just been mentioning the kobe the pandemic   but i want to remind exactly in this session  we are having that actually an application of   ai into a supercomputer has helped an achievement  that was made in the european union and by the way   uh also on the basis of european programs because  the eu funded escalate for ceo v project started   in march 2020 combined supercomputing ndi to  identify the drug candidates that could help   in curing the kovid and so there was a ultra high  performance virtual screening platform that took   more than 1 000 existing drugs and screened them  against a very large chemical database with more   3 million molecules per second so this is the kind  of processing that supercomputers can do and the   result of that is that there were seven thousand  molecules pre-selected tested again in vitro   and then we came up with raloxyfan this is a drug  that is already used nowadays for osteoporosis   and it's a very promising molecule that can be  used for treating covalent 19 patients it's not a   vaccine it's a cure and um but while we're waiting  for the vaccine of course this search for drugs is   very very important and super computers as we  said earlier with ai are very useful for that   then ai in kovid has been used in other ways it's  been used for reading ct scans so medical imaging   identifying through ct scans if patients were  infected with kovid or with other pneumonia the   extent of the infection and so on so ai is not  being the solution to kovid it's not a vaccine   but it has been used in many different ways to  be able to fight covet including in the tracing   apps excuse me um i i then would like to um  conclude that simply remembering that the european   commission is investing in the next generation of  supercomputers we have a joint undertaking called   eurhpc with member states and industry where  we invest in supercomputers in the european   union we already started reversing the trend and  having in european soil some of the most powerful   supercomputers in the world and we are now moving  towards the exascale supercomputing so your hpc in   the next multi-annual financial framework will  be very important from this effect and we also   invest in ai in that context as well as we invest  in ai in a dedicated public private partnership   so these are our investment in research and  and in deployment as well and we will also be   looking at the regulatory framework like  eva said we are interested in a trustworthy   approach to artificial intelligence and we  will come at the beginning of next year with   a proposal for a regulatory framework for  human-centric artificial intelligence based   on requirements that have been already  proposed in the white paper thank you very much thank you very much lucilla for this very  interesting uh update and now i would like   to bring in the industry sector perspective  with bin and then followed by alessandro   being over to you hi uh can you hear me very  well yeah okay great and uh hope everybody   is well durian is pandemic and yeah i agree with  previous speakers with that ai is helping fighting   kobe and we see a lot of cases especially in  china we are using ai in hospitals and in public   health sectors to fight with the calling pandemic  and especially we are seeing the trend of ai and   hpc are converging especially the new applications  are using ai capabilities to solve the traditional   supercomputer problems however this will present  a lot of challenges for our computing architecture   i will think from the fundamental technology  part that for solving those kind of   huge challenges of computing requirements  uh which will require that we reorganize the   fundamental computing architecture especially  from the processing elements part because   the ai processing pattern is different we  see that ai especially uh deep learning   require different processing pattern with  traditional super computers and the traditional   is designed for massively parallel processing  architecture however ai especially deep   blending is a tensor processing and those  kind of different processing requirements   will dramatically change our supercomputer's  architecture and as while we especially industrial   we are redesigned the whole processing  architecture from scratch up and we can see that   we are using uh a different processing cars with  traditional cpus to build our ai supercomputers   and those will require a lot of investment  and also the processing software stack   and algorithms and the rent temps compilers  debuggers all the tools will be rebuilt   and this will help the industry and also  the academia and researchers to facilitate   their ai researches so and we can see not only the  super computers but we see uh the cloud with ai   and because we are using the cloud capabilities  to process super computer problems and also   the furion of cloud computing and ai computing and  supercomputer and we see those kind of trends in   technology also we see the collaboration between  cognitive computing and edge computing because   if ai want to help improve our industry and  society we need to put air computing capacities   to edge computing environment and this will  dramatically change the society and we see   that we can use robotics to help moving goods  during the pandemic instead of using people to   avoid contacting each other and this will help a  lot of uh fields and also the privacy and we see   ai is a new technology and we can because there  are lots of data invoked and and this will um   this will read the risks of the privacy problem  so we need to use the technologies to protect the   privacy and also the safety of our data and  we are developing different technologies for   those kind of uh uh targets for example  we are using encryptions and also the uh   privacy protection technologies for trusted  platforms and also other technologies for   helping to protect the data privacy and also we  require standards because there will be different   data formats and data streams and algorithms  and even processing architectures we need   a unified standard for uh interoperability and  collaboration between different sectors and also we think there will be more  investments for ai applications   with supercomputing because we see the  trends of ai merging with cheaper computing   and we urging that different uh different  sectors uh who will invest more in these fuels   and as long as we invest more in these fields  and this will help to improve uh the researches   on ai using supercomputer capacities also uh worse  worthwise we can use ai to solve supercomputer   problems and we see ai is the next exact skill for  supercomputing and we see it is not a trend it is   the reality right now and we see different  countries are investing in this sector very   heavily and not only the us but also china and the  european and so uh so we will we will see that ai   together with supercomputing will create a new era  for computing technologies and in the industrials   we are developing also can new technologies for  supporting those trends and so uh we believe   that ai with emerging supercomputer technologies  we all bring a new better world together thank you thank you very much for sharing   the technology challenges but also the  opportunities that we have ahead of us   i would like to give the floor to alessandro  now over to you alessan good morning everybody   i would like to share a presentation that will  help me to convey my messages give me one second okay so i'm very very happy to to  be here and discuss about artificial   intelligence supercomputing look what  has happened right with this coronavirus   crisis that has been one of the  worst crisis that we had in the   last 100 years this created really a wake-up  call for us right because we do have all   these uh exponential technology that we do  believe we should invest right and this crisis   is telling us we have to do better or now we bring  together all these things really to help us to   uh solve and tackle crises like the coronavirus  okay we understand that you know we cannot wait   10 years and invest 4 billions to develop a  single drugs to solve a single problem right so   this crisis is telling us to all of us that  we do need really to create a new approach   to acceleration tv discovery and we have been  saying right in the past decade that super   computing simulation and ai can be a solution of  these problems but we have to do things better   and one thing that i want to make sure that  everybody understand ai is one superpower   powerful instrument but is only one part of the  solution as we have said right in order to have ai   a solution right we need to create the right  ecosystem that include you know the data how   we we can bring together all these data how we  can share this data to the scientific community   and also to the business community when it's  needed but while protecting properties and   privacy okay without the proper data sharing  mechanism at the output of ai is limited okay   another thing that we need to do is we need to  further develop ai and how ai go together with   the scientific method right bring more rigor on  ai you know the approach artificial intelligence   plus data equal a solution if we don't make  more rigorous right as limited application and   then the last piece it is very important that we  develop a proper infrastructure that is able to uh   empower ai in the proper way right and also  keeping the sustainability of the investment   right the infrastructure needs to allow us to  run artificial intelligence on data much better   and the last point that in my opinion is very  important to share with each of you is all these   needs to be embedded you know a new concept of  community of discovery working together to take   all these problems it's not something  that you know can be handled and taken   from a single country a single institution  but for some of these problems while you put   all these things together we have to find better  way to work together and let me speak two minutes   about method infrastructure i told you that  ai needs to be better embedded right on   scientific method than the scientific discovery  process you know it's uh important to have   method infrastructure that allow us to extract the  knowledge that is is available around the subject   to augment eventually this knowledge through  simulation okay and then use ai with the new   methods for example generative model to create  hypotheses right around a certain problems   and to search a solution and then again ai can  can help us also to accelerate the testing of   our hypothesis so in other words supercomputing  in the eye can help us if we do things right to   overboost the scientific method that is what we  do need now okay to do that we do strongly believe   that yes we have conventionally approaches that  were coming from conventionally supercomputing   but these things has to come together and  fuse right with new approaches on computing   that make you know artificial intelligence  algorithm implementation more sustainable   and eventually also convergence with uh quantum  computing all these right eventually delivered   with a platform that allow you know application  to be run in a seamless way in a very very   transportable way and with the maximum interval  or interoperability okay so these two things are   must for us in order to really accelerate  the impact of ai and super computing the   last things that i want to spend few words is  this concept of community of discovery to me   even if we have an infrastructure even if we have  the right algorithm right even if we make the full   things more rigorous without collaboration scales  all these infrastructure and approaches will not   get you know impact to scale and example and this  covid strongly accelerated this is possible to do   it think about a community of discovery like the  kovid performance computing consortium generated   in united states we have helped to create these  but then you know developed worldwide 80 projects   uncovered 40 consortium members or a similar  initiative and by the way they are collaborating   that were put together in europe exactly  to bring simulation and ai right in the   right ecosystem to solve the problems and in this  particular case try to find a solution for kovit   a few examples here they've already been mentioned  by you know drug repositioning 1500 already   fda approved the drug drugs okay 7 000  that are in the process to be approved   using ai and super computing we have demonstrated  that we can go from this number to few and then   if we have the right ecosystem eventually  go to rapid testing okay but all these only   uh possible if we are able to create this concept  of global collaboration and i finish saying that   you know if we are able to do this this is  not going to solve only and to take all only   the covid problems but for example will help us  as you can see in this list that we are trying   to push this from the company to solve many  other problems that we do have in our world   and uh i stop here thank you for  for attention thank you very much   thank you very much alessandro for your  presentation and the very clear messages   that you shared with us i would like to bring in  uh jacques now for the last uh speech last but   not least of course over to you jacques i'm gonna  say thanks so much for inviting me and uh uh i was   going to present a few slides i don't think i will  do so i will try to uh elaborate a bit more about   the points that have been made so far which by  the way i i find extremely powerful and i uh fully   agree with most of them but i will try to make  three messages here the very first one is that   whatever happened to the coveted or the  ai power of some of the algorithms the   point that we need to remind us is that we  are at the moment at the tipping point of a   moving into a real fundamental knowledge economy  and that part line by itself it's no way out   and that means it takes times to build roma  it will take time to build all the elements   the building block to make sure that we are  full into the knowledge economy benefits   uh that we want to see but i'm very optimistic  that this is something that would be for the goods   the point number two i want to elaborate on is  that a proof that this is possibly more than a bet   is that there is a global race and everyone is  trying to take a piece of that new architecture   that new value chain to make sure that they  can benefit from the knowledge economy and   that race today has been a race which maybe  we think that europe is not necessarily   good at but i would say that the fundamental  question is not that the question is that in that   race is the race fair enough to make sure that  everybody's can benefit and i will argue it's not   this is the case at this stage but three uh i will  also make a point about europe because actually we   we're talking about europe at this stage i will um  don't i don't think we should be negative europe   as multiple paths for the future we can actually  benefit substantially and be a major player into   uh the ai uh slash super computing game so  let's go to each of these points one by one   the very first one is and i think it has been said  very well uh from uh or represented from ibm we're   moving to a knowledge economy and that knowledge  economy uh uh there is fundamental public shift   uh let me take the example of uh economics  because i've got myself a phd in economics   and economics is based on two basic principles  uh which you will see are no longer valid uh in   the future of the ai supercomputing world the very  first one is that we have so many complex problems   in economics the way we solve complexity is to go  at the margin we go always the marginal delta such   that we simplify mega problems and the complexity  because at the margins the linear approximation   is so tiny that you are pretty sure to be good but  you don't solve the problem at the systemic level   and the second axis of economic science has  been testing and in social science as you know   it's very difficult to replicate experiments  so we've got statistical methods that try to go   always to say if you can prove that something  is statistically different from the mainstream   then we can move so you see that with these  two elements of paradigm you solve only problem   at the margin and you only can move on if  you find something which is statistically   robustly different from what you know which with  small data is usually not the case that often so   you are basically in a statical mode in the ai  world you will go for much more complex problem   and you have with big data many replicability that  you can do and that's the power of super computing   that's the poor ai algorithms and deep learning  which is that we are there to solve complex system   we supposed to be very different answers  the answers at the margin and possibly can   replicate and test it now this being said i also  agree with the fact that for that system to work   we're going to need to change a bit of the  architecture this is true today that the super   computing model has been much more parallel  computing to include much more uh power into   a crunching data if you like but we all know that  whatever system we moved on the architecture needs   to evolve uh we've seen that between the pc even  the mobile so obviously if it moves to the ai it   will be the case as well um it also means that  uh uh given the product the pattern change uh   if we think about complex problem uh and we  we think about replicability we need enough   of clean data we know enough of good real-time  data and it requires collaboration and solving   uh issues like privacy uh and uh uh incentive  for people to share and collaborate this data   so all that will not be done in one day but  again the point i wanted to make here is that   we are at the beginning of that knowledge economy  with a paradigm shift that requires that we build   the building block super computing is  one of that ai tools are one of that   data cloud architecture and other blocks of  that and all those blocks needs to work out it   will take time but i believe we are already well  ahead into that fantastic journey for the future   so comes the second point which is where do  we stand today as i said uh let's not look at   this as saying well it's not working as quickly  as we as we think still believe today that the   tens of phases of ai that i've seen are obviously  most of the time very restricted uh but in one way   the gain productivity uh the gaining innovation  system uh the collaboration tools that i've   seen coming from that are so promising and uh  personally i think that the uplift in productivity   coming from uh these knowledge economy tools are  going to be fantastic even if today obviously not   all the cases are working the way we want but most  of the time it's not because the technology is not   working it's because the architecture bottleneck  is because the data is still small data or they   are not clean enough so there's still a lot  of things to solve but it's not from the power   of the ai and the super computing architecture  that we should a claim that is not working is the   missing blocks that are not necessary or organized  to make it work the only issue is that if you   look today in the market that stands this market  which again taking my head as a as an economist   i would say is very concentrated if you look today  and any elements of computer visions ai services   even robotics the effinghall index which measure  the the the concentration level uh of of domains   is in the range for computer vision is up  to 50 percent which means that give and take   two firms globally could run the computer vision  worldwide and then robotic is in the range of 25   which means that four firms global firms could run  that world globally obviously it's the beginning   of those technologies but definitely this is a  power that needs to be worked out at this watch   out now uh phenilenov of course europe is not  that bad he's good in some of the robotics is good   in application of ai services but uh this  is where the market is the less concentrated   and where is not very good at it's in uh you  know a computer vision nlps machine learning   like so which reflects the point that yes we need  to watch out for that control and last but not   least watch out on the way people try to continue  the control and there are basically two ways to go   one way is the patent race and we see for  instance much more asia where patentability   or the proportion of firms making patents is  being extremely high in the range of 60 percent   and is driven also with a public private  partnership then you've got the odx train which   is a standardization battle which is happening  in the us where some of the large players are   obviously obviously patenting a lot of things but  are using the power to de facto creating standards   we talk about tensor tensor processing is  obviously a very good innovation but in the   same terms it can lead to a certain way of  pushing certain type of crunching data and   standardization which at the end of the day  is something to be solved uh having said that   we are the beginning of of of the journey and i  believe that there are multiple european paths   for a future um one still to make a a a point  this is something that europe should do but you   should not miss the boat we've seen that in the  technology race when somebody uh gets it wrong it   get it trunks for a long long time japan in the  80s were extremely good in consumer electronics   didn't overspell overspill that to ai at this  stage except in in the pure robotics china and   the uh and u.s are possibly two uh uh part of  the of the words having uh they saying the ai   let's not miss obviously uh india which are very  young population and actually 70 percent of the   stock of digital talent is actually happening in  india and india is an outsourcing service strategy   uh from which they have outsourced a lot of the  service from the us and from the anglo-saxon   countries so india is not that and possibly will  push that i think say that what are the three   paths that i will finish on that uh what are three  parts europe could do given all that evolutions   the very first one and i think uh most people  from the commission and from the parliament have   already said so but i think that we are sometimes  seen as overly regulating from the europe point   of view i disagree with that term it's about  adequacy of regulations i think the open data   is going to be fundamental to make sure that smps  but also everybody has a playing field to use the   data because data is a probably good lgbt has been  a very good aspect of all you you you you treat   obviously part of the privacy issues so i believe  that expanding on the regulation especially from   the adequacy of the playing field is definitely  something europe needs to do and europe has the   power to do it because the balance today between  excessive patenting and de facto standardization   leads to concentration which at the end of the  day regulation must solve porn number two is   their strategy at the frontier for europe where  we talk already about the fact that europe leads   in super computing i would say it's fantastic i  would also make the warning that watch out super   computing as a parallel programming and computing  power is good but most of the applications of ai   will possibly uh leads to a very different  architecture possibly more at the edge if we   want ai to be successful i think that the point  has been already made but also europe as robotics   is actually having its fair share in my services  so we should continue to push downstream to get   that lead and finally on that path i think  there is no path where ai should be taken   if it's not merged with sustainability and vice  versa interestingly europe can differentiate in   that race because the us is not necessarily  that's in the sustainability game and china   is moving a bit of that but at the end of the  day still a lot to learn from that perspective   and also a thing about the convergence that ict ai  will have with sustainability what i mean by that   is that the sectors that we're lagging in digital  maturity are likely to become much more digital   because of sustainability if you think about  manufacturing which is traditionally lagging   it takes to be much more sustainable and to create  circular economic solutions uh we're going to need   extreme digitization where the full supply chain  is totally digitized to have stimulus open data   flows such as the synchronization of the value  chain exist if you think about the sector like   like energy it's quite evident that energy to be  green will have to go to a system of distributed   grids for instance which requires obviously  an ict layer and last but not least if you   think of sectors that are leading uh on ict they  will need sustainability themselves that's the   issues of how you consume excessive energies in  the context of ai last but not least the past   three that europe can take adequate regulation is  one differentiate frontier strategies another one   the past three is that despite what people claim  we have a very large vibrant digital ecosystem   of startup uh we have 75 of ai services coming  from very young small ai driver driven firms in   europe in contrast it's barely 30 in china because  china is no very large firms possibly with a layer   of public private partnership uh we've got not  only the countries the way that we think about   europe but we have the regions and we see a lot of  regional clusters and connections happening within   the european markets that basically create that  digital ecosystem much more vibrant and last but   not least we start to see an emergence of the vc  industry where there's a new culture of coaching   of digital startup uh i told you that i was part  of an advisory board for foreign capital that's an   example of a of a company that basically created  that vc structure for the bet that the large vapor   and digital ecosystem can emerge europe so largest  at least the point i wanted to take again is that   rome is not done in one day two it's the future is  here we have to shape it and tree europe has a lot   to say and what he has done so far in regulation  in supercomputing or in developing the startup   ecosystem is actually something that needs to  be scaled but it's a promising start thank you thank you very much jacques you gave us a  lot of food for thoughts for sure we will   now move to the q a session where we will  continue the conversation with our audience   as well we will take questions from the audience  and participants now only have to click on the   q a session button or otherwise on the link that  will be shared in the chat box we'll see you there 