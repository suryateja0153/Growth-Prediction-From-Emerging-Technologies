 welcome to this afternoon spark in AI summit general session the resurgence and interest in deep learning can be traced back to record-setting models in computer vision and speech recognition almost a decade ago now deep learning is finding its way into familiar enterprise applications including natural language applications we're lucky to have cam Hazelwood with us today she's currently the West Coast head of engineering at face book AI research and she'll discuss recent applications of deep learning to personalized recommendation systems so give it up for Kim Hazelwood okay thanks so much as mentioned my name is Kim Hazelwood from face book AI research there I work with an amazing set of engineers scientists researchers who are passionate about the intersection between systems and machine learning and today on behalf of the entire team I want to talk to you about an often overlooked space within machine learning and systems first let's take a look at how we got here over the past 20 years we have seen a fairly significant increase in investment in deep learning now a lot of that has come from fairly significant advances algorithmic advances that have really driven new use cases now a lot of those algorithmic advances have been empowered by fairly fundamental breakthroughs at the systems layer be it hardware software systems and then on top of that we now have access to significant amounts of data better quality data as well as the tools needed to be able to aggregate and procure that data so now let's also take a look at the end-to-end machine learning execution flow so we essentially have three stages of the machine learning pipeline we have the data stage we have training and then we have inference in the data stage we're taking unstructured data and structuring it into features and the training stage we're taking those features and determining how much do we care about any given feature and building out better models once we're happy with model we may deploy that out into production or to users and that in and of itself produces additional data that we can use to advance the the models that we've developed continuing the cycle so what I'd like to do is talk a little bit about each of those three stages and the scale at which we're we're facing each of these stages at Facebook so first let's take a look at data so if we look at over the past year the amount of data from our data warehouse that is feeding ml models that went from 30 percent of all data driving machine learning models up to the current state of 50 percent of all data and then on top of that the amount of data that we've had doubles every year so over a one-year span if you're doing the math this ends up being a 3x increase in the amount of data that we're using for machine learning over a single year now if we take a look at training first let's look at people so the number of engineers who are training models is their day job each and every day has doubled over a 12 month span the amount of models that they're training has increased by 5x over that same time duration and then the amount of computational capability needed to be able to power all of that machine learning training has increased by 8x over a one-year span and then how about inference so each and every day at Facebook across all the family of products we're doing hundreds of trillions of predictions across all products these may be translations from dozens of language pairs to other language pairs they may be detecting objectionable content and removing hate speech from our platform or detecting fraudulent account which we which are automated systems do each and every day catching millions of fake accounts so now let's talk about the machine learning models that power all of that all of our products many people have a fairly simplified view of the world when it comes to machine learning where the focus is either on computer vision or natural language processing so we get a lot of questions along the lines of you care more about CN NS or ardennes but the reality is that at Facebook the picture is much more diverse and we have a wide variety of models in use some of them not even in the category of deep learning and in fact if you look across all of the various use cases we have a pretty heavy focus on MLP across all of our ranking and recommendation products so it's that recommendation space that I want to talk to you about today so what are we using recommendation for who all who are using it for all sorts of use cases if you take a look at your Facebook newsfeed or using recommendation to determine from the thousands of candidate stories we could have showed you which ones are you most likely to like and engage with when it comes to stories which is across many of our products we have lots of options that we could have shown you how do we choose which ones are are you most likely to like and then Instagram itself if you're searching knowing what kinds of images do you like to see where this is all powered by recommendation systems so let's talk about the compute footprint that is powering all of those systems so if you look across all training at Facebook over half of it is training recommendation models and then if you look at the deployed models we have in production over 80% of our computational resources are being spent making predictions for recommendation systems meanwhile if we take a look at the research community you'll see a fairly different picture so what we did was looked at the top system conferences for the past five years and took a look at what kinds what areas of NL were they focusing on where what were they designing systems for and there we were we noticed that computer vision really took the cake so most people were working on developing systems to recognize cats and dogs over 82% of publications we're focusing on that we saw 16% of publications we're focusing on natural language processing and then a mere two percent were focusing on recommendation systems so what's going on why is there such a disconnect between what is happening in reality and in production and what researchers are focusing on in the community now before we uncovered that first let's sort of run through what is widel recommendation systems doing from a high level so if you think about the scale at which we're dealing with recommendation systems we're dealing with hundreds of thousands of items that we're trying to decide how to rank in order to make a prediction about what should be the item that we show a given user so we start from hundreds of thousands of candidate items we're sending it through a neural recommendation model which has billions of parameters were then coming up with this ranked list and then that list is going out to users and the scale of users at Facebook is in the billions let's take a step down and take a look at how do those recommendation models work from an algorithmic standpoint so the thing to know about recommendation systems is they're leveraging two different types of features they're leveraging dense and sparse features dense features for all of the continuous information that we have and sparse features for all of the category categorical features and the way to think about continuous features is these are feature these are question that have a concrete answer and then categorical sparse features are a vast number of yes-or-no questions about the user or about the items that we're trying to recommend so the way we represent the continuous features we send those through a density n n n LP like you're You're Expecting when it comes to the categoricals first features there were leveraging embedding tables and this is just a representation of all of the sparse data we then need to take those two different components and integrate and combine them into a singular DNN and coming out of that singular DNN then is a set of predictions across for each individual item what is the likelihood that the user will like this and then we can form a ranked list from that and this allows us to come up with a recommendation for what the user might like and recommend a book or an article of clothing or photo so when it comes to evaluating those recommendation models there's a couple things we need to keep in mind so number one is it's widely known that ranking more items leads to better recommendations therefore from a systems perspective what we want to focus on is very high throughput we want to be able to evaluate lots of different candidate items all at once at the same time there's a user waiting on the other end for that recommendation therefore we have a pretty firm latency requirement so that they're not left waiting for that recommendation to the point where they don't care anymore so the way we evaluate and the way we optimize our systems is that we're focusing on latency bounded throughput now when it comes to how those recommendations systems are hitting the hardware or hitting the underlying systems it turns out there are some fairly unique challenges when you focus on recommendation systems so I'm going to talk about three of those challenges first I'm going to talk about the embedding tables themselves and the stress that that introduces into the system next I'm going to talk about how the recommendation models themselves have a wide variety of features of axes that they will vary and how they execute on the underlying Hardware will vary the performance will vary depending on the features of the specific model and so I'm going to talk about each of these systems challenges in turn so first let's take a look at the embeddings themselves so the embeddings are very large and so these are orders of magnitude larger than anything we're used to seeing if we're focusing on cnn's rms or fully connected layers so there we have to deal with pretty significant challenges to our storage hierarchy and how we optimize for that on top of that because we're dealing with sparse data the computational intensity is actually quite low it's a lot of zeros it's not particularly computationally intensive to multiply lots of different numbers by zeros so the overall flops per byte is significantly lower for embeddings than we're used to seeing and cnn's and rnas and then finally because the the data is so sparse the access patterns throughout memory are going to also be very irregular and this is pretty challenging to deal with from a systems perspective next if you take a look at the models themselves so if we took a look at three different recommendation models that are in at Facebook and it turned out those recommendation models vary significantly in some of the fundamental traits that they had so the across the three recommendation models you would have fully connected layer sizes varying significantly you had the number of embedding tables would vary the size of those embedding tables how often were accessing those embedding tables would vary significantly across three different recommendation models then if we start to take a look at the bottlenecks that get introduced by each of these recommendation models and hone in on the specific operators that where all of the time is being spent that also was varying across different recommendation models to where you can't even just go in and optimize for a very important operator because that's going to be different between the different recommendation models and a lot of that had to do with some of the characteristics of how the recommendation systems were set up and then finally there the sensitivity of those models when it came to how they would perform on the underlying systems this also would vary and it was very sensitive to any minor change we would make like batch sizes would swing which hardware system was better optimized for that particular model therefore it's extremely important that both the model itself and the underlying system are Co designed designed together so that you can optimize for the specific bottlenecks that are going to come into play and that you define your batch sizes according to what the underlying system prefers okay so let's go back to my earlier point about what's going on in the research community why is everybody writing papers about recognizing cats and dogs when we have a fairly important problem on our hands on how to design systems for recreation models and I've already outlined a long series of challenges that need to be solved in that domain so if you think back to what's different about computer vision and an LP domains you'll get a little bit of a clue if you take a look at how they were able to evaluate any new ideas that they had so it turns out one of the key enablers to doing research is having an agreed-upon standard set of workloads and data sets that everyone can agree upon and can optimize for and in the CV and NLP communities we had those but in the recommendation world recommendation is extremely sensitive to the data set and a lot of the data sets are proprietary so this made it extremely challenging to even work in the space so it's not that the researchers didn't think it was an important problem it was that they didn't have the tools techniques and data that they needed so that's why I'm excited to talk about DLR M a year ago Facebook released DLR M this is the deep learning recommendation model what this is is a configurable model where you can change lots of different parameters about the type of recommendation that you're trying to do the ratio of dense too sparse features the widths and depths of your dns all of these can be varied so that you can get a good sense of how sensitive are your systems to the types of variables that will change across recommendation models and so that has been open source it's available on github and then on top of that there's also a industry wide effort to standardize the workloads and the datasets needed to be able to evaluate systems in the ml community and that effort is called ml perf this is a fairly widespread effort across in nearly 50 companies and dozens of universities and the latest release of ml per includes the DL RM benchmark and it also includes a non proprietary data set adds data set that can drive the DL RM model so now we have all of the ingredients that we need to be able to kick-start research and advances in the recommendation community so hopefully throughout this talk I have convinced you that recommendation systems are important it's over 80 percent of what the computational cycles at Facebook are used for also they're under invested only 2% of the recent publications coming out of the systems community or focusing on recommendation systems and at the same time they have a set of unique challenges lots of problems that need to be solved and so that's why it's very important that we're remedying this under investment and that we have more people working in the space and to be able to enable that we are excited that now there are standardized benchmarks workloads and datasets available for the community to be able to leverage ok so thank you so much for your time and if you'd like to learn more feel free to check out the Facebook research website where we have lots of publications the you can download the DL ORM recommendation model from github and you can contribute to ml Perth or compete and the NL Perth competitions thanks so much thank you dr. Hazelwood it will be great to see how deep learning continues to evolve our next speaker is one of the pioneers in the field of digital forensics which now finds itself at the center of the battle against deep fakes UC Berkeley professor Hani Farid will give us an overview of the creation of deep fakes and he'll describe emerging techniques for detecting them please join me in welcoming professor for read to spark nai summit thank you it's good to be here I'm gonna talk today about deep bass it's probably a term you've heard about but before I dive into deep face come on just give you a little bit of history of photo manipulation and media manipulation and and it is not something new and arguably it's we've been manipulating images and photographs as long as photography has been around Stalin for example famously airbrushed people out of photos that fell out of favor but really starting in the 1990s we started to see a revolution in digital imaging and much of that has been driven by digital cameras ubiquitous computing and of course programs like Adobe Photoshop which have made it easier and easier to alter and manipulate photographs and so in this 25-year period we saw this rise of photo manipulation and in 2015 we started to be able to do some pretty fun things with photographs like this where for example we would swap President Obama and Michelle Obama's face and relatively straightforward to do this in a program like Photoshop and we've also started to be able to manipulate videos in the mid-2000s and do things like this one of the conversations I think it will actually yield results before the end of the year and I look forward to continuing this dialogue in the months ahead thank you very much everybody bye around the mid-2000s we've already started to see photo and video manipulation in many cases they were like the two last images and videos that I showed you which is sort of fun um we wanted to be able to poke fun or have humor or spoof presidents for example but since 2015 we've started to see a new age of digital manipulation and that's what we're going to talk about today so called deep face so if you navigate to the website this person does not exist comm true to the name of that URL you will be presented with a face of a person well who doesn't exist so these six people that you see here were completely 100% synthesized by a computer algorithm they don't exist and you can see that they covered race age facial hair glasses and computers can now hold cloths synthesized images and as I'll show you in a little bit video of people who don't exist or people doing things that they never did and this is a bit of a game changer and that's what we're gonna talk about today so let's talk about how this person does not exist works so this is a so called these are created with a so called Gann a generative adversarial Network and here's the basic workings of how it works up in the top you start with a random image and when I say random image I literally mean you drop down a bunch of pixels into an image and that goes into a generator that's the generators responsibilities to create the image of the person who doesn't exist and so it takes that image of random pixels and it hands it to a discriminator and the discriminator has access to images of well people actual people and the discriminators job is to ask can i distinguish that image provided to me from the generator from these images of actual people and in this case the answer is of course yes and so it goes back to the generator and says please try again and the generator makes modifications to those pixels send it back to the discriminator to discriminate X again and it does that millions and millions of millions of times in a very tight loop very very rapidly and this is why it's called a generative adversarial Network generative because it's making something adversarial because you're pitting that generator with the discriminator and network because the underlying mechanism for the generator and the discriminator is a so-called deep neural network and when you run this simple mechanism in millions and millions of iterations it will eventually create an image with a discriminator will look at and say well I can't tell that this is not a person and now you have this person does not exist now we can do something a little bit different with this we can change identities with the same basic underlying mechanism so now let's say I want to change one person's identity in the top-left here to another person's identity let's say steve buscemi so the generators job is to modify pixels in the face hand that to the discriminator and the discriminators job is not is this a person the discriminators job is now to ask is this steve buscemi or whoever's identity you want to swap if the answer is no it sends it back to the gen and again they work in a very tight loop until the generator makes modifications that the discriminator cannot detect and then when you do that frame after frame after frame in a video you get something that looks a little bit like this expected aiming to win so I just like it was just this was very truly surprising for me so what you're seeing on the left is the original video Jennifer Lawrence of course accepting an award and on the right is a so-called Face Swap deep fake or on every frame again a generative ever serial network made the modifications that I was just talking about to replace Jennifer Lawrence's face with Steve Buscemi's face and again the power of this technology is that it is fully automatic you provide the content that you want as original source you provide the images of the face you want to swap and the computer takes over so there's no Photoshop there's no After Effects there's none of the skilled labor that is typically required to do this and so let's look at a couple of examples of the things that you might be able to do with this type of Face Swap deep face machine Obama stole my microphone the department took my microphone to Kenya and they broken it now it's broken somebody sniffing here so of course that's Alec Baldwin on Saturday Night Live and what we've done is replaced his face with that of President Trump's and you can now see the power of this technology in the ability to make it look like one person to saying something or doing something they never did let me show you just one more example listen America Donald Trump cannot be president he would be a disaster a failure a complete F in America you deserve better than an F so on November 8th vote for me and I promise I will be a stone cold bean so those are called so-called Face Swap deep face where you've taken one actor or impersonator and you've replaced one face with another face you can see the power of that technology to impersonate a president a candidate CEO whomever you like now this is a slightly different type of deep fake and I just want to mention it cause I'm going to be talking about it a little bit and in a little bit so let's go ahead and watch this and I'll explain what you're seeing now you see I would never say these things at least not in a public address but someone else would someone like Jordan Peele this is a dangerous time moving forward we need to be more vigilant with what we trust from the internet okay so what you're seeing there is a fully authentic video of President Obama and but what you're hearing is Jordan Peele and the manipulation now is not replacing an entire face but simply synthesizing the mouth to be consistent with a new audio track and again this is a very similar type of the goal is very similar which is to create a video of a person saying something they never did but the underlying mechanism is slightly different because we take an original video and modify only the mouth and the speech these are so-called lips ain't deep face and so we're where do we worry about this type of technology obviously lots of fun things you can do with it they're highly humorous and for political commentary but there's also a darker side to this technology and where we are seeing the biggest harm today is in the form of non-consensual pornography taking one person's likeness and inserting it into sexually explicit material and then distributing that on the Internet and that is probably today them the most common use of DFA technology which again is yet another example of the weaponization of technology against women and something that I think we need to get a handle on coming up into the 2020 elections here in the US we are very concerned about misinformation campaigns in all forms and one of them is in the creation of a video of a candidate saying something inappropriate or offensive and how that might affect an election obviously in the courts as we begin to rely more and more on digital evidence can we trust body cam footage can we trust surveillance footage can we trust footage skating from an iPhone if that footage can be manipulated how do we get our handle on evidence in courts of law there are huge national security implications when we rely on video of events happening around the world to make life-altering global decisions and of course in the form of fraud so what happens for example when I create a video of Mark Zuckerberg saying that profits are down 10% I leaked that on the internet I can I can manipulate the stock market to the tune of billions of dollars before anybody else figures out that it's fake so when you have the ability to make people say and do things that they never did you can see that you have this long list of potential threats and the things that we want to think about are now how do we protect against that from a policy perspective from a legal perspective from from an education perspective and from my world from the technology side and what I'm going to talk about next are some of the technologies that we are developing in order to detect these types of deep fakes so we can protect ourselves against a long list of potential threats let me start by way of motivation I'm going to show you a series of clips of President Obama and just pay attention and see if you notice anything yeah hi everybody hi everybody hi everybody hi everybody hi everybody hi everybody hi everybody hi everybody hi everybody hi everybody hi everybody so those are all separate clips of President Obama at the beginning of his weekly address and what you probably noticed is that whenever he said hi everybody he tilted his head up and to his right so hi everybody hi everybody and what you may not have noticed but you can see it on this frame right here is that when he comes down he pushes his lips and he begins he starts talking and it's really consistent he does this over and over and over again and it's it's sort of like a tell a mannerism a behavioral tic that he has and we all have it the way I raise my eyebrow when I emphasize something for example or the way I turn my head when I talk and we're gonna use those mannerisms to try to detect deep faith so let me show you an example of that so I'm showing in the top row is one frame of an authentic Obama video and that graph that you see is showing two things along the horizontal axis is time that's about 10 seconds of video and on the vertical axis I'm showing you two motions that he makes one in blue is how he rotates his head up and down along the horizontal axis and in orange is how he turns down the sides of his mouth as if he's frowning and these are computed average over over hours and hours of video of President Obama speaking and what do you notice they're correlated so when he turns his head down he tends to or when he frowns he tends to turn his head down and vice versa and you noticed this when President Obama speaks when he's delivering bad news sad news when he's upset when he's angry he tends to frown and his head turns down - ever so little it's it's a towel it's a mannerism it's a tic if you will now below what you're seeing is a lip sync deep fake similar to the Jordan Peele video that I showed you earlier and what do you notice here is that they're decoupled well why is that well in this video the mouth is saying something whatever the impersonator wants him to say but the head is saying something else the head doesn't know what the mouth is saying so we've decoupled and we've disrupted the mannerism that is typical of the way President Obama speaks now that's President Obama's mannerism that's his tell that's his tech other people have different ones so here for example is President Trump on the top and now the blue corresponds to the chin pucker and the orange corresponds to how wide the mouth is and you see here that they are D correlated so when he does that chin pucker his mouth is closed and vice versa on the bottom row is Alec Baldwin who does a very funny impersonation on Saturday alive and here you can see that those two mannerisms are now coupled they're correlated so Alec Baldwin took two tix a president Trump the chin pucker and the mouth open and he created a caricature of it but he did it wrong he got the dynamics of it wrong and so we can use that to detect that something is wrong with the video and everybody's different Elizabeth Warren Hillary Clinton President Trump President Obama Vice President Biden they all have different mannerisms and what we do is we learn them and we learn them by looking at hours of video of each of these individuals extracting those patterns and then using that to identify whether someone is impersonating them through a deep faith so let me show you just very quickly how we do that so we start with the video and we do some basic head and face tracking so that blue box you're seeing is telling me the three-dimensional rotation of President Obama's head as he speaks the green lasers coming out of the eyes are telling me where he's looking and all the dots on the face are tracking us facial expressions we take all of that information and we extract 190 measurements which I won't talk indeed about and now I'm going to project those onto a two-dimensional space just so you can visualize them so each dot in this in this graph here is corresponding to a 10-second video clip of Kamala Harris Hillary Clinton Elizabeth Moore and Cory Booker and so on and so forth these are obviously done at the height of the Democratic primary and you notice a couple of things one is everybody's off in the wrong corner so all of the Obama videos are distinct from the Trump videos which are distinct distinct from the Elizabeth Warren videos and so what that means is that when we now get a new video we project it into the space and we simply ask well does this have the characteristics of Vice President Biden Elizabeth Warren Hillary Clinton Kamala Harris and so on and so forth and then we can detect whether something is a de fake or an impersonation so that's one technique that we've developed and you can see that it's very specific to an individual very good for high-profile people like candidates but not so good for well people like me well you don't have hours and hours of video footage where you can measure my various mannerism so this is good for doing things like protecting our elections but not so good for the day-to-day run-of-the-mill people people like me so let's talk about another technique that we're developing so what I'm showing you on this graph on this figure rather is a mapping between phonemes the sounds that you make and vis eames which is the shape of your mouth so let's look in the bottom left hand corner MBP mother brother parent try saying this at home try saying mother and notice that your mouth has to close and now try saying it without closing your mouth try saying mother not as if you're eventually close you'll be able to do this everybody else you will sound like you can you're not enunciate in the word properly my other favorite one is F and V in the top row favored Victor your lower lip curves in ever-so-slightly and your top teeth come down favored and victor so when you make certain sound your mouth has to happen to have a certain shape this is the phoneme to vizima mapping and when we create things like lip sync deep fakes those mechanisms that gain that I told you about earlier the generative adversarial Network know anything about phonemes it doesn't know anything about viz Eames all it knows is about pixels and these classifiers and so we can leverage that ignorant in order to determine whether the mouth is making the proper shape to say a particular phoneme so let me give you a couple examples of that so what I'm going to show you here is a slow-motion version of President Trump saying I'm I am okay so let's go ahead and watch that video okay so you see them saying I'm and I'm gonna just show you in frame by frame so you can see what happens to his mouth so frame 1 of 6 2 of 6 3 of 6 4 of 6 5 of 6 and 6 of 6 and now his mouth is entirely closed I'm there's that M phoneme and then the vision is correct so this is an authentic clip let me show you now a segment of a lip-sync deep fake or again he's saying I'm and you're gonna hear the beginning of the next words you're gonna see I'm so I'm so and I'm gonna put in that s so you can see I'm closing off the phoneme so it's gone okay now let students flow motion again 1 of 4 2 or 4 3 or 4 4 or 4 so I'm Sur and you can see his mouth never closed and if his mouth never closed something is almost certainly wrong because it's very very difficult if not impossible to say month mother on without closing your mouth and so what we've been doing is building models of these phoneme visi matchings pairings rather and then going back in and making sure that the mouth has the proper shape and exposing things like lip sync deep fakes which are simply ignorant of these types of mappings because of the nature of the way gans work so I've described two techniques that we've developed for detecting deep fakes and I've described the threat of deep fakes and I've described how deep fakes are made and if you invite me back next year almost certainly everything will have changed the nature of the creation of deep fakes the risk of deep fakes and the detection of deface is changing it is a fast-moving field and we have to start thinking seriously and carefully about the threat of misinformation we are living through an unprecedented time where we are relying more and more on the internet for information for information that affects our health our societies our democracies and our economies and when we can't trust the media that we see here and read on a daily basis we are in trouble as a society and we are in trouble as a democracy and I while I focused on the technology we also have to get serious about the policies we have to get serious about the regulation the tech companies that allow this infamous misinformation and disinformation to proliferate through their networks have to get more serious about how their platforms are being weaponized our regulators have to get more serious about how to get control over missing disinformation that is designed to sow civil unrest terror societies apart and disrupt our democracies and we have to do all of that by the way quickly and with respecting freedom of expression and freedom of speech and a vigorous debate online about people who disagree and I think that there is a middle ground there but we have gone too far in one direction where we simply can't trust anymore what we see here and read online and we need to regain some trust in order to have a sound democracy society and economy thanks very much everybody thank you dr. Farina really great to learn how you're fighting the impact of deep fakes this concludes our general sessions for today before you go to your next session I just want to share a few final housekeeping items it's not too late to explore the developer hub and Expo visit our sponsor booths and place summit quest and as a final reminder we hope you'll consider participating in our summit donation matching program let's get to 100k thank you and have a great rest of your day [Music] Oh looking so handsome oh you have your way and it's making me we done you and your style walking like that sweetie get into my butt a camper bag though I tried to resist this [Music] I got out hold of me when I'm you and don't magic forgiving if I got no that I tried to resist but you pulling me close Oh God to stay away but you won't leave me [Music] [Music] [Music] [Applause] [Music] 