 [Music] uh so today we're uh lucky to have uh paul smalinski here um to give a presentation for us um paul is a professor of cognitive science at johns hopkins and also a partner researcher in the deep learning team here in msrai so uh as such he's sort of perfectly suited to give us this uh nice overview of sort of the history of human of uh thoughts of human cognition and approaches and how the pendulum has kind of moved between symbolic uh and and neural and back and forth and um i know his his current work is on um looking at how you can merge them to create these neural symbolic approaches that hopefully take the best of both worlds and i assume we'll learn a bit more of that as well um but with that said um paul why don't you go ahead and take it away and you're on you're muted right now are you seeing my screen map yep we can see your screen and hear you okay thanks a lot let's get started then okay so in the beginning models of intelligence use representations network discrete symbol structures i manipulated them with discrete rewrite rules like those of logic or grammar but this wasn't invented in the 20th century it was invented around 400 bce as we'll see soon but anyway in the mid 18 1980s the field took a huge swing the parallel distributed processing group among others showed how numerical vectors listing the activation values of groups of model neurons could be used as powerful ways of representing information for intelligent processing the 1990s saw another swing back to symbolic representations which were now assigned probabilities rather than manipulated by rules in the 2000s this pendulum swung again back to numerical vector representations designed from data by deep learning so what's going on here why can't the field make up its mind on such a fundamental distinction between using symbolic computation or neural computation to resolve this i propose we follow advice from my mother who used to say allegedly quoting yogi berra when you get to the fork in the road take it clearly both types of computation are essential and this is the moral of these lectures the pendulum will finally stop swinging only when the field rises up and adopts neurosymbolic computation so to really understand what's going on here i think we need to take a historical perspective ai inherits much of its intellectual technology from centuries of the study of human intelligence which in the recent era goes by the name cognitive science cognitive science in turn inherits much of its intellectual technology from computer science by adopting the view that what we have in our heads is really a computer but what type of computer do we have in our heads one built with symbolic computation or neural computation in this and next week's presentations i'm not wearing my msr ai researcher hat but my professor of cogs i have when i told henry kudjaman about my favorite course foundations of cognitive science he asked if i'd consider giving a two hour synopsis of it here unfortunately the course is entirely based on class discretion discussion of over 30 readings and there are no lectures so i've created these lectures just for the occasion and they have not been field tested so please be kind and keep in mind that i'm trying to compress 32 hours of class time into two hours this requires oversimplifying and skipping lightly over many deep and complex issues so please bear with me and take these lectures as a view of this complex material from outer space if you be it would be helpful if you submitted your questions by chat or held them to the question period now before proceeding i want to emphasize that the history of cognitive science or the ai is not for me a field of research or expertise my goal here is only to put a lot of ideas on the table for all of us especially interns into the field to think about and perhaps go investigate later in some detail i'll raise a lot of questions give a lot of proposed answers but not favor any particular answers except maybe at the very end next week so why do i think it is crucial to develop neurosymbolic architectures for ai to get started in the cognitive science perspective on this question let's start with a very concrete case study learning word formation specifically the english past tense and the german plural debates about this in kagsai have been raging on and off since the birth of the field and continue to this day the most recent round playing out in acl for a 2018 paper in the transactions of the association for computational linguistics chris kirov and ryan cotterell built a modern day lstm sequence to sequence model to map an english verb stem to its past tense form this includes regular verbs like pick and pig and pit now the past tense of all these is written e.d but pronounced in three different ways as shown here picked pig pitted the task also includes irregular verbs that don't follow these rules like come goes to kane kierov and cottero argued that their model provides a good account of human performance on this task succeeding where first generation models failed at correctly producing irregular past tenses but then in acl 2019 maria corkery yevgen matsuvage and sharon goldwater argued that well actually it doesn't for made-up words production probabilities of alternative past tense forms do not correlate well with humans just this month kate mcgurdy coldwater and adam lopez built a corresponding model of the german plural and argued that it too failed to learn like humans now this big debate dates back to at least the 1960s when susan irvin documented that children first successfully produced cain but then started to stay cund she argued that because they've never heard comed they must have generated it clearly they learned the regular rule and were now mistakenly applying it to come in this era learning language meant learning rules but one of the forces that swung the pendulum over the neural representations was a chapter in what became the bible of a new generation of neural network modelers the pdp books dave rommelhart and j mclellan argued that a simple neural network model shows the same learning trajectory as kids even though it is obviously not learning any symbolic linguistic rules now language learning became learning the statistics of data from the training environment in a legendary reply stephen pinker and alan prince argued that the pdp neural model suffered from a dozen serious flaws that could all be blamed specifically on the absence of symbolic representations and rules they advocated a dual route view in which kids have one system that learns a symbolic rule for the regular cases and a separate neural network system for the exceptions another player in this debate was gary marcus who you may know as a contemporary critic of deep learning marcus's career began with this follow-up study with pinker and others arguing that the only reason the pdp model could learn anything even remotely resembling the regular past tense rule of english is that it is an extremely frequent pattern where the regular rule is very infrequent as they argued was true for the german plural pdp models would have no hope of success this year's acl paper by mcgurdy adult essentially argues that marcus pinker and colleagues were right not just about 1980s pdp models but even 2020 deep learning models the debate over whether language learning meant learning symbolic rules or learning statistics so the training data raged vigorously for years here are 14 examples of some of the subsequent modeling papers addressing this debate now from the very concrete case of the english past tense let's zoom way out on the debate over whether human cognition is symbolic or neural computation and take advantage of a very helpful geographic metaphor here that was illustrated in a figure in a paper of dan dennis which i've augmented a bit at the center of this plot is the eminent philosopher jerry fodor who when at mit called all approaches to cognitive science west coast except those at mit which formed the east pole every direction away from mit goes west the east pole view is anchored in philosophy by voter in linguistics by noam chomsky uh and in psychology by liz spelke and sukhari and stephen pinker all having spent key parts of their careers at mit the east pole is quite unified well-defined and coherent we'll start by focusing on this view in contrast spread around the west coast and filling in the midwest are a huge variety of views that have nothing in common except that they all disagree with the east pole each in a different way time permitting i'll mention the green names i've added as well as ten of red and its originals in black by the way there is still a correlation between holding east post east pole views and actually working in the eastern u.s but the geography here is intended to be purely metaphorical in this slide i'm going to give a crude timeline of some of the key developments most of which i'll be explaining shortly please bear with me as i run through this quickly the east pole view in linguistics was articulated by chomsky in the 60s and then experimentally supported by psychologists the authors showed in shown in red on this slide will be briefly discussed in the story i'll be telling in these lectures for his views on the cognitive universality of grammar chomsky credited the work of the port royal grammarians in france three centuries earlier he called his approach cartesian linguistics because of its fruits in the work of rene descartes we will start the story of this so-called rationalist tradition with the work of plato in greece two thousand years earlier but as we're about to see rationalists thought was not just a western construct and although i unfortunately won't discuss them much i just wanted to mention important non-european traditions too now while chomsky's own work focused on syntax his work with morris halley founded the modern era of phenology the grammar of sound structure in english in language i mentioned this because this approach was in fact pioneered in ancient india by parliament arne's formal rule-based grammar of classical sanskrit is still regarded by many as the most complete generative grammar ever developed meanwhile in the ai sector of the east pole john mccarthy's logic school of ai was the culmination of millennia of formal work on logic including many important developments such as the port royal logic and even panani's logic which he developed for his grammatical work other non-western founders of formal logic in the ancient world included gautama in india and mozi in china back in greece purely hugely influential in the west for his work on logic but also many other areas was plato student arizona whose views became undeniable truths in europe for nearly 2000 years likewise the roots of many west coast views go back centuries as well the pdp approach to neural models of intelligence also known as connectionism follows philosophical empiricism developed in the 17th century by the british empiricists such as john locke and david hume connectionism also draws from more recent work in neuroscience especially the work of donald hebb in the 1950s opposed to chomsky linguistics cognitive linguistics draws from the experimental cognitive psychologists work such as that of eleanor roche cognitive psychology was itself a reaction against another west coast view behaviorism in which b.f skinner claimed that human cognition even language could be explained using the concepts he developed to explain the behavior of pigeons in simple conditioning experiments finally we zoom out in cognitive theory space which is defined by many dimensions along which theories differ we just implicitly discussed one dimension does the theory follow the empiricist view that all knowledge derives from experience or the rationalist view that much of our most important knowledge is prior to experience innate here are other important distinctions today i'll quickly discuss several of those in green now these are all distinctions pertaining to cognition itself there are also important distinctions include about how cognitive science should be practiced these are issues in the philosophy of science uh including these eight or so issues here now the plan for these lectures is to take up these issues in sequence as you can see as always i've packed in more material than anyone can absorb in one hour you may want to tune in and out a bit to conserve attention for the parts that most interest you okay we'll start now with perhaps the most fundamental issue this one what is cognitive science the science of brain dynamics or behavior or mental knowledge the east coast east pole position here is emphatic even though it is brain dynamics and behavior that are measurable cognitive science should be the study of mental knowledge which is not directly observable through sensory perception to understand this somewhat paradoxical position we need to view it from the perspective of rationalism plato emphasized that perception cannot provide knowledge plato's scorn for experience is a preview of chomsky's rejection of corpus data for studying language why can perception not provide knowledge well consider that having exactly equal length is a concept we know yet we can never perceive this sensorially more generally the most certain knowledge we have is about what we can't perceive mathematics in his famous parable of the cave plato asks us to imagine a group of prisoners chained for life so that all they have ever seen is the wall of the cave in front of them or they see their shadows cast by the fire behind them they believe the shadows are the reality of their world although we know they are merely images projected by the real objects plato says that our own perceptual world is likewise not reality but merely the shadows cast upon us by the reality that he calls the world of ideas since knowledge cannot rise from perception it has to come from somewhere else and plato posits that it comes from recollection from past lives now this is pretty untenable but it does anticipate chomsky's view that our deepest knowledge of language is innate not learned from experience plato also believed that the true student of astronomy is not to be troubled too much about the actual heavenly bodies but with the mathematics of the motion of ideal heavenly bodies foreshadowing chomsky's notion of linguistic competence which cannot be observed in language behavior fast forwarding two thousand years eminent rationalist erna descartes who philosophers call the founder of modern philosophy argued that the only thing whose existence we can be certain of is our own mind all else can be doubted perhaps what we think is real outside our heads is just a dream or perception deceived by an evil demon like the matrix a central pillar of rationalism is that what's outside our heads is a poor cousin of what's inside our heads for our second key dimension of theory space we ask should cognitive science seek theories that explain the details of actual human performance or theories of competence the knowledge underlying performance ignoring the vagaries of particular instances of use of this knowledge as we already saw anticipated in this remark of plato the eastfold position is that we need to find out what the underlying knowledge is first only then can we study how the knowledge is acquired by learning algorithms and used by processing algorithms now in the case of language this was chomsky's position of course how does it actually play out for chomsky well chomsky says that knowledge of language language competence that is consists primarily of two things first the mind's ability to construct representations of linguistic expressions like sentences or words symbol structures like these i hope you'll forgive my laziness and using my whiteboard drawings from class on the left is the parse tree of the noun phrase the man who i think that you said that you had seen the arrows show movements of symbols between positions on the right is the mental representation of the noun phrase the man who i wonder which scone preferred the second component of competence is knowing principles that determine which structures are well formed these principles define the grammar for example one such principle is subject which says that each step of movement may not cross more than one bounding node the set of bounding nodes is a parameter in this principle here's how this parameter explains cross-linguistic differences as you will have noticed the structure on the right the man who i wonder which scone preferred is not acceptable english marked conventionally by a star this is because on the chomsky view the set of bounding nodes in english includes the s sentence node and this step of movement here crosses one and then a second s node violating the principle now astonishingly the italian version of the same phrase is acceptable why because the parameter has a different setting in italian s is not a bounding node in italian s prime is this is the only s prime node here that's crossed by this movement so it does not violate the principle in italian the way it does in english the chomsky's view knowledge of principles is innate these principles structure how children analyze their linguistic input they know they need to observe which nodes can be crossed by movement in their language so they can learn the value of the parameter the set of bounding nodes for their particular language we'll come back to this in a moment when discussing an annual cancer reconciliation of nativism and empiricism so as we just saw for chomsky the data of language are expressions labeled as well-formed or ill-form the task of the linguist generative vermearian is to logically derive the labels of expressions from the principles these are theorems that require symbolic proof what is the state of the art on this task you might ask well it's provided by theories of from theoretical linguistics and models from classic symbolic computational linguistics not by neurologists whether they be nlp or connectionist cognitive models these models do not perform this task they do not symbolically deduce the data from principles or axioms of a theory they are categorically banned from the leaderboard could neural nets possibly have innate knowledge of principles of universal grammar such as subject well as it happens at the cognitive science society conference this week tom mccoy currently an msr summer intern and the curator of questions during this very talk will show how this can be done through meta learning now we're ready for another big dimension of cognitive theory space is the mind primarily a device for production for processing highly structured symbolic information or for performing statistical analysis of experience as we just saw in chomsky's work the east ball position is that the mind is principally a symbolic structure processor for this issue too the east pole roots lie in antiquity aristotle was the founder of deductive logic in the west one of his syllogisms asserts for example that if we know that some a's are b's and that all b's are c's then we can deduce that sum a's are c's the point is that the content of a b and c what they mean is irrelevant only the structure of this information matters this is pure meaning free symbol manipulation two thousand years ago and even before aristotle in india arnie used pure symbol manipulation to do the task of generative grammar that we saw on the previous slide close to the east pole our west coast west coast approaches that take statistical analysis as the primary computation in cognition the historical roots of this view date back to the british empiricists as i've already mentioned the empiricist emphasis on statistical computation derives from their position on the origin of knowledge whereas the rationalists focus on knowledge generated internally empiricists including many west coast approaches take the view that all knowledge is extracted from the external world through experience john locke maintained that all knowledge starts from perception and is built up by a sodium associating together sensations that are similar in the in their content or in their time of perception the empiricists did an amazing pr job and convinced the entire english-speaking world of their view now in our community there is virtually universal acceptance of the view that our minds start as blank slates you see it all the time in the ipads stated with absolutely no evidence it's obviously true just common sense but there are grave problems with this actually and here are just two that our perceptions are caused by events outside our heads we can't perceive outside events causing our perceptions so we can't know that they do if all knowledge derives from perceptions so we're back to descartes in the problem with the matrix second can we justify the belief that past correlations predict future ones what good is it to know that past correlations what the past correlations are if they don't inform us about the future but the only evidence we have is that in the past past correlations predicted what were then future ones but that's all in the past we can't justify believing that what is now in our future will be statistically like the past of course inference to future predictions is uncertain but there's simply no basis for even that form of inference that can be extracted from experience alone these are unsolvable problems for empiricism and in fact the great empiricist david kim himself just gave up on causation concluding that there is only correlation and our minds just have a habit of thinking that a causes b when the correlations between them are right now as we've seen the east pole position on the contrary is that much crucial knowledge is not extracted from experience chomsky innate knowledge of linguistic principles was anticipated by plato's conclusion that knowledge must arise from recollection since it can't arise from experience aristotle syllogisms enables new belief to be rationally generated internally to the mind no external input needed although this form of knowledge is purely taunological essentially true by definition emmanuel kant provided a synthesis of empiricism and rationalism which i think comes closest to the right view in cognitive science today that we are born with some important in the knowledge for how to impose organization on our experience so we can best learn from it for kant this included innate knowledge of a four-dimensional euclidean world which allows us to organize our perception of objects and events innate knowledge that calls our relations exist among external events and and acknowledge that our perceptions are caused by external events recall how innate knowledge of this adjacency principle allows children to organize their linguistic experience so as to be able to learn the specific parameter values characteristic of their particular language this is very much the way kant saw in the knowledge interacting with experience the study of innate knowledge is now highly experimental actually the field of cognitive development was revolutionized in the 1960s by methods for inferring knowledge in inside infants heads by measuring the time they spent looking at different types of events the six-month-old babies distinguish between event relations that we consider causal and those we consider merely correlational they respond differently if one object is set in motion upon collision with another if you can see my hands they respond differently to events like this and when an event is set into motion by another object that comes close and stops without making contact like this the correlational structure is exactly the same but one we regard as causal and the other not and infants make the same distinction among events at least by the age of four months these methods have also revolutionized uh the study of animal cognition and there the study of innate knowledge is informative about knowledge that evolution might have provided humans donkey summarized her extremely influential theory of core knowledge systems this way this research suggests that the human mind is not a single general-purpose device that adapts itself to whatever structures and challenges the environment affords humans learn some things readily and others with greater difficulty by exercising more specific cognitive systems with signature properties and limits the human mind also does not appear to be a massively modular collection of hundreds or thousands of special purpose cognitive devices rather the mind appears to be built on a small number of core systems these systems are knowledge of innate of inanimate objects and their mechanical interactions knowledge of animate agents and their goal directive actions knowledge about sets and the numerical relationships of ordering addition and subtraction knowledge about places in the spatial layout and their geometric relationships and finally knowledge for identifying and reasoning about potential social partners and social group members no matter how you look at it this work presents a major challenge to contemporary ai based on deep learning and neural networks either such abstract knowledge systems are innate or they are learnable unsupervised from the infinite decimal quantity of input that infants received compared to the gargantuan training debts that are now required by deep learning what ai needs to do argues gary marcus is to abandon pure empiricism and study the proper use of innate knowledge like that which makes the highly paid efficient learning of infants possible on the other side there's an important challenge too and a challenge to the east pool view that comes from a surprising place we return to our first issue what is cognitive science the science of and now consider the second option behavior behaviorism is a west coast perspective that dominated experimental psychology in the us for the first half of the 20th century strangely it has in fact made a comeback with a strong presence in contemporary neuroscience ef skinner argued that psychology should be the study of behavior and that we should explain behavior from the history of positive and negative reinforcement experienced by the subject on the other side nearly all of modern cognitive science says behavior should be explained by inner causes states of the mind beliefs skills and so on but skinner argued that explanation by inner causes has three fatal flaws first it is unnecessary if interstates are lawfully determined by reinforcement history and behavior is lawfully determined by inner states then behavior is lawfully determined by reinforcement alone we can just cut out the middleman inner causes second explanation by intercauses is unfalsifiable fake for any science because inner causes are not observable third explanation by inner causes is circuit how does it explain why a horse is drinking because of the inner cause of thirst how do we know the horse is thirsty because it is drinking completely useless circular reasons now i think these are serious accusations to which cognitive science must have very secure defenses my own in a nutshell goes like this hypothesizing inner causes is necessary if steps one and two of skinner's argument are interactively confident and valid if the number of hypothesized clauses is small relative to the number of of observable predictions that they make this can be formalized i think in computational learning theory's version of occam's razor when the dimension of the hypothesis space is much smaller than the number of observations the probability of correct generalization to unseat examples can be good skinner's approach to explaining language what he called verbal behavior extended his philosophy from pigeons to people then uh skinner wrote a book in 1959 extending this to verbal behavior which was followed rapidly by a review written by chomsky in which he granted that behaviorism that proved successful for explaining simple behavior of simple ordinances but that for human language what what skinner was to was just play acting in science that behaviors descriptions are really vague paraphrases of precise formalizable mentalist descriptions of inner causes the location of this review was one of the events that launched him for the status of the superstar and in fact to many even a god chomsky's sarcastic condescending tone in this review would characterize his style throughout his career for this reason within much of cognitive science reinforcement learning does not have a good pedigree now we shall take up an issue that is central to cognitive science across the board should a cognitive theory be a computational theory viewing the mind as a machine that takes data in processes it according to an algorithm and outputs behavior on this issue nearly all cognitive scientists agree that the answer is yes although we'll see a little bit of exception in next week's discussion one of the earliest modern expressions of this view was alan turing's classic 1950 paper a theater paper like many ai writers that followed him he described an approach to ai based on learning from a blank slate simply asserting that is how children learn instead of trying to produce a program to simulate the adult mind why not rather try to produce one which simulates the child's presumably the child brain is something like a notebook as one buys it from the stationers or other little mechanism and lots of blank sheets he then again with no justification asserts that learning in children is reinforcement learning we normally associate punishments and rewards with the teaching process but putting these aside the important point of the paper for our story is really about something else paper is really about the question can machines think he asserts that the question is too meaningless to take seriously so he proposes to replace it with what he calls the imitation game which has become what we now know as the touring piece during also began the tradition of absurdly naive over-optimistic predictions about ai i believe in about 50 years time it will be possible to program computers with a storage capacity of one megabyte to make them play the imitation game so well that an average interrogator will not have more than 70 chance of making the right identification after five minutes of questioning the turn test has of course been enormously influential and widely accepted within ai but from the perspective of cognitive science it is seriously defective it is entirely behaviorist appropriate for 1950 it reduces intelligence to behavior ignoring entirely what goes on inside the system it replaces the search for a theory of intelligence with the judgment of an informed naive human observer does this system's behavior seem intelligent to you here's an analogy from physics suppose we said the question is an object hot is too meaningless to take seriously we should put the object in a closed box let an observer reach in and touch the object and ask the observer does this seem hot to you of course that's ridiculous we'd never do that for a physical science the way turing proposes to do it for a science of the mind physics gives a theory of temperature with techniques for quantifying the hotness of an object laws that govern temperature and ultimately reducing being hot to a deep internal property of the object the average kinetic energy of the molecules that make it up so turing essentially dismisses the entirely the possibility of a science of intelligence this is absolutely not the case for computer scientists who followed him the founders of ai took their job to be to characterize the internal computational properties that make a system intelligent first we'll take up the work of john mccarthy and then look at the work of neil and simon these authors occupy a central place at the east pole but before we discuss these east pole ai plan years let me point out a contemporary deep learning is a return deterring west coast behaviorism turns behaviorist stance refusing to look inside the system is evident in contemporary ai because of the difficulty of looking inside neural networks concepts from cognitive science about system internal properties are now a routinely converted to behaviorist concepts that display the weaknesses that chomsky pointed out in skinner's attempt at behaviorist linguistics so just as turing replaces intelligence with behavior that fools people in deep learning the term rationale which properly refers to a rationalist logical derivation of a system's response from its internal knowledge is coerced to mean input that affects the output input in the stimulus or input training data the hypothesized internal property of cognitive systems now scientifically well studied in psychology and neuroscience has been coerced in deep learning so that awareness of x as when something is called exo layer what it means the behavior of this system is conditioned on x entirely behavior is nothing about what we actually know about awareness could be any further from relevant but now let's return to the founding of ai and consider an early work of john mccarthy who was credited with giving the field its name in 1956. unlike touring mccarthy's mission was all about looking inside intelligence to see what computations requires an issue separating many west coast theories from the east pole is whether inference is a kind of logic mccarthy's east ball position was certainly yes one of the earliest ai papers was mccarthy's 1959 paper programs with common sense in which he proposed a system he called the advice taker he gave an analysis of the capabilities required of an intelligent agent which were to acquire new knowledge by inference to process abstractions and to learn by being told his solution was that knowledge representation must be language must be structured symbolic expressions this enables abstract encoding symbols ensuring immediate consequences which he called common sense through logic assembling such infants formed chains and learning by being told to illustrate here's one of the premises he proposed for common sense deduction what this formula means is this if the system knows that x is true and knows that it can ultimately make w true whenever x is true by doing y and then doing z and it wants to make them true then it can infer that it should do y mccarthy's work was enormously influential in a.i the logic school flourished for decades filling up the journal artificial intelligence with a specialized logic for every task in cognitive science not so much as we'll see in next week's episode in cognitive science connectionist and probabilistic and friends nominated along with john mccarthy alan newell and herb simon were founders of the eye in the 1950s and like mccarthy their approach took peaceful positions on these issues the cognitive processes they studied were cognitive or conscious problem-solving processes using explicit representations of facts and rules and explicitly following those rules as interpreted programs this processing was primarily serial together these properties characterize what you may know as system 2 which joshua benjamin venjo has recently been talking quite a bit about citing like psychologist danny kahneman who actually took these terms from stenovich and west system 1 has the opposite properties on these three dimensions and is characteristic of predominantly intuitive automatic processes like most visual and language processing simon's particular easter position evolved into building production system-based general-purpose cognitive architectures their huge tone human problem solving was a landmark in the field summarizing two decades of work at this time ai heavily overlapped with cognitive science their work was based on human experimental data recorded eye movements and written transcripts of people thinking aloud as they solve problems symbolic logic chess and crypt arithmetic which had problems like this where you have to figure out which digit each letter stands for in order for the result to be a valid edition of six digit numbers their model of human problem solving was heuristic search in problem spaces problem spaces were graph structures in which the nodes for knowledge states consisting of about 20 symbols with operators performing transitions between nodes about every five seconds these operators were production rules like mccarthy's rule that we saw where the left side is a condition a symbolic pattern containing variables and the right side is an action to take the current problem state matches the condition the knowledge date nodes were symbol structures where each symbol was a pointer to a chunk of symbolic structure stored in memory there were three separate memory systems long-term memory short-term memory and external memory like paper or a chess board noodle and simon used their human problem-solving data to infer the characteristics of these memory systems long-term memory's limitation was a slow right thumb about five seconds per symbol short-term memory's limitation was a very small capacity about seven symbols my external memory also had a limited right time so you can see they were extremely serious about modeling the human mind as a kind of computer this computer is described here at three levels which the computer vision pioneer david maher would become very well known for he emphasized the importance of describing computational systems at three levels especially the highest level which he quite confusingly in my opinion called the computational level this corresponds here to the knowledge level which focuses on precisely characterizing the computational problem the system is solved in subsequent years newell and colleagues evolved the soar cognitive architecture which is still used in papers presented at the cognitive science society and has been applied to a very wide range of cognitive tasks following in this cmu tradition is one of the most eminent cognitive scientists of all time john anderson whose production system architectures have gone by the name act for adaptive control of thought act the 2005 version of anderson's act architecture consisted of these six modules in addition to the behavioral psychology evidence supporting act anderson was looking for neural evidence using using functional magnetic resonance imaging fmri the linking hypothesis between the computational model and neural activation was this the time each module is active solving a particular problem predicts fmri responses amount of neural activation in six brain regions as a function of the problem difficulty and amount of practice of the subject here are some results each of the six modules of the act model were associated with the brain the declarative memory is associated with the prefrontal area here the control state module is associated with the anterior cingulate area view in these plots dots are measurements and curves are predictions i don't know about you but given the limited number of free parameters available to fit the model for the data i think this is damn impressive so that's it for today next week's episode we cover several more key dimensions of cognitive space and the seminal work of several other prominent authors this will include a lot of west coast so to briefly summarize today's episode a fundamental question is what kind of computer is combination symbolic neural there are many dimensions or parameters along which proposed computational models of published differ coherent set of parameter values based on spell communication characterizes the east wall view a wide assortment of other values characterize different west coasts the east bold inherits from the rationalist tradition in which knowledge derived from experience is regarded as secondary to knowledge that is innate derived by internal reasoning our east pole linguistics focuses on theories of knowledge that is problems rather than on algorithms requiring or using this language elsewhere ai pioneers develop theories of the computational mechanisms for learning and using knowledge especially if conscious serial rule following arguments we also talked about problems with some widely accepted positions including these three all knowledge is derived from experience behaviorism and a turing test explanation by inner clause these problems are challenges some of them feast and some of them from us episode two as i said will feature more west coast uh thank you very much for your long attention and i'm happy to turn your questions [Applause] oh great thank you um if anyone has a question can you uh raise your hand click the little hand icon so that we can um call on you sort of i want us to ask excuse me sorry i've also asked tom to keep an eye on the questions in the chat uh and curate them so i also want to give him a chance to pass on any uh questions from the chat that he thinks would be particularly useful uh for people to hear about okay yeah there weren't any questions in the chat so it's open for um okay just raising questions people have okay so are you going to moderate this matt uh how is this going to work i see besides hand is up oh really it doesn't show that for me so okay bizarre do you want to go ahead and ask your question um what are your thoughts about you know um there seems to be a little bit of like a divisive nature in in the types of thoughts and of course like maybe this comes from historical reasons but it has reflected itself also in our community in the sense that perhaps there is no you know single answer to these questions perhaps humans when they know how exactly to solve a problem they have their rules and the algorithm is clear they follow that algorithm when they don't and they have maybe some data they try to learn from data and when they don't even have the data or memory capacity to store the data and process that data they maybe fall into their biases um do you see any sort of you know um attempts on unifying this this approaches or yes so um because of the limited amount of time i am not able to take rich accounts uh that deal with multiple of these dimensions and assign to various aspects of a problem that values on these dimensions that are appropriate so lots of people do the kind of thing that you're talking about um ask you know for some particular kind of phenomenon how much knowledge is internally derived how much is from the experience and how much if any is innate so for a particular uh domain of uh of behavior or knowledge uh we have to mix all these dimensions together in the right way so what i try to do in this class is just bring more to awareness what these dimensions are so that when people are doing these combinations people can sort of see what's going on better and see how one mixture of these elements in one theory might relate to a different mixture in a different year so it's certainly naive to think that that maybe in any case that we look at uh it's all a or b in these dichotomies um so i entirely endorse what you're saying but i also think it's characteristic of work in the field does that respond to what you're asking about it's a longer discussion but uh yeah thanks thanks bezzy um tom there's a couple questions in the chat did you want to do this um yeah i think there were people with their hands raised first maybe we should start keep going down that list yeah why don't you for some reason i only see bezzy's hand raised now so i don't know okay maybe you could just if you're thinking yes yes yeah hi paul can you hear me i can yes yeah so uh one of my questions was when we talk about innate knowledge isn't it even for a child right like even isn't it also uh acquired by experience in a different generation maybe like it even the inner knowledge is kind of a result of experiences but not by the same uh the body that we are trying to analyze but it is coming from a different body that has gone through a different experience and that's what is the acquired knowledge so it's still experiences but just passed on as you know an initial parameter so everything is an experience in the end like what do you think about that uh well i think that you know um evolutionary psychology tries to connect various aspects of our of for example the biases that as nero mentioned as well as the innate properties that we have some evidence for evolutionary psychology tries to relate those specifically to their uh function in the course of the evolution of the species and you can think of that as a learning process it's it's like a genetic algorithm at work uh learning uh what then becomes the initial state for later uh organisms you can call that learning from experience i think that's perfectly reasonable thing to do i mean of course a major part of it is death so you could call that an experience not one we definitely are uh looking forward to but of course evolution is all about the uh characteristics of organisms that allow them to survive and reproduce so that is a kind of experience if you like but um in any event uh yes i think that it's not uncommon to think about innate knowledge as the result of some kind of learning process uh in prior generations cool okay and i had a second thought uh which is do we also think it from a goal perspective like if we have a specific goal of identifying a person's face for example in a video now from that goals perspective um we can decide whether you know innate knowledge or symbolism is important or just going through 1000 videos to detect the face is enough to solve that specific problem so a goal-oriented view of analyzing these approaches like is there any do you have any thoughts around that well um i mean i guess to the extent that what you're referring to as a goal here defines a particular task then certainly there's a lot of um discussion of the relationship between the different mechanisms and the tasks that they are crucial for solving so absolutely the the role of inductive learning from lots of data in certain kinds of tasks maybe facial recognition is certainly discussed but also there's interest in what kind of innate characteristics of our perceptual system may be at work in how we're actually processing those faces as we experience experience them okay thank you thank you okay then i think um gonzalo was next then we can move to the questions in the chat sure uh paul such a great lecturer thank you my question maybe solid but something always bother me maybe you can provide some insight it will continue to meet the seems that people learn faster than machines we have these huge machines as big as buildings but they still take like several orders of magnitude longer to learn than people what do you think is that well i think that um the story that's you know presented from developmental psychology uh which is showing how early infants have knowledge of how to organize social events and physical events um suggests that there are innate organizing principles which means that when the data comes in it's prepared in a certain way that makes learning much more efficient um so that's the reason that innate knowledge was first proposed by chomsky to solve the problem of how with such a small amount of data a child can learn such abstract and rich knowledge systems as our grammars are so that's the conventional story does that speak to what you're asking about or did i miss the question it is it is an answer and thank you i mean i i don't want to imply that i endorse the view that innate knowledge is the only part or even the main part of the answer to your question we still certainly know that know very little about the space of possible unsupervised learning algorithms and we may just be in the wrong part of the space sometimes i wonder if it is the architecture itself i mean are we are we if we model computers as the models of the brain but just still take so learn so differently than the brain is that there are architecture or the right model to make and i have more questions than really answers so but really not to think about absolutely thank you okay so moving to the chat and i guess going based on likes for the questions um ben vandermee asked uh as models like gbt3 march towards being well beyond the footprint of what we'd consider as human bounded rationality both in memory computational cycles and access to sensory information i.e the internet what is something key about understanding human cognition that might inform ai development um and i'm sure he'd accept multiple uh things instead of just one thing and then feel free to type in if you wanted to add things or follow up on that uh did you want anything to that ben ah no that that's a good as always tom does an excellent job okay so um i guess we could ask the question about whether the form in which the knowledge that gbt3 is the form of the knowledge gpt3 requires um is a form that allows for maximal flexibility of use and generality of use so obviously people are looking into this all the time and trying to see to what extent can quickly um or even with zero shot experience do new tasks that hadn't been directly trained of course that's part of the research program but um i think the um the strong abstractive power and a generalization power of rules with variables and symbolic structures in supporting a wide range of general purpose problem solving and computation makes me wonder whether the form that the knowledge that gpt-3 has will will make it able to uh display the kind of um common entirely rich capabilities that symbolic forms of knowledge provide um you know that's just um a question not an answer what do you think ben i'm not sure right it's a good it's a good question and rather than answer but i guess the a succinct version of the question is like how how much um how much is our intelligence uh and it's especially the things you spoke to today sort of governed by the fact that we are bounded uh computational devices and as we get get the ability to build increasingly infinite computation um like how much will intelligence like the study of intelligence between ai and humans actually diverge or if or if there just never will be enough compute um and and these um the ability to generalize will become will continue to be essential for both machines and humans i mean i think i think uh you have a very good point that the study of intelligence in 3 versus in humans could very well take rather different forms given the very different constraints under which those different kinds of computation operate as you say i think that's true and i think a number of people that microsoft and elsewhere are always interested in the question of how to build collaborative systems that take advantage of what that what is limiting in one system being a strength of the other so that the fact that they're different is actually a strength and not necessarily a limitation but um and in fact sometimes my view of the current uh spur of progress in ai uh is that the main relation it has to cognitive science is somewhat opposite from what you were asking for it's not so much but from this point of view what cognitive science can teach us about gpt3 it's what gpt3 can teach us about cognition which is that you know having had only natural organisms to study the cognition of until now we've had humans we've adults babies we've had brain damaged and intact individuals we've had animals all sorts of different cognizers to study uh but now we have a very different cognizer to study as cognitive scientists and to try to understand the theory of um and as you say there's every reason to think it could be quite different from theories that are appropriate for systems that are working under the up the constraints of natural uh cognition so i think that's a super exciting prospect for cognitive science um and as you know you know the kind of work that you do a lot of people are uh very excited about doing psycholinguistics on language on burp you know um taking what we've learned in cognitive science about the questions to ask and the methods used to answer them and taking those and applying them to a very different kind of cognizer and so that's another important connection between modern ai which actually gives us some intelligence to work with for the first time um and cognitive science which i i think is every bit as exciting as the other direction of what we learned about human cognition might be able to uh inform us about what uh to do in building uh in improving gpg iii uh thank you that was very well put thanks ben okay so next uh andy goresks at goris asks how is new technology for scanning working brains um more detailed anatomy of the brain and experiments and growing brain cells and watching their behavior how are those things influencing theories of cognition or are they influencing theories of cognition well um a a point in john anderson's 2005 paper was if i'm not mistaken that um in order to um to match well the proposed architecture of his cognitive model and observations in the brain and this was certainly true i'm i'm know for certain that this was true about uh trying to connect the predictions from his computational system and human behavioral experiments that the models had to be modified and the decomposition of the computation into modules had to be reformulated in light of what was learned from looking at behavioral data in problem solving and learning behavior in the laboratory but also i think in terms of the neural imaging results i do think that to the extent that that kind of work continues we are in the business of learning about what kind of deep models of visual processing best fit what we're seeing in neural activation in the human visual system or animal visual systems uh more often i think um so i think that we definitely are seeing feedback into the modeling enterprise from the neural data and i'm sure that that will continue to be more and more important it was already it has already been quite important in the study of computational models maybe that's stretching in a little bit but somewhat computational models of consciousness have been very heavily shaped by what has been observed about uh neural uh components interactions um for different states of awareness and so on uh so i think that it's been rapidly growing in importance that flow of information from neural data into cognitive theory development did that address your question i guess sorry i guess you asked tom yes yes thanks okay yes great so uh next was jenny chen who asked what are your thoughts on spiking neural networks do you believe they will generalize well across multiple types and dimensions of data or are there only certain types of tasks that they'd be advantageous for well i'm i'm not as much an expert on spiking neural networks as i wish so my answer is not as informed as i would like but i would say that um the the use of spikes as a kind of implementation level feature of neural networks um has not struck me yet um as sort of fundamentally changing the more high level descriptions of the computations that are going on um so uh i would want to see evidence of that before concluding that whether neurons spike or not is more than a low-level implementational detail but something that really profoundly affects the computation um at algorithmic and higher levels of description so maybe you know a reason to think to believe that about spiking models and if so then i would uh like to hear about it and uh would think that's important uh yeah thank you so much um i i don't like i like what you said about how spiking neural networks need kind of a larger architecture change um because from what i understand spiking networks are just kind of swapping out you know the plane in a neuron for a function and so it's not really changing um anything like it's not changing the structure of the brain on a whole right i mean um one thing i can mention from my own work is that the work that was done using spiking neurons as a way of binding together variables and values for example binding together the agent of some proposition with its its role uh so that you have you know if you have uh johnson mary then you have john bound to the receiver role and so there were models proposed in which uh neurons encoding the information about john and neurons were coordinated with neurons that encoded information about being a perceiver um they were their uh neural oscillations were uh correlated or synchronized um and um you know we showed that that kind of use of time to do variable binding was uh just a particularly temporal implementation of more general mechanisms for doing that variable lining that didn't necessarily involve time so it might or might not be a useful way of implementing a neural mechanism for binding variables to values but our work didn't suggest that it was fundamentally different really in the computational uh power that it offered but that's just one small bit of um relevant experience so thanks for the question thank you okay so uh felix faultings asks do you think system one versus system two thinking follow different models of cognition because it seems like um neural networks do more system one thinking while symbolic reasoning looks more like system two thinking well i think that this is um this is a good context to remember you know a warning we got from besmiro right off the bat which is basically that there are parallel subconscious components and conscious serial components to very many different cognitive uh processes they have to somehow work together to get the job done uh so um in john anderson's uh production system models you fire one production at a time it's very sequential just like newell and simon's production system models were but which determine which production fires is determined by a parallel process of spreading activation through a network um and uh so inside the whole production firing process there are parallel operations and those are not con not accessible to consciousness so there is always a mixture of these different aspects and so i think that um you could say that certain cognitive processes have more system one and others have more system two to them but i think you have to look at it pretty much that way and i agree with what you said that the most natural uh connection is to use neural network processing which is parallel and not naturally symbolic to model the system one aspects of a cognitive process uh and to tie that in somehow with using symbolic structural computation uh for more system two aspects of the computation um that's the huge challenge of doing neurosymbolic computation more generally but i do i do think that um you know we're going beyond merely saying well we can do certain things called system one tasks with no networks and other things uh that we use about methods to do with our system two we're going we're beyond that um for figuring out how to interweave these because any real task is going to involve a combination of the two okay and let's let's end on that note i think that's a great place to end it um we're out of time for more questions unfortunately but um i don't know if paul if you want to take a look at the questions that were there or maybe people could just ask next week when paul's back again to continue his presenting so let's thank paul again thanks paul okay thank you everybody thanks matt bye 