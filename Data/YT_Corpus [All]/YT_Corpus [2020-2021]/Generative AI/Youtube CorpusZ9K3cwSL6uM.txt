 hello welcome to matthew rayfield world internet television channel season 2. and today i have for you uh have you ever gpt2 or gpt3 maybe mess around with something like uh talk to transformer here we type something like i like chicken then you say complete text and then it says i like chicken noodle soup especially when i've been sick and especially when there is chicken in it i like it with carrots and blah blah blah anyways you get the idea gpt2 um let's see wikipedia says about it says it's the generative pre-trained transformer 2 unsupervised transformer language model successor gpt anyways it's basically a text generation tool uses a neural network um and you can start it with text and it completes that sentence or paragraph or story or whatever and it's kind of been trained on just you know huge amount of data from the internet a huge amount of text and the new one gpt3 is kind of even more impressive it's done things like generate html and just all kinds of stuff uh it's made by the openai group which is like a elon musk side project and actually i think the gpt2 was used to name his son i think that's the case anyways gpt2 is pretty interesting i was messing around with a version of it called gpt too simple and which is just a tool to kind of make it easier to work with gives you like a you know just a python library so i was messing around with it an interesting thing about gpt two or three but i have two um is that people have done things other than just text with it so that had me kind of thinking like people have done things for example chess moves where they'll load in a bunch of like a move and then a reaction to that move and get you know the output the input the output and create like a chess bot or i've seen people have um put in a bunch of midi songs midi notes and data and gotten out new tracks with it so in that way it's kind of like a general purpose tool as long as you can get you can kind of translate your input data into a text-based format just to clarify a little bit those things are not using the base model they're training on top of that so like the chess moves or the midi data they're not just putting in a few notes into the normal uh gpt2 model and then getting new notes out they are taking the base model retraining with a big set of data for chess moves or uh midi data or whatever and then after it's been retrained using it to produce new content so i was just thinking what kind of things i could do with it um and the one that came to me that i thought would be interesting is image generation now there's certainly been a lot of different ai image generation tools you've seen the the faces do not exist and the feet do not exist and the airbnbs do not exist and they're all they they're great but they have this like this quality to them this kind of like gooey photo quality because they've been trained on just a bunch of photos so for something like pixel art which people try to generate like small kind of pixel precise images they don't really work they just kind of turn out blurry so i thought that if uh i was able to get gpt2 to generate pixels they would be super precise just because of the nature of text right they're like not it's not photo based so anyways so first i had to find a bunch of images and i thought what might work is pokemon because there's a bunch of pokemon and they're they're kind of they're small they're sprites they're pixely so i got i got like 800 pokemon uh images here sprites from old games black and white games game boy color games whatever just a whole a whole bunch i think it's like three different games of sprites so with that i then created a script that would take go through every image and pixel by pixel uh translated into text so let me show you what that looks like right here all right so if you look you can actually almost see bulbasaur there this is bulbasaur that's uh ivysaur upside down and there's iso right side up like the old uh sprite original sprite and this this format you know translating image into text sounds like it could be complicated this is this is not complicated this is this is like the simplest format you could imagine so every line uh has a number in the beginning so this one is 22 d so that is the uh row 22 or 23 depending how account of pixels in that sprite image and so i tried it first without line numbers just with like enters line returns at the end of each line but uh it just didn't work so i thought adding line numbers would give the model more kind of idea of where in the image it was generating so that's why there's line numbers now and then the d means that it is going from top down to bottom because some of these are flipped like this one is flipped so it says you um and that's just to kind of give the give the the training give more training data so that gpt2 can like just has more data to work with so you flip it you get more data um and then otherwise there are a bunch of characters all separated by spaces so normally gpt2 is concerned about words right and words have spaces are you know surrounded by spaces they're separated by spaces so we're doing the same thing here except for instead of like multi-character words it's just one character so here teal day is a transparent pixel and like the explanation point is some other color and b is some other color i'm not sure exactly what the colors are off top of my head but you know that's what the code does it has a character in mind for every or not every but for a large amount of colors so anyways we put that put all the images into the script and then we get this big old text file which is uh over 100 000 lines of pokemon sprites so with that we take that and we use that to retrain gpt2 and it trains for a while uh it just you know sits and thinks and does its thing and then after we come back a few hours we can say hey give me a new sprite and kind of with some wrangling and normalizing we get something that looks like this which looks basically like the input that we gave it except for it's something new it's fresh it's not it's not the input we gave it um and so then what do we do we take that text and we put it back into an image like this so now we have something that looks you know i wouldn't say it looks like a pokemon but it looks it looks pokemon like right i mean if i saw that i would be like you know there's something going on there they're trying for for something i'm not sure they did it but you know it it certainly is not just random um pixels right i mean it's it's got a substance to it it's got a body there so the nice thing of course about generative uh kind of ai driven stuff is we can just make a whole bunch of them so here here's 3 000 plus um pokemon sprites and i mean it feels like it just goes on forever some of them are weird like just like a circle there some of them this one's pretty good i think actually yeah that was one i had picked out as like a nice one um let's find another good one like i think that looks nice it looks like some kind of like almost snake thing get some you get a lot of big blobs anyways you just get as many as you could ever want and then you can you know go through them and find some nice looking things um interestingly gpt2 also has a setting called temperature which um will like make things really kind of wild so some of these have varying temperatures and also if you scroll down here to the ones that have not been trained very much i think this is vaguely sorted by how much training uh was done on it like there was a point where it knew just enough to make something colorful but like it had absolutely no form so if you go down here yeah right around here these look like some kind of wild i don't know jackson pollock type thing um but that goes away like with just a little bit more training then you start to get um then you start to get some things actually have like a body and then it goes weird again so it's it's kind of it's it's interesting just just to play with kind of the black box that is a neural network feed it stuff let it train and then look at the results so can gpt2 create pokemon sprites uh yeah yeah i think you can um and i i think for the as the basis for something that you know you maybe use as the basis of a character design i think it works pretty well so uh to that point i had artist rachel briggs who's done a lot of pokemon stuff before i had her take some of these sprites that we picked out and uh see what it might look like if that that little sprite few pixels was turned into like a full illustration so this one here uh she named imperoo and i mean to me that looks like a pokemon i mean that that that totally could be a pokemon to me um this one i don't think we had a name for it but it was like a flotsam type thing watery garbage around it type doodad and then there's like a you know white cloth dragon man with like mickey mouse pants caterpillar bird thing and i really like this one this one this to me this sprite is so detailed i was just amazing at how it kind of uh the output had like shadows to it and everything and uh there was kind of a scorpion venom thing anyways i mean these again these don't have names let me know if you have some some names for these uh pokemon creations and she did 10 of these um and i will put these a link to these and her other work in the description um but yeah gpt2 i mean you can do a surprising amount of stuff with it i would be very interested to use it on some type of other project i think using it for like the the chess thing really stuck in my mind is like an interesting use where what other games could you automate with gpt2 i also tried to have it figure out some animations for these sprites but it really just didn't look good and i don't even have an example that it just was bad but anyways if you want to if you want to mess around with this i actually have put up this google collab project where you can train it on new sprites so you can just put in your own images and train it and then get out new images from those so you can train it you can also just if you want to just generate a bunch of pokemon sprites you can also do that and otherwise codes up on github link in the description more info there so just a little update uh i didn't realize this until editing this video but in june openai themselves actually released a paper on generating images with gpt2 and so in my defense i started this project in april and i didn't finish it until now and i just didn't notice that they had done this um but if you want to see a much more thorough implementation of generating images i'll link to that in the description however i still think this project that i did is is useful if you want to just see something that's very simple and uh you know mess around with uh yeah thanks for watching until next time 