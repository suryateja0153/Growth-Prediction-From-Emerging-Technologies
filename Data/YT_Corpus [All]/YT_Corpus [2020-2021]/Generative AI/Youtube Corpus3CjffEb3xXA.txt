 Hello, and welcome to the third episode of AWS DeepComposer: Train it again, Maestro. In this episode, I'm going to show you how to create your first AI generated music track. We will play a melody and then use one of the pre-trained genre models to generate a brand new song. Let's recap the high level steps for music composition with AWS DeepComposer. Step one is to input a melody. Step two is to generate an original song. Step three is to work with the accompanying instruments. We input a melody. Then we select our music genre. Next we'll generate an original song and work with the provided accompany instruments. Let's see this in action. It all starts with the melody. The melody is a linear succession of musical tones. And is a combination of pitch and rhythm. Pitch is how low or how high a musical note is perceived to be by our brain, the rhythm is the placement of sounds in time and makes the music flow right along. The more technical definition for rhythm is the way music is systematically divided into beats that represent a specific number of times within a bar at a set speed, or tempo. You can either be on rhythm or off rhythm. In this course, we are going to do our best to stay on rhythm. AWS DeepComposer accepts midi format. You can either play a melody on the physical keyboard or the virtual keyboard to produce a midi file. You can play your own melody, or if you don't trust your musical skills, you can choose from one of the prerecorded melodies like twinkle, twinkle little star, or we wish you a Merry Christmas, et cetera. The melody consists of the musical notes that you play on the keyboard. A note is a symbol denoting a musical sound, which represents the pitch and duration of that sound. In the US notes are represented with the first seven letters, A B, C, D E F and G. Let's look at the keyboard layout. I remember from playing piano for the youth choir, that middle C is considered to be homebase. On the AWS Deepcomposer keyboard, this is middle C. You will often see it referred to as C3 on musical sheets. Let's start the process to generate an original song based on a pre-trained model. I've logged into the AWS management console, and I'm going to click on the AWS deep composer service. This brings you to the main screen for AWS deep composer. If you click on this, you can expand the menu options and where you want to go. Is the music studio. So click on music studio. There are several things going on here on this screen. First, you'll see, play, stop and record buttons here. You'll see the melody down here. You'll see accompanying instruments and down here you will see the virtual keyboard. So first I'm going to turn off hotkeys. Hotkeys allow you to control the virtual keyboard using your computer's keyboard. But since I have an AWS deep composer device, that's already connected to the console. I'm going to turn this off and now you're able to see the letters that I play. So for example, if I play the C here, you'll see it light up on the virtual keyboard. If I play an F. And so that will allow you to see the notes that I'm going to play now for my melody. I did tell you before that, if you don't trust your musical abilities, you can select one of the preloaded melodies. For example, there's twinkle twinkle little star, Oh, to joy deck the halls. So you can click that and play it by clicking this play button. It's a fun Christmas song, but for me, I am going to play - I'm going to attempt to play - my own melody. And the melody that I want to play is when the saints go marching in. So this is a pretty popular gospel song. And it's often played a lot by jazz bands. So this is going to work well when I choose the jazz model to generate my composition. And I'll show that to you. So let's hear me play when the saints go marching in on my keyboard. Oh, we have to press record. Okay. Not too shabby. So let's play it back. Okay. And so now that I've input this melody, the next step is to select the model. In this case, I'm going to use the jazz pre-trained model. So select it and click on it. And now all you have to do to generate an AI inspired track is click generate composition. And it's usually pretty fast. Yeah. So now it's finished. So notice here on this screen, this bar here in blue, that shows my original melody and down here, notice it's added three accompanying instruments it's added an acoustic grand piano. It's added bass and drums. So in order to play this AI generated track, all you do is press, play and cross your fingers. Okay. I crossed my fingers, but I am still not sure that I like how this sounds. So it could be my awful playing. I don't know, or just could be the accompanying instruments that were added. So notice here, like I said, before, it added three accompanying instruments. Well, you have the option to change those instruments. And the first change I'm going to make click on acoustic grand piano notice. Now you'll have this drop down and you're able to select from different instrument types. So piano, organ, guitar, bass, strings, brass, et cetera. So for this, let's leave it at piano, but I want to choose a different piano. Let's try the electric piano too. And then let's close that back. And now what you can do, you can mute certain accompanying instruments. So I like to do that as I test and play around to try to find a sound that really sounds good. So let's mute this one and this one and let's even mute my melody. So let's play the electric piano. I like how that sounds by itself. Let's add it with my melody unmute that. Let's get rid of my melody. Okay. And so for the next accompanying instrument, let's try something different, not this bass, maybe an English horn. So that be considered a Reed instrument. So click on reed, notice you have different saxophones to choose from, but I want to choose the English horn and let's mute everything else just to see how that sounds by itself. I like it. Yeah. Okay. So let's stop that. And then notice the last accompanying instrument that it adds. It adds drums. So with drums right now through the console, we're not able to change accompanying instruments. Maybe one day, this will be supported and let's listen to the drum track by itself. Yeah. It adds sort of a, a beat or a rhythm to it. So let's unmute English horn and unmute the electric piano and let's play. [ music]. That sounds a little better. I don't know if it sounds like jazz, but I definitely like this better than the instruments that the AI initially picked. So let's unmute my melody and let's play it again. [Music]. Yeah, I think I like it without my horrible melody playing in the background. So let me play it one more time. [ music]. Yeah. That's okay. You definitely have to act as a musical producer to determine which instruments sound good together and trying to stay within your chosen genre. So I'm not sure if what I've produced here sounds like jazz, but it definitely sounds better than the initial track at this point. Just have fun playing around with it until you find a sound that you like. Congratulations, you've created your first AI inspired track. Well, that's it. For this episode, you have learned about the musical components that make up a melody like pitch, rhythm and tempo. You played your first melody on the AWS deep composer keyboard, and even generated a brand new song using artificial intelligence, how cool! Join me in the next episode where we will get hands on with generating an original track, using a genre model that we train ourselves with our own music data. See you soon. 