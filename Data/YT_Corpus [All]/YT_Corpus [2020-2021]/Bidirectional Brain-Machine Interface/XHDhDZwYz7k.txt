 Okay! Thank you for staying with us! The next  program is the Panel Discussion so let's invite   the morning speakers Professor Jodi Forlizzi,  Dr Ted Selker and VP SangWon Choi from LGE.   Because Professor Jodi mentioned she has to  leave in the next 20 minutes so we bring up the   questions to Jodi first. Here's a question  for Professor Jodi and the whole panel as well.  'AI can be an extremely powerful tool for  designers but also a very dangerous weapon.   How to teach students about ethical  implications and ethical use of AI?' Thank you. My thoughts about this are it's  not easy. I think that generally when we teach   designers how to design things we need to ask  them to think about their solutions put forth   in the world and think about what Tony Goldsby  Smith called the solution after next. And in AI   when it's regarding products and services with AI  I think we need to think about the failure case.   We need to think about all the instantiations of  what might be and that's often really hard for   designers to think about so as design educators  we've tried to develop tools to help designers   envision what AI might do when they're  designing. However I think a lot more is needed. Ted, what do you think? Yeah so all tools are  dangerous the idea of a tool is something that   allows you to do something bigger and more than  you could without it you can hit your hand with   a hammer. So when we take those dramatic  visualizations on the screen and choice   beautiful cockpits if those things are moving  while you're driving your attention is attracted   to them. So that's that the ethics of that are  also complicated and I mean he and Mr Choi s very   articulate explaining that. So I think that the the  question of AI often in in most people's thoughts   has to do with more with data and who and privacy  and security often. I think that   has always been a problem and without AI we still  are accumulating so much data about people and   and surveillance issues are dramatic too  and so we really of course want to think of   implications and unintended implications in  every design effort we do. Now quite frankly,  I'm going to go back to my theme which  is you think you understand how things   implications and and unintended implications are  going to go, but you just watch in Twitter and   Facebook and all of these other places where  the designers are so are shocked. I tell you   shocked. At what the implications actually ended  up being and what they continue to evolve to be   because every tool you give people they also think  of ways of using it that you didn't think of, and   when they do that changes the ethical consequences as well. Absolutely. But you mentioned the we consider AI as a tool. However i think there's  quite the fundamental differences between the   tools that we have experienced before in our  humanity and compared to AI because AI is kind of   an intelligence, you know it's not really like  extending our physical body and to help us do   things to make things become more efficient  but instead AI can help us make decisions.   So you know it's a sharing kind of a part of  a brain functionality, so in this case that's   why I think it's ethical issue has become more  significant than before. So what do you think   about this in the in the vehicle design industry,  VP Choi because more and more we are moving to   autonomous driving vehicles right and there's  a couple of questions regarding to the ethical   issue responsibility issues if something happens  who gonna be need to be responsible for this? So   from the vehicle design perspective is there any  consideration regarding to this topic? Yeah so the the very top popular topic of  autonomous vehicle I think that it's basically   we need discretion of how to just may have that  discretion standard is very important. But at this   moment just because it's capable, because it's  it's very good at what it does doing repetitive   tasks and make quick decisions, we tend to kind  of expect it to be making a good decision having   autonomous results. But in reality at least from my  perspective, there are still ways to go. Some OEMs   in announcing their autonomous vehicle capability  are more liberal than the others and each company   has a different criteria. Some are very for example  in Nissan where I used to work, the case was where   they had to have a perfect in designing or  the range of the the distance of the vehicle   it needed a certain size well a daily drive would  be this x number of miles and to go there the   battery has to be about this size and the vehicle  should be about this size. There was very logical   standard to do it. In in case of a Tesla the  range is much much more longer. But not because   it was well of course they had their unique  technology as well, but they decided to have.   I'll say basically that the Tesla S is  going to be a luxury car. They're going to be a   a much more performance car, not a a lean  kind of well-balanced car Nissan wanted to build,   but I wanted an American sports premium  car, So that standard was different that's   why one was 80 miles range or the other  one was 250 miles range in the beginning.   That type of this discretion is always necessary  and designers need to be able to and designers and   engineers obviously would have to have a certain  type of criteria for for making those decisions. Yeah, so I think you know having the relying  on AI is sort of like I would consider AI as another personality like a an acquaintance  of mine. I don't trust I'd like to but I don't   trust everybody a 100 percent. So there's  some level of trust that I have in   knowing their track history, their ethics and their  what not their pattern of behavior I think that we   should approach AI in kind of the same way like  another person it ha it does this well that   well but I mean I can't say that we  would trust that 100 percent in all the time.   But definitely make definitely value that  relationship I think that's very important.   That's very interesting when you say we  should you know treat AI as another person.   From the technology perspective I totally agree  that's that's the future we're heading up to.   But it's for example I think I want to map  out a scenario for everyone you know just to   build up the the conversation. For example this  morning when I'm prepared to leave home for work.   You know I asked my AI virtual assistant I say  hi Dummy Me you know just instead of Siri is a   chatbot you know maybe in the language recognition  perspective is machine learning but it's a chatbot.   But my virtual virtual assistant Dummy Me is  a real deal it's a let's imagine it's a real   AI okay so I asked him I said Hi Dummy Me  can you tell me which tie I should wear   because I will be the moderator for a very  important session this morning so at that Dummy   me started to search for my interest maybe through  my internet surfing records. I say maybe because   I actually don't know you know how AI gather  all my data and to understand user if AI doesn't   understand you how can they make decisions for you.  So in any case it has to understand you and search   my internet records and also analyze my character  maybe through monitoring my calls ooh scary   WhatsApp or WeChat conversation record and you  know to get the conclusion about the also compared   to the fashion code of this event etc, that it  can make the decision for me. So now here as you   mentioned the question here is what is the level  of transparency of information we should have here   between human with AI, if you don't know, because  you trust your friend for example because you know   how your friend think you have communicating  with your friend maybe from childhood   there is transparency through your experience  with your friend. But the AI is new thing came   up into your home. Dummy came my home last  week. How can you trust this character in case, for example, if there's one  parameters missing in driving assistance   in this virtual system and that gonna cause  a serious misjudgment? How can we ensure   you know if there's a lack  of transparency of this communication   decision makin, how can we ensure all the  parameters will be considered in this? What do you think?  Ah yeah, I mean it's a kind of a difficult.. I  don't think there's a good answer for that. I mean   like if there is... The trust is it needs to  build it over time I think. It's not something just you know at one point okay you can trust  this 100 percent, it's more of the track   record, isn't it? Being able to see the well  for us to see it's the AI's you know the trend   for us to recognize so it's kind of vice  versa it looks at us with all our   actions in online and our actions in the car by  cameras and whatnot but it's at the time at the   same time it goes both ways from us to you  know grow that trust level of the AI system   and maybe not a 100 percent but at least to an  acceptable limit. It's going to take time. I think   there's a bi-directional  decision-making over a period of time. Because I kind of I hate when I go to my instagram  page and or facebook page and I see kind of the   same type of feedback or news that comes up that I  have maybe looked at once when they decided to say   that this is the only thing that he's interested  in so my page is always cars cars cars cars cars.   But I am that's not the case I see cars maybe  once or twice but I want to see other things. But   AI makes that decision for me and just feeds me  with just cars and it's just really frustrating   sometimes. So I go intentionally to teach them so  I know I delete to what I've seen in search or   in the previous if there's a history  that I can correct. That option   probably over a period of time for a long period  of time if the learning the process is   always on. I think that kind of a feedback  going back and forth and back and forth needs   to basically be there for it to be to be an  acceptable level of trust.  For sure. Ted? There's a bunch of things to say I mean first of  all that conversation that you were alluding to   Mr Choi is the is the thing the problem is that  if as recently happened one of my brothers said   something awful to me stay with me for a long  time. So we can ruin the trust in a moment and   so it's building it up slowly it's about  not making certain egregious mistakes as well.   And part of that is that conversation  that we were talking about what what does the AI   know it is competent enough to say something about  certainly requiring the tie recommender to figure   out that maybe I need a hat because actually the  outfit doesn't go with a tie and my head is gets   gets cold in the winter is is is probably outside  the realm. But if I asked for Tie advice for a   variety of reasons first of all it's challenging  my goal and that's a problem. But I want to go back   to this dashboard for a second. There was a big  gigantic improvement in dashboards in simplifying   them. When we went from the oil meter to  a light. When we went to an idiot light   what happened is people noticed that there was  something wrong with their oil and so what we have   to think about is what is the appropriate feedback  that will simplify the problem space and simplify   the decisions for the user, because the user  has to be part of the equation, isn't   it? However smart our our AI is, it has  to reduce what it's saying to one what it can   knows it can be reliable about and that's about  testing it's a the AI before we ever give it to   a person which these collaborative filters  you're talking about aren't. And second what   is the feedback that a person is going to  respond be able to respond to appropriately. Jodi? Yes, I was going to just say that we try  to conceive of AI as a design material   much like paper or wood or clay understanding its  limitations and its abilities and I think in some   of these examples that we have been talking about, there may be a misunderstanding of how the AI   works, and if we start maybe with a simple robust  AI designers might be able to convey how that   works to the user of the product or the interface?  I think that's maybe something to think about. I would go on to venture that there are not  a lot of places a lot of apps or consumer   facing products where AI is being used in a really  elegant way. I mean for example Starbucks app which   is one of my favorites to pick on should know that  a customer is in a store wanting to order a drink.   But the customer has to click through four to five  screens to get the action accomplished and the   pay for correcting that error would just  be one click. We could just put the user   on the pay tab when they come in the store  if it's wrong it's one click to get away. So   this is a really simple example of how  a little bit of well-developed robust AI   could help, and yet people who are designing these  apps can't even think about this yet. So how can   they think about the scenarios that Mr Choi and  Ted have been talking about? It's just really   hard to conceive. It's beyond human factors,  it's beyond interface design, because it's not   understood as a design material yet, Yeah I kind  of have the same thing like that we mentioned   but like you said, like in the automotive  interior the action that you want   is a very simple. If I just say volume up just the  louder louder it can just go you know I don't need   to see all the menus to and use the buttons to  pull up the volume. You just, I just want a very   short command and then just kind of automatically  does what it's supposed to do. But yeah, we are   making you know 16 or 17 menu depths of menus over  and over again which is very frustrating. Yes. So if we take one step back and  we can consider this as maybe another   step of digital technology. Here's a question  from James. James is asking Professor Jodi. 'You mentioned that we have to now move beyond the  design thinking. But do you think there's enough   agreement or understanding of digital technology  to start to think what what is the next already?' I don't thank you for your question,  James. I don't think, excuse me, I don't think   there's enough understanding and I also think  that the technology will migrate. So, just to draw   a comparison when HTML first came people wrote  their own HTML and now you know fast forward a   few decades of they're entire meta design systems  that enable you to you know design a website in   a templated format. Perhaps aspects of AI will be  the same way and that they will be black box there   will be simple things that people can adopt and  develop I mean things can really be changing. So,   yes I think we need more but exactly what  and how that unfolds I'm not really sure.  The next question is to the panel. Thank  you, Jodi. The question is, 'isn't time to start   designing from what is relevant  instead of what is possible now?' Yeah, I mean I think that's exactly  what I want to see happen in  the interior of the automotive experience because it's possible we're just   making the system very heavy. The original  intent is not for that I mean it's to have   a very intuitive very natural interaction with  the machine with a good level of trust. I think   to have some and it's a challenge for  us I mean obviously. To be able to kind of   how to make an intuitive system  that matters to the consumer.  We want to and even from hardware as I mentioned  in the present presentation briefly when   we think that the choice of a  certain user experience and function and   feature should be given to the the  cons the consumer. The consumer can   and in just a kind of a vision but they can  choose what display they want to use if at   all and then be able to you know kind of curate  their technology in what they want in the vehicle   and then be able to load it in a position that  they want. And then just kind of work very lean   just keep what they actually use and don't use  and get rid of all this stuff that they don't use.   I hope that that's well the future  of the of the more intelligent vehicles that   staying relevant to what the consumers really  want and need and just shed all the rest. Well I want to respond to that there was a  movement in the 80s for customization and in computers and it became a disaster. Because  if you aren't a professional designer   and you're taking a lot of time to design  things but you don't know much about it, you   can make mistakes like like there's no oil meter  that knows that the engine is going to blow up.   And so the question of relevance becomes one  of course this fluidity and this reactiveness   that you're dreaming of is really exciting.  But I would like our talks to be deeply   describing, how do we evaluate these things? I  think the designers are asked to make something   this dramatic and then beautiful and of course  they can make things that shimmer and all of that.   The question is especially for a car, what  is going to make the person drive get   get to where they want to better interact with  the people that are in the car with them better   and achieve the goals that they  have while protecting the people outside and   and themselves as well? And those those things  take serious evaluation but the thing that's   missing I think that Jodi may have brought up is  this whole future thing which is which is this   we think we're going to ask people  what they want well people want what they know   about. And how do we invent how do we how  do we really create the the hunger for what's relevant in the future not what is only  possible I love that distinction very much. Jodi, do you have any comments related to this? VP Choi, I would like to ask.  The key question is how can we actually you know  of course we know, if we want to design as a   designer, we want to design something to satisfy the needs of these users.   But the key question is how can we explore what  the real needs of potential needs from the users.   I remember during the certain period I remember  one you know, just before Steve Jobs announced   the iPad Hitachi did investigation in Japan. They  had the idea about this kind of size you know as   a touch screen devices and they asked everybody  that was in Japanese market did the investigation,   and most of people they said no we don't need it,  We have smartphones we have laptop computers you   ask them they can't imagine they said why we  need these kind of devices. But once Steve Jobs   announced iPad this boom has become really popular  in the market. How this happening? How do   we know the potential needs from the users?  Go ahead, Jodi. I think Steve Jobs was a design  visionary and you know clearly had a unique   vision of what people would want to need. I think  that we need to consider designing things in   other ways then starting with scenarios  and personas. We may need to start with   a technological capability, or we may need  to start with data to understand where the   opportunities are and then pivot to a group  that needs those technological opportunities. So   I think part of the change in design is to  move beyond user-centered design to think about   data-driven design design that's  framed by enabling technologies etc. Yeah, I mean in this case, we all know the  the the basic investigation approach you know   to gather the user's opinion, but now we have  AI, right? Who is very smart you know got a lot   of data and can analyze for us. Dr David is  asking how can designers convey what AI knows.   Do you think what the AI knows this information  can help designers to predict and to analyze to   figure out what is the potential needs of  users?  So I go back to what Jodi just said   which is that basically the AI us understanding  what it knows is critical to us using it to   design. But I also think that designing where we  used to look at the user I think I really like   to look to psychology. I like to look at what is  our memory capabilities what are our perceptual   capabilities what are our social capabilities  what our behavioral capabilities and reactions   and how do we work as humans. Because unless we  are building things to work with people they're   not gonna it's not gonna work out. And we're gonna  overload them or we're to distract them or we're   going to just piss them off and they're going to  not go for it and so. You know we used to look at   users using this before you know we  aren't looking at horses to design cars anymore   we're looking at what people, what is possible  is as you know is so dramatically different now   and that we really have to look at the human  possibility and the technical possibility   and then start understanding  what that conversation. That conversation when it's actually when we've actually  built it is another part of it which is   you know that is it customization or is it even  just just learning about the you know, how do I how   do I work with a system that I don't understand  very well. Let me tell you the first time I   used autonomous driving in a Tesla and I was using  it to go onto a freeway, I don't know if any of you   guys have done this, but basically it knows nothing  about getting on a freeway. It knows a lot about   and you find yourself in a very very dangerous  position where you know basically it wants   to fly off the road. And so that  conversation of what is this capable of and   and helping people tamp down their expectations to  reality helping the AI tamp down its expectations   to not be thinking it knows what kind of choice  information Choi wants to devour. We've known   for decades that the collaborative filtering  doesn't work right and we still deploy. Yeah, indeed. What user needs is one thing what Jodi mentioned is the social benefits you   know it's from the social perspective.  Here's audience Farvous asked a tricky question related to COVID19.  He mentioned based on the lesson of a COVID19,   do you think the future  designers need a paradigm shift   you know from the social perspective in  design education and in design collaboration? Jodi, what do you think? I'm sorry can you repeat the question. Yeah the  question is based on the lessons of COVID19, do you   think the future designers need a paradigm shift  in design education or in design collaboration? Well that's a very slippery question! I mean, we could break it apart and say   when there are unexplained or unprecedented  phenomena what is best to address them.   We may not know or we may know and then there's  how can design how or can design even evolve to   address those things. You know I think that   if we look at the pandemic as an example  there's certainly much that science could do.   There are things that design could  do to maybe help buffer or prepare society or or help society to  mitigate the pandemic or work with it in a way.  But I really um you know i'm not sure  what is meant by a paradigm shift in the question.   Well I guess I could make a little couple  comments. First of all of course there's   always paradigm shifts with new technologies  and this this is a very strange experience where   somehow or rather the video and  bandwidth capabilities of the world   have held up. So that we have a very different  experience than than anyone had in in Spanish   Flu time or or or any other time where they  tried to quarantine. So we are actually   able to do all sorts of amazing things will  when we're over with it are we going to have the   roaring 20s like they like you know like like  they had after the Spanish flu or are we going   to instead of jumping out and running around  like we'd like to. Are we going to   be so used to these new techniques for communicating that we don't have to commute 25   minutes just to talk to somebody? And we don't have  to enter their office and show them that we have a   broken arm or whatever it is that it takes time  to get started up. We have much more fluid   much more quick, much more actually in some  ways almost too intimate of conversations   as you're staring at my eyes the whole  conversation that we're having with each other. I mean I don't think that there  will be a design you know education paradigm   shift is not necessary but and in our  case I mean I work at a tech company but the   irony is that the tech company has the most  conservative strongest security in   working online and digital data due to safety  reasons, data safety reasons. Not a paradigm   shift in design education due to COVID but i think  there is definitely an opportunity because of   the situation we ended up using  you know much more online collaboration tools   such as what we're using right now. It used  to be blocked. So I think it actually it   just gives a forces us to think differently and  there's definitely some benefit and opportunity   that we can identify from there. I mean obviously  it's a tragic situation for globally but there's   some always something that we learned from the  experience. I think that's a beneficial for   the all and not just designers but for everybody. Great! Thank You! Here is a another question from David ask VP Choi. 'How do you envision explanations  explanations of decisions made by machine learning in the vehicle being shown in the e-  dashboard especially safety critical ones?'   Sorry I couldn't quite understand  the question can you repeat that   It's a good point me neither. So Dr David  is asking Choi, how do you envision explanations   of decisions being made by machine learning  in vehicle being shown in the e-dashboard, especially safety related issues? I guess it's a trust question  about the information that's shown on the   digital cockpit. Obviously that's also  in automotive world the safety rules are   very very strict as I mentioned for company to  company there's a little difference in a level of   safety... just one second my battery  is about to die! Just one second.   I'm thinking about ABS brakes as he's leaning  down. ABS brakes were a problem for when they first   came out because people didn't understand how to  use them and so they actually had more accidents.   And what you have now is ABS brakes that give the  feedback through pedal itself so the pedal shakes   and tells you I'm in an ABS mode  and I think that the more that we take   the control surfaces and the the things that  we're interacting with to give the feedback   that is appropriate to the person relative to the  things that they imagine they are controlling the   more we're gonna make connections with them  and they're gonna be able to understand it.   Yeah I mean I think it's just because it's a  digital and because it's an AI the decision making   and the trust to the information we get from  the vehicle is any different from what it   is today it's still a mechanical and electric  signals that give us today's warning lights and   and things like that so I don't think it's  unique to digital cockpit but more of a   the vehicle actually I mean about this  the standard of the safety factors that   engineering and developments are set and par  oh yeah through their strategy. Great Thank You.   We come back to the to the ethical issue we  discussed before here is a very interesting   question Marty asks, 'is it creation of  desire in users also a deeply ethical issues/.'   My understanding of the question is  about how about the users' need   has ethical issues and how  we're going to deal with this as a designer. Ted, what do you think? Well certainly policy has intruded and tried to make sure that people  aren't, you know, driving without hands-free   of course and if you're watching a movie  in a car that's distracting they know.   The problem is that actually a lot of the the  studies have shown that what you think can be as   distracting as any perception anything that you're  looking at or or doing. And so the ethical the   questions become very complex when when what we  really have to do is we have to make the people   recognize that they're in a dangerous situation  and them having to take the decisions and   have the appropriate thoughts that relative  to the situation makes them appropriately   taking care of themselves the people around them  and the equipment that they're working. Jodi, what do you think? I had a thought and it went out of my head   I'm sorry it's getting very late here. Come back to it. I totally understand. It's  probably 10 or 11 o'clock in the in the US time, right?  So from another perspective, this is  about you know the new users needs,   about the materials for design. What a VP Choi  mentioned I think here's a question related to   in the corporate scenario I know there are  requirements for high efficiency of outcomes.   You know it's you have to build up these solutions  in a really fast-based pace and at the same time   the first changing of technology which requires  somewhat a kind of learning curve. So I wonder   do you see the opportunity to develop AI as a  tools or like a platform to support the team   collaborations and feedback cycles from your  working experience.  Yeah and as you mentioned   we not only with internally but we've also had the  experiences and still have experience continuing   experience with our OEM customers and  how to make this whole process and efficiency   improvement so making a  collaboration platforms and tools   are have been attempted. The challenge is to it's  not easy because so many different criteria is   I guess in a corporate environment there are  I mean obviously we have we want efficiency   and to create efficiency we have to go through  so a lot of internal corporate hurdles. I think to   a certain that there's the irony. I think  it's for an outside innovation small company can   make it make a very quick platform tool that seems  to easily connect connect the dots. But in a heavy   bureaucratic corporate environment it's actually  an additional challenge to make it work. Within   the company and you can kind of imagine it that  with it and even within the company but if you   imagine another company and for a company like us  we have to deal with all the OEMs around the world   and they all have different criteria  and different rules. So setting up a   a functioning collaboration tool is very  difficult. There we've tried a few and still   in search of improving that process so that's  one of the things that I mentioned in the in   in the presentation that how to make that flow  a process a pipeline into a lean one I think   it's a big design challenge, something  that the designers need to kind of actively try   in and and develop their own, but not as a  company to build a platform.  It's not very easy. We're trying. We  want to and I think that's the right direction   obviously we have some ways to go to  make that happen, and all those prototyping tools and collaboration  tools of the icons that I mentioned, we are   oftentimes very frustrated about because each  one of them end up being good at certain tasks   and and not sufficient in this task and  those characteristics are always   kind of becoming an obstacle of actually not using  it in the end. So finding a perfect mix seems to be   very different. But it from designers individual  designers point of view to kind of a search for   and then kind of build up the best  case pipeline, the workflow and processes maybe   it hooked someday we will be able to have a  more of a lean a system that can utilize the AI   to our advantage. Very interesting. So following this design tools conversation in Ted's presentation I also learned a task management  machine learning allows a designer to consider   like dozens of parameters, right? Which is instead  of like a ball rolling things, bowling things,   and how do you picture the opportunities for  designers in this developing such tools, Ted? Well I mean what what you know i was recently  making AR glasses and we were trying to   stabilize something about them. Instead of  you know using the standard engineering tools   we threw AI at it, after spending six months  trying to fiddle with a bunch of parameters. You know in AI you can take 30 parameters or 100  parameters and throw them into the mix and have   it and have it quantify the relationship between  them. It's just astonishing how complex   this is what automated tabulating machines are all  about right it's about simulating things that you   couldn't simulate in your head. And that's really  one of the big things that's wonderful about   about the AI models. And I wanted to make a little  comment about the last topic as well which is that   my view is that whatever we're doing with a  computer, whatever we're doing with other people   already has been this way and whatever we're  doing with the tool that we're picking up it's   a progressive. It's a progressive relationship.  This idea of a progressive relationship means   you know something about this trust that we were  talking about earlier that is you build up your   skills the tool shows more of its its abilities  through you understanding more about it you build   up your skills and you keep going. If you don't  do it in a manner that that is smooth   you might just fall off and throw the thing  away because you cut your finger with   your knife. You don't want to cut your  finger with your knife at any point. You want the   the knife to keep being something  that's useful as you learn more and more   and start depending on it more and more. So  that that's kind of a criteria for collaboration in my view. Yeah totally agree. You know in the human culture we build up trust through a long time but you lose trust just  probably one second, yeah very easily. Could I just say something?  Sure. A lot of studies show that when people's trust of technology fails   for whatever reason the technology fails, a lot  of times the trust comes back in an even more   heightened fashion. So you know human behavior  is also unpredictable. Totally it's not. I'm not wearing a Tie today.  So abusive computers might engender deeper relationships. Exactly. Okay. So before you go we actually have prepared  what we call word cloud. Could you please show the   word clouds? Which is articulating the  keywords and you have presented and we have a   discussed today. So we can see the biggest words  here are Design AI US which is human People Needs   Relationship Understanding. I believe understanding  is between human AI and the system Work Needs...   keep changing. How do you want me to chase?  It's a horrible interface you know... which one do you want me to aim at? Okay, so  anything else? We have mentioned the Trust   here we go... Future Needs, Tools, Company, which means  industry requirements and Corporate scenario   etc. Okay so I think it's time for everyone. Here I really want to appreciate everybody's   contribution. Jodi, Ted and VP Choi  and it was great to have you.   Before you go before you go the final question  just come up to a VP Choi, do you hire recently   graduated designers? If you do what type of  skills do you expect them to hire to have? Not in my well our studio actually did hire 12 new  designers today. So they were very lucky to have   found a job in this complex situation but unique  thing was that it was an online online internship   process not through you know the application  review process and portfolio process.   Actually we went through very proud actually  that to have a give them an experiential project   together and and through guidance and coaching and  they the 12 of them performed excels at it and we   actually after the internship it was became  a direct hire for us. So I was very happy to   hear them they were very happy today. Actually  they're introducing themselves online and by web   and what kind of a strange life at times that  we live in. If I i'm looking for the designer   obviously the you know the design talent is  important as well but as I mentioned I look for   inquisitiveness, the kind of search, kind of  a brave curious ones with passion. In a corporate   world unfortunately I see too many losing passion  over time and especially in a large organization   like us over time that passion whether it's  because of the organization or not, I don't know   but we look for that inquisitiveness of the  willing to change, willing to accept and willing to   try new things like you know not just designing  but understanding challenging the process and   learning to how to change the process and being  able to suggest and make opinion. I think that's a   very lacking and unfortunately in my experience  recently. So I have a very kind of it's personal   bias a little bit but I want that inquisitive  more passionate designers to be around me.   Great. Thank you! Jodi and Ted, do you want to give a  final sentence comments to the audience today? Always be exploring always be trying   and don't be frightened of new technologies  they're always coming. But try to understand   what they're valuable for and and how you  can learn from them as well as what you can   use them for. And I would just echo what both of you said and to say that   you know technology can be looked at as a  design material. Our value is in being innovative   in pivoting and in looking for new and passionate  and creative ways to do things. Okay. Thank you.   Thank you for all the audiences staying with  us for so long. That's the end of the morning   session. We will be back at 1:30PM in the  afternoon session. We will have Dr Joseph Francis Wong from the Hong Kong Design Institute and the  Institute of Vocational Education as our moderator. We also have amazing speakers in the afternoon.  They are Dr Zhanpeng Huang a Senior Vice Director   from SenseTime, Dr LingYun SUN Professor and  Deputy Dean from ZheJiang University and Professor   Ashley Hall Professor of Design Innovation from  the Royal College of Art, UK. So, stay tuned!    I'm Professor Stephen Jia Wang, School of Design  Hong Kong PolyU. Bye for now. Thank You. 