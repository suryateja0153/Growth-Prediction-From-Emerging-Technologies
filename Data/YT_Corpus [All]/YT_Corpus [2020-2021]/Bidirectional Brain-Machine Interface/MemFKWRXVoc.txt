 so thank you very much first of all an excellent forum and excellent talks and really the focus on neural circuits focus on neuromodulation it's interesting just recently the World Economic Forum came out and waro is here in the audience the paper which really emphasized on the effect of mental illness especially depression just not an individual rather than the whole families in the society there are depression is now the leading cause of disability in the world not just United States but in the world depression affects 300 million people in the world and it's trillions of dollars which are spend annually so it's a critical issue interestingly until recently neuropsychiatry psychiatry was kind of seen separate from the aboard other disciplines of the brain the neurology the neurosurgery the pain and other disciplines the fact remains that it is one brain and we are all working together and we had need to work together to for the benefits of other patients that would be my opening statements and I think what we have I heard what I heard today the connectomics the neural connections is critical you know when I was going through my residency and fellowship all I learned about psychiatry was neurochemical imbalance Depression was neurochemical imbalance schizophrenia was DiPalma nuoc and so and so forth anxiety was gaba your learning brain is an electrical component of the brain is neurotransmission oh and it's critical for us to recognize that it would have to be neuro stimulation along with the pharmacological interventions which will eventually be able to treat some of these very desperate patient so pharmaceuticals along with electro suta calls will be the one will capture this beast of mental illness yeah right so it's all one brain and it's all 31 perspectives around the the table and that's the challenge we're here to deal with right please yeah so my name is DJ speaker I'm a computer scientist and a leader group group it's called augmented vision at the DFK eye is the German Institute for artificial intelligence so it's about 40 people we are technical people so we develop algorithm we develop machine learning methods in basically image processing is recomputed vision and body sensor network half of the people work at the moment autonomous driving half perception citizen and half in computer vision and augmented reality so what we try to do here is to use AG mentality sometime also we're to reality to assist people in a better way classical augmented reality you just show one information after the other one you have very little knowledge about what the people want to do what they want to achieve and within which context they are so we try to move other say from this classical to cognitive what we call cognitive augmented reality how do we get this information and how can we try to infer the intention if a person is so we develop several techniques we put sensor on the body is about twenty sensors and we try to capture behavior or people also with the camera we try to capture how people do things and we develop a system which is a little bit like a robotic system or sometimes we call it parasitic system where we store we first learn we store how people do things for example if you repair something or if you're a champion in golf or something from expert you want to learn so we capture the expertise of the people sometimes we say even the skills we digitalize it so it's a lot of datas and we try to find worked our single actions in this workflow and we'll graphs about some tasks about some workflow maybe daily activities so once we have that we there is a person who wears same sensor we try to in real time to match what you're doing with our database basically and try to interpret what people are doing so once we know that we know what they are doing we know so what other people did before so if we have a knowledge of the workflow then we try to infer what could be the intention and then we put if you're doing well we don't do anything all the way we put additional information so it's technical and enhancement can be augmented reality visualization but can be also sonification and then we try to help or assist people during the task so that's what we we do in augmented reality we call it as a cognitive augmented reality so basically way too is behind that it's a lot of machine learning it's right from data to learn everything we see that the body sensor network we have is we capture the biomechanic of the people but we see that we have much more information inside and just a kinematic about the task we can see fatty we can detect fatty we can they take much more and I'm going to be very happy to see if we can detect depression in the data we have and then so we look now for more smaller signals and we add slowly let's say also some other sensors which capture physiological data and the ideas and to use that for yeah for better assistance system for maybe new Terapeak system and so on okay so you speak you know I'm just no I'm just making job I remember the first time I saw a motion-capture MIT people putting sensors on your knees and elbows and I gotta stick to be able to create a character that walk playing if you want or whatever and so this is emotion sensor in a sense that that you'd be able to capture intent and reaction and yes emotional basically yeah its motion sensors they're connected together now we managed to make them so small that's their inner inner closes basically we take this Najim bring it out of the lab yeah and we can yeah we work on different techniques is called Auto calibration so you just wear this and so you could start to work in everything calibrate and we managed to make them stable over a longer time not 10 minutes bits hours for that we yeah I can explain we remove some sensor magnetometers and Sun and yeah so we get to kinematic very stable over a long time yeah and just imagine if there's little little tiny sensors of brain state embedded in you as well thank you yes Michelle in my harvest I am professor at University California Berkeley and more recently co-founded and run a company called iota with Jose Carmen ah my partner in crime and many many things for many years now so I guess I'll start off with a thought an observation that there isn't a single implantable neural interface that you could put in someone today that will last an appreciable fraction of that person's lifetime so that that's actually a fundamental fact behind how people build clinical studies how you know we choose the problems that get translated today and as it exists as the that clinical ecology exists and I think that you know one of the challenges or maybe let's not say challenges one of the things we're going to see over the next 10 years is an interplay and this sort of answering of a question of where between imaging and non-invasive methods and some of these very invasive methods do you begin to to finally build interfaces to the brain and not just the brain but the periphery something that Jose and I are very passionate about at i/o to biosciences so I'll tell you a little bit about that but before I kind of do that little pitch that the that thought I think though should sink in because it's something that's often ignored it's a it's a it's a problem that is at a technical level is straightforward to articulate I can give everybody a little mini lecture you catch me on the side as to what it is about the neural interfaces that that are failing but it's an unsolved problem and everybody from you know neuro-link to whomever is is trying to solve this so you know to and then to kind of end up wrap up a little bit you know iota Biosciences was born out of this observation that we made is fundamentally a physics operation that then turned out to have it to be a pretty big deal which that picked up this academic monitor moniker neural dust which was all the rage for a bit but the observation is very simple it's that there has been a long-standing dream and many for many reasons Diagnostics recording brain state peripheral nerve neuromodulation whatever you know would be great to have very very small implants but I mean vanishingly small implants completely wireless complete tether list that you could go after very small nerve targets or processes in the brain and every time someone tried to do this in the past you know you you tried to do build a little radio or do some coil or something and physics works against you and the observation that in fact the right way to do this was with the physics of ultrasound you you it's a magic universe at that point because the the physics of ultrasound allow you to power and build a bi-directional communication interface with objects that today in current manufacturing are you know millimeter in size and if you look at the physics these are the papers that icon the academic side you know sort of we published over a few years you can go down to much much smaller sizes and so the the idea that you could fit bit your liver mmm you know for certainly brain state certainly peripheral ear model modulation but take a step beyond that what if you were at risk for fatty liver disease because you got genotyped and you knew you you had you were at risk and I you know we at iota we park a moat in your portal vein that tracts so oxygen state coming out of the liver and in furs liver state every morning you kind of you know and you'd you know you take your thing you can't do that with a wearable when you know when is where when do we get to the point where that'll be something that's fairly straightforward minimally invasive you know and it's a very different world on the other side of that all right there you go thank you yeah well Chris last night when you asked me what my focus was you probably saw my I start back and forth because they did that all the time yeah but I'm not very focused I'm I have really four occupations I'm trying to juggle one is being a bio behavioral neuroscientist at Stanford and doing some basic research on new interventions for depression and autism and Asperger's and and addictions I'm also working as a medical product developer trying to translate some of the basic neuro findings out into product zones I'm working as a technologist I had the pleasure of being around in the very early days of Hertz reality technology more than 33 years ago and I was part of the debate as to what we're gonna call it and I actually argued against the term virtual reality I thought it was a little bit too glib and I argued for a very scientific term I'm so glad I lost that argument but I've been working in the field of virtual reality augmented reality technology for medical applications now for considerable amount of time and one of the things I'm really excited about is we are going to have some very powerful assessment systems and very powerful intervention systems because of this emerging technology and it's it's going to be a strong part of our life in general it's going to be the next communication platform next entertainment platform next way that we we work how we interface with technology and the good news is I think about dramatic implications for both the clinical work we're interested in doing in the basic research we're interested in doing you want to describe one of those assessment and intervention systems I'm sure we now have ways of evoking an emotional state or a common state in a very culturally sensitive or age-appropriate manner in a reproducible way and have people have a challenge that they respond to we also have a way of for the example with treating addictions to have a virtual environment where people can learn refusal skills or practice situational confidence for in the zone of the autism spectrum disorder were able to have people rehearse social interactions and we can exaggerate the nonverbal communication body language facial expressions etc and all while you know to take a cue off some of your work is capturing the the small movements the micro movements and understand some of the basic interpersonal dynamics people have not just how they interact with environment but how groups of people work together so it's a powerful tool for research and for interventions mm-hmm thank you so there's a bit of gamification and a lot of VR and and the time of the of the individual well part of the challenge has been that you know originally VR was viewed as a gaming environment right and so we're now seeing it shift over to the enterprise the tech Titans have put billions of dollars into developing this technology they're not going to recoup it through entertainment and gaming so they needed to work move to the enterprise the medical is one of the biggest enterprises and they're investing heavily in this arena we still we can take some of the learnings from gamification and make some of the interventions to promote adherence because we can use gamification as a way of facilitating engagement right but it's in a way it's worked against us by having people not view this very powerful technology as a tool but more as a game uh-huh yeah great so I'm gonna follow on what Michele introduced so the next step in after we focus on what right now we call from the neck down by electronic medicine applications nerves and organs is the brain ultimate frontier that's relevant to the topic of brain machine interfaces which is what I have dedicated my academic career at Berkeley and where I build a long and fruitful collaboration with Michele so I want to make two points really about this brain machine interface so I'll start first with a obviously has different components one of which is very important if not the most petite a technology to be used the second one is the the AI or machine learning block and that's really something that we have been putting a lot of thinking about because we look we like to look at this problem as a to learner problem is the brain and is the machine in the same loop some natural artificial intelligence at very different time scales of adaptation for example so it's a very interesting problem how can you get or leverage the volitional part of voluntary motor control of the brain and the plasticity mechanisms about learning new skills for example with the much faster timescales of adaptation of an algorithm we thought compromising what the brain is learning so it doesn't become like a moving target so how can you really get this to intend them to work in a fearful way right so that's a very interesting problem but on the spirit of the brain centric topic of this meeting the other thing part I think fascinating about this problem is that we like to look at it like how the brain learns skills so we have a very action centric view of the brain everything the brain does is action if we don't move you die okay so that's an important point meaning because even perception you can look at that like an action from the brain right so the transformation of sensation into perceptions and action that the brain produces so how does the brain learn to produce new yorks or you know whether these are motor in the motor cortex or decision-making improve frontal cortex or attention your visual cortices and what we have find out and this is with our academic hats is that there is this common structure between basically across the whole new your cortex that involves cortical chemistry at all circuits so it's a cortical straight a loop that is common across the hall near court is whether you are in prefrontal or occipital cortices and the point is that these circuits are necessary for learning actions again motor sensory or even more on the decision-making real right so the BMI problem is again one of those new actions how the brain learns to control a prosthetic device it can be seen the same way so we can learn very important principles about how the brain learns skills in general to use them in how can we empower a healthy individual to control more degree of freedom in the world in a more invasive or less invasive manner but right all the way to of course what today is beat centric in BMI which is helping people with disabilities right which is the first entry point the second I'm very rapidly pointer when I make is that the transition of this motor or prosthetics application of BMI is moving very rapidly into the domain of mental health what we call mental prosthetics in fact you kill my question because it was gonna be like what do you think well shall it Jessica well played yes actually are we actually bridging now so to the actual question yeah so what I was gonna say is that I think the the fill is moving very rapidly into these leveraging they now have these new technologies and what can we do with them these closed-loop systems to treat these new psychiatric disorders in a very different way that pharmacology right which is basically mapping the individual's physiology circuits identify the nodes in the network that are you know responsible for certain conditions whether the circuit is the inside the depression and then apply intervention stimulation for example to alleviate those and maybe in the gold I mean in the long term the goal the long term goal being to to cure like to unlearn those conditions because of you know inducing plus the see do you think that's actually feasible so or the only way to unlearn very interesting question of course and having this discussion throughout this meeting trying to understand first of all the functioning of the neural circuits I think one of the things that I was very impressed by how neuroimaging can distinguish between depression and between schizophrenia and between anxiety so once we understand there are those neural circuits and then the mechanism and how could causes problems then there is possibilities of course as we know in depression the best known thing that we knew about treatment of depression and I've seen it myself with DBS deep brain stimulation facial you know the patients are awake when the DBS is being provided and the patient will start laughing and what are you doing to me and the emotion changes so there's clearly evidence that that is possible but you're a question then can modulating the mural circuits can help in alleviating depression there are a lot of complications it's not that simple I mean my mind so the moving forward we would have to think about modulating the circuits probably non-invasive we heard early about ultrasound focal ultrasound and I think it has a potential similarly in Israel that they have been in advanced in TMS the deep TMS which is now going much deeper the brains way which is developed I mean I think Spain is well positioned to develop that kind of work which we can target those specific circuits in that regard back to what our group came back with however I still believe that psychiatry is somewhat different like a stroke is very similar in two patients but depression is very different in two patient so personalised and identifying so it may take some time before we reach that goal the I would might add with your permission so the closed loop that you're talking about the reward circuits that you're talking about addiction ology is another huge field neither DARPA DoD's throwing tons of money right now to look into opioid crisis how neuromodulation might be able to help in that regard at your TMS is being used for that purposes still in experimental stages my point is that there is so much that can be done by modulating these and we have a long way to go especially when it comes to neuropsychiatric disorders thank you so your question for Lydia all right so one of the things that you mentioned that you have these external sensors have you develop or is there scope of developing specific sensors for certain disorders like panic disorder is very specific increased respiration increased pulse rate increased heart rate and it can be closed-loop it can be identified earlier is there some work which is going in that area yeah yeah yeah yes indeed we we start to work in this area every starting point maybe just a word there's a body sensor network we develop is becoming mature so we get a kinematic of a person pretty well with a lot of details and there we are now looking at more physiological sensors because I think that the next step to to having to mix this information with some other more behavioral data system so we look at basically how to measure heart rate from an external camera because you can just read from the skin the palace and so on and so that's start to work as well pretty well but our goal is to put that out of the lab again so that in any kind of environment even with the camera which is not super high level or in some condition with external lighting like in a car and so on to try to measure the pulse and basically what we get is a wave and this wave is we can measure or her trait variation and apparently correlate also to respiration rate with some da so we start to look at that so it's possible that's going to be possible and that will be very interesting to to awesome mix that with behavior or data so I think that could be the the next step here thank you I think my watch can do that now EKG well I mean that's respiration art variability yeah anyway yeah it's close it's the same technique here the same technique basically such we use external camera yeah your question oh so I was wondering we focus a lot on the brain we focus more on the body is that sufficient to just look at the brain for brain computer interface or for characterizing characterizing for example depression or characterizing anything I think we should look at it further and we were interesting in more classifying of disease a mental disease so and for me some depression is very complicated and they're very as you say we need personalization so what would be the past - yeah so we violently agree with you absolutely so so the the idea that you're just gonna drill a hole in someone's head and that's the that's the story is pretty absurd I'll answer it from the perspective of an engineer that thinks about how to get things translated and then you know over long periods of time make a difference right get things into actual people you know I think there's no doubt that the the peripheral nervous system and Oregon State are things that are now accessible and and the amount of data that you could potentially get not only the things you can do clinically actionable a like stimulate nerves to get effects therapeutic effects in diseases which is of course you know what what investors usually interested in but the idea of the amount of state that you could pull out using manipulative a Savannah bulls that are close cousins of the things we dream about for CNS is a very very powerful idea you know if you want to be a little science fiction you or a lot science fiction I think the notion that you could you can imagine a future where not the technology for this doesn't exist yet but you can imagine a future where you can pull out most signals going through your vagus signals going through your spinal cord maybe if the spinal cord is inaccessible except in limited ways you go downstream and you you find nerves here plus Oregon State not just the things your watch does but a lot of the things and what's interesting about this we're finding it now and one of the therapies we're working on and we've been but you find it in many many things it's like anything you know when you have a new instrument and you start going to the level of what that instrument can do you find that people actually don't know what's going on so you know you find it you go to Grey's Anatomy or you ask your friendly clinician and they'll tell you all that well of course that nerve goes like this and then you start to say okay yeah but we actually are messing with that nerve right now and it doesn't really kind of do that it looks like it's very heterogeneous or it turns out that there's like a bunch of weird stuff going on here even strange things like simple things like you know what is the temperature distribution along your gut during the day there's austere stuff like that so I think that's that's the world you're gonna see pretty soon sure yeah yeah thanks my turn so I I have a question that it might seem like a soft ball but I'm super interested because I follow a RV are sort of voyeuristically and I'm calling it extended reality extended reality there you go I'll use that term since use the RV are I was following along but since you work in it so deeply you know I'm actually honestly curious there's a lot of relatively obvious things that are gonna come online I mean you know I from the technology side from the people doing direct right to retina for AR you know all this stuff so you you can see the next few years what's kind of easy to interpolate but you work at a deep enough that what is the most non-obvious thing that worked that in ten years will be true that none of us kind of really it's kind of easy for us to guess right so right so so we make sense a lot that's not a softball question yeah well I make something up we won't know right that makes it non-obvious extra non-obvious I probably can guess what's going to happen I just really can't say when you know I I think that we're gonna see a blending of the technologies that we use for work for entertainment for healthcare I think our interface to our smart cars to our technology system aren't gonna be limited by the small bandwidth that we have of texting or typing right now or even talking over the phone or even skyping which isn't really an experience it's more of a window of interaction I think what will change this will have much more rich ways of interacting with people and you know and today is always on world with I I think we're getting more and more limited and sometimes getting dark very Cartesian I think what's going to explode is more experiences that we have with each other and with family members and friends and colleagues who are at a distance and I think that we'll have a social strong social effect I'm excited about the applications in in research in clinical care but I really think there's a wave of technology coming that's going to not limiting as some of the recent technologies had but really expensive 33 so that's actually fascinating so you know a lot of what's if in the Bay Area but probably everywhere in the world you know that sort of people are getting increasingly depressed that we're all just sort of staring at this stupid little rectangle yeah like all the time now right and so you really are optimistic that that AR will crack that open and we'll stop doing that but it's not just because I'll be checking my email while pretending to look at you know I think what will happen is that you'll have a way of going for a walk with me instead of texting and and having a dialogue along along a beach or obviou to see your what instead of what you just described to be verbally about your work you'll be able to throw it up and I'll be - I'll be wearing some glasses or maybe something will be projected into my eyes and I'll see dynamically what you were trying to describe with a few words and will be an interact with it together so if you can control a robot arm with your mind today you can presumably control your avatar tomorrow with all the things you're all talking about right and then you can modify your avatar because you know why get a facelift when you can give your avatar face and then you'll have very rich social interaction well in fact that's what these bread and butter so I don't know of you it's right but that's what he spent his career that's my question what's the question so actually my question is I got a pretty good feeling for the measurement technologies you have on the analytics what I don't quite get maybe I missed it is the feedback loop how are you taking those assessments and turning it into an intervention so the feedback loop right now in the BMI BMI field is pretty much dominated by visual feedback that's how we close the loop because there is you take it for free it's perfect you don't have to encode visual information the next level which is already happening in many labs is enhancing that with artificial somatosensory feedback the example will be to feel what the robotic arm is grabbing with the gripper an artificial sense of proprioception where the robotic arms in space for example so that will be like increasing the embodiment of a prosthetic by artificial means of course that goes on and on I'm talking is strictly in there in a motor scenario but with a extended extended reality case and the avatar you could imagine pretty much that being the case you can be confined someplace and basically having your avatar interacting somewhere I'm filling that right that's a plausible scenario because of the technologies of what people are doing right it's like combining as you said this with this with that and I'm not saying that that's a ideal future or that's what we want to do it but that's where we are gearing towards at least to make that happen for whatever that will be useful for and I think this is a great forum to talk about it the only add-on I want to add to that is thing I forgot to mention earlier which is the ethics component in all this implantables especially for mental health because it's really I mean I think the the data and experiments are lagging are leading the ethics so we don't even know what to do what issues our agency and many other problems associated with what happens when you stimulate deep into the in the brain of someone right and there are many testimonies of people with DBS saying that they feel the sense of self is different when they are the stimulator is on or off or intermittent whatever so it's a big deal if you know we're gonna transition from wearables to implantables and people are gonna be walking around with these things for medical indications first later on likely for other reasons and but we don't have a framework to deal with all the issues well we'll develop that framework this afternoon no problem but seriously that's that is the we are at a point where we've discussed more like our earlier and now closer to D of how the science is moving toward affecting our world and we will this afternoon talk about ethical issues among others so I think at this point we should thank our our panelists for being part of this part of the fishbowl and then we'll ask you to do one more thing before lunch so thank you very much for being with us [Applause] 