 Good afternoon. Good evening, everyone. My name is Lee, and I'm a principal bioinformatics architect with Amazon Web Services. First, I want to thank you for taking the time to join me today. In this talk, I wanted to cover some of the core concepts for building scalable genomics data analysis using the cloud, but before we begin, I think it's important to understand what the challenges are in genomics when it comes to data analysis, so let's take a look at this chart. This chart shows how much it costs to generate a whole human genome from the years 2001 to just last year in 2019. What's started as something that mirrored Moore's Law has rapidly accelerated to the point where the cost of genomic sequencing is at or below $1,000 and making it much more widely accessible. And so globally, over about $4 billion has been appropriated to population sequencing initiatives to better understand genetic risk factors and contribute to population health, and it's estimated that over 60 million individuals are expected to have their individual genome sequenced in a health care setting by the year 2025. So ultimately, what that means is that the amount of genomics data generated each year outpaces that from other fields that you think of traditionally as large such as astronomy or social media or video content, and if you look closely, you'll see that the footprint of genomics data is expected to grow annually on the scale of exabytes. So when it comes to processing genomics data or running genomics workloads, there are a couple of key considerations. First is the size of genomic data. It can be there are multiple types of genomics data. You can have whole genome sequencing. You can have whole exome sequencing. You can have target of panels. The size of the data can range on the order of tens of gigabytes to hundreds of gigabytes per sample, and the amount of data, as I showed before, is rapidly growing because of continuous improvements in the sequencing technologies. Second is the compute required to process that data, so there are many steps linked that are used together to process genomic data from its raw form into a scientifically usable form, and there are a lot of tools involved, and each one of those have varied computational needs depending on the genomic data type and tool that is involved, so in short, one does not simply process whole genomic sequencing data on their laptop. So how can the cloud help? Well, the level set, I think it's important to kind of talk briefly about what the cloud is, so cloud service providers like AWS provide four fundamental services that enable all of the services and infrastructural agility, so first of all is compute, so with Amazon, you have Amazon Elastic Compute Cloud. You can think of these as cloud-based virtual machines. There's storage so things like block storage like Amazon Elastic Block Store, EBS, or object storages like Amazon S3 and Identity and Access Management, so in AWS, this is AWS IAM, and then these three fundamental services are then used and cobbled together to create higher-level services or managed services, things like AWS Batch or Amazon Elastic Container Service which I'll talk about a bit later in this talk. Another important fact is, the cloud is globally distributed, and so if you look at AWS' global infrastructure, it has presence in 24 geographically isolated regions. Each of these regions is comprised of multiple availability zones, and these availability zones are distinct but closely coupled data centers for a total of 76 availability zones worldwide, and it's important to note that this footprint is always constantly growing and increasing at a pretty significant rate, and so with all of this, what does the cloud provide? Well, it provides five things, so there's security, so at its core, AWS infrastructure is custom-built and designed to meet the most stringent security requirements in the world. Next, there's availability. Cloud infrastructure and services are designed for high availability, and applications that you build on the cloud can be spread across multiple AZs or multiple regions so that they are available to you and your customers. Next, there's performance, so AWS offers low latency, low packet loss and overall high network quality. Next is scalability. Cloud applications can dynamically scale and grow to meet the needs of immediate demand or scale back, so that includes scaling up and scaling down as demands against a cloud-based application rise and grow, rise and then decrease over time, and then finally, there's flexibility, so you can run your applications or develop their applications where and how you need them, and all of this is given to you at reasonable cost, so what you can think of the cloud as is more or less computing as a utility, so AWS provides you with computing services kind of like you would think of, like, your local utilities like the power company, so think of it like you would go to your home, and you could turn on the light switch, and the power comes flowing in. You can think of AWS in the cloud as providing computing in the same fashion, so what does that translate into? Well, that means that computing infrastructure is available to you on demand and fit for your immediate needs. You only have to pay as you go and pay for what you use. There aren't any up-front contracts to get started, and also, finally, you can focus on the applications that you want to build that differentiates your workload from everything else and not have to worry about managing the underlying infrastructure associated with it, so let's talk about how using the cloud applies to genomics data analysis, specifically workflow pipelines, so when we talk about genomics workflow pipelines, they typically looked something like this, so you start with your raw sequencing data, your As, Ts, Cs and Gs, and you have a sequence of tools that you need to use to process them into a form that you can start to interrogate and use for scientific or clinical action. Each of these tools expects a files input, and they generate a files output, and each tool in this workflow is unique. Some of them can be command-line utilities. Others can be Python scripts. Others can be compiled like Java or C++ programs, and so underlying that is that there are a lot of software dependencies to manage. Similarly, each tool has specific computational needs and performance profiles, so some of them may be compute-bound. Others will require lots of memory, and also, parts of the pipeline may run quickly while others a little more slowly, so this adds complexity as to how and when a tool in the workflow should be run. So when it comes to running your genomics data analysis and workflow pipelines, there are three major infrastructural components to consider, so first is data storage. Next is job execution and finally workflow orchestration, and we'll cover all of these in this talk. So let's start with data storage, so there are three aspects of storage to consider. First, you need durability so robust and accurate storage for both your active and archive data. Second is availability. You want to be able to access, have your data be easily available to you, to your collaborators and to the compute resources that's going to operate on it, and finally, you want controlled accessibility or security. Genomics data is arguably the most sensitive type of data. In fact, it's a person's biological source code, so you'd expect the highest amount of security around it, and so for these three reasons, I would argue that cloud object storage like Amazon S3 provides the easiest way to store with 11 lines of durability and security share data, and as a highly available resource, it can provide a cloud-native single source of truth for your data-heavy applications. So let's talk about how you run workflows, specifically all of the individual jobs within a workflow, and so if you take a step back, there are kind of a couple ways that you can think about to run a workflow. The first is to take your workflow and run it entirely on a single compute node that is scaled for the biggest job in your workflow, or what you can ... And I would argue that this is a more scalable way to do this, is to split up your workflow into individual tasks and distribute those tasks onto smaller compute instances that are more fit for purpose and fit for size for the task at hand, and so we're going to walk through this model of running workflows for DNA analysis. So if you kind of zoom in on one of these tasks, the basic processing pattern looks like this, so you'll have your raw data that's stored in object store so like an Amazon S3 bucket. You'll have a compute node that is like an Amazon EC2 instance like a Linux server with an attached EBS volume as a hard drive, and on this compute node, you will have a specific tool installed on it, and so you'll take the inputs from an S3 bucket. You'll stage it onto this compute node. The tool will do its job, process that raw data into an output, and then that output is returned back to an S3 bucket, and so for each step of a workflow pipeline, this pattern repeats itself. And so what's important is, you want to be able to use each of the computing resources as efficiently as possible, and so you'll probably think about, "Well, I want to try to place as many jobs as I can that are fit for that compute node to run in parallel." You might run into challenges there where you'll have dependency clashes, so in this case, we're looking at a tool here that requires, say, Numpy 1.14 and another one that requires Numpy 1.18, and you can't run these two tools at the same time because you could run into dependency clashes with this particular library. And so some of the best practices here is to isolate each of these tools from each other, and the recommended way to do this that is kind of promoted by the community is to use a Docker container, so now if you containerize these two tools, you can run them simultaneously on this compute node and not have to worry about dependency clashes between them. Second, you want to be able to carve out this computing instance to fit the jobs that are running on it, so here, I'm showing a tool here that requires a lot of CPU and a lot of memory so 16 CPU, 64 gigabytes of memory and then another tool that's also running simultaneously on it that requires about half of what the other tool requires, so you want to be able to carve this out within this compute instance. And then finally, you want to match each of these tools to the right compute instances, so here, you have a memory-constrained operation. You want to place that on a memory-optimized compute instance, so something like an R4 type of instance from Amazon EC2. Conversely, if you have something that's compute-bound, you want to place that on a compute-optimized instance. And so what you can now do is, you can take compute instances, and you can group them into logical clusters or compute environments, and these compute environments can be based on either on-demand instances, or if you are cost-conscious, you can use spot instances which are spare capacity in AWS' cloud infrastructure. And then you can take all of the tools in your workflow and schedule them up in a job queue, and then you can use a service like AWS Batch to schedule these jobs onto the right compute instance at the right time. And so now, let's work about kind of workflows as a whole, so workflows as a whole, they can be complex. As we talked about before, there are multiple tools involved. There are multiple paths within a workflow, and there can be multiple outputs in either intermediate or final from within a workflow. And so this is where workflow languages help abstract the problem away, workflow languages like WDL or CWL or Nextflow or even Amazon States Language, and what they allow you to do is to distill the jobs of your workflow into their core components so, in particular, a container image, the immediate compute resources that that job requires, the command or the task that that job performs and the data inputs and outputs associated with that task, and then they also allow you to define the relationships between those tasks so either organized by orders of steps or, in most cases, by data dependencies between each task. And so if you wanted to assemble this whole picture together, what you do is, you write your workflow definition using one of these languages here. You would send that workflow to an orchestration engine that's specific to that language, so for WDL, you'd send that to Cromwell. For Nextflow, you'd send it to Nextflow. For Amazon States Language, you'd send it to AWS Step Functions, and then you would have that engine would then integrate with something like AWS Batch to run those containerized jobs in a scalable way, and then finally, while this workflow is done working, it would send all of its data to cloud object storage like Amazon S3. So what do sample architectures look like? Well, let's start with this one. This is an AWS reference architecture for using AWS Native Services. It uses AWS step functions as the workflow orchestrator. It uses AWS Batch for job execution, and it uses Amazon S3 for data storage, and what's important to note here in this architecture is that it's entirely serverless. What that means is that the compute scales up as needed when running workflows and completely scales down when the workflow is complete, and so there's no permanently running servers to manage with this architecture. Next, this is an example architecture that shows running Nextflow on AWS, and again, it's important to draw out some of the patterns here, so we were running Nextflow as a containerized job, so think of this as the workflow orchestration layer. It is now also talking to AWS Batch for running individual processes within a Nextflow Workflow, and again, data from the workflow itself and logs and session cache of the workflow are sent to Amazon S3, and so like the previous step functions example, this architecture is also entirely serverless. Here, AWS Batch is handling all the scaling required to run a Nextflow Workflow, including the master process and the individual tasks in the workflow. And finally, here is something that's slightly more complicated. This is an example of architecture for running Cromwell on AWS, and the only difference here is that there's a small server, a small EC2 instance for the Cromwell executable to be running in server mode. Otherwise, everything else is roughly the same as what you saw before. Jobs are sent to AWS Batch for processing. The cash data here is being sent to Amazon Aurora Serverless and Amazon Aurora Serverless database, and data from the workflow and logging information is sent to Amazon S3. So what does this actually look like in real life? So here at ... This is an example from the Quantitative Biology Center at Tubingen, Germany or QBiC. It's a research center that's located at the University of Tubingen in Tubingen, Germany. They moved their HBC environment and data management platform to the AWS cloud, and QBiC now runs Nextflow and AWS for their workflow management using AWS Batch, and they're able to efficiently run hundreds of thousands of batch computing jobs in the cloud. Using this, they can easily scale on demand, be it processing 30 samples or 100,000 samples for one research project. In doing so, they were able to reduce the research and processing time by 50 percent for all of their jobs. Next, this is one of our newest genomics use cases that recently came out. This is from the Fred Hutch Cancer Research Institute. Here, they were using Nextflow and AWS Batch, and they had a project where they were processing 15,000 biological samples, each about a gigabyte in size, and using architectures that I described before, they were able to perform the equivalent of 7 years of compute in just 7 days. So there's certainly a lot more that I could cover, but unfortunately, there isn't enough time in this talk to do so at great depth, so what I want to do is, I want to leave you with a couple of parting thoughts and areas to explore on your own. So first, while the architectures I've shown you before may look complex, you don't need to build them from scratch or manually, so workflow definitions, as I'm sure you know, are source code, and they can be version tracked and distributed using source code revisioning tools like Git, but it's important to know that you can also define your cloud infrastructure as code and automate its deployment with services like AWS Cloud Formation, and this makes it easier for you and your collaborators to reproduce cloud environments for processing genomics data. Also, the concepts and services I covered are both the most cloud native and also the most cost optimized, but we here at AWS recognize that every customer is unique, and as such, there are plenty of options to choose from to meet your specific needs, so for example, there are many different workflow orchestrators to choose from. There are also many different ways to handle job execution like using familiar HBC schedulers, using AWS parallel cluster or using Kubernetes with Amazon EKS, and finally, there are also different storage solutions that you can leverage like NFS Shares with Amazon Elastic File System or high-performance parallel file systems like FSx for Lustre, and so I think the most important things that you should take away from this talk about using AWS and in more in general the cloud is that the cloud provides storage as a platform. There are a broad spectrum of compute instances that you can leverage to process your data as efficiently as possible. There are plenty of managed services for doing task execution, running analytics, doing machine learning, and finally, there are serverless and container-based architectures that provide you flexibility and agility. And so with that, I encourage you to explore more and learn more about the cloud in AWS and how it can be used for genomics, and so here is some extra resources that you can use to get more details about the architectures and concepts that we discussed today. Specifically, here is a prescriptive guide for building and operating genomics workflows on AWS, and if you're looking for more, we have blog posts and additional use cases that you can check out at our AWS genomics landing page. And with that, I'd like to thank you very much. Thank you for your time, and I hope you have a great rest of your conference. 