 [Music] hi and welcome to episode number 184 of the weekly Google cloud platform podcast I am mark and today I'm here with Mark hey Mark hey Mark how are ya I have a cold so I'm at home and my house is flowing pop but that's none of that I'm doing well how are you doing you know I like your positive attitude which is off yeah thanks that sound that sounds bad it's fine it's fine everything will be fine eventually it all works out after a while but we have a great interview today Debbie and I did an interview with informatica with Bill Creek balm senior director of product management for cloud big data and analytic ecosystems at informatica whoo that is a long title I hope when they have a title that long but we talked all about hybrid cloud with big data and analytics migrations from prime to cloud with big data analytics all sorts of good stuff around essentially big data analytics that sounds pretty exciting and I think that if you tried hard enough you could probably just insert more Google products into your title yeah I think so master of a gonna say and kubernetes and dataflow and bigquery and also consultant on and you could just keep going they not have to learn a lot more products that I currently know and that sounds hard and I don't feel like doing that well in order to test your knowledge there I have a great question of the week for you which talks a little bit about App Engine and using custom domains but before we even get an assassin we should talk about our cool things of the week we absolutely should so first of all let me say a Ledge congratulations to Chronicle if you're not familiar with Chronicle they are the security moonshot company when inside Google that deal with all kinds of interesting security stuff you may have heard the episode we did previously 1:35 talking about that one of their things which is virus turtle which is actually a free scanner for files for malware and viruses can also be used by companies it's very very cool and she's one of the things they do in the security space but pretty excited to have them on board with Google cloud to help enhance the security features we have with Google cloud and make all the security things better for all our customers yeah I mean it sounds awesome and I think that it's not as though people aren't concerned about security and you know we talk a lot about encryption and all the kind of different infrastructure level security offerings that Google cloud has by default but for a larger company is like you need more right you need virus protection email infection all those things so I think that then joining Google cloud will really open up some real cool opportunities for people who use the cloud one of the cool things that I was actually just recently reading is that we are opening a new undersea cable absolute it's right around though the west coast of Africa so it goes all the way from Europe all the way down to the bottom of Africa and case you weren't aware Africa is a very big continent so that's gonna be a big cable I just think it's fascinating when I joined Google there were a lot of people making jokes about the undersea cables and the shark proofing which apparently is a real thing right and for anyone who hasn't heard of it you know we had these big undersea cables that is the thing around the clear thing and a common problem apparently with those cables is that sharks like to eat them which I can't relate to I have today I believe it actually has something to do with the electronics going through it and it sets up their sensors and like they like really like I don't know exactly but oh I should do some research on that sounds really cool yeah but for the people who are trying to get internet through those wires it turns out sharks are kind of a pain yeah generally speaking people chewing through your cables is a bad thing anyway I think it's really awesome and it just fascinates me that we're just building these huge pipelines to just kind of add additional connectivity for a lot of different areas so I'm really excited to see this one come online the next two years yeah absolutely and shout out to all their listeners in Africa hopefully this works out very well for you alright cool so I think I have something else as well oh yes I would be remiss if I didn't mention kubernetes at least once in a podcast so this is a little bit ago but I don't think it's been mentioned so far kubernetes 115 congratulations to the team on that release I'm pretty excited about this this is a lot of extensibility around Cora Crippen Eddy's API is including custom resource definitions and a lot of new features for custom resource definitions which is an area in which I work in a lot so it's very excited about that as well as cluster or lifecycle stability and usability improvements container storage functionality and lots of other good things there as well so if you want to dig more into that there's actually a really good article that will link to as well talking about the future of customer resource definitions which they're calling structural schemas that's a lot of alliteration yeah when they go into that a lot deeper and I'm pretty excited about it looks like it's gonna be really really handy for those people who write controllers and operators you know there's a little lot of obviously a lot of recent news around kubernetes and then somewhat related is sto of course which I think just relaunched two or 1.12 not recently I should know that but I think it's super cool to see all these updates I'm seeing a lot of stuff on the internet about people being scared about kubernetes kind of adding too many features into that so I'm really interested to see how the community is really driving a lot of the kind of upgrades and different things that go into each kubernetes release yeah I think you know and it's just year 1.2 I check it out for you this could be a whole episode in and of itself you know I think there's two things to that I think there's a lot of stuff that you can just do with kubernetes like services and deployments and that's it like you could just get started with that you know you can get running but I think all the extension mechanisms mean that people can build simpler layers even or highly opinionated layers going forward as well to make things easier for very specific workloads so I think there's there's a two-pronged approach there but yeah that could almost be a turn episode that sounds like it might be a good episode actually yeah actually now that you mention it why don't we do that episode we should do that episode all right well make a note and do that cool but let's finish this one first yes I have one more cool thing of the week which is now that stack driver profiler is now generally available who fancy this was a really cool tool that it was I think wasn't beta for quite a while but it actually lets you kind of look at production code that's executing and then kind of see how it's performing as it traces through like as different functions are being called and you kind of gives you this cool little visual stack of where your time is being spent so for a lot of the people who use stackdriver and a lot of people who actually I should say who are using production code on GCP stackdriver has been a really awesome tool because it lets you do live code debugging and fixing in production mmm which is super impressive but probably not fixing but actual like observation and seeing like oh well you know sometimes in dev you just can't reproduce that problem yeah so being able to reproduce it in production and then having a really clear visual graph of like where those slowdowns are and where the problem might be I think that's super awesome and so now that it's GA I think hopefully a lot more people will be more comfortable trying it out yeah that sounds really great fantastic well I tell you what why don't we get stuck into the interview that Gaby and I did with Bill from informatica and we can hear all about big data and analytics and all sorts of other fun things cool excited to hear it [Music] so I'm very happy today to have Bill Creek bomb here senior director product management cloud and big data ecosystems from informatica oh my god that's a lot bill how are you doing today I'm doing great thanks mark thank you so much for joining us today before we get stuck into some big data things and talking a little bit of informatica as well that is a really big product title so and who are you what do you do what was listed all about so I have the privilege of working with the cloud big data analytics ecosystems are informatica and a lot of our customers would think especially in a context of Google that means we really focus on connectivity to bigquery and Google Cloud Storage but we actually have a much broader charter I'm really focused on making sure that all of our products take the most advantage of the strengths of the Google cloud platform you know so for example we have a big data management product that allows customers to visually build and manage Big Data jobs that integrate with all our governance tools and what not an option that we have through the partnership with Google is we allow the customers to design and informatica and push the job down to data procs so it actually runs as a pushdown job there we can do similar capabilities with bigquery more recently we have really done a lot of partnership with Google to create value added solutions for our Comment customers and its far more than just connectivity now we're really thinking about you know broad use cases you know customer 360 type use cases marketing use cases it's very excited so you said a little words that I'm gonna guess relate to Big Data and stuff but why don't we have start at a high level like so what is informatica actually do so you know informatica provides import photo of data management products you know all of our products are very metadata aware and you know the benefit there is by having a complete solution that focuses on you know integration governance security data quality and discoverability you know you have that completely integrated solution that allows you to you know move quickly move safely deal with you know strict regulations with confidence and at the same time deliver business value right I mean everyone talks about the democratization of data this is how you do it yeah you're missing any one of those pieces then you're starting to worry you open yourselves up to risk and then that's when you start to hold the data back and so I think with our platform you know we really allow business users to get a hold of the data awesome so what's like a really great example of someone using informatica and Google cloud together that the people might like what would be a canonical example of that there's a couple of really good examples yeah I think a lot of what I've been really excited to see recently is you know customers that you try to build like a customer 360 type you know analytical solutions and you know they started on Prime they started using Hadoop and that was really a lot of the promise of you know the beginning of the big Native movement but the operational costs are just so extreme and but now they're working with you know Google and bigquery in particular and there just seems so much tremendous opportunity to move those very expensive workloads on-prem into the cloud they're saving a ton of money but more importantly they're seeing new opportunities that technology is opening doors to new use cases and I think that's my favorite part is like customers begin the journey is like oh it's gonna be cheaper for me to run it at the cloud and then they pause I think like Oh a living you mean I can do it completely different and faster and still do it cheaper definitely you start to see the creativity of our customers in our industry at large really take flight so if I'm a ticket then it's more like for one I got it you were able to facilitate ETL processing for customers let's say you let them build their own pipelines apparently and beyond that how the customers approached you you started some already have an old set up idea from the beginning of big data but how usually like a new company comes to you to have no big data at all they want to start doing it how does approach happens well you know it definitely depends on where that particular customer is in their what's called the modernization journey right but what we've been really excited to see is that when our customers use you know our complete portfolio not just our integration products but the complete portfolio especially with you know our metadata driving cattle like it please because they start much more from a use case perspective they start from a business object perspective you know because first of all you know you gotta find the right data right you might have like a sales operation use kiss right and you're working with sales ops you want to modernize you know let's say a marketing lead campaign initiative right well to start I gotta go find good marketing lead data and so if I have a catalog that has you know scan my enterprise I could type in you know the Google for the enterprise right you know I'll show me all my marketing lead data and you might get back twenty thirty maybe fifty different data assets at that point okay I'm overwhelmed as a business user so did I just picked the one at the top do I randomly pick how do I choose and what's really beneficial is that when you have that data catalog capability with a higher order value right whose machine learning to identify Business Objects you know low KPI hi you can start to make some really intelligent decisions and yeah because now I can determine this says marketing lead does I have all the elements that's required for a complete marketing the object so that's kinda like step one and step two is do I know where that data came from and do I know if it's being used downstream of by a different application so for example if I see a market and late object and I see that that object is being populated by you know Marketo and Salesforce sources right those were pretty reliable industry sources and I see it being consumed by ten downstream applications that says well this is actually being used by the business I can safely assume that this object is valuable and trusted whereas if I compare it with another object that has no downstream consumption I can make some you know informed decisions on which data to begin using so the point is is by combining data discovery with data integration you can make you know much better decisions about what dated integrate and then go straight into the provisioning process to bigquery I usually see people saying agreed that your business value relies on the quality of data that you have it doesn't matter how much money I'm bringing if you're not curating your data properly you're gonna have some troubles especially if you wanna more than do data analytics do machine learning you need to relying on your source and do you encounter a lot of people having problems with like data that's not normalized data that's not like duplicated records let's say you know do you have that many issues and how do you help those customers solve this kind of issues too or not absolutely I've been in the analytic space for better part of the past decade and I've seen so many analytics initiatives fail after such great intentions because of bad quality it has nothing to do with the analytics itself has to do it bad raw material right and the quality of data comes from a couple of different scenarios number one is like is it safe for me to access right if I can't safely access the data there's no point right at that point quality doesn't matter so you know having a solution that you know masks data or adheres to role based access controls you know number one I mean that allows a business user to safely use the data right and we all talk about enabling the citizen X rights as integrators as an application developer so as an analyst we want those business users to safely acquire them okay so once your platform has allowed them to safely acquire the data what is the quality right and quality is completeness of data right you know if I've got a data set that's got a bunch of null values that's gonna have limited utility for me right and being able to really profile your data set gives me an understanding of the quality of data but beyond that you know now we get into chemical higher order of data quality and so let's continue our marketing late example you know if I you know got a table what's really good marketing lead object definitions and part of that is email addresses phone numbers and zip codes yet 60% of my email addresses are malformed and my zip codes only have three digits yeah the structure might look fantastic but the actual data's gonna be useless for me right and you don't want to throw it away you know do you have the ability to recover from it and you know get quality data and if not you know can we safely exclude the data so it's absolutely essential because at the end of the day analytics comes down to do you trust the output and the higher the quality input the better trusty house you know with to go analytic given that we are the Google cloud platform podcast this so sounds really great but like in application like what tools and products were using here on Google cloud to help facilitate this sort of pipeline the our customers is a combination of both of our company's products right yep and so you know from informatica side they're using our intelligent cloud services they're using our kind of price data catalog big data management and sometimes secured source which is one of our governance tools and then on the Google cloud platform side you know Google bigquery I mean I'm telling you guys I am seeing so much traffic flow through to bigquery and the adoption is fantastic and I'm seeing you know like huge curves up into the right in adoption and usage but to really complement bigquery there's a lot of usage of Google Cloud Storage that makes a lot of sense I mean you know behind the covers we use a lot of them in tandem to lit drive performance of bulk loading we also see a lot of interoperation with Google Analytics and we're starting to see a much bigger uptake of technologies like pub/sub as part of these workflows and already talked about data proc earlier so what I think that I think about a great deal and my entire team thinks about is how can we best provide our customers with the strengths of bigquery and the entire go platform a surfaced through the informatica products right because I want to give them easy access to that's what informatics brings to the table right we're doing yeah easy access visual design environments governance lineage metadata management etc but I don't want to provide coverage that's just like vanilla access I want our customers to take the most advantage of why they picked Google cloud in the first place yes do you have customers that are like hey I've already got a Google cloud project and I've got a bunch of stuff in Google Cloud storage and they come to you and they're like we're already doing stuff how do we integrate or do you find it's coming from the other way where like you've got customers for informatica and they're like oh actually now we want to push this down into Google Cloud in some way shape or form I gotta tell you mark sometimes I feel like it's coming from top bottom left and right Oh different combinations but in all seriousness I mean we really focus on the hybrid Enterprise right and there's just crazy momentum to the clock right I mean heck I've been talking about it for ever since the club was born right but it is just happening with just fierce velocity but no matter that velocity large enterprises are still gonna have a presence on Prem and we have to treat that hybrid nature of unprimed multi Club as first-class service right we all do you know so a lot of times in our customers will you know I hate to speak in generalities but you know from anecdote you know engagements in evidence a lot of our customers will start with I need to modernize Mike legis warehouse and I want to get into bigquery great cost performance benefits great technology and they start off with really just more of a cost savings right they might get rid of their physical infrastructure shift the operational low to Google but the reality is that halfway through that journey that light that PIFAN II happens they start to see much more than value add of what can be done you know for example I was engaging a large customer the joint customer earlier in the year and their initial goal was just to modernize their warehouse with bigquery we started down that path and it was going really well and actually during a joint engagement where I was actually co-presenting with somebody from Google to this particular customer the light went on and they're gonna quit moving can I replace my Hadoop environment on Prem with bigquery and actually unify all my data you should see the grins it was like this collective room of lights going on about what was possible the art of the possible you know so back to your point mark me too you know coming from like you know from existing scenarios or new scenarios a lot of times it'll come with a new initiative but then all of a sudden they'll kind of blossom into multiple initiatives happening at once so I'm glad you brought up on Prem because I wanted to ask you about like that data migration story how are you seeing customers taking their data and bringing it from saying on Prem environment and bringing it into the cloud I mean that seems like a big job in and of itself you know it is a big job in that itself and you know there are you know technical nuances that need to be considered right yeah the one that I run into most often data types right but you know why I see a lot of customers start with is just like again they see dollar signs in the opportunity for immediate cost savings and that's absolutely correct I mean there can be a tremendous and fast ROI by moving from a legacy warehouse into bigquery and what that means is that you know customers oftentimes starting with just like a lifted shift I just want to take what's there move into bigquery and be done right and it's true the customer can realize some quick savings that way but so much is lost and if you're gonna go through this effort and let's be honest this is an effort no matter how much Austin tooling both of our companies bring to the table it's still an effort customers then don't take this you know inflection point to think about the future I think are missing a great deal of opportunity right I think the obvious example is you know classic warehouse models are you know heavily normalized right which made a lot of sense for you know the classic warehouse right based on old technologies store jewel-tone tube and whatnot but we all know that when you moved a bit query it's like no no no no but seriously normalize this really take advantage of the power but it's such a complete shift for you know DBAs and people have been doing this for 25 30 years right and you know for those that just simply do it lift and shift for that immediate cost savings I think they're really missing a great opportunity and so a lot of times we'll start off with a lift and shift to get immediate success but then it immediately moves into an evolution once you're in bigquery to start taking advantage of the data structures and technologies in there so it's not an either/or but it's a closely synchronous and if you will you know if we go lift and shift immediately into evolution and that's where I think we see a lot of benefits gained I remember when there started working with a bit of big data I'm not that versed let's say but the fact of being able to use bigquery like just put my data there and if you're out indexes if you go out how many server is gonna say crisping up a query that probably makes your product more versatile taking advantage of this kind of thing Knology and you said like this mind shift for all time old-school DBAs some has growing pains does that happen to you too it certainly does you know and I think you know especially customers that have been working with Tim from Attica for twenty twenty-five years there's a familiarity with the you know common patterns right yeah but sometimes those common patterns don't translate well into the clouds there's a learning curve and I think one of the thing is that informatica is able to bring to the table is that we help flat net learning curve we can help take advantage of the unique capabilities at the club faster because you know from our customers perspective they're still working with this familiar toolset and yes the technology behind that we're connecting to differs but we're able to kind of abstract it so we're able to get some really fast adoption but once you get that fast adoption remember you know a few moments ago was talking about we also want to make sure that the customers can truly take advantage of the characteristics of Google cloud platform and query it so for example maybe we talked about ETL earlier but let's talk about alt you know extract load transform we want to seriously take advantage of that kind of capability in a bit queries so using our you know intelligent cloud services to actually load data into bigquery and then process the transformation inside bigquery we're able to actually push down the entire job into bigquery so that we're using the bigquery engine to do all the transformations and that's got a couple of benefits number one you just talked about you know it's a Service Catalog environment with tremendous compute power that you're able to spin up on to Mia that means informatica is able to take advantage of that and so we're able to deliver you know a crazy amount of performance with ease and our common customers are benefiting greatly from that fantastic I'm kind of curious as well to obviously you've worked with a variety of people who do these sort of big data and analytics platforms if you could like tell anyone who works in like big dairy analytics like one thing that they should all be doing or like one mistake they should potentially not make that's broadly generalized like what would you what would you suggest is like maybe like the best practice you would love to get out into their Oh mark that's such a loaded question that's why I asked it I have like 10 not one okay yeah we can be able to come I got some time yeah I think gotta probably boil it down into three very distinct recommendations number one is you got to take stock of what you've got I think companies are completely surprised by the amount of data assets that they have an every nook and cranny of the enterprise and you know you really want take a good inventory of what you have determine what's important and prioritizing cataracts that that's not one but maybe most importantly you need to set goals and I know that sounds basic and it sounds obvious but more often than not I'm not seeing clear goal set so hey we have no idea when we ever finished because we don't know where we're headed and when we do get there was it successful was it not we don't know and by setting goals you set focus you said come like your guiding star that everyone aligns it marches towards which then leads them to the third one and that is you got to develop a team and again it seems obvious but maybe not in the way that you're thinking about it I would recommend companies to format my Gration you know SWAT team and this is the team that is well versed both in the technology and the business goals because they need to be the leaders right because they're gonna need good people to follow them on this journey into the cloud and for many people especially those that comfortable with the familiarity of doing it the old way they're gonna ask why and you want this team to be able to not only execute but to also inspire the confidence in moving to the cloud and so when you kind of combine that with you know clear goals and really go to understand what you have in place today I just think it's an enterprise up for success talking about innovations and easy to use technologies is good but also brings up great powers great responsibilities right so how does gdpr and those kind of regulations ensure they're working with informatica because one thing is to be GDP are ready and another thing to be GDP are compliant absolutely you know so how do you deal with that well you know again I mean it's you know I don't want like a broken record but yeah because we deliver a platform that integrates you know integration governance security but a data management discovery as part of the whole platform it's a little bit easier for us to deliver on the realization of being GDR PR compliant not just ready you know for example you know the right to be forgotten it's a difficult problem right I mean if you think like a global enterprise with many subsidiaries probably not PII sitting all over the globe right managed by many different business units but the right to be forgotten doesn't care about such silos it's like compelling to be forgotten and that's it you need to forget me and so you know we have a product called secured source that allows a compliance officer to kind of log in and actually says you know show me all the locations within my enterprise where PII exists and then from there again it's like okay I have a roadmap of where I need to go so that when somebody chooses to be forgotten I'm not guessing or hoping I'm able to know right and it's definitely one of the benefits of having that you know unified platform that's you know integrated as a complete solution because it enables that and you know things like GDP are and CCPA I mean they codified much of what we've talked about right we could talk about security and governance see'em since we began a conversation short while ago and you know this kind of like codifies the requirements but I think in some sense every Enterprise worries about this regardless of the regulation speaking of things like personally identifiable information and other potential high risk sort of information storage do you have best practices or things that people should be aware of when looking at that kind of data that could potentially be high risk absolutely so I mean we started off talking about modernizing your data infrastructure to bigquery so what's from the construct of you know that journey right and yeah we talked about you know setting goals and building a team to be successful well part of being successful also is quick wins right yeah you want to build a momentum based off of success so you know one of the things that I've seen successful companies do is when they start their migrations into the cloud let's not start off with the tables full of PII because that radically complicates the scenario because now you guys get your IT people in Baguio it's just security people in barber governs people about so sometimes it's best to know where your PII data is not right and so by using your data catalog by using informatica as enterprise data catalog you can see right and not guess it's like okay this tables got a bunch of PII a lot of value here but you know what let's do that maybe in phase two or phase three let's come and take a look at these other data objects that has a lot of business value below PII and that's gonna let me to migrate to bigquery rapidly get success build a new use case and now I can repeat and build on that success and gain momentum probably like almost like the opposite answer of what you were expecting but sometimes knowing where your PII is not is very beneficial awesome all right cool so we're coming up on time here unfortunately but before we go bill is there anything that we've missed or you wanna mention or make sure that you get out there so people can hear it you know mark so number one thanks to you Gavin have a great time my chat with you both yeah I would say that to our customers listening today you know check out the partnership between our companies it's fantastic and I truly enjoy working with the team at Google and together we're doing some great solutions for our customers and it's fun to be in market with you guys so thank you awesome well thanks for being a wonderful partner well bill thank you so much for joining us today on the podcast my pleasure thank you huge thanks to Bill for joining Gabby and I this week super interesting episode really I don't do a lot with big data analytics so it was super handy for me to learn more about that that area and some of the migration patterns that people have plus I feel like if you do some more in that area then you can add that to your title this year yeah then I can have a long title like Bill well more relevant to I think everyone listening than your title I think we have our question of the week yes yes we do go ahead ask it I'm ready so when you create an app engine app you get a domain that comes with it yep usually a pretty generic domain based on the project name and then you know App Engine but of course you can use your own custom domains yep and I think a lot of people you know they want to do that because custom domains are nice yep but when you're using a custom domain sometimes a lot of times you need to use subdomains yep how the heck do you use subdomains with a custom domain in App Engine oof that's a good question so there's actually a lot of really cool ways you can configure subdomains with App Engine in both static and dynamic ways which is super nice so for a static point of view you can set up dispatch yamo it's a configuration file wherein you can configure actually a variety of stuff not only just subdomains but also pods and some other things to particular services so services are individual deployments inside App Engine like if you had different API endpoints you might want to do different services and you can have versions within those services as well so you can set that up within your dispatch amol to say like oh I want you know dog food up bar I want that com to go to my default service but you know cat dog food up are I want to go to my cat service and that's pretty straightforward it's just just an animal file and it was pretty easy to set up that being said if you want to get dynamic with it which some people - and we use it for for some things it might be a bit easier you can set that up with wild cards as well so you can do that to the lower level down in your dispatch animal but if you just want to do it simply you don't even need a dispatch Gemmell you can set up your custom domain with basically a wild card so you might be like start free calm and you can set that up in your custom domain configuration and potentially also have a wild card for your SSL if you have an SSL which you probably should and what's nice there is what will happen there is if a person goes to a subdomain writes a wild card could be any subdomain App Engine will actually look for a version or a service that matches the same name as that subdomain if you go to dog food com it'll go look for a service named Doug and it will then serve that so that can be a really handy way of if you have some to come up on a regular basis maybe you have snapshots of documentation that you want to be have version something like that that come up every regular period you can set up something dynamic like that so the all you have to do is create a new either version or service that matches this subdomain that you have and then that will get served and if App Engine can't find that subdomain we'll just send it back to default which is fine too so you can do some really nice done it make stuff that way too so you have lots of options so if you have the wild card you obviously get all the subdomains you want and then from there you can either statically configure them saying which ones you want or you can do it dynamically and then pull up different versions which I think you made a great use case for when you said hey you know you might have different versions that are in the past and you want to still have references to those yeah so you kind of have two great ways to continue hosting content all from a single app engine project yeah and it's kind of like that whole thing wins convention for configuration you know one way with the wild cards or you can have static configuration using your dispatch ammo awesome well I think that should help a lot of people who are looking to kind of make more complex App Engine deployments awesome well before we wrap up Marc are you going anywhere doing any cool content are you working on anything you can talk about it there's a whole super-secret I'm always nervous about talking about content before it goes live because like what if the dates change or anything like that so it's super secret it's nothing secret but you know they involve customers and different people working with the clouds yeah I'm like oh hey we got you know next President Obama on here to talk about cloud and of course I didn't but that would be cool that would be really cool so anything you recently released that you can talk about yeah I mean I think we released two episodes earlier this month on snapchat which I think we mentioned once or twice before which is kind of our customer interview yep series and I'm working on and one of them talks a lot about anthos and I think that's really timely just because there's been a lot of buzz around anthos absolutely and a little bit of confusion about like you know hey what actually is it and how does it work and I think this helps talk a little bit about how this company arctic found the use case for it and then used anthos to solve it and I think we're seeing a lot of cool media on anthos there's actually a really fun video that Sandeep just put out which is a rewind of a presentation that next called meet anthos and these rewinds are fun because they only take about four or five minutes to watch and they kind of summarize that talk so I definitely recommend checking out the anthos episode the interview with arctic of stack chat as well as sandeep to meet anthos I guess it's not really related to me traveling though so long story short no I'm not traveling because we're making videos no no that's fine it's all good what about yourself I will be took your next presenting I'm pretty excited about I always loved going to Japan and then the day before the North American open source summit there's an open source of gaming day where are we presenting a couple of things I think actually I'm doing at keynote which will be fun so I'll be doing that and I'll also be hanging around the North American or if it's or summit so I'll be hanging out there so if you're around come say hi very very cool it sounds like dream in a lot of places hi I get around a bit I feel like for all the traveling you do I don't do which is good because then the mark equilibrium would be upset if we both travel the way people both didn't travel Yeah right some kind of paradox yeah you can't have us both at the same place at the same time well I think I think so so mark thank you so much for joining me on this week's podcast thank you mark thank you all for listening and we'll see you all next week bye [Music] you 