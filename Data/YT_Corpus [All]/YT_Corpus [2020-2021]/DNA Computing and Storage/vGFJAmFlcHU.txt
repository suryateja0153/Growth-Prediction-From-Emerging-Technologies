 Hey friends? Do you know what Hollywood, NASA, and cancer research all have in common? They all use accelerated storage with a high performance cache to render their work. Now that capability is available on Azure with the Azure FXT Edge Filer. Ron Hogue is here to tell us how it works today on Azure Friday. [MUSIC].  Hey folks, I'm Scott. It's another episode of Azure Friday. I'm here with Ron Hogue. This is a little different than I usually see on Azure Friday because I see racks. I see actual pieces of hardware.  It's certainly different to be doing hardware when we're talking about Azure. But we're talking about the Azure FXT Edge Filer. So we were part of the Aveer acquisition which just means that we had this hardware and we're required by Microsoft and specifically in the Azure environment. Let's talk about what makes, what that does? It is first of all hardware points like you just mentioned we're talking about hardware and it's a clustered file system. So now we're talking, we have multiple hardware items. They're working together as if it's one system. You can see here on the slide we have three nodes in that clustered file system. We use this as a read cache for storage. So you think about where's the bottleneck, whenever we're talking about any kind of computing and it's typically the storage. We have the CPU that's running, it's spinning so fast and it's just waiting on storage. We want to be able to accelerate that storage.  Is the bottleneck at some point the laws of physics itself?  Well, it could be but most of the time yes, we're waiting for something, we're waiting for a return to come back from a request. A lot of times when we thought about the older spinning disks, then that would take some time for us to seek and find that and bring that back now that we have SSD, of course that's a lot faster.  So is it a balance? I understand that like no one wants things on spinning rust because rust type it takes it takes time to spin up. Then you can put on an SSD which has a limit of speed. You can cache everything in memory, except memory is expensive. But isn't ultimately the goal to keep everything in memory and just have it ready at all times?  It is and what you'll find out is that the majority, what we tried to do is just max out the memory on these devices because that will be the fastest. So we want to have all of our storage available as quickly as possible. So good section of that in memory that should be the hardest, the fastest, the most frequently accessed data. Then after that, we'll put SSD for the next tier, the warm tier for whatever the render farm or whatever it is that it's trying to access the data is requesting.  If I'm making a big competitive cartoon that's going to be like the next big thing and I'm going to render a terabytes of data, am I thinking about it in the sense of I've got all my animators and then there's just this one giant central disc that we all mount and we have a really fast local network? Are we talking about gigabit, 10 gigabit, 100 gigabits because I wanted to feel like a local disk, right?  Sure. There are a couple of different workflows that you're asking about here. So one is about the animators themselves and the animators do work with a repository of data and some of those animators are remote. If we can put these FXT's at the remote sites, then they can access that information quickly as if they're on-site. That's part of your question. The other part is we do have a perhaps a repository of data where when we're trying to render the videos themselves, we want to go to the textures and things like that. So if you think about your animation you might have different, you know what does the sky look like and what does the clothing look like? What about the lights that are coming in? All of those different things have to be stored somewhere. When you're rendering a video, when you're rendering even just one frame, we need to pull all that together and get that back to our render farm as quickly as possible or compute nodes.  I see.  If any one of those assets in my catalog of assets is not available then somehow we have to wait?  We have to wait, yes.  If I want to open a remote office, maybe I'm in Portland and you are in Seattle you want, it's on the edge and the edge is is close to me as possible?  Correct. It's as close to whatever consuming the data as possible. So if you are an artist we want to have that data close to you. If you have a render firm that is in Portland then we want to also have an FXT Edge Filer cluster sitting at your render firm.  Now, I think of Azure Blob Storage as an infinite disk. I mean ultimately I just keep throwing stuff at it and it's attached to my credit card and as much data as I mean it's ultimately infinite. How big are these things?  Well, let's talk about that. Let's go on, perhaps we'll go over to this slide.  Then we can go back.  Then we can go back. So the two models that we're talking about here. So we're announcing these new models, the FXT 6000 series. Of course, there were series before that. The FXT 6000 series has two models. The 6600 and the 6400. That's really what I'm here to talk to you about.  The exciting parts to me one of the things that I'm most excited about is that number of that amount of RAM. So you've talked about wanting to put as much memory as possible. Here our top flagship product has 1.5 terabytes of RAM in the box which blows my mind. I don't know if it blows your mind too. Macros computer was around 64 or 64K of memory. So the fact that we're talking about terabytes now is just awesome. So that's our like I said our flagship product. The 6400 has half that, but it's still over 700 gigs of RAM that we're putting in these boxes.  It's funny when you're looking at specs like this. I see its like for example on the 6400, it's got 768 gigabytes RAM. I'm so used to seeing 768 next to MB. Just with the change of one letter, we're talking about a huge amount of memory and then double that on the 6600.  Orders of magnitude larger. Then on top of that, we were talking about how SSD is fast and we want to be able to use that as much as possible. We're not only just using SSD but we're using NVMESSD. So instead of SATA which is slower, we're using a faster process to get the SSD data back to us as quickly as possible. So NVMESSD.  I assume that there is a software special source as well because ultimately I'm an animator. I don't want to think about this. This isn't just a giant fast machine, it's got brains.  It does. Yes, the special source really is what was built in that was what was acquired by Microsoft. That special source helps us to identify what the most important data is and put that at the top, make sure that that's available to you as quickly as possible and you being again an artist or a render farm. Then where we were also talking about speeds of course we have 625 gig or even 10 gig ether-net ports on top of that and a couple of one gig if we wanted to use something for management for example.  I can see that network port thing is really interesting because I've recently retrofitting my house to one gigabit which makes me feel like I have local disks. But if you're trying to move a terabyte from place to place, it's still a lunch break.  It does take some time.  Sure.  Even over the one gig.  So when you've got linked things like this and smarts and Jumbo frames and all the different things you can do to potentially make it feel like it's a local disk, the animator hopefully does feel like their assets are like right there on their screen.  That's right. We're talking about animation, but that's not the only use case. So if I can go back we'll talk about some other use cases like so we said the special effects would be one the animation and special effects kind of go together to create those frames, those video frames. But also we're in life sciences genomic analysis when we think about our DNA and not just necessarily our DNA as human DNA but even plant DNA or bacteria DNA. We can use that DNA and do all types of analysis to find out. Hopefully we're working toward a cure for cancer. So cancer research as you mentioned in the intro is somebody or organizations who are using the Aveer to the Azure FXT in order to accelerate that and find those solutions and test those things as quickly as possible.  They're all doing that locally. So it is this hybrid solution which is really interesting. They're not necessarily going up to Azure and back and forth all the time. The device is smart enough to cache. It's an edge front end on the Blob Storage, is that correct?  Well, yeah. So let's talk about that. So you mentioned Blob, normally the data is all local and we're thinking about having our data local and perhaps an isolation or DOE at EMC AI Salon or Ornette app. But we could put data into Blob. So what we want to do is we won't accelerate anything that's already in Blob but we will use Blob as a destination for let's say Active archive. So let's say we talk about genomics or we're talking about the animation. We're going to take things that we might not need immediately but we could use like reference information, put that into Blob. So you might have lots of videos that you've done. We think about animated videos that have come out and now they're on version two or three or even four of that video. Maybe they put the first three in the Cloud and they could store those in Blob and then pull down just the assets they need because oh we're bringing this character back. So let's have that available to us as animators.  I think you had mentioned to me this concept beforehand about warm storage versus cold storage. Is that the idea that if it's colder storage than I accepted that it's a little bit farther away.  That's right.  Yes. So the coldest storage would be either it could be in Blob if that's where you decided to put it or somewhere On-Prem. So thinking again about your On-Prem network attached storage. The hot, the medium to warm or hot data would all be on your Azure FXT so that you can get that information to your cluster, your servers as quickly as possible.  So fun stuff like animations, important stuff like science, weather simulations, anywhere where you've got hundreds of terabytes or tens of terabytes of data.  Yes.  So we're thinking, that's exactly right. We could be in front of petabytes of data if we need to but you're correct. We could be but we're only accelerating tens of terabytes like you've said. So we're going to cache only the act of working set and that will be inside the cluster itself.  That's smart because ultimately you aren't going to be dealing with the entire petabyte or entire multiple petabytes at the time and you're making all of that as transparent as possible?  Yes and it doesn't matter where it is if it's on the Aveer itself, that's fine. If it's On-prem, that's fine. If it's in the Cloud, that's fine. It shouldn't look any different to the end-user.  I love it.  Okay, good. Then simulations is another top use case. So we think about simulating financial data, financial services, you probably had a 401K and somebody might be managing that. So they're going to run a lot of simulations. They could take that stock market data, run different simulations against that. We also do simulations for autonomous vehicles and we think about well how does that go down the road and what happens if somebody's walking across or running across? So somebody is running a red light, those simulations, the more simulations you can run through, the faster you can iterate and improve those programs. Then also simulations for genomic types. I'm sorry, geological types of things like oil and gas when they're trying to drill and find out where that oil is? How can they get all of that petroleum out I guess?  It's funny. When you think about the historical context of someone writes a four loop in the eighties and they can conceive of the combinatorics of they like well, this is a four-loop that kind of describes how I think the tectonic plates auto work. I have this question but I need to run n times m number of thanks simulations and you're in the 1980s and you're thinking well the Cloud doesn't exist, haven't invented it yet, how am I going to do this? It's going to take until the universe is sudden death or whatever, the sudden death of the solar system and then fast-forward 20 or 30 years and we have this amazing amount of technology not only the power of the Cloud. But the power of the Edge with something like an Edge Filer to provide just effectively infinite storage that we couldn't even conceive of. Just a couple of decades before and I can solve those hard problems that with a combinatorics exploded into petabytes of data.  When you're talking about that kind of computation, we're thinking about having, we talked about HPC, those are thousands or tens of thousands of compute cores that you're going to run against some sort of workload. That's what the Azure FXT is really designed for, those high-performance computing workloads. This isn't something where you just want to accelerate something local, home Durer's or anything like that. That's a horrible fit. We're thinking about high performance computing, just thousands of compute cores, working against this. We had one customer who was using the 6600 and was able to sustain 300000 operations every second for over 24 hours.  Wow.  So this thing is just cranking out as much that as it can in order to support compute.  Yeah, that juxtaposition you made. This is not for your PowerPoint files.  Never.  This is not additionally now that I pick up at Best Buy. This is for serious work.  That's right. So let's talk about a few of these other features. We already talked about the NVMe SSD and we talked about that incredible amount of RAM and the network ports. We do support NFSv3. So a lot of people that are using high-performance computing are using NFS for that. We also support SMB2. We have a single mount point and this is one of the features of the product where if we do have an isolation and a Net app and we have something in Blob up in the Cloud. So here's up in the Cloud back here. We can make it look as if there's just one storage area that they have to go to and that's the Aveer itself. The Aveer will make all of those disparate systems look as if it's in one storage. So that's the user experience.  So just to be clear so a Aveer was a company in a product and then that became acquired and then now that is now the Azure FXT Filer.  Initially, the Aveer FXT and now it's the Azure FXT.  I think that single mount point is worth pointing out as well because there's a piece of impedance mismatch when an animator or a scientist or someone has to think oh where's that data? Ultimately, it's just it's slash mount and go and have fun and the petabytes of data at a single mount point is where you want it to be.  That's right. Like I said it could have been something where people had several mount points in the past or they were mapping different shared drives and it can all appear as if it's in one area there behind the Azure FXT.  It's in a clean one you. I mean this is a standard.  It's a one new service that we have, it's amazing that we could fit all this computing power, all that memory and everything within one user. We have the smallest footprint that we could possibly do. Three nodes is the minimum. So that would be it. Just a few inches in your server room. We can go up to 24 nodes in a stack.  Wow.  So you can imagine all that terabytes of RAM or SSD. I guess and SSD that you'd have available to you for caching. You also mentioned a little bit about Blob. So I do want to mention here again that we can put things in the Cloud. We can move things to Blob if we need to use that for active archive. With that, we have this sort of bonus and that is that until June of 2020, or while funds last, customers can get $4000 in Azure credits because we know we love Azure and we want everybody to be in the Cloud. They can use that toward whatever they want. Any kind of proof-of-concept. So in a three node cluster we're thinking about having $12000 available to the customer to do whatever they want.  I have a lot in Azure Storage and that's a lot of storage.  Well, yeah and it's not just storage. It's Azure credits for anything.  Oh really?  Yes, it's not.  So compute or?  Yes, anything they want to use in Azure. $12000.  That is a heck of a deal.  Yeah. So we say hey, grab this incredible hardware, use it, and while you're using it throw some stuff into Blob and while you're using Azure already to store some things, why don't we to test out some workloads and try to do some virtualization in the Cloud, try to do some animation in the Cloud.  All right. How can people go and learn about this?  They can go to azure.Microsoft.com./services/fxt-edge-filer/.  Or if you go out and search for FXT Edge Filer, you will be successful?  Yes. If you could just go to Azure.com and search FXT, you'll be able to find it there as well. That would be the easiest way.  I look forward to my free sample.  Okay, very good.  Fantastic. I have learned all about the Azure FXT Edge Filer today on Azure Friday. 