 hi today we are going to talk about how you can evolve to a zero trust security model with anthous i am samrat ray i am the product management lead for antho security at google cloud and with me is sandra my name is sandra gua i'm a security product manager for google cloud and today we'll talk about how you can implement zero trust security with anthony's but before we talk about how you can do it let's first talk about what is zero trust when we talk to a folks out of outside of google we hear many different definitions of what is zero trust we hear terms like it's micro or even nano segmentation right done at the workload level we've heard terms like perimeter less um we've heard somebody say it's something as an error was hey i've implemented mtls therefore i'm doing zero trust we have heard definitions from vendors and others saying things like trust endpoints and not the network continuous threat monitoring all of this is zero trust so in order to make sense of this term we decided that we will give it a clear definition rooted in certain sets of principles as we understand it at google and then explain how we're implementing parts of those principles using enthus so how do we think about the term zero trust the first way of thinking about it is to think about the term trust right and instead of focusing on the word zero because we all understand there's a bit of a marketing spin there we think about the reducing privilege or trust on all production entities right with respect to data critical workloads and infrastructure right so what we're saying is we don't trust any one thing it's not just about network security it is bigger than that broader than that we think about it as a series of controls for defense in depth and those controls include infrastructure security code or deployment security production network access and employee or insider access we have described our approach that covers all of these dimensions uh through a paper called beyond fraud and this has this is available for you to read we highly recommend that you take a look at that now let's talk about how we can take these principles and implement them with anthos before we dive into the how let's talk about another aspect why why is this approach certainly relevant to you the reason for this being important and gaining more and more relevance with our customers is the confluence of three technology trends the first is a hybrid and multi-cloud we are seeing increasingly that the production environment is changing from a single homogeneous production environment right without perhaps a single network to a distributed production environment spanning multiple clouds and on-premises with different network architectures and not having a consistent way of viewing network security right this means that your traditional parameter based security approaches no longer apply as if as well as they did before second is the adoption of containers and of kubernetes the adoption of containers in particular implies that your traditional security that was based upon securing the host and trusting the host that ie at the infrastructure level is no longer sufficient because the strong correlation between a workload and its host is no longer true with kubernetes therefore in addition to securing your infrastructure you now need to rethink about how you're securing your workloads that are deployed to this infrastructure where many of those workloads may be deployed on the same node and a single workload may be deployed on multiple nodes throughout the screen the last dimension is that option of service based architectures so we are seeing the breaking of monoliths into microservices this is great from a developer velocity perspective the challenge being you have now suddenly increased the surface area of access in within your production network by several magnitudes thus you now need to ensure that you are properly securing access to sensitive infrastructure and to sensitive data within your production network and not just relying on coarse grained controls that you had before so all of these trends together mean that we need to revisit how we are doing security and zero trust is a great way of thinking about how security can be appropriately appropriately applied in this modern environment so how can anthes help before we talk about what anthos does for you i just want to set the context that in this presentation we are only going to talk about zero trust approaches to production workload security we are not going to talk about infrastructure security or perimeter security you can apply zero trust approaches to those dimensions as well we're just not covering them today we're going to focus on workload security so with anthos we enable you to think about zero trust along three macro principles the first being only trusted code and configuration can be deployed to production the second is that trust is not associated with just the network location of the workload but is actually associated with who the workload is and the user on behalf of which the workload is accessing any other system on the production the third is to make sure that all service access is granted to the right peer and to the under the right rippers context so now we'll talk about how you can actually implement these principles in your production environment with anthros technologies and with that i'll hand it over to sandra to walk you through the anthos workload lifecycle thank you samurai if we take a look at at a workload lifecycle it can roughly be categorized into two phases the deploy phase and the runtime phase with production identity uh acting as a linchpin that ties together um the two phases so provenances um can be tied with so with the right production identity can tie together the provenance to the production privileges that a workload can assume and ultimately the production resources that the workload can access so the goal for the deploy phase is to ensure that only trusted workload can assume the rate production identity then during the runtime phase making sure that secure accesses are carried out only by trusted production identities if we take a closer look at the deploy phase uh we realize that um production identities are typically associated with a scoped runtime environment such as the namespace or cluster then the deploy production security goal can roughly be translated to ensure only trusted workload can be deployed to the designated trusted environments so what exactly is a trusted workload so there are a common set of risks associated with uh deploying a workload the workload deployed may be built from untrusted code in an untrusting environment and the typical mitigation for that is to make sure it's viewed centrally and also make sure that it's signed by the centralized process that use it so that it can be verified later on the workload may include a vulnerable package to help with that all images should be scanned for no vulnerabilities before they are deployed but that again that is not sufficient because you have to act on the vulnerability findings um by again signing it that verifies that the um vulnerability scan bar has been reached before a workload is deployed and then a workload what about what about workloads that are not sufficiently tested or reviewed again it is not sufficient that the necessary tests are performed there should also be evidences um such as the signature that a workload passes all necessary tests once a workload is a pre uh is approved for deployment it may still be deployed with a wrong configuration um such as wrong as root that is why it's important to have configuration guardrails to catch those mistakes last but not least the workload that is approved for a while environment may not be suitable for the other um so it's important to have deploy policies that are environmentally appropriate uh to only admit workloads that are approved for the target environment in summary if we put in place all these controls we should have trusted workload that are built from the right code through the right process and deploy it with the right configuration to the right environment enzos offers tools and products to implement zero trust deployments and all the controls that we described in the previous slide customer can choose to use cloud build or other ci tools to implement a centralized lock down csd process and they can build workloads using secure managed base images um that are continuously scanned and patched for normal abilities once the image is built um and it gets checked into the container google content registry it gets picked up by the vulnerability scanner um google also hosts a container analysis api that serves as a metadata as a container knowledge base that stores uh metadatas bindings uh build records um test results so that all the information associated with a container can be found in one place for verification later on once the image is ready to be deployed a key part of the security control is a deploy policy final authorization ensures that only explicitly authorized image can be deployed to the target runtime environment for example customer can set a policy for their pci clusters to only allow images from a centralized build pipeline that also meets their vulnerability scanning bars let's take a closer look at binary authorization binary authorization defines an attestation framework using signature verification um so csv components can sign or attest an image as it passes through each of the required stages in the release process the user can then require certain attestations to be present at deploy time to make sure that the required stages in the release process were actually carried out this mechanism allows the customer to control on what can be deployed in addition to who can deploy one may have different policies for each of the production environments for example customers may require images deployed to the pci environment to be signed off by the compliance stakeholders in addition to meeting the regular test and quality bars for regular production environments in addition to signature verification final authorization also supports an allow list for certain third-party images that are deployed in the user's environment the security team for example can make it explicit which third-party images and versions is allowed across your organization that makes it very easy to manage and upgrade and then there are also break glass processes in case there is a production emergency and the workload needs to be pushed without satisfying the necessary release requirement in which case the deployment will be logged in autolog and can be reviewed later on in the end with the binary authorization every workload that gets released into the production environment can be accounted for um it should be either built by the customer and signed by their centralized viewer and processors or is explicitly whitelisted from for render images or if it's a google provided system image that is white listed by default using the system policy in addition to binary authorization here are um additional product features of ansels for secure deployment the google container registry offers a vulnerability scanning feature that provides detailed insights for known vulnerabilities for checking images once the initial scan is done it continues to perform incremental scannings every time the vulnerability is updated user gets vulnerability updates even for images that are already running enzo's config management makes it easy to set up configuration guardrails so it offers both customizable and building policies such as requiring strict mtls for all services in a particular namespace and then base managed base image are a set of container based images host on a cloud marketplace that are maintained and regularly patched by google they're used for google's own products and are good place to start when building application containers now um that we have looked over the product features let's do a quick recap so we take a look at the um working life cycle again a code from approved sources are used in a locked-down centralized view process to produce a workload container and the workload container then gets tested and scanned for known vulnerabilities then as part of the the release process for that um workload during the deployment stage it gets verified by final authorization against a deploy policies to ensure that it meets the customer requirements and has come from a trusted process at this point the trusted workload has assumed the right production identity by running on the designated production environment i'm now going to hand over to samurai to describe how to secure this workload while it's running thank you sandra we now have a trusted workload that we can trust in addition to just trusting the network right this allows us now to have a different basis of trust which is rooted in the workload and its identity rather than on just the network we will now talk about how we can leverage this workload identity to uh securely grant access to sensitive data and to sensitive infrastructure in our production environment so how do we trust a production client the way to trust a production client is to mitigate a number of risks associated with access within a production environment these risks include access to payload by entities listening on the production network it includes things like untrusted workload replaying application credentials uh which uh to gain access to data right so some stolen application credentials can be used to then gain access to data which the workload is not supposed to gain have access to um and so uh another risk that is there is a client impersonating a more privileged workload right and uh similarly um a compromised client can not only impersonate the privileged workload but a compromised client can also exfiltrate all user data um that it has access to on its own privilege lastly and an insider can also gain access to sensitive data and um sensitive back-ends without going through appropriate checks by bypassing certain front-ends right so all of this risks exist in terms of access within a production network so the corresponding set of controls that we can use to mitigate these risks are we can ensure that all workload to workload communication is encrypted in transit to prevent entities that are listening on the network from gaining access to sensitive data and credentials etc we can ensure that all clients are explicitly authorized such that untrusted clients don't gain access even if they have the right application level credentials we want to ensure that when we authorize a client we are authorizing it based upon a non-replayable attribute of the client versus identifying the client through something like a token that itself can be replayed right thus we want to prevent impersonations by using something like an ip address or a credential that is based upon a cryptographically signed certificate for example that cannot be replayed the next is we want to ensure that for in the case there is a client that can access pii on behalf of an end user it can only do so when it is acting on behalf of that end user and not when you know if it's compromised that it can gain access to pii without a valid end user that actually has authority on that data and lastly we want to ensure that all insider access are locked down to authorized clients that can implement the right set of checks and obfuscation etc before granting access to data to earn a privileged insider thus we will now talk about how we can implement these set of control mechanisms with anthony's a key tool for implementing these principles that we just talked about is antho service mesh we'll walk you through how anther service mesh can help you secure workload access followed by access to data and to mitigate uh in privileged insider risks as well so the first step is to ensure that we can secure workload access without taking a dependency on the security of the underlying network this does not mean that you are not securing the underlying network you we still recommend that you have the right kind of perimeter security and uh have a minimum set of segmentation to for not south access ensuring that your backends are not exposed to the internet for example right having said that once you do that it we as we described before that is not a sufficient um for modern production environments so thus we now will talk about how you will actually grant access within your production network context so the first step is to ensure that you can um we only grant access to authorized network peers right to authorize clients and we recommend doing that using a certificate based identity the advantage of a certificate based identity is that it is not replayable because the receiver of a certificate cannot replay it without also being in possession of the private keys thus it prevents impersonation attacks right and the use of mutual tls for authentication also implies that you get encryption in transit another key property that we described earlier the value of answer service mesh in this context is to automatically manage your certificates and keys for tens of thousands of workloads in your production the next step is to ensure that you use an authorization policy that can reason about these identities and in addition to that can also reason about additional attributes like namespace and ips as needed in order to grant access to a network player answer service mesh provides such a policy that is integrated into the mesh all of this implies that your security can be policy driven and is not baked into the code thus your application developers can focus on business logic rather than on security the next step after having secured workload to workload access is to secure access to user data by a workload so in addition to ensuring that you have the right client in order to gain access to user data we want to ensure that the client is accessing on behalf of the right end user and we can do this by ensuring that the client presents a valid end user credential that is has the right kind of claims to access the data on the back end again answer service mesh provides you with a policy engine that can a validate that there is a valid end user credential that is being presented with the right signer and that is actually has not expired for example and it can also reason about the claims in that jwt credential to ensure that the credential has the right kind of claims so that the data can be accessed based upon what the end user has access to and not on the privilege of the credit card front end itself the last piece that antho service mesh helps you secure is insider access with respect to insider access and the service mesh ensures that your insider can only gain access to the right front end because enter service mesh will grant access to data let's say based upon a valid end user credential and your credit card back end will grant access to data if it's a valid privileged insider but at the mesh layer you can ensure that this valid insider is actually accessing the data via the right front end such as the case tool over here which could implement uh obfuscation or pii as needed it will deny access if the same privileged insider where to deploy their own personal script and then try to gain access to data without going through the case too a key principle for granting access to sensitive information or infrastructure to an insider is to ensure that we strongly authenticate the insider and this is done in google cloud platform through a product called identity about proxy identity aware proxy uses beyond core principles to ensure that the user identity is authenticated based on multiple factors such as the client device attributes and ip address for example you can ensure that you can you only grant access to sensitive data when the insider accesses the case tool from a well-managed corporate device that is secured this ensures that you're only granting access under uh to the right person via the right front end coming from the right um endpoint device for example so to summarize antos provides um features for securing access in productions based upon zero trust principles the first being amster service mesh which provides mutual tls for encryption in transit and for stronger authentication and authorization and the service mesh allows you to secure access across clusters and across vpc networks it also allows you to secure access based upon end user context and not just on the peer context identity aware proxy enables you to grant access to to your insiders based upon strong authentication of the end user itself and based upon things like the device context and ip address for example it's integrated with answer service mesh and it can also support third party identities so you can bring your own identity provider and use that with identity proxy lastly one of the things that we did not talk about before is kubernetes network policy it is still important in this context of zero trust access um because it provides you with a segmentation technology that works within a single cluster so thus you can use something like kubernetes network policy to implement a policy that says the front end which is internet facing cannot directly access the back end by bypassing the middle tier right so this kind of a knocks out segmentation can be implemented with the kubernetes network policy and it adds defense and depth on top of what you have at the base infrastructure security level and the security that you implement using anthra service mesh to summarize zero trust production uh security uh can be achieved with three principles which is only trusted code and configuration can be deployed to production trust is associated with workload and user and not just with the network location and all access to sensitive data and infrastructure is granted to the right network peers and under the right user context thank you 