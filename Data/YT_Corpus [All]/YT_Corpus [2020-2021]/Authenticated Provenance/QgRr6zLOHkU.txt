 [Music] hello everyone welcome to this talk about best practices that we have learnt in google production security and how we can apply them with sto so the focus for today's sorry one of the focus for today we will will talk about how the production landscape is changing right what is its impact on network security and why Google's approach is actually increasingly relevant and now more approachable than ever for the enterprise and sto is a means to an end of achieving a security purpose right the key thing is to implement a set of key security principles that we have learned over the years to protect microservices infrastructures within Google's production and that's what we will talk about and I am Samrat ray I'm a product manager on Google cloud security and privacy organization and my focus is on service security and insider threat with me is Julian birth he is the network security lead for Google's production and I think this session is special in the sense that you get to hear from the people who actually build the stuff which is Julian right versus the people who generally talk about it so so with that with further without further delays I'll hand it over to Julian to start explaining how he sees the threat model evolve or with the changing production needs and and then talk about how Google production the principles of Google production security that have informed our posture for over the last decade or so all right thank you very much Samrat and hi everyone so production infrastructure is changing right and that has a big impact on security so we are serving a number of trends from our customers and our partners and they are like three major trends that I want to talk about the first trend is the use of orchestration frameworks and containers and the the most popular of these orchestration frameworks is kubernetes today the second trend is the use of hybrid and multi-cloud meaning that one workload may be in one environment on premise and can move to another environment on a cloud provider and the third trend is the adoption of micro services so let's let's start with containers and an hybrid and I will I will have a big claim here is that IP base network security is suboptimal so your IP tables can only go so far and why is that that's because when you think about it on accusation framework is going to schedule containers on a pool of hosts right and the orchestration framework can kill the workload on a hosts reschedule that another the hosts and as a consequence the IP and the hosts IP in particular doesn't have a lot of relevance anymore right these containers also these workloads they are ephemeral then can be start and stop very quickly now for hybrid as I said you will have a workload that starts on an environment on premise and then that moves to another environment which is cloud and when that occurs you don't want to have to reprogram all you network policies because the subnet is not the same right and so what that means is that we need policies and access logs like policies on access logs they need to have a stable identifier for the workload the other trend is micro services and when you think about you all monolith all monolith monolithic application where everything was integrating in one big binary that-that-that-that Molly's got exploded into a constellation of microservices and as a consequence calls function call that used to be local are now completely distributed over the network and what that means in terms of network security is that your network is much more privileged now if you don't do anything about it meaning that somebody who has a privileged stance on the network is able to do be able to do much more damage than before so so we need a solution for that the other point that I want to make around micro-services is that they expose a lot of different methods and let's take an example of a key distribution service for example this key distribution service is going to expose some methods that have very different security properties one method call can be completely innocuous such as a health check you want to check whether the service is dead or alive and you will have another call that is going to be rotating the master key and this one needs to be really heavy protected and again what this means is that the policies need to be able to reason about these different methods and the different levels of privilege so that means the policies have to go way beyond layer 3 on layer 4 they have to operate at layer 7 so the good news here to some extent is that adoption of containerized workloads and micro services that's what Google has been doing for the last 10 years we've been doing that over a decade and we have in production millions of of microservices endpoints and so we're informing our network security posture by a set of principles and I'm going to talk about these principles now so I'm going to start this part of the talk by a quote from News Provost Neal's used to be our security horizontal lead and he gave a talk on production security in this very forum a couple of years ago and at the time he said at Google we are not pursuing a hard shell parameter model instead we really focused on prefaces defense-in-depth there's another term that you may have heard about pervasive defense-in-depth and it's zero trust security so personally I'm not a big fan of zero trust security because at the end of the day you have to trust something or a set of things right you if you go with an identity based system you will have to trust your identity provider your identity if you're on system you will have to trust your network for availability in any case so I prefer the term difference in depth which i think is more correct and you can see difference in depth along a set of dimensions and a first dimension maybe how to build your stack on a production machine from a hardware tool of trusts to a bootloader to an operating system to containers and applications and how do do you make sure that at each layer what you're running is what you think is running that's not malicious code and that's one type what one dimension of difference in depth the other type of difference in depth that that we can think about is along the network path and how you can have two layers of security one that is at the edge of the perimeter well at the edge of the protection network and the other that is inside within the production network and since we don't have that much time today we're going to focus on the second one the network path so the first principle that we have is that so we need two layers so the first layer is that you have to protect your protection network at the edge right and proxies are the thing that provides this isolation you can see on this diagram here you have our customers the blue and the yellow person has going through the Google front end in order to invoke a service at Google this Google front end is going to do a bunch of security checks and you can see that if an attacker tries to attack us here with for example a denial of service attack we can detect this attack and we can react appropriately through aggressive like rate limiting for example now for workloads that are within the network we ensure that these workloads cannot arbitrarily egress out to the internet because that would be an obvious vector for exfiltration of data so we have perimeter security here as well and even with within our corporate network we make sure that in order to access the production network we go through an administrative proxy and you may have heard of beyond Corp which is something that we're very keen on but there are sometimes some misconception about what beyond Corp is about so beyond Corp is about the fact that being on the corporate network per se doesn't just give you access to the production network there are a bunch of other signals that you need to take into account in order for you to have access to some privileged resources within the production network and these the things are for example what is the device from which you're operating this request to the production network is it to trusty device is it an ultra C device who is the person who is authenticated on this device is it a Google employee is it something else right and the admin proxy is the one that will based on all the signal and the type of resource that you want to access in the production network to make the decision as to whether you can or cannot access the resource in question the thing that I want to tell you here is that you you don't stop there right you don't stop at the parameter within the production network you have to protect your clothes for all the reasons that we talked about before with respect to micro services for example so how do we do that the first thing that we do is that we use federal shows backed identities for all the entities on the network and the entities are the administrators the machines and the workloads and let me talk to you about a LTS because alt s is a application layer Transport Security is also known as Louis and that is the system that we use to do this type of thing so LT s does two main things the first thing that it does is that it provisions rotates and revokes all the credentials for all these different entities but the first thing that it does but alts is also at for security protocol meaning that it's very extremely similar to mutual TLS and its certificate based and private key based so now let's see how Alice who is a site reliability engineer can schedule a workload which is dual or front-end on a production machine so the first thing that Alice does is that Alice makes a request to the wall master which is our scheduler our men scheduler for workloads and he gives the description of the doodle fronting workload and she also says I want this workload to run as the doodle from 10 identity and she does that over on alts which we authenticated channel once the ball master receives these requests the ball master is going to do two types of checks the first check is going to be those alleys have the rights to start a workload as the doodle frontal identity the first thing right it does can she act as this identity and the second check that is going to be done is that oh but this workloads comes with a configuration about the binaries that are going to be running and do we have some information about the provenance of this binary and that's called binary authorization 1 these two checks are cleared the ball master will then choose a production machine a worker machine on yellow here and we'll threw on alts channel again that is materials authenticated and encrypted send the configuration to the pro machine of dual front end along with the credentials for the role for the end and now dual front end can authenticate to any of the other entities that we described before for example dude on front end is going to authenticate to another another workload which is going to be doodled back-end through again on alts mutually authenticated channel and from the doodled back-end standpoint dual front end is going to appear as the client authenticated entity another principle that we have is to use channel bound credentials for authenticated services within the production network so what is a channel you can see the channel as a TLS session between a client and a server and by channel bound what I mean is that the proof of authentication is only relevant within the context of this channel so authentication credentials can be of two forms one can be certificate and private keys and the other can be bearer tokens and you can see on the web that bearer tokens are pretty popular but we've been strongly that they're the wrong choice for authenticating within you infrastructure why is that is that basically bearer token by their very nature can be replayed and that is a big issue here because you have doodled fronting on one one end we need to talk to do roll back end on the other end but that's unique that's not the only channel of communication that exists dual front end is going to talk to a bunch of different other services such as the load reporting service or the lock service or the name resolution service and when that happens you don't want the lord reporting service or any of these services to be able to replay the bearer token of doodled front end to doodle backend in other terms to impersonate doodle front end to the - sorry dude in fact solidoodle front end to the back end and what that means is that we really want general bank credentials and so again for in your production we use alt s which is certificate and private key based and that doesn't suffer from this big drawback of where tokens another principle is that you have to be able to grant access based on multiple identities and that's not something that you can do with like again policies just add the layer 3 on layer for each service each workload exposes methods and sometimes user data and all this access might be explicitly authorized by policies now let's talk about the different identities that we have here on the network on the on the request path you first have the workload identities or service identity or channel identities or P identities all these things are the same the same thing and these are ingress front and back and health service these are the identity that I talked about previously but at the beginning of the request you also have another identity which is the original requester identity and that can be for example Bob checking his gmail on his phone and he's very important for this original requester identity to be forwarded along the chain from ingress to the database because at the end of the chain it's Bob's data that we want to retrieve from the database and let's see how this can work hand in hand with the peer identities along the chain each workload can decide which peer identities are allowed to present such original requester identities and here for example from the database point of view the database can say it's perfectly legitimate for the backend to present me with our original requester identity but a half service which is just there to make sure that I'm alive this one is certainly not privileged to present me with an end-user identity the fifth principle which is going to be the last year and that's probably the most important one is that your platform must implement security by default and if you see this diagram here you have what is provided by the platform which is at the bottom and the application logic which is at the top the platform supplies service a and service B with credentials with an identity automatically without the application having to think about it without the application they'd rather have it to think about that you know there's some magic key distribution going on here it just happens when a wants to call the get info method on B again just by virtue of using the RPC framework automatically a channel is created a mutually authenticated channel that will now say that the caller is a service and the collie is B service and the service owners are going to to be able to configure some authorization checks here for example service we can say identity a service can access B dot get info and this is the since this is the case here the call is going to be able to go through but again all this happens at the platform level without the involvement of of the application logic and that's really important now there maybe some types of authorization that really need some context from the request itself and such applications are typically heavily melt multi-tenant so if you want an example you can think of a a file or directory service right depending on the path that is in the request you will want to apply one type of authorization versus another type of authorization depending on the path and but even for these types of applications even authorization checks fine-grained access we want to provide framework for that and internally Google I am is a good way a good framework for achieving this so let's recap here the five principles that we talked about so the first one is protect your network at the edge second one is to use credentials backed identities for all the entities on the network the third one is to use channel bound credentials for authenticating services for to grant access based on multiple identities if this is applicable you don't always have multiple identities but if you do you grant access based on that and the fifth one and the most important one again is that the prima the platform implements security by default and I cannot stress that enough if there's one thing that I want you to take away from this talk is that is the role of the platform for security like don't let each team of you in your organization reinvent the wheel reinvent its own framework settle on one thing and make it better over time so if Co security has been informed by all these principles and now some rot will tell you how these principles are being implemented in this view Thank You Julian so Julian outplayed some very important principles about how we at Google protect our production environment against some fairly sophisticated attacks right and increasingly if we find as enterprises get more digitized and move to cloud platforms enterprises are exposed to similar sort of threats that Google has been exposed to over the years and we feel that it's increasingly relevant that enterprises adopt such principles to protect their own production environment however one of the big challenges here is I'm sure all of you realized what yulian presented was technically complex right it's non-trivial to do this in any shape or form in an enterprise environment right and one of the things you immediately that strikes you and when it when when Julian presents something like this was that how does this apply to my production environment it doesn't look anything like Google's production environment at all right the problem is not hundreds of millions of endpoints it's not scale the problem is heterogeneity right I have different workloads from different generations using different protocols using different languages all sitting within my data center there is no uniform deployment model right there across different kinds of runtimes there is no standard application frameworks like the kind Julian described right because it's been acquired over time across various third-party software in many cases so this new security approach which was described elegantly it's actually very technically complex to roll out in my environment right and lastly even if I do a time to roll it out how do I ensure the success of this how do I measure this how do I get a visibility in such a complex environment as how to achieve this and as a product manager these are the kind of problems that we that we landed up thinking about as to like how do we make what is really necessary from a security perspective much more accessible to the enterprise customer and with that is how we started thinking about this problem we didn't start thinking about saying we want to build security features for sto actually we weren't even thinking about history when we started off with this problem we wanted to make these security principles and this posture more approachable right and we started thinking about how we can do that and it is over time and looking at this problem in a incremental manner that we realized that having something like sto is very important way to enable enterprises to be able to adopt these principles so let's talk about the primitives that build up to form sto and make this possible right the first thing that you need to do given your heterogeneous infrastructure and and the fact that you have all kinds of protocols and languages is the ability to virtualize this application or network endpoint right and envoy is a sidecar but something that you know our senior technical leads did a long evaluation across a bunch of models and they came up and said this is the most optimal way of achieving this goal right and so that gives us this abstraction in addition to so a key thing about that abstraction is now you can start being a transparent to your application code because this now becomes your policy enforcement point right and as well as policy monitoring and network monitoring point right so now you certainly have something that is the equivalent of a NIC card but at the application level right that gives you all these properties right another key feature which we did invest in an envoy was to make sure that the TCP support was more robust because this is one of the key things that differentiates a homogeneous infrastructure that's all restful to something that there's more enterprise like right and so with this in place you can now have uniform policy enforcement and you can have uniform access metrics and logs the second question you might ask is I get the value of on four I get the value of having a proxy but why do I need a service mesh what is the service mesh I know I have a mess in my production environment do I really need a mesh on top of that so it's yeah the name mesh is a bit of a marketing ploy right what it really is is a way to virtualize your network at the application levels to some extent right and in order to do that you actually need just like with any other networking software or you need a control plane right and you need a control plane that can scale to thousands of services and just like any other networking system you need to have a central policy control or central policy visibility and you need to wait to have a notion of being able to reason about who is talking to whom right and you're able to do that at the l3 level with your tools and you must be able to do that at this level right and how do we achieve that the proxies by themselves are not enough right and sto really solves for those problems right so we chose this to you not because it's a cool thing but because it actually solves a real problem from a security perspective so going forward is to does more than just security obviously for those who have familiar with it it does traffic management like load balancing as well as things like ability to route with layer 7 semantics of course it does security and we'll deep dive into that today a little bit more and it does telemetry which allows you to get various kinds of signals around performance and error rates to make sure that your services are more reliable and and performant so we go back and look at those five principles and how you can apply them using the technologies that we provide on Google cloud and through Sto so the first is about protecting your VPC in the context of cloud your production environment can be represented as your V PC right and how do you protect that at the edge the there are two main things to achieve here there are two things to do here one is to protect your public facing endpoints right and protect them against internet-based threats so we provide a couple of technologies there which are very powerful one is cloud armor you will induct about DDoS protection cloud armor allows you to it's sort of a sophisticated you ask which also has DDoS protection baked in right so this is a critical piece of your front-end strategy the second is Julian talked a bit about how we have an admin proxy to allow beyond cop like principles in order to grant access for our employees to gain access to production systems we have built a corresponding thing called identity our proxy right which allows you such four it's a good way to allow humans and to secure human-based access to the production environment you having protected the front end you think of the parameter actually the parameter is not just what's facing the Internet in many cases your parameter may be a departmental boundary that you wish to drop within your network sometimes or in kubernetes landscape we call those clusters or namespaces right in your other environments you might call it a network segment you need to protect that against other parts of your network that don't don't have the same level of sensitivity security sensitivity this internal segmentation is also needed and sto ingress is a solution for that because it's it can act both as a layer for as well as a layer seven sort of a proxy in order to segment two different pieces of your infrastructure and then once you have this front-end protected you need to now seal out the parameter right and that means defending against exfiltration vectors and control so one of the things we provide is firewall policies like these are layer 3 policies to understand like the out to be able to control outbound communication from within your network and now with what is just G a is VPC service controls which is a way to extend this notion of a secure perimeter to multi-tenant cloud services like GCS and bigquery so that you can implement a similar parameter strategy for those as well so this is a diagrammatic view of what I just talked about right so as you can see here from a corporate network you can gain access to our identity our proxy you have cloud armor in front and these are actually implemented on Google's clouds load balancer so they are effectively policy engine both identity our proxy and cloud armor on Google cloud load balancer right additionally you can now implement an sto ingress that sits right behind it to provide additional segmentation so let's take the second principle using credentials back to identities for all entities on your network now Julian talked about having alt s as being the source of truth to provide and the certificate manager to provide identities to everything administrators hosts and workloads in your enterprise typically it's very hard to have this kind of a uniform way of meaning Trust it's a assigning trust to users in two-horse it's typically a solved problem in most production environments you have been doing this for many years right what is really unsolved as a problem is a way to assign identities in a secure manner to the workloads so this is what this tier is trying to solve it tries to complement what you already have and add to that by providing a certificate authority for workloads which is different from necessarily the roots of trust that you might use to say identify users which might be an Active Directory or identify your hosts which and in this particular example that could be the kubernetes which is able to determine the trustworthiness of a node on which it is deployed so in this particular example taking the same example that Julian gave but now applying it to kubernetes you have Alice who is on a corporate workstation trying to deploy a pod to a kubernetes cluster right in this particular case Alice authenticates to the cluster to the master and perhaps as a particular namespace admin with deployment privileges in order to be able to deploy so therefore we know she has the right privileges in order to start doodle dot front-end over here right at this point once she is authenticated the master can then deploy the doodle front-end and it assigns an identity which we call a service account right so service accounts are now becoming a common parlance it's used in Google cloud platform AWS and kubernetes they basically represent an identity that is typically associated with a workload so at this point once it's deployed if this workload were to be part of an sto enabled environment then there's a node manager which is running on that particular node that then is able to use this identity that was just issued by the master and create a CSR or a certificate request to the service mesh certificate authority right and the service master certificate authority now takes this identity and encodes it into a x.509 credential that is then placed that is provided to doodle front-end for authentication traditional x.509 certificates authenticated hosts so we worked with the open-source community to have a to come up with a way that everybody agrees on at least within the open-source community of encoding a workload identity into an x.509 certificate this is called spiffy and the and the format that we all agreed upon was how it would be encoded in x.509 and it's just supposed to that and is able to interplay with any other party that can also support the spiffy format for certificates going to the third principal using channel bound credentials for authenticating services Julian touched upon this lightly I will give a concrete example to make this real right you can with sto specify a policy that says all communications to service B must be authenticated over mutual TLS right as in when we talk about channel bound I'll cover that one more time it must the identity actually must be a certificate on the channel right such that that identity cannot be replayed so in this particular example assuming the shared service the logging service was compromised if you are using if you're only allowing mutual TLS based identities for authentication then even if service a were to presence its certificate to the logging service the certificate by itself cannot be replayed because logging service cannot create a channel right a TLS channel with the private keys that correspond to the certificate right so this is a very key principle in order for us to mitigate risk and escalation of privileges associated with impersonation right so thus the all peers once you enable this mutual TLS we can guarantee that all peers are authenticated using certificates based specific credentials that a channel mount however this is easier said than done for your Bromfield applications right imagine a world where you have an application of existing service you turn on MPLS voila here's some bunch of phones ringing because a whole lot of clients which you didn't know existed weren't enable for MPLS and they just broke right so it's very hard to actually do this in practice so one of the things we did in sto was to create this mode called permissive mode and in the permissive mode when you set it to permissive mode or server can accept both mutual TLS authenticated clients as well as regular your existing clients so does what we would recommend for your brownfield applications is you set all your services to this permissive mode which is now the default mode for sto and then you ensure that all your clients are talking MPLS at some point you are able to determine that all clients talking to a service are now mutual TLS enabled and at that point you can lock this service down by changing it to a strict mode we talked about the identity of origin earlier right and we must be able to propagate that as a forwardable credential right so in this particular in the cloud environment for example you can use identity aware proxy to authenticate any human coming from a portable device you can use certain principles like which device type etc when authenticating to identity a web proxy right so those checks can be done in order to grant access now all this context that is part of the client context can what identity a web proxy does is it encodes it in a token which we call RC token it's a form of JSON web token that has been structured specifically with great we provide greater structure and very importantly it's a short-lived token this reduces insider risk because if the token is logged or stolen there is we are reducing the risk by reducing the time for which it is valid right where it stewards value in this process is being able to authenticate or sorry able to validate that this token is actually a valid token by contacting the issuer and validating the fact that it's a valued token such that the backend can now safely use the claims in order to grant access or influence business behavior right and thus as you can see it's just taking care of a lot of the plumbing that you would normally have to do in these particular cases going back to the fourth principle which is granting access based on multiple identities right the main reason to do this is to protect user data so many of you might be handling data of your customers and and this is the reason you want to do this not for any other reason it's not a traditional network security posture it's more about user data protecting that through access control let's take this example where there is a privileged in insider for example a support engineer who can access based upon real business requirements your user data or your customer data right but what you really want the support engineer to do is to be only be able to access the data by the case tool because the case tool implements a lot of your business policies like for example is there a valid support ticket against this right who'da is the support engine you properly logged in to the system are we logging all accesses so on and so forth right if you're able to bypass this tool then you were able to bypass all those checks right but at the same time the case tool might be a tool that is delivered by a bunch of your developers in internally or a third-party software which is deployed by somebody else the people who deploy who have the deployment privileges in the case tool need not have access to the data imagine a financial services sort of or financial records the person who runs the job may not be an insider to get you a quarterly report right but they have the admin privileges to deploy their job right this is an example in support that's another example in the sort of a fr kind of world right so which means there are two things that must be true the access must come from the case tool and the authenticated user or which it is acting on behalf of right must be a support engineer right these two things must be true in order to grant access thus you have to reason about both of these identities in order to grant access such that this privileged insider cannot create an unauthorized client and simply access because the only the user was authorized or was on the policy similarly the case tool cannot identify itself and in using its ambient Authority have broad access to the data because that's a sure way of getting inside increasing an insider risk right so therefore it must be working under the delegated authority of a customer support engineer right and this is a very key reason why we need to create yet another policy engine for sto and not simply rely on existing network policy engines that exist in communities and outside right this is not a solved problem now it's a it's a new policy language that we are building and we will continue to work on this right over time but this is the primary use case that we are targeting right there's multiple channels through which different users can access for different use cases right and how do we make it easy for you to be able to build such policies and implement user data protection within your production environment so we talked a lot about two identities and origin identities and you might wonder what what about HTTP service interactions like my sequel for example and the answer is that's true we cannot reason about the identity on the at the sequel protocol level because today on why doesn't understand it hopefully over time we want to increase the number of a layer seven protocols that we understand but today we're limited to http G RPC as the primary protocols that we support right so in such cases yes we are not able to reason so strongly about who is the user on behalf of which the call is coming from but we can still constrain which are the prom which any access can be presented from so for example even if you have the my sequel credentials you should not be able to access the database from anywhere except through service a right and we can enforce that property right so no matter what like if your my sequel credentials were stolen or it was in a source control system somewhere and somebody accessed it you dish will still not gain access because they have to go through service a and that is still being enforced so there's still a VIN for TCP communications outside of where we don't understand the layer 7 protocol the last part is platform implements security by default throughout this talk you might realize that I've kept talking about how is to implements all of these I've never said how your application needs to change in order to adopt any of this posture all of this complex technological paradigms are all expressed as policies that get enforced at the proxy level right so these include encryption of data in transit it includes the ability to auto-rotate certs and keys a very hard problem actually to do this at scale right and do it properly so to ensure that you have the right cryptographic hygiene how do you protect user data access are using both identities right this has been traditionally been a hard problem to enforce consistently across and how do you monitor security posture consistently across the heterogeneous environment right now you have the ability to do all of that because you are able to use something like Sto the last point deserves a little more attention since I did not cover it before and it's important to understand that an in a new world let's say you have a MapReduce workload that comes up on a bunch of containers access your sensitive data as a bad job and then disappears it was a bad job you go back look at your network flow logs a week later a month later and try to explain to your internal and external auditors what just happened a bunch of IP showed up contacted this back-end IP and then a bunch of IPs again showed up new IPs that contacted something else we have no idea what that IP actually meant because it's completely different work that ran in different points in time right now you can actually have logs that has an identity for that workload not of the host right and you're now able to have this visibility across a heterogeneous set of environments heterogeneous set of protocols including the TCP protocol which I just explained who acts as the my sequel database is still expressible as an identity right so you're able to do that right so you're able to understand that and it makes your network acts of logs much more meaningful in this new environment and it helps you go through your security and compliance or it's much more easily write and and you're able to do this in a consistent manner independent of your infrastructure so with that I would like to just explain how you can get started if this is something that is of interest to you how you can get engaged to start without strongly recommend that you read our infrastructure security papers and in particularly the application transport security paper so that you have a deeper understanding of how this actually works at a deep technical level and then to engage an Sto you can start by reading the blogs and going to our website which has the concepts a bunch of examples and how to get started in open source on Google Cloud we have an sto on gke which is sort of makes it much more easy for you to just get started so strongly recommend that as a way to get started on a hands-on basis if you want to know more about what we are doing is Google secret sauce around sto please reach out to me at some Rodri at Google calm right and I'm happy to sort of help work with you to give you more information about what we are doing to make this much more magical for you so thank you all for taking the time and having the patience to go through a fairly technically complex topic I hope this was a good use of your time and there's a lot of interesting talks about service mesh that have happened during next some have already occurred some are coming up please feel free to attend those you those which are coming up and or go and look at the videos for those which have already occurred if you haven't attended them already your feedback is greatly appreciated we don't have a moderator for the Dory but if you do ask questions we can on the dory we can certainly look at it and come back to you offline in the meanwhile you have a few minutes like a 4-man so if anybody has a few questions you can take a couple of questions right now [Music] 