 [Music] hello everyone I am in the best possible position standing between you and lunch so thank you all so much for coming today I want to talk to you about the various ways in which we've invested in running hashtag or vault on GCP over the past year and a half to two years this is a kind of high-level introductory talk I will be doing some live demos but we're not going to really be getting deep on any one topic so this is more of an overview of some of the ways that we've made investments in the past year and a half to two years Lake mano said my name is Seth I work on the developer relations team here at Google my twitter handle is south fargo if you have questions comments complains or concerns you can tweet at me please don't complain but otherwise fine if you have questions you don't feel comfortable asking publicly my direct messages are also open so you can feel free to send me a direct message cool so with that let's go ahead and get started I want to provide a quick overview of what is vault for those of you they might not be aware and then we'll jump into some of the GCP specific things that we've been working on so in order to talk about vault it's important to talk about what is a secret when we talk about a secret we're specifically talking about anything that can be used to authorize or authenticate so that might be a username and password an API token a TLS certificate but it also might be something that's personally identifiable or business intelligence data like a social security number or credit card a passport number the API key to access your internal analytics dashboards that give you a competitive advantage in your market and given this problem and given that secrets are a common attack vector because they often have overly broad access or they access critical systems data we often ask questions like how do our applications get secrets how do humans get secrets how are secrets updated how are they revoked who is using this secret right now why are they using it when are they with it and what do we do in a compromise because as much as we would like to protect our secrets and make sure that no one ever has access to them at some point we have to accept the reality that an attacker is going to exploit a vulnerability in our software or in our humans and they're going to get access to our secrets so we need a plan for rotation and we need a plan for revocation what is the worst-case scenario how quickly can we recover so what is our mean time to patch a CVE what is our mean time to recovery in case of a leak so vault is an open source tool it's written in go so it's free and open source that is designed to answer these questions and many more it tries to be a single source of secrets for your organization it provides programmatic access so that machines and humans can access the API but it also has a CLI and a UI for human access so humans can interact with the API or the UI and then machines or other applications and services can interact with the API directly and it's important that to note that it's cloud friendly so volt doesn't require that you have some special hardware or some special hardware device attached to a physical machine this runs on you know native VMS and any cloud provider including GCP so it's very cloud friendly works very well in the cloud ecosystem you can even run it in a container vault stores all of its volt encrypts all of its data in transit using TLS 1.2 or most recently 1.3 for client authentication the data is encrypted at rest with 256 bit AES GCM encryption and it offers a hierarchical key value store for storing data so it's a path based approach to storing data and the data inside a secret is a key value pair one of the things that's really interesting about vault is that it offers dynamic secrets so in a traditional world let's say I need a database username and password to connect to my my sequel instance well an operator has to provision that credential by running you know create user in the sequel command and then they take that username and password and they put it in a text file to give it to the application with vault vault can actually run sequel for you and provision that user automatically so a human never sees the credential only the end application sees the credential and this helps you maintain provenance a one-to-one mapping between a credential and the application or service that's consuming it this gives us a really tight audit trail and it allows us to time-bound our credentials so instead of having a human creative credential that lives forever we can have a machine create a credential that's valid for 24 hours or a week or a month and by Auto expiring these credentials we reduce our surface area for an attack we reduce the number of credentials and we reduce secret sprawl and more importantly we can revoke any of those credentials at any time in the event of a data breach humans or machines authenticate to vault by providing some type of credential vault then goes to these third-party databases things like Redis my sequel Postgres or as we'll see in a bit Google Cloud and dynamically generate credentials on the fly and return them to the requester each time someone requests a credential they get a brand new unique credential and Voltas pluggable so I already mentioned like post Grass Mike my sequel post grass etc basically any sequel database including Oracle and MongoDB and sequel server are supported for the database side of things there's also cloud provider supporters so at Google we have full-time engineers who are contributing support to vault there's also plug-ins for other clouds for your multi cloud strategy like AWS or assurer or Oracle or VMware but then there are other systems that we jet that we don't think of when we talk about secrets but things like rabbitmq how do you get that API key out there things like SSH access how do you maintain the ability for people to SSH into systems things like managing TLS certificates running your own PKI infrastructure vault can actually act as a certificate authority or an intermediate Civic certificate authority providing TLS or mutual TLS authentications between your micro services it obviously integrates really well with other tools in the hash Corp ecosystem and most recently you can also use it to provision active three users as well as open I deeper connect providers so what are some ways that you can use vault with GCP so we've made a few key investments and a few areas that allow you as Google Cloud customers into Google cloud consumers to gain the benefits of running vault as an open source product on GCP while leveraging other GCB tools and technologies and the first one I want to talk about is storage backends so vault itself is actually a stateless service it instead has pluggable storage backends storage back-end is just where vault puts its data the easiest one to think about is the filesystem vault is just going to write its data to the filesystem it also has an in-memory implementation where it will store all of its data in memory and when you stop the process all of that data is lost it's great for local development but in production how could you run vault against a storage back-end that's highly available provides high availability high durability but also is low maintenance right ideally you don't want to carry a pager just for your storage back-end so we've made some key investments on GCP the first storage back-end which is probably the most common among our customers is the Google Cloud storage or the GCS storage back-end this is a GCP native storage back-end you create a Google Cloud Storage bucket you grant vault or a service account running vault permission to read and write data from that storage bucket that'll give you three and a half nines of availability you don't have to carry the pager we carry that pager for you and it allows you to run vault in high availability mode so this allows you to run multiple vault instances in high availability mode for you another storage back-end we offer for our enterprise customers or for customers need a little bit more availability as our Google Cloud spanner storage back-end Google Cloud spinner is GCP native it gives you five nines over the availability and the highest configuration also supports vaults high availability mode it also supports vault enterprise if you're running hash Corpse proprietary Enterprise offering it's supported on spanner but not GCS because of the way that vault Enterprise requires a transactional interface again both of these storage back-end support high availability both of these storage backends are available with zero maintenance to you Google carries the pager and the slides that I'm showing you here are exactly how easy it is to add this configuration to your vault server config it's just three or four lines of configuration and the iam authentication and now you're using a Google cloud supported storage back-end both of these storage backends were contributed by Google engineers to vault core they're available in the vault open source distribution you don't need to install a plug-in or run any sidecar applications you can download vault today or really any of the recent versions of vault these configuration stands ups will work out of the box they also support GCP native default application credentials that means if you're running vault on a Google compute engine instance a Google container engine instance or Google kubernetes engine instance cloud run cloud functions anything that supports instance metadata you can attach a service account to that VM or that underlying runtime and it will automatically authenticate so you don't have to worry about passing around a service account so those are the storage backends now let's talk about secrets engines so in vault secrets engines our pluggable systems that allow us to extend vaults functionality and there are two secrets engines that I want to talk to you about today that can really help accelerate the way that you do security with DCP the first is our iam secrets engine so this is our Google Cloud Identity and Access Management vault secrets engine plug-in it's a mouthful what this allows us to do is to configure vault to generate ooofff to access tokens for provisioning access to Google Cloud so what I do is I configure vault with a service account and some permissions and then I say hey vault I would like you to generate service accounts or oauth2 tokens for me whenever someone interacts with this path what vault is going to do is it's then gonna make the various API calls to Google Cloud and it will generate an OAuth 2 access token which expires in a certain amount of in this example 60 minutes so this is an OAuth 2 access token that you can use to sign and authenticate requests to Google cloud and they're automatically cleaned up after that 60 minutes expires unless you write this yourself vault is actually the only way today to have time based G cpi-m credentials that automatically expire this allows you to provide automated short-term access to your various Google resources with very little overhead so you imagine you have some batch process that needs to get some information from a cloud storage bucket decrypt it with Cod KMS run some data and store the results somewhere you can leverage a storage back-end like our secrets engine like this to generate those credentials for you that automatically expire whenever the job expires so you don't have to worry about leaking those credentials or having a long-running service account with permissions the next secret engine which is one of our newest secret engine is the google cloud KMS secrets engine this secrets engine is an abstraction on top of google cloud KMS our key management service the google cloud KMS secrets engine allows you to create manage delete update encrypt decrypt sign verify all kinds of data through vaults api now you could do this by using the Google cloud kms API directly all of the functionality that we expose in the plug-in is also available via the API or the UI directly but we have a lot of customers who are already heavily invested in vaults and they wanted to use the same interface the same policies the same authentication that they're already using for their multi cloud strategy or their hybrid cloud strategy but they want to leverage Google Cloud kms and this plugin is a way that you can do that the coolest part about this plug-in though is that it actually allows you to encrypt and decrypt data backed by a hardware security module in HSM and this has exposed via the Google Cloud kms api's so just by reading and writing from a json rest endpoint you can actually have your data be encrypted and decrypted by a physical hardware security module up to FIPS 140-2 level 3 if you have those regulatory requirements so again this is GCB native integrates with called HSM you can manage your keys using vault you can use your existing policies and configurations in vault and you can encrypt sign verify decrypt data using the vault API so instead of just showing you this on a slide I figured I'd show you what this looks like so with that we'll jump over to the live demo so I have a vault server here already set up it's running on Google kubernetes engine and I'm just going to go ahead and run vault read GCP token dev token and what this is going to do in real time this is very real you would theoretically be able to use that token for the next 60 minutes if I don't revoke it by the end of this talk this will give you access to this project you can't actually do anything in the project but this is real every time I run this command I'll actually get a new Google Cloud access token this is an access token that I can authenticate to the API with it is an OAuth to bearer token and I can give this to any of the Google Cloud client libraries or any service account or any type of officially supported tool and it will authenticate as this user and be able to access the api's the permissions as dictated by I am so that's actually just how easy it is to generate these tokens and again they automatically expire after 60 minutes I've already configured the GCB kms plugin and I'm gonna save some typing by copying it to my clipboard so here I'm using the vault API to encrypt and decrypt data using the Google Cloud kms managed keys so all I do is I ask volt to encrypt some data in this case I gave it the plaintext hi and vault gives me back so encrypted cipher text from here I can also create new keys rotate keys upgrade keys and even delete keys all using vault API under the hood that's backed by Google Cloud kms and Google Cloud HSM but it's abstracted for you at the API layer so all of these secrets engines are developed by Google as plugins so they are third-party plugins but they're bundled automatically in all vault open-source distributions so even though they're developed third-party plugins they're included in vaults distribution which means you don't have to download or install them on your own if you download any recent version of vault they'll be available for you and as I said before just like the storage backends these secrets engines support the Google cloud application default credentials which means you don't have to worry about passing around service accounts if you're on a Google managed VM or something with instance metadata so the last thing I want to talk about is off methods so we've talked about how you can run vault on GCP we've talked about how you can provision accounts and interact with kms but if i'm a google cloud user maybe i'm a g suite user google cloud user I have these service accounts how do my humans or my applications authenticate to vault using GCP in other words can i leverage GCP as my source of trust for my underlying authentication and we can we actually have the Google cloud off method in vault an off method is the way in which we convert a human or machine supplied information into an authentication credential and this is what it looks like we can log into vault using the GCP method with a particular role a service account and the underlying service account credentials vault will authenticate this against the Google Cloud I am api's and it will give me back a vault session vault token if you will and this allows me to then interact with vault given any pre-configured policies that my security team might have created in advance so this is GCP native it allows you to authenticate with I am service accounts or GCE instance metadata so you can actually authenticate to vault just because you are an instance in GCE or anything that has instance metadata and it has support for vault group aliases and policy management which is really important if you're running vault enterprise and you want to use namespaces so very quickly let me show you what this looks like it's thinking so it does take a little bit longer because we have to make a few different API calls to authenticate the request but what I did here is I gave vault my credential as well as the service account that I'm authenticating with and the role in which I'm authenticating and vault gives me back a token that token has some policies so I basically get a session with policies attached that were configured and managed by my security team so I just authenticate to vault using my existing Google Cloud credentials so this is a great way to kind of trust vault as kind of the source of truth for secrets but then leverage the identity bits to Google Cloud on google kubernetes engine or any kubernetes cluster we also have the kubernetes off method now this is not something that Google engineers have specifically developed we've partnered with a number of folks including folks at Hoshi Corp to write the kubernetes off method but this is a way to authenticate pods and services in kubernetes engine using vault this is GCP agnostic it allows you to restrict access via our back permissions and various kubernetes service accounts you can restrict access by kubernetes namespaces and it works great on gke because gk is just kubernetes but this also works if you have G key on prem with ombos if you have your own IKS cluster or eks cluster because this is kubernetes native it'll work on all of those as well so these off methods are developed as plugins that are some of them are maintaining contributed by Google and Google engineers they are also bundled in the open-source distribution of vault so again you don't have to worry about installing them yourselves they just have a separate development velocity than vault core and they help solve that first secret problem how do I authenticate the vault without like hard coding or credentials somewhere how does all of this work so these off methods help you do that do that by delegating trusts to either the cloud platform or the kubernetes api server so I have a few links if you're going to take a picture of a slide this is the one to take a picture of there are a few things here that are really important the cloud spanner in the clouds storage backends are heavily documented as well as all of our secret engines including all of our off methods so everything i've talked about here today is on this slide except the last one and i have one minute left so i'm actually going to show it to you so the vault fluent d' configurations allow us to abstract vault audit logs and system logs into stackdriver in a really friendly way and i'm glad i have an extra minute because this is just really cool to me so i'm gonna go ahead and jump over here into the Google Cloud console and make this a little bit bigger I've configured this in advance I've configure this in advance so again I'm running vault on GCE VMs in this case you know notice if I click on this little drop down I have two tags the vault project IO audit and vault project IO server the audit logs are actually vault audit logs vault audits every request and response in the system and the server logs are just the operational logs what you would expect to see from kind of any microt service or any long-running service I'm gonna go ahead and filter by the audit logs here here are audit logs where and this is directly using that fluent e configuration I have my IP address the alias idea of the credential the API method I used and the path that I accessed and right inside stackdriver I can actually drill down into the direct request and response headers in the JSON payload this is structured this is available and I can actually filter directly on some of this data so if I just want to click show matching entries I can see all of the requests that that particular token made right from inside stackdriver and this is not both specific but this is those fluency configurations allow the audit logs to be parsed in a way that stackdriver exposes this functionality to you that's all I have for you here today thank you all so very much I'll be available for questions outside of the deaf zone thank you [Music] 