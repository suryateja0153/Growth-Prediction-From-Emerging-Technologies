 what's going on i'm andy i'm a technical milliner  you can tell i'm a build fanatic and an advocate   of continuous everything i'm a founder of  control plane continuous infrastructure   and security practices with a focus on containers  and kubernetes we are of course hiring cloud   native hackers and engineers if i can get to  the end i will give you more details and i've   done a little bit of everything from development  databases administration operations pen testing   architecting i want to talk about network security  in kubernetes so what is this it is a way to   ensure private and trusted communications  across potentially untrusted networks with   malicious actors like the internet why do we need  it because we can't trust anything the internet   was built with trust between everything but unlike  the origins of the internet we're not a bunch of   academics running trusted workloads anymore we  think about runtimes and we write software to   run as if it were a day voting on the lake when  in reality there are pirates everywhere we should   be designing our systems for the most hostile  conditions they should they could possibly face   resilience is key so we'll look at how kubernetes  does it it uses a lot of standard components   but sometimes in a slightly different way to the  manner they used on the internet for example on   the public internet self-signed certificates are  bad we'll look at why they might be good we'll   look at how encryption works how we establish  trust and finally how we determine identity from   the protocols that keep kubernetes secure and  our workload safe and if there is one takeaway   from this it is encrypt everything everywhere we  are at the bleeding edge of a revolution that is   already permeating traditional enterprise systems  these systems have high compliance and high audit   requirements and breaking away from traditional  network security patterns is really difficult   there are many layers to a security onion so cloud  native applications give us an opportunity and a   problem it's difficult to encrypt everything  but it's also difficult to encrypt workloads   that are constantly churning restarting and being  rescheduled to unexpected or unpredictable places   in our infrastructure the spiffy project is  looking to solve some of these issues the   subject is broad and deep so we will cover some  key technologies and hopefully leave you enough   pointers to go and do some further investigation  on the parts that interest you more thoroughly   so network security 101 kubernetes api components  tls in general mutual authentication in particular   cni and network policies for applications and  finally looking at bootstrapping identity for   dynamic workloads with spiffy so what  do we want from network communications   we want privacy and we want trust private  means it's confidential trusted means we have   integrity and authentication on the communication  and non-repudiation sometimes makes an appearance   here that means the inability to disprove it was  the person actually communicating we won't worry   about that one for now so human communications  trusted and local this is like whispering between   two people we know who is talking to us and nobody  else can hear us this is like a private air-gapped   network we believe there's nobody else there and  so we take no extra steps to verify the identity   of the other party this is okay in a very small  number of situations but in general it is not   if somebody else sneaks into the room or is  hanging from the eaves our security is broken   we need it to be private as well as trusted so  how does this work on the internet communicating   on a public network is like shouting across  a crowded streets we see the speaker or ip we   hear their voice synchronized with the movement  of their lips and hear the words is that enough   to trust somebody well in human terms right now  yes although in the future deep fakes mean im   impractically that may not be a possibility but  this only works when both parties are local what   happens when we need to communicate remotely  you may remember postman pat from your youth   we use the postal service or these days this is  the internet so with the postal service we want   to trust the stamp on the letter as a guarantee  of sanctity nobody is supposed to open this right   wrong the uk in particular has a long history  of postal interception and communications in   transit in general preventing them from reaching  their destination or spying on their contents   so we need to get our privacy what can we do  when our communications path is untrusted we   use encryption and on the internet that  encryption is what we know is http secure   ssl tls and back we go in time to 1991 when  there were no certificates neither was their   geniuses but for those of you old enough to  remember it here's a trip down memory lane   we tried for a few years we released ssl  version two it was difficult it was slow   algorithmically and computationally and it  was broken so out came ssl version three more   turmoil and finally tls backwards incompatible  everything is deprecated we're now on tls 1.3   and there are many many attacks against these  protocols and specific implementations of them   so as always keep your systems patched  is it really that simple will smith   sadly not a single mistake anywhere in  configuration implementation or usage   can compromise the integrity of our encryption  leading to the oft-cited aphorism don't roll   your own there's no greater challenge for a  cryptography nerd than an unhackable cipher c   cryptography is just a mathematical  puzzle with some strict assumptions   and with that warning on to  kubernetes securing the api server   there are a lot of encryption options on the api  server we use tls everywhere but how does this   work we ask for a set of data to be signed and  a certificate guaranteeing that data is produced   this is the csr request and we can then use the  trust we have in the certificate chain from the   signer to the leaf certificate to validate an x  509 certificate at runtime so we have the root   certificate the root certificate authority is  generally kept offline and safely secured the   root signs and intermediate or a more general  signing certificate which finally signs the leaf   or end entity certificate which is what we get on  a website or a workload or on the api server and   what's that that is a load of x 509 certificates  in a chain of trust that is the basis for tls   okay so what are these concepts and how can  we establish new encryption keys across a   network that we do not trust because it's not  already encrypted we use public key cryptography   so what is this simply it's a way to send messages  that only the intended recipients can read we use   the public key to unlock the mailbox the public  key can be shared given to everybody because it's   meant to start the conversation and not end it  then the message is encrypted with that key and   put into the box and finally the private key is  used to unlock the box and decrypt the message the   public key cannot decrypt a message that it itself  has encrypted only the private key can do so   so how does this all work some quick glossary  descriptions symmetric encryption is both keys   being the same you use one key to open  and close the same door this wouldn't be   any good on the internet because the server  would have to share its private keys with   every client who wanted to talk to it  so asymmetric encryption the keys are   different this is more like it this is how  pki works we base this on elliptic curves   which is essentially curves that don't cross  and loop around the plane and we use certain   properties of the elliptic curve to make a far  more difficult problem space to brute force   and finally to start uh this is these are  elliptic curves um and then finally diffie-hellman   is a way of generating a shared secret between  two people in such a way that the secret cannot   be seen by observing the communication this  is how ssh works this has been integrated   into the bootstrap phase of tls now so you're  not sharing information keys during you're not   sharing information during the key exchange  you're creating a key together separately and we've actually seen these guys there  we go these are the two gentlemen heroes   of cryptography that have kept us safe since  1976 fighting u.s export grade classifications   on cryptography and uh doing a great service  for all of us in the meantime so moving on   there's more info on how this bootstrapping  and tls actually works from dns simple   explained with cats what more could you possibly  ask for and this is the original crypto not this don't tell the other room so let's  move this back to kubernetes land the   api server presents a certificate when  cube control makes a request to the api   it's usually self-signed this sits in  user.cubeconfig on your local machine   and typically contains the public portion of the  root certificate for the api service certificates   which is specified when used in place of the  system default certificates cube control uses   the public key of the api server to start the  diffie-hellman exchange they generate their seats   if their shared secrets then shared a secret  key and begin to talk this is now secure exactly the same certificate validation as before  so this is what a public key is made from its   ssl tls certificates are the public part of a  server's x-509 key pair it contains a public key   and an identity a host name or an organization or  an individual and is either signed by certificate   authority or self-signed what does a certificate  look like well here is a certificate spec from   the x 509 version 3. we recognize this  as the encoded version of a certificate   and we can decode it very easily to see its  contents how do we know that we can trust it we're   back to certificate path validation and there's  a question here of self-signed certificates on   the public internet self-signed certificates are  bad they are generally the sign of a man in the   middle attack we don't trust them and it looks  like somebody has potentially pro intercepted   and reproxied our connection to a server  then presented the communications back to us the difference here is with kubernetes uh we sign  with a certificate authority that is generated   within the cluster the private keys for that  certificate authority do not leave the cluster   and as such there is one place to control  your key material if the route on the api   servers where those public where those certificate  authority private keys are stored is compromised   you have bigger problems than the encryption in  transits of the cluster so arguably this is a new   pattern and it's better than having centrally  organization controlled certificate which you   have to manage not only offline and some sort of  cold storage but also bringing into the cluster   regeneration and management of keys and rotation  time so the new cloud native way is generate your   certificates keep everything all key material  inside the cluster it's nice it works we do this   in kubernetes land with two certificates one for  the server so we prove the identity and another   one for the clients we've mentioned this a couple  of times already it's just the tls negotiation   there is a second certificate exchange between the  client and the server after the initial handshake   this establishes a two-way trust mechanism  that guarantees the identity of both parties so   on the internet you would ask for the  certificate of the server and you would   get back the google.com host name with mutual  tls you also provide a second certificate with   your identity encoded into it so both parties  can identify each other and that authentication   can then be used as the basis of authorization  this is a good thing so where are we we have   private communications confidential encrypted  we have trusted communications we have integrity   given to us by the encryption decipher guarantees  we get the correct output with the correct inputs and finally trust we have  authentication from client certificates   so back to the kubernetes api server do we trust  the network frankly no and why should we if a   malicious actor gets inside the perimeter  they have access to everything behind it   phrases such as perimeter and dmz should  raise flags in cloud native architectures   beyond core from google is designed as a response  to these newly emergent threats this is a project   that basically says trust nothing validates  everything and run your servers as close to   public as you possibly can because that's  the best way to bring pain forward and be   sure that your configurations are secure this is  called zero trust and it means that our systems   continue to make some guarantees of safety  even when some components are compromised   obviously the nature of that safety is entirely  dependent on the system and the type of data it   stores but contrast this to traditional perimeter  based approaches one compromise and the whole   system might be hosed say what equifax so if  you want to run your own xero trust server   all you need to do is put an identity aware  proxy in front of it or in the same pod as it   there are multiple examples of this online and  it's fine for simple applications it works nicely   but for complex micro services with deep  transitive dependencies and crazy call graphs   you'll probably have to run some sort of  one-time token service to prevent replays   pass request context around and another number of  non-trivial application layer concerns fortunately   they're all described in this book by spiffy  author evan gilman if you want to dig deeper   into the future of network security  this is a great place to start we will   examine some of these concepts in detail  shortly but first back to the api server what does zero trust really mean in this context  it means that we mutually authenticate the tls   connection with client certificates between  the cubelet and the api server between clients   that are connecting to it it means we know the  identity of the server and of the clients and that   we have our own private and trusted criteria  fulfilled zero trust is a lot more than this   but we're adhering to one of his principles to  restrict the blast radius of potential compromise   in our network some container or server has  an authenticated unauthorized user and their   intentions are malicious let's have a look at  the api server components and their communication   this is an awesome diagram from lucas calstrom  the cube adm maintainer it's in more or less every   talk i ever deliver and it shows us the network  communication parts and protocols for the various   components of the system so let's think about  this what could go wrong well a container has   an unauthorized user how likely is that well what  about if somebody roots a privileged container   admit it everybody is running some and with a few  caveats that is game over privileged containers   are the worst thing to happen to computing or  they get onto a load balancing box that proxy or   transiting packets to the api server with some  caveats game over or there's another container   in the same pod as us remember the pod is  a shared network name space they share the   same network adapter we can then sniff  their traffic under certain conditions   game over defense in depth is our friend here  this is similar to how traditional breaches occur   an attacker gains a foothold within a system  and starts to look for other chinks in the   armor to pivot and to continue to escalate their  privilege we can fix this for more on sealing up   those gaps in kubernetes this talk goes into  a lot more low-level implementation detail   thank you for the cats this relentless focus  on automation allows engineers to automate   and refine the businesses concerns veracity  security and performance in some order so   now that we're sure that the control plane  is able to communicate in hostile waters   what about the applications running on it our data  is the golden treasure trove that attackers are   keen to retrieve so if we leak our database keys  over the wire we may as well have not bothered   encrypting our control plane traffic so what's  next static endpoints are easier to encrypt as   they tend to stay in one place or more importantly  one ip domain uh this can then be used for x five   and nine as an identity but that's all very well  if your public uh if your um infrastructure has a   static ip as the front door but what about dynamic  resources containers break the coupling between ip   and identity that has traditionally been used  for firewalling and network security containers   churn they get rescheduled they are dynamic  so we need a component with a holistic view   of the whole cluster to run our firewalls for us  our cloud-native firewalling is network policy   kubernetes is a complex mix of abstractions  and network types and providers   and so enforcement of network policy should be  deferred to the orchestrator which has a holistic   view of the whole system this is what a network  policy looks like they are applied pods by label   of course labels are loosely typed if you put  that in inverted commas in kubernetes there is   no verification of labels as a security feature  they're the loosest possible way to enforce   anything but unfortunately we deal with what  we have with an empty pod selector this denies   everything in the cluster so it's a default fail  closed it should really look like this i'd test   this api i think for something so important it  is not very clear here's another an example that   only permits egress for port 53 traffic on both  protocols for some reason of course maintenance of   policies as applications change is very important  and this is just for layers three and four that   is because dns is inherently non-deterministic  we could be load balanced we could be geoip'd   could just be round robin going on so this was  ignored for uh for kubernetes purposes istio   does away with this problem because istio lives at  layer 7 so you can perform e-rest filtering with   an egress gateway at layer 7 with istio which  is something we will touch on briefly later so here's an impermissible network policy of  course and we have a pattern for testing these   how are you going to know if something so  loosely typed and verified actually breaks   you ssh onto the node you enter the same network  namespace and you aggressively parallelize nmap   to white and blacklist the desired endpoints  that your application can reach this is a meta   pattern for testing network policy start with  the default deny and build out your code based on   the kubernetes deployment names uh produces simple  tap compliant outputs and there are other ways   to firewall things in kubernetes um notably  new vector operates at a different level   network policy whatever you do do something  uh unless you are a creative agency with no   state in your application at all so we also have  encrypted container network interface plugins   these do some good if you're using one but  they only fulfill part of our requirements   this is blanket symmetric encryption on all  traffic we have no identity and there's no   authentication and we're using a single key  a public api is an attack surface so we need   to do something else to fix this problem enter  spiffy spiffy is a set of open source standards   for securely identifying software systems in  dynamic and heterogeneous production environments   spire is the reference implementation which  is a tool chain for establishing trust   between software systems across a wide variety  of hosting platforms and concretely spire exposes   the spiffy workload api which can attest running  software and issues spiffy ids and s-vids and   s-vid is a spiffy verifiable id document and is  the foundation of the identity that we then use   to bootstrap our network encryption this in turn  allows two workloads to establish trust between   each other for example by establishing mutual  tls connection and we do this by attesting to   individual workloads this is an example of aspire  a tester for kubernetes and attestation policy is   describing the properties the workload must  exhibit to conform to the policy and to gain   the identity and have the certificate generated  for them and it's typically a mixture of process   attributes so the contents of pids proc sorry  and infrastructure attributes so testing to a   vm on a cloud provider you're using the metadata  api to pull back instance id and type for example so spiffy is a standard for how an application  can retrieve an identity programmatically   and importantly generate short-lived  credentials on the back of that identity   and just as importantly the api allows workload to  retrieve a trust bundle which is the public keys   that can be used to verify these self-signed keys  so we're self-signing with a private ca and we   need to generate we need to share the public key  of that ca so that workloads can validate the tls   certificates that we have minted and handed out  to our clusters so our applications in the cluster   so this means applications libraries and tools  can retrieve uh sorry can retrieve credentials   that automatically identify them  without needing any secrets co-deployed   a spiffy id looks like this there is a trust  domain which in kubernetes is your cluster name   and you have a workload identifier and it's  encoded into an x509 just like we saw earlier   using the certificates extensions to encode  further information here is a certificate spec   the x509x here are what are used by spiffy how  do we know that we can trust this we're back to   certificate path validation it's exactly the same  technology used in a slightly different manner   and we can see how further selectors can  be used to identify all sorts of workloads the workload and node tester plugins here   bootstrap the identity process and can do so  across multiple different deployment types   while istio implements a rudimentary first  cut version of spire of spiffy i'm sorry spy   implements a whole lot more so this technology is  actively being pursued outside of the sda project   it is important to note that spire and well spiffy  in particular is not the network encryption itself   it provides the identity on to which we can  hang all our network encryption and generate   certificates but it does not have anything in  the specification that describes what the usage   of the verifiable identity document is for  and very simply it looks like that we insert   the spiffy id into the san this is the istio  implementation envoy has the public keys of   the certificate authority injected into it because  istio is using its pilot component to write those   api changes to one voice api it's all api driven  configuration and as such envoy is able to verify   the uh authenticity of those certificates  and uh security tightening will continue in   this project istio is still nowhere near where  ultimately its promise suggests that it will be   so yes a couple more minor things the secure  naming is then used secure naming is extracting   that sam and using it as the basis for routing  decisions so we then put on top of that   are back at layer seven so http verbiage paths  and uh we can also um uh and there's something   else that hangs off that escapes me right  now and there's plenty more so recapping we have end-to-end encryption private mutually  trusted communications between the api server and   kubernetes and its callers we have encryption in  kubernetes equally now for the values in the xcd   store which we didn't used to have you must turn  on ltd encryption on the api server if you uh have   the chance and in istio's case we are actually  minting certificates and handling them to envoy   um control plane have uh some threat modelling  on istio and envoy um from a devsecops meetup   in london recently that you'll be able to find on  the twitter stream eventually there are attacks on   envoy from compromised pods um if you want  to talk more about that we've got lots of   interesting stuff um find me afterwards so the  takeaway from this is do encryption it's great   encrypt everything and while  you're there you may as well do it   everywhere uh incredibly i've managed to go  fast enough the obligatory hiring notification   um if you would like to come and work in  london on difficult problems to do with   network security application security and the  provenance of artifacts and third-party code risk   then we are a very nice team small team of people  and uh we offer some great benefits please hit me   up afterwards and any any title that you want you  can more or less have so with that in conclusion   network security is very important x509 and  tls keep safe network policies are mandatory   you really must be running them in your kubernetes  clusters otherwise you're allowing routes all over   the place um on that topic make sure you also run  something to block off your cloud metadata apis   cloud native applications have way more  opportunities for securing them than previously   a container is a per process granular high  fidelity hangar for us to put security policies on   we can put you can wrap security around a single  process so although containers are fast and loose   in some uh and from some angles they also  offer a far greater opportunity to uh learn   set conf um it's the on spiffy give you wings and  encrypt everything everywhere thank you very much we can do one question so uh banks love using ip addresses as the  only source of identity for firewalling   um yeah and it'll be have you had any success  convincing people that ip addresses are not   particularly good identity or is that mindset  uh yeah so this is wrapped up in the whole uh   breaking the traditional enterprise mindset it's  difficult um the way this works best for us is   an enlightened vp will say our developers have  deployed loads of deployed loads of kubernetes   what do we do how do we fix this um it's still  the audit requirements and change control required   to get changes for peering requests or subnet  allocations is still super super difficult so   much success no but the beginnings of changing the  mentality absolutely there's one further problem   that if people have uh any interest in this spiffy  are currently looking well saitail are currently   looking at how to solve federated trust domains  because tls libraries do not check the federated   aspects of um some of the extensions to x509  well at all which means ideally for a banking   scenario you would have multiple uh kubernetes  or sdo or whatever just tls trust domains   that are able to verify each other without being  able to uh cross cross generate each other's   certificates like an obvious requirement however  it's not as easy as that and the project's um   very much looking for help so if federation of  trust domains works then ultimately we can say   issuing ips entirely like we do in the cni can  be done on a wider infrastructure level because   we're layer 7 everywhere more help is needed  good question though thank you thank you 