 The human eye has to be one of the cruelest tricks nature ever pulled. We can see a tiny cone-shaped area of light right in front of our faces, restricted to a very narrow band of the electromagnetic spectrum. We can't see around walls, we can't see heat or cold, we can't see electricity or radio signals, we can't see at a distance. It is a sense so limited that we might as well not have it. Yet, we have evolved as a species to depend so heavily on it that all other perception has atrophied. We have wound up with the utterly mad, and often fatal delusion, that if we can't see something, it doesn't exist. Virtually all of civilizations' failures can be traced back to that one ominous sentence: I'll believe it when I see it. We can't even convince the public that global warming is dangerous. Why? Because carbon dioxide happens to be invisible. Hello everyone, my name is Abi Ramanan I am the CEO and co-founder of Impact Vision, and I'm not that young, really, but I am really delighted to be here and I'm gonna talk to you a little bit about hyperspectral imaging, which you've heard about before, um, from Raymond's talk, and also what the potential of this technology is in the food supply chain. But first, I'm just going to tell you a quick story. So, this animal is called the mantis shrimp, and the mantis shrimp has one of the most advanced vision systems of any creature in the world. If you think of human beings, so us, we have three color receptive cones, red, blue, and green, and we see the world through a combination of these three. The mantis shrimp has 16 color receptive cones, so it can see both ultraviolet and infrared light. That makes it, you would think, a really kind of joyous creature of the sea but it's actually a very violent predator. Another fun fact about the mantis shrimp is it can kill its prey by whipping its tail so fast it boils water! A rainbow for the mantis shrimp would come from 16 colors; which we can't even really imagine. Similarly, if you have a look at the yellow flower on the screen, this is how a human eye perceives it. But, a bee perceives the same flower in a completely different way, because it has ultraviolet vision, helping it to locate the nectar at the center of the flower. So just from these two quick examples, it's obvious that there's more information that exists in the world that would be really beneficial to be able to access. So what does all of this have to do with food? So we're at a food and agriculture conference, and one of the main issues of our generation, of our time, is food waste. A third of all the food produced in the world today is wasted. This costs around 1.2 trillion dollars annually and there's another problem. So, there is a growing area of crime called food fraud. Some of you might be fortunate enough to remember the horse meat scandal of several years ago that tore across the European Union. But it manifests in lots of other ways; contaminating melamine with milk powder, or, if you buy red snapper in the US, nine times out of ten you're actually getting tilapia. So, it's very difficult for the human eye to tell the difference between two white powders, or two fillets of fish that look the same. But, this type of crime cost the global economy an additional 40 billion dollars a year, and we really need rapid, real-time, and accurate techniques to assess both food quality, but also product authenticity. So, just a bit more information about food waste, it costs around 1.2 trillion dollars a year, and if food waste was a country, it would be the third largest emitter of greenhouse gases in the world. The problem is that for food companies, they've been mechanized, the food supply chain has been mechanized, but it hasn't been information enabled. I've been to hundreds of distribution centers and processing facilities, and often people stand by the side of the conveyor belt looking for contamination; plastics, or paper. Or, they're testing one in a thousand or, one in 2,000 samples using an invasive pH meter, or, a destructive firmness test. This is a spectacularly inefficient way to process the industrialized food system, and 50% of all the waste that occurs, happens upstream. We feel that hyperspectral imaging is a really interesting technique that has a potential to address a lot of that waste. So actually, New Zealand is a bit of hub, a bit of a hub, for hyperspectral imaging with the really big meat sector. So like was mentioned earlier, work has been done on this here, but it hasn't really proliferated into the food processing section of the supply chain. It's largely been an academic or used pre-harvest. Hyperspectral imaging combines two different techniques. Spectroscopy, which is the chemical technique of measuring reflectance from a single pixel with computer vision. And the computer vision component is important because if you're measuring light just from a single pixel it, take me for example, it could be a lean pixel, it could be a fat pixel, but it doesn't tell you something about the distribution across the sample. With hyperspectral imaging, by measuring reflectance across hundreds of pixels, you're able to get a much more accurate reading and it's much more suitable for in-line. So Impact Vision is a machine learning company. We're combining these two novel techniques, hyperspectral imaging and machine learning, to provide real-time, non-invasive, food quality information post-harvest to really empower food companies to be more effective and predictive in how they ripen, process, distribute, and sort food. Hyperspectral imaging actually isn't a new technology, it's been, it was developed for use in space by NASA. It then took a traditional route, went to defense, it's been used in oil and gas pipeline monitoring, and I'll talk about some of the other interesting emerging use cases later. But the reason why, why now is because the price, the form factor, have been decreasing steadily. So, we now have sensors suitable for industrial uses, and the power of computation allows us to do real-time transmission of these images; which can be up to 700 megabytes in size. So that's a small movie. This is our first product. So, we launched this with Mexico's largest sugar processor, and it's a product to detect contamination; specifically, tiny non-magnetic contaminants. We designed our own casing, and it meets FDA approval, and as you can see, for supply chain machinery, it's fairly compact, and it's designed to be a modular system that you can bolt on to existing sorting, rejection, infrastructure. So, I'll just talk you through an example here, you can see here avocados are being scanned on a conveyor belt, and I'll just explain why this is important. So, New Zealand has a big avocado sector. Dry matter or moisture -- the lack of -- is one of the most important parameters for understanding how avocados should be ripened. But today, you have to take an avocado, cut it open, you put in a laboratory oven for a couple of hours, you take it out, you wait again, and you perform an equation to understand the dry matter. As a result, you're testing a fraction of samples passing through the supply chain. This results in a few big problems, so checkerboarding, or rejection, say there's a change in seasonality between Peru and Mexico, or Mexico and Chile. You get a lot of inconsistency in dry matter, resulting in inconsistency in ripening, and high rejection rates. We can take an example, a food service company that we spoke to, they source around 50 million avocados a year, and around 30 percent is wasted. That's, a lot of that's due to inconsistency in ripening. So we're developing a tool that allows you to do that dry matter test, in-line, understanding that internal quality or chemical composition from images. So you're facilitating a shift from testing a fraction of samples to 100% product coverage. You can then sort avocados into buckets with much lower variance, ripen more consistently, and start driving that efficiency from a post- harvest perspective; all the way down to food service and retail. So like I mentioned, we're a post-harvest company. So, we sit in the section of the supply chain that's all about improving distribution, improving processing, determining end use of product, and really optimizing activity, and moving away from using those manual tests. The benefits for food companies fall into a few areas, so, understanding tenderness or shelf-life. So, determining, should this be sold as ground beef? Or should it be packaged as steak? Detecting contaminants, like I mentioned, optimizing yields for vegetables and produce. Another example is doing in-line Brix segmentation of berries. We're also working with a large meal kit delivery company. Today, to understand the shelf life of salad, a manual inspection is carried out. So, a QC person has a look at different batches and says, "oh, I think this has about three days shelf-life." There's obviously a lot of variation between people, and it's not really a model that scales. So, we're developing a tool that can predict four days shelf lives; accept. And then finally, the application that I actually think is revolutionary, well I think they're all great, but, there's so many challenges in the, in the fish industry. We're dramatically overfishing, this is leading to all kinds of issues, rise in sea food allergies, really putting the oceans under threat. And that's, part of that is due to illegal fishing, it's due to mislabeling and substitution, so being able to identify the species of fish, once it's been filleted, from an image could be really interesting. And there's a lot of hype these days about blockchain. So I'm sure everyone's come across blockchain at some point or another. The challenge of blockchain systems for the food supply chain is the inputs in many of these cases are still being entered manually. If you distribute, securely, information that is inherently not guaranteed to be trustworthy, that doesn't necessarily result in a really, kind of, significant improvement. But what could be valuable, is taking sensor based data, putting that on a blockchain, so you then get the really accurate quality data, and the end-to-end supply chain traceability and transparency, and this is a conversation I had with one of the people, Chid, who's leading on IBM's blockchain work. I think that presents one of the most integrated solutions for end-to-end traceability and is really exciting for the, for the future. So some other applications where hyperspectral imaging could be interesting... if I had a background in healthcare, I think I'd definitely have gone after, gone after that. So for example, you could take an image of the human retina and understand someone's predisposition to diabetes. Or you can take an image of the skin, and determine biochemical changes in the blood. Another really interesting use case, recently, hyperspectral imaging was used in some Mexican caves to determine ancient texts underneath a layer where they thought nothing was, kind of, underneath, and so it's also used a lot for manuscript detection and fraud. Forensics, crime scenes, imagine being able to take images of a crime scene and understand the underlying traces that could, that could be there without having to do swabs and destructive tests. But as you can see, once you open up this possibility of having as much vision as the bee, or the mantis shrimp, we really can think of so many areas where being able to see more of information that exists in the world, it's just that we have limited vision. So, you can kind of think about hyperspectral imaging as a technology that is empowering us to see beyond the borders of human vision. And then finally, onto the future. So, hyperspectral cameras used to be the size of a room and cost hundreds of thousands of dollars, and now we're working with one of the first sensors that's been designed for industrial use cases. So, for conveyor belts and sorting machines, and the price will continue to drop, and the size will continue to drop. So, there is a company that we're already working with that's developing a hyperspectral camera for the smartphone. They need to build out a supply chain for that but, within the next two to three years you'll be able to walk into a supermarket, take a photo of an avocado, and know how many days until it's ripe. Or, take a picture of the fish that you're being served, and know the species. We think this is really exciting. We think it has the potential to be almost as revolutionary as GPS was, for us, for navigation and location, and it also means we start to address the balance that we as consumers also have in being able to understand quality and authenticity. Thank you very much. 