 I'm going to talk about our project and panning and zooming panoramas in virtual reality devices we are devices have created girls growing interest in a new generation of user interaction and user experiences such immersive digital content experiences enable users to explore since by panning our odd it is amazing that we can virtually be there and give get to gaze as the third story Rita but can we plug in and get closer to the stars to observe them better in details in VR devices first it becomes more and more accessible to create high resolution panoramic imagery with the development of robotic image acquisition technology in fact there are thousands of such panoramas being shared online which makes anyone with a brother being able to zoom in and explore big events urban scape and or the nature intimately nature of the image array contains plentiful details which are worth exploring Vic demo this is a panorama taken from the London 2012 Olympics Opening Ceremony zooming in user can not only observe the teams from various countries in a parade user can even look at each single person as well high-resolution of panoramic imagery can also be surreal artistic are creating very large format panoramas combining high resolution imagery with AI base a deep dream to create a new artistic world but so me in this dreamlike appearance is been better visualized and can be better its board at viewer but how can we view them in VR as the current emerged the panorama viewers in VR devices only allow users to pan and decide which direction to look at our goal is to enable users to zoom in and determine what details they want to explore actually pan and zoom is a fundamental operation for image viewer applications on flat devices this involves the movement of mouse control especially when the mouse tracks from one building to another as actually scanning a very small small area in the huge panorama 2 million more clearly we show them in this hemispherical projections here when user drags a mouse on the broaden window the wheel moves from dark red to breakfast we can see that at higher zoom level it rolls has in a smaller scale the other world the higher the zoom level is the slower the panel speed become so we call it as normal this is very natural and in flat devices then resistive question why not just use slower modes in VR in VR devices the direction of display is controlled by users head rotation if we also consequence 8 panning to be slower in higher zoom level it may result in two problems physical challenges and a pro pro pro acceptor problem look at this example the user first looked at the Chrysler Building and then zoom in and observed that it helped details after article ornamentation that shipping down her face the first problem is when she still one who came down she physically connect to her head further nest vision zooms out know that she's still facing down as at her feet that she feels like looking forward because she's seen the heart hot horizon and when she faced up to look forward through the screen however she feels like she's up in the air because in which totally upset her sense of the stability in this environment this is the proprioception problem having experienced this problems with slower mode we identify the following criteria for our design interface first user should have the freedom to look all around the environment and zoom in the details in any direction second for the viewpoint the interface troops face video switch users real were self motion as mentioned before as discomforting to the horizon line the first design are straightforward well keeping this properties which we called to normal mode in this mode user controls the direction of vo really the height most head motion directly independent with the zoom level it allows user can all around at algin levels and doesn't move the horizon after operations of zooming in and out let's see how it works this is a panorama we took on the roof of Facebook office in fiallo so here the user first zoom in and want to look closer to the people along the South Lake Union and then even as he pans slowly to the right the scenes change to rapid to observe and mix the user experience nausea and fatigue and when the user is asked to search and look at the Space Needle he got lost and stand up quite a while to find it in a very in this very room in imagery their fourth navigation is one of the problem in this normal mode another problem in that as the zoom level becomes half higher the pursuit of video motion becomes faster which in this case is 8 times faster than the speed in traditional floor mode the mismatch between the slower slow head motion and fast display motion these two more users motion sickness third since the video screen changes very fast with the head motion user needs to move their head very carefully if they want to observe a specific spot so in normal mode it is hard to control seeing YouTube want to see based on those downside we then identified three more properties for a desire finance and view are in BR the display should match well with yours perceptual movement to reduce motion sickness additionally users should be able to control where they want you and expected to see and finally the interface should help user to navigate you see with this objective in mind we propose first to limit the field of view to the center of the screen being able to displace users perceptual motion and simulation sickness then to place to place a zoom insert central area in front of announcer in background that provides contacts in your perfect peripheral vision here we show an example of circle mug so wrap hip and still bring strong motion sickness when user has slowly limiting the fermion with visual field reduces the video motion and a background layer serves as a stable reference to a little elevate the motion sickness the next mode we modify the circle transparency based on the Panny velocity it will allow the background to be visible through in imagery during rapid head motion which reduces the motion sickness a lot we also add a cusp crosshair when the circle becomes transparent to improve targeting and navigating experiments we also proposal zoom circle mode which adapt is zoom level to users head motion it zooms out during during rapid motion and zooms back in as the bill comes rest on his subject we conduct a user study and after different participants to complete several texts in each task they were asked to find a specific object in the scene which is hard to notice real value min before starting the task we gave users a shot in short instruction for the modes we discussed before and in each task we randomly assign them one of the foremost and don't allow them to change and we require the time spent by participant to find this target here we showed his realm of completion time used in thermal mode consuming several participant had had no VR experience before and can suffer from different level of motion sickness we allow them to create a task whenever they feel discomfort here the for visualization purpose will show the time as a 180 seconds if they created tasks in normal mode there are 16 out of 89 subjects 22 people and the meaning of all the completion time is 1989 here five seconds here are the histogram for an Sycamore purely subjective gave up and there are stills but there are still six out of 93 and the median time is much lower than normal than that in a mode in both alpha mode and some chakra mode there's no give up and the median time is even slower in this figure before the median distance from users pen window to target along the time in each mode we can see that the distance of outer circle and zoom chakra mode drops significantly faster than other mode during the first 20 second which suggests that both of them helps the navigation here the solid line only includes subjects completing the task whereas the dash lines include to keep up data and me that has as well know that the green solid line in the normal mode start at the distance much slower than others Estridge that suggests that the user that starts far from the target are more inclined to give up we also collect the several positive data file questionnaire the score arranged our lecture scales from one meaning bad to five minutes when well as aspects we are concerned about is whether subjects experience motion sickness as this either fizzes from the histogram and the muse for showing here we know that narrowing the field appears like improved it to meet slightly improves the movement comfort while adapting transparency or zoom level which can speed significantly help us reduce motion sickness we also asked how easy it is to navigate to other area and target to object objects there and the score shows a similar Parton and alpha zoom circle and zooms are called mode still outperform the others finally we asked which one they prefer to use to explore new panoramas the result also looks similar based on both the qualitative and quantitative result we come to the conclusion that numeral mode is not suitable for panning companion zoom in imagery why is there commode is slightly better alpha and circle mode are assessed significantly better than the other two people like this mode in different scenarios for different reasons some people prefer alpha decay mode when they know where to explore nest but when user is now familiar with the panorama scene one if he presumes a commode to gradually find interesting object or area to explore in summary as VR devices become more popular it is interesting to rethink how we can solve the traditional tasks which are well studied on the flat platform panning and zooming high-resolution panoramas discussed in this paper is just one example and this leads out to some ideas for future work in this paper we haven't delved into stabilization technique or adjuster interactions in days and both of them could improve the user control and viewing experience for the more it is also an interesting problem to extend the pan and zoom interface was dural parama panoramas this comes to the end of the top and thanks I console of Remos Microsoft Research I wonder as virtual reality becomes more prevalent and you actually have synthetic scenes not just a panoramic imagery that zoom is not much assume is for us I'm actually getting closer to the area I want to see and then looking around is just looking around do you see the same techniques applying or just not necessary potentially for those things or you may be able to synthesize what a parallel may look like if you work closer actually so your question is why is it different intricity videos are in simulated being before I know why a panorama different than actually pretty cinco very complex and dense 3d scene but I'm wondering if you think the lessons you learn here carried forward or perhaps there's this interesting idea can you synthesize the panorama from the point of view of being closer to what you want to look at yeah and actually we also try like imagining this panorama at this 3 3ds of fear stuff Europe and we just like move the object like originally in center and move the movie closer to the Saffir to the edge of sphere and it will get distorted because like if you look forward is actually get closer to the panorama but if you look around it will like the closer it is a Gaussian is like stretch a large larger and like further it's really like compressed like surprise like lead or and you just like don't know what to do at that point so that's a problem we also try other possible ways to deal with this this panning and zooming and either is icon that no of then works great better than just like so commode so we'd stuck with this line thank you I am terribly from Christ and Korea a very interesting talk and very practical on to I'm this might be a little silly question is there a reason why it has to be a circle and not a square or any other polygonal shape next question yeah during this study we also tried like first to answer your question why like circle is more like intuitive because we imagine like this problem as like you put a telescope like looking on the top on the top of a building it's like very similar to that case so it's more intuitive to users and we also try other like of trance like a transition between the edge like like more transition that is almost the same performance thank you I have Tim dois Monash University I was wondering if you tried to stabilize the image at all when you're in zooms thank you so actually I haven't mentioned in the in the talk that we already like before trying like Stockholm mode we're already like like a dummy than being like effect to help the slips of stabilization but yeah it still doesn't like good enough yeah so I think so this is already stabilized it is already stabilized yeah and is talked like in details in the paper did you decide the size of the circle and fighters like like each yes thank you for the question we are also we try like a pile of study like - ranging like this the sides of circle and it's like a balance between the field of view and motion sickness like effect so without 