 I love it when a plan comes together first Yuval and zade and John Ramallah who's not with us today for making this possible Flextronics of course for making their their space available to us and innovating on the original open 19 designs that LinkedIn did come up with it's great to be here we're gonna talk about specifically the edge I love the fact that we talked about predicts we talked a little about HPE they just showed you a little bit about the edge use cases for LinkedIn and that's all we're going to talk about is edge because that's effectively where vapor IO exists and what we aim to accomplish but just a parrot Kara earlier how many of you didn't just by raising your hands how many of you heard the phrase economies of scale everybody right what about economies of innovation not as many people Kara had said this collective genius and others have said we're in this knowledge economy and it's absolutely absolutely correct um but by being here today you're part of that engine that is driving that transformative change you guys are part of the economies of innovation that is happening right now with open 19 so I guess you should really give yourselves a round of applause please just really quickly for being part of that change it's a big deal it's a very big deal so we're talking about the speed of light I don't know if anybody knows who John Carmack is but he was the creator of doom and Wolfenstein and quake and a bunch of other video games for ID and he was literally writing this as as these video games were sort of the first video games to be latency driven in in these games the idea is to have a low latency connections so you can frag if you're gamers you'll understand that but John fit was famously quoted as saving saying the speed of light sucks and it absolutely does and and and and that's because we are moving from business critical applications to life critical applications think about that today on the planet there's somewhere around fifteen sixteen zettabytes of data by 2020 there's going to be at least forty to fifty zettabytes of data an IBC just recently predicted that by 2025 there'd be a hundred and sixty-three zettabytes of data on this planet and we will be creating over a hundred and sixty-three zettabytes of data every single year so while we are moving from core to edge we need to be thinking about data centers as into your architecture and where does that where does that ingest start where does the decentralize machine learning start where does the low latency artificial intelligence start these are the things that vapor is trying to solve from an infrastructure standpoint so I'm not picking on anybody here I'm just talking about geography the cloud and the Internet as we know it was built out exactly the same way as Airlines and the way they traveled their routes from from the beginning of the airline industry to you pretty much today I travel the Pittsburgh quite a bit and I can't get there directly and in the airline industry this is called hub-and-spoke and the internet was built exactly like the airline industry you've got Mae East you've got my West you've got carrier hotels you've got interconnects and you traverse this information superhighway with fiber optics in the ground and you've got Tier one data center markets you've got here two datacenter markets but when you're moving from business critical to life critical infrastructure where a medical sensor needs to make a low latency decision about how to save a life or an autonomy vehicle is driving around and it needs to detect not via the car but via the via the infrastructure via the the I to V the infrastructure to vehicle technology it needs to make a decision around a hundred and seventy degree turn where there's where there's a dog and a human running across the street how does an autonomous vehicle make a decision about how to do that low latency artificial intelligence decision so the the world today has been architected with hub-and-spoke and and you know as an example there is exactly for data centers for physical big million square feet plus data centers for AWS today and of course lots of static content can be delivered to you through cloud front through lots of various CDN technologies but what about all of this dynamic content that gets created and needs to be analyzed this is a picture courtesy of of Carl kasell and I'm not sure if you guys know who crown castle is they're not normally shown in context of data centers but this is a map of crown castles infrastructure and and and they own forty thousand towers in the United States shared infrastructure towers where your your cell phone signal comes from imagine what a data center would look like if we could put data centers embedded close to the user last mile right as close to the edge as it can be literally cross connected from the radio access network which is how we get our cell phone signals and then cross connected into the cloud this is a map of of where we are right now in in Milpitas now check that out this is how you solve for a hundred and sixty-three zettabytes of data on the planet by 2025 you put meaningful density meaningful density 150 kilowatts potentially out at the edge tower by tower as close to the user and as close to where that data is being generated as you can this allows you to do a couple of things at the edge number one all of the data that's being created we're friends with an observatory that does this massive array of telescopes and when the array is open its collecting seven petabytes of data a second of the universe how do they get that in to do data processing how do you do any sort of machine learning and today this particular Observatory ships hard drives around and I kid you not I read an article just last week about exactly a service offered by a very large cloud service provider that literally ships your hard drives around and we think there's got to be a better way the one thing that cloud has has shown us and the one thing that just the evolution of of IT and the the maturity that we're going through in terms of how we manage that IT I shown us is that humans don't scale well with automation we just don't we just don't scale well with the type of complexity and the type of growth that we're seeing in cloud computing today so let's take a look at it typical what we call backhaul and you can just think a backhaul is data transport because that's what it is so today we're driven by the Internet of Things and the industrial Internet of Things and we've got our cloud providers and everybody's trading in their capex for op X and we're putting more stuff in these big centralized cloud locations when we're menteng these big CSP data with regional data centers of course you've got you know your big regional data center carriers that are able to accommodate those but in every case off of the devices which are largely connected to an LTE network in the future of 5g network potentially in the future unlicensed spectrum like 60 gigahertz or CBR s 3.5 gigahertz on licensed spectrum we've got this latency dilemma that we have to solve for so off of the telephone which I don't have in my pocket but I keep wanting to you you have a round trip latency back through the tower the exchange a central office a carrier hotel cross connected IP termination exists it goes out to get its resource and then it travels that same path all the way back and companies have solved some of this by creating things like env GRE tunnels or doing l2tp v3 or doing MPLS circuits and you can cut a lot of that out by doing some of that but in general this is sort of the path we take to get to the cloud and then you've had a regional data centers and you've got your 50 50 average 50 millisecond round trip or one trip decision-making capabilities which is pretty good for a lot of things you can actually cut out a lot of latency I mean you cut it by about 50 percent in a regional datacenter but what about low latency augmented reality where you need a sub 10 millisecond connection before your inner ear gets you nauseous when you look around and you see the you see the screen trace you follow you shadow you as you're looking around or that low latency autonomous driving capability an average car going 60 miles an hour covers a third of a football field every single second an airplane goes even faster and in the world of 2020 where we've got magical drones delivering all sorts of things to us how do we solve for the airliner that has deviated off of a flight path when it's coming in for a landing in Chicago O'Hare and there's a drone that's in the way how does that drone make a very low latency decision about getting out of the way of this airliner we think the world needs sub 10 millisecond round-trip decisions for tons of new capabilities tons of new use cases user termination life sciences autonomous driving a RV our industrial IOT these are the use cases that we think about so it's funny this morning somebody said oh I like that you use unrest Thompson he's crazy town we're kind of crazy I guess we've taken a very contrarian view to the edge and as we went down this rabbit hole we discovered some really interesting challenges really interesting challenges about what happens at the far edge of the network at the far edge of the network how do you solve for not four data centers but forty thousand data centers all decentralized challenge number one a standardized truck roll so public enemy number one for any enterprise thinking about procuring anything is vendor lock-in how does vapor how do our customers how do we as a customer how do we think about how to allow vendors to differentiate where differentiation matters but standardize on interface and interface connections that that matter to us but may not be a differentiator for that Oh am or that odm how do we allow innovation to continue how do we allow it to prosper and how do we go to market with people that still allow us to deliver a standardized truck roll we're at 40,000 different locations I can guarantee my customer that no matter if it's flex or groupware or Dell or HP II or any other vendor how can I ensure that I can manage that box I can sense that box I can understand the performance of that box and we can offer the SLA s and we can offer the operational of agreements that customers expect solving for this standardized truck roll is ism was a paramount requirement for us to be able to succeed differentiation for differentiations sake as a terrible thing and it's even harder to support in production so that was that was challenge number one challenge number two is this lights-out operation when you're forty miles from the nearest person who would have to get in their car and drive to an edge location to service a a box or worse yet a power shelf or some part of the M&E plant the mechanical engineering plant for the data center fails how do you understand that as a as a knock person as somebody who is delivering an SLA to their customer how do you solve for that sort of telemetry we vapor has developed an open-source completely open source GPL license same as the Linux operating system I'm sure everybody in this room probably uses inside of their data centers we have built this open source solution called open data center run time and environment to which we are contributing to open 19 so this will be one of the one of the contributions that were making to open 19 we've got lots of neat innovations that we're working on that we will be contributing but but this is a big deal because even ourselves while this could be something we could take to market and we could differentiate on we could say these api's they're ours the real estate is what matters here and we're gonna win by locking you into a service that we control that didn't feel right to us we wanted we wanted people that managed their infrastructure at the edge the far edge no different than they can manage their infrastructure and their core data center and that and that that resonated with a few folks and very early on in vapor IOT's existence we decided open source all of open D CRE which you'll see as a contribution and then the last thing and I think this is probably the most paramount today in these pristine data centers we're we're building five nines of redundancy how many people have you heard this I need five nines that's a huge thing in datacenter land and you know we did this in computers once we call the mainframes we built lots of fault tolerance vertically into something and we ensured that your your your your you know 40 volt 3-phase had substation one power in your a channel and substation two powered your B Channel and you had lots of UPS systems and you had lots of I mean this was the way we built data for decades but what we're finding and and and in this world our applications expect five nines in fact our applications expect 100% our applications aren't aware of a fan wall failing our applications aren't aware of an HVAC system or a building management system going out our applications are designed to be as dumb as they can there is the rack and that is no-man's land for the data center you've got a critical environment guys below you working on facilities stuff and you've got the IT folks that are racking and stacking and the application developers that sit on top of the rack and that pour rack is sitting there just waiting to tell somebody to go fix something that may be dependent on the building in the critical environments or it may be dependent on some other component in the rack itself the bad memory module about hard drive a bad sensor or something so what if our applications were autonomous what if our applications could literally sense and understand the physical world that they lived in so now out at the edge where you are 40 miles away from the nearest person the application can fix itself and this allows us to scale the edge as we go out and deploy 40,000 locations of data centers which by the way is six gigawatts of data center capacity so because open 19 uses a standard AIA rack we were able to retrofit very very quickly what you're looking at here is the vapor chamber and all this is is an optimized rack infrastructure for density and footprint rack density and footprint optimization via lots of physics related technologies Bernoulli principle venturi effect oh maybe just really quickly by show of hands who here knows where the 19-inch rack came from like where it originated so a lot of people don't actually know this it came out of the 18th century old railroad switching era that's right our data centers are powered by RAC infrastructure that came out of the railroad industry adopted by telco adopted by music industry and then adopted by IT compact was the first company to own a patent around the rack for the data center so here we are taking a cold air particle and moving that cold air particle horizontally and as you know there's a direct relationship between energy and heat so as we add more density in the rack we have to create more air volume in the hot aisle we create more space in the hot oil and we have diminishing returns on how dense we can actually get and we have to recertify hot and cold aisles the actually comes in or the NFPA comes in and they do their certifications the chamber was optimized specifically to help with the air flow and because it's 19-inch it's the only rack solution we know of this may be a false statement I hope it isn't but as far as we know it's the only rack solution on the planet that supports a EIA OCP v1 v2 and and now open 19 because of the EIA capability it's it's huge for us to be able to to support again the the type of the type of gear that goes into these edge data centers this is uh this is the way that we wanted to solve for that that edge truck roll on the sensing side we've been working very closely with future facilities and understanding how the how the chamber is operating at the edge is is absolutely paramount to our ability to deliver these edge services and again open 19 the ability to take one vendor's box and other vendors box plug them into the exact same rack over the exact same backplane standardized Network standardized power standardized interface or how you manage that from the out-of-band capability we're adapting our software that we're adapting open D CRE and we're again contributing that to the foundation and I'd just like to show you guys what this sorta looks like out at the edge future facilities work really hard with us but imagine there's a flex has a booth back there with an HTC vive imagine being able to put on a pair of VR goggles and walk around one of 40,000 data centers where you've got open D CRE data running live on you hear this check for the blinking lights where you've where you can literally put on a VR headset and you could walk around one of 40,000 locations virtually and see everything there is to see about your data center with that I want to invite anybody who's actually thinking about low latency applications decentralized machine learning low latency artificial intelligence industrial IOT that come talk to us and help us build out the edge thank you very much [Applause] 