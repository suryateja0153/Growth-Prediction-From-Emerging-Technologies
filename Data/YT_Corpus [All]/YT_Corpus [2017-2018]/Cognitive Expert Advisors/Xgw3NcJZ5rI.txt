 All right, well, since most of you were here before, I'll be quick. I'm Tony, I work at Microsoft, part of the SQL Server engineering team. I've been there nine years. I've been working on SQL. I was there as one of the 28 people who started Azure SQL DB. I guess it was Azure SQL DB's grandfather or something. Cuz we used to call it a cloud DB back then. It's gone through several name changes. It's been eight, nine years now. So I'm not gonna cover a lot of database stuff. I'm gonna cover a lot of the service stuff with SQL DB. When it comes to this service, you give up some control when you use cloud services. You don't have control over what kind of hardware exactly we have. You don't have too much control about exact versions of OS or what version of SQL we're running, because we take care all of that stuff. So we take care of all of the management stuff. So in exchange, what customers are saying is fine, you manage the stuff. I don't care. But I expect it be fast, I expect it to be reliable. I expect you to obey your SLAs. I want it to be secure, I want it to be cheap, and I want it to be fast. Because the whole point of cloud is, I want efficiency, I want agility. So in exchange for giving up control over what version of the SAN firmware we're running, you know you have SANs, by the way. You expect the service to do the work for you. So we've been on this journey for some time, trying to get the service to a point where you can just use the databases, and not really worry too much about management. And that's what we really mean. Again, cloud database service for Azure SQL DB, we spend most of our time getting the cloud part and the service part. And then the database engine features just come as part of overall SQL Server investments that we're making. I'll do a quick tour of the portal, just for the fun of it, if people haven't seen it. So this is the Azure portal. You'll see a lot of SQL stuff, you'll see SQL databases. You'll see SQL Data Warehouse, there are SQL Server instances. There's MySQL, there's PostgreSQL. If you search in the Gallery for databases, you'll find Oracle, DB2, you'll find HANA. And the entire concept here about Azure is, we actually are running a Cloud service. And as a cloud service, if you wanna be successful, you have to have variety. Because most people who move to the cloud from their enterprises, they're probably not running just one thing. They're running a variety of software from a variety of vendors. And so the goal in Azure is to provide the choice and the variety necessary for an enterprise to be successful. Of course, databases are a key part of that. And so we offer Azure SQL database and Azure SQL VMs. And there's a couple of questions about, well, when do you use SQL DB and when do you use SQL Server in a VM? And people always want a formulaic, technical decision tree. And it's not that simple. Because human preferences and the desire to control things comes into play when choosing what path you're gonna take. We have some customers who want to control the exact versions of everything. They want to be able to go and change the Windows registry settings. So clearly you need to have control over the VM. We have customers who run thousands of SQL Servers on-prem, and they have a few things in the cloud. And they wanna be able to manage the SQL Server in Azure the same way they manage SQL Server on-prem. Which means they want to domain join, they wanna have the same set of security processes. And for that, you really have to have more control over the environment. For that, you have to have control over the VMs and the instances, so you can do what you need. So for those customers who want to have that level of control, obviously running SQL Server in VMs is the option, because they have more control over the environment. And then we have some customers who have a lot of databases, like software vendors that have now switched to become SaaS vendors, software as a service. And there's lots of examples. Like Office 365, I don't know if you use Office, Office uses SQL DB. They have hundreds of thousands of databases. We have customers who provide financial accounting software. And they have a database for every customer they have. They have 150,000 customers, they have 150,000 databases, plus some test and this, that, and the other. Before you know it, they have 200,000 databases in the service. They're not interested in being in control of anything other than their app. They just want the database. And they don't wanna, because with control comes responsibility and work. So they're like, I don't wanna do that, you do it. And those are the customers that always go to SQL DB. So these all play a role. And there is some technical reasons, like if you have an application that runs and it needs access to file system. Or you run XP command shell and you need to break into the OS, and stuff like that. Which the app is so integrated with the environment, you need access to the OS. Then, Azure SQL VM is the choice. So those are some of the decision factors that you have to make. And the biggest difference is really, is in the operational aspect. Like operating a SQL Server on-prem versus operating a SQL Server running in a VM, which you own the VM. Versus, I have a database and I use it with Word Press, and I have no idea what the database is doing, nor should I care about what the database is doing. I just use Word Press, and there's a database there somewhere. I don't care. So the spectrum is pretty wide. So when you go here and you want to create a SQL database, you pick your servers and so on, and you go from there. Now, I have a lot of junk here, so I won't bore you with all of them. But let's see, I have a test database here. It's a P1 database, and in this case, it's just a database, right. There's a server, it has a name. Because in SQL Server, you have to connect to something, and the something is a server. This is not a real server, it doesn't have a physical manifestation. It's a logical concept, which is just a DNS name. It is used for grouping of databases. If you go create one of these servers in Central US, and then create a bunch of databases underneath, let's say okay, these databases all need to be in central US because they're associated with the server. And the server has a little fake master, and you can create users and stuff, right. But it's all managed by us, and you don't really have an instance in play. If you have thousands of databases, clearly they don't all fit on one machine. But you can have lots of databases under a server. So in this particular case, this database happens to be a premium database, P1. A lot of times, people say how do you size things? Well, again, sizing things is not easy, it's never been easy. On-prem, people say I've got an 8-core machine I use for my database. The first question is, what is the vintage of those course? Did you just buy them yesterday, or they're five years old? Because Intel has made a lot of progress in the last five years. So 8-cores from five years ago or three years ago, have nothing to do with 8-cores from today, right. And then there's the IO, and memory, and so on. But you get used to what you have on-prem. And you have the relative performance in your head. And you know that it's a three-year-old machine. And if you were to replace it, you probably wouldn't need 8 cores. But there's not much you can do, because you can't buy 2-core machines anymore. Because all Intel machines come with lots of cores. So what we have in the cloud, we came up with this concept of the DTU, which is the Database Throughput Unit. It's a bounding box of resources which a database needs to do stuff. What do databases do? Databases read, databases write to the transaction log. Databases use memory to do joins and sorts. And databases burn CPU as they do queries and so on. So 125 DTU defines the amount of CPU, IO, transaction log, and memory, and it's fixed. And it's independent of the physical hardware because we do the relative mapping. As we buy newer machines or older machines, 125 DTU has the same throughput as times go on, right? So just the prices go down over time, as opposed to you used to run on a 12-core and now you run 6-core. And five years from now, you'll run on half a core, right? So you run 100 DTU, you'll run on 100 DTU. If your workload doubles, you'll need 200 DTU. Establishing the first benchmark in the cloud to figure out I have a workload, how many DTUs do I need? Once you have that figured out, you run some tests. Then you have that reference point. And then from there on, it gets easy because the reference point is fixed. Right? Initially when we were, I don't know, moving office to SQL DB, they're like, I need to know all the details. And two, three years later, all they talk about is that I need more DTUs, or I need 10,000 DTUs, or 5,000 DTUs. So you'd have to do some experimentation. The nice thing about the cloud is you go create a database, we charge you by the minute and the hour and all that, right? So it's not like you're going to go and spend $15,000 purchasing something just to find out that it's not big enough or it's too big. You create a database. You run your workload. If it's all good, you're happy, fine. If it's not, you can upgrade it. You can downgrade it. The upgrades and the downgrades all happen online. So this is what the concept of the DTU is. And you can go change the DTU. You Google the pricing tier and I can click P2, P3, P4. I can go down to the standard editions. So in this case this database is being replicated so, and it has readable secondaries so I can't go to Basic. Let's take a quick look at that. So, in this case I wanted this database to be replicated because even though in Azure SQL DB we do backups and everything. And we guarantee the DHA and all of that. You might still want to have a copy of your database outside of your region. So in this case this database is in East US and it has a replica in Central US and you can go change it, you can add replicas, and you can say hey, I wanna add another replica. I wanna have a replica in West US. And then it'll ask you if you have a server or not. You click and off it goes. You can drop the replicas. You can create replicas. We try to make things very simple through the portal. But the important thing to remember is a lot of people who build apps that run in the cloud, especially if you have lots of databases, people don't like to go to the portal and click and clack and, or if you have 700 databases or 10,000 databases. So everything that you do in the portal is also available to REST APIs and PowerShell and all of the CLIs. And the idea here is, you go to the portal, you do it once, figure out what it is and figure out how do it, and then you go write code to automate things. And so, that's kind of just a quick tour of SQL DB. When you go look at the database, it's got a lot of properties here that you can go, and we'll go visit some of these as we go through the presentation. So, this is what we're focusing on. Can we make it faster? Can we make it cheaper? Can we make it more secure? So, how do you make things cheaper? Well, if you worked in databases, you know you can optimize things, and you can make things run faster. You can make things use less memory. You can make things use less I/O. But generally, people don't bother with some of these things on-prem. Cuz if you have a machine, let's say you have your eight core machine and it's got 200 gig of memory and everything works fine, and you're running with 10% CPU utilization, there's really no incentive in going and optimizing your workload to go down to 5% CPU utilization because you already paid for the box and it's sitting there. And the time spending trying to figure out how to optimize may not give you the return on investment that you're looking for. However, in the cloud if you can take a database which happens to be a P2 and optimize it a little bit so that it fits in a P1, you could cut your costs in half. And that's something you pay every month. So it might be beneficial to do optimization. And whenever you go on these you pay as you go, the tendency to wanna optimize and save money is usually higher than you bought the cow, you own it. There's not much you can do with it, right? So for us, the goal is to make it really easy for you to do these things. And we have a lot of expertise in making SQL run well because we actually have access to the source code for SQL, not because we're really smart. It's just we have the data, and we have the source code, and we can see things normal people can't, right, outside of Microsoft. So we're going down the path of building these expert systems and these advisers to help you manage your environment. So we started with the security stuff, and then we went to the performance stuff, and then the cost optimization stuff. So in maximizing performance, we came up with this notion of getting new performance recommendations. You pay for a database which is bigger than what you need. Maybe you shouldn't. Or you have bunch of databases. If you group them in a pool, you could cut your cost in half. And so, we provide these recommendations so that you can make better decisions. Now, if you were to go do this yourself, you have to go collect all of the telemetry, process the telemetry, do all the necessary work to arrive to the conclusion that your database has more resources than you need. So we're trying to eliminate that and just give you the recommendation. The auto tuning stuff is that what we've found is that you go and optimize your database, create all the indices and whatever, and then a year goes by, the nature of the data changes, the schema changes, things tend to fall out of tune. So something which is highly optimized is not likely to remain highly optimized for a long period of time, if there are changes that are going on. So, the concept of auto tuning is that we provide you the auto tuning recommendation, and then you can agree that yeah, go ahead and do it for me. And then we just make the changes for you and try to keep the database optimized as possible. Again, on the cost is mostly around resource, efficient use of resources. And efficient use of resources matters in the cloud. And then, security, pretty much when we started with the cloud everybody said, when used to go to events like this, like SQL PASS or whatever, and talk about databases in the cloud, the first year I did it, people literally threw things at me. They said that you're an idiot, nobody would ever put databases in the cloud, security, and so on. And so, security has been a real challenge for lots of people. So we had to do a lot of work to, first of all, improve the security in general, but also the perception of security. It turns out everybody gets hacked anyway. If you're an insurance company, bank, or a government, you've been hacked. So it's gotten to a point where people are saying, maybe I should leave security in the hands of people who actually know the code more than I do, right? So more and more, we find people more willing to move to the cloud because they feel that we can do a good job, or just as good of a job in some cases. Again, in some cases, there's still a lot of compliance and governance rules that would prevent workloads from moving to the cloud. There are lots of reasons. So we don't anticipate that the planet is gonna move to cloud. In fact, we think that the world is gonna be very mixed. People will run stuff in the cloud. People will run stuff on-prem. And this mix will continue for a very long time. And our job is to make sure that it's as easy to have a hybrid system than it is to have an on-prem system, than it is to have pure cloud systems. So this is where the investments are going. We have teams that are responsible for these things. We have a security team. That's all they do is spend their time figuring out how to manage threat, security threats to a database and how to mitigate. So let's start with the maximizing app performance. And if you've worked with databases you've probably been in this situation. All of a sudden things run slow and then you have to go figure out why. And there's many, many reasons. So customer satisfaction, stuff runs slow, it's the first reason people hate you. It's like performance problems, apps not doing well is an issue. And it's an ongoing process. Again, you can't optimize once and be done with it. But it also requires expertise. Databases are not simple, not always. So knowing more about it helps you optimize better. And so we think hey, you know we could do a good job. The other thing which we found out is, the developers who write the app tend to know things about the app and how it behaves in ways that the DBAs don't. So if you're a DBA, you're trying to reverse engineer what this application is doing. If you're a dev you tend to know what you did. And so, generating recommendation which is useful for developers as well as DBAs is very beneficial in getting the job done. So we have the advisors, so, we tend to do everything for a database, right? We monitor every database, we collect the telemetry for every database, we resource govern every database. So we don't do things in collections. If you have hundred databases we look at the performance of every database. We look at the telemetry from every database and we resource govern every database, which is a little different than on-prem. Because if you have a server and it might have a bunch of databases and a bunch of apps, sometime it's really difficult to figure out what's doing what in the server. And so for us right from the beginning we said everything will be at the database level so we can figure things out. And then you find out that you can have the same set of apps with different databases and different behavior because of the nature of the data is different. So the work we do is based on the actual information that comes from that database. And we collect the telemetry. And the telemetry that we collect is basically all of the information that you can get from SQL Server in the DMVs. And SQL Server has lots of DMVs and X events and we collect all of that. And then we have a set of machine learning processes that go and analyze this stuff. So the automatic performance tuning. We try to be very, if you do anything for you, we will log it. We will have the history, and it'll be completely transparent. So it's not a mysterious thing, right? And you have the option to override, take recommendation or not, right? So let's go and actually take a quick look at what this stuff looks like. So I have this database. It's got some stuff running against it. Right at the top there was a database advisor. And this particular database advisor has been looking at the workload running on this database. And in this case has figured there a few things that you could do. So there is an index and SQL thinks that if you create this index the impact would be high, that it would be worth your time to create this index. Because probably it noticed that there are queries that are running and doing full table scans. Or queries that are not having the best plan and creation of the index would actually improve that. We also do the reverse which we think if you have lot of people who can get index happy and they create lots of indices because they're trying to cover all the bases. And then it becomes very inefficient, because in updates, you have to update all these unused indices. So we may recommend that you should drop an index. And then there are things like parameterizing queries. So SQL can do better optimization. And this is the kind of stuff that you get, you can take in advice, or not. It's up to you, you don't have to. And then, This is the history of the advices and whether they were successful or not. If you recommend that you should build an index and you say, okay go ahead, you do it for me. Auto indexing, great. We will create the index and then we'll benchmark it and see if it runs better. If it's not, then we would undo it. So we only keep things that actually made a difference, right? So we do that for you. You can get the scripts for all of these things, if you want to do, or not, and give us feedback on them. And all of these is optional, and you can configure your databases for these. So, under the performance tuning, you can turn it on, turn it off, Through the configuration for the database. You can set these things up so they inherit the settings from their logical server, or you can say don't inherit. Each database is gonna have a different set of rules for it. In general, people configure the server and the rules are inherited by the databases that are created on that server, but you don't have to do it. So, in this case you can automate index create and you can automate index drops, and you can have different rules for different settings, so, This is the performance recommendations. And we're getting better at this as time goes by. And a lot of times when we come up with lots of recommendations, at some point we say, you know what? Maybe SQL Server should be improved so people don't have to go through this work. And because the performance team that's working on auto tuning and auto indexing and all of that, they're also responsible for the optimizer and the language services. So sometime when we see set of recommendations surfacing a lot, we'll actually go and improve the SQL engine. And it's good for the service and it's good for the on-prem product, when we come up with it. If you haven't played with this stuff, you should definitely go give it a try. Most of the new things that we do, they come through the previews. So we'll announce that we are gonna have a preview, and you can join a preview, and you can have a direct dialogue with the engineers. You can exchange emails saying this is good, this is bad, you screwed up my database. And they work with you, right? Then we go through the process of there's a private preview for more brave customers, who are willing to do things. And then, there's a public preview, and then there's a GA. And sometimes, these things will be in preview for three, four, five months if it's a complex area and we need a lot of feedback. But again, everything is an opt in, never forced on you. So, That's about getting the best out of your apps. We have customers, so there's a company in Germany and they do document management. And they've been with us for a very long time. And they use the autotuning features because they really have a lot of databases. Again, this is one of those models that they provide a software service and so, they create databases that they get for every customer. And as they get more customers, they create more databases. So, at some point it becomes time prohibitive to manage everything yourself and monitor everything yourself. If you have one database, You could probably easily manage. If you have five databases, mm-hm, you could still do it. You'll do some automation. But as the number of databases grows and starts to see hundreds and thousands and tens of thousands, no amount of automation really gets the job done. So this is, again, areas where SQL DB does better. At some point, we had a lot of customers who said, look, I have an app that I've built on Azure and now your Azure SQL databases. And I create a database for every customer. So one of the most interesting one was a company that provides accounting software for small businesses. And it's interesting thing about small businesses is let's say you have a sandwich shop or a repair shop or I don't know, you're a contractor. You don't wake up in the morning and do accounting from 9 to 5. You do your accounting maybe once a day, maybe a couple of times a week, maybe three times a month. So these databases that were created for every customer are mostly just sitting there idle, doing nothing. But when the customer comes in wants to do their weekly or monthly accounting, they don't wanna wait. Like they don't wanna sit there and wait for stuff, they want really fast. So, the problem was this, our customer, the accounting firm, they have tens of thousands of databases, so their profit margins have to be by database. If I'm charging you $50 for accounting service, I can't pay Microsoft $60 for a database, right? So they want to pay us very little money for every database, but then they wanted the database to be super fast, right? When they need it, but they only need it 30 minutes a week. So we came up with this concept of pools, where you can take these Databases that have very stochastic usage patterns and they're seldom used. But when they're used, they need a lot of performance. And the concept of the pool is you can buy a pool of resources, which is enough for the aggregate. So let's say 5% of your user population is active at any one time. And this 5% of the active population wants to have really good performance. What does it take for 5% of your databases to get, I don't know, 200 DTU's each. Well let's say, it's 1000 times 200 is 200,000 DTU's will do it, right? So we came up with this concept of pools, where you can pool the resources. And you put databases in pools and they can share the resources. When databases are not busy, their neighbors use the resources. But we didn't want this pool to be a wild west sort of a place, where some very active users are always using and other people get short changed. So we also put a minimum and a maximum guarantee of resources per database. So you can say at minimum, every database should get five DTU's at all times. So there's a floor which gets established for the aggregate. And then you can say at any given time, I don't want anybody go above whatever DTUs, 125 DTUs or 200 DTUs. And then we resource govern every database individually, and the entire pool collectively. And this allows customers to decide how much they're gonna pay us for a database. Because the aggregate DTU divided by number of databases is the cost of the database. You decide what user experience you want your users to have. If you think that person is giving you $50 a month shouldn't get more than 100 DTU when they're using it because that's the value, then that's the settings that you set. And then this also allows you to have different pools. Maybe you have some customers that are paying you $150 a month, because maybe they're bigger. And then you should put them in the gold pool, as opposed to the silver pool and the bronze pool. And customers can move around. You can also have a premium pool. A pool of really cheap for I don't know, trials and whatever. But because you can move databases from pool to pool without actually taking them down, or have outages, you can move stuff around on demand. This is the concept of pools. So, we built all of these automation around collecting all of the performance statistics about databases and such to help customers manage their pools. Because now your managing things in aggregate. You can manage the peaks and valleys. You can set the price per database, you can decide which customers get what. You can always tell which one of your customers are the bully customers. You go into the pool and you say, show me the top ten databases by consumption. And the said, these five databases are always using more than everybody else. Maybe it's time to get them to pay more. Maybe it's time to offer them the premiums service. And you have customers who rarely do anything, maybe you could offer them a discount, move them to the bronze pool. We provide the telemetry and all the performance and consumption information you need to make these decisions. The picture of the pools is that we have basic pool, standard pull and premium pools. The difference between the basic, standard, and premium is how far you can spike. If you have that free offer, and you don't want people to really be able to hammer the system, you can put them in a basic pool. They can only go so far. And you can have your gold customers, and your premium pools, where they can go as far as they want, and have the greatest experience. And you can move the stuff around at different times. As you can imagine In the accounting world, there is a time of the year where you have to pay taxes, no matter what part of the planet you lived in. It sometimes is different times of the year, in different places. So if you're a multinational, you have to manage different tax times in different countries. What you do is you bump up the size of your pool when tax time comes up cuz that's when things are really active. We have to generate the reports and so on and so forth. And then you can dial it down. We have customers that change the size of the pool and how much resources are available different times of day, different times of week, different times of month. We have customers who run sales in January and everything gets maxed out. So they manage things differently. And this allows you to basically manage your cost at real-time, as opposed to buy hardware for peak use because if you're doing on-prem stuff and you have to buy hardware you buy it for the peak. The other interesting thing we've learned over time is, the peak for most of these workloads has nothing to do with what the users are doing, but what the DBAs are doing and what the app developers are doing. I'm gonna do backups, so I need to size the machine so I can finish the backups in six hours. So you buy a giant machine, so you can do backups in six hours. And during the week, the machine are sitting there, mostly idle. Or people wanna size the thing, so when you rebuild indexes at the end of the week and you go launch a rebuild for 10,000 databases and things go crazy right. You can change the sizes, you can smooth things out, you can do your administrative tasks over a period of time so, that you can manage the cost better and never have to really plan for the peaks. This is the concept of the pool. Now, we have lots of customers who don't use pools but they have lots of databases. Cuz they, I don't know, they've been using the service for a long time. We have customers that you might have, I don't know, 15, 20 80, 90, 100 databases. You might still benefit from a pool. Even if you're not a service provider and your databases aren't being used every once in a while, you still have different databases that are used at different times, with different level of resource consumption. One of the things we do is, we're continuously monitoring all of the databases that you have and we generate recommendations for maybe it would be useful to you to move this set up independent databases. We call them singletons, to a pool of this size. And we recommend this size of the pool that would allow each database to spike to their usual levels but also share resources with their neighbors so that you minimize your cost. So when we first built the pools, we gave it to a set of customers that were really expert in this cost optimization. But then most customers are like I don't know what size pool I should use. Well, it turns out we do because we can see the aggregate usage at any given time of day because we collect statistics at a really low granularity. We can tell at any given time you never ever collectively go beyond a 1,000 DTU. So there's really no reason for the collection of your databases to ever have more than 1000 DTU. And we can tell that no single database ever goes above 50. So if you set the max to 50 and have 1000 DTUs and throw all of your database in a pool, the chances are your performance will be exactly what it is now, but your cost will be a lot less. This moves you from having to reserve resources for the peak, even in the cloud to not having that reservation at any given time for any one database but have reservations for the aggregate group of databases. So that's kind of the idea of pool and how you can use the pool to really cost optimize. The other thing which is really important is this, let me just build this whole thing. You write some app, you have a bunch of queries in there, you have a bunch of SQL in there and you start running the app. And the developers leave or whatever and then you have a workload that's running. You no longer know what are the important queries, what are the queries that run most often, what are the queries that consume most resources, what are the transactions that are fast and slow and so on. We are collecting all of this information, using Query Store. And you're continuously analyzing and providing trends on Query Store, so that you can always go to the portal and drill down and figure out what's going on with your app. What is the one query in this app that uses more CPU than any other query. What is the one query in my app that uses more memory than any other query. What is the transaction that generates most log. And how often does it run and. So this is the information that's available, and this is also very important because if you find that you have 50 queries as part of an application that run, but one of the 50 consumes 90% of the resources. It's probably worth going out there and trying to figure out if you can optimize that 1 query, right? Again, doing this stuff is not cheap. You have to put resources to go optimize thing. So therefore, you wanna optimize things that have a return on investment worth the time. So our aim is to provide that, right? Let me shrink this a little bit so I can find the stuff. Okay, so I have this server, which has a bunch of databases. It has 49 databases in there. And so as you can see there is an elastic database pool advisor. And it will provide recommendations for those data bases. And it goes and calculates this, because the stuff changes all the time, right? So it'll go and live calculate and it will come up with a set of recommendations. It says we have 29 databases that could probably live with a total of 800 DTUs, and your monthly savings would be $1,800 dollars. And what the system is doing, they looked at all the 49 databases, the usage patterns for those databases, figured out which of them needs all the resources which is reserved for it, which ones don't. And came up with a collection of databases that could probably be pushed into a pool. Now if you want to take the recommendation, you can say okay, go create the pool and it'll help you, and it'll mark the databases. And then you can automatically move those databases in the pool and save the money. If you don't like it, you move them all back out and they'll just become databases again, independent of the pool and no harm done. It works well, you like the concept of the pool, but your workload increases, you increase the size of the pool, right? If the size of the pool is too big over time, then we'll recommend maybe you should shrink the pool. And again, the idea is that you can do these things pretty much real time. And I don't mean like every second you go change the pool. I mean that's not practical. But, Anything faster than every three year you buy a new hardware is an improvement, right? So that's the concept of the pool and the pool recommendations that comes with your server. So in this case you notice that I have to go to the server which has a collection of databases where I can look at an aggregate. So the recommendation for pools doesn't come for the database, it comes from the server that has a collection of databases. So we also have this database which we've been looking at, our CRM database. So I'm going to go and take a look at specifically on that database and see what's happening with this database. So there's the resource health, you can look at the health of the resources for the database. There's the performance overview, there's the performance recommendations. I'll make it a little bigger. So this is the data bases available and it's fine. The performance overview gives you an overview of the recommendations and whatever else is going on with that database. So you'll see the advisor recommendation as well as the queries and so on, right? So you get an overview of resource consumption. And you can go look at each one of those, right? And in the portal, if you remember we talked about DTU, we said that DTU is a box of resources you get for the database. So when you go look at the graphs, you can always look at the database with respect to each individual dimension of that resource box. So you can say show me the CPU consumption. So maybe you're maxing up 100 DTU because you're consuming 100 DTUs worth of CPU. But you're really not using the log or IO memory, right? And then go, hm, maybe some CPU optimization would help, because I'm not writing much, I don't use a lot of memory. It's just the CPU that's causing me to need 100 DTU. And this is the stuff that you can look at here by the various data IO, log IO, CPU, right? And you can see that the log IO for this database is really low, right? Where the data IO and the CPU are reasonably big, and then the CPU is the thing that usually spikes. So for this database it seems like CPU is the thing which defines what the performance characteristics is, and what the user experience is going to be. And we looked at the performance recommendation and autotuning. So I'm gonna go to the query performance insight. So when you look at the query performance insight, you'll see that these bars correspond to particular queries. So in this case, query ID 151 is consuming 29% of CPU. Basically no IO. It's the most frequently executed query, ran 6,965 times. I'm going to go look at this thing. When you go look at the query, you can actually get the text of the query which runs. And you can look at its historical trend and its various characteristics. Over time. So not only you can figure out what the query is, what is the query that's consuming the CPU, what is its historical trend, what did it look like before, now, and so on. And this is the stuff that allows you to have insight. It's hard to go get this kind of insight. But when you do have the insight, it's a lot easier to act on it. If you have to go spend days of digging for data to figure out what queries in your apps are consuming a lot of CPU, right, you probably aren't going to do it. If it's easy, then you're likely to optimize more. Now, you say, well, this is kind of cool stuff. And what can you do with SQL server on-prem? Well, everything that you see here comes from the SQL engine. And SQLdb, Azure SQL Database shares the SQL engine with SQL Server. It's the same thing. So query stores the thing which we are leveraging in the cloud. You could go do these things yourself. You just have to collect the data. You just have to enable all the telemetry and you actually have to spend the time, right, in doing the analysis. So the difference here is we're trying to reduce the labor necessary to get to useful and actionable information. Make sense? You guys are quiet.  [LAUGH]  Question, will that always capture the entire query? If you have a really long framework query will that-  Yeah. Let's just say, if we didn't know how to collect telemetry on entity framework, we would be doomed. Because pretty much every app which has a bad query probably has some entity framework in there somewhere. So we've been having a lot of conversations with our friends who work in entity framework. You could write an app using entity framework, and it'll work on SQL Server 7. And 2000, and 2005, and 2008, and 12, 14, and 16. So there's been little work in leveraging new functionality, right? So the code that entity framework generates is the least common denominator code for SQL, all right? Because they don't know what server you're gonna run. But they're adding options, so that you can say, you know what? I'm using 14 and above, or 12 and above, please generate code which is appropriate and most useful for that. So they'll start generating things, like hey, maybe you should use ColumnStore, this, that, and the other. So, entity framework will improve once they're able to generate version specific code. That's just a little tangent there on entity framework. These example customers that we have, big user of pools. And one of the things you'll notice, they have a lot of databases. A lot of them have a lot of databases, and that's one of the most interesting things we see with SQLdb. When we first started, we thought we'll have millions of customers with one or two databases. And what we have is we have customers, not in the millions, but those customers that we have, have lots of databases. It's not uncommon to have 10,000 databases in Azure SQL database. It's very common. We have a customer. They're into mapping software. They use SQL, they use all of the geospatial stuff. And one of the interesting things that he told us is that, when something bad happens on the planet, they get hammered. And that's the time wherein they need to be most responsive. So, for example, when tornadoes hit, when hurricanes hit, when earthquakes hit. This is when you need mapping software to figure out what, where and when. When in West Virginia, the mining accident, poisoned water. There was an app that you could go and type in your address. And they'd tell you if your water is poisoned or not. That's the stuff that you want the stuff to work really well. So they wanted to have lots and lots of databases, but be extremely responsive like within minutes. So they wanted to be able to figure out which database is a hot zone. Be able to automatically move those databases to bigger pools. Or even move a database out of the pool into a dedicated resources as big as possible to ride out the storm. And this is the stuff that people really automate in SQL DB because you can. So it gives you an idea of what people are doing with this stuff, which is sometimes not possible to do on-prem. Now, with virtualization, and so on and so forth, you could get very far, even on-prem. But, at some point, you have to have the assets on the ground to do it. So cloud really does help in these scenarios. So these guys, 350,000 websites. So you can imagine. So data security. I'll tell you a story. When we first wanted to do database in the cloud, this was early 2008. We're having a conversation amongst the engineering. And said, for years and years and years, Microsoft has recommended that you never expose your SQL Server to the Internet. And put port 1433 out in the open. Because of all the previous security. So we're gonna have a cloud service. And we're gonna put the thing on the Internet and open port 1433. What do you think is gonna happen? So we said, well, let's experiment. So we got an open Internet connection, which is difficult to do at Microsoft. Because everything is behind layers and layers. So we have to actually go and get an Internet connection, not inside Microsoft. We put a SQL Server on it, wide open, and started watching the logs. Within few hours, it had been discovered. Because, apparently, there are people out there who sit there and scan range of IP addresses, looking for known ports. So it was discovered that, gee, there's a SQL Server out there and port 1433 is exposed. The very next thing you see is their attempts to log in using SA. And then we were tracing the IP addresses that were coming. And it was from all kinds of interesting places on the planet. Not from New York City or anything like that, but very interesting places?  [INAUDIBLE]  Yes.  [LAUGH]  All kinds of places. So we decided that if you're gonna have a cloud service, and you do something which you recommended against. So we basically said in SQL Server, there's no SA. The login SA doesn't exist because it's the first thing that people try to use. Then we developed the DDoS-GUARD, which basically, after a few failed attempts, it just doesn't let you do anything. Which caused a lot of problems because people DoS themselves all the time. They forget to change the password. And then we also decided that we needed some set of firewall rules that you could restrict. Because there's really no reason for anyone from Uzbekistan to connect to my server. So there's a known set of IP addresses. So the DDoS-GUARD, the practices around account management. The password policies and the firewall were built into SQL DB since day one, before we even. And then that's when we started down this journey of, you gotta secure this thing in ways which is not traditional for. So, quickly, you learned that compliance and security are inseparable. Threats, well known threats. Most of the databases that are hacked is not very sophisticated at all. It's not like somebody really with a lot of skills. You can get packages that do it. They just always exploit known vulnerabilities, almost always. So covering known vulnerabilities helps a lot. SQL injections, every database is susceptible to SQL injections. And no matter how much we talk about it, developers just don't write code which protects against SQL injections. So we had to go and deal with these things. Both for real reasons, like people try to hack you all of the time. And to improve the perception of security in the cloud. And then we also learned that a lot of people use security as an example, as an excuse not to move to the cloud. Because we'd have customers say, no security. For this reason, I can't use it. And go fix that and they'll find another reason. But that stuff has improved significantly. So we did all the work necessary to comply with the various known governmental and industry regulatory standards. HIPAA, FedRAMP, PCI. So you can build applications that are HIPAA-compliant using Azure SQL DB. You have to do your own work to make sure your app is also compliant. So we don't do all the work for you. But you can build HIPAA-compliant apps. We built auditing so you can audit everything. So you can turn on auditing for all of your databases. You can turn on auditing for the server. And all the databases will inherit the auditing. You can go look at your audit records for everything that happens to your database. Very much like SQL Server auditing, maybe a little easier in some cases. SQL Server comes with TDE. SQL DB comes with TDE. So you can enable TDE so data at rest is encrypted. So all of the backups and everything is encrypted. Of course, when the database is running and the data and memory is not. But TDE is encryption at rest. You can turn it on by default. The performance impact of turning on TDE is fairly small. Because we do use the Intel instructions for the encryption. And in SQL Server 2016, the CPU impact of TDE has been reduced significantly as well. We do recommendation for security as well. If you see social security, a credit card number, PII stuff in your schema. We would recommend that maybe you should use data masking. And we'll provide masking functions. It helps to reduce the surface which exposes you. We also provide role level security. And you can combine some of these things together. So, for example, with role level security, you can have roles and responsibilities. And different people see different sets of data. And a good example is, if you go into a hospital, the nurses that work in pediatric have access to the data for kids in the unit. But other nurses in other sections have no reason to have access. Same thing for the psychiatric work. Again, this is to protect different patients in different areas. As you can imagine, if you're a celebrity and you walk into a rehab center in Los Angeles. Everyone in the hospital has access to the fact that you're there. That's a bad thing. So with role level security, you can decide who gets to see what without changing the app. Because the role level security, the policy you create and the database engine enforces the policy. As opposed to you build the logic in your app. And that's very important. Because, again, if you have to build the logic in the apps, saying this is a nurse from this section, so they should or should not see. That stuff gets out of date very soon, right, and you have to update the app all the time. If your policies change and you have to go change the app code. With role level security and data masking, it's policy driven, like a T-SQL policy that you create. And you don't have to touch the app code, right? So this is the stuff that we make recommendations. So let me do a quick dive into the security stuff. Again, here we have a database. So you can go and turn on Audit. You can look at the data masking. So in this case, SQL DB has detected that you have a column with numbers and could be credit card and it suggests data masking policy that you can add. You can add them from the portal or you can say, given the script, I'll go change it myself, or any way you choose. You have transparent data encryption, you can just on, off switch. We manage the keys for you. So it's really easy. This database doesn't have it. And turn it on. And make it as easy as possible for developers to write secure apps. And make it as easy as possible for the database and anybody around the database to manage it in a secure way. And that gives you a much better security posture. If it's difficult, inconvenient, people are not gonna do it. So can you make it really easy? If you have to go change app code, it's not gonna happen, right? It's just one of those things. That's why in the case of encryption at REST, or always encrypted, we really work hard to figure out how can you do this without having to change app code, right? So policies in the database, okay. Changing C, C# code or Java, difficult. So that's the security stuff. So NewOrbit is a customer, they're in UK. And I've met with him many times. He has a particular sense for what's gonna happen in the future. I've been meeting with him for years now. He was one of the first people who told us that our service was stupid and the business model would never work for people who have lots of databases that are not being used all the time. He is the person who put the idea of pools on the table for us. So we do engage with customers a lot and we will learn a lot in the cloud, right, because a lot of the innovative stuff is happening out there, not inside the database team at Microsoft. Threat detection and anomaly detection is also a very big area for us. So, We can tell when a SQL injection is happening. We can also tell when there's a brute force attack on a database. We can also tell when there's anomalous access and activity happening, because again we collect all the telemetry and we're continuously processing the stream of telemetry. So there's no humans involved here. What's happening is all the databases are generating stuff and we have a set of benchmarks and baseline data for every database. This includes the performance baselines, error baselines, right. As well as pattern access pattern baselines. So when we see a database being accessed from places which it's never been accessed before, right, we can raise an anomaly. It is the very same thing that credit card companies do, right? If I use my American Express here right in Chicago. Buy something at a store, and there's another transaction happening in person in Los Angeles, chances are one of them is weird, right. So they raise an alert, right. It's a anomalous thing. Whereas no matter what I do on Amazon it doesn't raise an anomaly because my wife buy so much stuff at Amazon, right. They go, it must be him. And one time I was traveling and somebody had gotten hold of my credit card number. And this is many years ago. And American Express was approving and denying individual transactions. And I was in Europe traveling for work and they were approving those while denying transactions in Portland, Oregon which is my home where I live, right? They had that much capabilities, all right, so to detect what is anomalous. And that has been a very, very impressive experience for me that I've always remembered. So we've been trying to do this kind of stuff with SQL DB, again, since the beginning. See if you can detect anomalies. And we have done a pretty good job, and we now have an anomaly detection that's in preview, and we have threat detection. And the idea is if somebody is running queries against the database that usually sees single transactions, that does an unusual access pattern, if that query is originating from an IP address which you've never seen before, it's outside Azure. And it's an unknown IP address to us, the chances are, maybe somebody is extracting data from the database, right. And so customers who opt in to have us analyze their data, then get emails with the logs, the audit records, the times, the query, and what was being accessed, so that they can go and investigate. And same thing with SQL injections, we inform customers that hey, somebody needs to go fix the app and eliminate the injection stuff. And again, the threat detection is, you basically go and turn it off. I mean, it's very simple. There's nothing here. If you have auditing. You have to have auditing, right? If you don't have auditing then we have no way of collecting the baseline necessary to detect the anomalies. But if you have auditing turned on, then you can also go and turn on threat detection and then we can do this analysis for you. And we'll do it for every database that you have. Yes?  You mentioned at the beginning of the talk about having just a SQL database on a VM, or a SQL DB. Are all these features only in SQL DB?  Yes.  Okay.  Yes, because we have no access to your Azure, because you're in charge and you're in control of your entire environment. Therefore, we can't access your audit logs. We can't baseline. We can't benchmark. So we have no visibility. By the way, all of the telemetry collection and the telemetry processing is done outside of your DTU box. So we don't use the resources that you bought for your database to do this work. So we always have system resources reserved for telemetry collection and processing outside of the bounding box which belongs to you. So if you're doing backups, if you're doing telemetry processing, it's not like all of a sudden my app runs slow because Microsoft is doing, I don't know, telemetry whatever, right? So all of that is resource governed outside of the bounding box which belongs to you. So we have a lot of people in the preview for the threat detection stuff. And we've caught a lot of interesting things like SQL injections, hacking, unauthorized access to credit card information. We've been able to inform our customers of those things. And this is one example. People have employees that go home and work from home, and access data, which really shouldn't be accessed from home. But they never knew, right? So the anomaly detection says, hey, unknown IP address. Somebody's doing things, right? Imagine all of these people who take secured documents home from CIA or whatever in their briefcase, right. Now there's nothing we can do that guarantees 100% secure, right? You can have a DRM document which you cannot print, you cannot forward, but you can take a picture with your iPhone and post it on Twitter, right? So if you wanna do bad things, you can. But in this case, it was just people were doing it and they had no awareness. And the awareness itself was useful because then they could set some procedures and processes around if you do access data from home, what are the things that you need to do, right? We've caught more than a few exfiltration attempts. But most of the time, it's just bad code. You call the customers, you tell them how to fix it, and they fix it. Some of the stuff we've tried to push down to SQL, so SQL can be better at some of these things, but really, you need the data to do these things. So when we talk about Azure SQL Database as an intelligent cloud database service, right? We didn't talk about index, column stored in memory, or whatever. It's really about this services that are around that makes it easy to use, build, manage lots and lots of databases. Let me, Yeah, so I'm gonna stop here. And if you have any questions, I'll take some questions.  Don't we have any static relationship between the [INAUDIBLE]  So the basic question is hey, is there any way you can make the mapping of the initial resources easier? So can you just tell me that a P2 is really two cores and it has 8 gig of memory and then I'll go from there. And we haven't done it because we weren't sure how stable that stuff is, right, because things change. So we tell you it's two cores and then we get cores that are twice as fast, is it gonna be still two cores? Well. But we're trying to find ways to communicate some of the more stable stuff. There's no reason to not communicate some of the memory and IO characteristics because they don't really change over time that much. The CPU stuff is really difficult. I have this rule in my head, I go, I take this DTU it by a 100, and that's kind of the number of cores. It's not exact, right, because if you have a brand new generation of machines, you're on the sixth generation of the Azure machines, right? So it's really difficult to keep that mapping constant all the time. The other thing we do is in Azure, we have 38 data centers all over the globe. There's millions of stuff out there. It's not like everything changes in one day from generation five to generation six. I mean, there's a ramp up and ramp down, and takes a long time. So at any given time, you might be on different stuff. So we try to use the DTU to insure that you would never notice a difference. If you go from an old machine to a new machine or new machine to an old machine, that you wouldn't perceive the difference. Because we give you more cycles, we give you more cores, or memory, or the IO, try to balance it out. It is a bit of a challenge. But we're trying to make it better. If you go to the portal or the documentation and comment on there. The chances are somebody will answer the question accurately for that time, right. So try it. And then you can give feedback there as well. You would say, I know you're trying to do this, Microsoft, but it isn't working, so come up with a better plan. That usually works. [LAUGH]  When we are [INAUDIBLE]  All right.  [INAUDIBLE]  Right.  [INAUDIBLE]  Right, well, that's the thing. You can change it as well. Especially with the data warehousing, it's so fixed and it's so hard to change it. So people always want to know, what is it exactly, and how much is it exactly over the next five years? In the cloud, you change these things a little easier. Yes?  [INAUDIBLE]  We're working on that for VNet support. So if you're interested, send me an email. I'll hook you up with the folks.  [INAUDIBLE]  Yeah, I think we just announced four terabyte, and if we haven't, it will be soon. So we're also trying to increase the sizes. So okay, I think this thing is beeping, which means I have to stop. But come by if you have more questions. Thank you very much.  [APPLAUSE] 