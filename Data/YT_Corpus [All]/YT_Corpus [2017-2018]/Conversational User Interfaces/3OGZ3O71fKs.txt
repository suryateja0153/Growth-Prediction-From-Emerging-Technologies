 My name is Phil Potloff, and I am the Chief Digital Officer at Edmunds.com. If you're not familiar with Edmunds, it's a car shopping and research website that gets about 20 million unique visitors every month who come to our site to help with reviews, pricing, as well as picking inventory and other buyer systems. Now, Edmunds has been a mostly digital business for the last 20 years, but the company actually dates back to the 1960's as a print publisher of car pricing guides. What we're going to talk about today are top lessons learned from innovation practices, and these are really the things we've figured out from growing it a number of times, over and over again. So here to share some of their biggest flaws with you are Julie Merges, our Chief People Officer, Eugene Park, our Chief Product Officer, and Paddy Hannon, our CTO. One of the main messages I hope you'll walk away with today and what you'll maybe see in what we talk about is that oftentimes when companies try to put a focus on innovation, undoubtedly what happens is that they put that burden on a very narrow function within the company, such as innovation labs, skunkworks, and incubators. What we want to try and show is that you may be forfeiting some untapped contributions from across the broader organization. We're going to share some of our top lessons at a high level that are really about how to staff, discover, and frame problems, in our case, car shopper problems and in some cases, car dealer problems. So, before we do that, what's typical in lessons learned is that you would look at past successes and failures and you would figure out what are the key takeaways for next time. We'll do a little bit of that today, but we also wanted to play it forward a little bit and see if we can actually apply some of these lessons to an actual current problem. The one we're going to pick today is something that has to do with the technology craze of Chatbots which you've probably been exposed to. While you would think of most innovation practices as blue sky opportunities, the reality is a lot of things get handed to you like this, and you have to be really effective at dealing with them. So let's say we're going to have this Chatbot problem, we'll walk through it the next half an hour. Hopefully there's something there, and in this case half of humanity is currently messaging and all of our kids and nieces and nephews prefer to message and chat versus any other communication media. Also if you look at the Gartner Hype Cycle, several of the key elements of Chatbots are trending big within the cycle. If you're not familiar with chat bots, they're really just a program that simulates a conversation with a human as opposed to a human having a conversation with a human via chat. It's pretty typical to see them in web and messaging interfaces. So let's dive right into our first problem. Julie, I'm going to ask you in a minute to help me with my Chatbot problem and figure out how to staff it since I have no budget and no team, but I've got according to our sales guy 6 RP's that need us to figure out Chatbots. So there's this concept that builders are great, but we need people that can create fire and this is about how you create teams. What are some of the lessons that we've learned from staffing mistakes on innovation teams or teams in general and what does it mean to have people that can create fire? Great. So as you've already highlighted, we've certainly made our share of mistakes and have taken that and sort of refined our approach to how we think about organizations and talent at Edmunds. You know, one of the biggest mistakes we've made in our past is getting prepared for the future. In terms of what our organization is going to need, it is having a robust succession plan. While it's a good practice in every organization to do that, it certainly does not prepare you for the future. You can't predict everything that's going to happen, and there's so much change that happens at a rapid clip. Really being prepared is trying to figure out how you're going to do this on the fly and doing it successfully. And so that is lesson #1 or mistake #1. Mistake #2 I would say is thinking that that great teams can be formed by just taking a bunch of really smart people and putting them on a team, and thinking that would bring success to just about anything. Or that you can just take whoever's available because they're not on a certain project, and then putting them on a project and thinking that would form a good team. What we've learned is that never works and it actually rarely ever works. What you have to do is be super deliberate about whom you're putting on the team and making sure you're the right mix, as Phil said, of builders and fire starters. We think of fire-starters as people who have fresh ideas and bring fresh perspectives to the table and can really ignite innovative, creative ideas. The third mistake that we've come across is that when you do get a team right, you can keep them together and put them on the next project and see success just in the way you did on the last project. We've realized that is a mistake too cause what you need to do is continue to refine those teams. Keep certain people together but reignite the teams by making sure the right, fresh perspectives are brought to the team, as well. So you know those are probably the three mistakes that I recall that have really been pivotal to thinking about things differently and Phil, it comes back to stories you tell around the office around West Side Story. These learnings have come directly from the story that you've often told. Yeah, this is actually one of my favorite organizational design/research stories, and you can't give a presentation at a university without citing research. It's the rule. This was a researcher who loved Broadway shows, and he also as a researcher became fascinated with what made them successful. The conventional wisdom, at least in Broadway, was that when you had a good team's production team, cast, whatever, is that you would actually keep moving them on to production after production, expecting hit after hit. So when he dug into the research, he actually found that that wasn't the case. I think there are a lot of applications on how we staff teams here. He looked at plays from Broadway shows from the 20's to the 80's, 1920's to 1980's. And what he found is that the shows that had the highest probability of success are the ones that have the best balance of people who are the executors, the builders and a balance of fire starters, the folks with new ideas. West Side Story is the classic example because you had Arthur Lawrence and Leonard Bernstein, who were hit machines, and they brought on Steven Sondheim, who was a 25 year old first time lyricist. And the rest is history there. But the message really is: taking all of your A-players and putting them on all your best projects is not always the right thing to do. They may execute, but they will get stagnant. Same thing goes with people who've never worked together before, trying to bring them together either because they're good or they''re available. They may have great ideas but they can't execute. So it's actually a really good mix that matters. So, Julie, throwing it back to you, what are some of the structural things you've done in the two plus years you've been here? And you've done a lot to build the capability for us to be able to put these kinds of teams together. Yeah, so we put a lot of focus on strategic planning. We spend quite amount of time as an executive team really charting what the strategic direction of the company will be. But in concert with that at the departmental level, what we're going to be focused on is how we'll team together to make that happen over the course of the couple of years ahead of us. One of the things that these executives do a great job of is really thinking about what impact that has on the organization. This is less so about how do we fill seats if they were to become vacant tomorrow, but our executive team and I work together to really think about, 18 months out, what does our organization structure need to look like based on the strategic direction we know we're going to take? So from an organization design structure perspective, capabilities, what do we have, what are we missing, and then from a talent perspective too, what are we missing, what do we have today. So it really helps us to get proactive about thinking in a midrange view, to think about if we know the company's going here, we know we need to achieve this, then what do we need from an organization talent perspective? And so what it does is give us great direction in terms of how we hire and the kind of talent assessments that we need to focus on. From a hiring perspective, when we hire for executives and other really strategic hires, we put a lot of energy into making sure that we get to know the talent really well. So we do the Hogan personality assessment, if some of you are familiar with that, and it gives us a really deep look into whether we are hiring builders, people with track records and an innate ability to build and do that well, or fire starters. So we get to know the talent really well from that perspective, but we also instituted a program that we call the Fit and Finish Program. For every hire that we make, we ensure that there is always an objective member on the interview panel so that it really does break the cycle of hiring teams: getting excited about a hire because they fit the need for an open role we have today, but that there's somebody looking at it from the organization's perspective, to make sure we're really hiring for versatility and agility. No matter who we hire, those people are going to go off and be successful in 8 other roles within the company so that they're not just perfect for the role we have today. So the program's been a great success, I mean, we are in our early days still, but what we've done is essentially picked the people that we consider our high potentials that have a track record of having zig zagged throughout the organization, because we think they're going to have the best perspective on making sure we repeat hires like themselves. Getting to know our talent at the hiring stage has been a big focus of ours and then "fuel your potential" is Edmunds' approach to how we think about the very traditional performance management process that many of you may be familiar with. We really put it on its side at Edmunds, because what the traditional approaches have often been is this process to evaluate and judge talent and then grade it. How are you doing, are these people meeting expectations or not? What we've done at Edmunds is take it to a different place and really use it as a platform to have conversations with the people that we work with, and use it as an opportunity to understand their backgrounds. Where have you worked, what have you done, tell me more about what potential you have, interests, backgrounds, that we aren't leveraging as a company that we should be to get the most out of the people we already have in the organization. And it's been amazing to see how many people have come forward looking forward to share with us what they've done or what they're are looking to do, where they feel that they're untapped because they know something is going to be done with it. It's been a great approach for us to really understand our talent at a very different level. What it's helped us do, from a hiring perspective but also from a talent assessment perspective, is for us to understand the talent very well and know how to form the teams that we were talking about earlier. Once you understand the talent, you have all the data at your fingertips to team the right people together, to be very deliberate about resource planning. Phil, Eugene, and Paddy do a great job every six months, essentially like a baseball trading exercise, really looking at the talent we have, not just looking at who is available but making sure we have the right mix of teams based on the opportunities that we have. And even through that exercise you can't plan for everything even though it's a 6 month window because you might get a request that should have been accomplished yesterday. Cool. Well, that's actually had a huge impact on the organization. Fuel is very visible in our company, and it's weird because I dread performance management as much as the next person, but you actually have our teams, our direct reports, reaching out to us because they want to talk about their career, what they've done right, what they need to do differently, and what their aspirations are. It's totally changed performance management altogether. So that's all great, but how are you going to help me with my Chatbot problem? Because I need a team, I need to figure this out in short order. So what we'd probably do is we'd get together. I'd probably get a better understanding of what you're looking for in terms of your vision for the Chatbot project. The purpose, the objective, and the vision you have, and also a little bit about what you're looking for: the kind of experience, background, skillset that you would need on the project, but also the duration of the project and those kinds of things. And that would really help me get a better sense of what we're looking for, and then we'd mine all that data I was talking about earlier. We'd mine the Hogan data; we'd mind the Fit and Finish data, as well as all the data we collect from Fuel Your Potential. It's amazing because every time we've done this, a leader comes forward, and just like we would in your case, it would surface several employees that fit the mold in terms of their experience, their background, and their interests. What we do is tap them because it really is amazing, cause when you tap people and you tie it back to what they've told you, it's amazing how people will remember that in terms of the next Fuel opportunity, and they can't wait to share with you what they're interested in next because they know that we use it constantly. So what we do, Phil, is that you and I sit down with those names, we talk a little bit about the folks that we think could be a potential fit, and then we probably hold an open house. An open house at Edmunds is essentially an opportunity for someone like Phil to get in front of a group of employees that we've just recently tapped and tell them a little bit about the Chatbot project. The vision that he has; what the project entails, the kind of relatable skillsets that you're looking for, and a chance for you to tell them what the 4-6 month duration would look like in terms of their day to day work. Then what we do is pretty informal informational interviews where you sit down with everyone who has come forward. Probably you and I would sit down with everyone that's come forward. It's interesting because we've had leaders in the past say: "why don't I just sit down with the people who have the background and the experience that look good to me?" And what I always encourage, and Phil I'd encourage you to do the same thing, is to sit down with everyone who has expressed an interest. Because it's amazing how much you get to know in just a 30 minute conversation that an employee otherwise wouldn't have the opportunity to have with the CDO to say here's what I've done, why am I interested, and then ask a series of questions. I think Phil would get a lot out of it, as well. And it's a great opportunity, because while it may not be a perfect fit for the Chatbot project, several months from now there might be another opportunity that arises and Phil remembers the conversation he had with the people that had come forward. We found it to be a great opportunity to just network so tap people on the shoulder of an opportunity inside the company rather than always going outside when you've got a need. And our employees have really come to appreciate it. These people have day to day jobs. How are you going to free them of what they're responsible for? Are you going to leave these departments in a lurch? And what we do at Edmunds is sort of tied to the Fuel program that we talked a little bit about earlier. We have this program called Cascade Development so if someone leaves a role to take on a separate project assignment, what we'll do is then take the roles and responsibilities of that one individual and we'll cascade it to their own direct reports or their peers and colleagues across the company. We open up that opportunity as if it's another project assignment. It essentially has a cascade effect or domino effect of alerting opportunities that are real experience based, real job based that go and multiply itself across the company. That's what we would do. We're talking about the Chatbot, and it's kind of a hypothetical, but this is something that we've seen cross our organization in multiple functions, not just technology or product, where we've had folks move across temporarily or permanently to work on these new challenges. So it's been really huge. Let's actually move on to our next lesson, and this gets to: how you do you know what to work on in innovation? We frame the problem is that the world is full of them and we need to be really good at picking them cause there's just too many. But really the issue here is not problems, it's that people get too fixated on solutions upfront, without really understanding the problem it solves. And that's where we find ourselves with this Chatbot thing we were handed as a solution or a tool. The manager of the Google X moonshot programs was interviewed recently for Bloomberg, and he talked about shutting down the Google X robotics program because in his view robotics was a tool and he wanted everybody in that program to be associated with a problem. So they weren't able to work on robotics unless it solved a specific problem. Eugene, I'm going to go to you now. Looking at this Chatbot problem, how do we use some of our problem identification techniques and idea generation to actually turn this thing upside down and try and find the real issue? Eugene Park (EP): Right, so one of the key ways we tackle these sorts of problems is by using a method we sort of developed in-house, and we call it Trust by Design. This method is a combination of a number of different methods and principles that you've probably already heard about: designed thinking, the lean startup, and user centered design. We've framed it a little differently to kind of put it into our own terms. But it's a relatively simple 4 step, 4 stage process. So I'll just talk a little bit about what we would do when facing this sort of situation with the Chatbots. First, we start by bringing the outside in, and what we mean by that is really focusing on our customers in their environment, and trying to understand, just trying to increase our understanding as to what situations our customers are dealing with. That helps us essentially get outside of ourselves, get outside of our preconceived assumptions or notions about what's actually happening in the world. It really helps us move to the next stage which is pinpointing the pain point. So what we mean by that is really framing up what we've observed in our research, our user interviews in the first stage, framing them up really as problem statements to solve, helping us figure out where the biggest areas of pain are. Once we do that, it's fairly easy for us to begin to move into prioritizing those pain points and begin to develop radical ideas that help to solve those pain points. That phase is really ideation and trying to understand: "Well from a blue ocean standpoint, how do we come up with ideas to actually solve these problems?" Then, from there, we move to a really structured part of the process which is developing experiments that actually help us learn whether the solutions that we're developing actually fix the pain point. It's a very iterative process because the learning that you get out of those experiments often times leads to you discovering new problems or seeing problems differently, and so it's a rinse and repeat cycle. As we think about this Chatbot situation, one of the things we would do in terms of bringing the outside in would be a lot of what Julie referenced in terms of Julie's teams research and understanding of the talent pool. But we'd probably go to Julie and ask questions like, "do we have any artificial intelligence experts in the company that could help us accelerate our learning? If so, what are the things they've told us that would help us to move faster? Yeah, and we know from having mined some of this data, we've got plenty of people with artificial intelligence experience, conversational interface experience, and machine learning experience. We have a great talent pool when it comes to being able to tap people for these opportunities. And having spoken to many of them, they really would boil it down to two counsel points that they would share with us which is make sure that we don't treat this as a tool. It's not a standalone, that it's integrated into products that we already have because really going to propel the success of an effort like this. Also, make sure that we're focused on a discrete problem to solve. Don't think about boiling the ocean, let's get focused on a discrete problem and let's kill it. Right, so taking that kind of information and having that expand kind of our understanding of what the situation is. We'd probably take that information, and try to figure out, don't try and start an entirely new conversation flow. Go to where the customers are; go to where the conversations are already happening. One of the places we'd be naturally leaning towards, a platform that we have called CarCode. What CarCode does is it's a texting and messaging platform for car shoppers and car dealers to communicate with one another when they're separated by distance. We've got probably 50,000 conversations or so a month that are happening over this platform. So we don't need to create a new audience or look for a place where there's a conversation happening, we already have a platform where this is happening so we can tap into that as a place where we can start to think about how to inject Chatbot as an innovation there.  So what would be some of the challenges that existing product has that a Chatbot couldn't help solve? Right, so when we think about what problem we want to solve, we have analytics. Our analytics team has done a lot of research in discovering and figuring out: Let's mine these conversations, figure out what are the conversations about, and what are the pain points that we're seeing through the conversation flow that's already happening. One of the areas that we would look at would be something like credit because credit is a pretty common conversation topic that's happening between car shoppers and dealers. Consumers try to figure out, am I credit worthy, what's my credit score? And that's a big pain point, for them to be able to understand that. From a car dealership standpoint, they obviously don't want to waste time on car shoppers that aren't going to be able to purchase the car when it comes down to doing the deal. So that's sort of a two sided solution or two sided problem where if we could inject some intelligence, there'd be a ripe area for innovation.  It's funny because there was a team doing a brainstorming session last month, and they were actually doing it from the position of the dealer, and they came up with this exact same problem. Because as much as we all like to think we have terrific credit, only about 20% of us do, and the rest don't qualify for offers they see advertised on TV. So this is a huge problem, and this actually came out of a brainstorming session. Again, talking about turning things upside down is this idea of brainstorming; instead of brainstorming for ideas you're actually putting yourself in the position of someone or of a particular situation, and what is their need or issue and why is it important to solve. That's a good validation of what you're thinking. I think, using these techniques, we've started to get to the point where we would begin to be ready to actually try and build some learning experiments. That's really where we go next.  Awesome. Well so far we've been able to get through a lot of these Chatbot problems fairly easily with some of these things. But now we've got the biggest problem of them all: we've got to deal with technology. So one of our key innovation practices here, especially on more speculative ideas, is do not fall in love with your technology, just data. Find Tinder for tech. So Paddy, you manage our entire website infrastructure and our entire back end infrastructure, how can I do something lean and test the Chatbot without getting stuck in procurement cycles and dealing with release road maps and other conflicts that may come up? Well, you're lucky because we just passed our procurement window so you have to wait three months before we can order any hardware for you. Thanks.  That's kind of what would have happened in the past, right? I would have sat there and said, I can't launch Chatbot software. I have to go buy some hardware; I have to stick it in our data center. How are you going to get access to any of the databases where the data is held? We've spent a lot of time over the last several years focusing on building capabilities to allow these innovation projects to go forward. Because something like a Chatbot is going to need access to data, right? So if you're going to do something on credit, you're going to need to know what the financing is. It's going to need access to hardware to run on and Eugene keeps talking about experiments, he's going to need some kind of experimentation framework, some way of recording data and reporting back on what he's doing. So let's go through each of those in sequence. The first big investment that we made, and these are all upfront investments that we had to do a while ago, but we're there, is to focus on modularizing our software design. So you can think of the Edmunds.com website, which was traditionally packaged as a single application. So the things that rendered the web pages, the data services, and everything, were sort of packaged in one container and shipped to production. What that meant is every single change required you to test the entire stack. So several years ago we started breaking it up. You hear people talking about micro services, and that's essentially what we did. We took the website and said, "Guess what, there's something that does vehicle data, there's something that does incentives, there's another thing that has to render pages." And we broke that down. Or send email. Or send email, or do user registration. Any number of core components that are needed in order to build a website. Once we broke those up and turned them into their own separate applications, I could put a small team on it. So I could have an email team, I could have a user registration team, I could have a website page building team, and they could all operate independently. They could push software independently of one another. They could move much more quickly than when they're lumped together. So the first real capability that we had to build was this modular design so that I could have a vehicle data service and the website could use it, an iOS app could use it, an Android app could use it, and maybe our Chatbot could possibly use it. The next area that we embraced was going cloud-native. When I say cloud native, I'm not just talking about forklifting your data center into Amazon. I'm talking about truly leveraging the entire cloud stack. The big thing there, and we've just recently done this and it's been a huge boon for us, is adoption of something called containers. If you think about containers, containers are akin to the changes that were made in the shipping industry a long time ago. So my grandfather was a longshoreman. He used to actually have to go into the hold of the boat, grab the goods, walk them out of the boat, and put them on the dock. The shipping industry got smart and they noticed that the boat could be a platform, and you could put a shipping container on said platform, and you could have an infinitely reconfigurable ship. The same ship that shipped rice could also be used to ship cars or anything else, and you could mix-and-match on one boat. That's what we've done with our infrastructure. We've taken what used to be servers, and we've put applications in these containers. Now, if you want to do a Chatbot, I can deploy a single container onto a machine somewhere, I don't even care where the machine is running, and if it becomes popular we can scale up to hundreds or thousands of these images very quickly, in a matter of minutes as opposed to months, days or hours. The other part of going cloud native was really embracing web services. So I don't have to write an identity service, I don't have to worry about user registration. Amazon provides one. I don't have to worry about how to store data. I don't have to configure database server or anything like that. Amazon will provide me a data store. This frees up the teams that are building these micro services to focus on what matters, which is retrieving, manipulating, and returning back vehicle data or building a webpage and not worry about the underlying format. The last thing we had to focus on, and this is probably the largest investment that we made, was building capabilities. So we have a lot of teams that are out there building features, but we can really help those teams a lot by paving a road for them, giving them a path to travel. So we spent a lot of time building an AB testing framework which allows Eugene's teams to run experiments and see the impact of these experiments, see the impact of new features on user behavior. And this AB testing framework was integrated, it's called WTF, Phil named it, but it stands for web testing framework. It's one of the only acronyms that I actually hold on to at Edmunds. It's a fairly brilliant acronym. And it's great to say in an executive meeting or in a room full of people. So WTF is a huge capability for us, woven into all of our software services, so anybody can get access to experimentation. Continuous deliveries is one of those buzzwords that's been around for a long time, but really what continuous delivery does is it means that the product teams don't have to think about how to move software from development and QA to production. It just goes automatically, the tests are run and it's deployed and they don't have to think about it which frees them up to focus on product development and building the features. The last one is standardization of analytics. This one actually has far reaching consequences because it means not only do the product teams not have to worry about how they have data collected, the data collection infrastructure for an Android app and for a web application, and potentially for this Chatbot would all use the same pattern and the same set of services, and would all store data in a very prescribed way such that the analysts and the product managers that need to access that data have a very repeatable pattern. So they don't have to relearn a new dataset when they launch a new application. It just speeds up, you know, when you think about innovation, how fast can I get something to market? And how fast can I learn from it? So having that standardized analytics really helps us get to a place where we can learn from it very quickly. So I think those are the three things: it's modular design of our software, and when you listen to the way everybody is talking, a lot of it is ingrained in our speech. Eugene was talking about experiments and running experiments, Phil was talking about data and accessing data in different ways, all of these things are baked into how we work. They allow us to really focus on the true problem at hand which is building this Chatbot. What do we have to do to build a Chatbot? Well, we don't have to worry about the data services, we don't have to worry about how we are getting it into production, we don't have to worry about how to measure whether it's working or not. So the team can focus on what really matters which is using their AI expertise to do natural language processing, figure out how to have a conversation, and how to win in getting the credit scores out there or figuring out what financing options are available for a consumer. And that's really the thing, building the core capabilities to allow our project teams to focus on delivering value. Cool. Well, it sounds like you're not going to be a roadblock so I appreciate it. So just to start to tie things together here is that whether you're trying to test a speculative idea like a Chatbot or you're trying to figure out a new revenue model for your business. In addition to trying to connect more resources, like we've hopefully shown you so far, there is a strong emphasis on innovation as a capability. So that you think about it the same way you think about your supply chain management system or your customer support workflows. Those are the things that don't really on serendipity to be successful, and neither should innovation practices. Again, the value in spending the time on developing all these capabilities, whether it's the human capital management, the problem identification or the technology stack, our goal as an innovation function is to improve the hit rate. If you never improve your chances of success, than you aren't really developing an innovation capability. That, hopefully, will lead to an increase in confidence. You can either get more allocation for investment for innovation dollars or keep your job. Then finally, what's really valuable to folks that are speculating on innovation practices is that you can earn the right to get longer runways because some of the more speculative things just take longer to gestate. If the company and the senior executives are confident that you know how to spin down a project as well as you know how to spin one up and not waste resources, you are very likely to earn the trust for those longer runways. And lo and behold, we've been able to build a Chatbot prototype in the last 29 minutes, as you can see here so it must work. That's pretty much what we have to say, and I hope it was meaningful. There's some time for questions. Commentator 1: Sounds like you've solved the problem of getting the right mix of builders and fire starters together, but for those of us from companies that are way out of balance, what advice do you have to keep the fire starters from getting completely disillusioned and leaving? I'll let Julie answer that in a second, but one thing I want to make sure is clear is that they aren't necessarily different people. Like you can have a really good builder, but you can put them on a different team and they're the fire starter. It's really about how you blend, and again, and at its base, and this is something Paddy and I really rely on in our careers in technology is, execution and technology because we only get paid attention to when something breaks. So execution really matters. But bringing on new people to help us re-envision our technology infrastructure and things like that is a big deal. So I think there are a couple of ways to solve for that. One is obviously hiring very deliberately. Beyond just the interview process most companies take, there are deeper ways for us to identify the fire starters from the builders. I think culturally it comes down to a lot of things in the environment, right? You might have plenty of fire starters in your organization, and it's about creating an environment where people feel like their ideas are heard but accepted too. Perhaps that's about getting focused on discreet problems and giving them feelings of success. You know, Phil just recently introduced something within the organization which was like the "failure bonus". He awards $1000 to the person who fails biggest. We have this thing called the rest stop reader at Edmunds, essentially a newsletter that hangs on the back of a bathroom stall so that's how people get their news at Edmunds, and we profile them in the bathroom stall. So it's not often that you sit in the bathroom stall and you realize your face is up there for a failure bonus. But that's the kind of stuff that we do, create an environment that makes that fun and makes it worthy. But we didn't have any of this stuff a few years ago. All of this stuff is fairly new. So this whole concept of how we're going to create teams and mix teams really is very nascent but it took over very quickly. Once you start having failure potential and you can start actually start asking people, I mean, my head of Big Data engineering came because he was going on vacation for two weeks and he grabbed me and said: "hey, we need to have our Fuel conversation." Once you have that culture of people wanting to tell you what they're interested in and you act on it, I think that's the big thing. Ask for those people to raise their hands, but then do something with them. Cool. Question? Commentator 2: How often do you go outside of your organization for innovation, either because you can't get the right talent or because you don't want a 100% of what you do to be invented here? That's the first question. Second question, it sounds like you built a platform for innovation and there's lots of standardization. So your success was doing things that are new to you, new to the world, something that nobody has ever done before? Standardization is not going to help you.  Sure. Eugene, why don't you take the first question on outside innovation? That sounds fine. We were debating over who was going to take it. We do rely pretty heavily on outside innovation. We actually had a series of hackathons where we invited individuals and sort of nascent companies within the auto industry to actually come and compete to solve a particular car buying challenge. Actually, the CarCode platform that we're highlighting in our presentation came out of that program. We ended up purchasing that company. It was the first ever company that Edmunds had purchased. The founder of that company ended up joining the company and staying with us. He's now one of our VP's of product innovation. We believe very heavily on being open minded to tapping innovative ideas from the outside and bringing them in. One of the things I think about too though is we've also reached out to outside companies to help us with the capabilities that we don't have. What that sometimes does is galvanize internal folk to try to be much more innovative, almost like a sense of competition. Like, "oh, we're not going to let these outside guys go build the cool thing. We're going to go build the cool thing ourselves." I think that's led to a lot too. Sometimes they win, sometimes they lose.  Sometimes they win, sometimes they lose but that's the thing with innovation. A little bit of that is not competition, but it is friction. It's a good thing. In terms of building brand new things, I think that's geared towards the technology area. I think by standardizing a lot of things, we're freeing up the teams to build things that the world has never seen. They don't have to worry about the plumbing; they can focus on doing something very creative and brand new. You don't want to get overly prescriptive, you want to give people freedom, but I think by not making them think about servers or databases or any of those other things, they're able to focus on the truly innovative stuff. Racking and stacking servers is fairly commodity. I don't want my technology team doing that. I want them building cool new things that the world hasn't seen. Commentator 3: Do you guys have a fixed view on culture or do you view it as something that needs to be adapted and changed over time? I don't think it's fixed, but I do believe it has to be authentic. I think most of us in the room would probably agree. It's amazing because companies could try to mimic things that are done at one company to create that world class culture, that environment that you want to create for your employees. But it's not easily mimicked unless it's truly authentic to the senior team. So I think that's one of the things that is quite special about Edmunds, that from top all the way down, there is a shared sense of putting our employees first, putting innovation first. It's because of these principles that we're able to do these things that we talked about today. It's not in the belief system; it's just practices that fall right on its face. I've seen that happen within other organizations. And yes, I do think it constantly needs to adapt. For example, like our ROW culture. We have a result only work environment which essentially gives our employees the freedom to work however they want to, wherever they want to. We adopted ROW in its textbook form; it didn't work for us, but I think it's adapted to become us over the years. So we've adapted that to work best for us and our employees. Definitely not fixed. Thank you so much. Let's thank Julie, Paddy, Eugene and Phil. 