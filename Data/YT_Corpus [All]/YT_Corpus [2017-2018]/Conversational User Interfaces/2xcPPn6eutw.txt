 Hi, welcome to Udacity. I have the privilege and honor of interviewing Dr. Ashwin Ram, senior manager of AI Science at Amazon Alexa and Dr. Sebastian Thrun, president and co-founder of Udacity. Can you tell us a little bit about yourselves, and how you got into AI, and some of the projects you worked on in the past? So my first introduction to AI was Doug Hofstadter's book, Gödel, Escher, Bach. I came to the US to study engineering in grad school and rapidly discovered that AI was my passion. I also found my wife here, which is nice. I had an interesting experience, I did a PhD in AI at a liberal arts school at Yale. So I was studying science and technology but also being exposed to the human side of technology: so looking at philosophy, psychology, design, the human experience and that colored the way I look at AI. You know, my story is somewhat similar. I was in college and I wanted to understand people. And I studied philosophy, medicine, some psychology, a little biology. And I studied computer science as my major. And in computer science I found AI to be an interesting study of the human intelligence. And I got really frustrated with philosophy because people make these outrageous claims and they can't back it up. They can't say, here's a system and the system does exactly the following thing. Because in AI you couldn't make an outrageous claim at the time. It's very small but at least could build an entire system. So I got really intrigued about building robots that do something good I can understand. And what are some of your past projects that you're most proud of in AI? Well, I've worked on self-driving cars. I've built a huge number of different robots. I've built robots that would explore abandoned mines and build mine maps. I've built robots that went to Smithsonian Museum and gave tours to tourists, robots in the medical sector that help elderly age and be able to be more mobile and so on. And these are all AI projects. All the way to more like intellectual perception projects. I did a project recently on fighting skin cancer where we could show that an adequately trained AI is better in fighting skin cancer than the best human doctors. How about you Dr. Ram? I think my most previous project is the first one I did and it's also the last one I'm doing now. I've worked on a range of things. I've worked on robotics. I've worked on computer games, AI for games. I've worked on machine diagnostics. But I started my life in language understanding and in looking at how AI might understand human language and learn from human language. Several years later, full circle, now at Alexa I'm working on the same problem again. The progress has been amazing. The progress has been amazing and there's still a lot of hard problems to solve. Alexa, what time is it? The time is 2:07 PM. It's so cool. So you're currently working on Alexa and voice user interfaces. How are these two different? And, also, how do you explain to the lay audience the difference between conversational AI and voice recognition? The voice user interface part of Alexa or any other system is the speech recognition part. Right? We have to understand what words you just said from the sound waves to turn it into text. And then we have to also understand what you are asking. In this case, Sebastian was asking about the time, and so we have to then respond back with the time. That gives Sebastian a voice interface to a well known application. In this case, the time application. When you get into conversational AI, now he is talking about truly understanding what language means. Why the person is asking me this? And what response he might want? So if I ask Alexa to wake me up in the morning, what I'm really asking is set an alarm in the morning. I didn't say that. People don't say what they mean, they expect you to infer that. So you can ask Alexa something quite complicated. Like, "Alexa, who was the president when Obama was a teenager?" Richard Nixon, Ronald Reagan, Jimmy Carter, and Gerald Ford were the US presidents when Barack Obama was a teenager. So there's a lot of inference going on here. Firstly, what kind of president? Not a company president like Sebastian, the country's president. We know that because we're talking about Obama. Which Obama? We have shared knowledge of the world around us and we know exactly who Obama refers to. We also now, we can't look up a web page to find the answer to this question, it doesn't exist. We have to go back and do some inference. There's many steps involved in figuring out what time period were we talking about? Finding the individual piece of information and collecting it together on the fly. All of these are hard problems and it all has to happen in about a second. What are the implications of voice user interfaces for interfaces in the future and for human computer interaction? I would say we trained ourselves to use our fingers and, in the beginning, it was a very cryptic language to talk to a computer. In the early days, you had to do PIP and LS and crazy commands. And then we got to a point where we can move stuff with our hand mouse around. We trained our hand to move left and right, and up and down, or your finger on the trackpad. And now it's coming full circle, now we can just talk to our house the same way we talk to our family. So there's no instructions. They can unpack Alexa as example, and put on your desk. And the only thing you have to learn is their name. So you call Alexa and then you can talk to her natural language. And I think it's a great ability to take this compute idea and make it so pervasive in our lives without any training whatsoever. That just everyone in the world can benefit from it. Yeah, very similar story. For years, we've been typing to our computers and other devices. You know, we type on microwave control panels, and TV remotes, and all kinds of things. And for the last few years, 10 or so years, we've had touchscreens so we've been able to touch and swipe and so forth. But that's not how we communicate. When we want to talk we are not typing at each other. We are not touching and swiping. We're just talking and you're talking back. Right? Why can't our devices do that? Not just computers, all devices. Why can't they talk to my thermostat, and my microwave, and my car, and every other piece of technology? Imagine the world of technology being accessible to everyone not just to the techno savvy. I think that's the future of AI. I just spent in a hotel and Alexa was part of the hotel room, we've talked about this before - with this recording and I could go in and open the curtains using voice. So do you think we're upon the end of keyboards as we know it? Would you say that it's happening soon? I think there's a sweet spot for IV mortality, they're never going entirely away. If we look at the ability to, the number of word counts per minute and so on, keyboards will have the sweet spot. But I feel bothered by the fact that I have to move my fingers to talk to a computer, honestly. I'd rather talk the way we're talking right now. I think this is the first time it's become a reality. That's why I'm such a big fan of Alexa. And I really am not just because he is sitting here and working with us. I'm a big fan of Alexa. I have many of them at home because it is, for me, a complete new era of computing. Yes. So, again, the sweet spot. We still need to type things. We still need a mouse and keyboard. If I'm making a PowerPoint presentation or writing a word document, I'm not going to speak it out. And I certainly can't draw using my voice. But that's a very niche use case. I think from 80, 90, 95% of what we do in our daily lives voice should be just fine. That's amazing. We actually do some speech to text dictation when teaching. It's a tool for rapid prototyping sometimes at Udacity when we're scripting out our courses or content. So there's also that use case too. So you're solving a major challenge with conversational AI and what are the product challenges and the technical challenges that you're encountering along the way? So there are several science challenges and, of course, engineering challenges as well. On the science side, I mentioned some of them earlier: understanding meaning, understanding the speaker's intent in talking about something. Another tough one is in a conversation where you have multiple tones in a dialogue, you have to track context across dialogue. A lot of our conversational agents nowadays are very good at transactional interaction. Sort of one-step: play music, tell me the time. But in order to carry on a multi-step conversation, we have to track the context of the dialogue along as we go. That's another really hard problem. Personalization is a hard problem. Personality in the dialogue is to every individual. On the technical side, there are a lot of challenges in training some of the machine learning systems that I use to do this, it requires a lot of data. It requires a lot of computer power and lot of times. So we have highly paralyzed training systems that are used to train models. These models have to run in real time, that's a hard problem as well. And they're typically too large to put on a device. So you also need connectivity to the cloud at all times with fast enough response rate and low enough latency. Dr. Thrun you have any questions? Well, I would say, as much as I'm fan of Amazon Echo it's still in the infancy. So this box, at some point, should be smarter than the smartest Stanford professor. In fact, my several PhD students would say I'd rather study with Alexa than study with Sebastian. If you look at the spectrum of [inaudible] , now the point being, we have good transactional models. I actually like this much over the previous generation of speech systems where you had to learn the vocabulary. My car had to understand which word to use. This is now flexible enough. It understand stand me without any training. But as you said, I think it's becoming really wise and smart. And being real coached with me and understand what I want. It's a long step. And the reason I mention this is because I know you guys are hiring. It's an amazingly great feat to be in right now. I mean, this is amazing. But just think about where it is going to be 10 years from now. When I can come home and it knows exactly what my favorite food is, and knows that the spinach is spoiled this day, and it reminds me of this. Or maybe even ordered already and Amazon drones came by and delivered it before you even thought about it. That's an amazing vision. This can become really a personal assistant in some sense. Yeah, that's absolutely a future that we can all look forward to. Again several hard challenges in realizing that. Speech recognition is near solved. We get very high accuracy with no training on most systems now. The next step, of course, is the conversational language understanding I talked about. Once you've done that, the beyond that, to get to the kind of vision you're talking about, we now need reasoning. We now need these systems to be able to understand us and reason about our world not just the language part of it but listen about our goals, and our beliefs, and our intents, and our desires and recognize that you're home late, and want a quick meal, and have that drone deliver to you ahead of time. I think the next big challenge in AI is going to be reasoning system, natural language or otherwise. Yeah, it's going to be complete transformation. We're going to look at these devices as dinosaurs. You could touch them and so on and you could probably text somebody else? And it does show me the time, but it was in my pocket. And if this technology becomes pervasive and you never ever touch a device again. And you don't even know what devices are anymore because they're with you when you go to your office or go jogging. And then there's another device with you and it just seamlessly integrates. That is going to be the future of computer science. And so many of us get stuck. Like, they think, OK, in the mainframe time it was mainframes. In the smartphone, smartphone is the ultimate thing to do. And they can't really think ahead what's next. I think this is showing us the way ahead. I agree with that. I think the future of computing is where we won't see computers anymore. We have that with motors, electrical motors, and everything around us. We never see them, we don't talk about them, we take it for granted that they exist, and they do the right things for us the right time. Computing should be like that. Do you both imagine that computers will be embedded in our environment all around us? Or do you imagine it being embedded within us? Or we're constantly carrying it as we're carrying that dinosaur brick. I for one can't wait until I have at least one chip embedded in me. It really, really upsets me to have to authenticate. And I would love to pay this, on this way, honestly. And I'm super happy to have a chip implanted if that's what it takes. So that I can just move around without, like, every so and so often I have to go to my phone and read some two factor number, and then punch it back into a browser. That's just so wrong, in my opinion. Will I go further? I mean, if we really go far out I think that's an opportunity to have a brain interface that's better than speech. Right now, our brains are limited in part because our own I/O is not very good. We are very slow in speaking, very slow in listening. So maybe we cannot get to the system that newborn babies know a lot of stuff about the world already because they have a brain interface. I don't know. But before that happens, I just envision that my clothing, my environment, my building, and so on will have this pervasive network of whatever evolves out of Amazon Echo that is able to listen to me, understand me, and assist me. Yeah, I agree with that vision as well. I think there is a value to having a conversational interface in addition to having a brain interface. Just like typewriters didn't go away I don't think voice will go away once we have brain interfaces. There are many use cases where you want, for example, a conversational companion at home. Yeah. You know, a babysitter for your kid. Or a companion for an older person. You don't necessarily need a computer reading your great-grandmother's brain. When people live to be 250 years old you want them to be able to talk to them. So I think this use case will follow them, but I think computers will be everywhere. They'll be on us and they'll be around us. There's a great book, regarding the companion topic, it's called Marjorie Prime, or it was a play that was recently turned into a movie. And it really goes into AI and companions. I think it's a great film and a great play. I highly recommend it. On the topic of hiring, which you mentioned earlier, and the topic of the challenges in AI, as you know, we have an Artificial Intelligence Nanodegree program at Udacity, and we have this self-driving car Nanodegree program that Sebastian pioneered. What are the challenges and skills that you think are most important that students need to have to tackle these challenges in the near future? So we're very excited to be partnering with the AI Nanodegree at Udacity. And I've spoken to many of the students. I think they're bright and they have great futures ahead of them. One of the interesting things about AI is that, when you think of this future world with AI being embedded everywhere, AI jobs aren't just in AI. They're in every part of life. You know, you will need some knowledge and understanding of AI. So what is that knowledge and understanding? You need to understand how to make sense of large amounts of data and build models that will enable you to then predict the future based on other new data you might not have seen yet. You need to be able to do that kind of reasoning and inference that I talked about. You need to be able to do problem solving and decision making that is really data driven and also contextually knowledge driven. And so the Nanodegrees that you're creating have a lot of the core technology and a lot of the core understanding. The thing is, you do need to understand the algorithms and the math, but it's really more than just that. It's trying to understand what are the kinds of conceptual frameworks you bring to bear when trying to solve a problem? In computer science, well, I used to be a professor, we call it computational thinking. Just like you have design thinking and you have other kinds of mathematical thinking. Computational thinking is a way of thinking about problems and this AI thinking is another newfangled way now that's just emerging and will become pervasive. What I find fascinating is the way recent work in AI is changing the way we program computers. In the past, a software engineer would sit down and think about every possible contingency. So if you write, say, an Android operating system there's 12 million possible contingencies and you write this amazingly long kitchen recipe like, if this happens so this, if this happens so this, if this happens so this, and then iterate to this. And because it is so hard to anticipate every contingency you would pay these people lots of money. Of course, many of Udacity students expect to make a lot of money and hopefully make lots of money doing this. But the transition to machine learning now is kind of much more, I think, much more humane. We don't tell kids in the first 18 years of life every possible contingency and then let them out. We let them learn. If you give them examples and then make up their own rules and they'll learn from their own data. And now we're at the point where our AI systems we can actually teach them based on data. So rather than telling it, this is exactly what this vowel looks like, this is exactly how we process documents, how to exactly we respond, let them look at data. That's what deep learning really has done to us in artificial intelligence. And I think it's a paradigm shift not just for AI. It's a paradigm shift for all of computer science. In the future, I think, there will be a much strong component of trusting our machines to find their own rules than having to sit down and give them all the rules by hand. One of the effects of that is going to be that these machines will all be different from each other. Even today, your Alexas that are in your house are different from mine. Because they're personalized, they're learning about me, they know what music I have, and what time I wake up in the morning. As you fast forward that into the future, these self-learning machines are all going to be different. So nowadays if you go out and buy any piece of technology, a car or a computer, they're all identical if you buy the same model. That will no longer be the case. Different training data in every household? Identical twins turn out to be often very different. And it's not the DNA that makes them different. It's the environment. Different environment, different experiences. So these AI's have experiences as well and as Sebastian said it's all about learning from those experiences. So the programmers of today are people who know how to design models that can learn from experiences as opposed to building code. And that's a complete new skill set that doesn't exist today. If you go to any major college, you learn how to code and so on. But this new kind of programming is so brand new and so interesting and I think it's just now coming to the point where you have really interesting results like self-driving cars, cancer diagnostics, legal document discovery, speech recognition, natural language understanding. All these things are now getting to the point where they become really really interesting. Is Amazon hiring, Dr. Ram? We're hiring a ton. Amazon is hiring 100,000 people this year across all the different businesses. That's a lot of people. Alexa is hiring as well. And we are certainly super excited about our partnership with Udacity. We have our recruiters talking to your folks and we have a pipeline of really good people. I see more and more candidates with some kind of Udacity Nanodegree on them which is nice. I have a question for you? If you had a magic wand to solve one hard technology problem, what would it be? Like, something that bugs you when you wake up in the morning and say, this is me in the way of meeting needs whatever you want to build? I think the big gap right now in AI is what people sometimes call the knowledge graph, is knowing enough about the world. So the data driven vision that we talked about is great when you have all that data and you have all that computer horsepower. And you can train these machines with all possible contingencies that you might have seen. When you're in something new, new situation, new use case, new problem you want to address, or when, again, back to the example when we're just talking, we share a lot of knowledge about the world, how do we capture that shared knowledge and make it available to computers? Really, nteresting. When I studied AI and so I'm used to AI, we were much more than knowledge-based world, [inaudible] building out this big knowledge-based and so on. And now, we seem to be much more in the perceptual world when we can recognize voice and recognize images and so on. Do you think the pendulum is swinging back? I think it'll emerge. I want to see hybrid solutions. I've worked in for years, as have you, in the knowledge-based paradigm. I know its strengths and its weaknesses. And now with the data-driven and machine learning paradigms, there are certainly limitations there as well. We're going to need both. I think the big problem we haven't solved yet is how we merge them. There's some sort of ad hoc solutions out there, we use a little of this, a little of that, but no truly integrated approach as yet. One more question, in the media, AI is often discussed in some very ambivalent terms like if you talk to people like Elon Musk, they believe AI will enslave us and kill us possibly or whatever. You built probably the most direct system that is in touch with all of us. My Alexas listen to me all day long. I have a concern that some smart AI may break lose, listen to me, and take control of me? I'm not concerned about that. I'm not anymore concerned about that. I'm concerned about, you know, smart people breaking loose, my kids, or friends, or strangers as well. Occasionally, there are rouge people and they maybe rouge AIs, but that's not the dominant future. I think these AIs they grow up in our world, they're socialized in our world. And as we get more and more towards AI's that truly learn from experience, they're going to learn our values as well. And then a lot of good people working on the ethics of AI and building ethics into the AI, I don't know that we necessarily have to build it in as a rule. I think it's something that emerges from the kind of data that they encounter in the world that they live. They learn from us because they interact with us. I'm with you. I'm totally with you. So, in addition, to being a founder of a very successful e-learning company, you're also a technologist. If you have a magic wand and could wave that, what technology, or science problem would you like to have solved? I would literally love to get computers into my brain. I mean, if I look at my example, the Google self-driving car was, that the self-driving car would surpass human driving and it was predictable. And the reason is, when we people make a driving mistake I learn from it or maybe you learn from it. But I won't learn from your mistakes and you won't from my mistakes so all of us have to make the same mistakes. And that's an impediment to progress. Let's say if Google self-driving car makes a mistake, all the other ones know from it including all the unborn cars. So I would love to have a world where we birth a child and they're as smart as a high school graduate or have a PhD and they know something very interesting. Of course, it's physiologically impossible today. But perhaps instead of having to train all these things all our life maybe we can just know them. And we've gotten very close, honestly. And I think if I can Google anything right now or I can Echo anything and I get the facts right there. And it's a big game changer for me because now I know about Afghanistan, know about the Civil War, and all these things just by googling it when I need it. But it's still effort involved, [inaudible] know these things. So can I make a device that I recognize every face I ever seen. I recognize any conversation I ever had. And really put my brain on steroids so I can learn from others mistakes much faster. There would, it's hard to think about today before you involve some crazy implant and I'm not sure people want to have a crazy implant. But, you know, everything is possible. I'll beta test for sure. Sign me up. My friend Eli Brazer is very passionate about the same topic. He's a data scientist at Netflix, and he's very passionate about the fact that humans will pass away. And when a human being passes away, we lose all of that knowledge and all that experience and all of the intuition and the intuitive choices we make. So, if you're a surfer and you go to the beach and you know the waves are choppy you have this intuitive feeling, "Oh, it feels like sharky waters," or "All this experience is lost." So I hope that that our future comes to pass. Yeah. I'm confident. I mean, go back I don't know about a little more than 100 years ago, the world's expert on flights met. And they determined, absolutely, flight is impossible after many decades of trying. Secretly in Kittyhawk, two brothers invent the flight at the same time and they didn't know about it and so on. All of a sudden, "Oh, my god, it's possible." So all these things when people say it's impossible, my take is just wait. OK. Because typically things are possible, in my opinion. And many things that we've deemed impossible like, today, my voice is strong enough that it carries to Australia. And so, I take this thing over here and I talk with someone in Australia. It's amazing. That was deemed to be impossible for the vast majority of human history. So having a brain interface, to me, seems very possible. And we're pretty close in some some areas. There's some very nice brain interfaces, for example, for disabled people and locked-in patients. And the next step is the kind of world that might allow all of us to augment our brain. Not just to control things, like in the case of disabled people today, but also in terms of to ingest the sum total of human knowledge. That'd be amazing. That'd be like The Matrix. No, better. Better. Much better. I don't think we would use human bodies for energy because it makes no sense to me whatsoever. I meant when Neo learns kung fu in, like, an instant. You can learn anything in seconds. That's amazing. Well, that's it for time. That's all the questions we have today. Thank you, Ashwin. And thank you. Thank you, Sebastian. Thank you both for being here today. Pleasure. Greatly appreciate it. And thank you for watching. Join us next time. 