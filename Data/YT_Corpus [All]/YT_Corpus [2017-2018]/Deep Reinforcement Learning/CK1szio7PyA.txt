 This video shows a hardware implementation of Socially Aware Motion Planning with Deep Reinforcement Learning. Pedestrians follow subtle social rules when navigating, like passing on the right and overtaking on the left. A robot that operates in pedestrian- rich environments should respect these rules. This work presents a navigation strategy that accounts for social rules, which enabled autonomous navigation in crowded environments at the average human walking pace. Shown here is a robot outfitted with a suite of sensors including various RGB-D cameras and a Lidar for localization and obstacle detection. Pedestrians are detected by tracking the Lidar point cloud clusters and combined with people detection using computer vision techniques. Each detected pedestrian is shown as a cylinder with a velocity vector. A global path planner is used to find a sub-goal, which is shown as the green vector in the sensor data view. Here the robot waits while a lady gets her coffee. The vehicle uses SA-CADRL, an algorithm developed in this work to move the vehicle toward its sub-goal while taking into account the motion of nearby pedestrians. The next several clips show the robot driving to different places inside a building at a nominal speed of 1.2 m/s. The robot generally maintained a safe distance from pedestrians and respected right-handed social norms. All pedestrians here are part of the regular daily traffic in a large public building. The robot can be trained with either right or left-handed rules depending on the country that it's going to be driving in. Here, we show a right-handed version since the robots operating in the US. The algorithms presented in this work enable autonomous navigation in pedestrian-rich environments at the average human walking speed. 