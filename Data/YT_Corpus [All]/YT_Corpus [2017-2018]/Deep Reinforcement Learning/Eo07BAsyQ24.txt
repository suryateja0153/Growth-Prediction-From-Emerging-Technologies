 This is a recording of a Convolutional Neural Network playing Mario Kart 64 in real-time. The network only sees display pixels and can't read the game's memory. It outputs a single steering value as shown through the on-screen slider. Our AI trains and plays without human intervention, only requiring configuration for each track. The AI is even stable to perturbations from a joystick. In many situations, it can recover from being intentionally directed off the road. We started with TensorKart - a previous Mario Kart AI created by Kevin Hughes. TensorKart learns to map screen images to controller output from recordings of human players. However, TensorKart has two major flaws. The first is that humans must play unnaturally to create good training data. We found that most human input is too jerky for the model to learn properly. The second and most important is that the AI is unstable. The AI is worse than human players, so it accumulates errors causing it to drift off the track. Because human players don't drift off of the track in the same way, the AI has no data that teaches it how to recover. Thus it continues to drift off of the track, never correcting its course. When we replicated TensorKart with our own data, we found that the AI rarely completed the most basic track, often crashing into walls and getting stuck there. We solve these problems by creating a second omniscient search AI. This second AI doesn't use any learning at all. Instead, it can rewind time and try all the possibilities to find the best steering input for a given state of the game. We then trained the real-time AI from the recordings of the search AI. We pull one more trick to ensure that the real-time AI learns how to recover. We start running the real-time AI, but interrupt it at random points, switching to the search AI. We do this for several runs of the track. Then, we retrain the neural network on the aggregated data and start the process again with the updated network weights. This process is repeated until the AI learns how to stabilize itself on the road. The result is an AI that can play reasonably well on many simple tracks and can complete longer ones. Although we trained only in Time Trial we found that the AI generalized to Grand Prix mode. The AI has flaws and doesn't always avoid hitting walls. The AI is especially weak when the left and right walls of the track have the same texture. Future work includes adding support for drifting, incorporating time series information instead of singular frames, and using traditional computer vision techniques to extract the mini-map position. In the video description, you will find links to a playlist of unedited runs, a GitHub code link, and a link to a more detailed write-up with the techniques that we used. 