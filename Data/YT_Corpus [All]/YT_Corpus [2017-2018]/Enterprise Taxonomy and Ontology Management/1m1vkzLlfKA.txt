 So good morning. Everyone 9 AM on the West Coast. I'm Alex Bui, Co-director of the BD2K Centers Coordination Center. So today, we continue our computing overview with what I believe is our fifth talk in this section. I have the distinct pleasure of introducing Dr. Vivien Bonazzi of NIH. Dr. Bonazzi is the Senior Adviser for Data Science Technologies and the Commons, which is what she'll be talking about shortly. She serves on the BD2K executive committee and leads a variety of data science and sustainability efforts through the National Institutes of Health. She holds a PhD in molecular pharmacology and computational biology from the University of Melbourne and was a senior associate at Booz Allen Hamilton, managing several genome and protein bioinformatics projects there. As part of NIH, she has served as the program director for the National Human Genome Research Institute and was part of the Human Microbiome Project, where she was responsible for the bioinformatic and computational elements of that effort. So please join me in welcoming Dr. Bonazzi this morning. She'll be giving us some insights about the relatively new and exciting NIH Commons. So Dr. Bonazzi, thank you for joining us today. The floor is yours. Right. Good morning, everyone. Thank you, Alex. Thank you for the opportunity to speak to you today. So today, I'm going to talk to you a little bit about the Commons, but also just give you a few updates on where we are with that, which is the context of this talk today. So I'm just going to-- can everyone see my screen? Is the answer to that yes, Alex, to you, at least? Hello? Can you hear me? Alex, can you hear me? Hello? We can hear you. OK, great. I'm just trying to get my slides to advance. All right, so the previous slide was just a little bit about myself. Let's keep moving. So I'm going to talk to you a little bit about biomedical big data. I don't know what all of the audience's background is, so I'm going to assume something in biomedical areas and some different degrees in terms of data science. And I'm going to try and build up a picture of, essentially, why we would need something like the Commons, and how we're going to approach it in NIH. So starting, really, at its basic level, this is the kind of data that NIH is well known for. A lot of it is- So starting, really, at its basic level, this is the kind of data that NIH is well known for. A lot of it is-a lot of it was analog, but it's moving more and more to digital sciences. And I think we see that from some of the examples I'm just showing here. And as we get more towards wearables and collecting that kind of information, we're obviously going towards more and more data collection as well. So I think this slide is something that, maybe, people have seen before, which is, we hear about the four Vs related to big data. I've heard of several different other ones. And that is the Volume, as in the amount; the Velocity, which is the speed at which you need to process this information, and it's coming up very quickly; the Variety, in terms of the different data types that we have; and then the Veracity, which is really the trustworthiness of the data and its cleanliness. Can you really trust it, and can you use it? These are the ones that I've seen a lot of, and I've seen a few others. But one of the ones that I want to focus on today is also this, which is that I think that data has value. And it's, I think, a signal of the coming digital economy that I think we're all realizing we're in, and that data is really central to that particular digital economy. I think that economy is characterized by using data to gain a business advantage. And I think, yes, institutions, not just commercial entities, are businesses when we come to data, and I think that organizations that aren't born digital will be at a disadvantage in that new economy. So I think organizations will be defined by their digital assets in the future. And by digital assets, I mean these, in terms of the sciences-- that is, data, software, workflows, documentations, journal articles, and there's probably others here, as well, that I could include. But I think these are the ones that most people would know about. And I think what's really important here is that a lot of the most successful organizations of the future will be those that can leverage those digital assets and, importantly, transform them into a digital enterprise. How do we pull all these pieces together, is the question we have to ask. We know we have the pieces, but what do we need to do? I think one of the key ones is to make data the central currency of an organization. And it's really usable in a digital ecosystem, in the context of where we're talking about the Commons. So really, the transactions of using data is really what the Commons facilitates. And I'm going to go through that in a little more detail now. So let's have a look a little bit about the problem with biomedical data. And when I talked about digital assets before, I want to say that includes data. It isn't just data. And I think there are lots of challenges in biomedical data, and that is-- and they fall in a couple of different categories. There is the journal article, which is still, I think, the end goal of many scientists. And that's fine, but the data, which is seen as a means to an end, is really low value. And I think the argument I was just making before is that data actually has value, and it's higher than what we're giving it at the moment. The data is not FAIR, and that is the term that is being used fairly recently. I'm assuming that listeners have heard of this term, but those that don't, I'm implying that it's Findable, Accessible, Interoperable, and Reproducible. And there have been a number of papers over the last few years which talk about this-- that in fact, if we're going to give data value, it has to have these properties here in order to be able to do something with it. I think there are also limited infrastructures to support FAIR data. And I think what the Commons is trying to do is going some way towards doing that. So here is just a short presentation, which is from the New York Health Sciences Library. Some of you may have seen this-- it's quite long. The original is actually quite long. I've just taken a short abstract from it to sort of identify the problems with data. And this little YouTube video really encapsulates the issues with data. I think it's only about a minute and a bit long, so I'm going to play that now. The link to the full video shown here at the bottom of the screen, so you can go to YouTube and actually have a look at that. So here it is. Enjoy. Hopefully the audio will play for you. [VIDEO PLAYBACK] - Hi. - Hello. - My name is Dr. Judy Benign. I'm an oncologist at NYU School of Medicine. - Hello, Dr. Judy Benign. - I read your article about B cell functions. It was very interesting. I think that I could use the data for my work on pancreatic cancer. - I am not an oncologist. - I know, but I think I could use the data for my work on pancreatic cancer. - Oh. - So do you have the data? - Everything you need to know is in the article. - No, what I need is the data. Will you share your data? - I am not sure that will be possible. - But your work is in PubMed Central and was funded by NIH. - That is true. - And it was published in Science, which requires that you share your data. - I did publish in Science. - Then I am requesting your data. Can I have a copy of your data? - Everything you need to know is in the article. - No. - I am not sure where my data is. - But surely you saved your data. - I did. I saved it on a USB drive. - Where is the USB drive? - It is in a box. It is in a box at home. I just moved. - But can I use your data? - There are many boxes. Well, I forgot to label the boxes. [END PLAYBACK] And as you can see, I think this encapsulates a lot of the problems that we're seeing with data. It's a small vignette. I highly recommend watching the entire video. It's in three parts. So what's changing? We know what the problems are, but let's have a look at what's actually changing. I think one of the things I just mentioned before, which is the issue about making data FAIR, which is Findable, Accessible, Interoperable, and Reproducible, and I've just shown a clipping here from the [? Walkerson ?] paper that came out about a year and a half-- year ago that actually starts addressing this. There have been a couple of additional papers around this area. And I think what it's doing is really explaining what you need to think about when you're dealing with data and the kinds of issues that you need to be considering when you're dealing with data overall. And I think this is having an impact at all sorts of different levels, from institutions like NIH, but I know it's also having an impact across different government institutions, both in the United States, certainly in Europe, also Australia, and in Asia. And I think what you're going to see is the applications of these two data sets as we move forward. Another key issue that's, I think, changing, that's hopefully avoiding what we just saw in that short video, is the data sharing policies from funding agencies like NIH, but I think other agencies that also deal with data, which is making the data shareable-- not just in a form, as in making data FAIR, but also having policies saying we want things to be shared, looking at open data and the standards associated with that, and the things that go along with grants that are actually paid by NIH, and ensuring that that data is made available. But I think we're also seeing a couple other things, and that is that when you store your data, that you're moving towards-- instead of just having it on local repositories or in general archive repositories-- we're actually looking at, now, research data repositories, which store data per se. And there are a number of these that have been coming about, and I think that's also a change in the way that we're looking at data, making these available in a fair format, but also having them available to the broader community, rather than just a USB drive, which is what the previous YouTube video showed. I think the other thing is metadata. Metadata is really important in describing the data that you have. And ensuring that it has quality standards around it is really important. There have been many projects at NIH which have used metadata, but not particularly well, or used community standards. And this is critical for the way that you actually want to index this information, and search it, and make it findable by others and usable by others. Another one which is-- another change that I'm seeing is the use of the unique identifiers-ensuring that we have identifiers for the data per se that are consistent and also to formulated standards. And standards are starting to come across this area. So I think where the YouTube video showed a lot of problems, I think here are some of the areas that I think we're starting to see some change, which is starting to enable the better use of data and to see value in the system. But I think we're still in the early days of this, and I think it's important that it happens from the ground up, from the PhD students all the way up to the leaders of the institutions, to embrace these kinds of changes and to enable them within their organizations, or even at a small level, as graduate students actually do this within their own work. So I think what we're also trying to get at here is that the FAIR principles drive data to become the currency. If you actually can describe it, you know what it is, it's interoperable, it's reproducible, it's basically an apples-to-apples comparison, you can understand what it is that you have. And I think what we also need to look at are policies that promote data sharing via FAIR, can really help change that culture, which is why I think the leveraging of fair principles, and turning those into guidelines that the community can use within the context of their own data, really will help promote this kind of work. So that's great. You make data FAIR. But then I think what we also need is ecosystems that allow transactions to occur on that FAIR data. And importantly for biomedical data, you want to do this at scale. We all know, particularly from genome studies, but I think also from some of the brain studies, where you're looking at not just genomic data, but also imaging studies from those things, that the data is large and getting larger. And it's quite cheap to generate the data, but it's a lot of effort on the other end to store it, and also to look at harmonization and to deal with all of these FAIR concepts. So I think what we want to do is to do all of these things, to look at the way we handle data in the future. So now I want to talk a little bit about the Data Commons. Up until now, I've just explained the kinds of things that we're seeing. I think much of the community knows about big data, but I've tried to sort of lay the groundwork about the sort of pieces around the data, the problems, and the things that are changing. As I just mentioned, what you also need to think about is the way a platform works here to support this whole ecosystem. And really, the work that's going on in the Data Commons is really that. It's looking at a platform that fosters the development of a digital ecosystem to support transactions on FAIR data. So I'm just going to talk a little bit about some of the principles behind the Commons, as we see it. And that is, as I just mentioned, it's a platform that fosters development of a digital ecosystem. But it treats the products of research, whatever they are, as digital assets. And as I mentioned before, these will be the currencies of institutions in the future. We want all of these digital objects to conform to FAIR principles, as I've just said before. And we want these digital objects to exist in some sort of shared virtual space so that you can find them, deposit, manage, share, reuse-- essentially do work on these objects, and do science. And you want to you create a platform, because the platforms enable interactions between producers and consumers of those digital assets. And I think there are many biomedical scientists who produce information that want it to be consumed by others, and what we want is some sort of level exchange to do that. It also gives currencies to the digital assets, and the people who develop and support them. One of the big issues is that the papers that are produced can often have PIs, and that's important to do that, but a lot of the people that do the data scrubbing, the informaticians, some of the software engineers, don't get the kind of currency that they really need when they're actually working on these digital assets. And I think papers are great, but it would also just be very helpful, and I think really good, to give currency to the digital assets themselves, be they-- whatever they are. And I think the most common ones right now that people look at are data and software. And if somebody developed those, they get attribution for that. And there is a way to do that that isn't necessarily a paper. And I think we're starting to see elements of that-- you see that, certainly, within GitHub, and you see it within data repositories that are just involved in sorting data, particularly from papers. So I mentioned before that the Data Commons is a platform. So I'd like to talk to you a little bit more about a platform. And it's essentially a platform that fosters that development of the ecosystem. So let's talk a little bit about what that might look like. And we're in the fairly early days of this. So I'm going to take a quote here from a fellow that I've been doing some work with, here, which is Sangeet Paul Choudary, who's been looking at-- he's written a book called Platforms of Scale. This slide has a link to that. I presume these slides will be made public. I'll certainly put them on my SlideShare afterwards, and you'll be able to download them. Sangeet looks at platforms in the digital space, and I'll explain those in one minute. But here, he's saying, "Platforms is a plug and play model allows multiple participants, the producers and consumers, to connect to it, to interact with each other, and to create value." And what Sangeet just been looking at specifically is all of these platforms, that if I just showed you this icon, you'll identify pretty much all of them. A very classic one is AirBnB, right? It's a platform that allows producers and consumers to interact with vacant apartments, houses, essentially accommodation, with people who need that. And he's been looking at how those platforms are set up to connect producers and consumers, and what really allows them to work, and what are their business models behind that. So as I mentioned before, but I think it's worth stating again, that you want interactions between producers and consumers. So somebody who generates biomedical data and often the tools, but not necessarily just that, wants to be able to share that information with others, either within a consortium or with just others in the future who want to consume it-- say, if they have an new grant that they want to submit, or application they want to submit to NIH. So to understand the Data Commons Platform, and really, how it might work for biomedical sciences, I'm going to use what's called a platform stack to help visualize this concept. Sangeet looks at it in terms of the broader digital community, but I think it's really important for us to look at some of the layers that are really consistent amongst every single one of these platforms that he's been talking about, and certainly consistent with the ones I just showed before, and examples were Uber, AirBnB, et cetera. They're really in three layers. There's a technology infrastructure component, there's a data component, and there's a network marketplace community that consumes this information. In the context of the Data Commons for NIH, this is something I've been working on over the last 18 months or so, and really looking at, OK, how do we look at this-- if this is a platform to support data at-- for NIH data, what's the right way to think about it? And this is something that's just a model of that stack, and a diagram. I'll just walk through it just briefly, here. So the bottom layer is the technology layer. This is where we have a compute platform. You want to operate on the data in some form. We are going to leverage cloud services at NIH, in part because we see a great deal of researchers, particularly using large data, moving from repositories to clouds-- commercial clouds-- essentially doing some work on it, some form of analysis, and once they've done their analysis, they remove it from the cloud, and they have their results. But they generally don't leave their data sets up there, because storage costs are too high, and certainly, moving multiple petabytes of data would incur a huge number of costs for them. So we're looking at, what's the right way to use the cloud platform to facilitate the researchers at NIH? In saying that, we're also dealing with supercompute facilities. They're primarily funded through DOE, not NIH, but we're working with them to figure out how we can collaborate. But essentially, bottom line is, you've got a technology platform here, which is cloud supercompute. S The next layer is data, and we have a collection of data that-- some of those are from large generated data sets, which are funded by NIH. These are often-- I call them reference data sets. They're in the, certainly, terabyte to petabyte range, generated by NIH, usually under consortiums, and with the intent to share. And just some of the examples I can think of, there are the encode data sets, which are used by the community, and also the GTEx data sets, are some examples of ones that I've been dealing with. These are large, hundreds of terabyte, petabyte data sets, which people want to consume, but they can't do that either locally, in their own systems, or at the repositories, because they simply don't have the compute resources to it. But we also have user-defined data, in the sense that people have smaller data sets that they actually want to bring to these larger data sets, perhaps, and actually do some sort of analysis. But the bottom layer is that you've got a whole bunch of data which needs to be computed against. And then the top layer here is really saying that if you have a platform with data, you want to be able to do various things to it. And the most common thing that people see is, you want to do some sort of analysis on it-- scientific analysis. But to do that in these environments, you also need to have a collection of services to enable you to do that. First of all, you need to find this information, so you need some for of indexing. This is where the metadata becomes really important. But also any APIs that can access the data, and you also want, particularly if you're using the cloud, containers. A common form of that would be, say, Docker containers. So there are a series of services that enable you to use this data in these particular environments, and we need to pay attention to those, as well as the scientific analysis tools that you want to use to actually operate on the data. And on the top of all of that, I think what you want is to have some form of interface which allows you to access a collection of these data sets appropriately, and some sort of, really, marketplace to allow those interactions to drive innovation. The other thing you need to do is, obviously, have digital object compliance, and this touches on the FAIR principles. So essentially, this stack is three parts-- some form of compute, a whole of data from NIH in some form, or biomedical data in general, and our collections of services and tools that allow you to operate on that data-- on FAIR data. If you want more information, there's a link at the bottom of the slide that takes you to far more detailed information at the Commons, if you want to read about [? it. ?] A couple of other things I just want to point out, again, looking at platforms in general. If you look at this in the context of [INAUDIBLE] the way IT sees it, the bottom layer is really the infrastructure as a service. And then the layers around the data, and the tools around those, the services and the analytics, these are really platforms for software as a service. And I think this is where we're starting to see some play, certainly, in the market. We're seeing a lot SaaS providers out there, certainly in biomedical sciences. But you're certainly seeing it in other areas as well, and I'll show a couple of examples of those in a minute. But I think we're also going to see a drive to data as a service in the long term, because I think, really, data is going to be the currency to this. And how that looks like, I think we're just starting to understand those pieces. Just a moment about digital object compliance, this is really about making things FAIR. I won't go through this in a lot of detail. I'll just say that there are key aspects of this that we need. We need digital object identifiers that resolve to original sources that's machine readable, and you have a minimal set of metadata, and you have clear access rules and entry in indices. If you do this, I think what that does is, it allows us to move towards FAIRness, essentially. This slide was done a little while ago. So our initial focus was looking at this, and what we've actually started to do is develop working groups within BD2K, but also reaching out more broadly across the community to look at developing FAIR guidelines. What does that really mean, to be FAIR? And that group, I think, started last year, and it's just starting to gather steam. And the purpose is to develop guidelines to share those with the community. Right, here's some examples of just platforms. I'm not endorsing any of these. I'm just simply saying, here are examples. This is a SaaS application that a lot of people who do genomics probably know, which is DNAnexus, that allows you, essentially, to develop-- to use pipelines and various tools, essentially, over clouds. And they have a lot of genomic data, and the purpose of this company, I think, is to enable scientists to really use data at scale. And it's very much a platform that follows some of the principles I just showed for the Commons. Another one is, in this example, is SevenBridges, as well. I think they fall into the same category of a SaaS. And as you'll notice, many of them call themselves platforms, for good reasons, I believe. So I think what you'll find is that the Data Commons, therefore, drives this digital ecosystem. It's the pieces behind it that enable you to do work with that data. And so now, what I want to do is switch a little bit to talk about some Data Commons Pilots and talk about some of the work that we're doing in NIH. I'm not covering all of it. I'm just covering some examples of that, that sort of enable you to hopefully understand a little bit more about the concept of the platform and the Commons. So one of the ones we're working on is really looking at the co-location of large and/or highly utilized NIH-funded data, with storage and compute infrastructure, i.e. a cloud. And they're commonly used tools for the analysis and the sharing of those digital objects. The purpose is to create an interoperable resource for the research community. Another key factor is, the purpose of the cloud isn't just necessarily because the data is large. It's also a place for collaboration and sharing of digital objects. And I think this is one of the key things that we've also found, that researchers often do their analysis, they use, say, a cloud simply because they have large data sets, but they often want to share or collaborate as projects are going on. And collaborators and investigators are located geographically in different places across the United States or across the world. So these environments allow them to do these kinds of collaborations much more easily, and look at the output of the results, collaborate together. Just want to point out that the Commons that I'm talking about in the Platform-- there are the commonses developing out there. And I want to point out a couple of these. Probably one of the best-known ones is the Genomic Data Commons from NCI an NIH, which is looking at much of the TCGA data loaded up into that system, then made available exactly the same way I've been talking about in the general commons concept. But certainly, in the last year or so, we've also seen the emergence of other ones. So the Fred Hutch Cancer Center over in Seattle, also, is developing the Hutch Data Commonwealth. And the New York Genome Center, under Toby Bloom, has been developing, also, the New York Genome Center Commons. There's also been work done at NIH, at NAID, the Allergy and Infectious Diseases Institute, developing, essentially, a microbiome platform, as well, for analysis. So what we're seeing is a collection of commonses happening. The structure of them is very similar to what I've just described before, is the platform stack. They're all using the basic premise, but the data is somewhat different, depending on what the particular data sets they are. But I think it's important to see that they all have fundamentally the same principles, and they're all starting to come together. And one of the other things is, how do we connect to them? And I'll get to that in a minute. So I'm going to talk a little bit, now, about the Pilot. But I just want to emphasize that this is just an So I'm going to talk a little bit, now, about the Pilot. But I just want to emphasize that this is just an example. The data sets I'm going to show here are not the ones we're going to use. They're just examples of the kinds of things that we have. So it's just a draft, but we are actually working on the principles behind this. And some time early this year, in the first quarter, we'll be able to announce some of the work that we're actually doing in this area, and some of the specifics around it. So I'm going to take the platform and just give an example around some of this. So I think what we've got here is, we have a platform. So we have a collection of different clouds that we can use. I think it's important to look at a variety of different clouds, not just one, in part because we obviously want to avoid some level of vendor lock-in. But I think it also is helpful for supporting innovation and competition amongst them. And each one of the systems is different. They do offer slightly different services. That's potentially a problem, and also an opportunity. So I think we're looking at a collection of those, which ones we choose is going to be dependent upon some of the things that we do based on our use cases. The other thing we're doing there is looking at-- if I'm taking this platform, [INAUDIBLE] we would take a collection of data. So here are just some examples of data sets, which are supported by NIH. I'm not saying that these would be the ultimate ones we use. But essentially, what you're creating is a collection of data. They're different types, they don't necessarily interoperate with each other. But essentially, you're creating a pool of data that people could potentially query individually or across, and I think that's pretty important. And from that is going to come from the need to potentially harmonize, or not, and that's a question that we need to look at. But I think a pool of data would actually be quite useful to consider. So if we take that a little bit further, then we could layer on top of that a series of analytics and services. And these are just examples of some of those. Some of those are commercial, some of them are not commercial. Some of them are tools, some of them are tool systems, some of them are platforms as a service, and the Global Alliance is obviously looking at some standard APIs for querying the data. So this is a collection of things that already exist out there, that could essentially layer over the top of this, that could leverage the data in a variety of different forms and provide access to the rest of the biomedical community. The other thing that I think you want to look at is, you need to think, obviously, about the indexing. And there's work being done inside BD2K with bioCADDIE, which is an indexing system, and Bioschemas, which has been discussed with [? Alexia, ?] which is the group in Europe, looking at schema [INAUDIBLE] applications to biomedical sciences. And I know bioCADDIE has been heavily involved in looking at those, as well, and incorporating a lot of that work within DataMed. But the key point I'm trying to make here is that you need some form indexing. I'm pointing out these ones here are just as examples, in part because we're having a BD2K lecture, and we are planning to leverage the work that bioCADDIE [? hands. ?] But it's really critical that you actually consider the indexing of that. Otherwise, what you have is a whole lot of data and a whole lot of tools that are not necessarily easily findable. And I think that's really important, to actually have here and call that in the system. I think another aspect here is how we would leverage this, potentially, at NIH. And I think a real key factor there is, the things that we can actually do is, if we make this data available-- these large data sets available in the cloud, and we can layer on these tools, I think there are multiple ways that NIH can foster the innovation of further development in this area. The tools that I've laid out here in this-- around the analytics and services are currently tools that have been developed. But I think we want to foster more of that. And I've just given some examples here of-- [? our ones ?] were a bread-and-butter grant from NIH, but there are other ways to do this. Essentially, there are ways to get grants at NIH to foster innovation over the use of this particular data. And I think we definitely want to do that. But I think what we also want to look at is consider looking challenges and prizes. Why? Because I think it could be really interesting to sort of ask questions across some of this data, assuming the consents allow us to do that, to really kind of think about new ways that you can actually intersect and ask questions across that data to enable discovery in a different way. You can do that, I think, from a couple of different angles. One, from a biomedical one, where you can ask an interesting biomedical question across these biomedical data sets to improve the outcome-- the biomarker, some sort of new discovery, a better understanding of a disease, all of those are relevant. But I think what is also relevant is the services and tools that are needed to do that at a faster and more accurate rate. So how well can you predict a biomarker? What's the best way you can actually do that? What are the tools that you need to do that? What's the statistics you need to do that? Those are some of the aspects, I think, here, that some of these challenges and prizes could also address, that I think could yield to some pretty interesting ways that we could leverage this particular data. I think the other thing I want to point out is that over the top of this whole thing, you want to have this marketplace, which is-- I'm using the term app store, because that's where people really have their best understanding of how it works, when you use an app, and it works over the top of data, or within your system. But I think, really, I'm going towards the concept of a marketplace. How do we actually have a collection of tools, systems, data that you can easily find and create a marketplace for the way that you operate over particular data sets or particular tools? What's the right way to think about that, rather than a single way to view a data through one set of tools alone? I think that's pretty critical. Another aspect to consider about here is what I call the authorization authentication layer, and there is the-- a lot of this data was likely to have human subjects issues. So some will not, but some does. So for example, human microbiome data does not, but many of the other data sets do. So we obviously need to think of the right way to handle that from NIH. And much of the data that's human based is stored at dbGaP at NCBI. So there's a critical discussion, there, to happen about, how do you set up the authorization authentication layer that allows you to get access to that data in the appropriate way? And we've been having conversations around that, within NIH, about how that might actually occur. But that's pretty critical, so that you can ensure that only the people that are permitted to use the data can actually access that. Another thing that I want to point out here is that this isn't the only Commons. What we're looking at here is NIH-funded data. But as I pointed out before, there's a collection of different commonses that are being developed. And I think what's really important, there, is that we start talking with them now, not at the end. Otherwise, we create cylinders of excellence, and that's not what we want. So I've certainly had conversations with all of the folks that I pointed out before, and there are more and more folks thinking about this. And we've started some discussions around, what's the right way for these pieces to interact and intersect? And where are they separate? And they need to be separate. So obviously, one of the most obvious ones is to look at it through an API access point between these commonses. And looking at how we can run services between them, it's complicated, especially when we deal with human subjects' data. But I think the conversation is the important point here-- that we don't want to simply look at providing data and creating innovation on the topic point here-- that we don't want to simply look at providing data and creating innovation on the topic from NIH, and not connecting to what other folks are already doing in their other commonses. So I have some considerations I want to just talk through now, and that is metrics. What I'm describing here is essentially a platform to support biomedical data that uses cloud data and services. But understanding how, and you account for all of the data usage, is really important, because there will be-- we need to understand how it's being used and why. There's also a cost, particularly for these large data sets. Cloud storage is not cheap for the large data sets, particularly if you want to put them in more than one cloud. In saying that, many of the commercial providers are very interested in working with us, because they see the value of a platform and an ecosystem that is more than just data storage. So we are in, obviously, lots of deep conversations with them about the right way to interact. This is also a pay-for-use cloud compute. There is a project which is being developed in NIH called the NIH credits model, and I'm not going to speak about that today. But it's really looking at, how do you pay for those services directly, and how does NIH really understand what people are paying for? For example, when you are using cloud services, a lot of the time, you get free credits from the cloud providers per se, which is great. But if you probably tried to include everything that you used on the cloud in your NIH grant, it probably would be very expensive, and it would take a fairly large chunk out of your grant. There are also other issues that we need to deal with, which is the indirect costs for cloud. When you submit a grant to NIH, there are indirect costs, which are associated with the research institution. And I think what we need to look at is the way that these things, obviously, interact, and what's the right way to pay for these and also to deal with the institutions? And now, let's be clear-- the commercial clouds are useful in the sense that they have scale, but there are many groups out there that have already developed private or institutional-based clouds. And there's good reason for doing that. Cost is one, privacy of data-- there's been a lot of concern, if you put this commercial clouds, what's the right way of handling that? I think we're still in the midst in determining those things. And so I think we will see situations where hybrid clouds really are important and necessary. And we need to look at what's the right mix between those. And that's pretty-- a very important thing to look at. We have to look at managing open- versus controlled-access data. The controlled-access data is obviously related to human. And we've got to look at, what's the right way to manage that? I mentioned that before, that the authorization, potentially through a single sign-on, is the way to do that. But is that really a dream or a nightmare, because it's-- from what we've seen, it's really a very complicated set of things to do. And there may be reasons where a single sign-on is good, but there may be situations where that's not possible, so we need to sort of test all of that and figure out what's the right way to approach it. It's important to point out that we need to look at the difference between archiving versus working and versioning copies of the data. NIH requires that we keep all our data, certainly the-- we archive it. That's where very large archives like NCBI are very important in EBI over in Europe. But if we put working copies of the data onto the cloud, they're not archives, and we need to know that that's what we're actually doing and why. Another one is, if we do move copies of large data sets to the cloud, obviously, versioning is going to be pretty important. So how do we handle that? That leads to all sorts of issues around syncing, and I think whatever we do in testing this, we need to figure that out. Another one, which I mentioned before, is interoperability with other commonses. Many of them are going to be based on clouds. The ones I mentioned to you before are going to be based on clouds. And it would be important to ensure that we don't have these cylinders of excellence, that we actually have interoperability between these clouds. We also have standards around metadata, UIDs, and the APIs. And the key, I think, here is to reuse what we've already-- available to us in the community. There is work being done, certainly within BD2K around metadata templates by Mark Musen's group at CEDAR. There's a lot of work being done by various groups with UIDs, and there's the Global Alliance, which has been looking at open-standard APIs. There's also work being done within some commons, smaller efforts looking at open-standard APIs that incorporate metadata, and that are smart, and actually know they can find different APIs and locate them, so that we have a better understanding of what's available to us. But this is critically an important area that we need to have further development in. Discoverability touches on the indexing issue. I mentioned bioCADDIE before, but we need to look at-- bioCADDIE's one place to start. And it's a really good place to have-- to use. But there are other ways to do that, and we need to-- and the field is changing, so we need to figure out what's the right way to support that kind of work. And particularly, if we're going to have data and digital the right way to support that kind of work. And particularly, if we're going to have data and digital objects of various sorts across different clouds, that's going to be an interesting problem to try and solve, as well. Regarding interfaces, I think that's really pretty critical, because you've got users with different needs and different capabilities. Certainly, in the early versions of what we're trying to do here, will probably the most usable by those that have a whole lot of bioinformatics capabilities already, and understanding. But we understand very clearly that biomedical researchers don't necessarily have the capacity, all the time, to have bioinformaticians in their group. And so we need to be able to have interfaces that are available to biologists that don't have those capabilities, but definitely want to be able to use the data. So that's something we're really being very mindful of in all of these pieces. Consent-- this is a really important piece. So we're getting onto some policy pieces here. Reconsenting of the data may be necessary, and that also could be very complex, particularly if you're trying to traverse across two different data sets that weren't consented to be using for the purpose of using them to mine across two data sets. So we have to be very mindful of those consents in the first place. And so engaging with the right folks to talk about that is really important. We've certainly been doing that at NIH. There are policies that need to be also considered in such an endeavor, and that is the data sharing policies that are useful and effective to support this kind of open science. We have some already at NIH, but I certainly think we need a further focus on this, and there are certainly efforts underway at NIH to do this. And I think we need more effort in this area, and I think NIH understands that. I think we also need to keep pace with the use of technology. And here, the example I'd give you is the example of dbGaP data in the cloud. This is-- a couple of years ago, the policy precluded the use of dbGaP data in the cloud. This was a big problem for researchers, since they wanted to use that data in the cloud, because they had-- it was large, and they also had large data that they wanted to compare it against. But policies precluded the use of that. And so a group of us, including myself, helped change some of the policies around that to enable the use of dbGaP data in the cloud. So sometimes what happens is, technology is further ahead than the policies. And we need to do a good job of making sure that these two things are aligned. And again, it means that we talk-- in the case, the Office of Science Policy, and work with those people to ensure that they understand what we're trying to do, and vice versa, so we can keep up to speed with the changes in the technologies. I think incentives are incredibly important here for the shareability of FAIR data, as part of the grant review criteria of NIH. By that I mean, when you submit an application to NIH, you obviously missed all of your papers, but it would be really good if people could also cite their data and software, and any of the other data assets-- digital assets that you have in a way that's meaningful and consistent. So I think we don't have any incentives in there right now, but I think we're really looking at the fact that if data becomes currency, and FAIR data becomes currency, what's the right way to include that in the review system when you're putting in applications to NIH? I think we also need to look at governance, which is, how do we do this? How do we actually govern the overall way that we handle a commons? I think what's critical here is to have community involvement in this governance model that isn't just generated by NIH. If this is really going to be an open-- a platform for open science, and an ecosystem to be able to use data at scale and to share it, then I think getting an understanding from community involvement is really important. And I think a key one here, the last one I've got here on my slides, is sustainability. We all know that grants have a cycle at NIH, and then they end. So what's the long-term support for this? If we do move data, for example, in the cloud for some of these large data sets, how do we sustain that in the longer term? What's the right business model to do that, and what's the right way to attempt to do that? I think these are all questions that we're having in terms of what we are trying to think about, how we approach the commons. So I think I've got just to my last slide here, which is the acknowledgements. And there's a lot of people that have been involved in this. And most-- there will be some folks who recognize the names here. But my point I want to make out is that there's a lot of work happening across NIH that isn't just within one Institute. It's across many institutes and in places that are unusual, so to speak, and sometimes we do bio work. And that is CIT, the Center for Information Technology, and Andrea Norris's group, who's also the CIO of NIH, which is all the pure computing side has been working heavily with us. Also, Common Fund, who's very interested in this kind of work, has been working with us. I've listed, also, the Clinical Center is working with us-- the NIH Clinical Center-- to look at some of their data. And also, the Office of Science Policy. So it's a collection of folks across NIH. But I'd also like to just have a shout-out to Research and Industry. We've spent a lot of time working with our industry, primarily cloud providers, but also the SaaS providers, and also other folks in the community developing commonses. And they have been providing really good and helpful input into the way we're thinking about the commons. So it's really a unified effort across NIH in these discussions, in places not just across certain institutes and centers, but in places that wouldn't normally be involved in this. So it's really touching on the issue that data is really the currency of the way we have to go forward. So I'm just going to end by just saying thank you for your time. I hope that this has helped you understand a little bit about the path that we took to the Data Commons, that we have some idea of some Pilots we want to do for these large data sets. And in the coming months, we'll be able to explain a lot more detail around what that will be. But essentially, what NIH would like to do is to enable the use and access to NIH data sets to the community. And the innovation we hope will come from the community, and how you will use those data, and how you will actually develop tools, systems, services, platforms, et cetera, over the top of that. The data sets are large, and they cost. I think this is where NIH really needs to play in the game, and we need to help the community get access to that data so that we can innovate both in the data science realm, as well as the biomedical realm, so that we can actually foster new discoveries. All right, I think that's where I'm going to stop right now. And I think we're going to take some questions, is that right? It is. Thank you, Vivien, for this great overview, and for giving us an update on what's going on with the NIH data commons. So we've actually got quite a few questions for you. I'll just go through some of them. We'll start with this first one, which sort of has to do with the fees that are always associated with big data. And this is actually touching on the veracity component. And the question is really, given that we're moving toward these sort of open data repositories, and public access to this information, and obviously, sharing the information, as well, and people being able to put their own data into it, how do you know that you can trust the data? How do we actually get to veracity of data? Right, and I think that comes down to some of the FAIR guidelines, and making sure that you know that when people apply them, what's the right way that we can-- I don't want to use the term policing, but we need to know that we can do that. And that's a complex issue. I think if we can agree to a set of guidelines of what FAIRness is, and then we can empower ourselves to use those guidelines, I think that's important. I think another thing that we need to consider is that, as people start using them, if more transactions happen on quality FAIR data, if they meet the guidelines, then the incentives kick into play, right? So if more people are using the data, and it's in FAIR format, and it's compliant, and you can quote it, say, for example, in an application for NIH, that's a good thing. So are there are ways to do that where it's actually driven, in part, by policing policy-making. And some of it is, I think, pushed by the community, where if we agree to a standard, it makes the transactions and the systems stronger, and the data more usable and more quotable. So I think it comes from a combination of two different things. And I think it also comes from the fact that we don't yet know how to do all of that. But knowing the fact that the data can be dirty, and not quality, I think is really important, too. So I think it allows for a little bit of wiggle room to say, I don't think we know, yet, the entirety of the system. OK, I mean, it-- definitely, it is an open question. And it's how do we look at that? So following up on that sort of question is another one from-- regarding the culture of data sharing. And what is your perception of where the community is in terms of this new culture of data sharing? Do you feel that there is a broad acceptance, or a growing acceptance? What proportion of scientists and researchers do you feel are embracing the data sharing and participating in it, versus those that are basically going to have to be mandated to do the data sharing? Well, this will be my entire opinion, but I can try and address it from couple of different regions. My own personal view is that the participants come from a couple of different regions. I certainly notice it with the younger generation. So the postdocs and the grad students-- their openness, their approach, they come from open. So their mindset is open. So they tend to share. I think as you go up the seniority stack, so to speak, some of the PIs who are there now, who come from an older generation, don't have that kind of mindset. So that creates some issues. But that's not true of all of them. I think some certainly see the value of it. But the mentality, I think, has been changing in the current generations and the ones that are coming through now. So that's one of the things that I see. And so as the grad students are going through the system, and becoming professors within departments, they'll bring their culture with them. It will take time, but I think we're going to see that. And also, I think we've got some, perhaps, enlightened souls who are pretty senior in their organizations, who are also beacons of trying to push this through. And I think there are plenty of examples that we see. So the combination of those, I think, are what I see changing. I think the funding institutions play a crucial role in this. And that is that the funding institutions also have to provide incentives. So as I mentioned during my talk, you need to think about-- well, we at NIH, need to think about the way that this enters the review system. So if there is an incentive for a digital asset that has either-- primarily, data or software is where the talk is right now-- that has, for example, a DOI associated with it, that that can actually be listed as something very important in your grant application. And that that has value and weight within the way that NIH sees it. And when it does, a review. It's not just about your paper. It's all about the other things that have occurred, as well. And there, it touches on the fact of what you just mentioned before, which is, well, if I've got a bunch of these things, and I have DOIs, how do I know that the quality of that data is high, or not just a bunch of data that is meaningless? So what are the bars there? And I think the application there is, how do we do that? And I don't think we know yet, and we have to look at it. But I think it's really important that NIH think about the way that they set up incentives for that, and they also have policies in place which are the-- I guess the stick part of the carrot and the stick, where there is some level of ensuring that the community follows some rules. But I think it would be wrong for NIH to simply use the stick all the time. It would be good to have both of those in play, in part because that's the nature of the way systems work, and not all humans play fair. So I think it would be really good to see if we could have a combination of those. That's just sort of my broad, general view of what I'm seeing with the culture change. I'm certainly seeing it changing more and more. Every year, I see changes. And that's, I think, a good thing towards open. I would agree with you on that. I think there is a culture change that is happening. It's not happening overnight, but it is slowly percolating up and becoming more common. Another question, and this is going to some of the comments-- or some of the remarks you made regarding bioCADDIE and other sort of efforts. The question revolves around researchers being able to find the most appropriate resources for their needs. And I would assume that that is both with respect to data and the tools and software. Could you comment further on other sort of works that bioCADDIE or other groups that you're aware of are doing to sort of help researchers in this regard? aware of are doing to sort of help researchers in this regard? Sure. So I think this is a wide-open field. So I think bioCADDIE has been doing a lot of work in this area, to try and find ways of indexing resources. And I think we're in the early days of that. I'm not going to go into the details of bioCADDIE here, in part because I know it to a certain degree, but I think the question is more relevant broadly. I think there's a lot of efforts happening, both in industry as well as in research. I've certainly seen it within BD2K, that there are different slants on the way that you might want to look at discoverability. It partly depends on what you want to find and how you want to find it. Some things are more discoverable than others because of their metadata. Sometimes they're different kind of objects. Sometimes you're going to find software, sometimes you don't. So there are multiple research and commercial efforts underway. And I think what we need to do is to sort of do some bake-offs to see, how do they work against some of the data and tools that we have? How does that work? And I think we're just starting to begin that whole process. I'll give you an example of some of the work I've done with Zenodo, over at CERN in Europe. They're looking at how that they-- both a repository, but also access points for data and tools. How can they search for that? So what's the right way to do that? And then once you do find it, how do you connect it with a service? How do you do something with it once you've actually found it? I think there is that, and then an obvious one, of course, is, Google's really good at this kind of stuff. And a lot of their work around schema.org, which is now being incorporated into bioschema.org, I think is another effort to look at, how do you leverage ways that methodologies related to discoverability can be used in more appropriate ways for biomedicine? So for example, I know that bioCADDIE has been moving towards incorporating a lot of that work within its own DataMed component. So I think it's a wide-open field, and it's both got industry as well as researchers across the world looking at this. And I think we're at the stage where we really need to start probing into, what are the different resources that are available? How do they do it differently? And is it-- does it impact what you're searching for? If a different-- does it matter which type of digital asset you're searching for? I think that's currently where we've been thinking at NIH. And I think the work that we've seen from bioCADDIE has been helping us better understand the way that the community is thinking about it. And as bioCADDIE has been looking at indexing various data sets, we're sort of seeing the outcome of those, and saying, well, that one worked, and this one didn't work so well. So that helps us feed back into the system to say what we need to actually do. It's a pretty general answer, but I think that's just generally where we're at the moment. Fair enough. I think that there are, obviously, lots of BD2K-specific projects that are also looking at indexing from different perspectives. I know that there's ones from UCLA, and there are others throughout the different centers of excellence, so-- And I think the good thing is that they're all coming together under one umbrella. So actually, there was a question that was posed, which is talking about FAIR framework, and the working groups around that. I think I can answer that for you, in this particular case. Someone asked, how do you go about finding out more about FAIR and joining the working group? There is a Commons framework working groups that actually addresses FAIR and other aspects. And we'll make that information available more broadly to the community after this talk, if individuals are interested in finding out more about FAIR and the various working groups that Vivien has mentioned. Yeah, that-- I would add, Alex, there, that Valentina di Francesco over at NHGRI is the contact person for this-- from the NIH perspective, too. Yes. So one last question before we go. This has to do, again, with the platform and the idea of collaboration. Do you envision any types of collaborative tools to support active collaboration, or being more proactive in forging collaborations within the cloud-- or not within the cloud, within the Commons? So things like being able to communicate, find researchers- Yes. So I-- yes, I do. And I think that layer is often not seen by-- often by NIH. But for example, figshare, that does a lot of these connections, [INAUDIBLE]. There are groups out there that have pieces of information that would be really useful to connect with in this environment, not just the data. There are also people that are developing collaborative-- tools for collaboration that allow connections, data to tools through services, but also ways to do other things, like linking to scholarly research and scholarly papers, journals, publications, et cetera. And there are several groups looking at that, and have actually developed some platforms in this area. And I think we need to look at what that will be, because one, the way that they're developing those collaborative platforms, so to speak, are a lot easier for biologists to use. They don't-- there's a lower learning curve. curve. And the cloud, to some extent, if it's being used, is hidden in the background. But it's still being used, but it's a whole lot easier for the people to connect to it. If you think about it, like, for example, I gave the example of AirBnB. You can see it immediately. You just see the picture of what you want, and then you can connect to it. All the pieces that happen underneath, behind it, the data, the cloud, all the rest of it, is visible to you. But it means that anyone can use that platform. And I think that's where the collaboration pieces fit into play with some of these tools. They're going to enable more and more people to use these environments, and it's going to enable them to do science faster, and at scale, with lower levels of computing capability. And that's fine, because many biologists don't have that. What we have to do is, we're right at the start of figuring out, if this is what we're looking at as the ecosystem, what do we need to test? And there's a lot of technology we need to test before we can get to the place where it becomes smooth transactions in that environment. Hope that helps. That's great. So thank you again, Vivien. I know it's 10:00, at least on the west coast. Thank you for your time in this presentation. We've had a lot of great questions and discussion. And [INAUDIBLE] the insights you provided were wonderful. Sure. I'm happy to take questions offline. I think my desktop still has my email address. I'm happy to take private questions about this. You can find me in different places. I'm also going to put this presentation up on SlideShare after this meeting, in the spirit of open science, just making sure everything's open. Great. Thank you again. Thanks so much, everyone. Have a good day. 