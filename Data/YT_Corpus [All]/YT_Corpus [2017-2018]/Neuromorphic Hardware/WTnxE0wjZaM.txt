 Hello world it's Suraj and what is the future of deep learning? That's the topic for today? Inspired by something that Geoffrey Hinton recently said this talk is gonna be divided into three parts. I'm gonna talk about how backpropagation works what the most popular deep learning algorithms are right now and Finally seven research directions that I have personally hand-picked, okay That's the talk in three parts, so let's get started here So this whole video was inspired by what Geoffrey Hinton recently said in an article so Geoffrey Hinton is the Godfather of neural networks? He's the guy who invented the backpropagation algorithm back in 86 Which is the workhorse of all almost almost all deep learning, okay? So without backpropagation all the great things. We're seeing in deep learning would not be possible today self-driving cars image classification language translation almost all of it is because of that propagation so this what Hinton recently said is causing shockwaves in the deep learning community He said that he was deeply suspicious of backpropagation his own algorithm and said my view is to throw it all away and start again, and I have to say that I Agree with Hinton. I know it's crazy right because back propagation has just given us so much But if we really want to get to artificial general intelligence We've got to do something. That's more complicated or just something else entirely because It's not just about stacking layers, and then back propagating some hair gradient recursively. That's not gonna get us to consciousness that's not gonna get us to systems that are able to learn a Huge variety of tasks everything from playing games to piloting an aircraft to figuring out the most complex equations in the universe It's got to be about more than just gradient based optimization, so Let's first start. Let's first talk about how back propagation works Okay So the billion dollar question is this probably multibillion-dollar actually how does the brain learn so well from sparse? Unlabeled data. That's how we learn we don't sit there We don't have labels for everything we're learning if you look at a baby It's incredible how much it learns without some kind of supervision Right it can learn how to do all these different tasks stack blocks and all these they Learn how to speak and there are no labels per se in the sense that we use them in deep learning It's all happening unsupervised and when a sparse means few right so it's not about very dense Descriptive data. It's sparse right. There's a lot of zeroes in it and yet we can still learn from it So how does it do this well, let's first understand how back propagation works so in Back propagation so first of all a neural network is a huge composite function. It's a function Consisting of other functions and these functions are all in the form health layers right so you've got a input layer a hidden layer maybe multiple hidden layers, and then finally an output layer and You can look at it as this four-step process that I've got right here So the first step is to receive a new observation X in a target label Y so this could be some image of Cancer cell and then the label cancer right and they could be either cancer or not cancer and so you'll take that input and you already have the label right, that's That's how back propagation works as long as you know that label You are golden, but you've got to know the label so you take that input It's an image think of it as a series of pixels, so it's just a huge group of numbers So it's a vector right so you take that group of numbers and you Then you go to step 2 you feed it forward through the layers. What do I mean? What do I mean by feeding it forward you you continually take that input? Multiply it by some weight value add a bias value and then activate it by applying a non-linearity to it and you Continually do that over and over again until you have an output prediction, and I'm gonna go over this more in a second we're gonna look at the code, but once you have that output prediction you compare it to your actual prediction your real label by doing this a difference the subtraction right you you're subtracting the actual from the from the that right and that that difference because it's these are all just numerical values that difference is your error and Then you go to the last part step for back Propagating that error so once you have that error you're gonna compute the partial derivative of that error with respect to each wait Recursively for every layer so you'll compute the partial derivative with respect to the layer before and then you take that error Gradient that you that you've just calculated and use it to compute the partial derivative with respect to the next layer and you'll keep doing that every time and then what happens is you're going to have a Set of gradient values that you can then use to Update all the weights in your network for as many as there are so the process is input feed-forward Get the error back propagate update the weights repeat feed-forward Get the error back propagate the peat Over and over and over and over again hundred thousand million times right and that is the back propagation algorithm I'm gonna go into it in more detail, but that's at a high level, okay, so The paper that I'm talking about where Hinson released this I've got it linked to right here, but it's a very old paper It's it was it was done in 86 and the reason it was created in 86 and the reason that Hinton is such a gene Is because everybody was telling him. This is not gonna work You've got a thing of something else, but Hinton held strong to this belief okay, and I think that is the mark of a good Researcher if you really believe in something To not let anything else influence what you believe in right stick to your belief if you're wrong you're wrong But at least you stuck to what you believed in and you and you listened to other opinions as well But you really you really believe in something so the reason that it works now And it didn't work in the 80s is because now we have the computing power and the data necessary to have these huge amazing classifications and these amazing generations right for classification and generative models for both So let's just look at this canonical example of a very basic neural network that uses back propagation Scratch out the input number for it's just three inputs right so we have it's a 3 layer Network input hidden and output I'm gonna go through this Kind of fast because we're gonna get to what really matters in a second here And if already if you already know how backpropagation works just skip forward probably I'm gonna estimate five minutes from now So we have this very simple basic neural network and the goal is to take some input data And then predict the output label right, so we've got some input data Which is a series of triplets 0 0 1 0 1 1 you know etc and then we have a? set of Associated labels 0 1 1 0 so for 0 0 1 The Associated output label Y is 0 and then etc etc Alright, so that those are our inputs and our outputs. We have this non-linearity which is a sigmoid function. It's an activation function and I'll talk about that in a second, but we'll take our input data We will take our output data And we want to learn the mapping function right so then given some new output 0 1 1 or 1 0 1 some arbitrary triplet we'll be able to correctly predict the Output label as it should be Right so the first step is first to initialize our weight values so our weight values are a set are both matrices They are they are randomly initialized matrices And so what happens is when we have our input right so again remember just scratch out the fourth one It's because there's only three. It's a triplet We'll take that input triplet multiply it by the weights And those are the matrices and so that's why you see these arrows right the reason we're using we they say we need linear algebra in deep learning is because linear algebra takes the standard algebra operations like multiplication and division and addition And it applies it to groups of numbers that are called matrices So linear algebra defines operations that we can apply to groups of numbers Matrices for example the dot product, which is used heavily in deep learning That's in fact that is the multiplication we use in all types of deep neural networks It's a way of multiplying groups of numbers together, which is what we're doing right? We're taking our input multiplying by a weight matrix And then we take that result and we add some bias value and a bias acts as our anchor It's a way for us to have some kind of Baseline where we don't go below that in terms of a graph think of like y equals MX plus B it's kind of like the y intercept for this function that we are trying to learn right and once we've Multiplied our input times our weight value added a bias and then applied some activation function to it which is our Non-linearity the sigmoid that's going to give us an output And we just take that output and do the same process for the next layer and the next layer and however many layers we have Okay, so that's what we're gonna do using the dot product and then we're gonna back propagate the error once we compute it so back propagation You don't need to know all of calculus to understand back propagation You only need to know really three concepts from calculus the derivative the partial Derivative and the chain rule which I'll go through in a second so first I'll go through the derivative so the derivative is the slope of the tangent line of a function at some point and Though an easy way to compute the derivative for some function like say y equals x squared or any function is to compute the power Rule which I have right here, so you'll take the exponent and you'll subtract one from it And you'll take the original exponent and move it to the coefficient so for y equals x squared You take the to move it to the coefficient subtract one so then it becomes two X to the first which is two x So the derivative of y equals x squared is 2x so the reason and so the derivative tells us the rate of change It tells us. How fast some function is changing and What what is happening for for gradient based optimization in neural networks in all of deep learning? Most of deep learning is we have some if if we were to map out all the possible error values on the x axis so Just imagine these are all errors And then all the possible weight values on the y axis it would come out to be a parabola Just like this and what we want to do is we want to find that minimum error value we want to find those weight values such that it's gonna give us the minimum error value and What that means is we want to find the minimum of that parabola and the way we're going to find that minimum of the parabola Is by computing the derivative which tells us the rate of change of wherever we are and then we're going to use it to update Our weights such that we are iterative ly incrementally continuously moving closer and closer and closer and closer to that minimum point And once we have that minimum point that is our optimal point where the error is smallest and the weights are at their most optimal Values such that the error is in the me the smallest every time we make a prediction right That's why it's called gradient descent in general right so when we take this very very popular Optimization formula gradient descent which I just described and we apply it to deep neural networks We call it back propagation right because we are back propagating an error gradient across every layer that we have and so The reason we know we need to know the derivative is because we're you because we're going to what we're actually computing is the partial Derivative it's derivative because a neural network Don't just have one variable it has several variables right for however for however complex your function is so We want to compute the partial derivative of the error with respect to each weight right so When I say with respect to I'm talking about that way and none of the others So you can think of a partial derivative as saying okay? Well what is a partial derivative with respect to X for this equation? What that means is we are only computing the power rule for X and we are ignoring everything else So Y to the fourth is ignored and when we compute the derivative of X It's going to be 1 right so then we are left with 5y Now if we're doing the partial derivative with respect to Y, then we don't care about X we only care about Y so we do the power rule for Y to the 4 so it's 4y cubed plus 5x because Y The derivative of Y has 1 so then the X remains so that's what we're computing we're computing the partial derivative And that's what's going to give us our error gradient the gradient tells us how which direction to move on that parabola To get to that the optimum of that minimum point gradient descent and the last part is the chain rule right? Because a neural network is a giant composite function right look. What did I just subscribe I described taking an input value Multiplying it so of input times way add a bias activate, right We've talked about this before input times weight added bias activate that is the formula that is happening that is the function right? That is happening at every layer And these layers are nested so every time you add a layer You are adding a nested function inside of this giant Composite function that is the that is the neural network so the chain rules tells us how to derive a composite function What you would do for a composite function is derive the outside keep the inside and multiply it by the derivative of the inside So that is a rule and that rule apply for cursive leaf Or as many nested functions as you have So that's the chain rule and so now that we understand that we can do back propagation that there's there's your calculus primer on doing Back propagation so the rest of this very canonical example is saying for 16,000 iterations. Let's feed forward That input data through each layer, and so what we do for each layer is say, okay. We've got K. 0 That's our input multiplied by the first synapse matrix and by multiply I'm talking about dot product Thank You numpy apply the activation function or non-linearity to it so the activation function the reason we do that is because a neural network is a universal function approximator, I'm Telling you a lot right now, so just don't worry if you don't understand everything There's a lot more to come and then re watch this video, and I've got a million other videos on this stuff as well So I'm very excited right now Where was I? Okay so we were taking the input times the weight were at Input time and so in this case we don't have a bias right because this is very basic But usually we have a bias, so we're doing input times weight Activate okay bye times. I'm talking about dot product so we say okay And then you repeat that again for the last layer, and then k2 is gonna be our output prediction And then we compute the error by finding the difference between our actual output in our predicted output, then we perform back propagation We take that error weighted gradient and we see in what direction is this target value by computing the activation of that output value and multiplying it by the error and that's going to give us the gradient value the Delta the change right and that Delta is what we're Going to use to update our weights in a second, but we've computed the Delta the gradient for this layer right though The hidden lair let's get it Let's compute the gradient for the next layer so recursively So we'll use the k2 Delta to can see how much the K 1 value Contributed to the k2 error and once we've got that K 1 error we'll we'll do the same exact problem process again to Compute the K 1 gradient, so the first layer is gradient and once we have both gradients Then we can up update both of those weight values using those grades And we just do that over and over again 60,000 iterations that is back propagation So I wanted to go into a tangent no pun intended to talk about derivatives and ingredients and how back propagation works But that propagation is the workhorse of deep learning? And this is a great chart the neural network suit that shows many different types of neural networks There are so many types of neural networks out there. It's not just one. There's a lot right and back propagation is the Optimization strategy of choice for almost all of them right almost all of them use labeled data And then back and then back propagation has an optimization strategy to learn some mapping function right everything is a function in life Everything is a function love is a function emotions are a function that the sound of the airplane above and then relating that to How fast velocity and you know all these different variables? It's all you can represent everything as a function math is everywhere math is all around us math is beautiful. It's beautiful seriously. Oh My god, it's awesome anyway everything is a function right so we're trying to learn the function and Supervised learning using back propagation is a way for us to do that so How do artificial and biological neural networks compare so this is a very basic view of how they compare the idea It's such a rough It's such a rough the initial perceptron the initial neural network were so roughly inspired by Biological neural networks. It wasn't like they were saying well. Let's let's implement a neuro trend let's let's implement You know dopamine and dendrites in all of their details. I mean neurons are these very complex cells It's very basic all the only inspiration is saying you have some neuron it's got a set of dendrites that receive some input it Performs some kind of activation from some kind of activation on that neuron what what that means is it decides whether or not to? Propagate that that signal onward or not using some function and if it decides to then it sends it out. That's it That's that's the extent of the inspiration between artificial and biological neural networks, right Because we have some input we compute some activation function like riilu or sigmoid Or you know there's there's many of them out there And then we output the value right so the brain has a hundred billion of these neurons Numerous dendrites and it commits it uses parallel chaining so each neuron is connected to ten thousand plus others Compare those two computers right computers don't have neurons in terms of hardware They are made of silicon And they are serially changed Which means these transistors on or off switches are each connected to two or three others and they form logic gates? So with and they are great at storage and recall even though. They are not as parallelized as our brain They are still better than at some things we got to admit Then we are like it's better at calculating numbers in in memory right we can't compute a million times a million But uh, but a computer can however what our brain is really good at that computers are not is Creativity right we are able to take some idea that is completely unrelated to another idea and apply it and then It results in some amazing innovation, or task and we are great at connecting different concepts together We are great at being able to learn many different things and apply our knowledge to many different tasks And that's what we should be trying to do with AI and so there are some really key differences between our brain and Artificial neural networks first of all everything in the brain is recurrent that means there is always some kind of feedback loop happen In any type of sensory or motor system right not all neural networks are recurrent There's a lot of lateral inhibition, which means that neurons are Inhibiting other neurons in the same layer. We haven't seen a lot of that in deep learning There is no such thing has a fully connected layer in the brain connectivity is usually sparse although not random Usually we have fully connected layers at the end of our networks like say for convolutional networks, but in the brain there are none, right? Everything is sparsely connected, but it's it's smartly sparsely connected Brains are born pre-wired to learn without supervision So we talked about this a little bit right now babies can know things even though they don't They learn there aren't given labels or any kind of supervision and lastly the brain is super low-power at least compared to deep neural networks Right the brain's power consumption is about 20 watts compare that to arguably one of the most advanced AIS today alphago it used about 1200 CPUs and 176 GPUs not to train But just to run just imagine how much how many watts that takes that's like an order of an order of magnitude More power than our brain takes, which is which is annoyingly inefficient right so we can Definitely definitely definitely improve on that There's this great book by this Harvard psychologist Steven Pinker Which I've read and I would highly recommend it called how the mind works, and this book is from a neuroscience perspective Not a machine learning perspective, but we need more of that We need more of that because there are certainly a lot of Secrets here that we haven't figured out But we're trying so this is a great book to read and it's a there's a great quote from that book that I'm gonna read Out to you Which I particularly like the quote is the brain is not a blank slate of neuronal layers waiting to be pieced together and wired up We are born with brains already structured for unsupervised learning in a dozen cognitive domains some of which Already work pretty well without any learning at all right evolution has primed us to be able to do certain things even though we don't have any Real-time learning happening. It's just wired into us right so there is something to be about structure versus learning everything Anyway, okay? So we've talked about that so where are we today right so that was the first part here the second part And then we'll get to the third part research directions, so where are we today in? Unsupervised learning we know where we are with supervised learning that means when we have labels But what if we don't have labels well we can divide machine learning into two types besides supervised and unsupervised classification and generation Right these are two tasks and one meta way of looking at it as is as creativity and discovery when everything else is automated for us when all of the You know all of the brainless labor that we don't care about when all that is automated what's gonna be left for us humans is our two tasks Creativity and discovery right what can we create? What can we discover and we're and we and we can frame those things as classification discovery and creativity? Generation so for classification what is something? clustering right clustering is perhaps the most popular technique when it comes to classification and There are many ways to cluster data, right if you don't have the labels, but you do have the data Maybe you can learn clusters for all of these labels Such that they're that you'll be able to know what groups each cluster are in so it's like learning without labels right there are several strategies to learn clusters from data k-means is perhaps the most popular dimensionality reduction techniques like T distributed stochastic neighbor embedding or th t-sne or Principal component analysis, there's an anomaly anomaly detection But most of them still used some sort of supervised learning And the ones that don't use back propagation are not necessarily better There are actually very simple algorithms like k-means is just you know these four steps right here It's very simple. There's it's just basic arithmetic and That's where we are right now There's also Auto encoding right auto-encoders are really popular for unsupervised learning the idea is that? If you are given some input try to reconstruct that input Through outputs you have an input you learn some dense representation and you try to reconstruct it from there And this is great for dimensionality reduction Alerting some feature some features etc For generation perhaps the most popular right now is the generative adversarial Network, so I met the creator he and good fellow We had a good conversation in San Francisco We had you know he's a really smart guy and really I mean the idea was so basic right it was such a basic very intuitive idea Yeah, it is the reason behind a lot of hype and deep learning right now The idea is to have two networks one tries to fool the other right you have a discriminator And you have a generator and so what happens is you have some data set let's say some images And you want to generate new images that look very similar But they're new so what you do is you take one network And it's it takes in an input of one image it applies some distribution function to it right in latent space so what that means is like a Gaussian or something like that so take some Gaussian distribution Multiply it by that image and so the image is basically a Group of numbers right pixel values and when you apply some distribution value to it you change those numbers ever so slightly So then if you look at it as a picture. It's that It's it's a slightly modified picture and that picture is then fake and it only does this sometimes sometimes it shows the real one it shows a fake one and The discriminator is a classifier it right So you know what the real image is and you know what but you don't know the fake image is fake Or not right the classifier doesn't know so it's got it So it tries to classify the fake image? And if it gets it right or wrong you could take its Prediction compute an error value between the real and the fake and then again back propagate an error gradient value Right so you are still using back propagation Across it so the whole thing is what's called end-to-end differentiable because we can differentiate Every weight value in the in this in this system so even though there are no explicit labels We are still using back propagation It's self supervised so it's like we are creating the labels Another great example our variational auto-encoders what we are embedding stochastic city inside of the model itself That means inside of the layers we have a random variable what that means is The the neural network is not deterministic. It's stochastic you cannot predict. What the output is gonna Be that means that if you have some input you feed it through these layers One of them is a random variable so it's a distribution that's applied to that input What happens is the output is going to be some unpredictable? New output that you didn't predict before which is what you're trying to generate, right? and Lastly, and these are the bleeding edge of unsupervised learning models by the way and lastly is the differentiable neural computer So I I am gonna go out on a limb, and I'm gonna say that the DMC is the most advanced algorithm currently that uses That propagation out there Maybe maybe alphago is better, but we haven't seen the source code for that so I wouldn't know but in terms of openly available Source code. The dnc is is is Amazing it's also highly complex. There are so many moving parts in the differentiable neural computer And I have a video on this just search DNC Siraj But there are so many moving parts here. You've got read and write heads but basically You are separating memory from the network itself Right so you have memory and the analogy fit that they made was between DNA and the brain right so you have DNA these this is encoded external memory so you have an external memory store and then you have your your internal controller right and so the the net the The controller is pulling from the memory And there are read and write heads between the controller and the memory Between there there are links between different rows in the memory basically you have let me show you this. Let me show you this you Have so many different Differentiable parameters all of these you have you have read and write heads you have Ellis TM cells every single one of these matrices are and Everything one of these major trees are differentiable So this is a gigantic very complex system and everything is differentiable right so that there's that and so now And what they did was for the DNC was they? generated a random graph and of Different subways and they use it to try to predict where someone was gonna go based on some questions Which is just incredible? They also trained it on family trees and a bunch of other things but Basically the best unsupervised learning methods still require back propagation so my point here is that back propagation really is the workhorse of deep learning even in the unsupervised setting but Another thing. I want to say is that a lot of Deep learning research is all about making small incremental improvements off of existing ideas and a lot of times academia kind of pushes us in that direction It pushes you to make incremental changes, maybe like tweaking one hyper parameter or adding some new layer Type or maybe new some new cell type like at GRU or whatever, but if you have but if you if you if you think of a radically new idea You can really shake things up seriously, and the idea it doesn't even have to be that difficult It really does it it doesn't even have to be that complex like think of games like think of generative adversarial networks It's such a simple idea you have two networks one tries to fool the other that's it It's just two neural networks one tries to fool the other and Jana Kuhn said this is the hottest idea in the past 20 years in deep learning and Look at this. I mean this idea was invented Just two years ago look at the number of Gans that have been have been inspired by that first Paper there are so many and this is in two years all of these different. I could go on you could make an entire Four month course on all the different types of Gans out there so my point is Anyone can think of a really good idea when it comes to D? Pointing the the playing field is is level for everyone, so let's get to their future research directions, okay? So the first one so my thesis is this is that unsupervised learning and reinforcement learning? Must be the primary modes of learning because labels mean little to a child growing right so we need to use more Reinforcement learning more unsupervised learning, and then we're gonna get to somewhere somewhere better than where we are right now so the first We research Direction is Bayesian deep learning, which is not discarding backpropagation is just making it smarter What do I mean by this Bayes Bayesian logic is all about having some prior assumption about how the world works versus frequentist, which just assumes that We have no assumptions right so when you take Bayesian reasoning and apply it to deep learning you can have Amazing results and this has been proven in the case of variational autoencoders But deep learning struggles to model this uncertainty so when I talk at what I want in what I? Specifically mean when I say Bayesian deep learning is smarter weight initialization and perhaps even smarter hyper parameter initialization right and this kind of relates back to a child and how Evolution has primed us to know certain things before we've learned them in real time right there are certain learnings We already have we are weights in our head are not initialized randomly when we start learning We have some sort of smarter weight Initialization so Bayesian logic is is it is a great direction is a great research direction just combining those two fields Bayesian logic and deep learning The second one is called spike timing-dependent plasticity and a great analogy for this is saying You know you're trying to predict if it's gonna be raining or not you can go out there And you can see if it's going to rain literally with your own eyes Or you can look at your roommate who tends to take an umbrella Every time he goes out and every single time he walks out with an umbrella It happens to be raining so rather than try to go out there yourself look at it's raining or not Instead you just look at your roommate see if he picks up an umbrella, and if he does you know that it's gonna rain So you take an umbrella so the analogy applies to spike timing-dependent plasticity? Because you can't properly back propagate for weight updates in a graph based network since since it's an asynchronous system, so we trust neurons that are faster than us at the task so it's all about timing looking at neurons and Faster firing and using those neurons as a signal as a signal for how we learn so suppose We have two neurons a and B And a synapses on to be The stdp rule states that if a fires and B fires after a short delay the synapse will be potentiated, okay So the magnitude of the weight increase is inversely proportional to the delay between a and B firing So we're taking timing into consideration which D pointing currently does not do the time of firing? The third idea is our Self-organizing maps so this is not a new idea at all, but that's okay. That's another thing that I want to mention There is so much machine learning and deep learning literature out there There is a lot and a lot of times the best ideas are forgotten They are lost in the mix because there's so much. Hype around certain ideas and sometimes. It's unnecessary Hype around certain ideas and some of the best ideas could have been invented 20-30 years ago I mean look at deep learning right so it's just all about finding those ideas and self-organizing maps are one of those ideas where You know this is an older idea, but it has a lot of potential and not many people know how these works how these work But this is a type of neural network that is used for unsupervised learning so the idea is that? We have we we randomized the node weight vectors in a map of them, so we have some weight vectors And then we pick some input vector, that's our that's our input data And we traverse each note in the map computing the distance between our input node and all the other nodes And then we find the node that is closest the most similar to our input node that is the best matching unit the B mu then we update the weight vectors of the nodes in the neighborhood of the B mu by pulling them closer to the input vector and what happens is this creates a self-organizing map and you can visualize it as different colors, but it's a basically clusters of different data points, so It's basically clustering, and I think this is a great idea. It doesn't use it that it doesn't use back propagation And we should look more into that the fourth idea the fourth for the fourth direction or synthetic gradients, so Who Andrew Trask has a great great blog post on this that I highly recommend you check out It's really in-depth, but this idea came out of deep mind this idea came out of deep mind And it's basically it's a much faster version of back Backpropagation in which you are not waiting as long to update your weights so individual layers make a best guess for what they think the data will say then they update their weights according to that guess and They call this best guess the synthetic gradient because it's a prediction of what the gradient will be not what it actually is and that Data is only used to help update each layers guess or synthetic gradient generator, and what this does is it allows individual layers to learn in isolation Which increases the speed of training individual layers can learn without having to do a full forward and backward pass So that synthetic gradients, and I think and and it's weird because even in the machine learning subreddit people who are talking about synthetic gradients but Some of the questions were hey we need more of this Why hasn't why hasn't this been talked about more and people don't know right? So this is a great idea came out of deep mind and definitely learn more about synthetic gradients the fifth research direction is our Evolutionary strategies so open AI had a great blog post on this Evolutionary strategies as a scaleable alternative to reinforcement learning But evolutionary strategies have not given us a lot of success so far, but that's okay Just intuitively they make a lot of sense right trying to resemble evolution you have Fitness you have a fitness function that determines how fit some individual is and these individuals mates right so there's Crossover and you know it's basically survival of the fittest you have you have mutation selection and crossover via of Fitness function and You can do this with a lot of games right so you can have several neural networks And you can use evolutionary strategies to have the best one win or or survive longer than the rest so I think there's a lot of potential for that and it's very similar to reinforcement learning so if I if I were to pick the lowest hanging fruit right the lowest hanging fruit in terms of Revolutionary ideas to come to the table of really radical changes It would be in reinforcement learning deep reinforcement learning Reinforcement learning is all about learning from trial and error right you have some you are some agent in some in some environments, right? It's called the agent environment loop you perform an action in that environment you get a reward Yes or no and then based on that reward you update your state your learnings, and you continue that process so alphago Used reinforcement learning deep reinforcement learning to get really good at its game And there are so many low-hanging fruits and deeb reinforcement learning how do we learn the best policy? Just there are so many unanswered questions so reinforcement learning in general is a great place to Do to just focus on in terms of research and the last one is the most capital intensive and perhaps the hardest but I just had to mention it right we talked about how transistors are on off switches and They are chained together serially to for to perform to form logic gates whereas neural networks are Are parallel in their construction so they're connected to ten thousand other ones so? Perhaps instead of trying to replicate the rules of intelligence in Silico or at least on the current types of chips we have let's just change the hardware completely right at the hardware Level and IBM's neuromorphic chips are a good example of going in this direction Google's TP use tensor processing unit but basically the idea is to wire up transistors in parallel like the brain Really, I think I think anyone can can do this. You know you if you have some idea I mean think about it the brain is only running on 20 Watts So it can't be that expensive right in terms of hardware or wetware right so there So if you have some idea you can crowd fund it for whatever Hardware you want to build and then you know use we funder or Kickstarter and yes I think you can even have a start-up for hardware for for machine learning for deep learning, so what is my conclusion? those are my seven research directions that I wanted to talk about today as a way as a Response to Hinton talking about backpropagation, so what is my conclusion? What do I think I think and so I agree with Andrey Carpathia? Who is one of the best deporting researchers out there? he's a director of AI a Tesla now and The conclusion is this let's create multi agents simulated environments that heavily rely on reinforcement learning and evolutionary strategies Carpathia this great talk at Y Combinator, which I didn't attend, but I the slides are online, but check this out He had this one slide that said intelligence the cognitive toolkit includes, but is not limited to all of these different aspects of intelligence attention working memory long-term memory knowledge representation emotions consciousness there are so many different topics that encompass learning it's this Orchestra of different of different Concepts and they all work together to define intelligence or intelligence so the Conclusion is we need to create environments that incentivize the emergence of this cognitive Toolkit so doing it the wrong way is to use this Environment what does this incentivize? incentivizes a lookup table of correct moves right for pong But what is doing it right this to agents in this world. There's some food. There's some survival There are learning to adapt to each other. It's much more like real life itself right and that incentivizes a cognitive toolkit cooperation attention memory emotions even right with more complexity so It comes down to the exploration versus exploitation Dilemma from reinforcement learning how much do we want to exploit existing? Algorithms back propagation by making incremental improvements versus how much do we want to explore entirely new ideas? And we need people doing both we need people improving the deep learning algorithms because there's still a lot to be improved upon But we also need people working on exploration like entirely new ideas in fact I think we need more people Focusing on that that we have currently so if I were to you know take some away I would say let's take 20% and put them 20% from the exploitation and put them in the exploration category so Yeah, it's just something to think about I hope this video helped you think more about all these concepts and where we're headed and where We should go I hope it gave you some ideas for what you might be more interested in and I'm gonna keep making videos like this so Yeah, please subscribe for more programming videos and for now I've got it evolved so thanks for watching 